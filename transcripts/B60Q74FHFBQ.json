{
  "id": "fyh6cbrboiskr5zpja6sek4jea",
  "version": "91ee9c0c3df30478510ff8c8a3a545add1ad0259ad3a9f78fba57fbc05ee64f7",
  "input": {
    "audio": "https://upcdn.io/FW25b4F/raw/coding-train/B60Q74FHFBQ.m4a"
  },
  "logs": "Transcribe with large-v2 model\nDetected language: English\n  0%|          | 0/116529 [00:00<?, ?frames/s]\n  2%|▏         | 2480/116529 [00:06<05:02, 376.51frames/s]\n  5%|▍         | 5436/116529 [00:13<04:44, 390.27frames/s]\n  7%|▋         | 8312/116529 [00:21<04:47, 376.14frames/s]\n 10%|▉         | 11108/116529 [00:28<04:30, 389.19frames/s]\n 12%|█▏        | 14040/116529 [00:36<04:26, 384.68frames/s]\n 14%|█▍        | 16780/116529 [00:41<03:55, 423.15frames/s]\n 17%|█▋        | 19644/116529 [00:49<04:05, 394.62frames/s]\n 19%|█▉        | 22588/116529 [00:57<04:03, 386.41frames/s]\n 22%|██▏       | 25584/116529 [01:04<03:40, 412.24frames/s]\n 24%|██▍       | 28260/116529 [01:16<04:30, 326.59frames/s]\n 27%|██▋       | 30988/116529 [01:24<04:18, 331.26frames/s]\n 29%|██▉       | 33988/116529 [01:32<04:04, 337.64frames/s]\n 32%|███▏      | 36836/116529 [01:41<03:58, 334.04frames/s]\n 34%|███▍      | 39478/116529 [01:48<03:45, 342.17frames/s]\n 36%|███▋      | 42326/116529 [01:57<03:36, 342.76frames/s]\n 39%|███▊      | 45002/116529 [02:03<03:18, 359.61frames/s]\n 41%|████      | 47886/116529 [02:11<03:11, 357.82frames/s]\n 44%|████▎     | 50886/116529 [02:20<03:06, 352.50frames/s]\n 46%|████▌     | 53542/116529 [02:29<03:06, 337.76frames/s]\n 46%|████▌     | 53542/116529 [02:40<03:06, 337.76frames/s]\n 48%|████▊     | 56342/116529 [02:41<03:23, 295.05frames/s]\n 51%|█████     | 59276/116529 [02:51<03:11, 299.28frames/s]\n 53%|█████▎    | 62232/116529 [03:00<02:57, 305.47frames/s]\n 53%|█████▎    | 62232/116529 [03:10<02:57, 305.47frames/s]\n 56%|█████▌    | 65224/116529 [03:11<02:52, 297.39frames/s]\n 58%|█████▊    | 68104/116529 [03:20<02:39, 302.74frames/s]\n 61%|██████    | 70836/116529 [03:28<02:28, 307.85frames/s]\n 63%|██████▎   | 73516/116529 [03:36<02:13, 321.41frames/s]\n 65%|██████▌   | 76108/116529 [03:42<01:59, 339.26frames/s]\n 68%|██████▊   | 78956/116529 [03:48<01:41, 369.74frames/s]\n 70%|███████   | 81912/116529 [03:55<01:28, 390.57frames/s]\n 73%|███████▎  | 84824/116529 [04:01<01:17, 407.59frames/s]\n 75%|███████▌  | 87532/116529 [04:07<01:09, 420.14frames/s]\n 78%|███████▊  | 90436/116529 [04:15<01:03, 412.97frames/s]\n 80%|███████▉  | 93064/116529 [04:21<00:56, 416.05frames/s]\n 82%|████████▏ | 95868/116529 [04:28<00:50, 412.71frames/s]\n 85%|████████▍ | 98648/116529 [04:33<00:40, 439.86frames/s]\n 87%|████████▋ | 101596/116529 [04:41<00:35, 422.28frames/s]\n 90%|████████▉ | 104432/116529 [04:47<00:28, 422.99frames/s]\n 92%|█████████▏| 107368/116529 [04:56<00:23, 395.61frames/s]\n 95%|█████████▍| 110352/116529 [05:04<00:16, 380.18frames/s]\n 97%|█████████▋| 113188/116529 [05:12<00:08, 373.37frames/s]\n 99%|█████████▉| 115556/116529 [05:19<00:02, 362.88frames/s]\n99%|█████████▉| 115556/116529 [05:24<00:02, 356.43frames/s]\n",
  "output": {
    "detected_language": "english",
    "segments": [
      {
        "avg_logprob": -0.33104405876334386,
        "compression_ratio": 1.6692607003891051,
        "end": 2.96,
        "id": 0,
        "no_speech_prob": 0.03408809378743172,
        "seek": 0,
        "start": 0,
        "temperature": 0,
        "text": " Welcome back to another Discord bot tutorial.",
        "tokens": [
          50364,
          4027,
          646,
          281,
          1071,
          32623,
          10592,
          7073,
          13,
          50512
        ]
      },
      {
        "avg_logprob": -0.33104405876334386,
        "compression_ratio": 1.6692607003891051,
        "end": 4.5600000000000005,
        "id": 1,
        "no_speech_prob": 0.03408809378743172,
        "seek": 0,
        "start": 2.96,
        "temperature": 0,
        "text": " I'm so excited about this one.",
        "tokens": [
          50512,
          286,
          478,
          370,
          2919,
          466,
          341,
          472,
          13,
          50592
        ]
      },
      {
        "avg_logprob": -0.33104405876334386,
        "compression_ratio": 1.6692607003891051,
        "end": 7.36,
        "id": 2,
        "no_speech_prob": 0.03408809378743172,
        "seek": 0,
        "start": 4.5600000000000005,
        "temperature": 0,
        "text": " So where I last left off, I mean,",
        "tokens": [
          50592,
          407,
          689,
          286,
          1036,
          1411,
          766,
          11,
          286,
          914,
          11,
          50732
        ]
      },
      {
        "avg_logprob": -0.33104405876334386,
        "compression_ratio": 1.6692607003891051,
        "end": 9.32,
        "id": 3,
        "no_speech_prob": 0.03408809378743172,
        "seek": 0,
        "start": 7.36,
        "temperature": 0,
        "text": " couldn't possibly left off in a better place",
        "tokens": [
          50732,
          2809,
          380,
          6264,
          1411,
          766,
          294,
          257,
          1101,
          1081,
          50830
        ]
      },
      {
        "avg_logprob": -0.33104405876334386,
        "compression_ratio": 1.6692607003891051,
        "end": 11.76,
        "id": 4,
        "no_speech_prob": 0.03408809378743172,
        "seek": 0,
        "start": 9.32,
        "temperature": 0,
        "text": " where I have a kitten running a unicorn with a rainbow",
        "tokens": [
          50830,
          689,
          286,
          362,
          257,
          39696,
          2614,
          257,
          28122,
          365,
          257,
          18526,
          50952
        ]
      },
      {
        "avg_logprob": -0.33104405876334386,
        "compression_ratio": 1.6692607003891051,
        "end": 13.32,
        "id": 5,
        "no_speech_prob": 0.03408809378743172,
        "seek": 0,
        "start": 11.76,
        "temperature": 0,
        "text": " in the background.",
        "tokens": [
          50952,
          294,
          264,
          3678,
          13,
          51030
        ]
      },
      {
        "avg_logprob": -0.33104405876334386,
        "compression_ratio": 1.6692607003891051,
        "end": 15.68,
        "id": 6,
        "no_speech_prob": 0.03408809378743172,
        "seek": 0,
        "start": 13.32,
        "temperature": 0,
        "text": " But I have a bot that does only two things.",
        "tokens": [
          51030,
          583,
          286,
          362,
          257,
          10592,
          300,
          775,
          787,
          732,
          721,
          13,
          51148
        ]
      },
      {
        "avg_logprob": -0.33104405876334386,
        "compression_ratio": 1.6692607003891051,
        "end": 19.56,
        "id": 7,
        "no_speech_prob": 0.03408809378743172,
        "seek": 0,
        "start": 15.68,
        "temperature": 0,
        "text": " I say, choo choo to it, and it replies with a random message,",
        "tokens": [
          51148,
          286,
          584,
          11,
          1586,
          78,
          1586,
          78,
          281,
          309,
          11,
          293,
          309,
          42289,
          365,
          257,
          4974,
          3636,
          11,
          51342
        ]
      },
      {
        "avg_logprob": -0.33104405876334386,
        "compression_ratio": 1.6692607003891051,
        "end": 20.52,
        "id": 8,
        "no_speech_prob": 0.03408809378743172,
        "seek": 0,
        "start": 19.56,
        "temperature": 0,
        "text": " choo choo back.",
        "tokens": [
          51342,
          1586,
          78,
          1586,
          78,
          646,
          13,
          51390
        ]
      },
      {
        "avg_logprob": -0.33104405876334386,
        "compression_ratio": 1.6692607003891051,
        "end": 23.84,
        "id": 9,
        "no_speech_prob": 0.03408809378743172,
        "seek": 0,
        "start": 20.52,
        "temperature": 0,
        "text": " I say gif, and maybe I feel like looking at a kitten today,",
        "tokens": [
          51390,
          286,
          584,
          290,
          351,
          11,
          293,
          1310,
          286,
          841,
          411,
          1237,
          412,
          257,
          39696,
          965,
          11,
          51556
        ]
      },
      {
        "avg_logprob": -0.33104405876334386,
        "compression_ratio": 1.6692607003891051,
        "end": 24.8,
        "id": 10,
        "no_speech_prob": 0.03408809378743172,
        "seek": 0,
        "start": 23.84,
        "temperature": 0,
        "text": " and I get a nice.",
        "tokens": [
          51556,
          293,
          286,
          483,
          257,
          1481,
          13,
          51604
        ]
      },
      {
        "avg_logprob": -0.32847989748602047,
        "compression_ratio": 1.702054794520548,
        "end": 28.560000000000002,
        "id": 11,
        "no_speech_prob": 0.0016743486048653722,
        "seek": 2480,
        "start": 24.8,
        "temperature": 0,
        "text": " I'm going to get a unicorn.",
        "tokens": [
          50364,
          286,
          478,
          516,
          281,
          483,
          257,
          28122,
          13,
          50552
        ]
      },
      {
        "avg_logprob": -0.32847989748602047,
        "compression_ratio": 1.702054794520548,
        "end": 30.64,
        "id": 12,
        "no_speech_prob": 0.0016743486048653722,
        "seek": 2480,
        "start": 28.560000000000002,
        "temperature": 0,
        "text": " So how is this working in the code?",
        "tokens": [
          50552,
          407,
          577,
          307,
          341,
          1364,
          294,
          264,
          3089,
          30,
          50656
        ]
      },
      {
        "avg_logprob": -0.32847989748602047,
        "compression_ratio": 1.702054794520548,
        "end": 33.68,
        "id": 13,
        "no_speech_prob": 0.0016743486048653722,
        "seek": 2480,
        "start": 30.64,
        "temperature": 0,
        "text": " Well, if I look at the code, I have this lovely if statement.",
        "tokens": [
          50656,
          1042,
          11,
          498,
          286,
          574,
          412,
          264,
          3089,
          11,
          286,
          362,
          341,
          7496,
          498,
          5629,
          13,
          50808
        ]
      },
      {
        "avg_logprob": -0.32847989748602047,
        "compression_ratio": 1.702054794520548,
        "end": 37.8,
        "id": 14,
        "no_speech_prob": 0.0016743486048653722,
        "seek": 2480,
        "start": 33.68,
        "temperature": 0,
        "text": " If tokens equals choo choo, else if tokens index 0 equals gif.",
        "tokens": [
          50808,
          759,
          22667,
          6915,
          1586,
          78,
          1586,
          78,
          11,
          1646,
          498,
          22667,
          8186,
          1958,
          6915,
          290,
          351,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.32847989748602047,
        "compression_ratio": 1.702054794520548,
        "end": 40.16,
        "id": 15,
        "no_speech_prob": 0.0016743486048653722,
        "seek": 2480,
        "start": 37.8,
        "temperature": 0,
        "text": " So this is not a super sustainable method.",
        "tokens": [
          51014,
          407,
          341,
          307,
          406,
          257,
          1687,
          11235,
          3170,
          13,
          51132
        ]
      },
      {
        "avg_logprob": -0.32847989748602047,
        "compression_ratio": 1.702054794520548,
        "end": 42.28,
        "id": 16,
        "no_speech_prob": 0.0016743486048653722,
        "seek": 2480,
        "start": 40.16,
        "temperature": 0,
        "text": " I mean, if I'm being honest, this is kind of,",
        "tokens": [
          51132,
          286,
          914,
          11,
          498,
          286,
          478,
          885,
          3245,
          11,
          341,
          307,
          733,
          295,
          11,
          51238
        ]
      },
      {
        "avg_logprob": -0.32847989748602047,
        "compression_ratio": 1.702054794520548,
        "end": 44.56,
        "id": 17,
        "no_speech_prob": 0.0016743486048653722,
        "seek": 2480,
        "start": 42.28,
        "temperature": 0,
        "text": " I would be happy to just stay with this method,",
        "tokens": [
          51238,
          286,
          576,
          312,
          2055,
          281,
          445,
          1754,
          365,
          341,
          3170,
          11,
          51352
        ]
      },
      {
        "avg_logprob": -0.32847989748602047,
        "compression_ratio": 1.702054794520548,
        "end": 46.760000000000005,
        "id": 18,
        "no_speech_prob": 0.0016743486048653722,
        "seek": 2480,
        "start": 44.56,
        "temperature": 0,
        "text": " add a few more commands, a few more else ifs.",
        "tokens": [
          51352,
          909,
          257,
          1326,
          544,
          16901,
          11,
          257,
          1326,
          544,
          1646,
          498,
          82,
          13,
          51462
        ]
      },
      {
        "avg_logprob": -0.32847989748602047,
        "compression_ratio": 1.702054794520548,
        "end": 48.84,
        "id": 19,
        "no_speech_prob": 0.0016743486048653722,
        "seek": 2480,
        "start": 46.760000000000005,
        "temperature": 0,
        "text": " But a much more sort of conventional way",
        "tokens": [
          51462,
          583,
          257,
          709,
          544,
          1333,
          295,
          16011,
          636,
          51566
        ]
      },
      {
        "avg_logprob": -0.32847989748602047,
        "compression_ratio": 1.702054794520548,
        "end": 52.24,
        "id": 20,
        "no_speech_prob": 0.0016743486048653722,
        "seek": 2480,
        "start": 48.84,
        "temperature": 0,
        "text": " of building a scalable Discord bot with many,",
        "tokens": [
          51566,
          295,
          2390,
          257,
          38481,
          32623,
          10592,
          365,
          867,
          11,
          51736
        ]
      },
      {
        "avg_logprob": -0.32847989748602047,
        "compression_ratio": 1.702054794520548,
        "end": 54.36,
        "id": 21,
        "no_speech_prob": 0.0016743486048653722,
        "seek": 2480,
        "start": 52.24,
        "temperature": 0,
        "text": " handling many, many commands is to use",
        "tokens": [
          51736,
          13175,
          867,
          11,
          867,
          16901,
          307,
          281,
          764,
          51842
        ]
      },
      {
        "avg_logprob": -0.20982246141175967,
        "compression_ratio": 1.70125786163522,
        "end": 57.36,
        "id": 22,
        "no_speech_prob": 0.0025909505784511566,
        "seek": 5436,
        "start": 54.4,
        "temperature": 0,
        "text": " some kind of command handler framework.",
        "tokens": [
          50366,
          512,
          733,
          295,
          5622,
          41967,
          8388,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.20982246141175967,
        "compression_ratio": 1.70125786163522,
        "end": 60.2,
        "id": 23,
        "no_speech_prob": 0.0025909505784511566,
        "seek": 5436,
        "start": 57.36,
        "temperature": 0,
        "text": " And in fact, if you go to the discord.js guide,",
        "tokens": [
          50514,
          400,
          294,
          1186,
          11,
          498,
          291,
          352,
          281,
          264,
          32989,
          13,
          25530,
          5934,
          11,
          50656
        ]
      },
      {
        "avg_logprob": -0.20982246141175967,
        "compression_ratio": 1.70125786163522,
        "end": 63.56,
        "id": 24,
        "no_speech_prob": 0.0025909505784511566,
        "seek": 5436,
        "start": 60.2,
        "temperature": 0,
        "text": " you'll see an entire page here on command handling.",
        "tokens": [
          50656,
          291,
          603,
          536,
          364,
          2302,
          3028,
          510,
          322,
          5622,
          13175,
          13,
          50824
        ]
      },
      {
        "avg_logprob": -0.20982246141175967,
        "compression_ratio": 1.70125786163522,
        "end": 66.8,
        "id": 25,
        "no_speech_prob": 0.0025909505784511566,
        "seek": 5436,
        "start": 63.56,
        "temperature": 0,
        "text": " I'm going to use a slightly different method than the one",
        "tokens": [
          50824,
          286,
          478,
          516,
          281,
          764,
          257,
          4748,
          819,
          3170,
          813,
          264,
          472,
          50986
        ]
      },
      {
        "avg_logprob": -0.20982246141175967,
        "compression_ratio": 1.70125786163522,
        "end": 68.38,
        "id": 26,
        "no_speech_prob": 0.0025909505784511566,
        "seek": 5436,
        "start": 66.8,
        "temperature": 0,
        "text": " described here, although you certainly",
        "tokens": [
          50986,
          7619,
          510,
          11,
          4878,
          291,
          3297,
          51065
        ]
      },
      {
        "avg_logprob": -0.20982246141175967,
        "compression_ratio": 1.70125786163522,
        "end": 69.84,
        "id": 27,
        "no_speech_prob": 0.0025909505784511566,
        "seek": 5436,
        "start": 68.38,
        "temperature": 0,
        "text": " could use this one as well.",
        "tokens": [
          51065,
          727,
          764,
          341,
          472,
          382,
          731,
          13,
          51138
        ]
      },
      {
        "avg_logprob": -0.20982246141175967,
        "compression_ratio": 1.70125786163522,
        "end": 71.34,
        "id": 28,
        "no_speech_prob": 0.0025909505784511566,
        "seek": 5436,
        "start": 69.84,
        "temperature": 0,
        "text": " I'm going to follow the methodology",
        "tokens": [
          51138,
          286,
          478,
          516,
          281,
          1524,
          264,
          24850,
          51213
        ]
      },
      {
        "avg_logprob": -0.20982246141175967,
        "compression_ratio": 1.70125786163522,
        "end": 73.58,
        "id": 29,
        "no_speech_prob": 0.0025909505784511566,
        "seek": 5436,
        "start": 71.34,
        "temperature": 0,
        "text": " that I learned when I was a guest on Coding Garden",
        "tokens": [
          51213,
          300,
          286,
          3264,
          562,
          286,
          390,
          257,
          8341,
          322,
          383,
          8616,
          19429,
          51325
        ]
      },
      {
        "avg_logprob": -0.20982246141175967,
        "compression_ratio": 1.70125786163522,
        "end": 74.58,
        "id": 30,
        "no_speech_prob": 0.0025909505784511566,
        "seek": 5436,
        "start": 73.58,
        "temperature": 0,
        "text": " that CJ showed me.",
        "tokens": [
          51325,
          300,
          42285,
          4712,
          385,
          13,
          51375
        ]
      },
      {
        "avg_logprob": -0.20982246141175967,
        "compression_ratio": 1.70125786163522,
        "end": 78.6,
        "id": 31,
        "no_speech_prob": 0.0025909505784511566,
        "seek": 5436,
        "start": 74.58,
        "temperature": 0,
        "text": " I think it works well, and it's a nice way to handle commands.",
        "tokens": [
          51375,
          286,
          519,
          309,
          1985,
          731,
          11,
          293,
          309,
          311,
          257,
          1481,
          636,
          281,
          4813,
          16901,
          13,
          51576
        ]
      },
      {
        "avg_logprob": -0.20982246141175967,
        "compression_ratio": 1.70125786163522,
        "end": 80.28,
        "id": 32,
        "no_speech_prob": 0.0025909505784511566,
        "seek": 5436,
        "start": 78.6,
        "temperature": 0,
        "text": " So you can check out this GitHub repo",
        "tokens": [
          51576,
          407,
          291,
          393,
          1520,
          484,
          341,
          23331,
          49040,
          51660
        ]
      },
      {
        "avg_logprob": -0.20982246141175967,
        "compression_ratio": 1.70125786163522,
        "end": 81.72,
        "id": 33,
        "no_speech_prob": 0.0025909505784511566,
        "seek": 5436,
        "start": 80.28,
        "temperature": 0,
        "text": " for another version of the example",
        "tokens": [
          51660,
          337,
          1071,
          3037,
          295,
          264,
          1365,
          51732
        ]
      },
      {
        "avg_logprob": -0.20982246141175967,
        "compression_ratio": 1.70125786163522,
        "end": 83.12,
        "id": 34,
        "no_speech_prob": 0.0025909505784511566,
        "seek": 5436,
        "start": 81.72,
        "temperature": 0,
        "text": " that I'm going to build right now.",
        "tokens": [
          51732,
          300,
          286,
          478,
          516,
          281,
          1322,
          558,
          586,
          13,
          51802
        ]
      },
      {
        "avg_logprob": -0.24986129078438613,
        "compression_ratio": 1.7317073170731707,
        "end": 86.2,
        "id": 35,
        "no_speech_prob": 0.00045120675349608064,
        "seek": 8312,
        "start": 83.12,
        "temperature": 0,
        "text": " And the core idea, if I, looking at the code",
        "tokens": [
          50364,
          400,
          264,
          4965,
          1558,
          11,
          498,
          286,
          11,
          1237,
          412,
          264,
          3089,
          50518
        ]
      },
      {
        "avg_logprob": -0.24986129078438613,
        "compression_ratio": 1.7317073170731707,
        "end": 88.24000000000001,
        "id": 36,
        "no_speech_prob": 0.00045120675349608064,
        "seek": 8312,
        "start": 86.2,
        "temperature": 0,
        "text": " here that I'm about to write, is that there's",
        "tokens": [
          50518,
          510,
          300,
          286,
          478,
          466,
          281,
          2464,
          11,
          307,
          300,
          456,
          311,
          50620
        ]
      },
      {
        "avg_logprob": -0.24986129078438613,
        "compression_ratio": 1.7317073170731707,
        "end": 89.80000000000001,
        "id": 37,
        "no_speech_prob": 0.00045120675349608064,
        "seek": 8312,
        "start": 88.24000000000001,
        "temperature": 0,
        "text": " almost like nothing here.",
        "tokens": [
          50620,
          1920,
          411,
          1825,
          510,
          13,
          50698
        ]
      },
      {
        "avg_logprob": -0.24986129078438613,
        "compression_ratio": 1.7317073170731707,
        "end": 91.92,
        "id": 38,
        "no_speech_prob": 0.00045120675349608064,
        "seek": 8312,
        "start": 89.80000000000001,
        "temperature": 0,
        "text": " There's just like creating the Discord client.",
        "tokens": [
          50698,
          821,
          311,
          445,
          411,
          4084,
          264,
          32623,
          6423,
          13,
          50804
        ]
      },
      {
        "avg_logprob": -0.24986129078438613,
        "compression_ratio": 1.7317073170731707,
        "end": 92.56,
        "id": 39,
        "no_speech_prob": 0.00045120675349608064,
        "seek": 8312,
        "start": 91.92,
        "temperature": 0,
        "text": " It's ready.",
        "tokens": [
          50804,
          467,
          311,
          1919,
          13,
          50836
        ]
      },
      {
        "avg_logprob": -0.24986129078438613,
        "compression_ratio": 1.7317073170731707,
        "end": 95.96000000000001,
        "id": 40,
        "no_speech_prob": 0.00045120675349608064,
        "seek": 8312,
        "start": 92.56,
        "temperature": 0,
        "text": " And when there's a message, ah, send the message",
        "tokens": [
          50836,
          400,
          562,
          456,
          311,
          257,
          3636,
          11,
          3716,
          11,
          2845,
          264,
          3636,
          51006
        ]
      },
      {
        "avg_logprob": -0.24986129078438613,
        "compression_ratio": 1.7317073170731707,
        "end": 97.68,
        "id": 41,
        "no_speech_prob": 0.00045120675349608064,
        "seek": 8312,
        "start": 95.96000000000001,
        "temperature": 0,
        "text": " to this thing called a command handler.",
        "tokens": [
          51006,
          281,
          341,
          551,
          1219,
          257,
          5622,
          41967,
          13,
          51092
        ]
      },
      {
        "avg_logprob": -0.24986129078438613,
        "compression_ratio": 1.7317073170731707,
        "end": 102.32000000000001,
        "id": 42,
        "no_speech_prob": 0.00045120675349608064,
        "seek": 8312,
        "start": 97.68,
        "temperature": 0,
        "text": " And that command handler is required from. slash command.",
        "tokens": [
          51092,
          400,
          300,
          5622,
          41967,
          307,
          4739,
          490,
          2411,
          17330,
          5622,
          13,
          51324
        ]
      },
      {
        "avg_logprob": -0.24986129078438613,
        "compression_ratio": 1.7317073170731707,
        "end": 104.24000000000001,
        "id": 43,
        "no_speech_prob": 0.00045120675349608064,
        "seek": 8312,
        "start": 102.32000000000001,
        "temperature": 0,
        "text": " What does that even mean?",
        "tokens": [
          51324,
          708,
          775,
          300,
          754,
          914,
          30,
          51420
        ]
      },
      {
        "avg_logprob": -0.24986129078438613,
        "compression_ratio": 1.7317073170731707,
        "end": 106.88000000000001,
        "id": 44,
        "no_speech_prob": 0.00045120675349608064,
        "seek": 8312,
        "start": 104.24000000000001,
        "temperature": 0,
        "text": " So this is where I want to start.",
        "tokens": [
          51420,
          407,
          341,
          307,
          689,
          286,
          528,
          281,
          722,
          13,
          51552
        ]
      },
      {
        "avg_logprob": -0.24986129078438613,
        "compression_ratio": 1.7317073170731707,
        "end": 111.08000000000001,
        "id": 45,
        "no_speech_prob": 0.00045120675349608064,
        "seek": 8312,
        "start": 106.88000000000001,
        "temperature": 0,
        "text": " What does it mean to, in your node program,",
        "tokens": [
          51552,
          708,
          775,
          309,
          914,
          281,
          11,
          294,
          428,
          9984,
          1461,
          11,
          51762
        ]
      },
      {
        "avg_logprob": -0.21291355347969163,
        "compression_ratio": 1.8057553956834533,
        "end": 113.64,
        "id": 46,
        "no_speech_prob": 0.002889550756663084,
        "seek": 11108,
        "start": 111.08,
        "temperature": 0,
        "text": " in your JavaScript file that you've been writing in node,",
        "tokens": [
          50364,
          294,
          428,
          15778,
          3991,
          300,
          291,
          600,
          668,
          3579,
          294,
          9984,
          11,
          50492
        ]
      },
      {
        "avg_logprob": -0.21291355347969163,
        "compression_ratio": 1.8057553956834533,
        "end": 115.92,
        "id": 47,
        "no_speech_prob": 0.002889550756663084,
        "seek": 11108,
        "start": 113.64,
        "temperature": 0,
        "text": " that I've been writing in node, that's only ever been,",
        "tokens": [
          50492,
          300,
          286,
          600,
          668,
          3579,
          294,
          9984,
          11,
          300,
          311,
          787,
          1562,
          668,
          11,
          50606
        ]
      },
      {
        "avg_logprob": -0.21291355347969163,
        "compression_ratio": 1.8057553956834533,
        "end": 119.48,
        "id": 48,
        "no_speech_prob": 0.002889550756663084,
        "seek": 11108,
        "start": 115.92,
        "temperature": 0,
        "text": " in my entire life until now, basically, one JavaScript file,",
        "tokens": [
          50606,
          294,
          452,
          2302,
          993,
          1826,
          586,
          11,
          1936,
          11,
          472,
          15778,
          3991,
          11,
          50784
        ]
      },
      {
        "avg_logprob": -0.21291355347969163,
        "compression_ratio": 1.8057553956834533,
        "end": 123.92,
        "id": 49,
        "no_speech_prob": 0.002889550756663084,
        "seek": 11108,
        "start": 119.48,
        "temperature": 0,
        "text": " how can I pull code that I save and manage in multiple files?",
        "tokens": [
          50784,
          577,
          393,
          286,
          2235,
          3089,
          300,
          286,
          3155,
          293,
          3067,
          294,
          3866,
          7098,
          30,
          51006
        ]
      },
      {
        "avg_logprob": -0.21291355347969163,
        "compression_ratio": 1.8057553956834533,
        "end": 127.56,
        "id": 50,
        "no_speech_prob": 0.002889550756663084,
        "seek": 11108,
        "start": 123.92,
        "temperature": 0,
        "text": " This is not unlike what I do very commonly with p5.js.",
        "tokens": [
          51006,
          639,
          307,
          406,
          8343,
          437,
          286,
          360,
          588,
          12719,
          365,
          280,
          20,
          13,
          25530,
          13,
          51188
        ]
      },
      {
        "avg_logprob": -0.21291355347969163,
        "compression_ratio": 1.8057553956834533,
        "end": 130.12,
        "id": 51,
        "no_speech_prob": 0.002889550756663084,
        "seek": 11108,
        "start": 127.56,
        "temperature": 0,
        "text": " So here's a p5.js sketch of a particle system.",
        "tokens": [
          51188,
          407,
          510,
          311,
          257,
          280,
          20,
          13,
          25530,
          12325,
          295,
          257,
          12359,
          1185,
          13,
          51316
        ]
      },
      {
        "avg_logprob": -0.21291355347969163,
        "compression_ratio": 1.8057553956834533,
        "end": 133,
        "id": 52,
        "no_speech_prob": 0.002889550756663084,
        "seek": 11108,
        "start": 130.12,
        "temperature": 0,
        "text": " And the way that I manage that in client-side JavaScript",
        "tokens": [
          51316,
          400,
          264,
          636,
          300,
          286,
          3067,
          300,
          294,
          6423,
          12,
          1812,
          15778,
          51460
        ]
      },
      {
        "avg_logprob": -0.21291355347969163,
        "compression_ratio": 1.8057553956834533,
        "end": 136.32,
        "id": 53,
        "no_speech_prob": 0.002889550756663084,
        "seek": 11108,
        "start": 133,
        "temperature": 0,
        "text": " is have index.html, where I reference",
        "tokens": [
          51460,
          307,
          362,
          8186,
          13,
          357,
          15480,
          11,
          689,
          286,
          6408,
          51626
        ]
      },
      {
        "avg_logprob": -0.21291355347969163,
        "compression_ratio": 1.8057553956834533,
        "end": 137.6,
        "id": 54,
        "no_speech_prob": 0.002889550756663084,
        "seek": 11108,
        "start": 136.32,
        "temperature": 0,
        "text": " multiple JavaScript files.",
        "tokens": [
          51626,
          3866,
          15778,
          7098,
          13,
          51690
        ]
      },
      {
        "avg_logprob": -0.21291355347969163,
        "compression_ratio": 1.8057553956834533,
        "end": 140.4,
        "id": 55,
        "no_speech_prob": 0.002889550756663084,
        "seek": 11108,
        "start": 137.6,
        "temperature": 0,
        "text": " Sketch.js for the main sketch, Particle.js",
        "tokens": [
          51690,
          49245,
          13,
          25530,
          337,
          264,
          2135,
          12325,
          11,
          4100,
          3520,
          13,
          25530,
          51830
        ]
      },
      {
        "avg_logprob": -0.2177600860595703,
        "compression_ratio": 1.6425531914893616,
        "end": 143.64000000000001,
        "id": 56,
        "no_speech_prob": 0.00037409403012134135,
        "seek": 14040,
        "start": 140.4,
        "temperature": 0,
        "text": " for the particles, System.js for the particle system code.",
        "tokens": [
          50364,
          337,
          264,
          10007,
          11,
          8910,
          13,
          25530,
          337,
          264,
          12359,
          1185,
          3089,
          13,
          50526
        ]
      },
      {
        "avg_logprob": -0.2177600860595703,
        "compression_ratio": 1.6425531914893616,
        "end": 146.96,
        "id": 57,
        "no_speech_prob": 0.00037409403012134135,
        "seek": 14040,
        "start": 143.64000000000001,
        "temperature": 0,
        "text": " So I want to figure out what is the equivalent",
        "tokens": [
          50526,
          407,
          286,
          528,
          281,
          2573,
          484,
          437,
          307,
          264,
          10344,
          50692
        ]
      },
      {
        "avg_logprob": -0.2177600860595703,
        "compression_ratio": 1.6425531914893616,
        "end": 150.84,
        "id": 58,
        "no_speech_prob": 0.00037409403012134135,
        "seek": 14040,
        "start": 146.96,
        "temperature": 0,
        "text": " of multiple JavaScript files for a node project.",
        "tokens": [
          50692,
          295,
          3866,
          15778,
          7098,
          337,
          257,
          9984,
          1716,
          13,
          50886
        ]
      },
      {
        "avg_logprob": -0.2177600860595703,
        "compression_ratio": 1.6425531914893616,
        "end": 153.92000000000002,
        "id": 59,
        "no_speech_prob": 0.00037409403012134135,
        "seek": 14040,
        "start": 150.84,
        "temperature": 0,
        "text": " And the secret to that is right there",
        "tokens": [
          50886,
          400,
          264,
          4054,
          281,
          300,
          307,
          558,
          456,
          51040
        ]
      },
      {
        "avg_logprob": -0.2177600860595703,
        "compression_ratio": 1.6425531914893616,
        "end": 157.20000000000002,
        "id": 60,
        "no_speech_prob": 0.00037409403012134135,
        "seek": 14040,
        "start": 153.92000000000002,
        "temperature": 0,
        "text": " in this require function.",
        "tokens": [
          51040,
          294,
          341,
          3651,
          2445,
          13,
          51204
        ]
      },
      {
        "avg_logprob": -0.2177600860595703,
        "compression_ratio": 1.6425531914893616,
        "end": 159.8,
        "id": 61,
        "no_speech_prob": 0.00037409403012134135,
        "seek": 14040,
        "start": 157.20000000000002,
        "temperature": 0,
        "text": " Now, in truth, require is perhaps",
        "tokens": [
          51204,
          823,
          11,
          294,
          3494,
          11,
          3651,
          307,
          4317,
          51334
        ]
      },
      {
        "avg_logprob": -0.2177600860595703,
        "compression_ratio": 1.6425531914893616,
        "end": 163,
        "id": 62,
        "no_speech_prob": 0.00037409403012134135,
        "seek": 14040,
        "start": 159.8,
        "temperature": 0,
        "text": " going to become outdated as time passes.",
        "tokens": [
          51334,
          516,
          281,
          1813,
          36313,
          382,
          565,
          11335,
          13,
          51494
        ]
      },
      {
        "avg_logprob": -0.2177600860595703,
        "compression_ratio": 1.6425531914893616,
        "end": 164.86,
        "id": 63,
        "no_speech_prob": 0.00037409403012134135,
        "seek": 14040,
        "start": 163,
        "temperature": 0,
        "text": " There are now some, there's now something",
        "tokens": [
          51494,
          821,
          366,
          586,
          512,
          11,
          456,
          311,
          586,
          746,
          51587
        ]
      },
      {
        "avg_logprob": -0.2177600860595703,
        "compression_ratio": 1.6425531914893616,
        "end": 167.8,
        "id": 64,
        "no_speech_prob": 0.00037409403012134135,
        "seek": 14040,
        "start": 164.86,
        "temperature": 0,
        "text": " called an import module that's part of JavaScript.",
        "tokens": [
          51587,
          1219,
          364,
          974,
          10088,
          300,
          311,
          644,
          295,
          15778,
          13,
          51734
        ]
      },
      {
        "avg_logprob": -0.233353717907055,
        "compression_ratio": 1.6881028938906752,
        "end": 170.56,
        "id": 65,
        "no_speech_prob": 0.0000075279699558450375,
        "seek": 16780,
        "start": 167.8,
        "temperature": 0,
        "text": " From what I understand, it's an experimental feature",
        "tokens": [
          50364,
          3358,
          437,
          286,
          1223,
          11,
          309,
          311,
          364,
          17069,
          4111,
          50502
        ]
      },
      {
        "avg_logprob": -0.233353717907055,
        "compression_ratio": 1.6881028938906752,
        "end": 174.84,
        "id": 66,
        "no_speech_prob": 0.0000075279699558450375,
        "seek": 16780,
        "start": 170.56,
        "temperature": 0,
        "text": " in node.js using imports instead of require.",
        "tokens": [
          50502,
          294,
          9984,
          13,
          25530,
          1228,
          41596,
          2602,
          295,
          3651,
          13,
          50716
        ]
      },
      {
        "avg_logprob": -0.233353717907055,
        "compression_ratio": 1.6881028938906752,
        "end": 176.96,
        "id": 67,
        "no_speech_prob": 0.0000075279699558450375,
        "seek": 16780,
        "start": 174.84,
        "temperature": 0,
        "text": " So I'm going to stick with require.",
        "tokens": [
          50716,
          407,
          286,
          478,
          516,
          281,
          2897,
          365,
          3651,
          13,
          50822
        ]
      },
      {
        "avg_logprob": -0.233353717907055,
        "compression_ratio": 1.6881028938906752,
        "end": 178.44,
        "id": 68,
        "no_speech_prob": 0.0000075279699558450375,
        "seek": 16780,
        "start": 176.96,
        "temperature": 0,
        "text": " And then someday in the future, I",
        "tokens": [
          50822,
          400,
          550,
          19412,
          294,
          264,
          2027,
          11,
          286,
          50896
        ]
      },
      {
        "avg_logprob": -0.233353717907055,
        "compression_ratio": 1.6881028938906752,
        "end": 180,
        "id": 69,
        "no_speech_prob": 0.0000075279699558450375,
        "seek": 16780,
        "start": 178.44,
        "temperature": 0,
        "text": " look forward to your comments that all",
        "tokens": [
          50896,
          574,
          2128,
          281,
          428,
          3053,
          300,
          439,
          50974
        ]
      },
      {
        "avg_logprob": -0.233353717907055,
        "compression_ratio": 1.6881028938906752,
        "end": 182.68,
        "id": 70,
        "no_speech_prob": 0.0000075279699558450375,
        "seek": 16780,
        "start": 180,
        "temperature": 0,
        "text": " say about how I should be using import instead of require.",
        "tokens": [
          50974,
          584,
          466,
          577,
          286,
          820,
          312,
          1228,
          974,
          2602,
          295,
          3651,
          13,
          51108
        ]
      },
      {
        "avg_logprob": -0.233353717907055,
        "compression_ratio": 1.6881028938906752,
        "end": 183.96,
        "id": 71,
        "no_speech_prob": 0.0000075279699558450375,
        "seek": 16780,
        "start": 182.68,
        "temperature": 0,
        "text": " Oh, it's going to be great.",
        "tokens": [
          51108,
          876,
          11,
          309,
          311,
          516,
          281,
          312,
          869,
          13,
          51172
        ]
      },
      {
        "avg_logprob": -0.233353717907055,
        "compression_ratio": 1.6881028938906752,
        "end": 185.88000000000002,
        "id": 72,
        "no_speech_prob": 0.0000075279699558450375,
        "seek": 16780,
        "start": 183.96,
        "temperature": 0,
        "text": " Pressing forward, step number one,",
        "tokens": [
          51172,
          6776,
          278,
          2128,
          11,
          1823,
          1230,
          472,
          11,
          51268
        ]
      },
      {
        "avg_logprob": -0.233353717907055,
        "compression_ratio": 1.6881028938906752,
        "end": 187.96,
        "id": 73,
        "no_speech_prob": 0.0000075279699558450375,
        "seek": 16780,
        "start": 185.88000000000002,
        "temperature": 0,
        "text": " I want to take this entire gotMessage function",
        "tokens": [
          51268,
          286,
          528,
          281,
          747,
          341,
          2302,
          658,
          44,
          442,
          609,
          2445,
          51372
        ]
      },
      {
        "avg_logprob": -0.233353717907055,
        "compression_ratio": 1.6881028938906752,
        "end": 189.76000000000002,
        "id": 74,
        "no_speech_prob": 0.0000075279699558450375,
        "seek": 16780,
        "start": 187.96,
        "temperature": 0,
        "text": " and just put it in another JavaScript file,",
        "tokens": [
          51372,
          293,
          445,
          829,
          309,
          294,
          1071,
          15778,
          3991,
          11,
          51462
        ]
      },
      {
        "avg_logprob": -0.233353717907055,
        "compression_ratio": 1.6881028938906752,
        "end": 192.32000000000002,
        "id": 75,
        "no_speech_prob": 0.0000075279699558450375,
        "seek": 16780,
        "start": 189.76000000000002,
        "temperature": 0,
        "text": " because I want to be able to work with it separately",
        "tokens": [
          51462,
          570,
          286,
          528,
          281,
          312,
          1075,
          281,
          589,
          365,
          309,
          14759,
          51590
        ]
      },
      {
        "avg_logprob": -0.233353717907055,
        "compression_ratio": 1.6881028938906752,
        "end": 195,
        "id": 76,
        "no_speech_prob": 0.0000075279699558450375,
        "seek": 16780,
        "start": 192.32000000000002,
        "temperature": 0,
        "text": " from this main index.js file.",
        "tokens": [
          51590,
          490,
          341,
          2135,
          8186,
          13,
          25530,
          3991,
          13,
          51724
        ]
      },
      {
        "avg_logprob": -0.233353717907055,
        "compression_ratio": 1.6881028938906752,
        "end": 196.44,
        "id": 77,
        "no_speech_prob": 0.0000075279699558450375,
        "seek": 16780,
        "start": 195,
        "temperature": 0,
        "text": " Or it's called bot.js.",
        "tokens": [
          51724,
          1610,
          309,
          311,
          1219,
          10592,
          13,
          25530,
          13,
          51796
        ]
      },
      {
        "avg_logprob": -0.18451473929665305,
        "compression_ratio": 1.608365019011407,
        "end": 199,
        "id": 78,
        "no_speech_prob": 0.0008830419974401593,
        "seek": 19644,
        "start": 196.44,
        "temperature": 0,
        "text": " I called it bot.js.",
        "tokens": [
          50364,
          286,
          1219,
          309,
          10592,
          13,
          25530,
          13,
          50492
        ]
      },
      {
        "avg_logprob": -0.18451473929665305,
        "compression_ratio": 1.608365019011407,
        "end": 202.92,
        "id": 79,
        "no_speech_prob": 0.0008830419974401593,
        "seek": 19644,
        "start": 199,
        "temperature": 0,
        "text": " Creating a new file, I'll call it commands.js.",
        "tokens": [
          50492,
          40002,
          257,
          777,
          3991,
          11,
          286,
          603,
          818,
          309,
          16901,
          13,
          25530,
          13,
          50688
        ]
      },
      {
        "avg_logprob": -0.18451473929665305,
        "compression_ratio": 1.608365019011407,
        "end": 204.24,
        "id": 80,
        "no_speech_prob": 0.0008830419974401593,
        "seek": 19644,
        "start": 202.92,
        "temperature": 0,
        "text": " And I've pasted it in.",
        "tokens": [
          50688,
          400,
          286,
          600,
          1791,
          292,
          309,
          294,
          13,
          50754
        ]
      },
      {
        "avg_logprob": -0.18451473929665305,
        "compression_ratio": 1.608365019011407,
        "end": 207.2,
        "id": 81,
        "no_speech_prob": 0.0008830419974401593,
        "seek": 19644,
        "start": 204.24,
        "temperature": 0,
        "text": " And back in bot.js, you can see there's almost nothing left.",
        "tokens": [
          50754,
          400,
          646,
          294,
          10592,
          13,
          25530,
          11,
          291,
          393,
          536,
          456,
          311,
          1920,
          1825,
          1411,
          13,
          50902
        ]
      },
      {
        "avg_logprob": -0.18451473929665305,
        "compression_ratio": 1.608365019011407,
        "end": 211.44,
        "id": 82,
        "no_speech_prob": 0.0008830419974401593,
        "seek": 19644,
        "start": 207.2,
        "temperature": 0,
        "text": " Ah, this replies really goes with those commands.",
        "tokens": [
          50902,
          2438,
          11,
          341,
          42289,
          534,
          1709,
          365,
          729,
          16901,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.18451473929665305,
        "compression_ratio": 1.608365019011407,
        "end": 212.88,
        "id": 83,
        "no_speech_prob": 0.0008830419974401593,
        "seek": 19644,
        "start": 211.44,
        "temperature": 0,
        "text": " So I should also move this over.",
        "tokens": [
          51114,
          407,
          286,
          820,
          611,
          1286,
          341,
          670,
          13,
          51186
        ]
      },
      {
        "avg_logprob": -0.18451473929665305,
        "compression_ratio": 1.608365019011407,
        "end": 214.12,
        "id": 84,
        "no_speech_prob": 0.0008830419974401593,
        "seek": 19644,
        "start": 212.88,
        "temperature": 0,
        "text": " I mean, ultimately, this might have",
        "tokens": [
          51186,
          286,
          914,
          11,
          6284,
          11,
          341,
          1062,
          362,
          51248
        ]
      },
      {
        "avg_logprob": -0.18451473929665305,
        "compression_ratio": 1.608365019011407,
        "end": 215.76,
        "id": 85,
        "no_speech_prob": 0.0008830419974401593,
        "seek": 19644,
        "start": 214.12,
        "temperature": 0,
        "text": " to go in a different place entirely.",
        "tokens": [
          51248,
          281,
          352,
          294,
          257,
          819,
          1081,
          7696,
          13,
          51330
        ]
      },
      {
        "avg_logprob": -0.18451473929665305,
        "compression_ratio": 1.608365019011407,
        "end": 218.44,
        "id": 86,
        "no_speech_prob": 0.0008830419974401593,
        "seek": 19644,
        "start": 215.76,
        "temperature": 0,
        "text": " But let's take it out of here right now.",
        "tokens": [
          51330,
          583,
          718,
          311,
          747,
          309,
          484,
          295,
          510,
          558,
          586,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.18451473929665305,
        "compression_ratio": 1.608365019011407,
        "end": 224.24,
        "id": 87,
        "no_speech_prob": 0.0008830419974401593,
        "seek": 19644,
        "start": 218.44,
        "temperature": 0,
        "text": " Then the idea is, could I get this gotMessage function",
        "tokens": [
          51464,
          1396,
          264,
          1558,
          307,
          11,
          727,
          286,
          483,
          341,
          658,
          44,
          442,
          609,
          2445,
          51754
        ]
      },
      {
        "avg_logprob": -0.18451473929665305,
        "compression_ratio": 1.608365019011407,
        "end": 225.88,
        "id": 88,
        "no_speech_prob": 0.0008830419974401593,
        "seek": 19644,
        "start": 224.24,
        "temperature": 0,
        "text": " from the other file?",
        "tokens": [
          51754,
          490,
          264,
          661,
          3991,
          30,
          51836
        ]
      },
      {
        "avg_logprob": -0.20968306298349418,
        "compression_ratio": 1.614678899082569,
        "end": 230.04,
        "id": 89,
        "no_speech_prob": 0.000046112676500342786,
        "seek": 22588,
        "start": 225.88,
        "temperature": 0,
        "text": " And let's call this command handler.",
        "tokens": [
          50364,
          400,
          718,
          311,
          818,
          341,
          5622,
          41967,
          13,
          50572
        ]
      },
      {
        "avg_logprob": -0.20968306298349418,
        "compression_ratio": 1.614678899082569,
        "end": 231.56,
        "id": 90,
        "no_speech_prob": 0.000046112676500342786,
        "seek": 22588,
        "start": 230.04,
        "temperature": 0,
        "text": " I want that to be command handler.",
        "tokens": [
          50572,
          286,
          528,
          300,
          281,
          312,
          5622,
          41967,
          13,
          50648
        ]
      },
      {
        "avg_logprob": -0.20968306298349418,
        "compression_ratio": 1.614678899082569,
        "end": 237.96,
        "id": 91,
        "no_speech_prob": 0.000046112676500342786,
        "seek": 22588,
        "start": 231.56,
        "temperature": 0,
        "text": " And I want to say const command handler equals require.",
        "tokens": [
          50648,
          400,
          286,
          528,
          281,
          584,
          1817,
          5622,
          41967,
          6915,
          3651,
          13,
          50968
        ]
      },
      {
        "avg_logprob": -0.20968306298349418,
        "compression_ratio": 1.614678899082569,
        "end": 239.64,
        "id": 92,
        "no_speech_prob": 0.000046112676500342786,
        "seek": 22588,
        "start": 237.96,
        "temperature": 0,
        "text": " What do I put here?",
        "tokens": [
          50968,
          708,
          360,
          286,
          829,
          510,
          30,
          51052
        ]
      },
      {
        "avg_logprob": -0.20968306298349418,
        "compression_ratio": 1.614678899082569,
        "end": 242.2,
        "id": 93,
        "no_speech_prob": 0.000046112676500342786,
        "seek": 22588,
        "start": 239.64,
        "temperature": 0,
        "text": " So I'm pretty sure the way that it works",
        "tokens": [
          51052,
          407,
          286,
          478,
          1238,
          988,
          264,
          636,
          300,
          309,
          1985,
          51180
        ]
      },
      {
        "avg_logprob": -0.20968306298349418,
        "compression_ratio": 1.614678899082569,
        "end": 245.35999999999999,
        "id": 94,
        "no_speech_prob": 0.000046112676500342786,
        "seek": 22588,
        "start": 242.2,
        "temperature": 0,
        "text": " is for me to reference the name of the other JavaScript",
        "tokens": [
          51180,
          307,
          337,
          385,
          281,
          6408,
          264,
          1315,
          295,
          264,
          661,
          15778,
          51338
        ]
      },
      {
        "avg_logprob": -0.20968306298349418,
        "compression_ratio": 1.614678899082569,
        "end": 248.92,
        "id": 95,
        "no_speech_prob": 0.000046112676500342786,
        "seek": 22588,
        "start": 245.35999999999999,
        "temperature": 0,
        "text": " file without.js.",
        "tokens": [
          51338,
          3991,
          1553,
          2411,
          25530,
          13,
          51516
        ]
      },
      {
        "avg_logprob": -0.20968306298349418,
        "compression_ratio": 1.614678899082569,
        "end": 251.8,
        "id": 96,
        "no_speech_prob": 0.000046112676500342786,
        "seek": 22588,
        "start": 248.92,
        "temperature": 0,
        "text": " However, if I do this, it's actually",
        "tokens": [
          51516,
          2908,
          11,
          498,
          286,
          360,
          341,
          11,
          309,
          311,
          767,
          51660
        ]
      },
      {
        "avg_logprob": -0.20968306298349418,
        "compression_ratio": 1.614678899082569,
        "end": 255.84,
        "id": 97,
        "no_speech_prob": 0.000046112676500342786,
        "seek": 22588,
        "start": 251.8,
        "temperature": 0,
        "text": " going to look for a node, a proper node module that's",
        "tokens": [
          51660,
          516,
          281,
          574,
          337,
          257,
          9984,
          11,
          257,
          2296,
          9984,
          10088,
          300,
          311,
          51862
        ]
      },
      {
        "avg_logprob": -0.2663183434064998,
        "compression_ratio": 1.8038461538461539,
        "end": 259.4,
        "id": 98,
        "no_speech_prob": 0.0008167357300408185,
        "seek": 25584,
        "start": 256.8,
        "temperature": 0,
        "text": " been installed as part of my node modules, like discord.js",
        "tokens": [
          50412,
          668,
          8899,
          382,
          644,
          295,
          452,
          9984,
          16679,
          11,
          411,
          32989,
          13,
          25530,
          50542
        ]
      },
      {
        "avg_logprob": -0.2663183434064998,
        "compression_ratio": 1.8038461538461539,
        "end": 260.8,
        "id": 99,
        "no_speech_prob": 0.0008167357300408185,
        "seek": 25584,
        "start": 259.4,
        "temperature": 0,
        "text": " or node.fetch.",
        "tokens": [
          50542,
          420,
          9984,
          13,
          69,
          7858,
          13,
          50612
        ]
      },
      {
        "avg_logprob": -0.2663183434064998,
        "compression_ratio": 1.8038461538461539,
        "end": 262.44,
        "id": 100,
        "no_speech_prob": 0.0008167357300408185,
        "seek": 25584,
        "start": 260.8,
        "temperature": 0,
        "text": " So I need to tell it, no, no, no, no.",
        "tokens": [
          50612,
          407,
          286,
          643,
          281,
          980,
          309,
          11,
          572,
          11,
          572,
          11,
          572,
          11,
          572,
          13,
          50694
        ]
      },
      {
        "avg_logprob": -0.2663183434064998,
        "compression_ratio": 1.8038461538461539,
        "end": 264.52,
        "id": 101,
        "no_speech_prob": 0.0008167357300408185,
        "seek": 25584,
        "start": 262.44,
        "temperature": 0,
        "text": " Don't go look in the node modules folder.",
        "tokens": [
          50694,
          1468,
          380,
          352,
          574,
          294,
          264,
          9984,
          16679,
          10820,
          13,
          50798
        ]
      },
      {
        "avg_logprob": -0.2663183434064998,
        "compression_ratio": 1.8038461538461539,
        "end": 265.8,
        "id": 102,
        "no_speech_prob": 0.0008167357300408185,
        "seek": 25584,
        "start": 264.52,
        "temperature": 0,
        "text": " Look locally.",
        "tokens": [
          50798,
          2053,
          16143,
          13,
          50862
        ]
      },
      {
        "avg_logprob": -0.2663183434064998,
        "compression_ratio": 1.8038461538461539,
        "end": 269.28000000000003,
        "id": 103,
        "no_speech_prob": 0.0008167357300408185,
        "seek": 25584,
        "start": 265.8,
        "temperature": 0,
        "text": " And the way that that is done is with.slash.",
        "tokens": [
          50862,
          400,
          264,
          636,
          300,
          300,
          307,
          1096,
          307,
          365,
          2411,
          10418,
          1299,
          13,
          51036
        ]
      },
      {
        "avg_logprob": -0.2663183434064998,
        "compression_ratio": 1.8038461538461539,
        "end": 270.8,
        "id": 104,
        "no_speech_prob": 0.0008167357300408185,
        "seek": 25584,
        "start": 269.28000000000003,
        "temperature": 0,
        "text": " So I'm done, right?",
        "tokens": [
          51036,
          407,
          286,
          478,
          1096,
          11,
          558,
          30,
          51112
        ]
      },
      {
        "avg_logprob": -0.2663183434064998,
        "compression_ratio": 1.8038461538461539,
        "end": 273.16,
        "id": 105,
        "no_speech_prob": 0.0008167357300408185,
        "seek": 25584,
        "start": 270.8,
        "temperature": 0,
        "text": " Command handler equals require commands.",
        "tokens": [
          51112,
          17901,
          41967,
          6915,
          3651,
          16901,
          13,
          51230
        ]
      },
      {
        "avg_logprob": -0.2663183434064998,
        "compression_ratio": 1.8038461538461539,
        "end": 274.72,
        "id": 106,
        "no_speech_prob": 0.0008167357300408185,
        "seek": 25584,
        "start": 273.16,
        "temperature": 0,
        "text": " I get everything in that other file.",
        "tokens": [
          51230,
          286,
          483,
          1203,
          294,
          300,
          661,
          3991,
          13,
          51308
        ]
      },
      {
        "avg_logprob": -0.2663183434064998,
        "compression_ratio": 1.8038461538461539,
        "end": 277.68,
        "id": 107,
        "no_speech_prob": 0.0008167357300408185,
        "seek": 25584,
        "start": 274.72,
        "temperature": 0,
        "text": " And now I can just say client.onMessageCommandHandler.",
        "tokens": [
          51308,
          400,
          586,
          286,
          393,
          445,
          584,
          6423,
          13,
          266,
          44,
          442,
          609,
          39206,
          474,
          39,
          474,
          1918,
          13,
          51456
        ]
      },
      {
        "avg_logprob": -0.2663183434064998,
        "compression_ratio": 1.8038461538461539,
        "end": 278.56,
        "id": 108,
        "no_speech_prob": 0.0008167357300408185,
        "seek": 25584,
        "start": 277.68,
        "temperature": 0,
        "text": " No!",
        "tokens": [
          51456,
          883,
          0,
          51500
        ]
      },
      {
        "avg_logprob": -0.2663183434064998,
        "compression_ratio": 1.8038461538461539,
        "end": 279.92,
        "id": 109,
        "no_speech_prob": 0.0008167357300408185,
        "seek": 25584,
        "start": 278.56,
        "temperature": 0,
        "text": " No, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no,",
        "tokens": [
          51500,
          883,
          11,
          572,
          11,
          572,
          11,
          572,
          11,
          572,
          11,
          572,
          11,
          572,
          11,
          572,
          11,
          572,
          11,
          572,
          11,
          572,
          11,
          572,
          11,
          572,
          11,
          572,
          11,
          572,
          11,
          572,
          11,
          51568
        ]
      },
      {
        "avg_logprob": -0.2663183434064998,
        "compression_ratio": 1.8038461538461539,
        "end": 280.68,
        "id": 110,
        "no_speech_prob": 0.0008167357300408185,
        "seek": 25584,
        "start": 279.92,
        "temperature": 0,
        "text": " stop!",
        "tokens": [
          51568,
          1590,
          0,
          51606
        ]
      },
      {
        "avg_logprob": -0.2663183434064998,
        "compression_ratio": 1.8038461538461539,
        "end": 282.6,
        "id": 111,
        "no_speech_prob": 0.0008167357300408185,
        "seek": 25584,
        "start": 280.68,
        "temperature": 0,
        "text": " I have to add something else.",
        "tokens": [
          51606,
          286,
          362,
          281,
          909,
          746,
          1646,
          13,
          51702
        ]
      },
      {
        "avg_logprob": -0.18288561877082377,
        "compression_ratio": 1.82010582010582,
        "end": 287.20000000000005,
        "id": 112,
        "no_speech_prob": 0.00026118982350453734,
        "seek": 28260,
        "start": 282.6,
        "temperature": 0,
        "text": " I have to explicitly state inside of this file",
        "tokens": [
          50364,
          286,
          362,
          281,
          20803,
          1785,
          1854,
          295,
          341,
          3991,
          50594
        ]
      },
      {
        "avg_logprob": -0.18288561877082377,
        "compression_ratio": 1.82010582010582,
        "end": 290.68,
        "id": 113,
        "no_speech_prob": 0.00026118982350453734,
        "seek": 28260,
        "start": 287.20000000000005,
        "temperature": 0,
        "text": " what I want to make available when it is required.",
        "tokens": [
          50594,
          437,
          286,
          528,
          281,
          652,
          2435,
          562,
          309,
          307,
          4739,
          13,
          50768
        ]
      },
      {
        "avg_logprob": -0.18288561877082377,
        "compression_ratio": 1.82010582010582,
        "end": 295.12,
        "id": 114,
        "no_speech_prob": 0.00026118982350453734,
        "seek": 28260,
        "start": 290.68,
        "temperature": 0,
        "text": " And the way that I do that is saying module.exports.",
        "tokens": [
          50768,
          400,
          264,
          636,
          300,
          286,
          360,
          300,
          307,
          1566,
          10088,
          13,
          3121,
          17845,
          13,
          50990
        ]
      },
      {
        "avg_logprob": -0.18288561877082377,
        "compression_ratio": 1.82010582010582,
        "end": 298.56,
        "id": 115,
        "no_speech_prob": 0.00026118982350453734,
        "seek": 28260,
        "start": 295.12,
        "temperature": 0,
        "text": " So anything that I put inside of module.exports",
        "tokens": [
          50990,
          407,
          1340,
          300,
          286,
          829,
          1854,
          295,
          10088,
          13,
          3121,
          17845,
          51162
        ]
      },
      {
        "avg_logprob": -0.18288561877082377,
        "compression_ratio": 1.82010582010582,
        "end": 299.84000000000003,
        "id": 116,
        "no_speech_prob": 0.00026118982350453734,
        "seek": 28260,
        "start": 298.56,
        "temperature": 0,
        "text": " will be available.",
        "tokens": [
          51162,
          486,
          312,
          2435,
          13,
          51226
        ]
      },
      {
        "avg_logprob": -0.18288561877082377,
        "compression_ratio": 1.82010582010582,
        "end": 301.76000000000005,
        "id": 117,
        "no_speech_prob": 0.00026118982350453734,
        "seek": 28260,
        "start": 299.84000000000003,
        "temperature": 0,
        "text": " So what do I want to make available?",
        "tokens": [
          51226,
          407,
          437,
          360,
          286,
          528,
          281,
          652,
          2435,
          30,
          51322
        ]
      },
      {
        "avg_logprob": -0.18288561877082377,
        "compression_ratio": 1.82010582010582,
        "end": 305.64000000000004,
        "id": 118,
        "no_speech_prob": 0.00026118982350453734,
        "seek": 28260,
        "start": 301.76000000000005,
        "temperature": 0,
        "text": " This gotMessage function.",
        "tokens": [
          51322,
          639,
          658,
          44,
          442,
          609,
          2445,
          13,
          51516
        ]
      },
      {
        "avg_logprob": -0.18288561877082377,
        "compression_ratio": 1.82010582010582,
        "end": 306.6,
        "id": 119,
        "no_speech_prob": 0.00026118982350453734,
        "seek": 28260,
        "start": 305.64000000000004,
        "temperature": 0,
        "text": " And there we go.",
        "tokens": [
          51516,
          400,
          456,
          321,
          352,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.18288561877082377,
        "compression_ratio": 1.82010582010582,
        "end": 309.88,
        "id": 120,
        "no_speech_prob": 0.00026118982350453734,
        "seek": 28260,
        "start": 306.6,
        "temperature": 0,
        "text": " Module.exports equals the function gotMessage.",
        "tokens": [
          51564,
          48251,
          13,
          3121,
          17845,
          6915,
          264,
          2445,
          658,
          44,
          442,
          609,
          13,
          51728
        ]
      },
      {
        "avg_logprob": -0.18470937837430132,
        "compression_ratio": 1.6785714285714286,
        "end": 312.8,
        "id": 121,
        "no_speech_prob": 0.00007368586375378072,
        "seek": 30988,
        "start": 309.88,
        "temperature": 0,
        "text": " Now, ultimately, I don't need that name of the function",
        "tokens": [
          50364,
          823,
          11,
          6284,
          11,
          286,
          500,
          380,
          643,
          300,
          1315,
          295,
          264,
          2445,
          50510
        ]
      },
      {
        "avg_logprob": -0.18470937837430132,
        "compression_ratio": 1.6785714285714286,
        "end": 313.3,
        "id": 122,
        "no_speech_prob": 0.00007368586375378072,
        "seek": 30988,
        "start": 312.8,
        "temperature": 0,
        "text": " anymore.",
        "tokens": [
          50510,
          3602,
          13,
          50535
        ]
      },
      {
        "avg_logprob": -0.18470937837430132,
        "compression_ratio": 1.6785714285714286,
        "end": 314.2,
        "id": 123,
        "no_speech_prob": 0.00007368586375378072,
        "seek": 30988,
        "start": 313.3,
        "temperature": 0,
        "text": " It's irrelevant.",
        "tokens": [
          50535,
          467,
          311,
          28682,
          13,
          50580
        ]
      },
      {
        "avg_logprob": -0.18470937837430132,
        "compression_ratio": 1.6785714285714286,
        "end": 318.76,
        "id": 124,
        "no_speech_prob": 0.00007368586375378072,
        "seek": 30988,
        "start": 314.2,
        "temperature": 0,
        "text": " Basically, when I say require commands,",
        "tokens": [
          50580,
          8537,
          11,
          562,
          286,
          584,
          3651,
          16901,
          11,
          50808
        ]
      },
      {
        "avg_logprob": -0.18470937837430132,
        "compression_ratio": 1.6785714285714286,
        "end": 321.24,
        "id": 125,
        "no_speech_prob": 0.00007368586375378072,
        "seek": 30988,
        "start": 318.76,
        "temperature": 0,
        "text": " whatever is in module.exports will now",
        "tokens": [
          50808,
          2035,
          307,
          294,
          10088,
          13,
          3121,
          17845,
          486,
          586,
          50932
        ]
      },
      {
        "avg_logprob": -0.18470937837430132,
        "compression_ratio": 1.6785714285714286,
        "end": 322.76,
        "id": 126,
        "no_speech_prob": 0.00007368586375378072,
        "seek": 30988,
        "start": 321.24,
        "temperature": 0,
        "text": " be saved in command handler.",
        "tokens": [
          50932,
          312,
          6624,
          294,
          5622,
          41967,
          13,
          51008
        ]
      },
      {
        "avg_logprob": -0.18470937837430132,
        "compression_ratio": 1.6785714285714286,
        "end": 325.44,
        "id": 127,
        "no_speech_prob": 0.00007368586375378072,
        "seek": 30988,
        "start": 322.76,
        "temperature": 0,
        "text": " So the name of the variable that's holding that function",
        "tokens": [
          51008,
          407,
          264,
          1315,
          295,
          264,
          7006,
          300,
          311,
          5061,
          300,
          2445,
          51142
        ]
      },
      {
        "avg_logprob": -0.18470937837430132,
        "compression_ratio": 1.6785714285714286,
        "end": 326.92,
        "id": 128,
        "no_speech_prob": 0.00007368586375378072,
        "seek": 30988,
        "start": 325.44,
        "temperature": 0,
        "text": " here is command handler.",
        "tokens": [
          51142,
          510,
          307,
          5622,
          41967,
          13,
          51216
        ]
      },
      {
        "avg_logprob": -0.18470937837430132,
        "compression_ratio": 1.6785714285714286,
        "end": 330.48,
        "id": 129,
        "no_speech_prob": 0.00007368586375378072,
        "seek": 30988,
        "start": 326.92,
        "temperature": 0,
        "text": " So going back to commands, I can get rid of this.",
        "tokens": [
          51216,
          407,
          516,
          646,
          281,
          16901,
          11,
          286,
          393,
          483,
          3973,
          295,
          341,
          13,
          51394
        ]
      },
      {
        "avg_logprob": -0.18470937837430132,
        "compression_ratio": 1.6785714285714286,
        "end": 333.56,
        "id": 130,
        "no_speech_prob": 0.00007368586375378072,
        "seek": 30988,
        "start": 330.48,
        "temperature": 0,
        "text": " And I think this is all I need to do.",
        "tokens": [
          51394,
          400,
          286,
          519,
          341,
          307,
          439,
          286,
          643,
          281,
          360,
          13,
          51548
        ]
      },
      {
        "avg_logprob": -0.18470937837430132,
        "compression_ratio": 1.6785714285714286,
        "end": 335.96,
        "id": 131,
        "no_speech_prob": 0.00007368586375378072,
        "seek": 30988,
        "start": 333.56,
        "temperature": 0,
        "text": " Let's hope that my bot still works.",
        "tokens": [
          51548,
          961,
          311,
          1454,
          300,
          452,
          10592,
          920,
          1985,
          13,
          51668
        ]
      },
      {
        "avg_logprob": -0.18470937837430132,
        "compression_ratio": 1.6785714285714286,
        "end": 337.28,
        "id": 132,
        "no_speech_prob": 0.00007368586375378072,
        "seek": 30988,
        "start": 335.96,
        "temperature": 0,
        "text": " Let's try running it again.",
        "tokens": [
          51668,
          961,
          311,
          853,
          2614,
          309,
          797,
          13,
          51734
        ]
      },
      {
        "avg_logprob": -0.24461076198480067,
        "compression_ratio": 1.5870646766169154,
        "end": 341.12,
        "id": 133,
        "no_speech_prob": 0.00014653064135927707,
        "seek": 33988,
        "start": 339.88,
        "temperature": 0,
        "text": " Appears to be working.",
        "tokens": [
          50364,
          41322,
          685,
          281,
          312,
          1364,
          13,
          50426
        ]
      },
      {
        "avg_logprob": -0.24461076198480067,
        "compression_ratio": 1.5870646766169154,
        "end": 341.92,
        "id": 134,
        "no_speech_prob": 0.00014653064135927707,
        "seek": 33988,
        "start": 341.12,
        "temperature": 0,
        "text": " Go back to Discord.",
        "tokens": [
          50426,
          1037,
          646,
          281,
          32623,
          13,
          50466
        ]
      },
      {
        "avg_logprob": -0.24461076198480067,
        "compression_ratio": 1.5870646766169154,
        "end": 345.88,
        "id": 135,
        "no_speech_prob": 0.00014653064135927707,
        "seek": 33988,
        "start": 344.68,
        "temperature": 0,
        "text": " And voila.",
        "tokens": [
          50604,
          400,
          45565,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.24461076198480067,
        "compression_ratio": 1.5870646766169154,
        "end": 348.52,
        "id": 136,
        "no_speech_prob": 0.00014653064135927707,
        "seek": 33988,
        "start": 345.88,
        "temperature": 0,
        "text": " Let's check the GIFs because we can't",
        "tokens": [
          50664,
          961,
          311,
          1520,
          264,
          460,
          12775,
          82,
          570,
          321,
          393,
          380,
          50796
        ]
      },
      {
        "avg_logprob": -0.24461076198480067,
        "compression_ratio": 1.5870646766169154,
        "end": 351.52,
        "id": 137,
        "no_speech_prob": 0.00014653064135927707,
        "seek": 33988,
        "start": 348.52,
        "temperature": 0,
        "text": " have enough rainbow GIFs.",
        "tokens": [
          50796,
          362,
          1547,
          18526,
          460,
          12775,
          82,
          13,
          50946
        ]
      },
      {
        "avg_logprob": -0.24461076198480067,
        "compression_ratio": 1.5870646766169154,
        "end": 352.32,
        "id": 138,
        "no_speech_prob": 0.00014653064135927707,
        "seek": 33988,
        "start": 351.52,
        "temperature": 0,
        "text": " Oh.",
        "tokens": [
          50946,
          876,
          13,
          50986
        ]
      },
      {
        "avg_logprob": -0.24461076198480067,
        "compression_ratio": 1.5870646766169154,
        "end": 353.15999999999997,
        "id": 139,
        "no_speech_prob": 0.00014653064135927707,
        "seek": 33988,
        "start": 352.32,
        "temperature": 0,
        "text": " Ah!",
        "tokens": [
          50986,
          2438,
          0,
          51028
        ]
      },
      {
        "avg_logprob": -0.24461076198480067,
        "compression_ratio": 1.5870646766169154,
        "end": 354.56,
        "id": 140,
        "no_speech_prob": 0.00014653064135927707,
        "seek": 33988,
        "start": 353.15999999999997,
        "temperature": 0,
        "text": " Oh, it's not working.",
        "tokens": [
          51028,
          876,
          11,
          309,
          311,
          406,
          1364,
          13,
          51098
        ]
      },
      {
        "avg_logprob": -0.24461076198480067,
        "compression_ratio": 1.5870646766169154,
        "end": 355.56,
        "id": 141,
        "no_speech_prob": 0.00014653064135927707,
        "seek": 33988,
        "start": 354.56,
        "temperature": 0,
        "text": " The GIFs aren't working.",
        "tokens": [
          51098,
          440,
          460,
          12775,
          82,
          3212,
          380,
          1364,
          13,
          51148
        ]
      },
      {
        "avg_logprob": -0.24461076198480067,
        "compression_ratio": 1.5870646766169154,
        "end": 358.44,
        "id": 142,
        "no_speech_prob": 0.00014653064135927707,
        "seek": 33988,
        "start": 355.56,
        "temperature": 0,
        "text": " What happened?",
        "tokens": [
          51148,
          708,
          2011,
          30,
          51292
        ]
      },
      {
        "avg_logprob": -0.24461076198480067,
        "compression_ratio": 1.5870646766169154,
        "end": 359.76,
        "id": 143,
        "no_speech_prob": 0.00014653064135927707,
        "seek": 33988,
        "start": 358.44,
        "temperature": 0,
        "text": " The fetch is not defined.",
        "tokens": [
          51292,
          440,
          23673,
          307,
          406,
          7642,
          13,
          51358
        ]
      },
      {
        "avg_logprob": -0.24461076198480067,
        "compression_ratio": 1.5870646766169154,
        "end": 361.04,
        "id": 144,
        "no_speech_prob": 0.00014653064135927707,
        "seek": 33988,
        "start": 359.76,
        "temperature": 0,
        "text": " So guess what?",
        "tokens": [
          51358,
          407,
          2041,
          437,
          30,
          51422
        ]
      },
      {
        "avg_logprob": -0.24461076198480067,
        "compression_ratio": 1.5870646766169154,
        "end": 364.96,
        "id": 145,
        "no_speech_prob": 0.00014653064135927707,
        "seek": 33988,
        "start": 361.04,
        "temperature": 0,
        "text": " The fetch function is being used here in commands.js.",
        "tokens": [
          51422,
          440,
          23673,
          2445,
          307,
          885,
          1143,
          510,
          294,
          16901,
          13,
          25530,
          13,
          51618
        ]
      },
      {
        "avg_logprob": -0.24461076198480067,
        "compression_ratio": 1.5870646766169154,
        "end": 368.36,
        "id": 146,
        "no_speech_prob": 0.00014653064135927707,
        "seek": 33988,
        "start": 364.96,
        "temperature": 0,
        "text": " It is not being used here in bot.js.",
        "tokens": [
          51618,
          467,
          307,
          406,
          885,
          1143,
          510,
          294,
          10592,
          13,
          25530,
          13,
          51788
        ]
      },
      {
        "avg_logprob": -0.22462284564971924,
        "compression_ratio": 1.4912280701754386,
        "end": 372.8,
        "id": 147,
        "no_speech_prob": 0.00007141890091588721,
        "seek": 36836,
        "start": 368.36,
        "temperature": 0,
        "text": " So I will want to bring over this require of the node",
        "tokens": [
          50364,
          407,
          286,
          486,
          528,
          281,
          1565,
          670,
          341,
          3651,
          295,
          264,
          9984,
          50586
        ]
      },
      {
        "avg_logprob": -0.22462284564971924,
        "compression_ratio": 1.4912280701754386,
        "end": 373.76,
        "id": 148,
        "no_speech_prob": 0.00007141890091588721,
        "seek": 36836,
        "start": 372.8,
        "temperature": 0,
        "text": " module node fetch.",
        "tokens": [
          50586,
          10088,
          9984,
          23673,
          13,
          50634
        ]
      },
      {
        "avg_logprob": -0.22462284564971924,
        "compression_ratio": 1.4912280701754386,
        "end": 381.76,
        "id": 149,
        "no_speech_prob": 0.00007141890091588721,
        "seek": 36836,
        "start": 380.84000000000003,
        "temperature": 0,
        "text": " And there we go.",
        "tokens": [
          50988,
          400,
          456,
          321,
          352,
          13,
          51034
        ]
      },
      {
        "avg_logprob": -0.22462284564971924,
        "compression_ratio": 1.4912280701754386,
        "end": 384.2,
        "id": 150,
        "no_speech_prob": 0.00007141890091588721,
        "seek": 36836,
        "start": 381.76,
        "temperature": 0,
        "text": " Oh, we have this beautiful cat riding a unicorn",
        "tokens": [
          51034,
          876,
          11,
          321,
          362,
          341,
          2238,
          3857,
          9546,
          257,
          28122,
          51156
        ]
      },
      {
        "avg_logprob": -0.22462284564971924,
        "compression_ratio": 1.4912280701754386,
        "end": 386.36,
        "id": 151,
        "no_speech_prob": 0.00007141890091588721,
        "seek": 36836,
        "start": 384.2,
        "temperature": 0,
        "text": " with a rainbow GIF again.",
        "tokens": [
          51156,
          365,
          257,
          18526,
          460,
          12775,
          797,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.22462284564971924,
        "compression_ratio": 1.4912280701754386,
        "end": 388.96000000000004,
        "id": 152,
        "no_speech_prob": 0.00007141890091588721,
        "seek": 36836,
        "start": 386.36,
        "temperature": 0,
        "text": " Now, there's a lot more to say about module.exports.",
        "tokens": [
          51264,
          823,
          11,
          456,
          311,
          257,
          688,
          544,
          281,
          584,
          466,
          10088,
          13,
          3121,
          17845,
          13,
          51394
        ]
      },
      {
        "avg_logprob": -0.22462284564971924,
        "compression_ratio": 1.4912280701754386,
        "end": 390.96000000000004,
        "id": 153,
        "no_speech_prob": 0.00007141890091588721,
        "seek": 36836,
        "start": 388.96000000000004,
        "temperature": 0,
        "text": " I'm just scratching the surface here.",
        "tokens": [
          51394,
          286,
          478,
          445,
          29699,
          264,
          3753,
          510,
          13,
          51494
        ]
      },
      {
        "avg_logprob": -0.22462284564971924,
        "compression_ratio": 1.4912280701754386,
        "end": 392.76,
        "id": 154,
        "no_speech_prob": 0.00007141890091588721,
        "seek": 36836,
        "start": 390.96000000000004,
        "temperature": 0,
        "text": " I could set an equal to an object that",
        "tokens": [
          51494,
          286,
          727,
          992,
          364,
          2681,
          281,
          364,
          2657,
          300,
          51584
        ]
      },
      {
        "avg_logprob": -0.22462284564971924,
        "compression_ratio": 1.4912280701754386,
        "end": 394.78000000000003,
        "id": 155,
        "no_speech_prob": 0.00007141890091588721,
        "seek": 36836,
        "start": 392.76,
        "temperature": 0,
        "text": " has multiple properties and multiple functions",
        "tokens": [
          51584,
          575,
          3866,
          7221,
          293,
          3866,
          6828,
          51685
        ]
      },
      {
        "avg_logprob": -0.19702982498427568,
        "compression_ratio": 1.6788321167883211,
        "end": 398.65999999999997,
        "id": 156,
        "no_speech_prob": 0.009708338417112827,
        "seek": 39478,
        "start": 394.78,
        "temperature": 0,
        "text": " or use classes and all sorts of other kinds of JavaScript",
        "tokens": [
          50364,
          420,
          764,
          5359,
          293,
          439,
          7527,
          295,
          661,
          3685,
          295,
          15778,
          50558
        ]
      },
      {
        "avg_logprob": -0.19702982498427568,
        "compression_ratio": 1.6788321167883211,
        "end": 402.09999999999997,
        "id": 157,
        "no_speech_prob": 0.009708338417112827,
        "seek": 39478,
        "start": 398.65999999999997,
        "temperature": 0,
        "text": " things that I export from a particular JavaScript file.",
        "tokens": [
          50558,
          721,
          300,
          286,
          10725,
          490,
          257,
          1729,
          15778,
          3991,
          13,
          50730
        ]
      },
      {
        "avg_logprob": -0.19702982498427568,
        "compression_ratio": 1.6788321167883211,
        "end": 404.7,
        "id": 158,
        "no_speech_prob": 0.009708338417112827,
        "seek": 39478,
        "start": 402.09999999999997,
        "temperature": 0,
        "text": " But I'm going to stick with just this basic idea right now",
        "tokens": [
          50730,
          583,
          286,
          478,
          516,
          281,
          2897,
          365,
          445,
          341,
          3875,
          1558,
          558,
          586,
          50860
        ]
      },
      {
        "avg_logprob": -0.19702982498427568,
        "compression_ratio": 1.6788321167883211,
        "end": 408.85999999999996,
        "id": 159,
        "no_speech_prob": 0.009708338417112827,
        "seek": 39478,
        "start": 404.7,
        "temperature": 0,
        "text": " and, in fact, take it one step further because still, look,",
        "tokens": [
          50860,
          293,
          11,
          294,
          1186,
          11,
          747,
          309,
          472,
          1823,
          3052,
          570,
          920,
          11,
          574,
          11,
          51068
        ]
      },
      {
        "avg_logprob": -0.19702982498427568,
        "compression_ratio": 1.6788321167883211,
        "end": 411.02,
        "id": 160,
        "no_speech_prob": 0.009708338417112827,
        "seek": 39478,
        "start": 408.85999999999996,
        "temperature": 0,
        "text": " I have this long if statement.",
        "tokens": [
          51068,
          286,
          362,
          341,
          938,
          498,
          5629,
          13,
          51176
        ]
      },
      {
        "avg_logprob": -0.19702982498427568,
        "compression_ratio": 1.6788321167883211,
        "end": 413.73999999999995,
        "id": 161,
        "no_speech_prob": 0.009708338417112827,
        "seek": 39478,
        "start": 411.02,
        "temperature": 0,
        "text": " Yes, I get to put this if statement in a separate file,",
        "tokens": [
          51176,
          1079,
          11,
          286,
          483,
          281,
          829,
          341,
          498,
          5629,
          294,
          257,
          4994,
          3991,
          11,
          51312
        ]
      },
      {
        "avg_logprob": -0.19702982498427568,
        "compression_ratio": 1.6788321167883211,
        "end": 416.85999999999996,
        "id": 162,
        "no_speech_prob": 0.009708338417112827,
        "seek": 39478,
        "start": 413.73999999999995,
        "temperature": 0,
        "text": " but how could I maybe handle these commands more elegantly?",
        "tokens": [
          51312,
          457,
          577,
          727,
          286,
          1310,
          4813,
          613,
          16901,
          544,
          14459,
          3627,
          30,
          51468
        ]
      },
      {
        "avg_logprob": -0.19702982498427568,
        "compression_ratio": 1.6788321167883211,
        "end": 420.85999999999996,
        "id": 163,
        "no_speech_prob": 0.009708338417112827,
        "seek": 39478,
        "start": 416.85999999999996,
        "temperature": 0,
        "text": " And my goal here is to have a separate JavaScript",
        "tokens": [
          51468,
          400,
          452,
          3387,
          510,
          307,
          281,
          362,
          257,
          4994,
          15778,
          51668
        ]
      },
      {
        "avg_logprob": -0.19702982498427568,
        "compression_ratio": 1.6788321167883211,
        "end": 423.26,
        "id": 164,
        "no_speech_prob": 0.009708338417112827,
        "seek": 39478,
        "start": 420.85999999999996,
        "temperature": 0,
        "text": " file for every single command.",
        "tokens": [
          51668,
          3991,
          337,
          633,
          2167,
          5622,
          13,
          51788
        ]
      },
      {
        "avg_logprob": -0.2625437516432542,
        "compression_ratio": 1.6529411764705881,
        "end": 426.78,
        "id": 165,
        "no_speech_prob": 0.0002611899108160287,
        "seek": 42326,
        "start": 423.26,
        "temperature": 0,
        "text": " So let's think about, let's maybe add a folder.",
        "tokens": [
          50364,
          407,
          718,
          311,
          519,
          466,
          11,
          718,
          311,
          1310,
          909,
          257,
          10820,
          13,
          50540
        ]
      },
      {
        "avg_logprob": -0.2625437516432542,
        "compression_ratio": 1.6529411764705881,
        "end": 428.7,
        "id": 166,
        "no_speech_prob": 0.0002611899108160287,
        "seek": 42326,
        "start": 426.78,
        "temperature": 0,
        "text": " I'll create a folder called commands.",
        "tokens": [
          50540,
          286,
          603,
          1884,
          257,
          10820,
          1219,
          16901,
          13,
          50636
        ]
      },
      {
        "avg_logprob": -0.2625437516432542,
        "compression_ratio": 1.6529411764705881,
        "end": 434.26,
        "id": 167,
        "no_speech_prob": 0.0002611899108160287,
        "seek": 42326,
        "start": 428.7,
        "temperature": 0,
        "text": " In that folder, let's add a file called choochoo.js",
        "tokens": [
          50636,
          682,
          300,
          10820,
          11,
          718,
          311,
          909,
          257,
          3991,
          1219,
          1586,
          78,
          339,
          1986,
          13,
          25530,
          50914
        ]
      },
      {
        "avg_logprob": -0.2625437516432542,
        "compression_ratio": 1.6529411764705881,
        "end": 437.3,
        "id": 168,
        "no_speech_prob": 0.0002611899108160287,
        "seek": 42326,
        "start": 434.26,
        "temperature": 0,
        "text": " and a file called gif.js.",
        "tokens": [
          50914,
          293,
          257,
          3991,
          1219,
          290,
          351,
          13,
          25530,
          13,
          51066
        ]
      },
      {
        "avg_logprob": -0.2625437516432542,
        "compression_ratio": 1.6529411764705881,
        "end": 440.09999999999997,
        "id": 169,
        "no_speech_prob": 0.0002611899108160287,
        "seek": 42326,
        "start": 437.3,
        "temperature": 0,
        "text": " Now, I can require both of those.",
        "tokens": [
          51066,
          823,
          11,
          286,
          393,
          3651,
          1293,
          295,
          729,
          13,
          51206
        ]
      },
      {
        "avg_logprob": -0.2625437516432542,
        "compression_ratio": 1.6529411764705881,
        "end": 447.9,
        "id": 170,
        "no_speech_prob": 0.0002611899108160287,
        "seek": 42326,
        "start": 445.5,
        "temperature": 0,
        "text": " So what goes in those JavaScript files?",
        "tokens": [
          51476,
          407,
          437,
          1709,
          294,
          729,
          15778,
          7098,
          30,
          51596
        ]
      },
      {
        "avg_logprob": -0.2625437516432542,
        "compression_ratio": 1.6529411764705881,
        "end": 450.02,
        "id": 171,
        "no_speech_prob": 0.0002611899108160287,
        "seek": 42326,
        "start": 447.9,
        "temperature": 0,
        "text": " I'm going to think about this as I'm going.",
        "tokens": [
          51596,
          286,
          478,
          516,
          281,
          519,
          466,
          341,
          382,
          286,
          478,
          516,
          13,
          51702
        ]
      },
      {
        "avg_logprob": -0.22635226414121432,
        "compression_ratio": 1.7887323943661972,
        "end": 453.78,
        "id": 172,
        "no_speech_prob": 0.00010720854334067553,
        "seek": 45002,
        "start": 450.02,
        "temperature": 0,
        "text": " So in choochoo.js, that's the command",
        "tokens": [
          50364,
          407,
          294,
          1586,
          8997,
          1986,
          13,
          25530,
          11,
          300,
          311,
          264,
          5622,
          50552
        ]
      },
      {
        "avg_logprob": -0.22635226414121432,
        "compression_ratio": 1.7887323943661972,
        "end": 455.62,
        "id": 173,
        "no_speech_prob": 0.00010720854334067553,
        "seek": 45002,
        "start": 453.78,
        "temperature": 0,
        "text": " that returns a random reply.",
        "tokens": [
          50552,
          300,
          11247,
          257,
          4974,
          16972,
          13,
          50644
        ]
      },
      {
        "avg_logprob": -0.22635226414121432,
        "compression_ratio": 1.7887323943661972,
        "end": 457.46,
        "id": 174,
        "no_speech_prob": 0.00010720854334067553,
        "seek": 45002,
        "start": 455.62,
        "temperature": 0,
        "text": " So let's take these two lines of code",
        "tokens": [
          50644,
          407,
          718,
          311,
          747,
          613,
          732,
          3876,
          295,
          3089,
          50736
        ]
      },
      {
        "avg_logprob": -0.22635226414121432,
        "compression_ratio": 1.7887323943661972,
        "end": 460.82,
        "id": 175,
        "no_speech_prob": 0.00010720854334067553,
        "seek": 45002,
        "start": 457.46,
        "temperature": 0,
        "text": " and just kind of put them in here for safekeeping right now",
        "tokens": [
          50736,
          293,
          445,
          733,
          295,
          829,
          552,
          294,
          510,
          337,
          3273,
          25769,
          558,
          586,
          50904
        ]
      },
      {
        "avg_logprob": -0.22635226414121432,
        "compression_ratio": 1.7887323943661972,
        "end": 463.5,
        "id": 176,
        "no_speech_prob": 0.00010720854334067553,
        "seek": 45002,
        "start": 460.82,
        "temperature": 0,
        "text": " and then also go back to commands.js",
        "tokens": [
          50904,
          293,
          550,
          611,
          352,
          646,
          281,
          16901,
          13,
          25530,
          51038
        ]
      },
      {
        "avg_logprob": -0.22635226414121432,
        "compression_ratio": 1.7887323943661972,
        "end": 471.7,
        "id": 177,
        "no_speech_prob": 0.00010720854334067553,
        "seek": 45002,
        "start": 463.5,
        "temperature": 0,
        "text": " and take this whole bit of code and put that into gif.js.",
        "tokens": [
          51038,
          293,
          747,
          341,
          1379,
          857,
          295,
          3089,
          293,
          829,
          300,
          666,
          290,
          351,
          13,
          25530,
          13,
          51448
        ]
      },
      {
        "avg_logprob": -0.22635226414121432,
        "compression_ratio": 1.7887323943661972,
        "end": 475.5,
        "id": 178,
        "no_speech_prob": 0.00010720854334067553,
        "seek": 45002,
        "start": 471.7,
        "temperature": 0,
        "text": " All right, so I've got the code for sending a gif,",
        "tokens": [
          51448,
          1057,
          558,
          11,
          370,
          286,
          600,
          658,
          264,
          3089,
          337,
          7750,
          257,
          290,
          351,
          11,
          51638
        ]
      },
      {
        "avg_logprob": -0.22635226414121432,
        "compression_ratio": 1.7887323943661972,
        "end": 477.53999999999996,
        "id": 179,
        "no_speech_prob": 0.00010720854334067553,
        "seek": 45002,
        "start": 475.5,
        "temperature": 0,
        "text": " and I've got the code for sending a random reply",
        "tokens": [
          51638,
          293,
          286,
          600,
          658,
          264,
          3089,
          337,
          7750,
          257,
          4974,
          16972,
          51740
        ]
      },
      {
        "avg_logprob": -0.22635226414121432,
        "compression_ratio": 1.7887323943661972,
        "end": 478.85999999999996,
        "id": 180,
        "no_speech_prob": 0.00010720854334067553,
        "seek": 45002,
        "start": 477.53999999999996,
        "temperature": 0,
        "text": " in my separate files.",
        "tokens": [
          51740,
          294,
          452,
          4994,
          7098,
          13,
          51806
        ]
      },
      {
        "avg_logprob": -0.2312277420707371,
        "compression_ratio": 1.8508771929824561,
        "end": 481.14,
        "id": 181,
        "no_speech_prob": 0.000017778522305889055,
        "seek": 47886,
        "start": 478.86,
        "temperature": 0,
        "text": " The other thing that I think would be quite helpful here",
        "tokens": [
          50364,
          440,
          661,
          551,
          300,
          286,
          519,
          576,
          312,
          1596,
          4961,
          510,
          50478
        ]
      },
      {
        "avg_logprob": -0.2312277420707371,
        "compression_ratio": 1.8508771929824561,
        "end": 483.98,
        "id": 182,
        "no_speech_prob": 0.000017778522305889055,
        "seek": 47886,
        "start": 481.14,
        "temperature": 0,
        "text": " is for me to think more clearly about what's",
        "tokens": [
          50478,
          307,
          337,
          385,
          281,
          519,
          544,
          4448,
          466,
          437,
          311,
          50620
        ]
      },
      {
        "avg_logprob": -0.2312277420707371,
        "compression_ratio": 1.8508771929824561,
        "end": 486.62,
        "id": 183,
        "no_speech_prob": 0.000017778522305889055,
        "seek": 47886,
        "start": 483.98,
        "temperature": 0,
        "text": " in this variable called tokens.",
        "tokens": [
          50620,
          294,
          341,
          7006,
          1219,
          22667,
          13,
          50752
        ]
      },
      {
        "avg_logprob": -0.2312277420707371,
        "compression_ratio": 1.8508771929824561,
        "end": 488.34000000000003,
        "id": 184,
        "no_speech_prob": 0.000017778522305889055,
        "seek": 47886,
        "start": 486.62,
        "temperature": 0,
        "text": " There's really two things.",
        "tokens": [
          50752,
          821,
          311,
          534,
          732,
          721,
          13,
          50838
        ]
      },
      {
        "avg_logprob": -0.2312277420707371,
        "compression_ratio": 1.8508771929824561,
        "end": 491.98,
        "id": 185,
        "no_speech_prob": 0.000017778522305889055,
        "seek": 47886,
        "start": 488.34000000000003,
        "temperature": 0,
        "text": " There's the command, that's exclamation point choo choo,",
        "tokens": [
          50838,
          821,
          311,
          264,
          5622,
          11,
          300,
          311,
          1624,
          43233,
          935,
          1586,
          78,
          1586,
          78,
          11,
          51020
        ]
      },
      {
        "avg_logprob": -0.2312277420707371,
        "compression_ratio": 1.8508771929824561,
        "end": 493.74,
        "id": 186,
        "no_speech_prob": 0.000017778522305889055,
        "seek": 47886,
        "start": 491.98,
        "temperature": 0,
        "text": " exclamation point gif, and then there's",
        "tokens": [
          51020,
          1624,
          43233,
          935,
          290,
          351,
          11,
          293,
          550,
          456,
          311,
          51108
        ]
      },
      {
        "avg_logprob": -0.2312277420707371,
        "compression_ratio": 1.8508771929824561,
        "end": 499.38,
        "id": 187,
        "no_speech_prob": 0.000017778522305889055,
        "seek": 47886,
        "start": 493.74,
        "temperature": 0,
        "text": " the arguments, what comes after that command.",
        "tokens": [
          51108,
          264,
          12869,
          11,
          437,
          1487,
          934,
          300,
          5622,
          13,
          51390
        ]
      },
      {
        "avg_logprob": -0.2312277420707371,
        "compression_ratio": 1.8508771929824561,
        "end": 501.3,
        "id": 188,
        "no_speech_prob": 0.000017778522305889055,
        "seek": 47886,
        "start": 499.38,
        "temperature": 0,
        "text": " So the command is the first token,",
        "tokens": [
          51390,
          407,
          264,
          5622,
          307,
          264,
          700,
          14862,
          11,
          51486
        ]
      },
      {
        "avg_logprob": -0.2312277420707371,
        "compression_ratio": 1.8508771929824561,
        "end": 505.90000000000003,
        "id": 189,
        "no_speech_prob": 0.000017778522305889055,
        "seek": 47886,
        "start": 501.3,
        "temperature": 0,
        "text": " and it's only a valid command if the first character of it",
        "tokens": [
          51486,
          293,
          309,
          311,
          787,
          257,
          7363,
          5622,
          498,
          264,
          700,
          2517,
          295,
          309,
          51716
        ]
      },
      {
        "avg_logprob": -0.2312277420707371,
        "compression_ratio": 1.8508771929824561,
        "end": 507.18,
        "id": 190,
        "no_speech_prob": 0.000017778522305889055,
        "seek": 47886,
        "start": 505.90000000000003,
        "temperature": 0,
        "text": " is an exclamation point.",
        "tokens": [
          51716,
          307,
          364,
          1624,
          43233,
          935,
          13,
          51780
        ]
      },
      {
        "avg_logprob": -0.2626111058905573,
        "compression_ratio": 1.7123287671232876,
        "end": 514.42,
        "id": 191,
        "no_speech_prob": 0.00017674476839601994,
        "seek": 50886,
        "start": 509.86,
        "temperature": 0,
        "text": " And actually, a better way for me to do this",
        "tokens": [
          50414,
          400,
          767,
          11,
          257,
          1101,
          636,
          337,
          385,
          281,
          360,
          341,
          50642
        ]
      },
      {
        "avg_logprob": -0.2626111058905573,
        "compression_ratio": 1.7123287671232876,
        "end": 517.5,
        "id": 192,
        "no_speech_prob": 0.00017674476839601994,
        "seek": 50886,
        "start": 514.42,
        "temperature": 0,
        "text": " would be to actually remove that first token from the array",
        "tokens": [
          50642,
          576,
          312,
          281,
          767,
          4159,
          300,
          700,
          14862,
          490,
          264,
          10225,
          50796
        ]
      },
      {
        "avg_logprob": -0.2626111058905573,
        "compression_ratio": 1.7123287671232876,
        "end": 520.1,
        "id": 193,
        "no_speech_prob": 0.00017674476839601994,
        "seek": 50886,
        "start": 517.5,
        "temperature": 0,
        "text": " because I don't want it anymore because I want that array left",
        "tokens": [
          50796,
          570,
          286,
          500,
          380,
          528,
          309,
          3602,
          570,
          286,
          528,
          300,
          10225,
          1411,
          50926
        ]
      },
      {
        "avg_logprob": -0.2626111058905573,
        "compression_ratio": 1.7123287671232876,
        "end": 521.54,
        "id": 194,
        "no_speech_prob": 0.00017674476839601994,
        "seek": 50886,
        "start": 520.1,
        "temperature": 0,
        "text": " to be the arguments.",
        "tokens": [
          50926,
          281,
          312,
          264,
          12869,
          13,
          50998
        ]
      },
      {
        "avg_logprob": -0.2626111058905573,
        "compression_ratio": 1.7123287671232876,
        "end": 525.62,
        "id": 195,
        "no_speech_prob": 0.00017674476839601994,
        "seek": 50886,
        "start": 521.54,
        "temperature": 0,
        "text": " So let's say tokens.shift.",
        "tokens": [
          50998,
          407,
          718,
          311,
          584,
          22667,
          13,
          47445,
          13,
          51202
        ]
      },
      {
        "avg_logprob": -0.2626111058905573,
        "compression_ratio": 1.7123287671232876,
        "end": 530.1,
        "id": 196,
        "no_speech_prob": 0.00017674476839601994,
        "seek": 50886,
        "start": 525.62,
        "temperature": 0,
        "text": " Tokens.shift shifts everything in the array over one spot",
        "tokens": [
          51202,
          11036,
          694,
          13,
          47445,
          19201,
          1203,
          294,
          264,
          10225,
          670,
          472,
          4008,
          51426
        ]
      },
      {
        "avg_logprob": -0.2626111058905573,
        "compression_ratio": 1.7123287671232876,
        "end": 531.5,
        "id": 197,
        "no_speech_prob": 0.00017674476839601994,
        "seek": 50886,
        "start": 530.1,
        "temperature": 0,
        "text": " and removes the first element.",
        "tokens": [
          51426,
          293,
          30445,
          264,
          700,
          4478,
          13,
          51496
        ]
      },
      {
        "avg_logprob": -0.2626111058905573,
        "compression_ratio": 1.7123287671232876,
        "end": 532.98,
        "id": 198,
        "no_speech_prob": 0.00017674476839601994,
        "seek": 50886,
        "start": 531.5,
        "temperature": 0,
        "text": " So that command is there.",
        "tokens": [
          51496,
          407,
          300,
          5622,
          307,
          456,
          13,
          51570
        ]
      },
      {
        "avg_logprob": -0.2626111058905573,
        "compression_ratio": 1.7123287671232876,
        "end": 535.4200000000001,
        "id": 199,
        "no_speech_prob": 0.00017674476839601994,
        "seek": 50886,
        "start": 532.98,
        "temperature": 0,
        "text": " If the first character is exclamation point,",
        "tokens": [
          51570,
          759,
          264,
          700,
          2517,
          307,
          1624,
          43233,
          935,
          11,
          51692
        ]
      },
      {
        "avg_logprob": -0.2524859025174339,
        "compression_ratio": 1.7986348122866893,
        "end": 538.6999999999999,
        "id": 200,
        "no_speech_prob": 0.000027535670596989803,
        "seek": 53542,
        "start": 535.42,
        "temperature": 0,
        "text": " then also take out that first character,",
        "tokens": [
          50364,
          550,
          611,
          747,
          484,
          300,
          700,
          2517,
          11,
          50528
        ]
      },
      {
        "avg_logprob": -0.2524859025174339,
        "compression_ratio": 1.7986348122866893,
        "end": 541.5,
        "id": 201,
        "no_speech_prob": 0.000027535670596989803,
        "seek": 53542,
        "start": 538.6999999999999,
        "temperature": 0,
        "text": " which I can do by using the substring function",
        "tokens": [
          50528,
          597,
          286,
          393,
          360,
          538,
          1228,
          264,
          4594,
          2937,
          2445,
          50668
        ]
      },
      {
        "avg_logprob": -0.2524859025174339,
        "compression_ratio": 1.7986348122866893,
        "end": 543.5799999999999,
        "id": 202,
        "no_speech_prob": 0.000027535670596989803,
        "seek": 53542,
        "start": 541.5,
        "temperature": 0,
        "text": " to go from one to the end of the string.",
        "tokens": [
          50668,
          281,
          352,
          490,
          472,
          281,
          264,
          917,
          295,
          264,
          6798,
          13,
          50772
        ]
      },
      {
        "avg_logprob": -0.2524859025174339,
        "compression_ratio": 1.7986348122866893,
        "end": 546.2199999999999,
        "id": 203,
        "no_speech_prob": 0.000027535670596989803,
        "seek": 53542,
        "start": 543.5799999999999,
        "temperature": 0,
        "text": " But if I leave out the second argument by default.",
        "tokens": [
          50772,
          583,
          498,
          286,
          1856,
          484,
          264,
          1150,
          6770,
          538,
          7576,
          13,
          50904
        ]
      },
      {
        "avg_logprob": -0.2524859025174339,
        "compression_ratio": 1.7986348122866893,
        "end": 548.3399999999999,
        "id": 204,
        "no_speech_prob": 0.000027535670596989803,
        "seek": 53542,
        "start": 546.2199999999999,
        "temperature": 0,
        "text": " So this now, I mean, it's a little bit convoluted.",
        "tokens": [
          50904,
          407,
          341,
          586,
          11,
          286,
          914,
          11,
          309,
          311,
          257,
          707,
          857,
          3754,
          2308,
          292,
          13,
          51010
        ]
      },
      {
        "avg_logprob": -0.2524859025174339,
        "compression_ratio": 1.7986348122866893,
        "end": 550.3,
        "id": 205,
        "no_speech_prob": 0.000027535670596989803,
        "seek": 53542,
        "start": 548.3399999999999,
        "temperature": 0,
        "text": " I'm sure this could be condensed.",
        "tokens": [
          51010,
          286,
          478,
          988,
          341,
          727,
          312,
          36398,
          13,
          51108
        ]
      },
      {
        "avg_logprob": -0.2524859025174339,
        "compression_ratio": 1.7986348122866893,
        "end": 552.62,
        "id": 206,
        "no_speech_prob": 0.000027535670596989803,
        "seek": 53542,
        "start": 550.3,
        "temperature": 0,
        "text": " But take out the first token, check",
        "tokens": [
          51108,
          583,
          747,
          484,
          264,
          700,
          14862,
          11,
          1520,
          51224
        ]
      },
      {
        "avg_logprob": -0.2524859025174339,
        "compression_ratio": 1.7986348122866893,
        "end": 554.6999999999999,
        "id": 207,
        "no_speech_prob": 0.000027535670596989803,
        "seek": 53542,
        "start": 552.62,
        "temperature": 0,
        "text": " to see if the first character is exclamation point,",
        "tokens": [
          51224,
          281,
          536,
          498,
          264,
          700,
          2517,
          307,
          1624,
          43233,
          935,
          11,
          51328
        ]
      },
      {
        "avg_logprob": -0.2524859025174339,
        "compression_ratio": 1.7986348122866893,
        "end": 556.36,
        "id": 208,
        "no_speech_prob": 0.000027535670596989803,
        "seek": 53542,
        "start": 554.6999999999999,
        "temperature": 0,
        "text": " and then remove that exclamation point,",
        "tokens": [
          51328,
          293,
          550,
          4159,
          300,
          1624,
          43233,
          935,
          11,
          51411
        ]
      },
      {
        "avg_logprob": -0.2524859025174339,
        "compression_ratio": 1.7986348122866893,
        "end": 558.06,
        "id": 209,
        "no_speech_prob": 0.000027535670596989803,
        "seek": 53542,
        "start": 556.36,
        "temperature": 0,
        "text": " and I've got the valid command.",
        "tokens": [
          51411,
          293,
          286,
          600,
          658,
          264,
          7363,
          5622,
          13,
          51496
        ]
      },
      {
        "avg_logprob": -0.2524859025174339,
        "compression_ratio": 1.7986348122866893,
        "end": 560.42,
        "id": 210,
        "no_speech_prob": 0.000027535670596989803,
        "seek": 53542,
        "start": 558.06,
        "temperature": 0,
        "text": " I can get rid of this stuff now at the bottom.",
        "tokens": [
          51496,
          286,
          393,
          483,
          3973,
          295,
          341,
          1507,
          586,
          412,
          264,
          2767,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.2524859025174339,
        "compression_ratio": 1.7986348122866893,
        "end": 563.42,
        "id": 211,
        "no_speech_prob": 0.000027535670596989803,
        "seek": 53542,
        "start": 560.42,
        "temperature": 0,
        "text": " The only thing, the things that might be in the command",
        "tokens": [
          51614,
          440,
          787,
          551,
          11,
          264,
          721,
          300,
          1062,
          312,
          294,
          264,
          5622,
          51764
        ]
      },
      {
        "avg_logprob": -0.2153455029736768,
        "compression_ratio": 1.9187817258883249,
        "end": 566.38,
        "id": 212,
        "no_speech_prob": 0.0016743940068408847,
        "seek": 56342,
        "start": 563.42,
        "temperature": 0,
        "text": " variable now are choo-choo or GIF.",
        "tokens": [
          50364,
          7006,
          586,
          366,
          1586,
          78,
          12,
          339,
          1986,
          420,
          460,
          12775,
          13,
          50512
        ]
      },
      {
        "avg_logprob": -0.2153455029736768,
        "compression_ratio": 1.9187817258883249,
        "end": 568.4599999999999,
        "id": 213,
        "no_speech_prob": 0.0016743940068408847,
        "seek": 56342,
        "start": 566.38,
        "temperature": 0,
        "text": " OK, what do I do?",
        "tokens": [
          50512,
          2264,
          11,
          437,
          360,
          286,
          360,
          30,
          50616
        ]
      },
      {
        "avg_logprob": -0.2153455029736768,
        "compression_ratio": 1.9187817258883249,
        "end": 573.18,
        "id": 214,
        "no_speech_prob": 0.0016743940068408847,
        "seek": 56342,
        "start": 568.4599999999999,
        "temperature": 0,
        "text": " What if I have an object, think about this, called commands.",
        "tokens": [
          50616,
          708,
          498,
          286,
          362,
          364,
          2657,
          11,
          519,
          466,
          341,
          11,
          1219,
          16901,
          13,
          50852
        ]
      },
      {
        "avg_logprob": -0.2153455029736768,
        "compression_ratio": 1.9187817258883249,
        "end": 575.78,
        "id": 215,
        "no_speech_prob": 0.0016743940068408847,
        "seek": 56342,
        "start": 573.18,
        "temperature": 0,
        "text": " And in that object, I have something",
        "tokens": [
          50852,
          400,
          294,
          300,
          2657,
          11,
          286,
          362,
          746,
          50982
        ]
      },
      {
        "avg_logprob": -0.2153455029736768,
        "compression_ratio": 1.9187817258883249,
        "end": 579.9599999999999,
        "id": 216,
        "no_speech_prob": 0.0016743940068408847,
        "seek": 56342,
        "start": 575.78,
        "temperature": 0,
        "text": " called choo-choo, which is a function that does something.",
        "tokens": [
          50982,
          1219,
          1586,
          78,
          12,
          339,
          1986,
          11,
          597,
          307,
          257,
          2445,
          300,
          775,
          746,
          13,
          51191
        ]
      },
      {
        "avg_logprob": -0.2153455029736768,
        "compression_ratio": 1.9187817258883249,
        "end": 582.18,
        "id": 217,
        "no_speech_prob": 0.0016743940068408847,
        "seek": 56342,
        "start": 579.9599999999999,
        "temperature": 0,
        "text": " And I have something called GIF, which is",
        "tokens": [
          51191,
          400,
          286,
          362,
          746,
          1219,
          460,
          12775,
          11,
          597,
          307,
          51302
        ]
      },
      {
        "avg_logprob": -0.2153455029736768,
        "compression_ratio": 1.9187817258883249,
        "end": 584.9,
        "id": 218,
        "no_speech_prob": 0.0016743940068408847,
        "seek": 56342,
        "start": 582.18,
        "temperature": 0,
        "text": " a function that does something.",
        "tokens": [
          51302,
          257,
          2445,
          300,
          775,
          746,
          13,
          51438
        ]
      },
      {
        "avg_logprob": -0.2153455029736768,
        "compression_ratio": 1.9187817258883249,
        "end": 589.54,
        "id": 219,
        "no_speech_prob": 0.0016743940068408847,
        "seek": 56342,
        "start": 584.9,
        "temperature": 0,
        "text": " And maybe that function takes arguments.",
        "tokens": [
          51438,
          400,
          1310,
          300,
          2445,
          2516,
          12869,
          13,
          51670
        ]
      },
      {
        "avg_logprob": -0.2153455029736768,
        "compression_ratio": 1.9187817258883249,
        "end": 592.76,
        "id": 220,
        "no_speech_prob": 0.0016743940068408847,
        "seek": 56342,
        "start": 589.54,
        "temperature": 0,
        "text": " So this object acts as something like a lookup table.",
        "tokens": [
          51670,
          407,
          341,
          2657,
          10672,
          382,
          746,
          411,
          257,
          574,
          1010,
          3199,
          13,
          51831
        ]
      },
      {
        "avg_logprob": -0.20759572480854235,
        "compression_ratio": 1.8691588785046729,
        "end": 595.56,
        "id": 221,
        "no_speech_prob": 0.00005562203659792431,
        "seek": 59276,
        "start": 592.76,
        "temperature": 0,
        "text": " Let me look up the function associated with choo-choo.",
        "tokens": [
          50364,
          961,
          385,
          574,
          493,
          264,
          2445,
          6615,
          365,
          1586,
          78,
          12,
          339,
          1986,
          13,
          50504
        ]
      },
      {
        "avg_logprob": -0.20759572480854235,
        "compression_ratio": 1.8691588785046729,
        "end": 598.08,
        "id": 222,
        "no_speech_prob": 0.00005562203659792431,
        "seek": 59276,
        "start": 595.56,
        "temperature": 0,
        "text": " Let me look up the function associated with GIF.",
        "tokens": [
          50504,
          961,
          385,
          574,
          493,
          264,
          2445,
          6615,
          365,
          460,
          12775,
          13,
          50630
        ]
      },
      {
        "avg_logprob": -0.20759572480854235,
        "compression_ratio": 1.8691588785046729,
        "end": 600.76,
        "id": 223,
        "no_speech_prob": 0.00005562203659792431,
        "seek": 59276,
        "start": 598.08,
        "temperature": 0,
        "text": " So whatever the command is, I can look up",
        "tokens": [
          50630,
          407,
          2035,
          264,
          5622,
          307,
          11,
          286,
          393,
          574,
          493,
          50764
        ]
      },
      {
        "avg_logprob": -0.20759572480854235,
        "compression_ratio": 1.8691588785046729,
        "end": 605.16,
        "id": 224,
        "no_speech_prob": 0.00005562203659792431,
        "seek": 59276,
        "start": 600.76,
        "temperature": 0,
        "text": " the function associated with it in that object",
        "tokens": [
          50764,
          264,
          2445,
          6615,
          365,
          309,
          294,
          300,
          2657,
          50984
        ]
      },
      {
        "avg_logprob": -0.20759572480854235,
        "compression_ratio": 1.8691588785046729,
        "end": 609.12,
        "id": 225,
        "no_speech_prob": 0.00005562203659792431,
        "seek": 59276,
        "start": 605.16,
        "temperature": 0,
        "text": " and call that function with the tokens, which",
        "tokens": [
          50984,
          293,
          818,
          300,
          2445,
          365,
          264,
          22667,
          11,
          597,
          51182
        ]
      },
      {
        "avg_logprob": -0.20759572480854235,
        "compression_ratio": 1.8691588785046729,
        "end": 609.8,
        "id": 226,
        "no_speech_prob": 0.00005562203659792431,
        "seek": 59276,
        "start": 609.12,
        "temperature": 0,
        "text": " are the arguments.",
        "tokens": [
          51182,
          366,
          264,
          12869,
          13,
          51216
        ]
      },
      {
        "avg_logprob": -0.20759572480854235,
        "compression_ratio": 1.8691588785046729,
        "end": 612.6,
        "id": 227,
        "no_speech_prob": 0.00005562203659792431,
        "seek": 59276,
        "start": 609.8,
        "temperature": 0,
        "text": " Oh, boy, doesn't this look terrifying?",
        "tokens": [
          51216,
          876,
          11,
          3237,
          11,
          1177,
          380,
          341,
          574,
          18106,
          30,
          51356
        ]
      },
      {
        "avg_logprob": -0.20759572480854235,
        "compression_ratio": 1.8691588785046729,
        "end": 613.96,
        "id": 228,
        "no_speech_prob": 0.00005562203659792431,
        "seek": 59276,
        "start": 612.6,
        "temperature": 0,
        "text": " Let's think about it this way.",
        "tokens": [
          51356,
          961,
          311,
          519,
          466,
          309,
          341,
          636,
          13,
          51424
        ]
      },
      {
        "avg_logprob": -0.20759572480854235,
        "compression_ratio": 1.8691588785046729,
        "end": 617.6,
        "id": 229,
        "no_speech_prob": 0.00005562203659792431,
        "seek": 59276,
        "start": 613.96,
        "temperature": 0,
        "text": " If I had just said choo-choo tokens",
        "tokens": [
          51424,
          759,
          286,
          632,
          445,
          848,
          1586,
          78,
          12,
          339,
          1986,
          22667,
          51606
        ]
      },
      {
        "avg_logprob": -0.20759572480854235,
        "compression_ratio": 1.8691588785046729,
        "end": 622.3199999999999,
        "id": 230,
        "no_speech_prob": 0.00005562203659792431,
        "seek": 59276,
        "start": 617.6,
        "temperature": 0,
        "text": " and written some function like this,",
        "tokens": [
          51606,
          293,
          3720,
          512,
          2445,
          411,
          341,
          11,
          51842
        ]
      },
      {
        "avg_logprob": -0.17524677717766793,
        "compression_ratio": 1.8479087452471483,
        "end": 623.88,
        "id": 231,
        "no_speech_prob": 0.000060141479480080307,
        "seek": 62232,
        "start": 622.32,
        "temperature": 0,
        "text": " this would probably make sense to you.",
        "tokens": [
          50364,
          341,
          576,
          1391,
          652,
          2020,
          281,
          291,
          13,
          50442
        ]
      },
      {
        "avg_logprob": -0.17524677717766793,
        "compression_ratio": 1.8479087452471483,
        "end": 625.48,
        "id": 232,
        "no_speech_prob": 0.000060141479480080307,
        "seek": 62232,
        "start": 623.88,
        "temperature": 0,
        "text": " I'm calling the function choo-choo",
        "tokens": [
          50442,
          286,
          478,
          5141,
          264,
          2445,
          1586,
          78,
          12,
          339,
          1986,
          50522
        ]
      },
      {
        "avg_logprob": -0.17524677717766793,
        "compression_ratio": 1.8479087452471483,
        "end": 627.44,
        "id": 233,
        "no_speech_prob": 0.000060141479480080307,
        "seek": 62232,
        "start": 625.48,
        "temperature": 0,
        "text": " and passing it the tokens.",
        "tokens": [
          50522,
          293,
          8437,
          309,
          264,
          22667,
          13,
          50620
        ]
      },
      {
        "avg_logprob": -0.17524677717766793,
        "compression_ratio": 1.8479087452471483,
        "end": 629.1600000000001,
        "id": 234,
        "no_speech_prob": 0.000060141479480080307,
        "seek": 62232,
        "start": 627.44,
        "temperature": 0,
        "text": " What am I doing here?",
        "tokens": [
          50620,
          708,
          669,
          286,
          884,
          510,
          30,
          50706
        ]
      },
      {
        "avg_logprob": -0.17524677717766793,
        "compression_ratio": 1.8479087452471483,
        "end": 631.2,
        "id": 235,
        "no_speech_prob": 0.000060141479480080307,
        "seek": 62232,
        "start": 629.1600000000001,
        "temperature": 0,
        "text": " I am doing exactly the same thing,",
        "tokens": [
          50706,
          286,
          669,
          884,
          2293,
          264,
          912,
          551,
          11,
          50808
        ]
      },
      {
        "avg_logprob": -0.17524677717766793,
        "compression_ratio": 1.8479087452471483,
        "end": 633.44,
        "id": 236,
        "no_speech_prob": 0.000060141479480080307,
        "seek": 62232,
        "start": 631.2,
        "temperature": 0,
        "text": " only the function isn't just called choo-choo.",
        "tokens": [
          50808,
          787,
          264,
          2445,
          1943,
          380,
          445,
          1219,
          1586,
          78,
          12,
          339,
          1986,
          13,
          50920
        ]
      },
      {
        "avg_logprob": -0.17524677717766793,
        "compression_ratio": 1.8479087452471483,
        "end": 636.08,
        "id": 237,
        "no_speech_prob": 0.000060141479480080307,
        "seek": 62232,
        "start": 633.44,
        "temperature": 0,
        "text": " It's called choo-choo inside of an object called commands.",
        "tokens": [
          50920,
          467,
          311,
          1219,
          1586,
          78,
          12,
          339,
          1986,
          1854,
          295,
          364,
          2657,
          1219,
          16901,
          13,
          51052
        ]
      },
      {
        "avg_logprob": -0.17524677717766793,
        "compression_ratio": 1.8479087452471483,
        "end": 639.8000000000001,
        "id": 238,
        "no_speech_prob": 0.000060141479480080307,
        "seek": 62232,
        "start": 636.08,
        "temperature": 0,
        "text": " And the term, the lookup term choo-choo, that property name,",
        "tokens": [
          51052,
          400,
          264,
          1433,
          11,
          264,
          574,
          1010,
          1433,
          1586,
          78,
          12,
          339,
          1986,
          11,
          300,
          4707,
          1315,
          11,
          51238
        ]
      },
      {
        "avg_logprob": -0.17524677717766793,
        "compression_ratio": 1.8479087452471483,
        "end": 642.4000000000001,
        "id": 239,
        "no_speech_prob": 0.000060141479480080307,
        "seek": 62232,
        "start": 639.8000000000001,
        "temperature": 0,
        "text": " is inside of the variable called commands.",
        "tokens": [
          51238,
          307,
          1854,
          295,
          264,
          7006,
          1219,
          16901,
          13,
          51368
        ]
      },
      {
        "avg_logprob": -0.17524677717766793,
        "compression_ratio": 1.8479087452471483,
        "end": 647.8000000000001,
        "id": 240,
        "no_speech_prob": 0.000060141479480080307,
        "seek": 62232,
        "start": 642.4000000000001,
        "temperature": 0,
        "text": " So this is the equivalent of saying commands.choo-choo",
        "tokens": [
          51368,
          407,
          341,
          307,
          264,
          10344,
          295,
          1566,
          16901,
          13,
          339,
          1986,
          12,
          339,
          1986,
          51638
        ]
      },
      {
        "avg_logprob": -0.17524677717766793,
        "compression_ratio": 1.8479087452471483,
        "end": 648.96,
        "id": 241,
        "no_speech_prob": 0.000060141479480080307,
        "seek": 62232,
        "start": 647.8000000000001,
        "temperature": 0,
        "text": " tokens.",
        "tokens": [
          51638,
          22667,
          13,
          51696
        ]
      },
      {
        "avg_logprob": -0.17524677717766793,
        "compression_ratio": 1.8479087452471483,
        "end": 652.24,
        "id": 242,
        "no_speech_prob": 0.000060141479480080307,
        "seek": 62232,
        "start": 648.96,
        "temperature": 0,
        "text": " However, I can't do that because command is a variable.",
        "tokens": [
          51696,
          2908,
          11,
          286,
          393,
          380,
          360,
          300,
          570,
          5622,
          307,
          257,
          7006,
          13,
          51860
        ]
      },
      {
        "avg_logprob": -0.2083456293741862,
        "compression_ratio": 1.6845425867507886,
        "end": 654.5600000000001,
        "id": 243,
        "no_speech_prob": 0.00006205042882356793,
        "seek": 65224,
        "start": 652.24,
        "temperature": 0,
        "text": " I've got to pass it in with the square brackets.",
        "tokens": [
          50364,
          286,
          600,
          658,
          281,
          1320,
          309,
          294,
          365,
          264,
          3732,
          26179,
          13,
          50480
        ]
      },
      {
        "avg_logprob": -0.2083456293741862,
        "compression_ratio": 1.6845425867507886,
        "end": 656.32,
        "id": 244,
        "no_speech_prob": 0.00006205042882356793,
        "seek": 65224,
        "start": 654.5600000000001,
        "temperature": 0,
        "text": " So you might have to pause the video",
        "tokens": [
          50480,
          407,
          291,
          1062,
          362,
          281,
          10465,
          264,
          960,
          50568
        ]
      },
      {
        "avg_logprob": -0.2083456293741862,
        "compression_ratio": 1.6845425867507886,
        "end": 657.6800000000001,
        "id": 245,
        "no_speech_prob": 0.00006205042882356793,
        "seek": 65224,
        "start": 656.32,
        "temperature": 0,
        "text": " and think about this for a bit.",
        "tokens": [
          50568,
          293,
          519,
          466,
          341,
          337,
          257,
          857,
          13,
          50636
        ]
      },
      {
        "avg_logprob": -0.2083456293741862,
        "compression_ratio": 1.6845425867507886,
        "end": 659.6800000000001,
        "id": 246,
        "no_speech_prob": 0.00006205042882356793,
        "seek": 65224,
        "start": 657.6800000000001,
        "temperature": 0,
        "text": " But hopefully, you're following along with me.",
        "tokens": [
          50636,
          583,
          4696,
          11,
          291,
          434,
          3480,
          2051,
          365,
          385,
          13,
          50736
        ]
      },
      {
        "avg_logprob": -0.2083456293741862,
        "compression_ratio": 1.6845425867507886,
        "end": 661.6,
        "id": 247,
        "no_speech_prob": 0.00006205042882356793,
        "seek": 65224,
        "start": 659.6800000000001,
        "temperature": 0,
        "text": " And please ask your questions in the comments",
        "tokens": [
          50736,
          400,
          1767,
          1029,
          428,
          1651,
          294,
          264,
          3053,
          50832
        ]
      },
      {
        "avg_logprob": -0.2083456293741862,
        "compression_ratio": 1.6845425867507886,
        "end": 663,
        "id": 248,
        "no_speech_prob": 0.00006205042882356793,
        "seek": 65224,
        "start": 661.6,
        "temperature": 0,
        "text": " if this is confusing.",
        "tokens": [
          50832,
          498,
          341,
          307,
          13181,
          13,
          50902
        ]
      },
      {
        "avg_logprob": -0.2083456293741862,
        "compression_ratio": 1.6845425867507886,
        "end": 665.48,
        "id": 249,
        "no_speech_prob": 0.00006205042882356793,
        "seek": 65224,
        "start": 663,
        "temperature": 0,
        "text": " So let's build these out a little bit more.",
        "tokens": [
          50902,
          407,
          718,
          311,
          1322,
          613,
          484,
          257,
          707,
          857,
          544,
          13,
          51026
        ]
      },
      {
        "avg_logprob": -0.2083456293741862,
        "compression_ratio": 1.6845425867507886,
        "end": 671.64,
        "id": 250,
        "no_speech_prob": 0.00006205042882356793,
        "seek": 65224,
        "start": 669.08,
        "temperature": 0,
        "text": " And let's just test to see if this system works.",
        "tokens": [
          51206,
          400,
          718,
          311,
          445,
          1500,
          281,
          536,
          498,
          341,
          1185,
          1985,
          13,
          51334
        ]
      },
      {
        "avg_logprob": -0.2083456293741862,
        "compression_ratio": 1.6845425867507886,
        "end": 673.84,
        "id": 251,
        "no_speech_prob": 0.00006205042882356793,
        "seek": 65224,
        "start": 671.64,
        "temperature": 0,
        "text": " Whatever the command that comes in is,",
        "tokens": [
          51334,
          8541,
          264,
          5622,
          300,
          1487,
          294,
          307,
          11,
          51444
        ]
      },
      {
        "avg_logprob": -0.2083456293741862,
        "compression_ratio": 1.6845425867507886,
        "end": 675.52,
        "id": 252,
        "no_speech_prob": 0.00006205042882356793,
        "seek": 65224,
        "start": 673.84,
        "temperature": 0,
        "text": " I should see a console log in the server.",
        "tokens": [
          51444,
          286,
          820,
          536,
          257,
          11076,
          3565,
          294,
          264,
          7154,
          13,
          51528
        ]
      },
      {
        "avg_logprob": -0.2083456293741862,
        "compression_ratio": 1.6845425867507886,
        "end": 677.12,
        "id": 253,
        "no_speech_prob": 0.00006205042882356793,
        "seek": 65224,
        "start": 675.52,
        "temperature": 0,
        "text": " Remember, ultimately, where I'm going",
        "tokens": [
          51528,
          5459,
          11,
          6284,
          11,
          689,
          286,
          478,
          516,
          51608
        ]
      },
      {
        "avg_logprob": -0.2083456293741862,
        "compression_ratio": 1.6845425867507886,
        "end": 679.6,
        "id": 254,
        "no_speech_prob": 0.00006205042882356793,
        "seek": 65224,
        "start": 677.12,
        "temperature": 0,
        "text": " is I've got to execute the code that's in another JavaScript",
        "tokens": [
          51608,
          307,
          286,
          600,
          658,
          281,
          14483,
          264,
          3089,
          300,
          311,
          294,
          1071,
          15778,
          51732
        ]
      },
      {
        "avg_logprob": -0.2083456293741862,
        "compression_ratio": 1.6845425867507886,
        "end": 681.04,
        "id": 255,
        "no_speech_prob": 0.00006205042882356793,
        "seek": 65224,
        "start": 679.6,
        "temperature": 0,
        "text": " file, but I'm not there yet.",
        "tokens": [
          51732,
          3991,
          11,
          457,
          286,
          478,
          406,
          456,
          1939,
          13,
          51804
        ]
      },
      {
        "avg_logprob": -0.19420130033019586,
        "compression_ratio": 1.7462686567164178,
        "end": 683.64,
        "id": 256,
        "no_speech_prob": 0.00017674443370196968,
        "seek": 68104,
        "start": 681.04,
        "temperature": 0,
        "text": " I just want to have the command come in,",
        "tokens": [
          50364,
          286,
          445,
          528,
          281,
          362,
          264,
          5622,
          808,
          294,
          11,
          50494
        ]
      },
      {
        "avg_logprob": -0.19420130033019586,
        "compression_ratio": 1.7462686567164178,
        "end": 686.5999999999999,
        "id": 257,
        "no_speech_prob": 0.00017674443370196968,
        "seek": 68104,
        "start": 683.64,
        "temperature": 0,
        "text": " look up the function associated with it, and run that function.",
        "tokens": [
          50494,
          574,
          493,
          264,
          2445,
          6615,
          365,
          309,
          11,
          293,
          1190,
          300,
          2445,
          13,
          50642
        ]
      },
      {
        "avg_logprob": -0.19420130033019586,
        "compression_ratio": 1.7462686567164178,
        "end": 688.7199999999999,
        "id": 258,
        "no_speech_prob": 0.00017674443370196968,
        "seek": 68104,
        "start": 686.5999999999999,
        "temperature": 0,
        "text": " And this was extra extraneous code",
        "tokens": [
          50642,
          400,
          341,
          390,
          2857,
          16455,
          15447,
          3089,
          50748
        ]
      },
      {
        "avg_logprob": -0.19420130033019586,
        "compression_ratio": 1.7462686567164178,
        "end": 691.5999999999999,
        "id": 259,
        "no_speech_prob": 0.00017674443370196968,
        "seek": 68104,
        "start": 688.7199999999999,
        "temperature": 0,
        "text": " that I need to make sure I remove.",
        "tokens": [
          50748,
          300,
          286,
          643,
          281,
          652,
          988,
          286,
          4159,
          13,
          50892
        ]
      },
      {
        "avg_logprob": -0.19420130033019586,
        "compression_ratio": 1.7462686567164178,
        "end": 692.56,
        "id": 260,
        "no_speech_prob": 0.00017674443370196968,
        "seek": 68104,
        "start": 691.5999999999999,
        "temperature": 0,
        "text": " Back to Discord.",
        "tokens": [
          50892,
          5833,
          281,
          32623,
          13,
          50940
        ]
      },
      {
        "avg_logprob": -0.19420130033019586,
        "compression_ratio": 1.7462686567164178,
        "end": 694,
        "id": 261,
        "no_speech_prob": 0.00017674443370196968,
        "seek": 68104,
        "start": 692.56,
        "temperature": 0,
        "text": " I shouldn't see anything here now,",
        "tokens": [
          50940,
          286,
          4659,
          380,
          536,
          1340,
          510,
          586,
          11,
          51012
        ]
      },
      {
        "avg_logprob": -0.19420130033019586,
        "compression_ratio": 1.7462686567164178,
        "end": 697.4399999999999,
        "id": 262,
        "no_speech_prob": 0.00017674443370196968,
        "seek": 68104,
        "start": 694,
        "temperature": 0,
        "text": " but I should see gif and choo-choo.",
        "tokens": [
          51012,
          457,
          286,
          820,
          536,
          290,
          351,
          293,
          1586,
          78,
          12,
          339,
          1986,
          13,
          51184
        ]
      },
      {
        "avg_logprob": -0.19420130033019586,
        "compression_ratio": 1.7462686567164178,
        "end": 700.04,
        "id": 263,
        "no_speech_prob": 0.00017674443370196968,
        "seek": 68104,
        "start": 697.4399999999999,
        "temperature": 0,
        "text": " And then if I go back to the server, we see gif and choo-choo.",
        "tokens": [
          51184,
          400,
          550,
          498,
          286,
          352,
          646,
          281,
          264,
          7154,
          11,
          321,
          536,
          290,
          351,
          293,
          1586,
          78,
          12,
          339,
          1986,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.19420130033019586,
        "compression_ratio": 1.7462686567164178,
        "end": 702.1999999999999,
        "id": 264,
        "no_speech_prob": 0.00017674443370196968,
        "seek": 68104,
        "start": 700.04,
        "temperature": 0,
        "text": " So those functions are being called correctly.",
        "tokens": [
          51314,
          407,
          729,
          6828,
          366,
          885,
          1219,
          8944,
          13,
          51422
        ]
      },
      {
        "avg_logprob": -0.19420130033019586,
        "compression_ratio": 1.7462686567164178,
        "end": 703.16,
        "id": 265,
        "no_speech_prob": 0.00017674443370196968,
        "seek": 68104,
        "start": 702.1999999999999,
        "temperature": 0,
        "text": " All right.",
        "tokens": [
          51422,
          1057,
          558,
          13,
          51470
        ]
      },
      {
        "avg_logprob": -0.19420130033019586,
        "compression_ratio": 1.7462686567164178,
        "end": 706.3199999999999,
        "id": 266,
        "no_speech_prob": 0.00017674443370196968,
        "seek": 68104,
        "start": 703.16,
        "temperature": 0,
        "text": " And just as a reminder, this extra if statement up here",
        "tokens": [
          51470,
          400,
          445,
          382,
          257,
          13548,
          11,
          341,
          2857,
          498,
          5629,
          493,
          510,
          51628
        ]
      },
      {
        "avg_logprob": -0.19420130033019586,
        "compression_ratio": 1.7462686567164178,
        "end": 708.36,
        "id": 267,
        "no_speech_prob": 0.00017674443370196968,
        "seek": 68104,
        "start": 706.3199999999999,
        "temperature": 0,
        "text": " is just because I want this.",
        "tokens": [
          51628,
          307,
          445,
          570,
          286,
          528,
          341,
          13,
          51730
        ]
      },
      {
        "avg_logprob": -0.22306416829427084,
        "compression_ratio": 1.6159695817490494,
        "end": 711.6800000000001,
        "id": 268,
        "no_speech_prob": 0.005060289986431599,
        "seek": 70836,
        "start": 708.36,
        "temperature": 0,
        "text": " I'm testing this bot only in one particular channel.",
        "tokens": [
          50364,
          286,
          478,
          4997,
          341,
          10592,
          787,
          294,
          472,
          1729,
          2269,
          13,
          50530
        ]
      },
      {
        "avg_logprob": -0.22306416829427084,
        "compression_ratio": 1.6159695817490494,
        "end": 713.36,
        "id": 269,
        "no_speech_prob": 0.005060289986431599,
        "seek": 70836,
        "start": 711.6800000000001,
        "temperature": 0,
        "text": " So this might not at all be necessary",
        "tokens": [
          50530,
          407,
          341,
          1062,
          406,
          412,
          439,
          312,
          4818,
          50614
        ]
      },
      {
        "avg_logprob": -0.22306416829427084,
        "compression_ratio": 1.6159695817490494,
        "end": 714.24,
        "id": 270,
        "no_speech_prob": 0.005060289986431599,
        "seek": 70836,
        "start": 713.36,
        "temperature": 0,
        "text": " for what you're doing.",
        "tokens": [
          50614,
          337,
          437,
          291,
          434,
          884,
          13,
          50658
        ]
      },
      {
        "avg_logprob": -0.22306416829427084,
        "compression_ratio": 1.6159695817490494,
        "end": 716.08,
        "id": 271,
        "no_speech_prob": 0.005060289986431599,
        "seek": 70836,
        "start": 714.24,
        "temperature": 0,
        "text": " If I wanted my bot to participate",
        "tokens": [
          50658,
          759,
          286,
          1415,
          452,
          10592,
          281,
          8197,
          50750
        ]
      },
      {
        "avg_logprob": -0.22306416829427084,
        "compression_ratio": 1.6159695817490494,
        "end": 717.92,
        "id": 272,
        "no_speech_prob": 0.005060289986431599,
        "seek": 70836,
        "start": 716.08,
        "temperature": 0,
        "text": " in all the channels of a particular server,",
        "tokens": [
          50750,
          294,
          439,
          264,
          9235,
          295,
          257,
          1729,
          7154,
          11,
          50842
        ]
      },
      {
        "avg_logprob": -0.22306416829427084,
        "compression_ratio": 1.6159695817490494,
        "end": 720.04,
        "id": 273,
        "no_speech_prob": 0.005060289986431599,
        "seek": 70836,
        "start": 717.92,
        "temperature": 0,
        "text": " I certainly wouldn't have this here.",
        "tokens": [
          50842,
          286,
          3297,
          2759,
          380,
          362,
          341,
          510,
          13,
          50948
        ]
      },
      {
        "avg_logprob": -0.22306416829427084,
        "compression_ratio": 1.6159695817490494,
        "end": 720.84,
        "id": 274,
        "no_speech_prob": 0.005060289986431599,
        "seek": 70836,
        "start": 720.04,
        "temperature": 0,
        "text": " OK.",
        "tokens": [
          50948,
          2264,
          13,
          50988
        ]
      },
      {
        "avg_logprob": -0.22306416829427084,
        "compression_ratio": 1.6159695817490494,
        "end": 724.76,
        "id": 275,
        "no_speech_prob": 0.005060289986431599,
        "seek": 70836,
        "start": 720.84,
        "temperature": 0,
        "text": " We are getting close now to the end of this demonstration.",
        "tokens": [
          50988,
          492,
          366,
          1242,
          1998,
          586,
          281,
          264,
          917,
          295,
          341,
          16520,
          13,
          51184
        ]
      },
      {
        "avg_logprob": -0.22306416829427084,
        "compression_ratio": 1.6159695817490494,
        "end": 727.6,
        "id": 276,
        "no_speech_prob": 0.005060289986431599,
        "seek": 70836,
        "start": 724.76,
        "temperature": 0,
        "text": " The big next step is very exciting.",
        "tokens": [
          51184,
          440,
          955,
          958,
          1823,
          307,
          588,
          4670,
          13,
          51326
        ]
      },
      {
        "avg_logprob": -0.22306416829427084,
        "compression_ratio": 1.6159695817490494,
        "end": 731.08,
        "id": 277,
        "no_speech_prob": 0.005060289986431599,
        "seek": 70836,
        "start": 727.6,
        "temperature": 0,
        "text": " Instead of defining the function right here,",
        "tokens": [
          51326,
          7156,
          295,
          17827,
          264,
          2445,
          558,
          510,
          11,
          51500
        ]
      },
      {
        "avg_logprob": -0.22306416829427084,
        "compression_ratio": 1.6159695817490494,
        "end": 735.16,
        "id": 278,
        "no_speech_prob": 0.005060289986431599,
        "seek": 70836,
        "start": 731.08,
        "temperature": 0,
        "text": " I want to pull it from that other choo-choo.js file.",
        "tokens": [
          51500,
          286,
          528,
          281,
          2235,
          309,
          490,
          300,
          661,
          1586,
          78,
          12,
          339,
          1986,
          13,
          25530,
          3991,
          13,
          51704
        ]
      },
      {
        "avg_logprob": -0.18518742975198998,
        "compression_ratio": 1.5849056603773586,
        "end": 739.52,
        "id": 279,
        "no_speech_prob": 0.00008092747157206759,
        "seek": 73516,
        "start": 735.16,
        "temperature": 0,
        "text": " So first, I need to add module.exports to choo-choo.js.",
        "tokens": [
          50364,
          407,
          700,
          11,
          286,
          643,
          281,
          909,
          10088,
          13,
          3121,
          17845,
          281,
          1586,
          78,
          12,
          339,
          1986,
          13,
          25530,
          13,
          50582
        ]
      },
      {
        "avg_logprob": -0.18518742975198998,
        "compression_ratio": 1.5849056603773586,
        "end": 744.9599999999999,
        "id": 280,
        "no_speech_prob": 0.00008092747157206759,
        "seek": 73516,
        "start": 743.6,
        "temperature": 0,
        "text": " And it's as easy as this.",
        "tokens": [
          50786,
          400,
          309,
          311,
          382,
          1858,
          382,
          341,
          13,
          50854
        ]
      },
      {
        "avg_logprob": -0.18518742975198998,
        "compression_ratio": 1.5849056603773586,
        "end": 747.28,
        "id": 281,
        "no_speech_prob": 0.00008092747157206759,
        "seek": 73516,
        "start": 744.9599999999999,
        "temperature": 0,
        "text": " Now, I'm not using the arguments in this.",
        "tokens": [
          50854,
          823,
          11,
          286,
          478,
          406,
          1228,
          264,
          12869,
          294,
          341,
          13,
          50970
        ]
      },
      {
        "avg_logprob": -0.18518742975198998,
        "compression_ratio": 1.5849056603773586,
        "end": 748.52,
        "id": 282,
        "no_speech_prob": 0.00008092747157206759,
        "seek": 73516,
        "start": 747.28,
        "temperature": 0,
        "text": " It's just a random reply.",
        "tokens": [
          50970,
          467,
          311,
          445,
          257,
          4974,
          16972,
          13,
          51032
        ]
      },
      {
        "avg_logprob": -0.18518742975198998,
        "compression_ratio": 1.5849056603773586,
        "end": 751.68,
        "id": 283,
        "no_speech_prob": 0.00008092747157206759,
        "seek": 73516,
        "start": 748.52,
        "temperature": 0,
        "text": " And of course, I need to get, I keep moving this around,",
        "tokens": [
          51032,
          400,
          295,
          1164,
          11,
          286,
          643,
          281,
          483,
          11,
          286,
          1066,
          2684,
          341,
          926,
          11,
          51190
        ]
      },
      {
        "avg_logprob": -0.18518742975198998,
        "compression_ratio": 1.5849056603773586,
        "end": 755.24,
        "id": 284,
        "no_speech_prob": 0.00008092747157206759,
        "seek": 73516,
        "start": 751.68,
        "temperature": 0,
        "text": " but I need to get these replies.",
        "tokens": [
          51190,
          457,
          286,
          643,
          281,
          483,
          613,
          42289,
          13,
          51368
        ]
      },
      {
        "avg_logprob": -0.18518742975198998,
        "compression_ratio": 1.5849056603773586,
        "end": 757.76,
        "id": 285,
        "no_speech_prob": 0.00008092747157206759,
        "seek": 73516,
        "start": 755.24,
        "temperature": 0,
        "text": " These are part of this particular command.",
        "tokens": [
          51368,
          1981,
          366,
          644,
          295,
          341,
          1729,
          5622,
          13,
          51494
        ]
      },
      {
        "avg_logprob": -0.18518742975198998,
        "compression_ratio": 1.5849056603773586,
        "end": 761.0799999999999,
        "id": 286,
        "no_speech_prob": 0.00008092747157206759,
        "seek": 73516,
        "start": 757.76,
        "temperature": 0,
        "text": " I'm noticing another major issue that I forgot about.",
        "tokens": [
          51494,
          286,
          478,
          21814,
          1071,
          2563,
          2734,
          300,
          286,
          5298,
          466,
          13,
          51660
        ]
      },
      {
        "avg_logprob": -0.22575213862400428,
        "compression_ratio": 1.7586206896551724,
        "end": 765.96,
        "id": 287,
        "no_speech_prob": 0.00009610224515199661,
        "seek": 76108,
        "start": 761.08,
        "temperature": 0,
        "text": " The reply is being sent to the channel associated",
        "tokens": [
          50364,
          440,
          16972,
          307,
          885,
          2279,
          281,
          264,
          2269,
          6615,
          50608
        ]
      },
      {
        "avg_logprob": -0.22575213862400428,
        "compression_ratio": 1.7586206896551724,
        "end": 767.24,
        "id": 288,
        "no_speech_prob": 0.00009610224515199661,
        "seek": 76108,
        "start": 765.96,
        "temperature": 0,
        "text": " with the original message.",
        "tokens": [
          50608,
          365,
          264,
          3380,
          3636,
          13,
          50672
        ]
      },
      {
        "avg_logprob": -0.22575213862400428,
        "compression_ratio": 1.7586206896551724,
        "end": 771.2,
        "id": 289,
        "no_speech_prob": 0.00009610224515199661,
        "seek": 76108,
        "start": 767.24,
        "temperature": 0,
        "text": " And I don't have access to that message variable here anymore.",
        "tokens": [
          50672,
          400,
          286,
          500,
          380,
          362,
          2105,
          281,
          300,
          3636,
          7006,
          510,
          3602,
          13,
          50870
        ]
      },
      {
        "avg_logprob": -0.22575213862400428,
        "compression_ratio": 1.7586206896551724,
        "end": 774.5200000000001,
        "id": 290,
        "no_speech_prob": 0.00009610224515199661,
        "seek": 76108,
        "start": 771.2,
        "temperature": 0,
        "text": " So I think it would be important for the command handler",
        "tokens": [
          50870,
          407,
          286,
          519,
          309,
          576,
          312,
          1021,
          337,
          264,
          5622,
          41967,
          51036
        ]
      },
      {
        "avg_logprob": -0.22575213862400428,
        "compression_ratio": 1.7586206896551724,
        "end": 777.2,
        "id": 291,
        "no_speech_prob": 0.00009610224515199661,
        "seek": 76108,
        "start": 774.5200000000001,
        "temperature": 0,
        "text": " to also pass that in.",
        "tokens": [
          51036,
          281,
          611,
          1320,
          300,
          294,
          13,
          51170
        ]
      },
      {
        "avg_logprob": -0.22575213862400428,
        "compression_ratio": 1.7586206896551724,
        "end": 781.44,
        "id": 292,
        "no_speech_prob": 0.00009610224515199661,
        "seek": 76108,
        "start": 777.2,
        "temperature": 0,
        "text": " So not only send the tokens, the actual tokens,",
        "tokens": [
          51170,
          407,
          406,
          787,
          2845,
          264,
          22667,
          11,
          264,
          3539,
          22667,
          11,
          51382
        ]
      },
      {
        "avg_logprob": -0.22575213862400428,
        "compression_ratio": 1.7586206896551724,
        "end": 783.2800000000001,
        "id": 293,
        "no_speech_prob": 0.00009610224515199661,
        "seek": 76108,
        "start": 781.44,
        "temperature": 0,
        "text": " which are the arguments, but send,",
        "tokens": [
          51382,
          597,
          366,
          264,
          12869,
          11,
          457,
          2845,
          11,
          51474
        ]
      },
      {
        "avg_logprob": -0.22575213862400428,
        "compression_ratio": 1.7586206896551724,
        "end": 785.88,
        "id": 294,
        "no_speech_prob": 0.00009610224515199661,
        "seek": 76108,
        "start": 783.2800000000001,
        "temperature": 0,
        "text": " also pass along that additional message object,",
        "tokens": [
          51474,
          611,
          1320,
          2051,
          300,
          4497,
          3636,
          2657,
          11,
          51604
        ]
      },
      {
        "avg_logprob": -0.22575213862400428,
        "compression_ratio": 1.7586206896551724,
        "end": 789.5600000000001,
        "id": 295,
        "no_speech_prob": 0.00009610224515199661,
        "seek": 76108,
        "start": 785.88,
        "temperature": 0,
        "text": " which has all of the metadata associated with the message.",
        "tokens": [
          51604,
          597,
          575,
          439,
          295,
          264,
          26603,
          6615,
          365,
          264,
          3636,
          13,
          51788
        ]
      },
      {
        "avg_logprob": -0.26309477977263623,
        "compression_ratio": 1.5232067510548524,
        "end": 792.3599999999999,
        "id": 296,
        "no_speech_prob": 0.00008481095574097708,
        "seek": 78956,
        "start": 789.56,
        "temperature": 0,
        "text": " So adding that as another property here.",
        "tokens": [
          50364,
          407,
          5127,
          300,
          382,
          1071,
          4707,
          510,
          13,
          50504
        ]
      },
      {
        "avg_logprob": -0.26309477977263623,
        "compression_ratio": 1.5232067510548524,
        "end": 793.52,
        "id": 297,
        "no_speech_prob": 0.00008481095574097708,
        "seek": 78956,
        "start": 792.3599999999999,
        "temperature": 0,
        "text": " Let's see.",
        "tokens": [
          50504,
          961,
          311,
          536,
          13,
          50562
        ]
      },
      {
        "avg_logprob": -0.26309477977263623,
        "compression_ratio": 1.5232067510548524,
        "end": 797.4799999999999,
        "id": 298,
        "no_speech_prob": 0.00008481095574097708,
        "seek": 78956,
        "start": 793.52,
        "temperature": 0,
        "text": " Before I go on to the GIF, let's just see if this works now.",
        "tokens": [
          50562,
          4546,
          286,
          352,
          322,
          281,
          264,
          460,
          12775,
          11,
          718,
          311,
          445,
          536,
          498,
          341,
          1985,
          586,
          13,
          50760
        ]
      },
      {
        "avg_logprob": -0.26309477977263623,
        "compression_ratio": 1.5232067510548524,
        "end": 798.1999999999999,
        "id": 299,
        "no_speech_prob": 0.00008481095574097708,
        "seek": 78956,
        "start": 797.4799999999999,
        "temperature": 0,
        "text": " Oh, no, it doesn't.",
        "tokens": [
          50760,
          876,
          11,
          572,
          11,
          309,
          1177,
          380,
          13,
          50796
        ]
      },
      {
        "avg_logprob": -0.26309477977263623,
        "compression_ratio": 1.5232067510548524,
        "end": 798.6999999999999,
        "id": 300,
        "no_speech_prob": 0.00008481095574097708,
        "seek": 78956,
        "start": 798.1999999999999,
        "temperature": 0,
        "text": " It won't.",
        "tokens": [
          50796,
          467,
          1582,
          380,
          13,
          50821
        ]
      },
      {
        "avg_logprob": -0.26309477977263623,
        "compression_ratio": 1.5232067510548524,
        "end": 799.1999999999999,
        "id": 301,
        "no_speech_prob": 0.00008481095574097708,
        "seek": 78956,
        "start": 798.6999999999999,
        "temperature": 0,
        "text": " It won't.",
        "tokens": [
          50821,
          467,
          1582,
          380,
          13,
          50846
        ]
      },
      {
        "avg_logprob": -0.26309477977263623,
        "compression_ratio": 1.5232067510548524,
        "end": 799.88,
        "id": 302,
        "no_speech_prob": 0.00008481095574097708,
        "seek": 78956,
        "start": 799.1999999999999,
        "temperature": 0,
        "text": " Why not?",
        "tokens": [
          50846,
          1545,
          406,
          30,
          50880
        ]
      },
      {
        "avg_logprob": -0.26309477977263623,
        "compression_ratio": 1.5232067510548524,
        "end": 805.88,
        "id": 303,
        "no_speech_prob": 0.00008481095574097708,
        "seek": 78956,
        "start": 799.88,
        "temperature": 0,
        "text": " I need to replace this function here with the function",
        "tokens": [
          50880,
          286,
          643,
          281,
          7406,
          341,
          2445,
          510,
          365,
          264,
          2445,
          51180
        ]
      },
      {
        "avg_logprob": -0.26309477977263623,
        "compression_ratio": 1.5232067510548524,
        "end": 807.56,
        "id": 304,
        "no_speech_prob": 0.00008481095574097708,
        "seek": 78956,
        "start": 805.88,
        "temperature": 0,
        "text": " that I'm getting from choo-choo itself.",
        "tokens": [
          51180,
          300,
          286,
          478,
          1242,
          490,
          1586,
          78,
          12,
          339,
          1986,
          2564,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.26309477977263623,
        "compression_ratio": 1.5232067510548524,
        "end": 814.76,
        "id": 305,
        "no_speech_prob": 0.00008481095574097708,
        "seek": 78956,
        "start": 812.3599999999999,
        "temperature": 0,
        "text": " Now, this is kind of silly, ultimately.",
        "tokens": [
          51504,
          823,
          11,
          341,
          307,
          733,
          295,
          11774,
          11,
          6284,
          13,
          51624
        ]
      },
      {
        "avg_logprob": -0.26309477977263623,
        "compression_ratio": 1.5232067510548524,
        "end": 819.1199999999999,
        "id": 306,
        "no_speech_prob": 0.00008481095574097708,
        "seek": 78956,
        "start": 814.76,
        "temperature": 0,
        "text": " When I have a JavaScript object where the property and the value",
        "tokens": [
          51624,
          1133,
          286,
          362,
          257,
          15778,
          2657,
          689,
          264,
          4707,
          293,
          264,
          2158,
          51842
        ]
      },
      {
        "avg_logprob": -0.2536701886159069,
        "compression_ratio": 1.4485981308411215,
        "end": 822.6,
        "id": 307,
        "no_speech_prob": 0.00026530129252932966,
        "seek": 81912,
        "start": 819.16,
        "temperature": 0,
        "text": " have the same name, I can use, what is that called again?",
        "tokens": [
          50366,
          362,
          264,
          912,
          1315,
          11,
          286,
          393,
          764,
          11,
          437,
          307,
          300,
          1219,
          797,
          30,
          50538
        ]
      },
      {
        "avg_logprob": -0.2536701886159069,
        "compression_ratio": 1.4485981308411215,
        "end": 825.8,
        "id": 308,
        "no_speech_prob": 0.00026530129252932966,
        "seek": 81912,
        "start": 822.6,
        "temperature": 0,
        "text": " Enhanced object literals.",
        "tokens": [
          50538,
          2193,
          3451,
          1232,
          2657,
          2733,
          1124,
          13,
          50698
        ]
      },
      {
        "avg_logprob": -0.2536701886159069,
        "compression_ratio": 1.4485981308411215,
        "end": 828.6,
        "id": 309,
        "no_speech_prob": 0.00026530129252932966,
        "seek": 81912,
        "start": 825.8,
        "temperature": 0,
        "text": " I'm going to leave the GIF out right now.",
        "tokens": [
          50698,
          286,
          478,
          516,
          281,
          1856,
          264,
          460,
          12775,
          484,
          558,
          586,
          13,
          50838
        ]
      },
      {
        "avg_logprob": -0.2536701886159069,
        "compression_ratio": 1.4485981308411215,
        "end": 830.92,
        "id": 310,
        "no_speech_prob": 0.00026530129252932966,
        "seek": 81912,
        "start": 828.6,
        "temperature": 0,
        "text": " So essentially, this is my list of commands.",
        "tokens": [
          50838,
          407,
          4476,
          11,
          341,
          307,
          452,
          1329,
          295,
          16901,
          13,
          50954
        ]
      },
      {
        "avg_logprob": -0.2536701886159069,
        "compression_ratio": 1.4485981308411215,
        "end": 834.16,
        "id": 311,
        "no_speech_prob": 0.00026530129252932966,
        "seek": 81912,
        "start": 830.92,
        "temperature": 0,
        "text": " The function choo-choo is right in there.",
        "tokens": [
          50954,
          440,
          2445,
          1586,
          78,
          12,
          339,
          1986,
          307,
          558,
          294,
          456,
          13,
          51116
        ]
      },
      {
        "avg_logprob": -0.2536701886159069,
        "compression_ratio": 1.4485981308411215,
        "end": 835.26,
        "id": 312,
        "no_speech_prob": 0.00026530129252932966,
        "seek": 81912,
        "start": 834.16,
        "temperature": 0,
        "text": " Let's see if this works.",
        "tokens": [
          51116,
          961,
          311,
          536,
          498,
          341,
          1985,
          13,
          51171
        ]
      },
      {
        "avg_logprob": -0.2536701886159069,
        "compression_ratio": 1.4485981308411215,
        "end": 841.4,
        "id": 313,
        "no_speech_prob": 0.00026530129252932966,
        "seek": 81912,
        "start": 840.28,
        "temperature": 0,
        "text": " Beautiful.",
        "tokens": [
          51422,
          14724,
          13,
          51478
        ]
      },
      {
        "avg_logprob": -0.2536701886159069,
        "compression_ratio": 1.4485981308411215,
        "end": 842.52,
        "id": 314,
        "no_speech_prob": 0.00026530129252932966,
        "seek": 81912,
        "start": 841.4,
        "temperature": 0,
        "text": " Who shat my bell?",
        "tokens": [
          51478,
          2102,
          402,
          267,
          452,
          4549,
          30,
          51534
        ]
      },
      {
        "avg_logprob": -0.2536701886159069,
        "compression_ratio": 1.4485981308411215,
        "end": 843.92,
        "id": 315,
        "no_speech_prob": 0.00026530129252932966,
        "seek": 81912,
        "start": 842.52,
        "temperature": 0,
        "text": " Ding.",
        "tokens": [
          51534,
          20558,
          13,
          51604
        ]
      },
      {
        "avg_logprob": -0.2536701886159069,
        "compression_ratio": 1.4485981308411215,
        "end": 848.24,
        "id": 316,
        "no_speech_prob": 0.00026530129252932966,
        "seek": 81912,
        "start": 843.92,
        "temperature": 0,
        "text": " Next step, let's add the GIF command.",
        "tokens": [
          51604,
          3087,
          1823,
          11,
          718,
          311,
          909,
          264,
          460,
          12775,
          5622,
          13,
          51820
        ]
      },
      {
        "avg_logprob": -0.27812360257518537,
        "compression_ratio": 1.4904761904761905,
        "end": 851.8,
        "id": 317,
        "no_speech_prob": 0.00018235432798974216,
        "seek": 84824,
        "start": 848.32,
        "temperature": 0,
        "text": " So now the commands object has two properties, choo-choo",
        "tokens": [
          50368,
          407,
          586,
          264,
          16901,
          2657,
          575,
          732,
          7221,
          11,
          1586,
          78,
          12,
          339,
          1986,
          50542
        ]
      },
      {
        "avg_logprob": -0.27812360257518537,
        "compression_ratio": 1.4904761904761905,
        "end": 854.92,
        "id": 318,
        "no_speech_prob": 0.00018235432798974216,
        "seek": 84824,
        "start": 851.8,
        "temperature": 0,
        "text": " and GIF, both coming from two separate JavaScript files.",
        "tokens": [
          50542,
          293,
          460,
          12775,
          11,
          1293,
          1348,
          490,
          732,
          4994,
          15778,
          7098,
          13,
          50698
        ]
      },
      {
        "avg_logprob": -0.27812360257518537,
        "compression_ratio": 1.4904761904761905,
        "end": 857.72,
        "id": 319,
        "no_speech_prob": 0.00018235432798974216,
        "seek": 84824,
        "start": 854.92,
        "temperature": 0,
        "text": " I need to add the module.export stuff to GIF.js.",
        "tokens": [
          50698,
          286,
          643,
          281,
          909,
          264,
          10088,
          13,
          3121,
          2707,
          1507,
          281,
          460,
          12775,
          13,
          25530,
          13,
          50838
        ]
      },
      {
        "avg_logprob": -0.27812360257518537,
        "compression_ratio": 1.4904761904761905,
        "end": 863.04,
        "id": 320,
        "no_speech_prob": 0.00018235432798974216,
        "seek": 84824,
        "start": 860.8,
        "temperature": 0,
        "text": " And the arguments.",
        "tokens": [
          50992,
          400,
          264,
          12869,
          13,
          51104
        ]
      },
      {
        "avg_logprob": -0.27812360257518537,
        "compression_ratio": 1.4904761904761905,
        "end": 866.2,
        "id": 321,
        "no_speech_prob": 0.00018235432798974216,
        "seek": 84824,
        "start": 863.04,
        "temperature": 0,
        "text": " Also, once again, this particular command",
        "tokens": [
          51104,
          2743,
          11,
          1564,
          797,
          11,
          341,
          1729,
          5622,
          51262
        ]
      },
      {
        "avg_logprob": -0.27812360257518537,
        "compression_ratio": 1.4904761904761905,
        "end": 868,
        "id": 322,
        "no_speech_prob": 0.00018235432798974216,
        "seek": 84824,
        "start": 866.2,
        "temperature": 0,
        "text": " is using node fetch.",
        "tokens": [
          51262,
          307,
          1228,
          9984,
          23673,
          13,
          51352
        ]
      },
      {
        "avg_logprob": -0.27812360257518537,
        "compression_ratio": 1.4904761904761905,
        "end": 871.64,
        "id": 323,
        "no_speech_prob": 0.00018235432798974216,
        "seek": 84824,
        "start": 868,
        "temperature": 0,
        "text": " So that should no longer be here.",
        "tokens": [
          51352,
          407,
          300,
          820,
          572,
          2854,
          312,
          510,
          13,
          51534
        ]
      },
      {
        "avg_logprob": -0.27812360257518537,
        "compression_ratio": 1.4904761904761905,
        "end": 873.48,
        "id": 324,
        "no_speech_prob": 0.00018235432798974216,
        "seek": 84824,
        "start": 871.64,
        "temperature": 0,
        "text": " Instead, it goes here.",
        "tokens": [
          51534,
          7156,
          11,
          309,
          1709,
          510,
          13,
          51626
        ]
      },
      {
        "avg_logprob": -0.27812360257518537,
        "compression_ratio": 1.4904761904761905,
        "end": 875.32,
        "id": 325,
        "no_speech_prob": 0.00018235432798974216,
        "seek": 84824,
        "start": 873.48,
        "temperature": 0,
        "text": " And ah, OK.",
        "tokens": [
          51626,
          400,
          3716,
          11,
          2264,
          13,
          51718
        ]
      },
      {
        "avg_logprob": -0.24407818442896792,
        "compression_ratio": 1.5661157024793388,
        "end": 879.08,
        "id": 326,
        "no_speech_prob": 0.00004133537731831893,
        "seek": 87532,
        "start": 875.36,
        "temperature": 0,
        "text": " So the key words are no longer coming from the tokens.",
        "tokens": [
          50366,
          407,
          264,
          2141,
          2283,
          366,
          572,
          2854,
          1348,
          490,
          264,
          22667,
          13,
          50552
        ]
      },
      {
        "avg_logprob": -0.24407818442896792,
        "compression_ratio": 1.5661157024793388,
        "end": 880.72,
        "id": 327,
        "no_speech_prob": 0.00004133537731831893,
        "seek": 87532,
        "start": 879.08,
        "temperature": 0,
        "text": " They're coming from the arguments.",
        "tokens": [
          50552,
          814,
          434,
          1348,
          490,
          264,
          12869,
          13,
          50634
        ]
      },
      {
        "avg_logprob": -0.24407818442896792,
        "compression_ratio": 1.5661157024793388,
        "end": 884.0400000000001,
        "id": 328,
        "no_speech_prob": 0.00004133537731831893,
        "seek": 87532,
        "start": 880.72,
        "temperature": 0,
        "text": " And I don't need to slice out the first one,",
        "tokens": [
          50634,
          400,
          286,
          500,
          380,
          643,
          281,
          13153,
          484,
          264,
          700,
          472,
          11,
          50800
        ]
      },
      {
        "avg_logprob": -0.24407818442896792,
        "compression_ratio": 1.5661157024793388,
        "end": 886.32,
        "id": 329,
        "no_speech_prob": 0.00004133537731831893,
        "seek": 87532,
        "start": 884.0400000000001,
        "temperature": 0,
        "text": " because that's already been done by the original commands",
        "tokens": [
          50800,
          570,
          300,
          311,
          1217,
          668,
          1096,
          538,
          264,
          3380,
          16901,
          50914
        ]
      },
      {
        "avg_logprob": -0.24407818442896792,
        "compression_ratio": 1.5661157024793388,
        "end": 887.08,
        "id": 330,
        "no_speech_prob": 0.00004133537731831893,
        "seek": 87532,
        "start": 886.32,
        "temperature": 0,
        "text": " function.",
        "tokens": [
          50914,
          2445,
          13,
          50952
        ]
      },
      {
        "avg_logprob": -0.24407818442896792,
        "compression_ratio": 1.5661157024793388,
        "end": 888.6,
        "id": 331,
        "no_speech_prob": 0.00004133537731831893,
        "seek": 87532,
        "start": 887.08,
        "temperature": 0,
        "text": " So this is much simpler now.",
        "tokens": [
          50952,
          407,
          341,
          307,
          709,
          18587,
          586,
          13,
          51028
        ]
      },
      {
        "avg_logprob": -0.24407818442896792,
        "compression_ratio": 1.5661157024793388,
        "end": 893,
        "id": 332,
        "no_speech_prob": 0.00004133537731831893,
        "seek": 87532,
        "start": 888.6,
        "temperature": 0,
        "text": " I can just say args join with a space.",
        "tokens": [
          51028,
          286,
          393,
          445,
          584,
          3882,
          82,
          3917,
          365,
          257,
          1901,
          13,
          51248
        ]
      },
      {
        "avg_logprob": -0.24407818442896792,
        "compression_ratio": 1.5661157024793388,
        "end": 896.5600000000001,
        "id": 333,
        "no_speech_prob": 0.00004133537731831893,
        "seek": 87532,
        "start": 893,
        "temperature": 0,
        "text": " And then I think we're good here.",
        "tokens": [
          51248,
          400,
          550,
          286,
          519,
          321,
          434,
          665,
          510,
          13,
          51426
        ]
      },
      {
        "avg_logprob": -0.24407818442896792,
        "compression_ratio": 1.5661157024793388,
        "end": 899.8800000000001,
        "id": 334,
        "no_speech_prob": 0.00004133537731831893,
        "seek": 87532,
        "start": 896.5600000000001,
        "temperature": 0,
        "text": " Let's try running it.",
        "tokens": [
          51426,
          961,
          311,
          853,
          2614,
          309,
          13,
          51592
        ]
      },
      {
        "avg_logprob": -0.24407818442896792,
        "compression_ratio": 1.5661157024793388,
        "end": 903.36,
        "id": 335,
        "no_speech_prob": 0.00004133537731831893,
        "seek": 87532,
        "start": 899.8800000000001,
        "temperature": 0,
        "text": " Await is only valid in an async function.",
        "tokens": [
          51592,
          6381,
          1001,
          307,
          787,
          7363,
          294,
          364,
          382,
          34015,
          2445,
          13,
          51766
        ]
      },
      {
        "avg_logprob": -0.24407818442896792,
        "compression_ratio": 1.5661157024793388,
        "end": 904.36,
        "id": 336,
        "no_speech_prob": 0.00004133537731831893,
        "seek": 87532,
        "start": 903.36,
        "temperature": 0,
        "text": " Of course.",
        "tokens": [
          51766,
          2720,
          1164,
          13,
          51816
        ]
      },
      {
        "avg_logprob": -0.24145172637643167,
        "compression_ratio": 1.429951690821256,
        "end": 906.4,
        "id": 337,
        "no_speech_prob": 0.000033737167541403323,
        "seek": 90436,
        "start": 904.36,
        "temperature": 0,
        "text": " So I need to make sure that this function is",
        "tokens": [
          50364,
          407,
          286,
          643,
          281,
          652,
          988,
          300,
          341,
          2445,
          307,
          50466
        ]
      },
      {
        "avg_logprob": -0.24145172637643167,
        "compression_ratio": 1.429951690821256,
        "end": 908.16,
        "id": 338,
        "no_speech_prob": 0.000033737167541403323,
        "seek": 90436,
        "start": 906.4,
        "temperature": 0,
        "text": " modified with the async keyword.",
        "tokens": [
          50466,
          15873,
          365,
          264,
          382,
          34015,
          20428,
          13,
          50554
        ]
      },
      {
        "avg_logprob": -0.24145172637643167,
        "compression_ratio": 1.429951690821256,
        "end": 914.44,
        "id": 339,
        "no_speech_prob": 0.000033737167541403323,
        "seek": 90436,
        "start": 910.76,
        "temperature": 0,
        "text": " Back to Discord, and I hope this works.",
        "tokens": [
          50684,
          5833,
          281,
          32623,
          11,
          293,
          286,
          1454,
          341,
          1985,
          13,
          50868
        ]
      },
      {
        "avg_logprob": -0.24145172637643167,
        "compression_ratio": 1.429951690821256,
        "end": 917.08,
        "id": 340,
        "no_speech_prob": 0.000033737167541403323,
        "seek": 90436,
        "start": 914.44,
        "temperature": 0,
        "text": " We already know choo-choo works.",
        "tokens": [
          50868,
          492,
          1217,
          458,
          1586,
          78,
          12,
          339,
          1986,
          1985,
          13,
          51000
        ]
      },
      {
        "avg_logprob": -0.24145172637643167,
        "compression_ratio": 1.429951690821256,
        "end": 918.52,
        "id": 341,
        "no_speech_prob": 0.000033737167541403323,
        "seek": 90436,
        "start": 917.08,
        "temperature": 0,
        "text": " Let's try GIF.",
        "tokens": [
          51000,
          961,
          311,
          853,
          460,
          12775,
          13,
          51072
        ]
      },
      {
        "avg_logprob": -0.24145172637643167,
        "compression_ratio": 1.429951690821256,
        "end": 920.92,
        "id": 342,
        "no_speech_prob": 0.000033737167541403323,
        "seek": 90436,
        "start": 918.52,
        "temperature": 0,
        "text": " And let's take a look at some puppies today.",
        "tokens": [
          51072,
          400,
          718,
          311,
          747,
          257,
          574,
          412,
          512,
          33734,
          965,
          13,
          51192
        ]
      },
      {
        "avg_logprob": -0.24145172637643167,
        "compression_ratio": 1.429951690821256,
        "end": 925.24,
        "id": 343,
        "no_speech_prob": 0.000033737167541403323,
        "seek": 90436,
        "start": 923.4,
        "temperature": 0,
        "text": " Oh, it's not coming.",
        "tokens": [
          51316,
          876,
          11,
          309,
          311,
          406,
          1348,
          13,
          51408
        ]
      },
      {
        "avg_logprob": -0.24145172637643167,
        "compression_ratio": 1.429951690821256,
        "end": 926.4,
        "id": 344,
        "no_speech_prob": 0.000033737167541403323,
        "seek": 90436,
        "start": 925.24,
        "temperature": 0,
        "text": " There's an error.",
        "tokens": [
          51408,
          821,
          311,
          364,
          6713,
          13,
          51466
        ]
      },
      {
        "avg_logprob": -0.24145172637643167,
        "compression_ratio": 1.429951690821256,
        "end": 929.12,
        "id": 345,
        "no_speech_prob": 0.000033737167541403323,
        "seek": 90436,
        "start": 926.4,
        "temperature": 0,
        "text": " Tokens is not defined GIF.js.",
        "tokens": [
          51466,
          11036,
          694,
          307,
          406,
          7642,
          460,
          12775,
          13,
          25530,
          13,
          51602
        ]
      },
      {
        "avg_logprob": -0.24145172637643167,
        "compression_ratio": 1.429951690821256,
        "end": 930.64,
        "id": 346,
        "no_speech_prob": 0.000033737167541403323,
        "seek": 90436,
        "start": 929.12,
        "temperature": 0,
        "text": " What did I miss?",
        "tokens": [
          51602,
          708,
          630,
          286,
          1713,
          30,
          51678
        ]
      },
      {
        "avg_logprob": -0.2429376554883216,
        "compression_ratio": 1.5859375,
        "end": 932.84,
        "id": 347,
        "no_speech_prob": 0.00008614639955339953,
        "seek": 93064,
        "start": 930.64,
        "temperature": 0,
        "text": " Aha, I joined the args, but I still",
        "tokens": [
          50364,
          27448,
          11,
          286,
          6869,
          264,
          3882,
          82,
          11,
          457,
          286,
          920,
          50474
        ]
      },
      {
        "avg_logprob": -0.2429376554883216,
        "compression_ratio": 1.5859375,
        "end": 934.56,
        "id": 348,
        "no_speech_prob": 0.00008614639955339953,
        "seek": 93064,
        "start": 932.84,
        "temperature": 0,
        "text": " checked the length of tokens.",
        "tokens": [
          50474,
          10033,
          264,
          4641,
          295,
          22667,
          13,
          50560
        ]
      },
      {
        "avg_logprob": -0.2429376554883216,
        "compression_ratio": 1.5859375,
        "end": 937.6,
        "id": 349,
        "no_speech_prob": 0.00008614639955339953,
        "seek": 93064,
        "start": 934.56,
        "temperature": 0,
        "text": " So now I just need to check if there are actual arguments",
        "tokens": [
          50560,
          407,
          586,
          286,
          445,
          643,
          281,
          1520,
          498,
          456,
          366,
          3539,
          12869,
          50712
        ]
      },
      {
        "avg_logprob": -0.2429376554883216,
        "compression_ratio": 1.5859375,
        "end": 939.52,
        "id": 350,
        "no_speech_prob": 0.00008614639955339953,
        "seek": 93064,
        "start": 937.6,
        "temperature": 0,
        "text": " and if the length is greater than 0,",
        "tokens": [
          50712,
          293,
          498,
          264,
          4641,
          307,
          5044,
          813,
          1958,
          11,
          50808
        ]
      },
      {
        "avg_logprob": -0.2429376554883216,
        "compression_ratio": 1.5859375,
        "end": 941.72,
        "id": 351,
        "no_speech_prob": 0.00008614639955339953,
        "seek": 93064,
        "start": 939.52,
        "temperature": 0,
        "text": " because again, the command is not part of it anymore.",
        "tokens": [
          50808,
          570,
          797,
          11,
          264,
          5622,
          307,
          406,
          644,
          295,
          309,
          3602,
          13,
          50918
        ]
      },
      {
        "avg_logprob": -0.2429376554883216,
        "compression_ratio": 1.5859375,
        "end": 943.1999999999999,
        "id": 352,
        "no_speech_prob": 0.00008614639955339953,
        "seek": 93064,
        "start": 941.72,
        "temperature": 0,
        "text": " So that should fix it.",
        "tokens": [
          50918,
          407,
          300,
          820,
          3191,
          309,
          13,
          50992
        ]
      },
      {
        "avg_logprob": -0.2429376554883216,
        "compression_ratio": 1.5859375,
        "end": 944.56,
        "id": 353,
        "no_speech_prob": 0.00008614639955339953,
        "seek": 93064,
        "start": 943.1999999999999,
        "temperature": 0,
        "text": " Back to Discord.",
        "tokens": [
          50992,
          5833,
          281,
          32623,
          13,
          51060
        ]
      },
      {
        "avg_logprob": -0.2429376554883216,
        "compression_ratio": 1.5859375,
        "end": 945.64,
        "id": 354,
        "no_speech_prob": 0.00008614639955339953,
        "seek": 93064,
        "start": 944.56,
        "temperature": 0,
        "text": " Let's see those puppies.",
        "tokens": [
          51060,
          961,
          311,
          536,
          729,
          33734,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.2429376554883216,
        "compression_ratio": 1.5859375,
        "end": 952,
        "id": 355,
        "no_speech_prob": 0.00008614639955339953,
        "seek": 93064,
        "start": 948.92,
        "temperature": 0,
        "text": " Oh, and there we go.",
        "tokens": [
          51278,
          876,
          11,
          293,
          456,
          321,
          352,
          13,
          51432
        ]
      },
      {
        "avg_logprob": -0.2429376554883216,
        "compression_ratio": 1.5859375,
        "end": 955.6,
        "id": 356,
        "no_speech_prob": 0.00008614639955339953,
        "seek": 93064,
        "start": 952,
        "temperature": 0,
        "text": " It couldn't be a more fitting end to this particular video.",
        "tokens": [
          51432,
          467,
          2809,
          380,
          312,
          257,
          544,
          15669,
          917,
          281,
          341,
          1729,
          960,
          13,
          51612
        ]
      },
      {
        "avg_logprob": -0.2429376554883216,
        "compression_ratio": 1.5859375,
        "end": 958.68,
        "id": 357,
        "no_speech_prob": 0.00008614639955339953,
        "seek": 93064,
        "start": 955.6,
        "temperature": 0,
        "text": " So hopefully now, just to recap for a moment,",
        "tokens": [
          51612,
          407,
          4696,
          586,
          11,
          445,
          281,
          20928,
          337,
          257,
          1623,
          11,
          51766
        ]
      },
      {
        "avg_logprob": -0.2105345578537774,
        "compression_ratio": 1.8009259259259258,
        "end": 963.56,
        "id": 358,
        "no_speech_prob": 0.0004955347394570708,
        "seek": 95868,
        "start": 958.68,
        "temperature": 0,
        "text": " starting back from bot.js, the only thing bot.js does",
        "tokens": [
          50364,
          2891,
          646,
          490,
          10592,
          13,
          25530,
          11,
          264,
          787,
          551,
          10592,
          13,
          25530,
          775,
          50608
        ]
      },
      {
        "avg_logprob": -0.2105345578537774,
        "compression_ratio": 1.8009259259259258,
        "end": 967.52,
        "id": 359,
        "no_speech_prob": 0.0004955347394570708,
        "seek": 95868,
        "start": 963.56,
        "temperature": 0,
        "text": " is connect to Discord and then import a command handler",
        "tokens": [
          50608,
          307,
          1745,
          281,
          32623,
          293,
          550,
          974,
          257,
          5622,
          41967,
          50806
        ]
      },
      {
        "avg_logprob": -0.2105345578537774,
        "compression_ratio": 1.8009259259259258,
        "end": 970.5999999999999,
        "id": 360,
        "no_speech_prob": 0.0004955347394570708,
        "seek": 95868,
        "start": 967.52,
        "temperature": 0,
        "text": " function from another JavaScript file.",
        "tokens": [
          50806,
          2445,
          490,
          1071,
          15778,
          3991,
          13,
          50960
        ]
      },
      {
        "avg_logprob": -0.2105345578537774,
        "compression_ratio": 1.8009259259259258,
        "end": 974.64,
        "id": 361,
        "no_speech_prob": 0.0004955347394570708,
        "seek": 95868,
        "start": 970.5999999999999,
        "temperature": 0,
        "text": " In that command handler JavaScript file,",
        "tokens": [
          50960,
          682,
          300,
          5622,
          41967,
          15778,
          3991,
          11,
          51162
        ]
      },
      {
        "avg_logprob": -0.2105345578537774,
        "compression_ratio": 1.8009259259259258,
        "end": 977.3199999999999,
        "id": 362,
        "no_speech_prob": 0.0004955347394570708,
        "seek": 95868,
        "start": 974.64,
        "temperature": 0,
        "text": " that file imports other JavaScript files,",
        "tokens": [
          51162,
          300,
          3991,
          41596,
          661,
          15778,
          7098,
          11,
          51296
        ]
      },
      {
        "avg_logprob": -0.2105345578537774,
        "compression_ratio": 1.8009259259259258,
        "end": 980.4799999999999,
        "id": 363,
        "no_speech_prob": 0.0004955347394570708,
        "seek": 95868,
        "start": 977.3199999999999,
        "temperature": 0,
        "text": " one for each command, stores them in an object,",
        "tokens": [
          51296,
          472,
          337,
          1184,
          5622,
          11,
          9512,
          552,
          294,
          364,
          2657,
          11,
          51454
        ]
      },
      {
        "avg_logprob": -0.2105345578537774,
        "compression_ratio": 1.8009259259259258,
        "end": 982.6999999999999,
        "id": 364,
        "no_speech_prob": 0.0004955347394570708,
        "seek": 95868,
        "start": 980.4799999999999,
        "temperature": 0,
        "text": " checks to make sure it's a valid message,",
        "tokens": [
          51454,
          13834,
          281,
          652,
          988,
          309,
          311,
          257,
          7363,
          3636,
          11,
          51565
        ]
      },
      {
        "avg_logprob": -0.2105345578537774,
        "compression_ratio": 1.8009259259259258,
        "end": 985.4399999999999,
        "id": 365,
        "no_speech_prob": 0.0004955347394570708,
        "seek": 95868,
        "start": 982.6999999999999,
        "temperature": 0,
        "text": " and then executes the proper function associated",
        "tokens": [
          51565,
          293,
          550,
          4454,
          1819,
          264,
          2296,
          2445,
          6615,
          51702
        ]
      },
      {
        "avg_logprob": -0.2105345578537774,
        "compression_ratio": 1.8009259259259258,
        "end": 986.4799999999999,
        "id": 366,
        "no_speech_prob": 0.0004955347394570708,
        "seek": 95868,
        "start": 985.4399999999999,
        "temperature": 0,
        "text": " with that command.",
        "tokens": [
          51702,
          365,
          300,
          5622,
          13,
          51754
        ]
      },
      {
        "avg_logprob": -0.22901682951012436,
        "compression_ratio": 1.6935483870967742,
        "end": 988.64,
        "id": 367,
        "no_speech_prob": 0.0003006145707331598,
        "seek": 98648,
        "start": 986.48,
        "temperature": 0,
        "text": " So now if I wanted to add another command,",
        "tokens": [
          50364,
          407,
          586,
          498,
          286,
          1415,
          281,
          909,
          1071,
          5622,
          11,
          50472
        ]
      },
      {
        "avg_logprob": -0.22901682951012436,
        "compression_ratio": 1.6935483870967742,
        "end": 990.76,
        "id": 368,
        "no_speech_prob": 0.0003006145707331598,
        "seek": 98648,
        "start": 988.64,
        "temperature": 0,
        "text": " let's say we're going to look up some information about a word.",
        "tokens": [
          50472,
          718,
          311,
          584,
          321,
          434,
          516,
          281,
          574,
          493,
          512,
          1589,
          466,
          257,
          1349,
          13,
          50578
        ]
      },
      {
        "avg_logprob": -0.22901682951012436,
        "compression_ratio": 1.6935483870967742,
        "end": 992.16,
        "id": 369,
        "no_speech_prob": 0.0003006145707331598,
        "seek": 98648,
        "start": 990.76,
        "temperature": 0,
        "text": " Maybe I'll use the Wordnik API.",
        "tokens": [
          50578,
          2704,
          286,
          603,
          764,
          264,
          8725,
          13123,
          9362,
          13,
          50648
        ]
      },
      {
        "avg_logprob": -0.22901682951012436,
        "compression_ratio": 1.6935483870967742,
        "end": 994.28,
        "id": 370,
        "no_speech_prob": 0.0003006145707331598,
        "seek": 98648,
        "start": 992.16,
        "temperature": 0,
        "text": " I definitely want to do an example of a Discord",
        "tokens": [
          50648,
          286,
          2138,
          528,
          281,
          360,
          364,
          1365,
          295,
          257,
          32623,
          50754
        ]
      },
      {
        "avg_logprob": -0.22901682951012436,
        "compression_ratio": 1.6935483870967742,
        "end": 995.72,
        "id": 371,
        "no_speech_prob": 0.0003006145707331598,
        "seek": 98648,
        "start": 994.28,
        "temperature": 0,
        "text": " bot that connects to an API.",
        "tokens": [
          50754,
          10592,
          300,
          16967,
          281,
          364,
          9362,
          13,
          50826
        ]
      },
      {
        "avg_logprob": -0.22901682951012436,
        "compression_ratio": 1.6935483870967742,
        "end": 999.4,
        "id": 372,
        "no_speech_prob": 0.0003006145707331598,
        "seek": 98648,
        "start": 995.72,
        "temperature": 0,
        "text": " I mean, I am doing that with the Tenor API, but some other API.",
        "tokens": [
          50826,
          286,
          914,
          11,
          286,
          669,
          884,
          300,
          365,
          264,
          9380,
          284,
          9362,
          11,
          457,
          512,
          661,
          9362,
          13,
          51010
        ]
      },
      {
        "avg_logprob": -0.22901682951012436,
        "compression_ratio": 1.6935483870967742,
        "end": 1003.9200000000001,
        "id": 373,
        "no_speech_prob": 0.0003006145707331598,
        "seek": 98648,
        "start": 999.4,
        "temperature": 0,
        "text": " So if I were to say, define, there's a define command.",
        "tokens": [
          51010,
          407,
          498,
          286,
          645,
          281,
          584,
          11,
          6964,
          11,
          456,
          311,
          257,
          6964,
          5622,
          13,
          51236
        ]
      },
      {
        "avg_logprob": -0.22901682951012436,
        "compression_ratio": 1.6935483870967742,
        "end": 1009.24,
        "id": 374,
        "no_speech_prob": 0.0003006145707331598,
        "seek": 98648,
        "start": 1003.9200000000001,
        "temperature": 0,
        "text": " All I would need to do is add that particular define",
        "tokens": [
          51236,
          1057,
          286,
          576,
          643,
          281,
          360,
          307,
          909,
          300,
          1729,
          6964,
          51502
        ]
      },
      {
        "avg_logprob": -0.22901682951012436,
        "compression_ratio": 1.6935483870967742,
        "end": 1010.36,
        "id": 375,
        "no_speech_prob": 0.0003006145707331598,
        "seek": 98648,
        "start": 1009.24,
        "temperature": 0,
        "text": " JavaScript file.",
        "tokens": [
          51502,
          15778,
          3991,
          13,
          51558
        ]
      },
      {
        "avg_logprob": -0.22901682951012436,
        "compression_ratio": 1.6935483870967742,
        "end": 1012.64,
        "id": 376,
        "no_speech_prob": 0.0003006145707331598,
        "seek": 98648,
        "start": 1010.36,
        "temperature": 0,
        "text": " That would have to have exactly the same format",
        "tokens": [
          51558,
          663,
          576,
          362,
          281,
          362,
          2293,
          264,
          912,
          7877,
          51672
        ]
      },
      {
        "avg_logprob": -0.22901682951012436,
        "compression_ratio": 1.6935483870967742,
        "end": 1014.72,
        "id": 377,
        "no_speech_prob": 0.0003006145707331598,
        "seek": 98648,
        "start": 1012.64,
        "temperature": 0,
        "text": " of a single function that handles the command,",
        "tokens": [
          51672,
          295,
          257,
          2167,
          2445,
          300,
          18722,
          264,
          5622,
          11,
          51776
        ]
      },
      {
        "avg_logprob": -0.22901682951012436,
        "compression_ratio": 1.6935483870967742,
        "end": 1015.96,
        "id": 378,
        "no_speech_prob": 0.0003006145707331598,
        "seek": 98648,
        "start": 1014.72,
        "temperature": 0,
        "text": " does everything it needs.",
        "tokens": [
          51776,
          775,
          1203,
          309,
          2203,
          13,
          51838
        ]
      },
      {
        "avg_logprob": -0.24253328578678643,
        "compression_ratio": 1.6666666666666667,
        "end": 1017.4000000000001,
        "id": 379,
        "no_speech_prob": 0.00037409417564049363,
        "seek": 101596,
        "start": 1015.96,
        "temperature": 0,
        "text": " And I would be done.",
        "tokens": [
          50364,
          400,
          286,
          576,
          312,
          1096,
          13,
          50436
        ]
      },
      {
        "avg_logprob": -0.24253328578678643,
        "compression_ratio": 1.6666666666666667,
        "end": 1020.64,
        "id": 380,
        "no_speech_prob": 0.00037409417564049363,
        "seek": 101596,
        "start": 1017.4000000000001,
        "temperature": 0,
        "text": " And then I could keep adding more commands.",
        "tokens": [
          50436,
          400,
          550,
          286,
          727,
          1066,
          5127,
          544,
          16901,
          13,
          50598
        ]
      },
      {
        "avg_logprob": -0.24253328578678643,
        "compression_ratio": 1.6666666666666667,
        "end": 1024.64,
        "id": 381,
        "no_speech_prob": 0.00037409417564049363,
        "seek": 101596,
        "start": 1020.64,
        "temperature": 0,
        "text": " So hopefully, if you watch this particular video",
        "tokens": [
          50598,
          407,
          4696,
          11,
          498,
          291,
          1159,
          341,
          1729,
          960,
          50798
        ]
      },
      {
        "avg_logprob": -0.24253328578678643,
        "compression_ratio": 1.6666666666666667,
        "end": 1026.96,
        "id": 382,
        "no_speech_prob": 0.00037409417564049363,
        "seek": 101596,
        "start": 1024.64,
        "temperature": 0,
        "text": " and you're making your own bot, try this",
        "tokens": [
          50798,
          293,
          291,
          434,
          1455,
          428,
          1065,
          10592,
          11,
          853,
          341,
          50914
        ]
      },
      {
        "avg_logprob": -0.24253328578678643,
        "compression_ratio": 1.6666666666666667,
        "end": 1028.48,
        "id": 383,
        "no_speech_prob": 0.00037409417564049363,
        "seek": 101596,
        "start": 1026.96,
        "temperature": 0,
        "text": " and try adding some more commands.",
        "tokens": [
          50914,
          293,
          853,
          5127,
          512,
          544,
          16901,
          13,
          50990
        ]
      },
      {
        "avg_logprob": -0.24253328578678643,
        "compression_ratio": 1.6666666666666667,
        "end": 1032.64,
        "id": 384,
        "no_speech_prob": 0.00037409417564049363,
        "seek": 101596,
        "start": 1028.48,
        "temperature": 0,
        "text": " I should say, however, there is one small potential issue.",
        "tokens": [
          50990,
          286,
          820,
          584,
          11,
          4461,
          11,
          456,
          307,
          472,
          1359,
          3995,
          2734,
          13,
          51198
        ]
      },
      {
        "avg_logprob": -0.24253328578678643,
        "compression_ratio": 1.6666666666666667,
        "end": 1034.48,
        "id": 385,
        "no_speech_prob": 0.00037409417564049363,
        "seek": 101596,
        "start": 1032.64,
        "temperature": 0,
        "text": " You might be making a bot where you imagine",
        "tokens": [
          51198,
          509,
          1062,
          312,
          1455,
          257,
          10592,
          689,
          291,
          3811,
          51290
        ]
      },
      {
        "avg_logprob": -0.24253328578678643,
        "compression_ratio": 1.6666666666666667,
        "end": 1036.48,
        "id": 386,
        "no_speech_prob": 0.00037409417564049363,
        "seek": 101596,
        "start": 1034.48,
        "temperature": 0,
        "text": " having 100 plus commands in it.",
        "tokens": [
          51290,
          1419,
          2319,
          1804,
          16901,
          294,
          309,
          13,
          51390
        ]
      },
      {
        "avg_logprob": -0.24253328578678643,
        "compression_ratio": 1.6666666666666667,
        "end": 1039.76,
        "id": 387,
        "no_speech_prob": 0.00037409417564049363,
        "seek": 101596,
        "start": 1036.48,
        "temperature": 0,
        "text": " If that's the case, having 100 require statements",
        "tokens": [
          51390,
          759,
          300,
          311,
          264,
          1389,
          11,
          1419,
          2319,
          3651,
          12363,
          51554
        ]
      },
      {
        "avg_logprob": -0.24253328578678643,
        "compression_ratio": 1.6666666666666667,
        "end": 1041.32,
        "id": 388,
        "no_speech_prob": 0.00037409417564049363,
        "seek": 101596,
        "start": 1039.76,
        "temperature": 0,
        "text": " is maybe not so great.",
        "tokens": [
          51554,
          307,
          1310,
          406,
          370,
          869,
          13,
          51632
        ]
      },
      {
        "avg_logprob": -0.24253328578678643,
        "compression_ratio": 1.6666666666666667,
        "end": 1043.8,
        "id": 389,
        "no_speech_prob": 0.00037409417564049363,
        "seek": 101596,
        "start": 1041.32,
        "temperature": 0,
        "text": " So one of the things you could do is actually read the file",
        "tokens": [
          51632,
          407,
          472,
          295,
          264,
          721,
          291,
          727,
          360,
          307,
          767,
          1401,
          264,
          3991,
          51756
        ]
      },
      {
        "avg_logprob": -0.24253328578678643,
        "compression_ratio": 1.6666666666666667,
        "end": 1044.32,
        "id": 390,
        "no_speech_prob": 0.00037409417564049363,
        "seek": 101596,
        "start": 1043.8,
        "temperature": 0,
        "text": " system.",
        "tokens": [
          51756,
          1185,
          13,
          51782
        ]
      },
      {
        "avg_logprob": -0.25000045960208017,
        "compression_ratio": 1.7701149425287357,
        "end": 1047.6,
        "id": 391,
        "no_speech_prob": 0.0023596237879246473,
        "seek": 104432,
        "start": 1044.32,
        "temperature": 0,
        "text": " So if you have this particular commands folder",
        "tokens": [
          50364,
          407,
          498,
          291,
          362,
          341,
          1729,
          16901,
          10820,
          50528
        ]
      },
      {
        "avg_logprob": -0.25000045960208017,
        "compression_ratio": 1.7701149425287357,
        "end": 1049.3999999999999,
        "id": 392,
        "no_speech_prob": 0.0023596237879246473,
        "seek": 104432,
        "start": 1047.6,
        "temperature": 0,
        "text": " with 100 JavaScript files in it, you",
        "tokens": [
          50528,
          365,
          2319,
          15778,
          7098,
          294,
          309,
          11,
          291,
          50618
        ]
      },
      {
        "avg_logprob": -0.25000045960208017,
        "compression_ratio": 1.7701149425287357,
        "end": 1052.36,
        "id": 393,
        "no_speech_prob": 0.0023596237879246473,
        "seek": 104432,
        "start": 1049.3999999999999,
        "temperature": 0,
        "text": " can automatically, with the node file system package,",
        "tokens": [
          50618,
          393,
          6772,
          11,
          365,
          264,
          9984,
          3991,
          1185,
          7372,
          11,
          50766
        ]
      },
      {
        "avg_logprob": -0.25000045960208017,
        "compression_ratio": 1.7701149425287357,
        "end": 1054.04,
        "id": 394,
        "no_speech_prob": 0.0023596237879246473,
        "seek": 104432,
        "start": 1052.36,
        "temperature": 0,
        "text": " just read what all those files are.",
        "tokens": [
          50766,
          445,
          1401,
          437,
          439,
          729,
          7098,
          366,
          13,
          50850
        ]
      },
      {
        "avg_logprob": -0.25000045960208017,
        "compression_ratio": 1.7701149425287357,
        "end": 1056,
        "id": 395,
        "no_speech_prob": 0.0023596237879246473,
        "seek": 104432,
        "start": 1054.04,
        "temperature": 0,
        "text": " And then you have all of your commands that way.",
        "tokens": [
          50850,
          400,
          550,
          291,
          362,
          439,
          295,
          428,
          16901,
          300,
          636,
          13,
          50948
        ]
      },
      {
        "avg_logprob": -0.25000045960208017,
        "compression_ratio": 1.7701149425287357,
        "end": 1058,
        "id": 396,
        "no_speech_prob": 0.0023596237879246473,
        "seek": 104432,
        "start": 1056,
        "temperature": 0,
        "text": " So actually, the only thing you would need to do",
        "tokens": [
          50948,
          407,
          767,
          11,
          264,
          787,
          551,
          291,
          576,
          643,
          281,
          360,
          51048
        ]
      },
      {
        "avg_logprob": -0.25000045960208017,
        "compression_ratio": 1.7701149425287357,
        "end": 1060.62,
        "id": 397,
        "no_speech_prob": 0.0023596237879246473,
        "seek": 104432,
        "start": 1058,
        "temperature": 0,
        "text": " to add a new command is just add another JavaScript file that's",
        "tokens": [
          51048,
          281,
          909,
          257,
          777,
          5622,
          307,
          445,
          909,
          1071,
          15778,
          3991,
          300,
          311,
          51179
        ]
      },
      {
        "avg_logprob": -0.25000045960208017,
        "compression_ratio": 1.7701149425287357,
        "end": 1062.48,
        "id": 398,
        "no_speech_prob": 0.0023596237879246473,
        "seek": 104432,
        "start": 1060.62,
        "temperature": 0,
        "text": " formatted in the same exact way.",
        "tokens": [
          51179,
          1254,
          32509,
          294,
          264,
          912,
          1900,
          636,
          13,
          51272
        ]
      },
      {
        "avg_logprob": -0.25000045960208017,
        "compression_ratio": 1.7701149425287357,
        "end": 1062.96,
        "id": 399,
        "no_speech_prob": 0.0023596237879246473,
        "seek": 104432,
        "start": 1062.48,
        "temperature": 0,
        "text": " Woof.",
        "tokens": [
          51272,
          10468,
          69,
          13,
          51296
        ]
      },
      {
        "avg_logprob": -0.25000045960208017,
        "compression_ratio": 1.7701149425287357,
        "end": 1063.6399999999999,
        "id": 400,
        "no_speech_prob": 0.0023596237879246473,
        "seek": 104432,
        "start": 1062.96,
        "temperature": 0,
        "text": " Oh, this is great.",
        "tokens": [
          51296,
          876,
          11,
          341,
          307,
          869,
          13,
          51330
        ]
      },
      {
        "avg_logprob": -0.25000045960208017,
        "compression_ratio": 1.7701149425287357,
        "end": 1066.12,
        "id": 401,
        "no_speech_prob": 0.0023596237879246473,
        "seek": 104432,
        "start": 1063.6399999999999,
        "temperature": 0,
        "text": " This is going to make bot making so much more organized",
        "tokens": [
          51330,
          639,
          307,
          516,
          281,
          652,
          10592,
          1455,
          370,
          709,
          544,
          9983,
          51454
        ]
      },
      {
        "avg_logprob": -0.25000045960208017,
        "compression_ratio": 1.7701149425287357,
        "end": 1068.84,
        "id": 402,
        "no_speech_prob": 0.0023596237879246473,
        "seek": 104432,
        "start": 1066.12,
        "temperature": 0,
        "text": " and neat and tidy and all the wonderful things that I love.",
        "tokens": [
          51454,
          293,
          10654,
          293,
          34646,
          293,
          439,
          264,
          3715,
          721,
          300,
          286,
          959,
          13,
          51590
        ]
      },
      {
        "avg_logprob": -0.25000045960208017,
        "compression_ratio": 1.7701149425287357,
        "end": 1071.52,
        "id": 403,
        "no_speech_prob": 0.0023596237879246473,
        "seek": 104432,
        "start": 1068.84,
        "temperature": 0,
        "text": " So this was a little challenging to make this video for you",
        "tokens": [
          51590,
          407,
          341,
          390,
          257,
          707,
          7595,
          281,
          652,
          341,
          960,
          337,
          291,
          51724
        ]
      },
      {
        "avg_logprob": -0.25000045960208017,
        "compression_ratio": 1.7701149425287357,
        "end": 1072.6799999999998,
        "id": 404,
        "no_speech_prob": 0.0023596237879246473,
        "seek": 104432,
        "start": 1071.52,
        "temperature": 0,
        "text": " to watch it, perhaps.",
        "tokens": [
          51724,
          281,
          1159,
          309,
          11,
          4317,
          13,
          51782
        ]
      },
      {
        "avg_logprob": -0.25000045960208017,
        "compression_ratio": 1.7701149425287357,
        "end": 1073.6799999999998,
        "id": 405,
        "no_speech_prob": 0.0023596237879246473,
        "seek": 104432,
        "start": 1072.6799999999998,
        "temperature": 0,
        "text": " I hope this makes sense.",
        "tokens": [
          51782,
          286,
          1454,
          341,
          1669,
          2020,
          13,
          51832
        ]
      },
      {
        "avg_logprob": -0.2580798544534823,
        "compression_ratio": 1.7070063694267517,
        "end": 1075.8,
        "id": 406,
        "no_speech_prob": 0.03904595226049423,
        "seek": 107368,
        "start": 1073.68,
        "temperature": 0,
        "text": " Ask your questions in the comments.",
        "tokens": [
          50364,
          12320,
          428,
          1651,
          294,
          264,
          3053,
          13,
          50470
        ]
      },
      {
        "avg_logprob": -0.2580798544534823,
        "compression_ratio": 1.7070063694267517,
        "end": 1077.04,
        "id": 407,
        "no_speech_prob": 0.03904595226049423,
        "seek": 107368,
        "start": 1075.8,
        "temperature": 0,
        "text": " There are more to come.",
        "tokens": [
          50470,
          821,
          366,
          544,
          281,
          808,
          13,
          50532
        ]
      },
      {
        "avg_logprob": -0.2580798544534823,
        "compression_ratio": 1.7070063694267517,
        "end": 1078.72,
        "id": 408,
        "no_speech_prob": 0.03904595226049423,
        "seek": 107368,
        "start": 1077.04,
        "temperature": 0,
        "text": " So what have I said so far I want to do?",
        "tokens": [
          50532,
          407,
          437,
          362,
          286,
          848,
          370,
          1400,
          286,
          528,
          281,
          360,
          30,
          50616
        ]
      },
      {
        "avg_logprob": -0.2580798544534823,
        "compression_ratio": 1.7070063694267517,
        "end": 1081.8,
        "id": 409,
        "no_speech_prob": 0.03904595226049423,
        "seek": 107368,
        "start": 1078.72,
        "temperature": 0,
        "text": " I want to connect to an API just to show another command.",
        "tokens": [
          50616,
          286,
          528,
          281,
          1745,
          281,
          364,
          9362,
          445,
          281,
          855,
          1071,
          5622,
          13,
          50770
        ]
      },
      {
        "avg_logprob": -0.2580798544534823,
        "compression_ratio": 1.7070063694267517,
        "end": 1084.0800000000002,
        "id": 410,
        "no_speech_prob": 0.03904595226049423,
        "seek": 107368,
        "start": 1081.8,
        "temperature": 0,
        "text": " I think there were some other things I was thinking of.",
        "tokens": [
          50770,
          286,
          519,
          456,
          645,
          512,
          661,
          721,
          286,
          390,
          1953,
          295,
          13,
          50884
        ]
      },
      {
        "avg_logprob": -0.2580798544534823,
        "compression_ratio": 1.7070063694267517,
        "end": 1085.16,
        "id": 411,
        "no_speech_prob": 0.03904595226049423,
        "seek": 107368,
        "start": 1084.0800000000002,
        "temperature": 0,
        "text": " I'll think of those again.",
        "tokens": [
          50884,
          286,
          603,
          519,
          295,
          729,
          797,
          13,
          50938
        ]
      },
      {
        "avg_logprob": -0.2580798544534823,
        "compression_ratio": 1.7070063694267517,
        "end": 1089.5600000000002,
        "id": 412,
        "no_speech_prob": 0.03904595226049423,
        "seek": 107368,
        "start": 1085.16,
        "temperature": 0,
        "text": " But I do want to show how to work with embeds.",
        "tokens": [
          50938,
          583,
          286,
          360,
          528,
          281,
          855,
          577,
          281,
          589,
          365,
          12240,
          82,
          13,
          51158
        ]
      },
      {
        "avg_logprob": -0.2580798544534823,
        "compression_ratio": 1.7070063694267517,
        "end": 1090.1200000000001,
        "id": 413,
        "no_speech_prob": 0.03904595226049423,
        "seek": 107368,
        "start": 1089.5600000000002,
        "temperature": 0,
        "text": " Embeds?",
        "tokens": [
          51158,
          24234,
          5147,
          30,
          51186
        ]
      },
      {
        "avg_logprob": -0.2580798544534823,
        "compression_ratio": 1.7070063694267517,
        "end": 1090.72,
        "id": 414,
        "no_speech_prob": 0.03904595226049423,
        "seek": 107368,
        "start": 1090.1200000000001,
        "temperature": 0,
        "text": " Embeds?",
        "tokens": [
          51186,
          3968,
          2883,
          82,
          30,
          51216
        ]
      },
      {
        "avg_logprob": -0.2580798544534823,
        "compression_ratio": 1.7070063694267517,
        "end": 1091.48,
        "id": 415,
        "no_speech_prob": 0.03904595226049423,
        "seek": 107368,
        "start": 1090.72,
        "temperature": 0,
        "text": " Embeds?",
        "tokens": [
          51216,
          24234,
          5147,
          30,
          51254
        ]
      },
      {
        "avg_logprob": -0.2580798544534823,
        "compression_ratio": 1.7070063694267517,
        "end": 1093.44,
        "id": 416,
        "no_speech_prob": 0.03904595226049423,
        "seek": 107368,
        "start": 1091.48,
        "temperature": 0,
        "text": " I will figure out how to say that word.",
        "tokens": [
          51254,
          286,
          486,
          2573,
          484,
          577,
          281,
          584,
          300,
          1349,
          13,
          51352
        ]
      },
      {
        "avg_logprob": -0.2580798544534823,
        "compression_ratio": 1.7070063694267517,
        "end": 1095,
        "id": 417,
        "no_speech_prob": 0.03904595226049423,
        "seek": 107368,
        "start": 1093.44,
        "temperature": 0,
        "text": " You've probably seen a Discord bot",
        "tokens": [
          51352,
          509,
          600,
          1391,
          1612,
          257,
          32623,
          10592,
          51430
        ]
      },
      {
        "avg_logprob": -0.2580798544534823,
        "compression_ratio": 1.7070063694267517,
        "end": 1098.28,
        "id": 418,
        "no_speech_prob": 0.03904595226049423,
        "seek": 107368,
        "start": 1095,
        "temperature": 0,
        "text": " that shows this kind of replies with this message that's",
        "tokens": [
          51430,
          300,
          3110,
          341,
          733,
          295,
          42289,
          365,
          341,
          3636,
          300,
          311,
          51594
        ]
      },
      {
        "avg_logprob": -0.2580798544534823,
        "compression_ratio": 1.7070063694267517,
        "end": 1099.3600000000001,
        "id": 419,
        "no_speech_prob": 0.03904595226049423,
        "seek": 107368,
        "start": 1098.28,
        "temperature": 0,
        "text": " nicely formatted.",
        "tokens": [
          51594,
          9594,
          1254,
          32509,
          13,
          51648
        ]
      },
      {
        "avg_logprob": -0.2580798544534823,
        "compression_ratio": 1.7070063694267517,
        "end": 1101.64,
        "id": 420,
        "no_speech_prob": 0.03904595226049423,
        "seek": 107368,
        "start": 1099.3600000000001,
        "temperature": 0,
        "text": " Here's an example one, the train bot.",
        "tokens": [
          51648,
          1692,
          311,
          364,
          1365,
          472,
          11,
          264,
          3847,
          10592,
          13,
          51762
        ]
      },
      {
        "avg_logprob": -0.2580798544534823,
        "compression_ratio": 1.7070063694267517,
        "end": 1103.52,
        "id": 421,
        "no_speech_prob": 0.03904595226049423,
        "seek": 107368,
        "start": 1101.64,
        "temperature": 0,
        "text": " If you issue the command user info,",
        "tokens": [
          51762,
          759,
          291,
          2734,
          264,
          5622,
          4195,
          13614,
          11,
          51856
        ]
      },
      {
        "avg_logprob": -0.27491710060521174,
        "compression_ratio": 1.7636986301369864,
        "end": 1106.16,
        "id": 422,
        "no_speech_prob": 0.00020662861061282456,
        "seek": 110352,
        "start": 1103.6,
        "temperature": 0,
        "text": " it gives you this nice sort of organized table,",
        "tokens": [
          50368,
          309,
          2709,
          291,
          341,
          1481,
          1333,
          295,
          9983,
          3199,
          11,
          50496
        ]
      },
      {
        "avg_logprob": -0.27491710060521174,
        "compression_ratio": 1.7636986301369864,
        "end": 1108.6,
        "id": 423,
        "no_speech_prob": 0.00020662861061282456,
        "seek": 110352,
        "start": 1106.16,
        "temperature": 0,
        "text": " if you will, box of information.",
        "tokens": [
          50496,
          498,
          291,
          486,
          11,
          2424,
          295,
          1589,
          13,
          50618
        ]
      },
      {
        "avg_logprob": -0.27491710060521174,
        "compression_ratio": 1.7636986301369864,
        "end": 1111.48,
        "id": 424,
        "no_speech_prob": 0.00020662861061282456,
        "seek": 110352,
        "start": 1108.6,
        "temperature": 0,
        "text": " Another example of this is if I say,",
        "tokens": [
          50618,
          3996,
          1365,
          295,
          341,
          307,
          498,
          286,
          584,
          11,
          50762
        ]
      },
      {
        "avg_logprob": -0.27491710060521174,
        "compression_ratio": 1.7636986301369864,
        "end": 1113.44,
        "id": 425,
        "no_speech_prob": 0.00020662861061282456,
        "seek": 110352,
        "start": 1111.48,
        "temperature": 0,
        "text": " if I issue the command help, I'll",
        "tokens": [
          50762,
          498,
          286,
          2734,
          264,
          5622,
          854,
          11,
          286,
          603,
          50860
        ]
      },
      {
        "avg_logprob": -0.27491710060521174,
        "compression_ratio": 1.7636986301369864,
        "end": 1116.56,
        "id": 426,
        "no_speech_prob": 0.00020662861061282456,
        "seek": 110352,
        "start": 1113.44,
        "temperature": 0,
        "text": " get a nice explanation of all the kinds of things",
        "tokens": [
          50860,
          483,
          257,
          1481,
          10835,
          295,
          439,
          264,
          3685,
          295,
          721,
          51016
        ]
      },
      {
        "avg_logprob": -0.27491710060521174,
        "compression_ratio": 1.7636986301369864,
        "end": 1118.28,
        "id": 427,
        "no_speech_prob": 0.00020662861061282456,
        "seek": 110352,
        "start": 1116.56,
        "temperature": 0,
        "text": " this bot can do and what the commands are",
        "tokens": [
          51016,
          341,
          10592,
          393,
          360,
          293,
          437,
          264,
          16901,
          366,
          51102
        ]
      },
      {
        "avg_logprob": -0.27491710060521174,
        "compression_ratio": 1.7636986301369864,
        "end": 1119.44,
        "id": 428,
        "no_speech_prob": 0.00020662861061282456,
        "seek": 110352,
        "start": 1118.28,
        "temperature": 0,
        "text": " and tips for using it.",
        "tokens": [
          51102,
          293,
          6082,
          337,
          1228,
          309,
          13,
          51160
        ]
      },
      {
        "avg_logprob": -0.27491710060521174,
        "compression_ratio": 1.7636986301369864,
        "end": 1120.92,
        "id": 429,
        "no_speech_prob": 0.00020662861061282456,
        "seek": 110352,
        "start": 1119.44,
        "temperature": 0,
        "text": " Oh, that's what I should do.",
        "tokens": [
          51160,
          876,
          11,
          300,
          311,
          437,
          286,
          820,
          360,
          13,
          51234
        ]
      },
      {
        "avg_logprob": -0.27491710060521174,
        "compression_ratio": 1.7636986301369864,
        "end": 1123.24,
        "id": 430,
        "no_speech_prob": 0.00020662861061282456,
        "seek": 110352,
        "start": 1120.92,
        "temperature": 0,
        "text": " I'll definitely make, maybe I should make a video on how",
        "tokens": [
          51234,
          286,
          603,
          2138,
          652,
          11,
          1310,
          286,
          820,
          652,
          257,
          960,
          322,
          577,
          51350
        ]
      },
      {
        "avg_logprob": -0.27491710060521174,
        "compression_ratio": 1.7636986301369864,
        "end": 1125.28,
        "id": 431,
        "no_speech_prob": 0.00020662861061282456,
        "seek": 110352,
        "start": 1123.24,
        "temperature": 0,
        "text": " to create an embed with a help command.",
        "tokens": [
          51350,
          281,
          1884,
          364,
          12240,
          365,
          257,
          854,
          5622,
          13,
          51452
        ]
      },
      {
        "avg_logprob": -0.27491710060521174,
        "compression_ratio": 1.7636986301369864,
        "end": 1126.2,
        "id": 432,
        "no_speech_prob": 0.00020662861061282456,
        "seek": 110352,
        "start": 1125.28,
        "temperature": 0,
        "text": " So that'll be perfect.",
        "tokens": [
          51452,
          407,
          300,
          603,
          312,
          2176,
          13,
          51498
        ]
      },
      {
        "avg_logprob": -0.27491710060521174,
        "compression_ratio": 1.7636986301369864,
        "end": 1128.8,
        "id": 433,
        "no_speech_prob": 0.00020662861061282456,
        "seek": 110352,
        "start": 1126.2,
        "temperature": 0,
        "text": " So that'll come maybe in the next video.",
        "tokens": [
          51498,
          407,
          300,
          603,
          808,
          1310,
          294,
          264,
          958,
          960,
          13,
          51628
        ]
      },
      {
        "avg_logprob": -0.27491710060521174,
        "compression_ratio": 1.7636986301369864,
        "end": 1131.8799999999999,
        "id": 434,
        "no_speech_prob": 0.00020662861061282456,
        "seek": 110352,
        "start": 1128.8,
        "temperature": 0,
        "text": " I also, yeah, the next video, maybe the Wordnik API thing.",
        "tokens": [
          51628,
          286,
          611,
          11,
          1338,
          11,
          264,
          958,
          960,
          11,
          1310,
          264,
          8725,
          13123,
          9362,
          551,
          13,
          51782
        ]
      },
      {
        "avg_logprob": -0.31791681360315394,
        "compression_ratio": 1.6185567010309279,
        "end": 1133.16,
        "id": 435,
        "no_speech_prob": 0.00573004549369216,
        "seek": 113188,
        "start": 1131.88,
        "temperature": 0,
        "text": " Leave your suggestions in the comments",
        "tokens": [
          50364,
          9825,
          428,
          13396,
          294,
          264,
          3053,
          50428
        ]
      },
      {
        "avg_logprob": -0.31791681360315394,
        "compression_ratio": 1.6185567010309279,
        "end": 1134.68,
        "id": 436,
        "no_speech_prob": 0.00573004549369216,
        "seek": 113188,
        "start": 1133.16,
        "temperature": 0,
        "text": " if the next video doesn't exist yet,",
        "tokens": [
          50428,
          498,
          264,
          958,
          960,
          1177,
          380,
          2514,
          1939,
          11,
          50504
        ]
      },
      {
        "avg_logprob": -0.31791681360315394,
        "compression_ratio": 1.6185567010309279,
        "end": 1135.8400000000001,
        "id": 437,
        "no_speech_prob": 0.00573004549369216,
        "seek": 113188,
        "start": 1134.68,
        "temperature": 0,
        "text": " because that'll help me figure out",
        "tokens": [
          50504,
          570,
          300,
          603,
          854,
          385,
          2573,
          484,
          50562
        ]
      },
      {
        "avg_logprob": -0.31791681360315394,
        "compression_ratio": 1.6185567010309279,
        "end": 1137.2,
        "id": 438,
        "no_speech_prob": 0.00573004549369216,
        "seek": 113188,
        "start": 1135.8400000000001,
        "temperature": 0,
        "text": " where this journey is taking me.",
        "tokens": [
          50562,
          689,
          341,
          4671,
          307,
          1940,
          385,
          13,
          50630
        ]
      },
      {
        "avg_logprob": -0.31791681360315394,
        "compression_ratio": 1.6185567010309279,
        "end": 1140.2,
        "id": 439,
        "no_speech_prob": 0.00573004549369216,
        "seek": 113188,
        "start": 1137.2,
        "temperature": 0,
        "text": " At some point, I got to stop and just leave the Discord bots",
        "tokens": [
          50630,
          1711,
          512,
          935,
          11,
          286,
          658,
          281,
          1590,
          293,
          445,
          1856,
          264,
          32623,
          35410,
          50780
        ]
      },
      {
        "avg_logprob": -0.31791681360315394,
        "compression_ratio": 1.6185567010309279,
        "end": 1143.0400000000002,
        "id": 440,
        "no_speech_prob": 0.00573004549369216,
        "seek": 113188,
        "start": 1140.2,
        "temperature": 0,
        "text": " alone and see what the universe brings me",
        "tokens": [
          50780,
          3312,
          293,
          536,
          437,
          264,
          6445,
          5607,
          385,
          50922
        ]
      },
      {
        "avg_logprob": -0.31791681360315394,
        "compression_ratio": 1.6185567010309279,
        "end": 1145.5200000000002,
        "id": 441,
        "no_speech_prob": 0.00573004549369216,
        "seek": 113188,
        "start": 1143.0400000000002,
        "temperature": 0,
        "text": " as little Discord bot presents that people are making.",
        "tokens": [
          50922,
          382,
          707,
          32623,
          10592,
          13533,
          300,
          561,
          366,
          1455,
          13,
          51046
        ]
      },
      {
        "avg_logprob": -0.31791681360315394,
        "compression_ratio": 1.6185567010309279,
        "end": 1147.92,
        "id": 442,
        "no_speech_prob": 0.00573004549369216,
        "seek": 113188,
        "start": 1145.5200000000002,
        "temperature": 0,
        "text": " But there are a few more things that I'd like to show you.",
        "tokens": [
          51046,
          583,
          456,
          366,
          257,
          1326,
          544,
          721,
          300,
          286,
          1116,
          411,
          281,
          855,
          291,
          13,
          51166
        ]
      },
      {
        "avg_logprob": -0.31791681360315394,
        "compression_ratio": 1.6185567010309279,
        "end": 1148.92,
        "id": 443,
        "no_speech_prob": 0.00573004549369216,
        "seek": 113188,
        "start": 1147.92,
        "temperature": 0,
        "text": " So stay tuned.",
        "tokens": [
          51166,
          407,
          1754,
          10870,
          13,
          51216
        ]
      },
      {
        "avg_logprob": -0.31791681360315394,
        "compression_ratio": 1.6185567010309279,
        "end": 1150.48,
        "id": 444,
        "no_speech_prob": 0.00573004549369216,
        "seek": 113188,
        "start": 1148.92,
        "temperature": 0,
        "text": " And thanks again for watching.",
        "tokens": [
          51216,
          400,
          3231,
          797,
          337,
          1976,
          13,
          51294
        ]
      },
      {
        "avg_logprob": -0.31791681360315394,
        "compression_ratio": 1.6185567010309279,
        "end": 1153.96,
        "id": 445,
        "no_speech_prob": 0.00573004549369216,
        "seek": 113188,
        "start": 1150.48,
        "temperature": 0,
        "text": " Goodbye, and see you in a future Coding Train video.",
        "tokens": [
          51294,
          15528,
          11,
          293,
          536,
          291,
          294,
          257,
          2027,
          383,
          8616,
          28029,
          960,
          13,
          51468
        ]
      },
      {
        "avg_logprob": -0.31791681360315394,
        "compression_ratio": 1.6185567010309279,
        "end": 1154.46,
        "id": 446,
        "no_speech_prob": 0.00573004549369216,
        "seek": 113188,
        "start": 1153.96,
        "temperature": 0,
        "text": " Oh.",
        "tokens": [
          51468,
          876,
          13,
          51493
        ]
      },
      {
        "avg_logprob": -0.31791681360315394,
        "compression_ratio": 1.6185567010309279,
        "end": 1154.96,
        "id": 447,
        "no_speech_prob": 0.00573004549369216,
        "seek": 113188,
        "start": 1154.46,
        "temperature": 0,
        "text": " Oh.",
        "tokens": [
          51493,
          876,
          13,
          51518
        ]
      },
      {
        "avg_logprob": -0.31791681360315394,
        "compression_ratio": 1.6185567010309279,
        "end": 1155.5600000000002,
        "id": 448,
        "no_speech_prob": 0.00573004549369216,
        "seek": 113188,
        "start": 1154.96,
        "temperature": 0,
        "text": " Oh.",
        "tokens": [
          51518,
          876,
          13,
          51548
        ]
      }
    ],
    "transcription": " Welcome back to another Discord bot tutorial. I'm so excited about this one. So where I last left off, I mean, couldn't possibly left off in a better place where I have a kitten running a unicorn with a rainbow in the background. But I have a bot that does only two things. I say, choo choo to it, and it replies with a random message, choo choo back. I say gif, and maybe I feel like looking at a kitten today, and I get a nice. I'm going to get a unicorn. So how is this working in the code? Well, if I look at the code, I have this lovely if statement. If tokens equals choo choo, else if tokens index 0 equals gif. So this is not a super sustainable method. I mean, if I'm being honest, this is kind of, I would be happy to just stay with this method, add a few more commands, a few more else ifs. But a much more sort of conventional way of building a scalable Discord bot with many, handling many, many commands is to use some kind of command handler framework. And in fact, if you go to the discord.js guide, you'll see an entire page here on command handling. I'm going to use a slightly different method than the one described here, although you certainly could use this one as well. I'm going to follow the methodology that I learned when I was a guest on Coding Garden that CJ showed me. I think it works well, and it's a nice way to handle commands. So you can check out this GitHub repo for another version of the example that I'm going to build right now. And the core idea, if I, looking at the code here that I'm about to write, is that there's almost like nothing here. There's just like creating the Discord client. It's ready. And when there's a message, ah, send the message to this thing called a command handler. And that command handler is required from. slash command. What does that even mean? So this is where I want to start. What does it mean to, in your node program, in your JavaScript file that you've been writing in node, that I've been writing in node, that's only ever been, in my entire life until now, basically, one JavaScript file, how can I pull code that I save and manage in multiple files? This is not unlike what I do very commonly with p5.js. So here's a p5.js sketch of a particle system. And the way that I manage that in client-side JavaScript is have index.html, where I reference multiple JavaScript files. Sketch.js for the main sketch, Particle.js for the particles, System.js for the particle system code. So I want to figure out what is the equivalent of multiple JavaScript files for a node project. And the secret to that is right there in this require function. Now, in truth, require is perhaps going to become outdated as time passes. There are now some, there's now something called an import module that's part of JavaScript. From what I understand, it's an experimental feature in node.js using imports instead of require. So I'm going to stick with require. And then someday in the future, I look forward to your comments that all say about how I should be using import instead of require. Oh, it's going to be great. Pressing forward, step number one, I want to take this entire gotMessage function and just put it in another JavaScript file, because I want to be able to work with it separately from this main index.js file. Or it's called bot.js. I called it bot.js. Creating a new file, I'll call it commands.js. And I've pasted it in. And back in bot.js, you can see there's almost nothing left. Ah, this replies really goes with those commands. So I should also move this over. I mean, ultimately, this might have to go in a different place entirely. But let's take it out of here right now. Then the idea is, could I get this gotMessage function from the other file? And let's call this command handler. I want that to be command handler. And I want to say const command handler equals require. What do I put here? So I'm pretty sure the way that it works is for me to reference the name of the other JavaScript file without.js. However, if I do this, it's actually going to look for a node, a proper node module that's been installed as part of my node modules, like discord.js or node.fetch. So I need to tell it, no, no, no, no. Don't go look in the node modules folder. Look locally. And the way that that is done is with.slash. So I'm done, right? Command handler equals require commands. I get everything in that other file. And now I can just say client.onMessageCommandHandler. No! No, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, stop! I have to add something else. I have to explicitly state inside of this file what I want to make available when it is required. And the way that I do that is saying module.exports. So anything that I put inside of module.exports will be available. So what do I want to make available? This gotMessage function. And there we go. Module.exports equals the function gotMessage. Now, ultimately, I don't need that name of the function anymore. It's irrelevant. Basically, when I say require commands, whatever is in module.exports will now be saved in command handler. So the name of the variable that's holding that function here is command handler. So going back to commands, I can get rid of this. And I think this is all I need to do. Let's hope that my bot still works. Let's try running it again. Appears to be working. Go back to Discord. And voila. Let's check the GIFs because we can't have enough rainbow GIFs. Oh. Ah! Oh, it's not working. The GIFs aren't working. What happened? The fetch is not defined. So guess what? The fetch function is being used here in commands.js. It is not being used here in bot.js. So I will want to bring over this require of the node module node fetch. And there we go. Oh, we have this beautiful cat riding a unicorn with a rainbow GIF again. Now, there's a lot more to say about module.exports. I'm just scratching the surface here. I could set an equal to an object that has multiple properties and multiple functions or use classes and all sorts of other kinds of JavaScript things that I export from a particular JavaScript file. But I'm going to stick with just this basic idea right now and, in fact, take it one step further because still, look, I have this long if statement. Yes, I get to put this if statement in a separate file, but how could I maybe handle these commands more elegantly? And my goal here is to have a separate JavaScript file for every single command. So let's think about, let's maybe add a folder. I'll create a folder called commands. In that folder, let's add a file called choochoo.js and a file called gif.js. Now, I can require both of those. So what goes in those JavaScript files? I'm going to think about this as I'm going. So in choochoo.js, that's the command that returns a random reply. So let's take these two lines of code and just kind of put them in here for safekeeping right now and then also go back to commands.js and take this whole bit of code and put that into gif.js. All right, so I've got the code for sending a gif, and I've got the code for sending a random reply in my separate files. The other thing that I think would be quite helpful here is for me to think more clearly about what's in this variable called tokens. There's really two things. There's the command, that's exclamation point choo choo, exclamation point gif, and then there's the arguments, what comes after that command. So the command is the first token, and it's only a valid command if the first character of it is an exclamation point. And actually, a better way for me to do this would be to actually remove that first token from the array because I don't want it anymore because I want that array left to be the arguments. So let's say tokens.shift. Tokens.shift shifts everything in the array over one spot and removes the first element. So that command is there. If the first character is exclamation point, then also take out that first character, which I can do by using the substring function to go from one to the end of the string. But if I leave out the second argument by default. So this now, I mean, it's a little bit convoluted. I'm sure this could be condensed. But take out the first token, check to see if the first character is exclamation point, and then remove that exclamation point, and I've got the valid command. I can get rid of this stuff now at the bottom. The only thing, the things that might be in the command variable now are choo-choo or GIF. OK, what do I do? What if I have an object, think about this, called commands. And in that object, I have something called choo-choo, which is a function that does something. And I have something called GIF, which is a function that does something. And maybe that function takes arguments. So this object acts as something like a lookup table. Let me look up the function associated with choo-choo. Let me look up the function associated with GIF. So whatever the command is, I can look up the function associated with it in that object and call that function with the tokens, which are the arguments. Oh, boy, doesn't this look terrifying? Let's think about it this way. If I had just said choo-choo tokens and written some function like this, this would probably make sense to you. I'm calling the function choo-choo and passing it the tokens. What am I doing here? I am doing exactly the same thing, only the function isn't just called choo-choo. It's called choo-choo inside of an object called commands. And the term, the lookup term choo-choo, that property name, is inside of the variable called commands. So this is the equivalent of saying commands.choo-choo tokens. However, I can't do that because command is a variable. I've got to pass it in with the square brackets. So you might have to pause the video and think about this for a bit. But hopefully, you're following along with me. And please ask your questions in the comments if this is confusing. So let's build these out a little bit more. And let's just test to see if this system works. Whatever the command that comes in is, I should see a console log in the server. Remember, ultimately, where I'm going is I've got to execute the code that's in another JavaScript file, but I'm not there yet. I just want to have the command come in, look up the function associated with it, and run that function. And this was extra extraneous code that I need to make sure I remove. Back to Discord. I shouldn't see anything here now, but I should see gif and choo-choo. And then if I go back to the server, we see gif and choo-choo. So those functions are being called correctly. All right. And just as a reminder, this extra if statement up here is just because I want this. I'm testing this bot only in one particular channel. So this might not at all be necessary for what you're doing. If I wanted my bot to participate in all the channels of a particular server, I certainly wouldn't have this here. OK. We are getting close now to the end of this demonstration. The big next step is very exciting. Instead of defining the function right here, I want to pull it from that other choo-choo.js file. So first, I need to add module.exports to choo-choo.js. And it's as easy as this. Now, I'm not using the arguments in this. It's just a random reply. And of course, I need to get, I keep moving this around, but I need to get these replies. These are part of this particular command. I'm noticing another major issue that I forgot about. The reply is being sent to the channel associated with the original message. And I don't have access to that message variable here anymore. So I think it would be important for the command handler to also pass that in. So not only send the tokens, the actual tokens, which are the arguments, but send, also pass along that additional message object, which has all of the metadata associated with the message. So adding that as another property here. Let's see. Before I go on to the GIF, let's just see if this works now. Oh, no, it doesn't. It won't. It won't. Why not? I need to replace this function here with the function that I'm getting from choo-choo itself. Now, this is kind of silly, ultimately. When I have a JavaScript object where the property and the value have the same name, I can use, what is that called again? Enhanced object literals. I'm going to leave the GIF out right now. So essentially, this is my list of commands. The function choo-choo is right in there. Let's see if this works. Beautiful. Who shat my bell? Ding. Next step, let's add the GIF command. So now the commands object has two properties, choo-choo and GIF, both coming from two separate JavaScript files. I need to add the module.export stuff to GIF.js. And the arguments. Also, once again, this particular command is using node fetch. So that should no longer be here. Instead, it goes here. And ah, OK. So the key words are no longer coming from the tokens. They're coming from the arguments. And I don't need to slice out the first one, because that's already been done by the original commands function. So this is much simpler now. I can just say args join with a space. And then I think we're good here. Let's try running it. Await is only valid in an async function. Of course. So I need to make sure that this function is modified with the async keyword. Back to Discord, and I hope this works. We already know choo-choo works. Let's try GIF. And let's take a look at some puppies today. Oh, it's not coming. There's an error. Tokens is not defined GIF.js. What did I miss? Aha, I joined the args, but I still checked the length of tokens. So now I just need to check if there are actual arguments and if the length is greater than 0, because again, the command is not part of it anymore. So that should fix it. Back to Discord. Let's see those puppies. Oh, and there we go. It couldn't be a more fitting end to this particular video. So hopefully now, just to recap for a moment, starting back from bot.js, the only thing bot.js does is connect to Discord and then import a command handler function from another JavaScript file. In that command handler JavaScript file, that file imports other JavaScript files, one for each command, stores them in an object, checks to make sure it's a valid message, and then executes the proper function associated with that command. So now if I wanted to add another command, let's say we're going to look up some information about a word. Maybe I'll use the Wordnik API. I definitely want to do an example of a Discord bot that connects to an API. I mean, I am doing that with the Tenor API, but some other API. So if I were to say, define, there's a define command. All I would need to do is add that particular define JavaScript file. That would have to have exactly the same format of a single function that handles the command, does everything it needs. And I would be done. And then I could keep adding more commands. So hopefully, if you watch this particular video and you're making your own bot, try this and try adding some more commands. I should say, however, there is one small potential issue. You might be making a bot where you imagine having 100 plus commands in it. If that's the case, having 100 require statements is maybe not so great. So one of the things you could do is actually read the file system. So if you have this particular commands folder with 100 JavaScript files in it, you can automatically, with the node file system package, just read what all those files are. And then you have all of your commands that way. So actually, the only thing you would need to do to add a new command is just add another JavaScript file that's formatted in the same exact way. Woof. Oh, this is great. This is going to make bot making so much more organized and neat and tidy and all the wonderful things that I love. So this was a little challenging to make this video for you to watch it, perhaps. I hope this makes sense. Ask your questions in the comments. There are more to come. So what have I said so far I want to do? I want to connect to an API just to show another command. I think there were some other things I was thinking of. I'll think of those again. But I do want to show how to work with embeds. Embeds? Embeds? Embeds? I will figure out how to say that word. You've probably seen a Discord bot that shows this kind of replies with this message that's nicely formatted. Here's an example one, the train bot. If you issue the command user info, it gives you this nice sort of organized table, if you will, box of information. Another example of this is if I say, if I issue the command help, I'll get a nice explanation of all the kinds of things this bot can do and what the commands are and tips for using it. Oh, that's what I should do. I'll definitely make, maybe I should make a video on how to create an embed with a help command. So that'll be perfect. So that'll come maybe in the next video. I also, yeah, the next video, maybe the Wordnik API thing. Leave your suggestions in the comments if the next video doesn't exist yet, because that'll help me figure out where this journey is taking me. At some point, I got to stop and just leave the Discord bots alone and see what the universe brings me as little Discord bot presents that people are making. But there are a few more things that I'd like to show you. So stay tuned. And thanks again for watching. Goodbye, and see you in a future Coding Train video. Oh. Oh. Oh.",
    "translation": null
  },
  "error": null,
  "status": "succeeded",
  "created_at": "2023-09-26T21:03:57.504285Z",
  "started_at": "2023-09-26T21:24:33.065686Z",
  "completed_at": "2023-09-26T21:30:02.091685Z",
  "webhook": "https://83ceaa0b612c.ngrok.app/?video_id=B60Q74FHFBQ",
  "webhook_events_filter": [
    "completed"
  ],
  "metrics": {
    "predict_time": 329.025999
  },
  "urls": {
    "cancel": "https://api.replicate.com/v1/predictions/fyh6cbrboiskr5zpja6sek4jea/cancel",
    "get": "https://api.replicate.com/v1/predictions/fyh6cbrboiskr5zpja6sek4jea"
  }
}