{
  "id": "6ti6fpzb3wom4swe5x6aw6koca",
  "version": "91ee9c0c3df30478510ff8c8a3a545add1ad0259ad3a9f78fba57fbc05ee64f7",
  "input": {
    "audio": "https://upcdn.io/FW25b4F/raw/coding-train/JtIX3HJKwfo.m4a"
  },
  "logs": "Transcribe with large-v2 model\nDetected language: English\n  0%|          | 0/52818 [00:00<?, ?frames/s]\n  5%|▌         | 2700/52818 [00:07<02:15, 371.12frames/s]\n 10%|█         | 5400/52818 [00:15<02:13, 354.54frames/s]\n 16%|█▌        | 8200/52818 [00:22<02:02, 364.94frames/s]\n 20%|██        | 10800/52818 [00:29<01:52, 374.76frames/s]\n 25%|██▌       | 13400/52818 [00:34<01:37, 404.89frames/s]\n 31%|███       | 16300/52818 [00:43<01:35, 381.28frames/s]\n 36%|███▋      | 19200/52818 [00:52<01:35, 351.04frames/s]\n 42%|████▏     | 22000/52818 [01:01<01:30, 340.31frames/s]\n 47%|████▋     | 24900/52818 [01:09<01:20, 346.79frames/s]\n 51%|█████▏    | 27100/52818 [01:17<01:18, 326.09frames/s]\n 57%|█████▋    | 29900/52818 [01:21<00:58, 392.25frames/s]\n 62%|██████▏   | 32600/52818 [01:30<00:57, 354.27frames/s]\n 67%|██████▋   | 35400/52818 [01:40<00:53, 324.76frames/s]\n 72%|███████▏  | 38200/52818 [01:47<00:42, 347.72frames/s]\n 78%|███████▊  | 41000/52818 [01:56<00:34, 342.55frames/s]\n 83%|████████▎ | 43600/52818 [02:03<00:26, 343.26frames/s]\n 88%|████████▊ | 46400/52818 [02:11<00:18, 347.80frames/s]\n 93%|█████████▎| 48900/52818 [02:17<00:10, 367.56frames/s]\n 98%|█████████▊| 51700/52818 [02:24<00:03, 367.89frames/s]\n100%|██████████| 52818/52818 [02:26<00:00, 393.37frames/s]\n100%|██████████| 52818/52818 [02:26<00:00, 360.41frames/s]\n",
  "output": {
    "detected_language": "english",
    "segments": [
      {
        "avg_logprob": -0.28962165618611274,
        "compression_ratio": 1.696,
        "end": 5,
        "id": 0,
        "no_speech_prob": 0.01098151970654726,
        "seek": 0,
        "start": 0,
        "temperature": 0,
        "text": " Hello, surprise! It's a video about Git and GitHub.",
        "tokens": [
          50364,
          2425,
          11,
          6365,
          0,
          467,
          311,
          257,
          960,
          466,
          16939,
          293,
          23331,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.28962165618611274,
        "compression_ratio": 1.696,
        "end": 9,
        "id": 1,
        "no_speech_prob": 0.01098151970654726,
        "seek": 0,
        "start": 5,
        "temperature": 0,
        "text": " And this video is about resolving merge conflicts.",
        "tokens": [
          50614,
          400,
          341,
          960,
          307,
          466,
          49940,
          22183,
          19807,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.28962165618611274,
        "compression_ratio": 1.696,
        "end": 13,
        "id": 2,
        "no_speech_prob": 0.01098151970654726,
        "seek": 0,
        "start": 9,
        "temperature": 0,
        "text": " So I probably should be doing this video in my poem repository,",
        "tokens": [
          50814,
          407,
          286,
          1391,
          820,
          312,
          884,
          341,
          960,
          294,
          452,
          13065,
          25841,
          11,
          51014
        ]
      },
      {
        "avg_logprob": -0.28962165618611274,
        "compression_ratio": 1.696,
        "end": 17,
        "id": 3,
        "no_speech_prob": 0.01098151970654726,
        "seek": 0,
        "start": 13,
        "temperature": 0,
        "text": " which I use for all of my intro to Git and GitHub videos,",
        "tokens": [
          51014,
          597,
          286,
          764,
          337,
          439,
          295,
          452,
          12897,
          281,
          16939,
          293,
          23331,
          2145,
          11,
          51214
        ]
      },
      {
        "avg_logprob": -0.28962165618611274,
        "compression_ratio": 1.696,
        "end": 22,
        "id": 4,
        "no_speech_prob": 0.01098151970654726,
        "seek": 0,
        "start": 17,
        "temperature": 0,
        "text": " but I happen to be here, streaming live, and working on this neural network library",
        "tokens": [
          51214,
          457,
          286,
          1051,
          281,
          312,
          510,
          11,
          11791,
          1621,
          11,
          293,
          1364,
          322,
          341,
          18161,
          3209,
          6405,
          51464
        ]
      },
      {
        "avg_logprob": -0.28962165618611274,
        "compression_ratio": 1.696,
        "end": 24,
        "id": 5,
        "no_speech_prob": 0.01098151970654726,
        "seek": 0,
        "start": 22,
        "temperature": 0,
        "text": " that I've been building in a bunch of other video tutorials.",
        "tokens": [
          51464,
          300,
          286,
          600,
          668,
          2390,
          294,
          257,
          3840,
          295,
          661,
          960,
          17616,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.28962165618611274,
        "compression_ratio": 1.696,
        "end": 27,
        "id": 6,
        "no_speech_prob": 0.01098151970654726,
        "seek": 0,
        "start": 24,
        "temperature": 0,
        "text": " So if you've just watched those Git and GitHub videos,",
        "tokens": [
          51564,
          407,
          498,
          291,
          600,
          445,
          6337,
          729,
          16939,
          293,
          23331,
          2145,
          11,
          51714
        ]
      },
      {
        "avg_logprob": -0.173426385653221,
        "compression_ratio": 1.6447876447876448,
        "end": 31,
        "id": 7,
        "no_speech_prob": 0.09135700762271881,
        "seek": 2700,
        "start": 27,
        "temperature": 0,
        "text": " all about using a poem to sort of demonstrate how Git and GitHub works,",
        "tokens": [
          50364,
          439,
          466,
          1228,
          257,
          13065,
          281,
          1333,
          295,
          11698,
          577,
          16939,
          293,
          23331,
          1985,
          11,
          50564
        ]
      },
      {
        "avg_logprob": -0.173426385653221,
        "compression_ratio": 1.6447876447876448,
        "end": 33,
        "id": 8,
        "no_speech_prob": 0.09135700762271881,
        "seek": 2700,
        "start": 31,
        "temperature": 0,
        "text": " there will be some aspects of this that are confusing,",
        "tokens": [
          50564,
          456,
          486,
          312,
          512,
          7270,
          295,
          341,
          300,
          366,
          13181,
          11,
          50664
        ]
      },
      {
        "avg_logprob": -0.173426385653221,
        "compression_ratio": 1.6447876447876448,
        "end": 35,
        "id": 9,
        "no_speech_prob": 0.09135700762271881,
        "seek": 2700,
        "start": 33,
        "temperature": 0,
        "text": " but hopefully this will be helpful anyway,",
        "tokens": [
          50664,
          457,
          4696,
          341,
          486,
          312,
          4961,
          4033,
          11,
          50764
        ]
      },
      {
        "avg_logprob": -0.173426385653221,
        "compression_ratio": 1.6447876447876448,
        "end": 38,
        "id": 10,
        "no_speech_prob": 0.09135700762271881,
        "seek": 2700,
        "start": 35,
        "temperature": 0,
        "text": " and I can always double back and make another video if this one doesn't work.",
        "tokens": [
          50764,
          293,
          286,
          393,
          1009,
          3834,
          646,
          293,
          652,
          1071,
          960,
          498,
          341,
          472,
          1177,
          380,
          589,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.173426385653221,
        "compression_ratio": 1.6447876447876448,
        "end": 39,
        "id": 11,
        "no_speech_prob": 0.09135700762271881,
        "seek": 2700,
        "start": 38,
        "temperature": 0,
        "text": " But let's just try it.",
        "tokens": [
          50914,
          583,
          718,
          311,
          445,
          853,
          309,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.173426385653221,
        "compression_ratio": 1.6447876447876448,
        "end": 41,
        "id": 12,
        "no_speech_prob": 0.09135700762271881,
        "seek": 2700,
        "start": 39,
        "temperature": 0,
        "text": " So what is a merge conflict, first of all?",
        "tokens": [
          50964,
          407,
          437,
          307,
          257,
          22183,
          6596,
          11,
          700,
          295,
          439,
          30,
          51064
        ]
      },
      {
        "avg_logprob": -0.173426385653221,
        "compression_ratio": 1.6447876447876448,
        "end": 48,
        "id": 13,
        "no_speech_prob": 0.09135700762271881,
        "seek": 2700,
        "start": 41,
        "temperature": 0,
        "text": " So a merge conflict is when you have, let's say, this is a file,",
        "tokens": [
          51064,
          407,
          257,
          22183,
          6596,
          307,
          562,
          291,
          362,
          11,
          718,
          311,
          584,
          11,
          341,
          307,
          257,
          3991,
          11,
          51414
        ]
      },
      {
        "avg_logprob": -0.173426385653221,
        "compression_ratio": 1.6447876447876448,
        "end": 54,
        "id": 14,
        "no_speech_prob": 0.09135700762271881,
        "seek": 2700,
        "start": 48,
        "temperature": 0,
        "text": " and in this case it's my file called matrix.js.",
        "tokens": [
          51414,
          293,
          294,
          341,
          1389,
          309,
          311,
          452,
          3991,
          1219,
          8141,
          13,
          25530,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.16316531788219105,
        "compression_ratio": 1.714975845410628,
        "end": 59,
        "id": 15,
        "no_speech_prob": 0.000698644551448524,
        "seek": 5400,
        "start": 54,
        "temperature": 0,
        "text": " So I have a file called matrix.js, and it has code in it.",
        "tokens": [
          50364,
          407,
          286,
          362,
          257,
          3991,
          1219,
          8141,
          13,
          25530,
          11,
          293,
          309,
          575,
          3089,
          294,
          309,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.16316531788219105,
        "compression_ratio": 1.714975845410628,
        "end": 64,
        "id": 16,
        "no_speech_prob": 0.000698644551448524,
        "seek": 5400,
        "start": 59,
        "temperature": 0,
        "text": " Now, I had two people, two separate people of the internet,",
        "tokens": [
          50614,
          823,
          11,
          286,
          632,
          732,
          561,
          11,
          732,
          4994,
          561,
          295,
          264,
          4705,
          11,
          50864
        ]
      },
      {
        "avg_logprob": -0.16316531788219105,
        "compression_ratio": 1.714975845410628,
        "end": 67,
        "id": 17,
        "no_speech_prob": 0.000698644551448524,
        "seek": 5400,
        "start": 64,
        "temperature": 0,
        "text": " happen to be working on this file.",
        "tokens": [
          50864,
          1051,
          281,
          312,
          1364,
          322,
          341,
          3991,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.16316531788219105,
        "compression_ratio": 1.714975845410628,
        "end": 73,
        "id": 18,
        "no_speech_prob": 0.000698644551448524,
        "seek": 5400,
        "start": 67,
        "temperature": 0,
        "text": " So we'll call one person A, and one person B.",
        "tokens": [
          51014,
          407,
          321,
          603,
          818,
          472,
          954,
          316,
          11,
          293,
          472,
          954,
          363,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.16316531788219105,
        "compression_ratio": 1.714975845410628,
        "end": 76,
        "id": 19,
        "no_speech_prob": 0.000698644551448524,
        "seek": 5400,
        "start": 73,
        "temperature": 0,
        "text": " Now, any text file has lines in it.",
        "tokens": [
          51314,
          823,
          11,
          604,
          2487,
          3991,
          575,
          3876,
          294,
          309,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.16316531788219105,
        "compression_ratio": 1.714975845410628,
        "end": 79,
        "id": 20,
        "no_speech_prob": 0.000698644551448524,
        "seek": 5400,
        "start": 76,
        "temperature": 0,
        "text": " So even if it were a poem, it would have lines of the poem.",
        "tokens": [
          51464,
          407,
          754,
          498,
          309,
          645,
          257,
          13065,
          11,
          309,
          576,
          362,
          3876,
          295,
          264,
          13065,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.16316531788219105,
        "compression_ratio": 1.714975845410628,
        "end": 82,
        "id": 21,
        "no_speech_prob": 0.000698644551448524,
        "seek": 5400,
        "start": 79,
        "temperature": 0,
        "text": " If it's a source code file, it has lines of the source code.",
        "tokens": [
          51614,
          759,
          309,
          311,
          257,
          4009,
          3089,
          3991,
          11,
          309,
          575,
          3876,
          295,
          264,
          4009,
          3089,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.17750777030477718,
        "compression_ratio": 1.5870646766169154,
        "end": 86,
        "id": 22,
        "no_speech_prob": 0.00008481005352223292,
        "seek": 8200,
        "start": 82,
        "temperature": 0,
        "text": " So we can think of the lines as like 1, 2, 3, 4, 5, 6.",
        "tokens": [
          50364,
          407,
          321,
          393,
          519,
          295,
          264,
          3876,
          382,
          411,
          502,
          11,
          568,
          11,
          805,
          11,
          1017,
          11,
          1025,
          11,
          1386,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.17750777030477718,
        "compression_ratio": 1.5870646766169154,
        "end": 93,
        "id": 23,
        "no_speech_prob": 0.00008481005352223292,
        "seek": 8200,
        "start": 86,
        "temperature": 0,
        "text": " Now, if person A makes a change and submits a pull request,",
        "tokens": [
          50564,
          823,
          11,
          498,
          954,
          316,
          1669,
          257,
          1319,
          293,
          8286,
          1208,
          257,
          2235,
          5308,
          11,
          50914
        ]
      },
      {
        "avg_logprob": -0.17750777030477718,
        "compression_ratio": 1.5870646766169154,
        "end": 98,
        "id": 24,
        "no_speech_prob": 0.00008481005352223292,
        "seek": 8200,
        "start": 93,
        "temperature": 0,
        "text": " meaning, hey, hey, you the library, please pull my changes, right?",
        "tokens": [
          50914,
          3620,
          11,
          4177,
          11,
          4177,
          11,
          291,
          264,
          6405,
          11,
          1767,
          2235,
          452,
          2962,
          11,
          558,
          30,
          51164
        ]
      },
      {
        "avg_logprob": -0.17750777030477718,
        "compression_ratio": 1.5870646766169154,
        "end": 103,
        "id": 25,
        "no_speech_prob": 0.00008481005352223292,
        "seek": 8200,
        "start": 98,
        "temperature": 0,
        "text": " I want to push my changes to you, but I'm asking, requesting that you pull my changes.",
        "tokens": [
          51164,
          286,
          528,
          281,
          2944,
          452,
          2962,
          281,
          291,
          11,
          457,
          286,
          478,
          3365,
          11,
          31937,
          300,
          291,
          2235,
          452,
          2962,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.17750777030477718,
        "compression_ratio": 1.5870646766169154,
        "end": 108,
        "id": 26,
        "no_speech_prob": 0.00008481005352223292,
        "seek": 8200,
        "start": 103,
        "temperature": 0,
        "text": " If this person just made changes to lines 5 and 6,",
        "tokens": [
          51414,
          759,
          341,
          954,
          445,
          1027,
          2962,
          281,
          3876,
          1025,
          293,
          1386,
          11,
          51664
        ]
      },
      {
        "avg_logprob": -0.2236678628360524,
        "compression_ratio": 1.634517766497462,
        "end": 115,
        "id": 27,
        "no_speech_prob": 0.03258799389004707,
        "seek": 10800,
        "start": 108,
        "temperature": 0,
        "text": " and this person just made changes to lines 2 and 3,",
        "tokens": [
          50364,
          293,
          341,
          954,
          445,
          1027,
          2962,
          281,
          3876,
          568,
          293,
          805,
          11,
          50714
        ]
      },
      {
        "avg_logprob": -0.2236678628360524,
        "compression_ratio": 1.634517766497462,
        "end": 122,
        "id": 28,
        "no_speech_prob": 0.03258799389004707,
        "seek": 10800,
        "start": 115,
        "temperature": 0,
        "text": " the git system is smart enough to figure out how to pull both of these things in with no conflicts.",
        "tokens": [
          50714,
          264,
          18331,
          1185,
          307,
          4069,
          1547,
          281,
          2573,
          484,
          577,
          281,
          2235,
          1293,
          295,
          613,
          721,
          294,
          365,
          572,
          19807,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.2236678628360524,
        "compression_ratio": 1.634517766497462,
        "end": 124,
        "id": 29,
        "no_speech_prob": 0.03258799389004707,
        "seek": 10800,
        "start": 122,
        "temperature": 0,
        "text": " Because there are no conflicts.",
        "tokens": [
          51064,
          1436,
          456,
          366,
          572,
          19807,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.2236678628360524,
        "compression_ratio": 1.634517766497462,
        "end": 128,
        "id": 30,
        "no_speech_prob": 0.03258799389004707,
        "seek": 10800,
        "start": 124,
        "temperature": 0,
        "text": " If I want to accept changes to lines 2 and 3, I can accept those at the same time,",
        "tokens": [
          51164,
          759,
          286,
          528,
          281,
          3241,
          2962,
          281,
          3876,
          568,
          293,
          805,
          11,
          286,
          393,
          3241,
          729,
          412,
          264,
          912,
          565,
          11,
          51364
        ]
      },
      {
        "avg_logprob": -0.2236678628360524,
        "compression_ratio": 1.634517766497462,
        "end": 134,
        "id": 31,
        "no_speech_prob": 0.03258799389004707,
        "seek": 10800,
        "start": 128,
        "temperature": 0,
        "text": " one before the other, simultaneously, as lines 5 and 6.",
        "tokens": [
          51364,
          472,
          949,
          264,
          661,
          11,
          16561,
          11,
          382,
          3876,
          1025,
          293,
          1386,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.1900114397848806,
        "compression_ratio": 1.7692307692307692,
        "end": 140,
        "id": 32,
        "no_speech_prob": 0.0021156135480850935,
        "seek": 13400,
        "start": 134,
        "temperature": 0,
        "text": " However, if right here, person B makes a change to line 4,",
        "tokens": [
          50364,
          2908,
          11,
          498,
          558,
          510,
          11,
          954,
          363,
          1669,
          257,
          1319,
          281,
          1622,
          1017,
          11,
          50664
        ]
      },
      {
        "avg_logprob": -0.1900114397848806,
        "compression_ratio": 1.7692307692307692,
        "end": 143,
        "id": 33,
        "no_speech_prob": 0.0021156135480850935,
        "seek": 13400,
        "start": 140,
        "temperature": 0,
        "text": " and person A also makes a change to line 4,",
        "tokens": [
          50664,
          293,
          954,
          316,
          611,
          1669,
          257,
          1319,
          281,
          1622,
          1017,
          11,
          50814
        ]
      },
      {
        "avg_logprob": -0.1900114397848806,
        "compression_ratio": 1.7692307692307692,
        "end": 146,
        "id": 34,
        "no_speech_prob": 0.0021156135480850935,
        "seek": 13400,
        "start": 143,
        "temperature": 0,
        "text": " then we have what's known as a conflict.",
        "tokens": [
          50814,
          550,
          321,
          362,
          437,
          311,
          2570,
          382,
          257,
          6596,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.1900114397848806,
        "compression_ratio": 1.7692307692307692,
        "end": 149,
        "id": 35,
        "no_speech_prob": 0.0021156135480850935,
        "seek": 13400,
        "start": 146,
        "temperature": 0,
        "text": " And typically, what will happen, what just happened to me right now,",
        "tokens": [
          50964,
          400,
          5850,
          11,
          437,
          486,
          1051,
          11,
          437,
          445,
          2011,
          281,
          385,
          558,
          586,
          11,
          51114
        ]
      },
      {
        "avg_logprob": -0.1900114397848806,
        "compression_ratio": 1.7692307692307692,
        "end": 151,
        "id": 36,
        "no_speech_prob": 0.0021156135480850935,
        "seek": 13400,
        "start": 149,
        "temperature": 0,
        "text": " is I merged this one.",
        "tokens": [
          51114,
          307,
          286,
          36427,
          341,
          472,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.1900114397848806,
        "compression_ratio": 1.7692307692307692,
        "end": 155,
        "id": 37,
        "no_speech_prob": 0.0021156135480850935,
        "seek": 13400,
        "start": 151,
        "temperature": 0,
        "text": " I merged this one, wasn't thinking about it, it was done, it's finished,",
        "tokens": [
          51214,
          286,
          36427,
          341,
          472,
          11,
          2067,
          380,
          1953,
          466,
          309,
          11,
          309,
          390,
          1096,
          11,
          309,
          311,
          4335,
          11,
          51414
        ]
      },
      {
        "avg_logprob": -0.1900114397848806,
        "compression_ratio": 1.7692307692307692,
        "end": 158,
        "id": 38,
        "no_speech_prob": 0.0021156135480850935,
        "seek": 13400,
        "start": 155,
        "temperature": 0,
        "text": " and it worked fine. It merged with no problems.",
        "tokens": [
          51414,
          293,
          309,
          2732,
          2489,
          13,
          467,
          36427,
          365,
          572,
          2740,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.1900114397848806,
        "compression_ratio": 1.7692307692307692,
        "end": 163,
        "id": 39,
        "no_speech_prob": 0.0021156135480850935,
        "seek": 13400,
        "start": 158,
        "temperature": 0,
        "text": " But now when I went to merge this one, I got a message saying, resolve conflicts.",
        "tokens": [
          51564,
          583,
          586,
          562,
          286,
          1437,
          281,
          22183,
          341,
          472,
          11,
          286,
          658,
          257,
          3636,
          1566,
          11,
          14151,
          19807,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.20617220951960638,
        "compression_ratio": 1.684375,
        "end": 167,
        "id": 40,
        "no_speech_prob": 0.024421120062470436,
        "seek": 16300,
        "start": 163,
        "temperature": 0,
        "text": " Now there are a variety of ways you can resolve conflicts,",
        "tokens": [
          50364,
          823,
          456,
          366,
          257,
          5673,
          295,
          2098,
          291,
          393,
          14151,
          19807,
          11,
          50564
        ]
      },
      {
        "avg_logprob": -0.20617220951960638,
        "compression_ratio": 1.684375,
        "end": 170,
        "id": 41,
        "no_speech_prob": 0.024421120062470436,
        "seek": 16300,
        "start": 167,
        "temperature": 0,
        "text": " and I think that I've, in some of my previous tutorials,",
        "tokens": [
          50564,
          293,
          286,
          519,
          300,
          286,
          600,
          11,
          294,
          512,
          295,
          452,
          3894,
          17616,
          11,
          50714
        ]
      },
      {
        "avg_logprob": -0.20617220951960638,
        "compression_ratio": 1.684375,
        "end": 174,
        "id": 42,
        "no_speech_prob": 0.024421120062470436,
        "seek": 16300,
        "start": 170,
        "temperature": 0,
        "text": " looked at working with git command line locally, and I could have the text file there,",
        "tokens": [
          50714,
          2956,
          412,
          1364,
          365,
          18331,
          5622,
          1622,
          16143,
          11,
          293,
          286,
          727,
          362,
          264,
          2487,
          3991,
          456,
          11,
          50914
        ]
      },
      {
        "avg_logprob": -0.20617220951960638,
        "compression_ratio": 1.684375,
        "end": 180,
        "id": 43,
        "no_speech_prob": 0.024421120062470436,
        "seek": 16300,
        "start": 174,
        "temperature": 0,
        "text": " but what I'm going to do is see if I can resolve the conflict just through the github interface itself.",
        "tokens": [
          50914,
          457,
          437,
          286,
          478,
          516,
          281,
          360,
          307,
          536,
          498,
          286,
          393,
          14151,
          264,
          6596,
          445,
          807,
          264,
          290,
          355,
          836,
          9226,
          2564,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.20617220951960638,
        "compression_ratio": 1.684375,
        "end": 182,
        "id": 44,
        "no_speech_prob": 0.024421120062470436,
        "seek": 16300,
        "start": 180,
        "temperature": 0,
        "text": " So let's take a look at how that works.",
        "tokens": [
          51214,
          407,
          718,
          311,
          747,
          257,
          574,
          412,
          577,
          300,
          1985,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.20617220951960638,
        "compression_ratio": 1.684375,
        "end": 185,
        "id": 45,
        "no_speech_prob": 0.024421120062470436,
        "seek": 16300,
        "start": 182,
        "temperature": 0,
        "text": " Now, once again, this isn't the best scenario,",
        "tokens": [
          51314,
          823,
          11,
          1564,
          797,
          11,
          341,
          1943,
          380,
          264,
          1151,
          9005,
          11,
          51464
        ]
      },
      {
        "avg_logprob": -0.20617220951960638,
        "compression_ratio": 1.684375,
        "end": 187,
        "id": 46,
        "no_speech_prob": 0.024421120062470436,
        "seek": 16300,
        "start": 185,
        "temperature": 0,
        "text": " and I might come back and do a follow-up,",
        "tokens": [
          51464,
          293,
          286,
          1062,
          808,
          646,
          293,
          360,
          257,
          1524,
          12,
          1010,
          11,
          51564
        ]
      },
      {
        "avg_logprob": -0.20617220951960638,
        "compression_ratio": 1.684375,
        "end": 192,
        "id": 47,
        "no_speech_prob": 0.024421120062470436,
        "seek": 16300,
        "start": 187,
        "temperature": 0,
        "text": " because it would be nice to see kind of a trivial example where I can really know what the changes are,",
        "tokens": [
          51564,
          570,
          309,
          576,
          312,
          1481,
          281,
          536,
          733,
          295,
          257,
          26703,
          1365,
          689,
          286,
          393,
          534,
          458,
          437,
          264,
          2962,
          366,
          11,
          51814
        ]
      },
      {
        "avg_logprob": -0.19812086118873976,
        "compression_ratio": 1.8639705882352942,
        "end": 195,
        "id": 48,
        "no_speech_prob": 0.010651547461748123,
        "seek": 19200,
        "start": 192,
        "temperature": 0,
        "text": " but I'm just going to look and see, there's a whole discussion here,",
        "tokens": [
          50364,
          457,
          286,
          478,
          445,
          516,
          281,
          574,
          293,
          536,
          11,
          456,
          311,
          257,
          1379,
          5017,
          510,
          11,
          50514
        ]
      },
      {
        "avg_logprob": -0.19812086118873976,
        "compression_ratio": 1.8639705882352942,
        "end": 197,
        "id": 49,
        "no_speech_prob": 0.010651547461748123,
        "seek": 19200,
        "start": 195,
        "temperature": 0,
        "text": " and we can see these are the files.",
        "tokens": [
          50514,
          293,
          321,
          393,
          536,
          613,
          366,
          264,
          7098,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.19812086118873976,
        "compression_ratio": 1.8639705882352942,
        "end": 199,
        "id": 50,
        "no_speech_prob": 0.010651547461748123,
        "seek": 19200,
        "start": 197,
        "temperature": 0,
        "text": " These are the files that have conflicts in them.",
        "tokens": [
          50614,
          1981,
          366,
          264,
          7098,
          300,
          362,
          19807,
          294,
          552,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.19812086118873976,
        "compression_ratio": 1.8639705882352942,
        "end": 201,
        "id": 51,
        "no_speech_prob": 0.010651547461748123,
        "seek": 19200,
        "start": 199,
        "temperature": 0,
        "text": " Matrix.js and Matrix.test.js.",
        "tokens": [
          50714,
          36274,
          13,
          25530,
          293,
          36274,
          13,
          31636,
          13,
          25530,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.19812086118873976,
        "compression_ratio": 1.8639705882352942,
        "end": 203,
        "id": 52,
        "no_speech_prob": 0.010651547461748123,
        "seek": 19200,
        "start": 201,
        "temperature": 0,
        "text": " So hopefully you can continue to watch this,",
        "tokens": [
          50814,
          407,
          4696,
          291,
          393,
          2354,
          281,
          1159,
          341,
          11,
          50914
        ]
      },
      {
        "avg_logprob": -0.19812086118873976,
        "compression_ratio": 1.8639705882352942,
        "end": 206,
        "id": 53,
        "no_speech_prob": 0.010651547461748123,
        "seek": 19200,
        "start": 203,
        "temperature": 0,
        "text": " even if you don't understand what the code in those files is doing.",
        "tokens": [
          50914,
          754,
          498,
          291,
          500,
          380,
          1223,
          437,
          264,
          3089,
          294,
          729,
          7098,
          307,
          884,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.19812086118873976,
        "compression_ratio": 1.8639705882352942,
        "end": 209,
        "id": 54,
        "no_speech_prob": 0.010651547461748123,
        "seek": 19200,
        "start": 206,
        "temperature": 0,
        "text": " I'm going to look and see what the conflicts are.",
        "tokens": [
          51064,
          286,
          478,
          516,
          281,
          574,
          293,
          536,
          437,
          264,
          19807,
          366,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.19812086118873976,
        "compression_ratio": 1.8639705882352942,
        "end": 215,
        "id": 55,
        "no_speech_prob": 0.010651547461748123,
        "seek": 19200,
        "start": 209,
        "temperature": 0,
        "text": " Oh, this is definitely going to go down the internet tubes really quickly.",
        "tokens": [
          51214,
          876,
          11,
          341,
          307,
          2138,
          516,
          281,
          352,
          760,
          264,
          4705,
          21458,
          534,
          2661,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.19812086118873976,
        "compression_ratio": 1.8639705882352942,
        "end": 218,
        "id": 56,
        "no_speech_prob": 0.010651547461748123,
        "seek": 19200,
        "start": 215,
        "temperature": 0,
        "text": " So I'm going to click this resolve conflicts button,",
        "tokens": [
          51514,
          407,
          286,
          478,
          516,
          281,
          2052,
          341,
          14151,
          19807,
          2960,
          11,
          51664
        ]
      },
      {
        "avg_logprob": -0.19812086118873976,
        "compression_ratio": 1.8639705882352942,
        "end": 220,
        "id": 57,
        "no_speech_prob": 0.010651547461748123,
        "seek": 19200,
        "start": 218,
        "temperature": 0,
        "text": " and now it's, ooh, look at this.",
        "tokens": [
          51664,
          293,
          586,
          309,
          311,
          11,
          17024,
          11,
          574,
          412,
          341,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.1996484224488135,
        "compression_ratio": 1.948616600790514,
        "end": 222,
        "id": 58,
        "no_speech_prob": 0.00955913681536913,
        "seek": 22000,
        "start": 220,
        "temperature": 0,
        "text": " Ooh, okay, all right.",
        "tokens": [
          50364,
          7951,
          11,
          1392,
          11,
          439,
          558,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.1996484224488135,
        "compression_ratio": 1.948616600790514,
        "end": 224,
        "id": 59,
        "no_speech_prob": 0.00955913681536913,
        "seek": 22000,
        "start": 222,
        "temperature": 0,
        "text": " Oh, I'm in Matrix.js.",
        "tokens": [
          50464,
          876,
          11,
          286,
          478,
          294,
          36274,
          13,
          25530,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.1996484224488135,
        "compression_ratio": 1.948616600790514,
        "end": 226,
        "id": 60,
        "no_speech_prob": 0.00955913681536913,
        "seek": 22000,
        "start": 224,
        "temperature": 0,
        "text": " Hmm, okay, I have to figure out what's going on here.",
        "tokens": [
          50564,
          8239,
          11,
          1392,
          11,
          286,
          362,
          281,
          2573,
          484,
          437,
          311,
          516,
          322,
          510,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.1996484224488135,
        "compression_ratio": 1.948616600790514,
        "end": 229,
        "id": 61,
        "no_speech_prob": 0.00955913681536913,
        "seek": 22000,
        "start": 226,
        "temperature": 0,
        "text": " So we can see, ah, look, this is where the conflict is.",
        "tokens": [
          50664,
          407,
          321,
          393,
          536,
          11,
          3716,
          11,
          574,
          11,
          341,
          307,
          689,
          264,
          6596,
          307,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.1996484224488135,
        "compression_ratio": 1.948616600790514,
        "end": 232,
        "id": 62,
        "no_speech_prob": 0.00955913681536913,
        "seek": 22000,
        "start": 229,
        "temperature": 0,
        "text": " Oh, look, I think I know how to resolve this.",
        "tokens": [
          50814,
          876,
          11,
          574,
          11,
          286,
          519,
          286,
          458,
          577,
          281,
          14151,
          341,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.1996484224488135,
        "compression_ratio": 1.948616600790514,
        "end": 236,
        "id": 63,
        "no_speech_prob": 0.00955913681536913,
        "seek": 22000,
        "start": 232,
        "temperature": 0,
        "text": " Okay, so this is where the conflict is.",
        "tokens": [
          50964,
          1033,
          11,
          370,
          341,
          307,
          689,
          264,
          6596,
          307,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.1996484224488135,
        "compression_ratio": 1.948616600790514,
        "end": 238,
        "id": 64,
        "no_speech_prob": 0.00955913681536913,
        "seek": 22000,
        "start": 236,
        "temperature": 0,
        "text": " Now, what is it telling me here?",
        "tokens": [
          51164,
          823,
          11,
          437,
          307,
          309,
          3585,
          385,
          510,
          30,
          51264
        ]
      },
      {
        "avg_logprob": -0.1996484224488135,
        "compression_ratio": 1.948616600790514,
        "end": 244,
        "id": 65,
        "no_speech_prob": 0.00955913681536913,
        "seek": 22000,
        "start": 238,
        "temperature": 0,
        "text": " Map improvements, master, equals, equals, equals, equals, greater than, greater than, greater than, greater than.",
        "tokens": [
          51264,
          22053,
          13797,
          11,
          4505,
          11,
          6915,
          11,
          6915,
          11,
          6915,
          11,
          6915,
          11,
          5044,
          813,
          11,
          5044,
          813,
          11,
          5044,
          813,
          11,
          5044,
          813,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.1996484224488135,
        "compression_ratio": 1.948616600790514,
        "end": 249,
        "id": 66,
        "no_speech_prob": 0.00955913681536913,
        "seek": 22000,
        "start": 244,
        "temperature": 0,
        "text": " So what this is showing me is, this is showing me through kind of like a visual interface to the text file",
        "tokens": [
          51564,
          407,
          437,
          341,
          307,
          4099,
          385,
          307,
          11,
          341,
          307,
          4099,
          385,
          807,
          733,
          295,
          411,
          257,
          5056,
          9226,
          281,
          264,
          2487,
          3991,
          51814
        ]
      },
      {
        "avg_logprob": -0.1569463461637497,
        "compression_ratio": 1.8008298755186722,
        "end": 254,
        "id": 67,
        "no_speech_prob": 0.006692712195217609,
        "seek": 24900,
        "start": 249,
        "temperature": 0,
        "text": " that there are two proposed ways that this code could run.",
        "tokens": [
          50364,
          300,
          456,
          366,
          732,
          10348,
          2098,
          300,
          341,
          3089,
          727,
          1190,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.1569463461637497,
        "compression_ratio": 1.8008298755186722,
        "end": 257,
        "id": 68,
        "no_speech_prob": 0.006692712195217609,
        "seek": 24900,
        "start": 254,
        "temperature": 0,
        "text": " One of the files had it this way, and one of the files had it this way.",
        "tokens": [
          50614,
          1485,
          295,
          264,
          7098,
          632,
          309,
          341,
          636,
          11,
          293,
          472,
          295,
          264,
          7098,
          632,
          309,
          341,
          636,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.1569463461637497,
        "compression_ratio": 1.8008298755186722,
        "end": 262,
        "id": 69,
        "no_speech_prob": 0.006692712195217609,
        "seek": 24900,
        "start": 257,
        "temperature": 0,
        "text": " In fact, the current master has it this way, but the one that I'm trying to merge has it this way.",
        "tokens": [
          50764,
          682,
          1186,
          11,
          264,
          2190,
          4505,
          575,
          309,
          341,
          636,
          11,
          457,
          264,
          472,
          300,
          286,
          478,
          1382,
          281,
          22183,
          575,
          309,
          341,
          636,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.1569463461637497,
        "compression_ratio": 1.8008298755186722,
        "end": 263,
        "id": 70,
        "no_speech_prob": 0.006692712195217609,
        "seek": 24900,
        "start": 262,
        "temperature": 0,
        "text": " And why does this one have it this way?",
        "tokens": [
          51014,
          400,
          983,
          775,
          341,
          472,
          362,
          309,
          341,
          636,
          30,
          51064
        ]
      },
      {
        "avg_logprob": -0.1569463461637497,
        "compression_ratio": 1.8008298755186722,
        "end": 264,
        "id": 71,
        "no_speech_prob": 0.006692712195217609,
        "seek": 24900,
        "start": 263,
        "temperature": 0,
        "text": " This is the thing that I changed.",
        "tokens": [
          51064,
          639,
          307,
          264,
          551,
          300,
          286,
          3105,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.1569463461637497,
        "compression_ratio": 1.8008298755186722,
        "end": 265,
        "id": 72,
        "no_speech_prob": 0.006692712195217609,
        "seek": 24900,
        "start": 264,
        "temperature": 0,
        "text": " I want it this.",
        "tokens": [
          51114,
          286,
          528,
          309,
          341,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.1569463461637497,
        "compression_ratio": 1.8008298755186722,
        "end": 266,
        "id": 73,
        "no_speech_prob": 0.006692712195217609,
        "seek": 24900,
        "start": 265,
        "temperature": 0,
        "text": " So it's up to me.",
        "tokens": [
          51164,
          407,
          309,
          311,
          493,
          281,
          385,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.1569463461637497,
        "compression_ratio": 1.8008298755186722,
        "end": 268,
        "id": 74,
        "no_speech_prob": 0.006692712195217609,
        "seek": 24900,
        "start": 266,
        "temperature": 0,
        "text": " Now, there's no right or wrong answer here.",
        "tokens": [
          51214,
          823,
          11,
          456,
          311,
          572,
          558,
          420,
          2085,
          1867,
          510,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.1569463461637497,
        "compression_ratio": 1.8008298755186722,
        "end": 271,
        "id": 75,
        "no_speech_prob": 0.006692712195217609,
        "seek": 24900,
        "start": 268,
        "temperature": 0,
        "text": " As the kind of proprietor of this GitHub repository,",
        "tokens": [
          51314,
          1018,
          264,
          733,
          295,
          27881,
          284,
          295,
          341,
          23331,
          25841,
          11,
          51464
        ]
      },
      {
        "avg_logprob": -0.18863544708643204,
        "compression_ratio": 1.5732484076433122,
        "end": 283,
        "id": 76,
        "no_speech_prob": 0.46481645107269287,
        "seek": 27100,
        "start": 271,
        "temperature": 0,
        "text": " I've got to decide if both pull requests worked on the same line, I have to pick one.",
        "tokens": [
          50364,
          286,
          600,
          658,
          281,
          4536,
          498,
          1293,
          2235,
          12475,
          2732,
          322,
          264,
          912,
          1622,
          11,
          286,
          362,
          281,
          1888,
          472,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.18863544708643204,
        "compression_ratio": 1.5732484076433122,
        "end": 284,
        "id": 77,
        "no_speech_prob": 0.46481645107269287,
        "seek": 27100,
        "start": 283,
        "temperature": 0,
        "text": " Which one do I want?",
        "tokens": [
          50964,
          3013,
          472,
          360,
          286,
          528,
          30,
          51014
        ]
      },
      {
        "avg_logprob": -0.18863544708643204,
        "compression_ratio": 1.5732484076433122,
        "end": 289,
        "id": 78,
        "no_speech_prob": 0.46481645107269287,
        "seek": 27100,
        "start": 284,
        "temperature": 0,
        "text": " And I want, I'm going to take this one at the bottom.",
        "tokens": [
          51014,
          400,
          286,
          528,
          11,
          286,
          478,
          516,
          281,
          747,
          341,
          472,
          412,
          264,
          2767,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.18863544708643204,
        "compression_ratio": 1.5732484076433122,
        "end": 298,
        "id": 79,
        "no_speech_prob": 0.46481645107269287,
        "seek": 27100,
        "start": 289,
        "temperature": 0,
        "text": " So I'm going to delete this, and I'm going to delete this.",
        "tokens": [
          51264,
          407,
          286,
          478,
          516,
          281,
          12097,
          341,
          11,
          293,
          286,
          478,
          516,
          281,
          12097,
          341,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.18863544708643204,
        "compression_ratio": 1.5732484076433122,
        "end": 299,
        "id": 80,
        "no_speech_prob": 0.46481645107269287,
        "seek": 27100,
        "start": 298,
        "temperature": 0,
        "text": " Whoops, what did I just do?",
        "tokens": [
          51714,
          45263,
          11,
          437,
          630,
          286,
          445,
          360,
          30,
          51764
        ]
      },
      {
        "avg_logprob": -0.20157013999091256,
        "compression_ratio": 1.7870722433460076,
        "end": 302,
        "id": 81,
        "no_speech_prob": 0.21202963590621948,
        "seek": 29900,
        "start": 299,
        "temperature": 0,
        "text": " I'm going to delete this.",
        "tokens": [
          50364,
          286,
          478,
          516,
          281,
          12097,
          341,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.20157013999091256,
        "compression_ratio": 1.7870722433460076,
        "end": 305,
        "id": 82,
        "no_speech_prob": 0.21202963590621948,
        "seek": 29900,
        "start": 302,
        "temperature": 0,
        "text": " Now, if only I knew how to use a computer.",
        "tokens": [
          50514,
          823,
          11,
          498,
          787,
          286,
          2586,
          577,
          281,
          764,
          257,
          3820,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.20157013999091256,
        "compression_ratio": 1.7870722433460076,
        "end": 306,
        "id": 83,
        "no_speech_prob": 0.21202963590621948,
        "seek": 29900,
        "start": 305,
        "temperature": 0,
        "text": " I'm going to delete this.",
        "tokens": [
          50664,
          286,
          478,
          516,
          281,
          12097,
          341,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.20157013999091256,
        "compression_ratio": 1.7870722433460076,
        "end": 310,
        "id": 84,
        "no_speech_prob": 0.21202963590621948,
        "seek": 29900,
        "start": 306,
        "temperature": 0,
        "text": " And now, are there any other conflicts?",
        "tokens": [
          50714,
          400,
          586,
          11,
          366,
          456,
          604,
          661,
          19807,
          30,
          50914
        ]
      },
      {
        "avg_logprob": -0.20157013999091256,
        "compression_ratio": 1.7870722433460076,
        "end": 311,
        "id": 85,
        "no_speech_prob": 0.21202963590621948,
        "seek": 29900,
        "start": 310,
        "temperature": 0,
        "text": " Please be, no other conflicts.",
        "tokens": [
          50914,
          2555,
          312,
          11,
          572,
          661,
          19807,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.20157013999091256,
        "compression_ratio": 1.7870722433460076,
        "end": 313,
        "id": 86,
        "no_speech_prob": 0.21202963590621948,
        "seek": 29900,
        "start": 311,
        "temperature": 0,
        "text": " Oh, I'm so lucky.",
        "tokens": [
          50964,
          876,
          11,
          286,
          478,
          370,
          6356,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.20157013999091256,
        "compression_ratio": 1.7870722433460076,
        "end": 316,
        "id": 87,
        "no_speech_prob": 0.21202963590621948,
        "seek": 29900,
        "start": 313,
        "temperature": 0,
        "text": " I'm going to now say, mark as resolved.",
        "tokens": [
          51064,
          286,
          478,
          516,
          281,
          586,
          584,
          11,
          1491,
          382,
          20772,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.20157013999091256,
        "compression_ratio": 1.7870722433460076,
        "end": 320,
        "id": 88,
        "no_speech_prob": 0.21202963590621948,
        "seek": 29900,
        "start": 316,
        "temperature": 0,
        "text": " Now, one thing you can do if you're the proprietor of a GitHub repository,",
        "tokens": [
          51214,
          823,
          11,
          472,
          551,
          291,
          393,
          360,
          498,
          291,
          434,
          264,
          27881,
          284,
          295,
          257,
          23331,
          25841,
          11,
          51414
        ]
      },
      {
        "avg_logprob": -0.20157013999091256,
        "compression_ratio": 1.7870722433460076,
        "end": 322,
        "id": 89,
        "no_speech_prob": 0.21202963590621948,
        "seek": 29900,
        "start": 320,
        "temperature": 0,
        "text": " is you could just write to the person that's making the pull request,",
        "tokens": [
          51414,
          307,
          291,
          727,
          445,
          2464,
          281,
          264,
          954,
          300,
          311,
          1455,
          264,
          2235,
          5308,
          11,
          51514
        ]
      },
      {
        "avg_logprob": -0.20157013999091256,
        "compression_ratio": 1.7870722433460076,
        "end": 324,
        "id": 90,
        "no_speech_prob": 0.21202963590621948,
        "seek": 29900,
        "start": 322,
        "temperature": 0,
        "text": " I'm so sorry, but some conflicts arose.",
        "tokens": [
          51514,
          286,
          478,
          370,
          2597,
          11,
          457,
          512,
          19807,
          37192,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.20157013999091256,
        "compression_ratio": 1.7870722433460076,
        "end": 325,
        "id": 91,
        "no_speech_prob": 0.21202963590621948,
        "seek": 29900,
        "start": 324,
        "temperature": 0,
        "text": " I love your pull request.",
        "tokens": [
          51614,
          286,
          959,
          428,
          2235,
          5308,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.20157013999091256,
        "compression_ratio": 1.7870722433460076,
        "end": 326,
        "id": 92,
        "no_speech_prob": 0.21202963590621948,
        "seek": 29900,
        "start": 325,
        "temperature": 0,
        "text": " Do you think you could refactor it?",
        "tokens": [
          51664,
          1144,
          291,
          519,
          291,
          727,
          1895,
          15104,
          309,
          30,
          51714
        ]
      },
      {
        "avg_logprob": -0.1926924598138064,
        "compression_ratio": 1.734006734006734,
        "end": 328,
        "id": 93,
        "no_speech_prob": 0.807884693145752,
        "seek": 32600,
        "start": 326,
        "temperature": 0,
        "text": " Because you could leave this up to the contributor, certainly.",
        "tokens": [
          50364,
          1436,
          291,
          727,
          1856,
          341,
          493,
          281,
          264,
          42859,
          11,
          3297,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.1926924598138064,
        "compression_ratio": 1.734006734006734,
        "end": 330,
        "id": 94,
        "no_speech_prob": 0.807884693145752,
        "seek": 32600,
        "start": 328,
        "temperature": 0,
        "text": " But I'm here, live on the internet.",
        "tokens": [
          50464,
          583,
          286,
          478,
          510,
          11,
          1621,
          322,
          264,
          4705,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.1926924598138064,
        "compression_ratio": 1.734006734006734,
        "end": 333,
        "id": 95,
        "no_speech_prob": 0.807884693145752,
        "seek": 32600,
        "start": 330,
        "temperature": 0,
        "text": " Maybe I'm not live anymore, I'm recorded.",
        "tokens": [
          50564,
          2704,
          286,
          478,
          406,
          1621,
          3602,
          11,
          286,
          478,
          8287,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.1926924598138064,
        "compression_ratio": 1.734006734006734,
        "end": 335,
        "id": 96,
        "no_speech_prob": 0.807884693145752,
        "seek": 32600,
        "start": 333,
        "temperature": 0,
        "text": " And so there we go.",
        "tokens": [
          50714,
          400,
          370,
          456,
          321,
          352,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.1926924598138064,
        "compression_ratio": 1.734006734006734,
        "end": 336,
        "id": 97,
        "no_speech_prob": 0.807884693145752,
        "seek": 32600,
        "start": 335,
        "temperature": 0,
        "text": " Oh, no.",
        "tokens": [
          50814,
          876,
          11,
          572,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.1926924598138064,
        "compression_ratio": 1.734006734006734,
        "end": 338,
        "id": 98,
        "no_speech_prob": 0.807884693145752,
        "seek": 32600,
        "start": 336,
        "temperature": 0,
        "text": " Okay, ah, so now I have this other file.",
        "tokens": [
          50864,
          1033,
          11,
          3716,
          11,
          370,
          586,
          286,
          362,
          341,
          661,
          3991,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.1926924598138064,
        "compression_ratio": 1.734006734006734,
        "end": 340,
        "id": 99,
        "no_speech_prob": 0.807884693145752,
        "seek": 32600,
        "start": 338,
        "temperature": 0,
        "text": " Let's look at this.",
        "tokens": [
          50964,
          961,
          311,
          574,
          412,
          341,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.1926924598138064,
        "compression_ratio": 1.734006734006734,
        "end": 345,
        "id": 100,
        "no_speech_prob": 0.807884693145752,
        "seek": 32600,
        "start": 340,
        "temperature": 0,
        "text": " I might just quit while I'm ahead here, but let's see if I can look at this other file.",
        "tokens": [
          51064,
          286,
          1062,
          445,
          10366,
          1339,
          286,
          478,
          2286,
          510,
          11,
          457,
          718,
          311,
          536,
          498,
          286,
          393,
          574,
          412,
          341,
          661,
          3991,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.1926924598138064,
        "compression_ratio": 1.734006734006734,
        "end": 348,
        "id": 101,
        "no_speech_prob": 0.807884693145752,
        "seek": 32600,
        "start": 345,
        "temperature": 0,
        "text": " So this code might look very strange to you.",
        "tokens": [
          51314,
          407,
          341,
          3089,
          1062,
          574,
          588,
          5861,
          281,
          291,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.1926924598138064,
        "compression_ratio": 1.734006734006734,
        "end": 350,
        "id": 102,
        "no_speech_prob": 0.807884693145752,
        "seek": 32600,
        "start": 348,
        "temperature": 0,
        "text": " This is something called unit testing.",
        "tokens": [
          51464,
          639,
          307,
          746,
          1219,
          4985,
          4997,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.1926924598138064,
        "compression_ratio": 1.734006734006734,
        "end": 352,
        "id": 103,
        "no_speech_prob": 0.807884693145752,
        "seek": 32600,
        "start": 350,
        "temperature": 0,
        "text": " And actually, related to this video series,",
        "tokens": [
          51564,
          400,
          767,
          11,
          4077,
          281,
          341,
          960,
          2638,
          11,
          51664
        ]
      },
      {
        "avg_logprob": -0.1926924598138064,
        "compression_ratio": 1.734006734006734,
        "end": 354,
        "id": 104,
        "no_speech_prob": 0.807884693145752,
        "seek": 32600,
        "start": 352,
        "temperature": 0,
        "text": " I have a video series that I will link to in this video's description",
        "tokens": [
          51664,
          286,
          362,
          257,
          960,
          2638,
          300,
          286,
          486,
          2113,
          281,
          294,
          341,
          960,
          311,
          3855,
          51764
        ]
      },
      {
        "avg_logprob": -0.1840907862929047,
        "compression_ratio": 1.7106227106227105,
        "end": 357,
        "id": 105,
        "no_speech_prob": 0.015905501320958138,
        "seek": 35400,
        "start": 355,
        "temperature": 0,
        "text": " about how you can run automated tests",
        "tokens": [
          50414,
          466,
          577,
          291,
          393,
          1190,
          18473,
          6921,
          50514
        ]
      },
      {
        "avg_logprob": -0.1840907862929047,
        "compression_ratio": 1.7106227106227105,
        "end": 360,
        "id": 106,
        "no_speech_prob": 0.015905501320958138,
        "seek": 35400,
        "start": 357,
        "temperature": 0,
        "text": " that make sure a change in your code doesn't actually break your code.",
        "tokens": [
          50514,
          300,
          652,
          988,
          257,
          1319,
          294,
          428,
          3089,
          1177,
          380,
          767,
          1821,
          428,
          3089,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.1840907862929047,
        "compression_ratio": 1.7106227106227105,
        "end": 362,
        "id": 107,
        "no_speech_prob": 0.015905501320958138,
        "seek": 35400,
        "start": 360,
        "temperature": 0,
        "text": " That's what this is doing here.",
        "tokens": [
          50664,
          663,
          311,
          437,
          341,
          307,
          884,
          510,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.1840907862929047,
        "compression_ratio": 1.7106227106227105,
        "end": 366,
        "id": 108,
        "no_speech_prob": 0.015905501320958138,
        "seek": 35400,
        "start": 362,
        "temperature": 0,
        "text": " So there's map improvements, that's the pull request.",
        "tokens": [
          50764,
          407,
          456,
          311,
          4471,
          13797,
          11,
          300,
          311,
          264,
          2235,
          5308,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.1840907862929047,
        "compression_ratio": 1.7106227106227105,
        "end": 367,
        "id": 109,
        "no_speech_prob": 0.015905501320958138,
        "seek": 35400,
        "start": 366,
        "temperature": 0,
        "text": " And master.",
        "tokens": [
          50964,
          400,
          4505,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.1840907862929047,
        "compression_ratio": 1.7106227106227105,
        "end": 368,
        "id": 110,
        "no_speech_prob": 0.015905501320958138,
        "seek": 35400,
        "start": 367,
        "temperature": 0,
        "text": " You know what?",
        "tokens": [
          51014,
          509,
          458,
          437,
          30,
          51064
        ]
      },
      {
        "avg_logprob": -0.1840907862929047,
        "compression_ratio": 1.7106227106227105,
        "end": 371,
        "id": 111,
        "no_speech_prob": 0.015905501320958138,
        "seek": 35400,
        "start": 368,
        "temperature": 0,
        "text": " I think this is a very trivial change.",
        "tokens": [
          51064,
          286,
          519,
          341,
          307,
          257,
          588,
          26703,
          1319,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.1840907862929047,
        "compression_ratio": 1.7106227106227105,
        "end": 374,
        "id": 112,
        "no_speech_prob": 0.015905501320958138,
        "seek": 35400,
        "start": 371,
        "temperature": 0,
        "text": " It looks to me like this was just added at the end,",
        "tokens": [
          51214,
          467,
          1542,
          281,
          385,
          411,
          341,
          390,
          445,
          3869,
          412,
          264,
          917,
          11,
          51364
        ]
      },
      {
        "avg_logprob": -0.1840907862929047,
        "compression_ratio": 1.7106227106227105,
        "end": 377,
        "id": 113,
        "no_speech_prob": 0.015905501320958138,
        "seek": 35400,
        "start": 374,
        "temperature": 0,
        "text": " and there was like a line break or something that caused a merge conflict.",
        "tokens": [
          51364,
          293,
          456,
          390,
          411,
          257,
          1622,
          1821,
          420,
          746,
          300,
          7008,
          257,
          22183,
          6596,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.1840907862929047,
        "compression_ratio": 1.7106227106227105,
        "end": 382,
        "id": 114,
        "no_speech_prob": 0.015905501320958138,
        "seek": 35400,
        "start": 377,
        "temperature": 0,
        "text": " So this looks like something that I could actually just completely delete here,",
        "tokens": [
          51514,
          407,
          341,
          1542,
          411,
          746,
          300,
          286,
          727,
          767,
          445,
          2584,
          12097,
          510,
          11,
          51764
        ]
      },
      {
        "avg_logprob": -0.207075075002817,
        "compression_ratio": 1.640926640926641,
        "end": 384,
        "id": 115,
        "no_speech_prob": 0.0010987103451043367,
        "seek": 38200,
        "start": 383,
        "temperature": 0,
        "text": " and then delete here.",
        "tokens": [
          50414,
          293,
          550,
          12097,
          510,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.207075075002817,
        "compression_ratio": 1.640926640926641,
        "end": 387,
        "id": 116,
        "no_speech_prob": 0.0010987103451043367,
        "seek": 38200,
        "start": 384,
        "temperature": 0,
        "text": " And this is just some new stuff that got added to the end as part of this pull request.",
        "tokens": [
          50464,
          400,
          341,
          307,
          445,
          512,
          777,
          1507,
          300,
          658,
          3869,
          281,
          264,
          917,
          382,
          644,
          295,
          341,
          2235,
          5308,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.207075075002817,
        "compression_ratio": 1.640926640926641,
        "end": 389,
        "id": 117,
        "no_speech_prob": 0.0010987103451043367,
        "seek": 38200,
        "start": 387,
        "temperature": 0,
        "text": " There was like an extra line break or something,",
        "tokens": [
          50614,
          821,
          390,
          411,
          364,
          2857,
          1622,
          1821,
          420,
          746,
          11,
          50714
        ]
      },
      {
        "avg_logprob": -0.207075075002817,
        "compression_ratio": 1.640926640926641,
        "end": 393,
        "id": 118,
        "no_speech_prob": 0.0010987103451043367,
        "seek": 38200,
        "start": 389,
        "temperature": 0,
        "text": " so GitHub detected a conflict, but it really was not a conflict.",
        "tokens": [
          50714,
          370,
          23331,
          21896,
          257,
          6596,
          11,
          457,
          309,
          534,
          390,
          406,
          257,
          6596,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.207075075002817,
        "compression_ratio": 1.640926640926641,
        "end": 398,
        "id": 119,
        "no_speech_prob": 0.0010987103451043367,
        "seek": 38200,
        "start": 393,
        "temperature": 0,
        "text": " So now I can go and I can click mark as resolved.",
        "tokens": [
          50914,
          407,
          586,
          286,
          393,
          352,
          293,
          286,
          393,
          2052,
          1491,
          382,
          20772,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.207075075002817,
        "compression_ratio": 1.640926640926641,
        "end": 400,
        "id": 120,
        "no_speech_prob": 0.0010987103451043367,
        "seek": 38200,
        "start": 399,
        "temperature": 0,
        "text": " And look at this.",
        "tokens": [
          51214,
          400,
          574,
          412,
          341,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.207075075002817,
        "compression_ratio": 1.640926640926641,
        "end": 402,
        "id": 121,
        "no_speech_prob": 0.0010987103451043367,
        "seek": 38200,
        "start": 400,
        "temperature": 0,
        "text": " Ha, commit merge.",
        "tokens": [
          51264,
          4064,
          11,
          5599,
          22183,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.207075075002817,
        "compression_ratio": 1.640926640926641,
        "end": 403,
        "id": 122,
        "no_speech_prob": 0.0010987103451043367,
        "seek": 38200,
        "start": 402,
        "temperature": 0,
        "text": " So here's the thing.",
        "tokens": [
          51364,
          407,
          510,
          311,
          264,
          551,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.207075075002817,
        "compression_ratio": 1.640926640926641,
        "end": 405,
        "id": 123,
        "no_speech_prob": 0.0010987103451043367,
        "seek": 38200,
        "start": 403,
        "temperature": 0,
        "text": " Hmm, hmm, where am I right now?",
        "tokens": [
          51414,
          8239,
          11,
          16478,
          11,
          689,
          669,
          286,
          558,
          586,
          30,
          51514
        ]
      },
      {
        "avg_logprob": -0.207075075002817,
        "compression_ratio": 1.640926640926641,
        "end": 408,
        "id": 124,
        "no_speech_prob": 0.0010987103451043367,
        "seek": 38200,
        "start": 405,
        "temperature": 0,
        "text": " So I, hmm, I resolved all the conflicts.",
        "tokens": [
          51514,
          407,
          286,
          11,
          16478,
          11,
          286,
          20772,
          439,
          264,
          19807,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.207075075002817,
        "compression_ratio": 1.640926640926641,
        "end": 410,
        "id": 125,
        "no_speech_prob": 0.0010987103451043367,
        "seek": 38200,
        "start": 408,
        "temperature": 0,
        "text": " Do I want to do this?",
        "tokens": [
          51664,
          1144,
          286,
          528,
          281,
          360,
          341,
          30,
          51764
        ]
      },
      {
        "avg_logprob": -0.18212878487326883,
        "compression_ratio": 1.7477477477477477,
        "end": 418,
        "id": 126,
        "no_speech_prob": 0.0009253741009160876,
        "seek": 41000,
        "start": 410,
        "temperature": 0,
        "text": " I think this button, if I'm right, is not actually,",
        "tokens": [
          50364,
          286,
          519,
          341,
          2960,
          11,
          498,
          286,
          478,
          558,
          11,
          307,
          406,
          767,
          11,
          50764
        ]
      },
      {
        "avg_logprob": -0.18212878487326883,
        "compression_ratio": 1.7477477477477477,
        "end": 422,
        "id": 127,
        "no_speech_prob": 0.0009253741009160876,
        "seek": 41000,
        "start": 418,
        "temperature": 0,
        "text": " I'm looking at the chat to see if anybody's complaining about what I've done,",
        "tokens": [
          50764,
          286,
          478,
          1237,
          412,
          264,
          5081,
          281,
          536,
          498,
          4472,
          311,
          20740,
          466,
          437,
          286,
          600,
          1096,
          11,
          50964
        ]
      },
      {
        "avg_logprob": -0.18212878487326883,
        "compression_ratio": 1.7477477477477477,
        "end": 424,
        "id": 128,
        "no_speech_prob": 0.0009253741009160876,
        "seek": 41000,
        "start": 422,
        "temperature": 0,
        "text": " is not actually merging the pull request.",
        "tokens": [
          50964,
          307,
          406,
          767,
          44559,
          264,
          2235,
          5308,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.18212878487326883,
        "compression_ratio": 1.7477477477477477,
        "end": 430,
        "id": 129,
        "no_speech_prob": 0.0009253741009160876,
        "seek": 41000,
        "start": 424,
        "temperature": 0,
        "text": " I think this is the committing the resolution of the conflicts to the pull request.",
        "tokens": [
          51064,
          286,
          519,
          341,
          307,
          264,
          26659,
          264,
          8669,
          295,
          264,
          19807,
          281,
          264,
          2235,
          5308,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.18212878487326883,
        "compression_ratio": 1.7477477477477477,
        "end": 431,
        "id": 130,
        "no_speech_prob": 0.0009253741009160876,
        "seek": 41000,
        "start": 430,
        "temperature": 0,
        "text": " Let's find out.",
        "tokens": [
          51364,
          961,
          311,
          915,
          484,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.18212878487326883,
        "compression_ratio": 1.7477477477477477,
        "end": 433,
        "id": 131,
        "no_speech_prob": 0.0009253741009160876,
        "seek": 41000,
        "start": 431,
        "temperature": 0,
        "text": " Because I'm going to just, it's a green button.",
        "tokens": [
          51414,
          1436,
          286,
          478,
          516,
          281,
          445,
          11,
          309,
          311,
          257,
          3092,
          2960,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.18212878487326883,
        "compression_ratio": 1.7477477477477477,
        "end": 435,
        "id": 132,
        "no_speech_prob": 0.0009253741009160876,
        "seek": 41000,
        "start": 433,
        "temperature": 0,
        "text": " When I see a green button, it just makes me want to click it.",
        "tokens": [
          51514,
          1133,
          286,
          536,
          257,
          3092,
          2960,
          11,
          309,
          445,
          1669,
          385,
          528,
          281,
          2052,
          309,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.18212878487326883,
        "compression_ratio": 1.7477477477477477,
        "end": 436,
        "id": 133,
        "no_speech_prob": 0.0009253741009160876,
        "seek": 41000,
        "start": 435,
        "temperature": 0,
        "text": " Click.",
        "tokens": [
          51614,
          8230,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.16002655029296875,
        "compression_ratio": 1.7165991902834008,
        "end": 440,
        "id": 134,
        "no_speech_prob": 0.00513948779553175,
        "seek": 43600,
        "start": 437,
        "temperature": 0,
        "text": " So I think the pull request is still going to be live and active.",
        "tokens": [
          50414,
          407,
          286,
          519,
          264,
          2235,
          5308,
          307,
          920,
          516,
          281,
          312,
          1621,
          293,
          4967,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.16002655029296875,
        "compression_ratio": 1.7165991902834008,
        "end": 441,
        "id": 135,
        "no_speech_prob": 0.00513948779553175,
        "seek": 43600,
        "start": 440,
        "temperature": 0,
        "text": " Boy, it's taking a while.",
        "tokens": [
          50564,
          9486,
          11,
          309,
          311,
          1940,
          257,
          1339,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.16002655029296875,
        "compression_ratio": 1.7165991902834008,
        "end": 442,
        "id": 136,
        "no_speech_prob": 0.00513948779553175,
        "seek": 43600,
        "start": 441,
        "temperature": 0,
        "text": " Yes.",
        "tokens": [
          50614,
          1079,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.16002655029296875,
        "compression_ratio": 1.7165991902834008,
        "end": 447,
        "id": 137,
        "no_speech_prob": 0.00513948779553175,
        "seek": 43600,
        "start": 442,
        "temperature": 0,
        "text": " All it did, yeah, all it did was fix the conflicts.",
        "tokens": [
          50664,
          1057,
          309,
          630,
          11,
          1338,
          11,
          439,
          309,
          630,
          390,
          3191,
          264,
          19807,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.16002655029296875,
        "compression_ratio": 1.7165991902834008,
        "end": 449,
        "id": 138,
        "no_speech_prob": 0.00513948779553175,
        "seek": 43600,
        "start": 447,
        "temperature": 0,
        "text": " Where can I find that that was done here?",
        "tokens": [
          50914,
          2305,
          393,
          286,
          915,
          300,
          300,
          390,
          1096,
          510,
          30,
          51014
        ]
      },
      {
        "avg_logprob": -0.16002655029296875,
        "compression_ratio": 1.7165991902834008,
        "end": 451,
        "id": 139,
        "no_speech_prob": 0.00513948779553175,
        "seek": 43600,
        "start": 449,
        "temperature": 0,
        "text": " Yes, that was this.",
        "tokens": [
          51014,
          1079,
          11,
          300,
          390,
          341,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.16002655029296875,
        "compression_ratio": 1.7165991902834008,
        "end": 452,
        "id": 140,
        "no_speech_prob": 0.00513948779553175,
        "seek": 43600,
        "start": 451,
        "temperature": 0,
        "text": " So this is me.",
        "tokens": [
          51114,
          407,
          341,
          307,
          385,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.16002655029296875,
        "compression_ratio": 1.7165991902834008,
        "end": 457,
        "id": 141,
        "no_speech_prob": 0.00513948779553175,
        "seek": 43600,
        "start": 452,
        "temperature": 0,
        "text": " Now there's a little note that I merged branch master into map improvements.",
        "tokens": [
          51164,
          823,
          456,
          311,
          257,
          707,
          3637,
          300,
          286,
          36427,
          9819,
          4505,
          666,
          4471,
          13797,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.16002655029296875,
        "compression_ratio": 1.7165991902834008,
        "end": 462,
        "id": 142,
        "no_speech_prob": 0.00513948779553175,
        "seek": 43600,
        "start": 457,
        "temperature": 0,
        "text": " That's basically saying there were conflicts between master and map improvements.",
        "tokens": [
          51414,
          663,
          311,
          1936,
          1566,
          456,
          645,
          19807,
          1296,
          4505,
          293,
          4471,
          13797,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.16002655029296875,
        "compression_ratio": 1.7165991902834008,
        "end": 464,
        "id": 143,
        "no_speech_prob": 0.00513948779553175,
        "seek": 43600,
        "start": 462,
        "temperature": 0,
        "text": " This pull request was map improvements.",
        "tokens": [
          51664,
          639,
          2235,
          5308,
          390,
          4471,
          13797,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.2589122417361237,
        "compression_ratio": 1.6473684210526316,
        "end": 467,
        "id": 144,
        "no_speech_prob": 0.02675851620733738,
        "seek": 46400,
        "start": 464,
        "temperature": 0,
        "text": " And there was me merging them together and resolving the conflicts.",
        "tokens": [
          50364,
          400,
          456,
          390,
          385,
          44559,
          552,
          1214,
          293,
          49940,
          264,
          19807,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.2589122417361237,
        "compression_ratio": 1.6473684210526316,
        "end": 470,
        "id": 145,
        "no_speech_prob": 0.02675851620733738,
        "seek": 46400,
        "start": 467,
        "temperature": 0,
        "text": " And now I can actually go ahead.",
        "tokens": [
          50514,
          400,
          586,
          286,
          393,
          767,
          352,
          2286,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.2589122417361237,
        "compression_ratio": 1.6473684210526316,
        "end": 475,
        "id": 146,
        "no_speech_prob": 0.02675851620733738,
        "seek": 46400,
        "start": 470,
        "temperature": 0,
        "text": " The conflicts are resolved and I can merge the pull request.",
        "tokens": [
          50664,
          440,
          19807,
          366,
          20772,
          293,
          286,
          393,
          22183,
          264,
          2235,
          5308,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.2589122417361237,
        "compression_ratio": 1.6473684210526316,
        "end": 480,
        "id": 147,
        "no_speech_prob": 0.02675851620733738,
        "seek": 46400,
        "start": 475,
        "temperature": 0,
        "text": " Nothing exciting is going to happen.",
        "tokens": [
          50914,
          6693,
          4670,
          307,
          516,
          281,
          1051,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.2589122417361237,
        "compression_ratio": 1.6473684210526316,
        "end": 481,
        "id": 148,
        "no_speech_prob": 0.02675851620733738,
        "seek": 46400,
        "start": 480,
        "temperature": 0,
        "text": " It really should.",
        "tokens": [
          51164,
          467,
          534,
          820,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.2589122417361237,
        "compression_ratio": 1.6473684210526316,
        "end": 482,
        "id": 149,
        "no_speech_prob": 0.02675851620733738,
        "seek": 46400,
        "start": 481,
        "temperature": 0,
        "text": " It should like confetti should explode.",
        "tokens": [
          51214,
          467,
          820,
          411,
          1497,
          12495,
          820,
          21411,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.2589122417361237,
        "compression_ratio": 1.6473684210526316,
        "end": 484,
        "id": 150,
        "no_speech_prob": 0.02675851620733738,
        "seek": 46400,
        "start": 482,
        "temperature": 0,
        "text": " Confirm.",
        "tokens": [
          51264,
          11701,
          3692,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.2589122417361237,
        "compression_ratio": 1.6473684210526316,
        "end": 486,
        "id": 151,
        "no_speech_prob": 0.02675851620733738,
        "seek": 46400,
        "start": 484,
        "temperature": 0,
        "text": " And look, but I can make something happen.",
        "tokens": [
          51364,
          400,
          574,
          11,
          457,
          286,
          393,
          652,
          746,
          1051,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.2589122417361237,
        "compression_ratio": 1.6473684210526316,
        "end": 489,
        "id": 152,
        "no_speech_prob": 0.02675851620733738,
        "seek": 46400,
        "start": 486,
        "temperature": 0,
        "text": " Yay.",
        "tokens": [
          51464,
          13268,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.2631164182696426,
        "compression_ratio": 1.6620209059233448,
        "end": 495,
        "id": 153,
        "no_speech_prob": 0.42624542117118835,
        "seek": 48900,
        "start": 490,
        "temperature": 0,
        "text": " Okay, so that was a video about resolving merge conflicts through the GitHub interface.",
        "tokens": [
          50414,
          1033,
          11,
          370,
          300,
          390,
          257,
          960,
          466,
          49940,
          22183,
          19807,
          807,
          264,
          23331,
          9226,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.2631164182696426,
        "compression_ratio": 1.6620209059233448,
        "end": 497,
        "id": 154,
        "no_speech_prob": 0.42624542117118835,
        "seek": 48900,
        "start": 495,
        "temperature": 0,
        "text": " The sort of basic gist of it.",
        "tokens": [
          50664,
          440,
          1333,
          295,
          3875,
          290,
          468,
          295,
          309,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.2631164182696426,
        "compression_ratio": 1.6620209059233448,
        "end": 502,
        "id": 155,
        "no_speech_prob": 0.42624542117118835,
        "seek": 48900,
        "start": 497,
        "temperature": 0,
        "text": " Perhaps I've missed something important and I will certainly make a follow-up video.",
        "tokens": [
          50764,
          10517,
          286,
          600,
          6721,
          746,
          1021,
          293,
          286,
          486,
          3297,
          652,
          257,
          1524,
          12,
          1010,
          960,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.2631164182696426,
        "compression_ratio": 1.6620209059233448,
        "end": 505,
        "id": 156,
        "no_speech_prob": 0.42624542117118835,
        "seek": 48900,
        "start": 502,
        "temperature": 0,
        "text": " So let me know what I missed, what questions you have in the comments.",
        "tokens": [
          51014,
          407,
          718,
          385,
          458,
          437,
          286,
          6721,
          11,
          437,
          1651,
          291,
          362,
          294,
          264,
          3053,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.2631164182696426,
        "compression_ratio": 1.6620209059233448,
        "end": 513,
        "id": 157,
        "no_speech_prob": 0.42624542117118835,
        "seek": 48900,
        "start": 505,
        "temperature": 0,
        "text": " And thanks for watching this video about merging, resolving conflicts, merging them with a pull request, something, something, GitHub.",
        "tokens": [
          51164,
          400,
          3231,
          337,
          1976,
          341,
          960,
          466,
          44559,
          11,
          49940,
          19807,
          11,
          44559,
          552,
          365,
          257,
          2235,
          5308,
          11,
          746,
          11,
          746,
          11,
          23331,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.2631164182696426,
        "compression_ratio": 1.6620209059233448,
        "end": 515,
        "id": 158,
        "no_speech_prob": 0.42624542117118835,
        "seek": 48900,
        "start": 513,
        "temperature": 0,
        "text": " I don't know.",
        "tokens": [
          51564,
          286,
          500,
          380,
          458,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.2631164182696426,
        "compression_ratio": 1.6620209059233448,
        "end": 517,
        "id": 159,
        "no_speech_prob": 0.42624542117118835,
        "seek": 48900,
        "start": 515,
        "temperature": 0,
        "text": " Search engine optimized keywords, throw them in there.",
        "tokens": [
          51664,
          17180,
          2848,
          26941,
          21009,
          11,
          3507,
          552,
          294,
          456,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.3487345377604167,
        "compression_ratio": 0.9230769230769231,
        "end": 518,
        "id": 160,
        "no_speech_prob": 0.08748949319124222,
        "seek": 51700,
        "start": 517,
        "temperature": 0,
        "text": " Okay, bye-bye.",
        "tokens": [
          50364,
          1033,
          11,
          6543,
          12,
          6650,
          13,
          50414
        ]
      },
      {
        "avg_logprob": -0.3487345377604167,
        "compression_ratio": 0.9230769230769231,
        "end": 528,
        "id": 161,
        "no_speech_prob": 0.08748949319124222,
        "seek": 51700,
        "start": 518,
        "temperature": 0,
        "text": " ♪♪♪",
        "tokens": [
          50414,
          220,
          158,
          247,
          103,
          158,
          247,
          103,
          158,
          247,
          103,
          50914
        ]
      }
    ],
    "transcription": " Hello, surprise! It's a video about Git and GitHub. And this video is about resolving merge conflicts. So I probably should be doing this video in my poem repository, which I use for all of my intro to Git and GitHub videos, but I happen to be here, streaming live, and working on this neural network library that I've been building in a bunch of other video tutorials. So if you've just watched those Git and GitHub videos, all about using a poem to sort of demonstrate how Git and GitHub works, there will be some aspects of this that are confusing, but hopefully this will be helpful anyway, and I can always double back and make another video if this one doesn't work. But let's just try it. So what is a merge conflict, first of all? So a merge conflict is when you have, let's say, this is a file, and in this case it's my file called matrix.js. So I have a file called matrix.js, and it has code in it. Now, I had two people, two separate people of the internet, happen to be working on this file. So we'll call one person A, and one person B. Now, any text file has lines in it. So even if it were a poem, it would have lines of the poem. If it's a source code file, it has lines of the source code. So we can think of the lines as like 1, 2, 3, 4, 5, 6. Now, if person A makes a change and submits a pull request, meaning, hey, hey, you the library, please pull my changes, right? I want to push my changes to you, but I'm asking, requesting that you pull my changes. If this person just made changes to lines 5 and 6, and this person just made changes to lines 2 and 3, the git system is smart enough to figure out how to pull both of these things in with no conflicts. Because there are no conflicts. If I want to accept changes to lines 2 and 3, I can accept those at the same time, one before the other, simultaneously, as lines 5 and 6. However, if right here, person B makes a change to line 4, and person A also makes a change to line 4, then we have what's known as a conflict. And typically, what will happen, what just happened to me right now, is I merged this one. I merged this one, wasn't thinking about it, it was done, it's finished, and it worked fine. It merged with no problems. But now when I went to merge this one, I got a message saying, resolve conflicts. Now there are a variety of ways you can resolve conflicts, and I think that I've, in some of my previous tutorials, looked at working with git command line locally, and I could have the text file there, but what I'm going to do is see if I can resolve the conflict just through the github interface itself. So let's take a look at how that works. Now, once again, this isn't the best scenario, and I might come back and do a follow-up, because it would be nice to see kind of a trivial example where I can really know what the changes are, but I'm just going to look and see, there's a whole discussion here, and we can see these are the files. These are the files that have conflicts in them. Matrix.js and Matrix.test.js. So hopefully you can continue to watch this, even if you don't understand what the code in those files is doing. I'm going to look and see what the conflicts are. Oh, this is definitely going to go down the internet tubes really quickly. So I'm going to click this resolve conflicts button, and now it's, ooh, look at this. Ooh, okay, all right. Oh, I'm in Matrix.js. Hmm, okay, I have to figure out what's going on here. So we can see, ah, look, this is where the conflict is. Oh, look, I think I know how to resolve this. Okay, so this is where the conflict is. Now, what is it telling me here? Map improvements, master, equals, equals, equals, equals, greater than, greater than, greater than, greater than. So what this is showing me is, this is showing me through kind of like a visual interface to the text file that there are two proposed ways that this code could run. One of the files had it this way, and one of the files had it this way. In fact, the current master has it this way, but the one that I'm trying to merge has it this way. And why does this one have it this way? This is the thing that I changed. I want it this. So it's up to me. Now, there's no right or wrong answer here. As the kind of proprietor of this GitHub repository, I've got to decide if both pull requests worked on the same line, I have to pick one. Which one do I want? And I want, I'm going to take this one at the bottom. So I'm going to delete this, and I'm going to delete this. Whoops, what did I just do? I'm going to delete this. Now, if only I knew how to use a computer. I'm going to delete this. And now, are there any other conflicts? Please be, no other conflicts. Oh, I'm so lucky. I'm going to now say, mark as resolved. Now, one thing you can do if you're the proprietor of a GitHub repository, is you could just write to the person that's making the pull request, I'm so sorry, but some conflicts arose. I love your pull request. Do you think you could refactor it? Because you could leave this up to the contributor, certainly. But I'm here, live on the internet. Maybe I'm not live anymore, I'm recorded. And so there we go. Oh, no. Okay, ah, so now I have this other file. Let's look at this. I might just quit while I'm ahead here, but let's see if I can look at this other file. So this code might look very strange to you. This is something called unit testing. And actually, related to this video series, I have a video series that I will link to in this video's description about how you can run automated tests that make sure a change in your code doesn't actually break your code. That's what this is doing here. So there's map improvements, that's the pull request. And master. You know what? I think this is a very trivial change. It looks to me like this was just added at the end, and there was like a line break or something that caused a merge conflict. So this looks like something that I could actually just completely delete here, and then delete here. And this is just some new stuff that got added to the end as part of this pull request. There was like an extra line break or something, so GitHub detected a conflict, but it really was not a conflict. So now I can go and I can click mark as resolved. And look at this. Ha, commit merge. So here's the thing. Hmm, hmm, where am I right now? So I, hmm, I resolved all the conflicts. Do I want to do this? I think this button, if I'm right, is not actually, I'm looking at the chat to see if anybody's complaining about what I've done, is not actually merging the pull request. I think this is the committing the resolution of the conflicts to the pull request. Let's find out. Because I'm going to just, it's a green button. When I see a green button, it just makes me want to click it. Click. So I think the pull request is still going to be live and active. Boy, it's taking a while. Yes. All it did, yeah, all it did was fix the conflicts. Where can I find that that was done here? Yes, that was this. So this is me. Now there's a little note that I merged branch master into map improvements. That's basically saying there were conflicts between master and map improvements. This pull request was map improvements. And there was me merging them together and resolving the conflicts. And now I can actually go ahead. The conflicts are resolved and I can merge the pull request. Nothing exciting is going to happen. It really should. It should like confetti should explode. Confirm. And look, but I can make something happen. Yay. Okay, so that was a video about resolving merge conflicts through the GitHub interface. The sort of basic gist of it. Perhaps I've missed something important and I will certainly make a follow-up video. So let me know what I missed, what questions you have in the comments. And thanks for watching this video about merging, resolving conflicts, merging them with a pull request, something, something, GitHub. I don't know. Search engine optimized keywords, throw them in there. Okay, bye-bye. ♪♪♪",
    "translation": null
  },
  "error": null,
  "status": "succeeded",
  "created_at": "2023-09-26T21:49:20.120088Z",
  "started_at": "2023-09-26T21:50:54.413745Z",
  "completed_at": "2023-09-26T21:53:25.007766Z",
  "webhook": "https://83ceaa0b612c.ngrok.app/?video_id=JtIX3HJKwfo",
  "webhook_events_filter": [
    "completed"
  ],
  "metrics": {
    "predict_time": 150.594021
  },
  "urls": {
    "cancel": "https://api.replicate.com/v1/predictions/6ti6fpzb3wom4swe5x6aw6koca/cancel",
    "get": "https://api.replicate.com/v1/predictions/6ti6fpzb3wom4swe5x6aw6koca"
  }
}