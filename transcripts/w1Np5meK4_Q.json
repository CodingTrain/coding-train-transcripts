{
  "id": "a7adopjbzdnrskl6vwab7sbb4u",
  "version": "91ee9c0c3df30478510ff8c8a3a545add1ad0259ad3a9f78fba57fbc05ee64f7",
  "input": {
    "audio": "https://upcdn.io/FW25b4F/raw/coding-train/w1Np5meK4_Q.m4a"
  },
  "logs": "Transcribe with large-v2 model\nDetected language: English\n  0%|          | 0/632416 [00:00<?, ?frames/s]\n  0%|          | 2796/632416 [00:04<16:31, 635.06frames/s]\n  1%|          | 4984/632416 [00:09<19:55, 524.65frames/s]\n  1%|          | 7600/632416 [00:13<17:44, 587.11frames/s]\n  2%|▏         | 9768/632416 [00:16<17:21, 597.93frames/s]\n  2%|▏         | 12724/632416 [00:20<15:50, 652.30frames/s]\n  2%|▏         | 15544/632416 [00:26<17:43, 579.95frames/s]\n  3%|▎         | 18226/632416 [00:32<18:55, 540.69frames/s]\n  3%|▎         | 21186/632416 [00:36<18:05, 562.94frames/s]\n  4%|▍         | 24090/632416 [00:43<19:36, 517.15frames/s]\n  4%|▍         | 26454/632416 [00:49<20:42, 487.55frames/s]\n  5%|▍         | 28914/632416 [00:54<20:37, 487.68frames/s]\n  5%|▍         | 31458/632416 [01:00<21:48, 459.19frames/s]\n  5%|▌         | 34458/632416 [01:06<21:21, 466.71frames/s]\n  5%|▌         | 34458/632416 [01:25<21:21, 466.71frames/s]\n  6%|▌         | 36714/632416 [01:30<43:01, 230.74frames/s]\n  6%|▌         | 39402/632416 [01:31<30:52, 320.14frames/s]\n  7%|▋         | 42186/632416 [01:37<28:14, 348.29frames/s]\n  7%|▋         | 45094/632416 [01:43<25:14, 387.79frames/s]\n  7%|▋         | 47362/632416 [01:47<23:26, 415.96frames/s]\n  8%|▊         | 50134/632416 [01:52<21:44, 446.41frames/s]\n  8%|▊         | 52958/632416 [01:57<20:01, 482.39frames/s]\n  9%|▉         | 55674/632416 [02:00<17:13, 557.90frames/s]\n  9%|▉         | 58486/632416 [02:06<17:45, 538.71frames/s]\n 10%|▉         | 61314/632416 [02:12<18:24, 516.89frames/s]\n 10%|█         | 64186/632416 [02:18<18:37, 508.51frames/s]\n 11%|█         | 67138/632416 [02:24<19:11, 490.96frames/s]\n 11%|█         | 70050/632416 [02:28<17:08, 546.96frames/s]\n 11%|█         | 70050/632416 [02:45<17:08, 546.96frames/s]\n 12%|█▏        | 72890/632416 [02:56<39:33, 235.74frames/s]\n 12%|█▏        | 75718/632416 [03:01<32:17, 287.33frames/s]\n 12%|█▏        | 78594/632416 [03:06<26:50, 343.86frames/s]\n 13%|█▎        | 81410/632416 [03:11<23:42, 387.25frames/s]\n 13%|█▎        | 84066/632416 [03:16<21:47, 419.24frames/s]\n 14%|█▎        | 86566/632416 [03:22<21:39, 419.94frames/s]\n 14%|█▍        | 89290/632416 [03:27<20:05, 450.54frames/s]\n 15%|█▍        | 92166/632416 [03:33<19:18, 466.32frames/s]\n 15%|█▌        | 95062/632416 [03:39<19:30, 459.07frames/s]\n 15%|█▌        | 97338/632416 [03:45<20:03, 444.78frames/s]\n 16%|█▌        | 100226/632416 [03:49<17:33, 505.00frames/s]\n 16%|█▋        | 103014/632416 [03:53<16:46, 525.88frames/s]\n 17%|█▋        | 105482/632416 [03:57<15:52, 553.17frames/s]\n 17%|█▋        | 108438/632416 [04:05<17:54, 487.50frames/s]\n 18%|█▊        | 111190/632416 [04:10<17:24, 498.99frames/s]\n 18%|█▊        | 113846/632416 [04:15<17:04, 506.06frames/s]\n 18%|█▊        | 116786/632416 [04:19<15:02, 571.36frames/s]\n 19%|█▉        | 119638/632416 [04:24<15:07, 564.96frames/s]\n 19%|█▉        | 122038/632416 [04:28<14:20, 593.38frames/s]\n 20%|█▉        | 124702/632416 [04:31<13:07, 644.91frames/s]\n 20%|██        | 127386/632416 [04:35<12:57, 649.75frames/s]\n 21%|██        | 129750/632416 [04:38<12:22, 677.03frames/s]\n 21%|██        | 132226/632416 [04:42<13:03, 638.13frames/s]\n 21%|██▏       | 134990/632416 [04:47<12:53, 642.91frames/s]\n 22%|██▏       | 137922/632416 [04:54<15:44, 523.76frames/s]\n 22%|██▏       | 137922/632416 [05:05<15:44, 523.76frames/s]\n 22%|██▏       | 140822/632416 [05:22<34:52, 234.95frames/s]\n 23%|██▎       | 143622/632416 [05:27<28:49, 282.55frames/s]\n 23%|██▎       | 146222/632416 [05:31<24:14, 334.34frames/s]\n 24%|██▎       | 148922/632416 [05:37<22:32, 357.39frames/s]\n 24%|██▍       | 151622/632416 [05:43<20:53, 383.54frames/s]\n 24%|██▍       | 154422/632416 [05:48<18:14, 436.69frames/s]\n 25%|██▍       | 157222/632416 [05:55<18:50, 420.18frames/s]\n 25%|██▌       | 160122/632416 [06:01<18:04, 435.46frames/s]\n 26%|██▌       | 162822/632416 [06:06<16:59, 460.47frames/s]\n 26%|██▌       | 165722/632416 [06:11<16:05, 483.45frames/s]\n 26%|██▋       | 167422/632416 [06:15<16:07, 480.69frames/s]\n 27%|██▋       | 169922/632416 [06:20<16:02, 480.39frames/s]\n 27%|██▋       | 172022/632416 [06:25<15:50, 484.45frames/s]\n 28%|██▊       | 174722/632416 [06:29<15:06, 504.73frames/s]\n 28%|██▊       | 177422/632416 [06:34<14:25, 525.43frames/s]\n 28%|██▊       | 180122/632416 [06:41<15:29, 486.85frames/s]\n 29%|██▉       | 182722/632416 [06:47<16:31, 453.71frames/s]\n 29%|██▉       | 185622/632416 [06:52<15:18, 486.53frames/s]\n 30%|██▉       | 188222/632416 [06:57<14:21, 515.87frames/s]\n 30%|███       | 190822/632416 [07:01<14:07, 521.00frames/s]\n 31%|███       | 193222/632416 [07:06<14:24, 508.24frames/s]\n 31%|███       | 195422/632416 [07:11<14:37, 497.83frames/s]\n 31%|███       | 197322/632416 [07:15<14:17, 507.65frames/s]\n 32%|███▏      | 200122/632416 [07:20<14:07, 510.05frames/s]\n 32%|███▏      | 202722/632416 [07:26<14:49, 483.20frames/s]\n 32%|███▏      | 205522/632416 [07:31<14:14, 499.56frames/s]\n 33%|███▎      | 208422/632416 [07:39<15:51, 445.73frames/s]\n 33%|███▎      | 211022/632416 [07:44<14:38, 479.67frames/s]\n 34%|███▍      | 214022/632416 [07:49<14:04, 495.61frames/s]\n 34%|███▍      | 216622/632416 [07:55<14:31, 476.84frames/s]\n 35%|███▍      | 219322/632416 [08:01<14:43, 467.71frames/s]\n 35%|███▌      | 222122/632416 [08:07<14:12, 481.15frames/s]\n 36%|███▌      | 225022/632416 [08:11<12:59, 522.54frames/s]\n 36%|███▌      | 227922/632416 [08:17<13:20, 505.45frames/s]\n 36%|███▋      | 230722/632416 [08:25<15:02, 445.18frames/s]\n 37%|███▋      | 233122/632416 [08:31<15:22, 432.83frames/s]\n 37%|███▋      | 235922/632416 [08:36<14:09, 466.81frames/s]\n 38%|███▊      | 238522/632416 [08:42<14:18, 458.88frames/s]\n 38%|███▊      | 241122/632416 [08:47<13:33, 480.91frames/s]\n 38%|███▊      | 243322/632416 [08:51<13:06, 494.54frames/s]\n 39%|███▉      | 246022/632416 [08:55<11:55, 539.91frames/s]\n 39%|███▉      | 248822/632416 [09:01<12:09, 525.65frames/s]\n 40%|███▉      | 251722/632416 [09:08<13:01, 487.33frames/s]\n 40%|████      | 254522/632416 [09:15<13:50, 455.14frames/s]\n 41%|████      | 257322/632416 [09:20<13:16, 471.01frames/s]\n 41%|████      | 259722/632416 [09:25<12:42, 488.75frames/s]\n 41%|████▏     | 262222/632416 [09:28<11:19, 544.81frames/s]\n 42%|████▏     | 264822/632416 [09:32<10:49, 565.72frames/s]\n 42%|████▏     | 267122/632416 [09:37<11:17, 538.86frames/s]\n 43%|████▎     | 269822/632416 [09:41<10:56, 552.43frames/s]\n 43%|████▎     | 272522/632416 [09:47<11:03, 542.53frames/s]\n 44%|████▎     | 275122/632416 [09:52<11:13, 530.77frames/s]\n 44%|████▍     | 277822/632416 [09:57<11:26, 516.76frames/s]\n 44%|████▍     | 280422/632416 [10:03<11:43, 500.06frames/s]\n 45%|████▍     | 282822/632416 [10:08<11:53, 490.07frames/s]\n 45%|████▌     | 285222/632416 [10:13<11:30, 502.68frames/s]\n 46%|████▌     | 287822/632416 [10:19<12:08, 472.91frames/s]\n 46%|████▌     | 290522/632416 [10:24<11:49, 481.55frames/s]\n 46%|████▋     | 293422/632416 [10:30<11:22, 496.84frames/s]\n 47%|████▋     | 296122/632416 [10:36<12:05, 463.80frames/s]\n 47%|████▋     | 298422/632416 [10:40<10:53, 511.42frames/s]\n 48%|████▊     | 301222/632416 [10:46<11:08, 495.19frames/s]\n 48%|████▊     | 303922/632416 [10:51<11:07, 492.24frames/s]\n 49%|████▊     | 306722/632416 [10:57<11:02, 491.32frames/s]\n 49%|████▉     | 309522/632416 [11:04<11:42, 459.38frames/s]\n 49%|████▉     | 312122/632416 [11:11<12:15, 435.28frames/s]\n 50%|████▉     | 314922/632416 [11:16<11:31, 459.33frames/s]\n 50%|█████     | 317822/632416 [11:20<10:02, 522.35frames/s]\n 51%|█████     | 320722/632416 [11:26<10:27, 496.52frames/s]\n 51%|█████     | 323522/632416 [11:35<11:53, 432.74frames/s]\n 52%|█████▏    | 326522/632416 [11:41<11:16, 451.91frames/s]\n 52%|█████▏    | 329322/632416 [11:46<10:50, 466.03frames/s]\n 53%|█████▎    | 332222/632416 [11:52<10:26, 479.19frames/s]\n 53%|█████▎    | 335122/632416 [11:58<10:28, 473.12frames/s]\n 53%|█████▎    | 337822/632416 [12:04<10:26, 470.25frames/s]\n 54%|█████▍    | 340722/632416 [12:10<09:58, 487.16frames/s]\n 54%|█████▍    | 343222/632416 [12:15<10:00, 481.90frames/s]\n 55%|█████▍    | 345922/632416 [12:19<09:07, 522.85frames/s]\n 55%|█████▌    | 348722/632416 [12:27<10:08, 466.16frames/s]\n 56%|█████▌    | 351622/632416 [12:34<10:35, 442.04frames/s]\n 56%|█████▌    | 354422/632416 [12:39<09:52, 469.29frames/s]\n 56%|█████▋    | 357222/632416 [12:44<09:25, 486.29frames/s]\n 57%|█████▋    | 359822/632416 [12:51<10:08, 447.94frames/s]\n 57%|█████▋    | 362522/632416 [12:57<09:52, 455.68frames/s]\n 58%|█████▊    | 365122/632416 [13:02<09:18, 478.93frames/s]\n 58%|█████▊    | 367822/632416 [13:06<08:36, 512.75frames/s]\n 59%|█████▊    | 370422/632416 [13:10<08:10, 534.23frames/s]\n 59%|█████▉    | 372222/632416 [13:12<07:01, 617.85frames/s]\n 59%|█████▉    | 375122/632416 [13:15<06:16, 683.40frames/s]\n 60%|█████▉    | 377922/632416 [13:23<07:49, 541.69frames/s]\n 60%|██████    | 380222/632416 [13:30<09:26, 445.05frames/s]\n 61%|██████    | 383022/632416 [13:38<09:50, 422.20frames/s]\n 61%|██████    | 385922/632416 [13:45<10:11, 402.84frames/s]\n 61%|██████▏   | 388722/632416 [13:54<10:55, 371.52frames/s]\n 62%|██████▏   | 391422/632416 [14:01<10:31, 381.89frames/s]\n 62%|██████▏   | 394322/632416 [14:06<09:10, 432.32frames/s]\n 63%|██████▎   | 395622/632416 [14:07<08:27, 466.23frames/s]\n 63%|██████▎   | 397122/632416 [14:09<07:21, 533.01frames/s]\n 63%|██████▎   | 400022/632416 [14:12<06:04, 637.80frames/s]\n 64%|██████▎   | 402122/632416 [14:17<07:08, 537.38frames/s]\n 64%|██████▍   | 405022/632416 [14:23<07:03, 537.56frames/s]\n 64%|██████▍   | 407522/632416 [14:28<07:29, 500.18frames/s]\n 65%|██████▍   | 410322/632416 [14:34<07:28, 494.83frames/s]\n 65%|██████▌   | 413222/632416 [14:40<07:31, 485.56frames/s]\n 66%|██████▌   | 416122/632416 [14:47<07:30, 480.29frames/s]\n 66%|██████▋   | 419022/632416 [14:54<08:06, 438.47frames/s]\n 67%|██████▋   | 421922/632416 [15:00<07:30, 467.19frames/s]\n 67%|██████▋   | 424622/632416 [15:07<07:56, 436.26frames/s]\n 68%|██████▊   | 427522/632416 [15:14<07:51, 434.33frames/s]\n 68%|██████▊   | 430022/632416 [15:21<08:14, 409.23frames/s]\n 68%|██████▊   | 432722/632416 [15:26<07:30, 443.34frames/s]\n 69%|██████▉   | 435522/632416 [15:31<07:11, 456.46frames/s]\n 69%|██████▉   | 437722/632416 [15:37<07:32, 430.01frames/s]\n 70%|██████▉   | 440522/632416 [15:42<06:46, 471.72frames/s]\n 70%|███████   | 443422/632416 [15:48<06:44, 466.98frames/s]\n 71%|███████   | 446222/632416 [15:54<06:25, 483.22frames/s]\n 71%|███████   | 448822/632416 [15:59<06:22, 480.33frames/s]\n 71%|███████▏  | 451022/632416 [16:03<05:53, 513.48frames/s]\n 72%|███████▏  | 453422/632416 [16:05<05:01, 592.71frames/s]\n 72%|███████▏  | 455922/632416 [16:09<04:54, 599.43frames/s]\n 72%|███████▏  | 455922/632416 [16:26<04:54, 599.43frames/s]\n 72%|███████▏  | 458422/632416 [16:39<13:42, 211.44frames/s]\n 73%|███████▎  | 461322/632416 [16:44<10:44, 265.43frames/s]\n 73%|███████▎  | 464022/632416 [16:49<08:50, 317.64frames/s]\n 74%|███████▍  | 466722/632416 [16:55<07:55, 348.70frames/s]\n 74%|███████▍  | 469522/632416 [17:03<07:46, 349.11frames/s]\n 75%|███████▍  | 472222/632416 [17:10<07:22, 362.36frames/s]\n 75%|███████▌  | 474922/632416 [17:16<06:49, 384.66frames/s]\n 76%|███████▌  | 477822/632416 [17:22<06:22, 404.20frames/s]\n 76%|███████▌  | 480622/632416 [17:30<06:24, 394.70frames/s]\n 76%|███████▋  | 483422/632416 [17:35<05:51, 423.97frames/s]\n 77%|███████▋  | 486122/632416 [17:41<05:42, 426.92frames/s]\n 77%|███████▋  | 488922/632416 [17:48<05:41, 419.74frames/s]\n 78%|███████▊  | 491422/632416 [17:53<05:16, 445.32frames/s]\n 78%|███████▊  | 494022/632416 [17:57<04:44, 486.39frames/s]\n 79%|███████▊  | 496522/632416 [18:02<04:39, 486.38frames/s]\n 79%|███████▉  | 498922/632416 [18:05<04:08, 538.05frames/s]\n 79%|███████▉  | 500422/632416 [18:07<03:46, 582.95frames/s]\n 80%|███████▉  | 503222/632416 [18:11<03:17, 654.05frames/s]\n 80%|███████▉  | 505322/632416 [18:14<03:14, 654.60frames/s]\n 80%|████████  | 508022/632416 [18:19<03:32, 585.55frames/s]\n 81%|████████  | 509622/632416 [18:22<03:27, 591.56frames/s]\n 81%|████████  | 511922/632416 [18:23<02:40, 751.47frames/s]\n 81%|████████▏ | 514822/632416 [18:29<02:59, 654.95frames/s]\n 82%|████████▏ | 517422/632416 [18:34<03:13, 595.28frames/s]\n 82%|████████▏ | 520022/632416 [18:40<03:32, 528.39frames/s]\n 83%|████████▎ | 522722/632416 [18:46<03:42, 493.85frames/s]\n 83%|████████▎ | 525322/632416 [18:52<03:37, 491.97frames/s]\n 83%|████████▎ | 528022/632416 [18:56<03:17, 529.47frames/s]\n 84%|████████▍ | 530822/632416 [19:03<03:30, 483.75frames/s]\n 84%|████████▍ | 533222/632416 [19:07<03:20, 495.18frames/s]\n 85%|████████▍ | 535522/632416 [19:11<03:02, 530.16frames/s]\n 85%|████████▌ | 538422/632416 [19:16<02:50, 551.72frames/s]\n 86%|████████▌ | 541222/632416 [19:22<02:54, 521.80frames/s]\n 86%|████████▌ | 544122/632416 [19:28<02:57, 496.10frames/s]\n 86%|████████▋ | 546922/632416 [19:35<03:01, 470.19frames/s]\n 87%|████████▋ | 549822/632416 [19:41<03:01, 455.73frames/s]\n 87%|████████▋ | 552422/632416 [19:48<03:00, 442.87frames/s]\n 88%|████████▊ | 555322/632416 [19:56<03:04, 417.87frames/s]\n 88%|████████▊ | 558222/632416 [20:03<03:01, 409.02frames/s]\n 89%|████████▊ | 560522/632416 [20:11<03:12, 373.88frames/s]\n 89%|████████▉ | 563422/632416 [20:16<02:44, 419.38frames/s]\n 90%|████████▉ | 566322/632416 [20:23<02:41, 409.39frames/s]\n 90%|█████████ | 569222/632416 [20:29<02:22, 444.59frames/s]\n 90%|█████████ | 571722/632416 [20:36<02:25, 415.90frames/s]\n 91%|█████████ | 574422/632416 [20:42<02:21, 410.78frames/s]\n 91%|█████████▏| 577222/632416 [20:49<02:10, 421.90frames/s]\n 92%|█████████▏| 579922/632416 [20:53<01:52, 466.41frames/s]\n 92%|█████████▏| 582022/632416 [20:59<01:56, 432.68frames/s]\n 92%|█████████▏| 584822/632416 [21:05<01:47, 442.91frames/s]\n 93%|█████████▎| 587222/632416 [21:10<01:39, 453.09frames/s]\n 93%|█████████▎| 589722/632416 [21:14<01:29, 477.02frames/s]\n 94%|█████████▎| 591922/632416 [21:19<01:23, 487.32frames/s]\n 94%|█████████▍| 594722/632416 [21:22<01:05, 578.69frames/s]\n 94%|█████████▍| 597522/632416 [21:27<01:02, 555.86frames/s]\n 95%|█████████▍| 600322/632416 [21:33<01:00, 534.03frames/s]\n 95%|█████████▌| 603122/632416 [21:39<00:58, 498.45frames/s]\n 96%|█████████▌| 605422/632416 [21:43<00:52, 518.78frames/s]\n 96%|█████████▌| 608322/632416 [21:49<00:46, 523.27frames/s]\n 97%|█████████▋| 611122/632416 [21:54<00:41, 508.14frames/s]\n 97%|█████████▋| 613822/632416 [22:01<00:38, 481.78frames/s]\n 97%|█████████▋| 616522/632416 [22:05<00:30, 516.68frames/s]\n 98%|█████████▊| 619222/632416 [22:10<00:25, 521.41frames/s]\n 98%|█████████▊| 622022/632416 [22:17<00:21, 482.74frames/s]\n 99%|█████████▉| 624822/632416 [22:22<00:15, 500.70frames/s]\n 99%|█████████▉| 627722/632416 [22:29<00:09, 473.41frames/s]\n100%|█████████▉| 630622/632416 [22:34<00:03, 497.51frames/s]\n100%|██████████| 632416/632416 [22:39<00:00, 466.17frames/s]\n100%|██████████| 632416/632416 [22:39<00:00, 465.25frames/s]\n",
  "output": {
    "detected_language": "english",
    "segments": [
      {
        "avg_logprob": -0.2972488178926356,
        "compression_ratio": 1.650943396226415,
        "end": 10.040000000000001,
        "id": 0,
        "no_speech_prob": 0.04739859327673912,
        "seek": 0,
        "start": 0,
        "temperature": 0,
        "text": " Okay, I have returned and I have restarted the computer and I have also switched some",
        "tokens": [
          50364,
          1033,
          11,
          286,
          362,
          8752,
          293,
          286,
          362,
          21022,
          292,
          264,
          3820,
          293,
          286,
          362,
          611,
          16858,
          512,
          50866
        ]
      },
      {
        "avg_logprob": -0.2972488178926356,
        "compression_ratio": 1.650943396226415,
        "end": 16.12,
        "id": 1,
        "no_speech_prob": 0.04739859327673912,
        "seek": 0,
        "start": 10.040000000000001,
        "temperature": 0,
        "text": " settings to, I had it set on YouTube for low latency because I like the live stream viewers",
        "tokens": [
          50866,
          6257,
          281,
          11,
          286,
          632,
          309,
          992,
          322,
          3088,
          337,
          2295,
          27043,
          570,
          286,
          411,
          264,
          1621,
          4309,
          8499,
          51170
        ]
      },
      {
        "avg_logprob": -0.2972488178926356,
        "compression_ratio": 1.650943396226415,
        "end": 22.6,
        "id": 2,
        "no_speech_prob": 0.04739859327673912,
        "seek": 0,
        "start": 16.12,
        "temperature": 0,
        "text": " to be as close in time to the actual real time of me speaking and demonstrating things,",
        "tokens": [
          51170,
          281,
          312,
          382,
          1998,
          294,
          565,
          281,
          264,
          3539,
          957,
          565,
          295,
          385,
          4124,
          293,
          29889,
          721,
          11,
          51494
        ]
      },
      {
        "avg_logprob": -0.2972488178926356,
        "compression_ratio": 1.650943396226415,
        "end": 27.96,
        "id": 3,
        "no_speech_prob": 0.04739859327673912,
        "seek": 0,
        "start": 22.6,
        "temperature": 0,
        "text": " but I switched it to normal latency in the hopes that that, you know, it says there,",
        "tokens": [
          51494,
          457,
          286,
          16858,
          309,
          281,
          2710,
          27043,
          294,
          264,
          13681,
          300,
          300,
          11,
          291,
          458,
          11,
          309,
          1619,
          456,
          11,
          51762
        ]
      },
      {
        "avg_logprob": -0.23311502190046413,
        "compression_ratio": 1.46,
        "end": 30.28,
        "id": 4,
        "no_speech_prob": 0.18704788386821747,
        "seek": 2796,
        "start": 27.96,
        "temperature": 0,
        "text": " highest viewer playback quality.",
        "tokens": [
          50364,
          6343,
          16767,
          37223,
          3125,
          13,
          50480
        ]
      },
      {
        "avg_logprob": -0.23311502190046413,
        "compression_ratio": 1.46,
        "end": 31.28,
        "id": 5,
        "no_speech_prob": 0.18704788386821747,
        "seek": 2796,
        "start": 30.28,
        "temperature": 0,
        "text": " So fixed.",
        "tokens": [
          50480,
          407,
          6806,
          13,
          50530
        ]
      },
      {
        "avg_logprob": -0.23311502190046413,
        "compression_ratio": 1.46,
        "end": 32.28,
        "id": 6,
        "no_speech_prob": 0.18704788386821747,
        "seek": 2796,
        "start": 31.28,
        "temperature": 0,
        "text": " Great.",
        "tokens": [
          50530,
          3769,
          13,
          50580
        ]
      },
      {
        "avg_logprob": -0.23311502190046413,
        "compression_ratio": 1.46,
        "end": 33.28,
        "id": 7,
        "no_speech_prob": 0.18704788386821747,
        "seek": 2796,
        "start": 32.28,
        "temperature": 0,
        "text": " All right.",
        "tokens": [
          50580,
          1057,
          558,
          13,
          50630
        ]
      },
      {
        "avg_logprob": -0.23311502190046413,
        "compression_ratio": 1.46,
        "end": 34.28,
        "id": 8,
        "no_speech_prob": 0.18704788386821747,
        "seek": 2796,
        "start": 33.28,
        "temperature": 0,
        "text": " Ah, wonderful.",
        "tokens": [
          50630,
          2438,
          11,
          3715,
          13,
          50680
        ]
      },
      {
        "avg_logprob": -0.23311502190046413,
        "compression_ratio": 1.46,
        "end": 36.56,
        "id": 9,
        "no_speech_prob": 0.18704788386821747,
        "seek": 2796,
        "start": 34.28,
        "temperature": 0,
        "text": " Okay, so that's good to know.",
        "tokens": [
          50680,
          1033,
          11,
          370,
          300,
          311,
          665,
          281,
          458,
          13,
          50794
        ]
      },
      {
        "avg_logprob": -0.23311502190046413,
        "compression_ratio": 1.46,
        "end": 39.64,
        "id": 10,
        "no_speech_prob": 0.18704788386821747,
        "seek": 2796,
        "start": 36.56,
        "temperature": 0,
        "text": " I guess I can't really use that low latency.",
        "tokens": [
          50794,
          286,
          2041,
          286,
          393,
          380,
          534,
          764,
          300,
          2295,
          27043,
          13,
          50948
        ]
      },
      {
        "avg_logprob": -0.23311502190046413,
        "compression_ratio": 1.46,
        "end": 45.6,
        "id": 11,
        "no_speech_prob": 0.18704788386821747,
        "seek": 2796,
        "start": 39.64,
        "temperature": 0,
        "text": " What I'm curious about is to do a little bit of timing.",
        "tokens": [
          50948,
          708,
          286,
          478,
          6369,
          466,
          307,
          281,
          360,
          257,
          707,
          857,
          295,
          10822,
          13,
          51246
        ]
      },
      {
        "avg_logprob": -0.23311502190046413,
        "compression_ratio": 1.46,
        "end": 49.84,
        "id": 12,
        "no_speech_prob": 0.18704788386821747,
        "seek": 2796,
        "start": 45.6,
        "temperature": 0,
        "text": " So what I'm going to do, so I'm going to watch the patron group in the Slack channel.",
        "tokens": [
          51246,
          407,
          437,
          286,
          478,
          516,
          281,
          360,
          11,
          370,
          286,
          478,
          516,
          281,
          1159,
          264,
          21843,
          1594,
          294,
          264,
          37211,
          2269,
          13,
          51458
        ]
      },
      {
        "avg_logprob": -0.29622373189011664,
        "compression_ratio": 1.5771812080536913,
        "end": 58.84,
        "id": 13,
        "no_speech_prob": 0.03358082100749016,
        "seek": 4984,
        "start": 49.84,
        "temperature": 0,
        "text": " I'm going to clap and then I'm going to start a timer on my watch.",
        "tokens": [
          50364,
          286,
          478,
          516,
          281,
          20760,
          293,
          550,
          286,
          478,
          516,
          281,
          722,
          257,
          19247,
          322,
          452,
          1159,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.29622373189011664,
        "compression_ratio": 1.5771812080536913,
        "end": 68.04,
        "id": 14,
        "no_speech_prob": 0.03358082100749016,
        "seek": 4984,
        "start": 58.84,
        "temperature": 0,
        "text": " Stop watch, reset, and I'm going to clap and then I want you to type clap into the patron",
        "tokens": [
          50814,
          5535,
          1159,
          11,
          14322,
          11,
          293,
          286,
          478,
          516,
          281,
          20760,
          293,
          550,
          286,
          528,
          291,
          281,
          2010,
          20760,
          666,
          264,
          21843,
          51274
        ]
      },
      {
        "avg_logprob": -0.29622373189011664,
        "compression_ratio": 1.5771812080536913,
        "end": 74,
        "id": 15,
        "no_speech_prob": 0.03358082100749016,
        "seek": 4984,
        "start": 68.04,
        "temperature": 0,
        "text": " Slack channel when I clap and I'll see how long the delay is.",
        "tokens": [
          51274,
          37211,
          2269,
          562,
          286,
          20760,
          293,
          286,
          603,
          536,
          577,
          938,
          264,
          8577,
          307,
          13,
          51572
        ]
      },
      {
        "avg_logprob": -0.29622373189011664,
        "compression_ratio": 1.5771812080536913,
        "end": 75,
        "id": 16,
        "no_speech_prob": 0.03358082100749016,
        "seek": 4984,
        "start": 74,
        "temperature": 0,
        "text": " Ready?",
        "tokens": [
          51572,
          9944,
          30,
          51622
        ]
      },
      {
        "avg_logprob": -0.29622373189011664,
        "compression_ratio": 1.5771812080536913,
        "end": 76,
        "id": 17,
        "no_speech_prob": 0.03358082100749016,
        "seek": 4984,
        "start": 75,
        "temperature": 0,
        "text": " Oh, wait.",
        "tokens": [
          51622,
          876,
          11,
          1699,
          13,
          51672
        ]
      },
      {
        "avg_logprob": -0.42136218731219954,
        "compression_ratio": 1.4296296296296296,
        "end": 78.08,
        "id": 18,
        "no_speech_prob": 0.18237042427062988,
        "seek": 7600,
        "start": 76.16,
        "temperature": 0,
        "text": " Actually, I'm going to say now.",
        "tokens": [
          50372,
          5135,
          11,
          286,
          478,
          516,
          281,
          584,
          586,
          13,
          50468
        ]
      },
      {
        "avg_logprob": -0.42136218731219954,
        "compression_ratio": 1.4296296296296296,
        "end": 85.12,
        "id": 19,
        "no_speech_prob": 0.18237042427062988,
        "seek": 7600,
        "start": 78.08,
        "temperature": 0,
        "text": " I can't clap because I'm going to press into the stopwatch.",
        "tokens": [
          50468,
          286,
          393,
          380,
          20760,
          570,
          286,
          478,
          516,
          281,
          1886,
          666,
          264,
          1590,
          15219,
          13,
          50820
        ]
      },
      {
        "avg_logprob": -0.42136218731219954,
        "compression_ratio": 1.4296296296296296,
        "end": 88.52,
        "id": 20,
        "no_speech_prob": 0.18237042427062988,
        "seek": 7600,
        "start": 85.12,
        "temperature": 0,
        "text": " Ready and now.",
        "tokens": [
          50820,
          9944,
          293,
          586,
          13,
          50990
        ]
      },
      {
        "avg_logprob": -0.42136218731219954,
        "compression_ratio": 1.4296296296296296,
        "end": 95.68,
        "id": 21,
        "no_speech_prob": 0.18237042427062988,
        "seek": 7600,
        "start": 88.52,
        "temperature": 0,
        "text": " So just type now when you hear this, although it'll be past.",
        "tokens": [
          50990,
          407,
          445,
          2010,
          586,
          562,
          291,
          1568,
          341,
          11,
          4878,
          309,
          603,
          312,
          1791,
          13,
          51348
        ]
      },
      {
        "avg_logprob": -0.42136218731219954,
        "compression_ratio": 1.4296296296296296,
        "end": 96.68,
        "id": 22,
        "no_speech_prob": 0.18237042427062988,
        "seek": 7600,
        "start": 95.68,
        "temperature": 0,
        "text": " I'm waiting.",
        "tokens": [
          51348,
          286,
          478,
          3806,
          13,
          51398
        ]
      },
      {
        "avg_logprob": -0.42136218731219954,
        "compression_ratio": 1.4296296296296296,
        "end": 97.68,
        "id": 23,
        "no_speech_prob": 0.18237042427062988,
        "seek": 7600,
        "start": 96.68,
        "temperature": 0,
        "text": " I'm waiting.",
        "tokens": [
          51398,
          286,
          478,
          3806,
          13,
          51448
        ]
      },
      {
        "avg_logprob": -0.3679402325604413,
        "compression_ratio": 1.3728813559322033,
        "end": 110.2,
        "id": 24,
        "no_speech_prob": 0.23084425926208496,
        "seek": 9768,
        "start": 97.68,
        "temperature": 0,
        "text": " Okay, I've really botched that.",
        "tokens": [
          50364,
          1033,
          11,
          286,
          600,
          534,
          10592,
          19318,
          300,
          13,
          50990
        ]
      },
      {
        "avg_logprob": -0.3679402325604413,
        "compression_ratio": 1.3728813559322033,
        "end": 113.88000000000001,
        "id": 25,
        "no_speech_prob": 0.23084425926208496,
        "seek": 9768,
        "start": 110.2,
        "temperature": 0,
        "text": " So you're about 17 seconds behind, which is fine.",
        "tokens": [
          50990,
          407,
          291,
          434,
          466,
          3282,
          3949,
          2261,
          11,
          597,
          307,
          2489,
          13,
          51174
        ]
      },
      {
        "avg_logprob": -0.3679402325604413,
        "compression_ratio": 1.3728813559322033,
        "end": 118.32000000000001,
        "id": 26,
        "no_speech_prob": 0.23084425926208496,
        "seek": 9768,
        "start": 113.88000000000001,
        "temperature": 0,
        "text": " Typically, I've been able to get the live stream lag down to less than 10 seconds, but",
        "tokens": [
          51174,
          23129,
          11,
          286,
          600,
          668,
          1075,
          281,
          483,
          264,
          1621,
          4309,
          8953,
          760,
          281,
          1570,
          813,
          1266,
          3949,
          11,
          457,
          51396
        ]
      },
      {
        "avg_logprob": -0.3679402325604413,
        "compression_ratio": 1.3728813559322033,
        "end": 120.56,
        "id": 27,
        "no_speech_prob": 0.23084425926208496,
        "seek": 9768,
        "start": 118.32000000000001,
        "temperature": 0,
        "text": " I'd much rather have higher quality for you.",
        "tokens": [
          51396,
          286,
          1116,
          709,
          2831,
          362,
          2946,
          3125,
          337,
          291,
          13,
          51508
        ]
      },
      {
        "avg_logprob": -0.3679402325604413,
        "compression_ratio": 1.3728813559322033,
        "end": 126.24000000000001,
        "id": 28,
        "no_speech_prob": 0.23084425926208496,
        "seek": 9768,
        "start": 120.56,
        "temperature": 0,
        "text": " Okay, we're back.",
        "tokens": [
          51508,
          1033,
          11,
          321,
          434,
          646,
          13,
          51792
        ]
      },
      {
        "avg_logprob": -0.3679402325604413,
        "compression_ratio": 1.3728813559322033,
        "end": 127.24000000000001,
        "id": 29,
        "no_speech_prob": 0.23084425926208496,
        "seek": 9768,
        "start": 126.24000000000001,
        "temperature": 0,
        "text": " All aboard.",
        "tokens": [
          51792,
          1057,
          27488,
          13,
          51842
        ]
      },
      {
        "avg_logprob": -0.3297499260016247,
        "compression_ratio": 1.5391304347826087,
        "end": 133.79999999999998,
        "id": 30,
        "no_speech_prob": 0.05500248819589615,
        "seek": 12724,
        "start": 127.8,
        "temperature": 0,
        "text": " Good morning, it's the coding train with me, your host.",
        "tokens": [
          50392,
          2205,
          2446,
          11,
          309,
          311,
          264,
          17720,
          3847,
          365,
          385,
          11,
          428,
          3975,
          13,
          50692
        ]
      },
      {
        "avg_logprob": -0.3297499260016247,
        "compression_ratio": 1.5391304347826087,
        "end": 134.79999999999998,
        "id": 31,
        "no_speech_prob": 0.05500248819589615,
        "seek": 12724,
        "start": 133.79999999999998,
        "temperature": 0,
        "text": " Something or other.",
        "tokens": [
          50692,
          6595,
          420,
          661,
          13,
          50742
        ]
      },
      {
        "avg_logprob": -0.3297499260016247,
        "compression_ratio": 1.5391304347826087,
        "end": 137.24,
        "id": 32,
        "no_speech_prob": 0.05500248819589615,
        "seek": 12724,
        "start": 134.79999999999998,
        "temperature": 0,
        "text": " Oh, there's actually a thing which gives the live latency.",
        "tokens": [
          50742,
          876,
          11,
          456,
          311,
          767,
          257,
          551,
          597,
          2709,
          264,
          1621,
          27043,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.3297499260016247,
        "compression_ratio": 1.5391304347826087,
        "end": 139.48,
        "id": 33,
        "no_speech_prob": 0.05500248819589615,
        "seek": 12724,
        "start": 137.24,
        "temperature": 0,
        "text": " All right.",
        "tokens": [
          50864,
          1057,
          558,
          13,
          50976
        ]
      },
      {
        "avg_logprob": -0.3297499260016247,
        "compression_ratio": 1.5391304347826087,
        "end": 142.16,
        "id": 34,
        "no_speech_prob": 0.05500248819589615,
        "seek": 12724,
        "start": 139.48,
        "temperature": 0,
        "text": " So I'm all rattled now.",
        "tokens": [
          50976,
          407,
          286,
          478,
          439,
          27081,
          1493,
          586,
          13,
          51110
        ]
      },
      {
        "avg_logprob": -0.3297499260016247,
        "compression_ratio": 1.5391304347826087,
        "end": 143.16,
        "id": 35,
        "no_speech_prob": 0.05500248819589615,
        "seek": 12724,
        "start": 142.16,
        "temperature": 0,
        "text": " So what was I talking about?",
        "tokens": [
          51110,
          407,
          437,
          390,
          286,
          1417,
          466,
          30,
          51160
        ]
      },
      {
        "avg_logprob": -0.3297499260016247,
        "compression_ratio": 1.5391304347826087,
        "end": 144.16,
        "id": 36,
        "no_speech_prob": 0.05500248819589615,
        "seek": 12724,
        "start": 143.16,
        "temperature": 0,
        "text": " Let me read.",
        "tokens": [
          51160,
          961,
          385,
          1401,
          13,
          51210
        ]
      },
      {
        "avg_logprob": -0.3297499260016247,
        "compression_ratio": 1.5391304347826087,
        "end": 147.35999999999999,
        "id": 37,
        "no_speech_prob": 0.05500248819589615,
        "seek": 12724,
        "start": 144.16,
        "temperature": 0,
        "text": " Let me act as if nothing has happened and I've just started.",
        "tokens": [
          51210,
          961,
          385,
          605,
          382,
          498,
          1825,
          575,
          2011,
          293,
          286,
          600,
          445,
          1409,
          13,
          51370
        ]
      },
      {
        "avg_logprob": -0.3297499260016247,
        "compression_ratio": 1.5391304347826087,
        "end": 148.88,
        "id": 38,
        "no_speech_prob": 0.05500248819589615,
        "seek": 12724,
        "start": 147.35999999999999,
        "temperature": 0,
        "text": " I'm going to click over here.",
        "tokens": [
          51370,
          286,
          478,
          516,
          281,
          2052,
          670,
          510,
          13,
          51446
        ]
      },
      {
        "avg_logprob": -0.3297499260016247,
        "compression_ratio": 1.5391304347826087,
        "end": 155.44,
        "id": 39,
        "no_speech_prob": 0.05500248819589615,
        "seek": 12724,
        "start": 148.88,
        "temperature": 0,
        "text": " Now I was saying, oh, I've run out of so much time.",
        "tokens": [
          51446,
          823,
          286,
          390,
          1566,
          11,
          1954,
          11,
          286,
          600,
          1190,
          484,
          295,
          370,
          709,
          565,
          13,
          51774
        ]
      },
      {
        "avg_logprob": -0.26704659895463423,
        "compression_ratio": 1.5833333333333333,
        "end": 163.4,
        "id": 40,
        "no_speech_prob": 0.6548067927360535,
        "seek": 15544,
        "start": 155.44,
        "temperature": 0,
        "text": " Coming soon, next week some point, a video tutorial from Lisa Jamboree about the Connectron",
        "tokens": [
          50364,
          12473,
          2321,
          11,
          958,
          1243,
          512,
          935,
          11,
          257,
          960,
          7073,
          490,
          12252,
          508,
          2173,
          418,
          68,
          466,
          264,
          11653,
          2044,
          50762
        ]
      },
      {
        "avg_logprob": -0.26704659895463423,
        "compression_ratio": 1.5833333333333333,
        "end": 164.4,
        "id": 41,
        "no_speech_prob": 0.6548067927360535,
        "seek": 15544,
        "start": 163.4,
        "temperature": 0,
        "text": " project.",
        "tokens": [
          50762,
          1716,
          13,
          50812
        ]
      },
      {
        "avg_logprob": -0.26704659895463423,
        "compression_ratio": 1.5833333333333333,
        "end": 166.4,
        "id": 42,
        "no_speech_prob": 0.6548067927360535,
        "seek": 15544,
        "start": 164.4,
        "temperature": 0,
        "text": " So I was talking about that earlier.",
        "tokens": [
          50812,
          407,
          286,
          390,
          1417,
          466,
          300,
          3071,
          13,
          50912
        ]
      },
      {
        "avg_logprob": -0.26704659895463423,
        "compression_ratio": 1.5833333333333333,
        "end": 167.56,
        "id": 43,
        "no_speech_prob": 0.6548067927360535,
        "seek": 15544,
        "start": 166.4,
        "temperature": 0,
        "text": " I guess I won't talk about it again.",
        "tokens": [
          50912,
          286,
          2041,
          286,
          1582,
          380,
          751,
          466,
          309,
          797,
          13,
          50970
        ]
      },
      {
        "avg_logprob": -0.26704659895463423,
        "compression_ratio": 1.5833333333333333,
        "end": 172.28,
        "id": 44,
        "no_speech_prob": 0.6548067927360535,
        "seek": 15544,
        "start": 167.56,
        "temperature": 0,
        "text": " I feel like I'm repeating myself, even though maybe that's all that bad quality stream thing",
        "tokens": [
          50970,
          286,
          841,
          411,
          286,
          478,
          18617,
          2059,
          11,
          754,
          1673,
          1310,
          300,
          311,
          439,
          300,
          1578,
          3125,
          4309,
          551,
          51206
        ]
      },
      {
        "avg_logprob": -0.26704659895463423,
        "compression_ratio": 1.5833333333333333,
        "end": 176.74,
        "id": 45,
        "no_speech_prob": 0.6548067927360535,
        "seek": 15544,
        "start": 172.28,
        "temperature": 0,
        "text": " is now gone from the internet forever.",
        "tokens": [
          51206,
          307,
          586,
          2780,
          490,
          264,
          4705,
          5680,
          13,
          51429
        ]
      },
      {
        "avg_logprob": -0.26704659895463423,
        "compression_ratio": 1.5833333333333333,
        "end": 179.64,
        "id": 46,
        "no_speech_prob": 0.6548067927360535,
        "seek": 15544,
        "start": 176.74,
        "temperature": 0,
        "text": " This afternoon, I want to get started with some coding because I've already lost a lot",
        "tokens": [
          51429,
          639,
          6499,
          11,
          286,
          528,
          281,
          483,
          1409,
          365,
          512,
          17720,
          570,
          286,
          600,
          1217,
          2731,
          257,
          688,
          51574
        ]
      },
      {
        "avg_logprob": -0.26704659895463423,
        "compression_ratio": 1.5833333333333333,
        "end": 182.26,
        "id": 47,
        "no_speech_prob": 0.6548067927360535,
        "seek": 15544,
        "start": 179.64,
        "temperature": 0,
        "text": " of my wasting time time.",
        "tokens": [
          51574,
          295,
          452,
          20457,
          565,
          565,
          13,
          51705
        ]
      },
      {
        "avg_logprob": -0.40717889929330475,
        "compression_ratio": 1.5392670157068062,
        "end": 188.82,
        "id": 48,
        "no_speech_prob": 0.32070404291152954,
        "seek": 18226,
        "start": 182.26,
        "temperature": 0,
        "text": " This afternoon, I am very excited to announce that Twitter.com, let me go actually Twitch",
        "tokens": [
          50364,
          639,
          6499,
          11,
          286,
          669,
          588,
          2919,
          281,
          7478,
          300,
          5794,
          13,
          1112,
          11,
          718,
          385,
          352,
          767,
          22222,
          50692
        ]
      },
      {
        "avg_logprob": -0.40717889929330475,
        "compression_ratio": 1.5392670157068062,
        "end": 189.82,
        "id": 49,
        "no_speech_prob": 0.32070404291152954,
        "seek": 18226,
        "start": 188.82,
        "temperature": 0,
        "text": " Noop Cat.",
        "tokens": [
          50692,
          883,
          404,
          9565,
          13,
          50742
        ]
      },
      {
        "avg_logprob": -0.40717889929330475,
        "compression_ratio": 1.5392670157068062,
        "end": 200.29999999999998,
        "id": 50,
        "no_speech_prob": 0.32070404291152954,
        "seek": 18226,
        "start": 189.82,
        "temperature": 0,
        "text": " Let's on the live stream this afternoon will be Noop Cat from Twitch that you might know",
        "tokens": [
          50742,
          961,
          311,
          322,
          264,
          1621,
          4309,
          341,
          6499,
          486,
          312,
          883,
          404,
          9565,
          490,
          22222,
          300,
          291,
          1062,
          458,
          51266
        ]
      },
      {
        "avg_logprob": -0.40717889929330475,
        "compression_ratio": 1.5392670157068062,
        "end": 202.85999999999999,
        "id": 51,
        "no_speech_prob": 0.32070404291152954,
        "seek": 18226,
        "start": 200.29999999999998,
        "temperature": 0,
        "text": " from, ah, don't make me watch this ad.",
        "tokens": [
          51266,
          490,
          11,
          3716,
          11,
          500,
          380,
          652,
          385,
          1159,
          341,
          614,
          13,
          51394
        ]
      },
      {
        "avg_logprob": -0.40717889929330475,
        "compression_ratio": 1.5392670157068062,
        "end": 204.85999999999999,
        "id": 52,
        "no_speech_prob": 0.32070404291152954,
        "seek": 18226,
        "start": 202.85999999999999,
        "temperature": 0,
        "text": " Okay, okay.",
        "tokens": [
          51394,
          1033,
          11,
          1392,
          13,
          51494
        ]
      },
      {
        "avg_logprob": -0.40717889929330475,
        "compression_ratio": 1.5392670157068062,
        "end": 209.85999999999999,
        "id": 53,
        "no_speech_prob": 0.32070404291152954,
        "seek": 18226,
        "start": 204.85999999999999,
        "temperature": 0,
        "text": " I'm so, okay, hold on.",
        "tokens": [
          51494,
          286,
          478,
          370,
          11,
          1392,
          11,
          1797,
          322,
          13,
          51744
        ]
      },
      {
        "avg_logprob": -0.40717889929330475,
        "compression_ratio": 1.5392670157068062,
        "end": 211.85999999999999,
        "id": 54,
        "no_speech_prob": 0.32070404291152954,
        "seek": 18226,
        "start": 209.85999999999999,
        "temperature": 0,
        "text": " Let's go to Noop Cat's website.",
        "tokens": [
          51744,
          961,
          311,
          352,
          281,
          883,
          404,
          9565,
          311,
          3144,
          13,
          51844
        ]
      },
      {
        "avg_logprob": -0.31467107337290845,
        "compression_ratio": 1.694915254237288,
        "end": 219.94000000000003,
        "id": 55,
        "no_speech_prob": 0.5466238856315613,
        "seek": 21186,
        "start": 212.46,
        "temperature": 0,
        "text": " So Noop Cat, Suze Hinton, will be here this afternoon at about 2.30pm Eastern time to",
        "tokens": [
          50394,
          407,
          883,
          404,
          9565,
          11,
          2746,
          1381,
          389,
          12442,
          11,
          486,
          312,
          510,
          341,
          6499,
          412,
          466,
          568,
          13,
          3446,
          14395,
          12901,
          565,
          281,
          50768
        ]
      },
      {
        "avg_logprob": -0.31467107337290845,
        "compression_ratio": 1.694915254237288,
        "end": 223.14000000000001,
        "id": 56,
        "no_speech_prob": 0.5466238856315613,
        "seek": 21186,
        "start": 219.94000000000003,
        "temperature": 0,
        "text": " talk about doing stuff with hardware and JavaScript.",
        "tokens": [
          50768,
          751,
          466,
          884,
          1507,
          365,
          8837,
          293,
          15778,
          13,
          50928
        ]
      },
      {
        "avg_logprob": -0.31467107337290845,
        "compression_ratio": 1.694915254237288,
        "end": 227.78,
        "id": 57,
        "no_speech_prob": 0.5466238856315613,
        "seek": 21186,
        "start": 223.14000000000001,
        "temperature": 0,
        "text": " I will stand all the way, I will have to leave the room or stand all the way in the corner",
        "tokens": [
          50928,
          286,
          486,
          1463,
          439,
          264,
          636,
          11,
          286,
          486,
          362,
          281,
          1856,
          264,
          1808,
          420,
          1463,
          439,
          264,
          636,
          294,
          264,
          4538,
          51160
        ]
      },
      {
        "avg_logprob": -0.31467107337290845,
        "compression_ratio": 1.694915254237288,
        "end": 231.98000000000002,
        "id": 58,
        "no_speech_prob": 0.5466238856315613,
        "seek": 21186,
        "start": 227.78,
        "temperature": 0,
        "text": " or something because if I go near hardware, it spontaneously bursts into flame.",
        "tokens": [
          51160,
          420,
          746,
          570,
          498,
          286,
          352,
          2651,
          8837,
          11,
          309,
          47632,
          41663,
          666,
          13287,
          13,
          51370
        ]
      },
      {
        "avg_logprob": -0.31467107337290845,
        "compression_ratio": 1.694915254237288,
        "end": 235.74,
        "id": 59,
        "no_speech_prob": 0.5466238856315613,
        "seek": 21186,
        "start": 231.98000000000002,
        "temperature": 0,
        "text": " There's actually downstairs in the shop, in the physical computing areas, there's various",
        "tokens": [
          51370,
          821,
          311,
          767,
          20148,
          294,
          264,
          3945,
          11,
          294,
          264,
          4001,
          15866,
          3179,
          11,
          456,
          311,
          3683,
          51558
        ]
      },
      {
        "avg_logprob": -0.31467107337290845,
        "compression_ratio": 1.694915254237288,
        "end": 236.94000000000003,
        "id": 60,
        "no_speech_prob": 0.5466238856315613,
        "seek": 21186,
        "start": 235.74,
        "temperature": 0,
        "text": " alarms that are set up.",
        "tokens": [
          51558,
          45039,
          300,
          366,
          992,
          493,
          13,
          51618
        ]
      },
      {
        "avg_logprob": -0.31467107337290845,
        "compression_ratio": 1.694915254237288,
        "end": 240.9,
        "id": 61,
        "no_speech_prob": 0.5466238856315613,
        "seek": 21186,
        "start": 236.94000000000003,
        "temperature": 0,
        "text": " If I walk anywhere near, all the alarms go off, all the students go running.",
        "tokens": [
          51618,
          759,
          286,
          1792,
          4992,
          2651,
          11,
          439,
          264,
          45039,
          352,
          766,
          11,
          439,
          264,
          1731,
          352,
          2614,
          13,
          51816
        ]
      },
      {
        "avg_logprob": -0.2547592448296948,
        "compression_ratio": 1.5817490494296578,
        "end": 244.46,
        "id": 62,
        "no_speech_prob": 0.3173171579837799,
        "seek": 24090,
        "start": 240.94,
        "temperature": 0,
        "text": " But I have the opposite effect sometimes on this like code, JavaScript code.",
        "tokens": [
          50366,
          583,
          286,
          362,
          264,
          6182,
          1802,
          2171,
          322,
          341,
          411,
          3089,
          11,
          15778,
          3089,
          13,
          50542
        ]
      },
      {
        "avg_logprob": -0.2547592448296948,
        "compression_ratio": 1.5817490494296578,
        "end": 248.06,
        "id": 63,
        "no_speech_prob": 0.3173171579837799,
        "seek": 24090,
        "start": 244.46,
        "temperature": 0,
        "text": " I could just walk by a computer and the bugs kind of go away.",
        "tokens": [
          50542,
          286,
          727,
          445,
          1792,
          538,
          257,
          3820,
          293,
          264,
          15120,
          733,
          295,
          352,
          1314,
          13,
          50722
        ]
      },
      {
        "avg_logprob": -0.2547592448296948,
        "compression_ratio": 1.5817490494296578,
        "end": 252.06,
        "id": 64,
        "no_speech_prob": 0.3173171579837799,
        "seek": 24090,
        "start": 248.06,
        "temperature": 0,
        "text": " I lead a very strange life.",
        "tokens": [
          50722,
          286,
          1477,
          257,
          588,
          5861,
          993,
          13,
          50922
        ]
      },
      {
        "avg_logprob": -0.2547592448296948,
        "compression_ratio": 1.5817490494296578,
        "end": 255.06,
        "id": 65,
        "no_speech_prob": 0.3173171579837799,
        "seek": 24090,
        "start": 252.06,
        "temperature": 0,
        "text": " So I would love for you to come and tune in this afternoon.",
        "tokens": [
          50922,
          407,
          286,
          576,
          959,
          337,
          291,
          281,
          808,
          293,
          10864,
          294,
          341,
          6499,
          13,
          51072
        ]
      },
      {
        "avg_logprob": -0.2547592448296948,
        "compression_ratio": 1.5817490494296578,
        "end": 259.9,
        "id": 66,
        "no_speech_prob": 0.3173171579837799,
        "seek": 24090,
        "start": 255.06,
        "temperature": 0,
        "text": " I'm really excited to have Noop Cat as a guest and I encourage you to subscribe to her Twitch",
        "tokens": [
          51072,
          286,
          478,
          534,
          2919,
          281,
          362,
          883,
          404,
          9565,
          382,
          257,
          8341,
          293,
          286,
          5373,
          291,
          281,
          3022,
          281,
          720,
          22222,
          51314
        ]
      },
      {
        "avg_logprob": -0.2547592448296948,
        "compression_ratio": 1.5817490494296578,
        "end": 260.9,
        "id": 67,
        "no_speech_prob": 0.3173171579837799,
        "seek": 24090,
        "start": 259.9,
        "temperature": 0,
        "text": " channel.",
        "tokens": [
          51314,
          2269,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.2547592448296948,
        "compression_ratio": 1.5817490494296578,
        "end": 264.54,
        "id": 68,
        "no_speech_prob": 0.3173171579837799,
        "seek": 24090,
        "start": 260.9,
        "temperature": 0,
        "text": " She typically does live streams on Sundays and I'm hoping to make an appearance on one",
        "tokens": [
          51364,
          1240,
          5850,
          775,
          1621,
          15842,
          322,
          44857,
          293,
          286,
          478,
          7159,
          281,
          652,
          364,
          8967,
          322,
          472,
          51546
        ]
      },
      {
        "avg_logprob": -0.3523596144214119,
        "compression_ratio": 1.6728971962616823,
        "end": 271.1,
        "id": 69,
        "no_speech_prob": 0.7632501721382141,
        "seek": 26454,
        "start": 264.54,
        "temperature": 0,
        "text": " of her live streams as well in my desire to collaborate with other people in the world",
        "tokens": [
          50364,
          295,
          720,
          1621,
          15842,
          382,
          731,
          294,
          452,
          7516,
          281,
          18338,
          365,
          661,
          561,
          294,
          264,
          1002,
          50692
        ]
      },
      {
        "avg_logprob": -0.3523596144214119,
        "compression_ratio": 1.6728971962616823,
        "end": 275.62,
        "id": 70,
        "no_speech_prob": 0.7632501721382141,
        "seek": 26454,
        "start": 271.1,
        "temperature": 0,
        "text": " of streaming, educational coding technology.",
        "tokens": [
          50692,
          295,
          11791,
          11,
          10189,
          17720,
          2899,
          13,
          50918
        ]
      },
      {
        "avg_logprob": -0.3523596144214119,
        "compression_ratio": 1.6728971962616823,
        "end": 276.62,
        "id": 71,
        "no_speech_prob": 0.7632501721382141,
        "seek": 26454,
        "start": 275.62,
        "temperature": 0,
        "text": " I don't know.",
        "tokens": [
          50918,
          286,
          500,
          380,
          458,
          13,
          50968
        ]
      },
      {
        "avg_logprob": -0.3523596144214119,
        "compression_ratio": 1.6728971962616823,
        "end": 280.06,
        "id": 72,
        "no_speech_prob": 0.7632501721382141,
        "seek": 26454,
        "start": 276.62,
        "temperature": 0,
        "text": " If there's anybody out there doing musical theater, I would love to collaborate with",
        "tokens": [
          50968,
          759,
          456,
          311,
          4472,
          484,
          456,
          884,
          9165,
          10612,
          11,
          286,
          576,
          959,
          281,
          18338,
          365,
          51140
        ]
      },
      {
        "avg_logprob": -0.3523596144214119,
        "compression_ratio": 1.6728971962616823,
        "end": 281.06,
        "id": 73,
        "no_speech_prob": 0.7632501721382141,
        "seek": 26454,
        "start": 280.06,
        "temperature": 0,
        "text": " you actually.",
        "tokens": [
          51140,
          291,
          767,
          13,
          51190
        ]
      },
      {
        "avg_logprob": -0.3523596144214119,
        "compression_ratio": 1.6728971962616823,
        "end": 283.70000000000005,
        "id": 74,
        "no_speech_prob": 0.7632501721382141,
        "seek": 26454,
        "start": 281.06,
        "temperature": 0,
        "text": " But you probably don't want to collaborate with me.",
        "tokens": [
          51190,
          583,
          291,
          1391,
          500,
          380,
          528,
          281,
          18338,
          365,
          385,
          13,
          51322
        ]
      },
      {
        "avg_logprob": -0.3523596144214119,
        "compression_ratio": 1.6728971962616823,
        "end": 288.06,
        "id": 75,
        "no_speech_prob": 0.7632501721382141,
        "seek": 26454,
        "start": 283.70000000000005,
        "temperature": 0,
        "text": " Okay, is it Noop Cat or Noop Cat?",
        "tokens": [
          51322,
          1033,
          11,
          307,
          309,
          883,
          404,
          9565,
          420,
          883,
          404,
          9565,
          30,
          51540
        ]
      },
      {
        "avg_logprob": -0.3523596144214119,
        "compression_ratio": 1.6728971962616823,
        "end": 289.14000000000004,
        "id": 76,
        "no_speech_prob": 0.7632501721382141,
        "seek": 26454,
        "start": 288.06,
        "temperature": 0,
        "text": " I always just say Noop Cat.",
        "tokens": [
          51540,
          286,
          1009,
          445,
          584,
          883,
          404,
          9565,
          13,
          51594
        ]
      },
      {
        "avg_logprob": -0.2638615553941184,
        "compression_ratio": 1.7822222222222222,
        "end": 291.21999999999997,
        "id": 77,
        "no_speech_prob": 0.6331624388694763,
        "seek": 28914,
        "start": 289.3,
        "temperature": 0,
        "text": " Am I been saying it wrong all this time?",
        "tokens": [
          50372,
          2012,
          286,
          668,
          1566,
          309,
          2085,
          439,
          341,
          565,
          30,
          50468
        ]
      },
      {
        "avg_logprob": -0.2638615553941184,
        "compression_ratio": 1.7822222222222222,
        "end": 294.46,
        "id": 78,
        "no_speech_prob": 0.6331624388694763,
        "seek": 28914,
        "start": 291.21999999999997,
        "temperature": 0,
        "text": " Like Noop Cat, like No Operation Cat?",
        "tokens": [
          50468,
          1743,
          883,
          404,
          9565,
          11,
          411,
          883,
          27946,
          9565,
          30,
          50630
        ]
      },
      {
        "avg_logprob": -0.2638615553941184,
        "compression_ratio": 1.7822222222222222,
        "end": 295.46,
        "id": 79,
        "no_speech_prob": 0.6331624388694763,
        "seek": 28914,
        "start": 294.46,
        "temperature": 0,
        "text": " I have no idea.",
        "tokens": [
          50630,
          286,
          362,
          572,
          1558,
          13,
          50680
        ]
      },
      {
        "avg_logprob": -0.2638615553941184,
        "compression_ratio": 1.7822222222222222,
        "end": 297.5,
        "id": 80,
        "no_speech_prob": 0.6331624388694763,
        "seek": 28914,
        "start": 295.46,
        "temperature": 0,
        "text": " Have I been saying it wrong all this time?",
        "tokens": [
          50680,
          3560,
          286,
          668,
          1566,
          309,
          2085,
          439,
          341,
          565,
          30,
          50782
        ]
      },
      {
        "avg_logprob": -0.2638615553941184,
        "compression_ratio": 1.7822222222222222,
        "end": 298.5,
        "id": 81,
        "no_speech_prob": 0.6331624388694763,
        "seek": 28914,
        "start": 297.5,
        "temperature": 0,
        "text": " Well, guess what?",
        "tokens": [
          50782,
          1042,
          11,
          2041,
          437,
          30,
          50832
        ]
      },
      {
        "avg_logprob": -0.2638615553941184,
        "compression_ratio": 1.7822222222222222,
        "end": 300.41999999999996,
        "id": 82,
        "no_speech_prob": 0.6331624388694763,
        "seek": 28914,
        "start": 298.5,
        "temperature": 0,
        "text": " We're going to find out this afternoon.",
        "tokens": [
          50832,
          492,
          434,
          516,
          281,
          915,
          484,
          341,
          6499,
          13,
          50928
        ]
      },
      {
        "avg_logprob": -0.2638615553941184,
        "compression_ratio": 1.7822222222222222,
        "end": 305.86,
        "id": 83,
        "no_speech_prob": 0.6331624388694763,
        "seek": 28914,
        "start": 300.41999999999996,
        "temperature": 0,
        "text": " The mystery will be solved.",
        "tokens": [
          50928,
          440,
          11422,
          486,
          312,
          13041,
          13,
          51200
        ]
      },
      {
        "avg_logprob": -0.2638615553941184,
        "compression_ratio": 1.7822222222222222,
        "end": 308.41999999999996,
        "id": 84,
        "no_speech_prob": 0.6331624388694763,
        "seek": 28914,
        "start": 305.86,
        "temperature": 0,
        "text": " So what am I here to do today?",
        "tokens": [
          51200,
          407,
          437,
          669,
          286,
          510,
          281,
          360,
          965,
          30,
          51328
        ]
      },
      {
        "avg_logprob": -0.2638615553941184,
        "compression_ratio": 1.7822222222222222,
        "end": 310.18,
        "id": 85,
        "no_speech_prob": 0.6331624388694763,
        "seek": 28914,
        "start": 308.41999999999996,
        "temperature": 0,
        "text": " I am going to talk to you about these things.",
        "tokens": [
          51328,
          286,
          669,
          516,
          281,
          751,
          281,
          291,
          466,
          613,
          721,
          13,
          51416
        ]
      },
      {
        "avg_logprob": -0.2638615553941184,
        "compression_ratio": 1.7822222222222222,
        "end": 313.58,
        "id": 86,
        "no_speech_prob": 0.6331624388694763,
        "seek": 28914,
        "start": 310.18,
        "temperature": 0,
        "text": " First what I'm going to do while I'm talking about these things, I'm going to erase this",
        "tokens": [
          51416,
          2386,
          437,
          286,
          478,
          516,
          281,
          360,
          1339,
          286,
          478,
          1417,
          466,
          613,
          721,
          11,
          286,
          478,
          516,
          281,
          23525,
          341,
          51586
        ]
      },
      {
        "avg_logprob": -0.2638615553941184,
        "compression_ratio": 1.7822222222222222,
        "end": 314.58,
        "id": 87,
        "no_speech_prob": 0.6331624388694763,
        "seek": 28914,
        "start": 313.58,
        "temperature": 0,
        "text": " whiteboard.",
        "tokens": [
          51586,
          2418,
          3787,
          13,
          51636
        ]
      },
      {
        "avg_logprob": -0.33388001124064126,
        "compression_ratio": 1.67578125,
        "end": 321.74,
        "id": 88,
        "no_speech_prob": 0.12247154861688614,
        "seek": 31458,
        "start": 315.58,
        "temperature": 0,
        "text": " Wouldn't it be nice if during a live stream I could have that like effect where it's just",
        "tokens": [
          50414,
          26291,
          380,
          309,
          312,
          1481,
          498,
          1830,
          257,
          1621,
          4309,
          286,
          727,
          362,
          300,
          411,
          1802,
          689,
          309,
          311,
          445,
          50722
        ]
      },
      {
        "avg_logprob": -0.33388001124064126,
        "compression_ratio": 1.67578125,
        "end": 324.14,
        "id": 89,
        "no_speech_prob": 0.12247154861688614,
        "seek": 31458,
        "start": 321.74,
        "temperature": 0,
        "text": " like me and fast forward doing it really fast.",
        "tokens": [
          50722,
          411,
          385,
          293,
          2370,
          2128,
          884,
          309,
          534,
          2370,
          13,
          50842
        ]
      },
      {
        "avg_logprob": -0.33388001124064126,
        "compression_ratio": 1.67578125,
        "end": 327.62,
        "id": 90,
        "no_speech_prob": 0.12247154861688614,
        "seek": 31458,
        "start": 324.14,
        "temperature": 0,
        "text": " Maybe I could try to do that live because that was recently in one of my videos.",
        "tokens": [
          50842,
          2704,
          286,
          727,
          853,
          281,
          360,
          300,
          1621,
          570,
          300,
          390,
          3938,
          294,
          472,
          295,
          452,
          2145,
          13,
          51016
        ]
      },
      {
        "avg_logprob": -0.33388001124064126,
        "compression_ratio": 1.67578125,
        "end": 332.74,
        "id": 91,
        "no_speech_prob": 0.12247154861688614,
        "seek": 31458,
        "start": 327.62,
        "temperature": 0,
        "text": " Mathieu, who does the editing, put in this like speed up effect thing and everybody loved",
        "tokens": [
          51016,
          15776,
          19347,
          11,
          567,
          775,
          264,
          10000,
          11,
          829,
          294,
          341,
          411,
          3073,
          493,
          1802,
          551,
          293,
          2201,
          4333,
          51272
        ]
      },
      {
        "avg_logprob": -0.33388001124064126,
        "compression_ratio": 1.67578125,
        "end": 333.74,
        "id": 92,
        "no_speech_prob": 0.12247154861688614,
        "seek": 31458,
        "start": 332.74,
        "temperature": 0,
        "text": " it.",
        "tokens": [
          51272,
          309,
          13,
          51322
        ]
      },
      {
        "avg_logprob": -0.33388001124064126,
        "compression_ratio": 1.67578125,
        "end": 334.74,
        "id": 93,
        "no_speech_prob": 0.12247154861688614,
        "seek": 31458,
        "start": 333.74,
        "temperature": 0,
        "text": " So I'm kind of in love with that.",
        "tokens": [
          51322,
          407,
          286,
          478,
          733,
          295,
          294,
          959,
          365,
          300,
          13,
          51372
        ]
      },
      {
        "avg_logprob": -0.33388001124064126,
        "compression_ratio": 1.67578125,
        "end": 336.38,
        "id": 94,
        "no_speech_prob": 0.12247154861688614,
        "seek": 31458,
        "start": 334.74,
        "temperature": 0,
        "text": " Okay, I'm going to attempt to do that.",
        "tokens": [
          51372,
          1033,
          11,
          286,
          478,
          516,
          281,
          5217,
          281,
          360,
          300,
          13,
          51454
        ]
      },
      {
        "avg_logprob": -0.33388001124064126,
        "compression_ratio": 1.67578125,
        "end": 337.97999999999996,
        "id": 95,
        "no_speech_prob": 0.12247154861688614,
        "seek": 31458,
        "start": 336.38,
        "temperature": 0,
        "text": " Maybe if I have the music on, it'll help me.",
        "tokens": [
          51454,
          2704,
          498,
          286,
          362,
          264,
          1318,
          322,
          11,
          309,
          603,
          854,
          385,
          13,
          51534
        ]
      },
      {
        "avg_logprob": -0.9958361983299255,
        "compression_ratio": 0.8333333333333334,
        "end": 350.65999999999997,
        "id": 96,
        "no_speech_prob": 0.3408769369125366,
        "seek": 34458,
        "start": 344.58,
        "temperature": 0.4,
        "text": " Sorry, Lisa.",
        "tokens": [
          50364,
          4919,
          11,
          12252,
          13,
          50668
        ]
      },
      {
        "avg_logprob": -0.9958361983299255,
        "compression_ratio": 0.8333333333333334,
        "end": 367.14,
        "id": 97,
        "no_speech_prob": 0.3408769369125366,
        "seek": 34458,
        "start": 350.65999999999997,
        "temperature": 0.4,
        "text": " It was a beautiful diagram.",
        "tokens": [
          50668,
          467,
          390,
          257,
          2238,
          10686,
          13,
          51492
        ]
      },
      {
        "avg_logprob": -0.8172593116760254,
        "compression_ratio": 0.8478260869565217,
        "end": 376.82,
        "id": 98,
        "no_speech_prob": 0.0675259456038475,
        "seek": 36714,
        "start": 367.14,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          50364,
          1033,
          13,
          50848
        ]
      },
      {
        "avg_logprob": -0.8172593116760254,
        "compression_ratio": 0.8478260869565217,
        "end": 394.02,
        "id": 99,
        "no_speech_prob": 0.0675259456038475,
        "seek": 36714,
        "start": 376.82,
        "temperature": 0,
        "text": " That was my exercise for the day.",
        "tokens": [
          50848,
          663,
          390,
          452,
          5380,
          337,
          264,
          786,
          13,
          51708
        ]
      },
      {
        "avg_logprob": -0.38979112534295945,
        "compression_ratio": 1.558139534883721,
        "end": 397.14,
        "id": 100,
        "no_speech_prob": 0.5233553647994995,
        "seek": 39402,
        "start": 395.02,
        "temperature": 0,
        "text": " Let's see what my Fitbit thinks of my steps.",
        "tokens": [
          50414,
          961,
          311,
          536,
          437,
          452,
          29263,
          5260,
          7309,
          295,
          452,
          4439,
          13,
          50520
        ]
      },
      {
        "avg_logprob": -0.38979112534295945,
        "compression_ratio": 1.558139534883721,
        "end": 401.29999999999995,
        "id": 101,
        "no_speech_prob": 0.5233553647994995,
        "seek": 39402,
        "start": 397.14,
        "temperature": 0,
        "text": " Fitbit not officially a sponsor, but Fitbit, sponsor.",
        "tokens": [
          50520,
          29263,
          5260,
          406,
          12053,
          257,
          16198,
          11,
          457,
          29263,
          5260,
          11,
          16198,
          13,
          50728
        ]
      },
      {
        "avg_logprob": -0.38979112534295945,
        "compression_ratio": 1.558139534883721,
        "end": 404.09999999999997,
        "id": 102,
        "no_speech_prob": 0.5233553647994995,
        "seek": 39402,
        "start": 401.29999999999995,
        "temperature": 0,
        "text": " Sponsorship, I'm taking sponsors now.",
        "tokens": [
          50728,
          1738,
          892,
          14752,
          11,
          286,
          478,
          1940,
          22593,
          586,
          13,
          50868
        ]
      },
      {
        "avg_logprob": -0.38979112534295945,
        "compression_ratio": 1.558139534883721,
        "end": 406.09999999999997,
        "id": 103,
        "no_speech_prob": 0.5233553647994995,
        "seek": 39402,
        "start": 404.09999999999997,
        "temperature": 0,
        "text": " Living in New York City is very expensive.",
        "tokens": [
          50868,
          18824,
          294,
          1873,
          3609,
          4392,
          307,
          588,
          5124,
          13,
          50968
        ]
      },
      {
        "avg_logprob": -0.38979112534295945,
        "compression_ratio": 1.558139534883721,
        "end": 408.26,
        "id": 104,
        "no_speech_prob": 0.5233553647994995,
        "seek": 39402,
        "start": 406.09999999999997,
        "temperature": 0,
        "text": " Okay, what is it doing?",
        "tokens": [
          50968,
          1033,
          11,
          437,
          307,
          309,
          884,
          30,
          51076
        ]
      },
      {
        "avg_logprob": -0.38979112534295945,
        "compression_ratio": 1.558139534883721,
        "end": 410.29999999999995,
        "id": 105,
        "no_speech_prob": 0.5233553647994995,
        "seek": 39402,
        "start": 408.26,
        "temperature": 0,
        "text": " I need a marker.",
        "tokens": [
          51076,
          286,
          643,
          257,
          15247,
          13,
          51178
        ]
      },
      {
        "avg_logprob": -0.38979112534295945,
        "compression_ratio": 1.558139534883721,
        "end": 412.5,
        "id": 106,
        "no_speech_prob": 0.5233553647994995,
        "seek": 39402,
        "start": 410.29999999999995,
        "temperature": 0,
        "text": " All right, so here's what I want to do today.",
        "tokens": [
          51178,
          1057,
          558,
          11,
          370,
          510,
          311,
          437,
          286,
          528,
          281,
          360,
          965,
          13,
          51288
        ]
      },
      {
        "avg_logprob": -0.38979112534295945,
        "compression_ratio": 1.558139534883721,
        "end": 418.65999999999997,
        "id": 107,
        "no_speech_prob": 0.5233553647994995,
        "seek": 39402,
        "start": 412.5,
        "temperature": 0,
        "text": " First of all, Suze, which now I'm apparently even saying this wrong all my life, no OP",
        "tokens": [
          51288,
          2386,
          295,
          439,
          11,
          2746,
          1381,
          11,
          597,
          586,
          286,
          478,
          7970,
          754,
          1566,
          341,
          2085,
          439,
          452,
          993,
          11,
          572,
          23324,
          51596
        ]
      },
      {
        "avg_logprob": -0.38979112534295945,
        "compression_ratio": 1.558139534883721,
        "end": 421.85999999999996,
        "id": 108,
        "no_speech_prob": 0.5233553647994995,
        "seek": 39402,
        "start": 418.65999999999997,
        "temperature": 0,
        "text": " cat or noob cat, which is the way that I say it.",
        "tokens": [
          51596,
          3857,
          420,
          572,
          996,
          3857,
          11,
          597,
          307,
          264,
          636,
          300,
          286,
          584,
          309,
          13,
          51756
        ]
      },
      {
        "avg_logprob": -0.3032111777915611,
        "compression_ratio": 1.63013698630137,
        "end": 428.5,
        "id": 109,
        "no_speech_prob": 0.10086040943861008,
        "seek": 42186,
        "start": 421.94,
        "temperature": 0,
        "text": " 2.30, Eastern Daylight Time.",
        "tokens": [
          50368,
          568,
          13,
          3446,
          11,
          12901,
          5226,
          2764,
          6161,
          13,
          50696
        ]
      },
      {
        "avg_logprob": -0.3032111777915611,
        "compression_ratio": 1.63013698630137,
        "end": 436.94,
        "id": 110,
        "no_speech_prob": 0.10086040943861008,
        "seek": 42186,
        "start": 428.5,
        "temperature": 0,
        "text": " Come for the rainbows, stars, hearts.",
        "tokens": [
          50696,
          2492,
          337,
          264,
          4830,
          21118,
          11,
          6105,
          11,
          8852,
          13,
          51118
        ]
      },
      {
        "avg_logprob": -0.3032111777915611,
        "compression_ratio": 1.63013698630137,
        "end": 438.54,
        "id": 111,
        "no_speech_prob": 0.10086040943861008,
        "seek": 42186,
        "start": 436.94,
        "temperature": 0,
        "text": " This is the most important thing to happen today.",
        "tokens": [
          51118,
          639,
          307,
          264,
          881,
          1021,
          551,
          281,
          1051,
          965,
          13,
          51198
        ]
      },
      {
        "avg_logprob": -0.3032111777915611,
        "compression_ratio": 1.63013698630137,
        "end": 442.42,
        "id": 112,
        "no_speech_prob": 0.10086040943861008,
        "seek": 42186,
        "start": 438.54,
        "temperature": 0,
        "text": " At least, I don't know, I might have something else that's kind of important, but I don't",
        "tokens": [
          51198,
          1711,
          1935,
          11,
          286,
          500,
          380,
          458,
          11,
          286,
          1062,
          362,
          746,
          1646,
          300,
          311,
          733,
          295,
          1021,
          11,
          457,
          286,
          500,
          380,
          51392
        ]
      },
      {
        "avg_logprob": -0.3032111777915611,
        "compression_ratio": 1.63013698630137,
        "end": 443.42,
        "id": 113,
        "no_speech_prob": 0.10086040943861008,
        "seek": 42186,
        "start": 442.42,
        "temperature": 0,
        "text": " think so.",
        "tokens": [
          51392,
          519,
          370,
          13,
          51442
        ]
      },
      {
        "avg_logprob": -0.3032111777915611,
        "compression_ratio": 1.63013698630137,
        "end": 445.66,
        "id": 114,
        "no_speech_prob": 0.10086040943861008,
        "seek": 42186,
        "start": 443.42,
        "temperature": 0,
        "text": " No, today in my life, this is the most important thing to happen.",
        "tokens": [
          51442,
          883,
          11,
          965,
          294,
          452,
          993,
          11,
          341,
          307,
          264,
          881,
          1021,
          551,
          281,
          1051,
          13,
          51554
        ]
      },
      {
        "avg_logprob": -0.3032111777915611,
        "compression_ratio": 1.63013698630137,
        "end": 448.78000000000003,
        "id": 115,
        "no_speech_prob": 0.10086040943861008,
        "seek": 42186,
        "start": 445.66,
        "temperature": 0,
        "text": " Now, this morning, she's coming at 2.30.",
        "tokens": [
          51554,
          823,
          11,
          341,
          2446,
          11,
          750,
          311,
          1348,
          412,
          568,
          13,
          3446,
          13,
          51710
        ]
      },
      {
        "avg_logprob": -0.3032111777915611,
        "compression_ratio": 1.63013698630137,
        "end": 450.94,
        "id": 116,
        "no_speech_prob": 0.10086040943861008,
        "seek": 42186,
        "start": 448.78000000000003,
        "temperature": 0,
        "text": " We're meeting to get set up here.",
        "tokens": [
          51710,
          492,
          434,
          3440,
          281,
          483,
          992,
          493,
          510,
          13,
          51818
        ]
      },
      {
        "avg_logprob": -0.23479852676391602,
        "compression_ratio": 1.53551912568306,
        "end": 452.98,
        "id": 117,
        "no_speech_prob": 0.4338989853858948,
        "seek": 45094,
        "start": 451.02,
        "temperature": 0,
        "text": " Before that, I need to eat some lunch.",
        "tokens": [
          50368,
          4546,
          300,
          11,
          286,
          643,
          281,
          1862,
          512,
          6349,
          13,
          50466
        ]
      },
      {
        "avg_logprob": -0.23479852676391602,
        "compression_ratio": 1.53551912568306,
        "end": 459.98,
        "id": 118,
        "no_speech_prob": 0.4338989853858948,
        "seek": 45094,
        "start": 452.98,
        "temperature": 0,
        "text": " So I think that I can reasonably stream until about 1 p.m. right now, which is only an hour",
        "tokens": [
          50466,
          407,
          286,
          519,
          300,
          286,
          393,
          23551,
          4309,
          1826,
          466,
          502,
          280,
          13,
          76,
          13,
          558,
          586,
          11,
          597,
          307,
          787,
          364,
          1773,
          50816
        ]
      },
      {
        "avg_logprob": -0.23479852676391602,
        "compression_ratio": 1.53551912568306,
        "end": 462.26,
        "id": 119,
        "no_speech_prob": 0.4338989853858948,
        "seek": 45094,
        "start": 459.98,
        "temperature": 0,
        "text": " and 20 minutes right now, which is not a lot of time.",
        "tokens": [
          50816,
          293,
          945,
          2077,
          558,
          586,
          11,
          597,
          307,
          406,
          257,
          688,
          295,
          565,
          13,
          50930
        ]
      },
      {
        "avg_logprob": -0.23479852676391602,
        "compression_ratio": 1.53551912568306,
        "end": 473.62,
        "id": 120,
        "no_speech_prob": 0.4338989853858948,
        "seek": 45094,
        "start": 462.26,
        "temperature": 0,
        "text": " So on my list is I wanted to finish off the quadtree challenges and do quadtree with collisions.",
        "tokens": [
          50930,
          407,
          322,
          452,
          1329,
          307,
          286,
          1415,
          281,
          2413,
          766,
          264,
          10787,
          83,
          701,
          4759,
          293,
          360,
          10787,
          83,
          701,
          365,
          46537,
          13,
          51498
        ]
      },
      {
        "avg_logprob": -0.24611523686623088,
        "compression_ratio": 1.6726457399103138,
        "end": 483.18,
        "id": 121,
        "no_speech_prob": 0.25661900639533997,
        "seek": 47362,
        "start": 473.62,
        "temperature": 0,
        "text": " I want to do Jabril's color predictor to finish off that collaboration.",
        "tokens": [
          50364,
          286,
          528,
          281,
          360,
          40319,
          24216,
          311,
          2017,
          6069,
          284,
          281,
          2413,
          766,
          300,
          9363,
          13,
          50842
        ]
      },
      {
        "avg_logprob": -0.24611523686623088,
        "compression_ratio": 1.6726457399103138,
        "end": 488.82,
        "id": 122,
        "no_speech_prob": 0.25661900639533997,
        "seek": 47362,
        "start": 483.18,
        "temperature": 0,
        "text": " So if you're not aware, Jabril was here last Friday, did a guest spot on the Coding Train",
        "tokens": [
          50842,
          407,
          498,
          291,
          434,
          406,
          3650,
          11,
          40319,
          24216,
          390,
          510,
          1036,
          6984,
          11,
          630,
          257,
          8341,
          4008,
          322,
          264,
          383,
          8616,
          28029,
          51124
        ]
      },
      {
        "avg_logprob": -0.24611523686623088,
        "compression_ratio": 1.6726457399103138,
        "end": 493.1,
        "id": 123,
        "no_speech_prob": 0.25661900639533997,
        "seek": 47362,
        "start": 488.82,
        "temperature": 0,
        "text": " about the color predictor, then on Sunday released a video on his own channel about",
        "tokens": [
          51124,
          466,
          264,
          2017,
          6069,
          284,
          11,
          550,
          322,
          7776,
          4736,
          257,
          960,
          322,
          702,
          1065,
          2269,
          466,
          51338
        ]
      },
      {
        "avg_logprob": -0.24611523686623088,
        "compression_ratio": 1.6726457399103138,
        "end": 496.78000000000003,
        "id": 124,
        "no_speech_prob": 0.25661900639533997,
        "seek": 47362,
        "start": 493.1,
        "temperature": 0,
        "text": " the color predictor that has me in it.",
        "tokens": [
          51338,
          264,
          2017,
          6069,
          284,
          300,
          575,
          385,
          294,
          309,
          13,
          51522
        ]
      },
      {
        "avg_logprob": -0.24611523686623088,
        "compression_ratio": 1.6726457399103138,
        "end": 501.34000000000003,
        "id": 125,
        "no_speech_prob": 0.25661900639533997,
        "seek": 47362,
        "start": 496.78000000000003,
        "temperature": 0,
        "text": " And then I thought I would do as a last piece of that, do a tutorial about building your",
        "tokens": [
          51522,
          400,
          550,
          286,
          1194,
          286,
          576,
          360,
          382,
          257,
          1036,
          2522,
          295,
          300,
          11,
          360,
          257,
          7073,
          466,
          2390,
          428,
          51750
        ]
      },
      {
        "avg_logprob": -0.34290091196695965,
        "compression_ratio": 1.4927536231884058,
        "end": 504.41999999999996,
        "id": 126,
        "no_speech_prob": 0.7661294341087341,
        "seek": 50134,
        "start": 501.34,
        "temperature": 0,
        "text": " own neural network-based color predictor.",
        "tokens": [
          50364,
          1065,
          18161,
          3209,
          12,
          6032,
          2017,
          6069,
          284,
          13,
          50518
        ]
      },
      {
        "avg_logprob": -0.34290091196695965,
        "compression_ratio": 1.4927536231884058,
        "end": 507.53999999999996,
        "id": 127,
        "no_speech_prob": 0.7661294341087341,
        "seek": 50134,
        "start": 504.41999999999996,
        "temperature": 0,
        "text": " And that's kind of my highest priority, I think, for this morning.",
        "tokens": [
          50518,
          400,
          300,
          311,
          733,
          295,
          452,
          6343,
          9365,
          11,
          286,
          519,
          11,
          337,
          341,
          2446,
          13,
          50674
        ]
      },
      {
        "avg_logprob": -0.34290091196695965,
        "compression_ratio": 1.4927536231884058,
        "end": 519.9399999999999,
        "id": 128,
        "no_speech_prob": 0.7661294341087341,
        "seek": 50134,
        "start": 507.53999999999996,
        "temperature": 0,
        "text": " And the third thing, as I want to follow up on my p5 load bytes pull request, and number",
        "tokens": [
          50674,
          400,
          264,
          2636,
          551,
          11,
          382,
          286,
          528,
          281,
          1524,
          493,
          322,
          452,
          280,
          20,
          3677,
          36088,
          2235,
          5308,
          11,
          293,
          1230,
          51294
        ]
      },
      {
        "avg_logprob": -0.34290091196695965,
        "compression_ratio": 1.4927536231884058,
        "end": 526.74,
        "id": 129,
        "no_speech_prob": 0.7661294341087341,
        "seek": 50134,
        "start": 519.9399999999999,
        "temperature": 0,
        "text": " four, oh, boy, I need to, like, come back tomorrow or something and Sunday and Monday.",
        "tokens": [
          51294,
          1451,
          11,
          1954,
          11,
          3237,
          11,
          286,
          643,
          281,
          11,
          411,
          11,
          808,
          646,
          4153,
          420,
          746,
          293,
          7776,
          293,
          8138,
          13,
          51634
        ]
      },
      {
        "avg_logprob": -0.34290091196695965,
        "compression_ratio": 1.4927536231884058,
        "end": 529.5799999999999,
        "id": 130,
        "no_speech_prob": 0.7661294341087341,
        "seek": 50134,
        "start": 526.74,
        "temperature": 0,
        "text": " I've got, like, an hour.",
        "tokens": [
          51634,
          286,
          600,
          658,
          11,
          411,
          11,
          364,
          1773,
          13,
          51776
        ]
      },
      {
        "avg_logprob": -0.5355588368007115,
        "compression_ratio": 1.3310810810810811,
        "end": 531.6600000000001,
        "id": 131,
        "no_speech_prob": 0.577434241771698,
        "seek": 52958,
        "start": 529.58,
        "temperature": 0,
        "text": " Any one of these things would probably take me the whole time.",
        "tokens": [
          50364,
          2639,
          472,
          295,
          613,
          721,
          576,
          1391,
          747,
          385,
          264,
          1379,
          565,
          13,
          50468
        ]
      },
      {
        "avg_logprob": -0.5355588368007115,
        "compression_ratio": 1.3310810810810811,
        "end": 537.1,
        "id": 132,
        "no_speech_prob": 0.577434241771698,
        "seek": 52958,
        "start": 531.6600000000001,
        "temperature": 0,
        "text": " And the fourth thing is I want to talk about TensorFlow.",
        "tokens": [
          50468,
          400,
          264,
          6409,
          551,
          307,
          286,
          528,
          281,
          751,
          466,
          37624,
          13,
          50740
        ]
      },
      {
        "avg_logprob": -0.5355588368007115,
        "compression_ratio": 1.3310810810810811,
        "end": 540.7800000000001,
        "id": 133,
        "no_speech_prob": 0.577434241771698,
        "seek": 52958,
        "start": 537.1,
        "temperature": 0,
        "text": " Wait, hold on.",
        "tokens": [
          50740,
          3802,
          11,
          1797,
          322,
          13,
          50924
        ]
      },
      {
        "avg_logprob": -0.5355588368007115,
        "compression_ratio": 1.3310810810810811,
        "end": 548.58,
        "id": 134,
        "no_speech_prob": 0.577434241771698,
        "seek": 52958,
        "start": 540.7800000000001,
        "temperature": 0,
        "text": " I've got a sound effect for this somewhere.",
        "tokens": [
          50924,
          286,
          600,
          658,
          257,
          1626,
          1802,
          337,
          341,
          4079,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.5355588368007115,
        "compression_ratio": 1.3310810810810811,
        "end": 556.74,
        "id": 135,
        "no_speech_prob": 0.577434241771698,
        "seek": 52958,
        "start": 548.58,
        "temperature": 0,
        "text": " TensorFlow dot JS.",
        "tokens": [
          51314,
          37624,
          5893,
          33063,
          13,
          51722
        ]
      },
      {
        "avg_logprob": -0.23609495617094495,
        "compression_ratio": 1.6181102362204725,
        "end": 562.66,
        "id": 136,
        "no_speech_prob": 0.05499768629670143,
        "seek": 55674,
        "start": 556.74,
        "temperature": 0,
        "text": " So something new came out last Friday called TensorFlow dot JS, which is actually formerly",
        "tokens": [
          50364,
          407,
          746,
          777,
          1361,
          484,
          1036,
          6984,
          1219,
          37624,
          5893,
          33063,
          11,
          597,
          307,
          767,
          34777,
          50660
        ]
      },
      {
        "avg_logprob": -0.23609495617094495,
        "compression_ratio": 1.6181102362204725,
        "end": 565.86,
        "id": 137,
        "no_speech_prob": 0.05499768629670143,
        "seek": 55674,
        "start": 562.66,
        "temperature": 0,
        "text": " known as DeepLearn dot JS, which I have referred to.",
        "tokens": [
          50660,
          2570,
          382,
          14895,
          11020,
          1083,
          5893,
          33063,
          11,
          597,
          286,
          362,
          10839,
          281,
          13,
          50820
        ]
      },
      {
        "avg_logprob": -0.23609495617094495,
        "compression_ratio": 1.6181102362204725,
        "end": 571.94,
        "id": 138,
        "no_speech_prob": 0.05499768629670143,
        "seek": 55674,
        "start": 565.86,
        "temperature": 0,
        "text": " And boy, am I planning a lot of sessions and tutorials and stuff about using that and how",
        "tokens": [
          50820,
          400,
          3237,
          11,
          669,
          286,
          5038,
          257,
          688,
          295,
          11081,
          293,
          17616,
          293,
          1507,
          466,
          1228,
          300,
          293,
          577,
          51124
        ]
      },
      {
        "avg_logprob": -0.23609495617094495,
        "compression_ratio": 1.6181102362204725,
        "end": 578.74,
        "id": 139,
        "no_speech_prob": 0.05499768629670143,
        "seek": 55674,
        "start": 571.94,
        "temperature": 0,
        "text": " it relates to this other project, which is called ML5, I guess, dot JS, which is an open",
        "tokens": [
          51124,
          309,
          16155,
          281,
          341,
          661,
          1716,
          11,
          597,
          307,
          1219,
          21601,
          20,
          11,
          286,
          2041,
          11,
          5893,
          33063,
          11,
          597,
          307,
          364,
          1269,
          51464
        ]
      },
      {
        "avg_logprob": -0.23609495617094495,
        "compression_ratio": 1.6181102362204725,
        "end": 583.14,
        "id": 140,
        "no_speech_prob": 0.05499768629670143,
        "seek": 55674,
        "start": 578.74,
        "temperature": 0,
        "text": " source library built on top of TensorFlow dot JS.",
        "tokens": [
          51464,
          4009,
          6405,
          3094,
          322,
          1192,
          295,
          37624,
          5893,
          33063,
          13,
          51684
        ]
      },
      {
        "avg_logprob": -0.23609495617094495,
        "compression_ratio": 1.6181102362204725,
        "end": 584.86,
        "id": 141,
        "no_speech_prob": 0.05499768629670143,
        "seek": 55674,
        "start": 583.14,
        "temperature": 0,
        "text": " This is kind of like a flawed analogy.",
        "tokens": [
          51684,
          639,
          307,
          733,
          295,
          411,
          257,
          38823,
          21663,
          13,
          51770
        ]
      },
      {
        "avg_logprob": -0.24645044077997622,
        "compression_ratio": 1.5892857142857142,
        "end": 590.02,
        "id": 142,
        "no_speech_prob": 0.13475963473320007,
        "seek": 58486,
        "start": 584.98,
        "temperature": 0,
        "text": " But just to make the case for a second, you might say that, like, p5 is a kind of higher",
        "tokens": [
          50370,
          583,
          445,
          281,
          652,
          264,
          1389,
          337,
          257,
          1150,
          11,
          291,
          1062,
          584,
          300,
          11,
          411,
          11,
          280,
          20,
          307,
          257,
          733,
          295,
          2946,
          50622
        ]
      },
      {
        "avg_logprob": -0.24645044077997622,
        "compression_ratio": 1.5892857142857142,
        "end": 597.82,
        "id": 143,
        "no_speech_prob": 0.13475963473320007,
        "seek": 58486,
        "start": 590.02,
        "temperature": 0,
        "text": " level API for HTML5 Canvas, sort of a lower level API for working in drawing in the browser.",
        "tokens": [
          50622,
          1496,
          9362,
          337,
          17995,
          20,
          25725,
          11,
          1333,
          295,
          257,
          3126,
          1496,
          9362,
          337,
          1364,
          294,
          6316,
          294,
          264,
          11185,
          13,
          51012
        ]
      },
      {
        "avg_logprob": -0.24645044077997622,
        "compression_ratio": 1.5892857142857142,
        "end": 599.26,
        "id": 144,
        "no_speech_prob": 0.13475963473320007,
        "seek": 58486,
        "start": 597.82,
        "temperature": 0,
        "text": " P5 is more than that.",
        "tokens": [
          51012,
          430,
          20,
          307,
          544,
          813,
          300,
          13,
          51084
        ]
      },
      {
        "avg_logprob": -0.24645044077997622,
        "compression_ratio": 1.5892857142857142,
        "end": 602.46,
        "id": 145,
        "no_speech_prob": 0.13475963473320007,
        "seek": 58486,
        "start": 599.26,
        "temperature": 0,
        "text": " And the distance between these two things actually isn't even that far.",
        "tokens": [
          51084,
          400,
          264,
          4560,
          1296,
          613,
          732,
          721,
          767,
          1943,
          380,
          754,
          300,
          1400,
          13,
          51244
        ]
      },
      {
        "avg_logprob": -0.24645044077997622,
        "compression_ratio": 1.5892857142857142,
        "end": 606.9,
        "id": 146,
        "no_speech_prob": 0.13475963473320007,
        "seek": 58486,
        "start": 602.46,
        "temperature": 0,
        "text": " But that's, I guess, that's the easiest way for me to explain what ML5 is.",
        "tokens": [
          51244,
          583,
          300,
          311,
          11,
          286,
          2041,
          11,
          300,
          311,
          264,
          12889,
          636,
          337,
          385,
          281,
          2903,
          437,
          21601,
          20,
          307,
          13,
          51466
        ]
      },
      {
        "avg_logprob": -0.24645044077997622,
        "compression_ratio": 1.5892857142857142,
        "end": 613.14,
        "id": 147,
        "no_speech_prob": 0.13475963473320007,
        "seek": 58486,
        "start": 606.9,
        "temperature": 0,
        "text": " TensorFlow being a JavaScript version of TensorFlow with low level functionality to do machine",
        "tokens": [
          51466,
          37624,
          885,
          257,
          15778,
          3037,
          295,
          37624,
          365,
          2295,
          1496,
          14980,
          281,
          360,
          3479,
          51778
        ]
      },
      {
        "avg_logprob": -0.28007943289620535,
        "compression_ratio": 1.696629213483146,
        "end": 617.46,
        "id": 148,
        "no_speech_prob": 0.08269022405147552,
        "seek": 61314,
        "start": 613.14,
        "temperature": 0,
        "text": " learning algorithms and mathematics and various tasks.",
        "tokens": [
          50364,
          2539,
          14642,
          293,
          18666,
          293,
          3683,
          9608,
          13,
          50580
        ]
      },
      {
        "avg_logprob": -0.28007943289620535,
        "compression_ratio": 1.696629213483146,
        "end": 621.54,
        "id": 149,
        "no_speech_prob": 0.08269022405147552,
        "seek": 61314,
        "start": 617.46,
        "temperature": 0,
        "text": " ML5 being a higher level layer API on top of that.",
        "tokens": [
          50580,
          21601,
          20,
          885,
          257,
          2946,
          1496,
          4583,
          9362,
          322,
          1192,
          295,
          300,
          13,
          50784
        ]
      },
      {
        "avg_logprob": -0.28007943289620535,
        "compression_ratio": 1.696629213483146,
        "end": 625.3,
        "id": 150,
        "no_speech_prob": 0.08269022405147552,
        "seek": 61314,
        "start": 621.54,
        "temperature": 0,
        "text": " Now, the other thing is I should mention in between those two things is something called",
        "tokens": [
          50784,
          823,
          11,
          264,
          661,
          551,
          307,
          286,
          820,
          2152,
          294,
          1296,
          729,
          732,
          721,
          307,
          746,
          1219,
          50972
        ]
      },
      {
        "avg_logprob": -0.28007943289620535,
        "compression_ratio": 1.696629213483146,
        "end": 626.46,
        "id": 151,
        "no_speech_prob": 0.08269022405147552,
        "seek": 61314,
        "start": 625.3,
        "temperature": 0,
        "text": " Keras.",
        "tokens": [
          50972,
          591,
          6985,
          13,
          51030
        ]
      },
      {
        "avg_logprob": -0.28007943289620535,
        "compression_ratio": 1.696629213483146,
        "end": 629.8199999999999,
        "id": 152,
        "no_speech_prob": 0.08269022405147552,
        "seek": 61314,
        "start": 626.46,
        "temperature": 0,
        "text": " Without going into a long history of what's TensorFlow, what's Keras, that would probably",
        "tokens": [
          51030,
          9129,
          516,
          666,
          257,
          938,
          2503,
          295,
          437,
          311,
          37624,
          11,
          437,
          311,
          591,
          6985,
          11,
          300,
          576,
          1391,
          51198
        ]
      },
      {
        "avg_logprob": -0.28007943289620535,
        "compression_ratio": 1.696629213483146,
        "end": 632.66,
        "id": 153,
        "no_speech_prob": 0.08269022405147552,
        "seek": 61314,
        "start": 629.8199999999999,
        "temperature": 0,
        "text": " be an interesting topic for a video.",
        "tokens": [
          51198,
          312,
          364,
          1880,
          4829,
          337,
          257,
          960,
          13,
          51340
        ]
      },
      {
        "avg_logprob": -0.28007943289620535,
        "compression_ratio": 1.696629213483146,
        "end": 638.02,
        "id": 154,
        "no_speech_prob": 0.08269022405147552,
        "seek": 61314,
        "start": 632.66,
        "temperature": 0,
        "text": " TensorFlow dot JS supports what's called the layers API, which is Keras itself is a higher",
        "tokens": [
          51340,
          37624,
          5893,
          33063,
          9346,
          437,
          311,
          1219,
          264,
          7914,
          9362,
          11,
          597,
          307,
          591,
          6985,
          2564,
          307,
          257,
          2946,
          51608
        ]
      },
      {
        "avg_logprob": -0.28007943289620535,
        "compression_ratio": 1.696629213483146,
        "end": 641.86,
        "id": 155,
        "no_speech_prob": 0.08269022405147552,
        "seek": 61314,
        "start": 638.02,
        "temperature": 0,
        "text": " level layer on top of TensorFlow.",
        "tokens": [
          51608,
          1496,
          4583,
          322,
          1192,
          295,
          37624,
          13,
          51800
        ]
      },
      {
        "avg_logprob": -0.30863448015348177,
        "compression_ratio": 1.5425531914893618,
        "end": 644.62,
        "id": 156,
        "no_speech_prob": 0.04958757013082504,
        "seek": 64186,
        "start": 641.98,
        "temperature": 0,
        "text": " And so ML5 is probably even higher level.",
        "tokens": [
          50370,
          400,
          370,
          21601,
          20,
          307,
          1391,
          754,
          2946,
          1496,
          13,
          50502
        ]
      },
      {
        "avg_logprob": -0.30863448015348177,
        "compression_ratio": 1.5425531914893618,
        "end": 649.78,
        "id": 157,
        "no_speech_prob": 0.04958757013082504,
        "seek": 64186,
        "start": 644.62,
        "temperature": 0,
        "text": " So a lot of the features that I'm hoping to work on in the next month or two and certainly",
        "tokens": [
          50502,
          407,
          257,
          688,
          295,
          264,
          4122,
          300,
          286,
          478,
          7159,
          281,
          589,
          322,
          294,
          264,
          958,
          1618,
          420,
          732,
          293,
          3297,
          50760
        ]
      },
      {
        "avg_logprob": -0.30863448015348177,
        "compression_ratio": 1.5425531914893618,
        "end": 656.58,
        "id": 158,
        "no_speech_prob": 0.04958757013082504,
        "seek": 64186,
        "start": 649.78,
        "temperature": 0,
        "text": " well over the summer is building out examples and tutorials that build on top of Keras and",
        "tokens": [
          50760,
          731,
          670,
          264,
          4266,
          307,
          2390,
          484,
          5110,
          293,
          17616,
          300,
          1322,
          322,
          1192,
          295,
          591,
          6985,
          293,
          51100
        ]
      },
      {
        "avg_logprob": -0.30863448015348177,
        "compression_ratio": 1.5425531914893618,
        "end": 658.26,
        "id": 159,
        "no_speech_prob": 0.04958757013082504,
        "seek": 64186,
        "start": 656.58,
        "temperature": 0,
        "text": " TensorFlow dot JS.",
        "tokens": [
          51100,
          37624,
          5893,
          33063,
          13,
          51184
        ]
      },
      {
        "avg_logprob": -0.30863448015348177,
        "compression_ratio": 1.5425531914893618,
        "end": 660.66,
        "id": 160,
        "no_speech_prob": 0.04958757013082504,
        "seek": 64186,
        "start": 658.26,
        "temperature": 0,
        "text": " OK, for machine learning stuff.",
        "tokens": [
          51184,
          2264,
          11,
          337,
          3479,
          2539,
          1507,
          13,
          51304
        ]
      },
      {
        "avg_logprob": -0.30863448015348177,
        "compression_ratio": 1.5425531914893618,
        "end": 661.66,
        "id": 161,
        "no_speech_prob": 0.04958757013082504,
        "seek": 64186,
        "start": 660.66,
        "temperature": 0,
        "text": " Thank you.",
        "tokens": [
          51304,
          1044,
          291,
          13,
          51354
        ]
      },
      {
        "avg_logprob": -0.30863448015348177,
        "compression_ratio": 1.5425531914893618,
        "end": 662.66,
        "id": 162,
        "no_speech_prob": 0.04958757013082504,
        "seek": 64186,
        "start": 661.66,
        "temperature": 0,
        "text": " Good night.",
        "tokens": [
          51354,
          2205,
          1818,
          13,
          51404
        ]
      },
      {
        "avg_logprob": -0.30863448015348177,
        "compression_ratio": 1.5425531914893618,
        "end": 663.66,
        "id": 163,
        "no_speech_prob": 0.04958757013082504,
        "seek": 64186,
        "start": 662.66,
        "temperature": 0,
        "text": " That's all I have.",
        "tokens": [
          51404,
          663,
          311,
          439,
          286,
          362,
          13,
          51454
        ]
      },
      {
        "avg_logprob": -0.30863448015348177,
        "compression_ratio": 1.5425531914893618,
        "end": 664.66,
        "id": 164,
        "no_speech_prob": 0.04958757013082504,
        "seek": 64186,
        "start": 663.66,
        "temperature": 0,
        "text": " So this is my list.",
        "tokens": [
          51454,
          407,
          341,
          307,
          452,
          1329,
          13,
          51504
        ]
      },
      {
        "avg_logprob": -0.30863448015348177,
        "compression_ratio": 1.5425531914893618,
        "end": 667.3000000000001,
        "id": 165,
        "no_speech_prob": 0.04958757013082504,
        "seek": 64186,
        "start": 664.66,
        "temperature": 0,
        "text": " And I have to decide what to do.",
        "tokens": [
          51504,
          400,
          286,
          362,
          281,
          4536,
          437,
          281,
          360,
          13,
          51636
        ]
      },
      {
        "avg_logprob": -0.30863448015348177,
        "compression_ratio": 1.5425531914893618,
        "end": 671.38,
        "id": 166,
        "no_speech_prob": 0.04958757013082504,
        "seek": 64186,
        "start": 667.3000000000001,
        "temperature": 0,
        "text": " And I know if Simon is watching, Simon would say to a straw poll.",
        "tokens": [
          51636,
          400,
          286,
          458,
          498,
          13193,
          307,
          1976,
          11,
          13193,
          576,
          584,
          281,
          257,
          10099,
          6418,
          13,
          51840
        ]
      },
      {
        "avg_logprob": -0.2813269210188356,
        "compression_ratio": 1.4722222222222223,
        "end": 673.42,
        "id": 167,
        "no_speech_prob": 0.001151349046267569,
        "seek": 67138,
        "start": 671.9,
        "temperature": 0,
        "text": " The straw polls never go well for me.",
        "tokens": [
          50390,
          440,
          10099,
          24264,
          1128,
          352,
          731,
          337,
          385,
          13,
          50466
        ]
      },
      {
        "avg_logprob": -0.2813269210188356,
        "compression_ratio": 1.4722222222222223,
        "end": 678.78,
        "id": 168,
        "no_speech_prob": 0.001151349046267569,
        "seek": 67138,
        "start": 673.42,
        "temperature": 0,
        "text": " I think what I'm going to...",
        "tokens": [
          50466,
          286,
          519,
          437,
          286,
          478,
          516,
          281,
          485,
          50734
        ]
      },
      {
        "avg_logprob": -0.2813269210188356,
        "compression_ratio": 1.4722222222222223,
        "end": 683.7,
        "id": 169,
        "no_speech_prob": 0.001151349046267569,
        "seek": 67138,
        "start": 678.78,
        "temperature": 0,
        "text": " I'm actually looking to see if there's any questions here in the chat.",
        "tokens": [
          50734,
          286,
          478,
          767,
          1237,
          281,
          536,
          498,
          456,
          311,
          604,
          1651,
          510,
          294,
          264,
          5081,
          13,
          50980
        ]
      },
      {
        "avg_logprob": -0.2813269210188356,
        "compression_ratio": 1.4722222222222223,
        "end": 689.42,
        "id": 170,
        "no_speech_prob": 0.001151349046267569,
        "seek": 67138,
        "start": 683.7,
        "temperature": 0,
        "text": " I know you're 20 seconds behind of me.",
        "tokens": [
          50980,
          286,
          458,
          291,
          434,
          945,
          3949,
          2261,
          295,
          385,
          13,
          51266
        ]
      },
      {
        "avg_logprob": -0.2813269210188356,
        "compression_ratio": 1.4722222222222223,
        "end": 700.5,
        "id": 171,
        "no_speech_prob": 0.001151349046267569,
        "seek": 67138,
        "start": 689.42,
        "temperature": 0,
        "text": " And I guess I should put my secret cloaking device on top of this secondary laptop where",
        "tokens": [
          51266,
          400,
          286,
          2041,
          286,
          820,
          829,
          452,
          4054,
          20123,
          2456,
          4302,
          322,
          1192,
          295,
          341,
          11396,
          10732,
          689,
          51820
        ]
      },
      {
        "avg_logprob": -0.45748512961647725,
        "compression_ratio": 1.5576036866359446,
        "end": 705.14,
        "id": 172,
        "no_speech_prob": 0.11122867465019226,
        "seek": 70050,
        "start": 700.54,
        "temperature": 0.4,
        "text": " I keep all of the answers and all of my code because that's my secret.",
        "tokens": [
          50366,
          286,
          1066,
          439,
          295,
          264,
          6338,
          293,
          439,
          295,
          452,
          3089,
          570,
          300,
          311,
          452,
          4054,
          13,
          50596
        ]
      },
      {
        "avg_logprob": -0.45748512961647725,
        "compression_ratio": 1.5576036866359446,
        "end": 708.58,
        "id": 173,
        "no_speech_prob": 0.11122867465019226,
        "seek": 70050,
        "start": 705.14,
        "temperature": 0.4,
        "text": " No, I'm just kidding.",
        "tokens": [
          50596,
          883,
          11,
          286,
          478,
          445,
          9287,
          13,
          50768
        ]
      },
      {
        "avg_logprob": -0.45748512961647725,
        "compression_ratio": 1.5576036866359446,
        "end": 712.06,
        "id": 174,
        "no_speech_prob": 0.11122867465019226,
        "seek": 70050,
        "start": 708.58,
        "temperature": 0.4,
        "text": " And that's pretty good.",
        "tokens": [
          50768,
          400,
          300,
          311,
          1238,
          665,
          13,
          50942
        ]
      },
      {
        "avg_logprob": -0.45748512961647725,
        "compression_ratio": 1.5576036866359446,
        "end": 713.06,
        "id": 175,
        "no_speech_prob": 0.11122867465019226,
        "seek": 70050,
        "start": 712.06,
        "temperature": 0.4,
        "text": " This needs to be...",
        "tokens": [
          50942,
          639,
          2203,
          281,
          312,
          485,
          50992
        ]
      },
      {
        "avg_logprob": -0.45748512961647725,
        "compression_ratio": 1.5576036866359446,
        "end": 714.3,
        "id": 176,
        "no_speech_prob": 0.11122867465019226,
        "seek": 70050,
        "start": 713.06,
        "temperature": 0.4,
        "text": " Actually, I need to fix one thing.",
        "tokens": [
          50992,
          5135,
          11,
          286,
          643,
          281,
          3191,
          472,
          551,
          13,
          51054
        ]
      },
      {
        "avg_logprob": -0.45748512961647725,
        "compression_ratio": 1.5576036866359446,
        "end": 716.98,
        "id": 177,
        "no_speech_prob": 0.11122867465019226,
        "seek": 70050,
        "start": 714.3,
        "temperature": 0.4,
        "text": " Let me do this.",
        "tokens": [
          51054,
          961,
          385,
          360,
          341,
          13,
          51188
        ]
      },
      {
        "avg_logprob": -0.45748512961647725,
        "compression_ratio": 1.5576036866359446,
        "end": 718.94,
        "id": 178,
        "no_speech_prob": 0.11122867465019226,
        "seek": 70050,
        "start": 716.98,
        "temperature": 0.4,
        "text": " Oops, wrong thing.",
        "tokens": [
          51188,
          21726,
          11,
          2085,
          551,
          13,
          51286
        ]
      },
      {
        "avg_logprob": -0.45748512961647725,
        "compression_ratio": 1.5576036866359446,
        "end": 722.5,
        "id": 179,
        "no_speech_prob": 0.11122867465019226,
        "seek": 70050,
        "start": 718.94,
        "temperature": 0.4,
        "text": " Sorry, I'm just fixing something in the live stream here.",
        "tokens": [
          51286,
          4919,
          11,
          286,
          478,
          445,
          19442,
          746,
          294,
          264,
          1621,
          4309,
          510,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.45748512961647725,
        "compression_ratio": 1.5576036866359446,
        "end": 724.22,
        "id": 180,
        "no_speech_prob": 0.11122867465019226,
        "seek": 70050,
        "start": 722.5,
        "temperature": 0.4,
        "text": " Moving myself down a tiny bit.",
        "tokens": [
          51464,
          14242,
          2059,
          760,
          257,
          5870,
          857,
          13,
          51550
        ]
      },
      {
        "avg_logprob": -0.45748512961647725,
        "compression_ratio": 1.5576036866359446,
        "end": 725.74,
        "id": 181,
        "no_speech_prob": 0.11122867465019226,
        "seek": 70050,
        "start": 724.22,
        "temperature": 0.4,
        "text": " There we go.",
        "tokens": [
          51550,
          821,
          321,
          352,
          13,
          51626
        ]
      },
      {
        "avg_logprob": -0.45748512961647725,
        "compression_ratio": 1.5576036866359446,
        "end": 728.9,
        "id": 182,
        "no_speech_prob": 0.11122867465019226,
        "seek": 70050,
        "start": 725.74,
        "temperature": 0.4,
        "text": " That's usually how I have it.",
        "tokens": [
          51626,
          663,
          311,
          2673,
          577,
          286,
          362,
          309,
          13,
          51784
        ]
      },
      {
        "avg_logprob": -0.3172469086699433,
        "compression_ratio": 1.403061224489796,
        "end": 730.74,
        "id": 183,
        "no_speech_prob": 0.009267205372452736,
        "seek": 72890,
        "start": 728.9399999999999,
        "temperature": 0,
        "text": " There we go.",
        "tokens": [
          50366,
          821,
          321,
          352,
          13,
          50456
        ]
      },
      {
        "avg_logprob": -0.3172469086699433,
        "compression_ratio": 1.403061224489796,
        "end": 736.66,
        "id": 184,
        "no_speech_prob": 0.009267205372452736,
        "seek": 72890,
        "start": 730.74,
        "temperature": 0,
        "text": " Ah, Kenneth Lim is around for an hour if you want to do the pull request first.",
        "tokens": [
          50456,
          2438,
          11,
          33735,
          16406,
          307,
          926,
          337,
          364,
          1773,
          498,
          291,
          528,
          281,
          360,
          264,
          2235,
          5308,
          700,
          13,
          50752
        ]
      },
      {
        "avg_logprob": -0.3172469086699433,
        "compression_ratio": 1.403061224489796,
        "end": 739.9399999999999,
        "id": 185,
        "no_speech_prob": 0.009267205372452736,
        "seek": 72890,
        "start": 736.66,
        "temperature": 0,
        "text": " I do.",
        "tokens": [
          50752,
          286,
          360,
          13,
          50916
        ]
      },
      {
        "avg_logprob": -0.3172469086699433,
        "compression_ratio": 1.403061224489796,
        "end": 741.54,
        "id": 186,
        "no_speech_prob": 0.009267205372452736,
        "seek": 72890,
        "start": 739.9399999999999,
        "temperature": 0,
        "text": " But I think that's probably not wise.",
        "tokens": [
          50916,
          583,
          286,
          519,
          300,
          311,
          1391,
          406,
          10829,
          13,
          50996
        ]
      },
      {
        "avg_logprob": -0.3172469086699433,
        "compression_ratio": 1.403061224489796,
        "end": 742.54,
        "id": 187,
        "no_speech_prob": 0.009267205372452736,
        "seek": 72890,
        "start": 741.54,
        "temperature": 0,
        "text": " But let's actually...",
        "tokens": [
          50996,
          583,
          718,
          311,
          767,
          485,
          51046
        ]
      },
      {
        "avg_logprob": -0.3172469086699433,
        "compression_ratio": 1.403061224489796,
        "end": 743.54,
        "id": 188,
        "no_speech_prob": 0.009267205372452736,
        "seek": 72890,
        "start": 742.54,
        "temperature": 0,
        "text": " Let me at least revisit.",
        "tokens": [
          51046,
          961,
          385,
          412,
          1935,
          32676,
          13,
          51096
        ]
      },
      {
        "avg_logprob": -0.3172469086699433,
        "compression_ratio": 1.403061224489796,
        "end": 744.54,
        "id": 189,
        "no_speech_prob": 0.009267205372452736,
        "seek": 72890,
        "start": 743.54,
        "temperature": 0,
        "text": " So I did...",
        "tokens": [
          51096,
          407,
          286,
          630,
          485,
          51146
        ]
      },
      {
        "avg_logprob": -0.3172469086699433,
        "compression_ratio": 1.403061224489796,
        "end": 757.18,
        "id": 190,
        "no_speech_prob": 0.009267205372452736,
        "seek": 72890,
        "start": 744.54,
        "temperature": 0,
        "text": " Since Kenneth is in the chat, let me go quickly to github.com processing p5.js.",
        "tokens": [
          51146,
          4162,
          33735,
          307,
          294,
          264,
          5081,
          11,
          718,
          385,
          352,
          2661,
          281,
          290,
          355,
          836,
          13,
          1112,
          9007,
          280,
          20,
          13,
          25530,
          13,
          51778
        ]
      },
      {
        "avg_logprob": -0.30033034839849365,
        "compression_ratio": 1.5,
        "end": 762.5799999999999,
        "id": 191,
        "no_speech_prob": 0.08034215867519379,
        "seek": 75718,
        "start": 757.18,
        "temperature": 0,
        "text": " Pull requests and load bytes.",
        "tokens": [
          50364,
          15074,
          12475,
          293,
          3677,
          36088,
          13,
          50634
        ]
      },
      {
        "avg_logprob": -0.30033034839849365,
        "compression_ratio": 1.5,
        "end": 765.42,
        "id": 192,
        "no_speech_prob": 0.08034215867519379,
        "seek": 75718,
        "start": 762.5799999999999,
        "temperature": 0,
        "text": " Here we go.",
        "tokens": [
          50634,
          1692,
          321,
          352,
          13,
          50776
        ]
      },
      {
        "avg_logprob": -0.30033034839849365,
        "compression_ratio": 1.5,
        "end": 769.02,
        "id": 193,
        "no_speech_prob": 0.08034215867519379,
        "seek": 75718,
        "start": 765.42,
        "temperature": 0,
        "text": " So I did just release a video this morning.",
        "tokens": [
          50776,
          407,
          286,
          630,
          445,
          4374,
          257,
          960,
          341,
          2446,
          13,
          50956
        ]
      },
      {
        "avg_logprob": -0.30033034839849365,
        "compression_ratio": 1.5,
        "end": 770.26,
        "id": 194,
        "no_speech_prob": 0.08034215867519379,
        "seek": 75718,
        "start": 769.02,
        "temperature": 0,
        "text": " This was made weeks ago.",
        "tokens": [
          50956,
          639,
          390,
          1027,
          3259,
          2057,
          13,
          51018
        ]
      },
      {
        "avg_logprob": -0.30033034839849365,
        "compression_ratio": 1.5,
        "end": 777.2199999999999,
        "id": 195,
        "no_speech_prob": 0.08034215867519379,
        "seek": 75718,
        "start": 770.26,
        "temperature": 0,
        "text": " I just had a mental block with releasing it, which is this video.",
        "tokens": [
          51018,
          286,
          445,
          632,
          257,
          4973,
          3461,
          365,
          16327,
          309,
          11,
          597,
          307,
          341,
          960,
          13,
          51366
        ]
      },
      {
        "avg_logprob": -0.30033034839849365,
        "compression_ratio": 1.5,
        "end": 779.9799999999999,
        "id": 196,
        "no_speech_prob": 0.08034215867519379,
        "seek": 75718,
        "start": 777.2199999999999,
        "temperature": 0,
        "text": " Adding a function to p5.js.",
        "tokens": [
          51366,
          31204,
          257,
          2445,
          281,
          280,
          20,
          13,
          25530,
          13,
          51504
        ]
      },
      {
        "avg_logprob": -0.30033034839849365,
        "compression_ratio": 1.5,
        "end": 785.9399999999999,
        "id": 197,
        "no_speech_prob": 0.08034215867519379,
        "seek": 75718,
        "start": 779.9799999999999,
        "temperature": 0,
        "text": " So I wanted to, in that video, show the process of making a pull request to a larger open",
        "tokens": [
          51504,
          407,
          286,
          1415,
          281,
          11,
          294,
          300,
          960,
          11,
          855,
          264,
          1399,
          295,
          1455,
          257,
          2235,
          5308,
          281,
          257,
          4833,
          1269,
          51802
        ]
      },
      {
        "avg_logprob": -0.284883265592614,
        "compression_ratio": 1.559090909090909,
        "end": 788.94,
        "id": 198,
        "no_speech_prob": 0.30069833993911743,
        "seek": 78594,
        "start": 785.94,
        "temperature": 0,
        "text": " source project and what's involved with that.",
        "tokens": [
          50364,
          4009,
          1716,
          293,
          437,
          311,
          3288,
          365,
          300,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.284883265592614,
        "compression_ratio": 1.559090909090909,
        "end": 789.94,
        "id": 199,
        "no_speech_prob": 0.30069833993911743,
        "seek": 78594,
        "start": 788.94,
        "temperature": 0,
        "text": " And I did that.",
        "tokens": [
          50514,
          400,
          286,
          630,
          300,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.284883265592614,
        "compression_ratio": 1.559090909090909,
        "end": 791.82,
        "id": 200,
        "no_speech_prob": 0.30069833993911743,
        "seek": 78594,
        "start": 789.94,
        "temperature": 0,
        "text": " This is the pull request.",
        "tokens": [
          50564,
          639,
          307,
          264,
          2235,
          5308,
          13,
          50658
        ]
      },
      {
        "avg_logprob": -0.284883265592614,
        "compression_ratio": 1.559090909090909,
        "end": 798.5,
        "id": 201,
        "no_speech_prob": 0.30069833993911743,
        "seek": 78594,
        "start": 791.82,
        "temperature": 0,
        "text": " There are some nice comments from meiamsomy and from limzykenneth, who's in the chat.",
        "tokens": [
          50658,
          821,
          366,
          512,
          1481,
          3053,
          490,
          385,
          2918,
          82,
          8488,
          293,
          490,
          2364,
          1229,
          74,
          1857,
          3293,
          11,
          567,
          311,
          294,
          264,
          5081,
          13,
          50992
        ]
      },
      {
        "avg_logprob": -0.284883265592614,
        "compression_ratio": 1.559090909090909,
        "end": 805.7,
        "id": 202,
        "no_speech_prob": 0.30069833993911743,
        "seek": 78594,
        "start": 798.5,
        "temperature": 0,
        "text": " And so I think, actually, just scanning this over, probably what I just want to do is implement",
        "tokens": [
          50992,
          400,
          370,
          286,
          519,
          11,
          767,
          11,
          445,
          27019,
          341,
          670,
          11,
          1391,
          437,
          286,
          445,
          528,
          281,
          360,
          307,
          4445,
          51352
        ]
      },
      {
        "avg_logprob": -0.284883265592614,
        "compression_ratio": 1.559090909090909,
        "end": 811.1,
        "id": 203,
        "no_speech_prob": 0.30069833993911743,
        "seek": 78594,
        "start": 805.7,
        "temperature": 0,
        "text": " this change to how I'm finding the error.",
        "tokens": [
          51352,
          341,
          1319,
          281,
          577,
          286,
          478,
          5006,
          264,
          6713,
          13,
          51622
        ]
      },
      {
        "avg_logprob": -0.284883265592614,
        "compression_ratio": 1.559090909090909,
        "end": 814.1,
        "id": 204,
        "no_speech_prob": 0.30069833993911743,
        "seek": 78594,
        "start": 811.1,
        "temperature": 0,
        "text": " So before this can be merged...",
        "tokens": [
          51622,
          407,
          949,
          341,
          393,
          312,
          36427,
          485,
          51772
        ]
      },
      {
        "avg_logprob": -0.3327241738637288,
        "compression_ratio": 1.5330188679245282,
        "end": 815.98,
        "id": 205,
        "no_speech_prob": 0.17776422202587128,
        "seek": 81410,
        "start": 814.1,
        "temperature": 0,
        "text": " It is over here.",
        "tokens": [
          50364,
          467,
          307,
          670,
          510,
          13,
          50458
        ]
      },
      {
        "avg_logprob": -0.3327241738637288,
        "compression_ratio": 1.5330188679245282,
        "end": 818.5400000000001,
        "id": 206,
        "no_speech_prob": 0.17776422202587128,
        "seek": 81410,
        "start": 815.98,
        "temperature": 0,
        "text": " There's some noise, but that's fine.",
        "tokens": [
          50458,
          821,
          311,
          512,
          5658,
          11,
          457,
          300,
          311,
          2489,
          13,
          50586
        ]
      },
      {
        "avg_logprob": -0.3327241738637288,
        "compression_ratio": 1.5330188679245282,
        "end": 823.34,
        "id": 207,
        "no_speech_prob": 0.17776422202587128,
        "seek": 81410,
        "start": 818.5400000000001,
        "temperature": 0,
        "text": " Before this can be merged, I've got to push some more changes to the pull request.",
        "tokens": [
          50586,
          4546,
          341,
          393,
          312,
          36427,
          11,
          286,
          600,
          658,
          281,
          2944,
          512,
          544,
          2962,
          281,
          264,
          2235,
          5308,
          13,
          50826
        ]
      },
      {
        "avg_logprob": -0.3327241738637288,
        "compression_ratio": 1.5330188679245282,
        "end": 826.5,
        "id": 208,
        "no_speech_prob": 0.17776422202587128,
        "seek": 81410,
        "start": 823.34,
        "temperature": 0,
        "text": " But I think I'm not going to do that right now.",
        "tokens": [
          50826,
          583,
          286,
          519,
          286,
          478,
          406,
          516,
          281,
          360,
          300,
          558,
          586,
          13,
          50984
        ]
      },
      {
        "avg_logprob": -0.3327241738637288,
        "compression_ratio": 1.5330188679245282,
        "end": 831.82,
        "id": 209,
        "no_speech_prob": 0.17776422202587128,
        "seek": 81410,
        "start": 826.5,
        "temperature": 0,
        "text": " But I would welcome any feedback or comments here, and I'll try to get to that soon.",
        "tokens": [
          50984,
          583,
          286,
          576,
          2928,
          604,
          5824,
          420,
          3053,
          510,
          11,
          293,
          286,
          603,
          853,
          281,
          483,
          281,
          300,
          2321,
          13,
          51250
        ]
      },
      {
        "avg_logprob": -0.3327241738637288,
        "compression_ratio": 1.5330188679245282,
        "end": 835.62,
        "id": 210,
        "no_speech_prob": 0.17776422202587128,
        "seek": 81410,
        "start": 831.82,
        "temperature": 0,
        "text": " All right.",
        "tokens": [
          51250,
          1057,
          558,
          13,
          51440
        ]
      },
      {
        "avg_logprob": -0.3327241738637288,
        "compression_ratio": 1.5330188679245282,
        "end": 840.6600000000001,
        "id": 211,
        "no_speech_prob": 0.17776422202587128,
        "seek": 81410,
        "start": 835.62,
        "temperature": 0,
        "text": " So now the question is color predictor or...",
        "tokens": [
          51440,
          407,
          586,
          264,
          1168,
          307,
          2017,
          6069,
          284,
          420,
          485,
          51692
        ]
      },
      {
        "avg_logprob": -0.286248759219521,
        "compression_ratio": 1.6905829596412556,
        "end": 844.8199999999999,
        "id": 212,
        "no_speech_prob": 0.14606457948684692,
        "seek": 84066,
        "start": 841.18,
        "temperature": 0,
        "text": " Let me do a straw poll, because I can't decide.",
        "tokens": [
          50390,
          961,
          385,
          360,
          257,
          10099,
          6418,
          11,
          570,
          286,
          393,
          380,
          4536,
          13,
          50572
        ]
      },
      {
        "avg_logprob": -0.286248759219521,
        "compression_ratio": 1.6905829596412556,
        "end": 845.8199999999999,
        "id": 213,
        "no_speech_prob": 0.14606457948684692,
        "seek": 84066,
        "start": 844.8199999999999,
        "temperature": 0,
        "text": " Color predictor...",
        "tokens": [
          50572,
          10458,
          6069,
          284,
          485,
          50622
        ]
      },
      {
        "avg_logprob": -0.286248759219521,
        "compression_ratio": 1.6905829596412556,
        "end": 852.02,
        "id": 214,
        "no_speech_prob": 0.14606457948684692,
        "seek": 84066,
        "start": 845.8199999999999,
        "temperature": 0,
        "text": " I really feel like I should do the color predictor, because it's following up on the livestream",
        "tokens": [
          50622,
          286,
          534,
          841,
          411,
          286,
          820,
          360,
          264,
          2017,
          6069,
          284,
          11,
          570,
          309,
          311,
          3480,
          493,
          322,
          264,
          29782,
          50932
        ]
      },
      {
        "avg_logprob": -0.286248759219521,
        "compression_ratio": 1.6905829596412556,
        "end": 855.02,
        "id": 215,
        "no_speech_prob": 0.14606457948684692,
        "seek": 84066,
        "start": 852.02,
        "temperature": 0,
        "text": " from last week, and doing it later will be stale.",
        "tokens": [
          50932,
          490,
          1036,
          1243,
          11,
          293,
          884,
          309,
          1780,
          486,
          312,
          342,
          1220,
          13,
          51082
        ]
      },
      {
        "avg_logprob": -0.286248759219521,
        "compression_ratio": 1.6905829596412556,
        "end": 857.02,
        "id": 216,
        "no_speech_prob": 0.14606457948684692,
        "seek": 84066,
        "start": 855.02,
        "temperature": 0,
        "text": " I'm going to do the color predictor.",
        "tokens": [
          51082,
          286,
          478,
          516,
          281,
          360,
          264,
          2017,
          6069,
          284,
          13,
          51182
        ]
      },
      {
        "avg_logprob": -0.286248759219521,
        "compression_ratio": 1.6905829596412556,
        "end": 861.5799999999999,
        "id": 217,
        "no_speech_prob": 0.14606457948684692,
        "seek": 84066,
        "start": 857.02,
        "temperature": 0,
        "text": " Yeah, let's do the color predictor.",
        "tokens": [
          51182,
          865,
          11,
          718,
          311,
          360,
          264,
          2017,
          6069,
          284,
          13,
          51410
        ]
      },
      {
        "avg_logprob": -0.286248759219521,
        "compression_ratio": 1.6905829596412556,
        "end": 862.6999999999999,
        "id": 218,
        "no_speech_prob": 0.14606457948684692,
        "seek": 84066,
        "start": 861.5799999999999,
        "temperature": 0,
        "text": " So let me get...",
        "tokens": [
          51410,
          407,
          718,
          385,
          483,
          485,
          51466
        ]
      },
      {
        "avg_logprob": -0.286248759219521,
        "compression_ratio": 1.6905829596412556,
        "end": 864.66,
        "id": 219,
        "no_speech_prob": 0.14606457948684692,
        "seek": 84066,
        "start": 862.6999999999999,
        "temperature": 0,
        "text": " We have an hour and 15 minutes for that.",
        "tokens": [
          51466,
          492,
          362,
          364,
          1773,
          293,
          2119,
          2077,
          337,
          300,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.286248759219521,
        "compression_ratio": 1.6905829596412556,
        "end": 865.66,
        "id": 220,
        "no_speech_prob": 0.14606457948684692,
        "seek": 84066,
        "start": 864.66,
        "temperature": 0,
        "text": " And I think it's going to happen.",
        "tokens": [
          51564,
          400,
          286,
          519,
          309,
          311,
          516,
          281,
          1051,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.2970203161239624,
        "compression_ratio": 1.5890410958904109,
        "end": 873.5,
        "id": 221,
        "no_speech_prob": 0.2308763563632965,
        "seek": 86566,
        "start": 865.86,
        "temperature": 0,
        "text": " One thing, though, I'm a little bit freaked out about is the following.",
        "tokens": [
          50374,
          1485,
          551,
          11,
          1673,
          11,
          286,
          478,
          257,
          707,
          857,
          37853,
          484,
          466,
          307,
          264,
          3480,
          13,
          50756
        ]
      },
      {
        "avg_logprob": -0.2970203161239624,
        "compression_ratio": 1.5890410958904109,
        "end": 877.54,
        "id": 222,
        "no_speech_prob": 0.2308763563632965,
        "seek": 86566,
        "start": 873.5,
        "temperature": 0,
        "text": " Let me show you what I'm freaked out about.",
        "tokens": [
          50756,
          961,
          385,
          855,
          291,
          437,
          286,
          478,
          37853,
          484,
          466,
          13,
          50958
        ]
      },
      {
        "avg_logprob": -0.2970203161239624,
        "compression_ratio": 1.5890410958904109,
        "end": 878.54,
        "id": 223,
        "no_speech_prob": 0.2308763563632965,
        "seek": 86566,
        "start": 877.54,
        "temperature": 0,
        "text": " Coding challenges.",
        "tokens": [
          50958,
          383,
          8616,
          4759,
          13,
          51008
        ]
      },
      {
        "avg_logprob": -0.2970203161239624,
        "compression_ratio": 1.5890410958904109,
        "end": 880.5,
        "id": 224,
        "no_speech_prob": 0.2308763563632965,
        "seek": 86566,
        "start": 878.54,
        "temperature": 0,
        "text": " I'm going to go to this playlist.",
        "tokens": [
          51008,
          286,
          478,
          516,
          281,
          352,
          281,
          341,
          16788,
          13,
          51106
        ]
      },
      {
        "avg_logprob": -0.2970203161239624,
        "compression_ratio": 1.5890410958904109,
        "end": 881.66,
        "id": 225,
        "no_speech_prob": 0.2308763563632965,
        "seek": 86566,
        "start": 880.5,
        "temperature": 0,
        "text": " Coding challenge one.",
        "tokens": [
          51106,
          383,
          8616,
          3430,
          472,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.2970203161239624,
        "compression_ratio": 1.5890410958904109,
        "end": 888.98,
        "id": 226,
        "no_speech_prob": 0.2308763563632965,
        "seek": 86566,
        "start": 881.66,
        "temperature": 0,
        "text": " 13 minutes, Starfield in processing, many fewer gray hairs, nicer shirt.",
        "tokens": [
          51164,
          3705,
          2077,
          11,
          5705,
          7610,
          294,
          9007,
          11,
          867,
          13366,
          10855,
          26525,
          11,
          22842,
          8336,
          13,
          51530
        ]
      },
      {
        "avg_logprob": -0.2970203161239624,
        "compression_ratio": 1.5890410958904109,
        "end": 892.9,
        "id": 227,
        "no_speech_prob": 0.2308763563632965,
        "seek": 86566,
        "start": 888.98,
        "temperature": 0,
        "text": " This shirt has now been gone into textile recycling, because it had two holes in it.",
        "tokens": [
          51530,
          639,
          8336,
          575,
          586,
          668,
          2780,
          666,
          42069,
          23363,
          11,
          570,
          309,
          632,
          732,
          8118,
          294,
          309,
          13,
          51726
        ]
      },
      {
        "avg_logprob": -0.34493717578572963,
        "compression_ratio": 1.6651162790697673,
        "end": 895.54,
        "id": 228,
        "no_speech_prob": 0.18241240084171295,
        "seek": 89290,
        "start": 893.14,
        "temperature": 0,
        "text": " But anyway, that's coding challenge one, whenever that was recorded.",
        "tokens": [
          50376,
          583,
          4033,
          11,
          300,
          311,
          17720,
          3430,
          472,
          11,
          5699,
          300,
          390,
          8287,
          13,
          50496
        ]
      },
      {
        "avg_logprob": -0.34493717578572963,
        "compression_ratio": 1.6651162790697673,
        "end": 898.14,
        "id": 229,
        "no_speech_prob": 0.18241240084171295,
        "seek": 89290,
        "start": 895.54,
        "temperature": 0,
        "text": " If I go all the way down to here...",
        "tokens": [
          50496,
          759,
          286,
          352,
          439,
          264,
          636,
          760,
          281,
          510,
          485,
          50626
        ]
      },
      {
        "avg_logprob": -0.34493717578572963,
        "compression_ratio": 1.6651162790697673,
        "end": 899.14,
        "id": 230,
        "no_speech_prob": 0.18241240084171295,
        "seek": 89290,
        "start": 898.14,
        "temperature": 0,
        "text": " I'll keep scrolling.",
        "tokens": [
          50626,
          286,
          603,
          1066,
          29053,
          13,
          50676
        ]
      },
      {
        "avg_logprob": -0.34493717578572963,
        "compression_ratio": 1.6651162790697673,
        "end": 900.14,
        "id": 231,
        "no_speech_prob": 0.18241240084171295,
        "seek": 89290,
        "start": 899.14,
        "temperature": 0,
        "text": " I'm going to scroll...",
        "tokens": [
          50676,
          286,
          478,
          516,
          281,
          11369,
          485,
          50726
        ]
      },
      {
        "avg_logprob": -0.34493717578572963,
        "compression_ratio": 1.6651162790697673,
        "end": 901.14,
        "id": 232,
        "no_speech_prob": 0.18241240084171295,
        "seek": 89290,
        "start": 900.14,
        "temperature": 0,
        "text": " Look at this.",
        "tokens": [
          50726,
          2053,
          412,
          341,
          13,
          50776
        ]
      },
      {
        "avg_logprob": -0.34493717578572963,
        "compression_ratio": 1.6651162790697673,
        "end": 904.5,
        "id": 233,
        "no_speech_prob": 0.18241240084171295,
        "seek": 89290,
        "start": 901.14,
        "temperature": 0,
        "text": " Quadtree 98.",
        "tokens": [
          50776,
          29619,
          83,
          701,
          20860,
          13,
          50944
        ]
      },
      {
        "avg_logprob": -0.34493717578572963,
        "compression_ratio": 1.6651162790697673,
        "end": 913.38,
        "id": 234,
        "no_speech_prob": 0.18241240084171295,
        "seek": 89290,
        "start": 904.5,
        "temperature": 0,
        "text": " This means my color predictor, the color predictor, Jabril's color predictor, would be coding",
        "tokens": [
          50944,
          639,
          1355,
          452,
          2017,
          6069,
          284,
          11,
          264,
          2017,
          6069,
          284,
          11,
          40319,
          24216,
          311,
          2017,
          6069,
          284,
          11,
          576,
          312,
          17720,
          51388
        ]
      },
      {
        "avg_logprob": -0.34493717578572963,
        "compression_ratio": 1.6651162790697673,
        "end": 914.38,
        "id": 235,
        "no_speech_prob": 0.18241240084171295,
        "seek": 89290,
        "start": 913.38,
        "temperature": 0,
        "text": " challenge 99.",
        "tokens": [
          51388,
          3430,
          11803,
          13,
          51438
        ]
      },
      {
        "avg_logprob": -0.34493717578572963,
        "compression_ratio": 1.6651162790697673,
        "end": 921.66,
        "id": 236,
        "no_speech_prob": 0.18241240084171295,
        "seek": 89290,
        "start": 914.38,
        "temperature": 0,
        "text": " Now, I can get away with coding challenge 98.3, being Quadtree part three.",
        "tokens": [
          51438,
          823,
          11,
          286,
          393,
          483,
          1314,
          365,
          17720,
          3430,
          20860,
          13,
          18,
          11,
          885,
          29619,
          83,
          701,
          644,
          1045,
          13,
          51802
        ]
      },
      {
        "avg_logprob": -0.27712015467365897,
        "compression_ratio": 1.6788321167883211,
        "end": 925.42,
        "id": 237,
        "no_speech_prob": 0.006692704278975725,
        "seek": 92166,
        "start": 921.66,
        "temperature": 0,
        "text": " But then it's going to be time for coding challenge number 100.",
        "tokens": [
          50364,
          583,
          550,
          309,
          311,
          516,
          281,
          312,
          565,
          337,
          17720,
          3430,
          1230,
          2319,
          13,
          50552
        ]
      },
      {
        "avg_logprob": -0.27712015467365897,
        "compression_ratio": 1.6788321167883211,
        "end": 928.3,
        "id": 238,
        "no_speech_prob": 0.006692704278975725,
        "seek": 92166,
        "start": 925.42,
        "temperature": 0,
        "text": " I feel really stressed out about...",
        "tokens": [
          50552,
          286,
          841,
          534,
          14471,
          484,
          466,
          485,
          50696
        ]
      },
      {
        "avg_logprob": -0.27712015467365897,
        "compression_ratio": 1.6788321167883211,
        "end": 931.9,
        "id": 239,
        "no_speech_prob": 0.006692704278975725,
        "seek": 92166,
        "start": 928.3,
        "temperature": 0,
        "text": " But I could just say, it's just another coding challenge.",
        "tokens": [
          50696,
          583,
          286,
          727,
          445,
          584,
          11,
          309,
          311,
          445,
          1071,
          17720,
          3430,
          13,
          50876
        ]
      },
      {
        "avg_logprob": -0.27712015467365897,
        "compression_ratio": 1.6788321167883211,
        "end": 932.9,
        "id": 240,
        "no_speech_prob": 0.006692704278975725,
        "seek": 92166,
        "start": 931.9,
        "temperature": 0,
        "text": " It's just number 100.",
        "tokens": [
          50876,
          467,
          311,
          445,
          1230,
          2319,
          13,
          50926
        ]
      },
      {
        "avg_logprob": -0.27712015467365897,
        "compression_ratio": 1.6788321167883211,
        "end": 937.18,
        "id": 241,
        "no_speech_prob": 0.006692704278975725,
        "seek": 92166,
        "start": 932.9,
        "temperature": 0,
        "text": " But I feel this pressure to do something extra special for that.",
        "tokens": [
          50926,
          583,
          286,
          841,
          341,
          3321,
          281,
          360,
          746,
          2857,
          2121,
          337,
          300,
          13,
          51140
        ]
      },
      {
        "avg_logprob": -0.27712015467365897,
        "compression_ratio": 1.6788321167883211,
        "end": 940.38,
        "id": 242,
        "no_speech_prob": 0.006692704278975725,
        "seek": 92166,
        "start": 937.18,
        "temperature": 0,
        "text": " Could be the neuroevolution thing, because that's kind of like a topic I've been building",
        "tokens": [
          51140,
          7497,
          312,
          264,
          16499,
          13379,
          3386,
          551,
          11,
          570,
          300,
          311,
          733,
          295,
          411,
          257,
          4829,
          286,
          600,
          668,
          2390,
          51300
        ]
      },
      {
        "avg_logprob": -0.27712015467365897,
        "compression_ratio": 1.6788321167883211,
        "end": 941.86,
        "id": 243,
        "no_speech_prob": 0.006692704278975725,
        "seek": 92166,
        "start": 940.38,
        "temperature": 0,
        "text": " up to for a while.",
        "tokens": [
          51300,
          493,
          281,
          337,
          257,
          1339,
          13,
          51374
        ]
      },
      {
        "avg_logprob": -0.27712015467365897,
        "compression_ratio": 1.6788321167883211,
        "end": 945.3399999999999,
        "id": 244,
        "no_speech_prob": 0.006692704278975725,
        "seek": 92166,
        "start": 941.86,
        "temperature": 0,
        "text": " Could be Tetris, but I'm not so game-focused that that really makes sense.",
        "tokens": [
          51374,
          7497,
          312,
          31580,
          5714,
          11,
          457,
          286,
          478,
          406,
          370,
          1216,
          12,
          44062,
          300,
          300,
          534,
          1669,
          2020,
          13,
          51548
        ]
      },
      {
        "avg_logprob": -0.27712015467365897,
        "compression_ratio": 1.6788321167883211,
        "end": 950.62,
        "id": 245,
        "no_speech_prob": 0.006692704278975725,
        "seek": 92166,
        "start": 945.3399999999999,
        "temperature": 0,
        "text": " Anyway, I'm open to your ideas.",
        "tokens": [
          51548,
          5684,
          11,
          286,
          478,
          1269,
          281,
          428,
          3487,
          13,
          51812
        ]
      },
      {
        "avg_logprob": -0.37279460586120033,
        "compression_ratio": 1.5086206896551724,
        "end": 953.02,
        "id": 246,
        "no_speech_prob": 0.03308490291237831,
        "seek": 95062,
        "start": 950.62,
        "temperature": 0,
        "text": " That's what I'm thinking about these days.",
        "tokens": [
          50364,
          663,
          311,
          437,
          286,
          478,
          1953,
          466,
          613,
          1708,
          13,
          50484
        ]
      },
      {
        "avg_logprob": -0.37279460586120033,
        "compression_ratio": 1.5086206896551724,
        "end": 955.98,
        "id": 247,
        "no_speech_prob": 0.03308490291237831,
        "seek": 95062,
        "start": 953.02,
        "temperature": 0,
        "text": " All right, let's do the color predictor.",
        "tokens": [
          50484,
          1057,
          558,
          11,
          718,
          311,
          360,
          264,
          2017,
          6069,
          284,
          13,
          50632
        ]
      },
      {
        "avg_logprob": -0.37279460586120033,
        "compression_ratio": 1.5086206896551724,
        "end": 960.98,
        "id": 248,
        "no_speech_prob": 0.03308490291237831,
        "seek": 95062,
        "start": 955.98,
        "temperature": 0,
        "text": " So let me get myself situated.",
        "tokens": [
          50632,
          407,
          718,
          385,
          483,
          2059,
          30143,
          13,
          50882
        ]
      },
      {
        "avg_logprob": -0.37279460586120033,
        "compression_ratio": 1.5086206896551724,
        "end": 962.54,
        "id": 249,
        "no_speech_prob": 0.03308490291237831,
        "seek": 95062,
        "start": 960.98,
        "temperature": 0,
        "text": " Someone's going to have to wake up Jabril.",
        "tokens": [
          50882,
          8734,
          311,
          516,
          281,
          362,
          281,
          6634,
          493,
          40319,
          24216,
          13,
          50960
        ]
      },
      {
        "avg_logprob": -0.37279460586120033,
        "compression_ratio": 1.5086206896551724,
        "end": 965.86,
        "id": 250,
        "no_speech_prob": 0.03308490291237831,
        "seek": 95062,
        "start": 962.54,
        "temperature": 0,
        "text": " He's early on the West Coast, and I know he's not a morning person.",
        "tokens": [
          50960,
          634,
          311,
          2440,
          322,
          264,
          4055,
          14960,
          11,
          293,
          286,
          458,
          415,
          311,
          406,
          257,
          2446,
          954,
          13,
          51126
        ]
      },
      {
        "avg_logprob": -0.37279460586120033,
        "compression_ratio": 1.5086206896551724,
        "end": 967.34,
        "id": 251,
        "no_speech_prob": 0.03308490291237831,
        "seek": 95062,
        "start": 965.86,
        "temperature": 0,
        "text": " That's something I learned.",
        "tokens": [
          51126,
          663,
          311,
          746,
          286,
          3264,
          13,
          51200
        ]
      },
      {
        "avg_logprob": -0.37279460586120033,
        "compression_ratio": 1.5086206896551724,
        "end": 972.38,
        "id": 252,
        "no_speech_prob": 0.03308490291237831,
        "seek": 95062,
        "start": 967.34,
        "temperature": 0,
        "text": " I was like, let me schedule you for this thing at NYU at 10am.",
        "tokens": [
          51200,
          286,
          390,
          411,
          11,
          718,
          385,
          7567,
          291,
          337,
          341,
          551,
          412,
          42682,
          412,
          1266,
          335,
          13,
          51452
        ]
      },
      {
        "avg_logprob": -0.37279460586120033,
        "compression_ratio": 1.5086206896551724,
        "end": 973.38,
        "id": 253,
        "no_speech_prob": 0.03308490291237831,
        "seek": 95062,
        "start": 972.38,
        "temperature": 0,
        "text": " That's no problem for you, right?",
        "tokens": [
          51452,
          663,
          311,
          572,
          1154,
          337,
          291,
          11,
          558,
          30,
          51502
        ]
      },
      {
        "avg_logprob": -0.3631416575113932,
        "compression_ratio": 1.3903743315508021,
        "end": 981.74,
        "id": 254,
        "no_speech_prob": 0.1540437936782837,
        "seek": 97338,
        "start": 973.38,
        "temperature": 0,
        "text": " Yeah, we're going to have a Y2K issue, because suddenly now the coding challenges have three",
        "tokens": [
          50364,
          865,
          11,
          321,
          434,
          516,
          281,
          362,
          257,
          398,
          17,
          42,
          2734,
          11,
          570,
          5800,
          586,
          264,
          17720,
          4759,
          362,
          1045,
          50782
        ]
      },
      {
        "avg_logprob": -0.3631416575113932,
        "compression_ratio": 1.3903743315508021,
        "end": 984.22,
        "id": 255,
        "no_speech_prob": 0.1540437936782837,
        "seek": 97338,
        "start": 981.74,
        "temperature": 0,
        "text": " numbers instead of two.",
        "tokens": [
          50782,
          3547,
          2602,
          295,
          732,
          13,
          50906
        ]
      },
      {
        "avg_logprob": -0.3631416575113932,
        "compression_ratio": 1.3903743315508021,
        "end": 988.9,
        "id": 256,
        "no_speech_prob": 0.1540437936782837,
        "seek": 97338,
        "start": 984.22,
        "temperature": 0,
        "text": " Our unit tests don't accommodate that.",
        "tokens": [
          50906,
          2621,
          4985,
          6921,
          500,
          380,
          21410,
          300,
          13,
          51140
        ]
      },
      {
        "avg_logprob": -0.3631416575113932,
        "compression_ratio": 1.3903743315508021,
        "end": 995.14,
        "id": 257,
        "no_speech_prob": 0.1540437936782837,
        "seek": 97338,
        "start": 988.9,
        "temperature": 0,
        "text": " CD desktop, P5G-B, color predictor.",
        "tokens": [
          51140,
          6743,
          14502,
          11,
          430,
          20,
          38,
          12,
          33,
          11,
          2017,
          6069,
          284,
          13,
          51452
        ]
      },
      {
        "avg_logprob": -0.3631416575113932,
        "compression_ratio": 1.3903743315508021,
        "end": 1002.26,
        "id": 258,
        "no_speech_prob": 0.1540437936782837,
        "seek": 97338,
        "start": 995.14,
        "temperature": 0,
        "text": " I don't know if color predictor is actually the right term for this.",
        "tokens": [
          51452,
          286,
          500,
          380,
          458,
          498,
          2017,
          6069,
          284,
          307,
          767,
          264,
          558,
          1433,
          337,
          341,
          13,
          51808
        ]
      },
      {
        "avg_logprob": -0.30890240512051426,
        "compression_ratio": 1.5923913043478262,
        "end": 1006.9,
        "id": 259,
        "no_speech_prob": 0.1918964385986328,
        "seek": 100226,
        "start": 1002.26,
        "temperature": 0,
        "text": " CD color predictor open.",
        "tokens": [
          50364,
          6743,
          2017,
          6069,
          284,
          1269,
          13,
          50596
        ]
      },
      {
        "avg_logprob": -0.30890240512051426,
        "compression_ratio": 1.5923913043478262,
        "end": 1007.9,
        "id": 260,
        "no_speech_prob": 0.1918964385986328,
        "seek": 100226,
        "start": 1006.9,
        "temperature": 0,
        "text": " Let's see.",
        "tokens": [
          50596,
          961,
          311,
          536,
          13,
          50646
        ]
      },
      {
        "avg_logprob": -0.30890240512051426,
        "compression_ratio": 1.5923913043478262,
        "end": 1010.58,
        "id": 261,
        "no_speech_prob": 0.1918964385986328,
        "seek": 100226,
        "start": 1007.9,
        "temperature": 0,
        "text": " I don't care about...",
        "tokens": [
          50646,
          286,
          500,
          380,
          1127,
          466,
          485,
          50780
        ]
      },
      {
        "avg_logprob": -0.30890240512051426,
        "compression_ratio": 1.5923913043478262,
        "end": 1013.9399999999999,
        "id": 262,
        "no_speech_prob": 0.1918964385986328,
        "seek": 100226,
        "start": 1010.58,
        "temperature": 0,
        "text": " So actually, this is ridiculous what I'm doing here, but I'm going to do it anyway.",
        "tokens": [
          50780,
          407,
          767,
          11,
          341,
          307,
          11083,
          437,
          286,
          478,
          884,
          510,
          11,
          457,
          286,
          478,
          516,
          281,
          360,
          309,
          4033,
          13,
          50948
        ]
      },
      {
        "avg_logprob": -0.30890240512051426,
        "compression_ratio": 1.5923913043478262,
        "end": 1017.74,
        "id": 263,
        "no_speech_prob": 0.1918964385986328,
        "seek": 100226,
        "start": 1013.9399999999999,
        "temperature": 0,
        "text": " I'm going to get rid of the libraries folder.",
        "tokens": [
          50948,
          286,
          478,
          516,
          281,
          483,
          3973,
          295,
          264,
          15148,
          10820,
          13,
          51138
        ]
      },
      {
        "avg_logprob": -0.30890240512051426,
        "compression_ratio": 1.5923913043478262,
        "end": 1024.86,
        "id": 264,
        "no_speech_prob": 0.1918964385986328,
        "seek": 100226,
        "start": 1017.74,
        "temperature": 0,
        "text": " I'm going to go to...",
        "tokens": [
          51138,
          286,
          478,
          516,
          281,
          352,
          281,
          485,
          51494
        ]
      },
      {
        "avg_logprob": -0.30890240512051426,
        "compression_ratio": 1.5923913043478262,
        "end": 1030.14,
        "id": 265,
        "no_speech_prob": 0.1918964385986328,
        "seek": 100226,
        "start": 1024.86,
        "temperature": 0,
        "text": " I think here, I'm going to see if there's any changes to my neural network library.",
        "tokens": [
          51494,
          286,
          519,
          510,
          11,
          286,
          478,
          516,
          281,
          536,
          498,
          456,
          311,
          604,
          2962,
          281,
          452,
          18161,
          3209,
          6405,
          13,
          51758
        ]
      },
      {
        "avg_logprob": -0.38336114480461875,
        "compression_ratio": 1.4855072463768115,
        "end": 1034.8600000000001,
        "id": 266,
        "no_speech_prob": 0.08631887286901474,
        "seek": 103014,
        "start": 1030.14,
        "temperature": 0,
        "text": " I'm going to grab...",
        "tokens": [
          50364,
          286,
          478,
          516,
          281,
          4444,
          485,
          50600
        ]
      },
      {
        "avg_logprob": -0.38336114480461875,
        "compression_ratio": 1.4855072463768115,
        "end": 1038.98,
        "id": 267,
        "no_speech_prob": 0.08631887286901474,
        "seek": 103014,
        "start": 1034.8600000000001,
        "temperature": 0,
        "text": " Come on.",
        "tokens": [
          50600,
          2492,
          322,
          13,
          50806
        ]
      },
      {
        "avg_logprob": -0.38336114480461875,
        "compression_ratio": 1.4855072463768115,
        "end": 1039.98,
        "id": 268,
        "no_speech_prob": 0.08631887286901474,
        "seek": 103014,
        "start": 1038.98,
        "temperature": 0,
        "text": " What the...",
        "tokens": [
          50806,
          708,
          264,
          485,
          50856
        ]
      },
      {
        "avg_logprob": -0.38336114480461875,
        "compression_ratio": 1.4855072463768115,
        "end": 1040.98,
        "id": 269,
        "no_speech_prob": 0.08631887286901474,
        "seek": 103014,
        "start": 1039.98,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          50856,
          1033,
          13,
          50906
        ]
      },
      {
        "avg_logprob": -0.38336114480461875,
        "compression_ratio": 1.4855072463768115,
        "end": 1045.66,
        "id": 270,
        "no_speech_prob": 0.08631887286901474,
        "seek": 103014,
        "start": 1040.98,
        "temperature": 0,
        "text": " I'm going to go grab matrix.js and neural network.js.",
        "tokens": [
          50906,
          286,
          478,
          516,
          281,
          352,
          4444,
          8141,
          13,
          25530,
          293,
          18161,
          3209,
          13,
          25530,
          13,
          51140
        ]
      },
      {
        "avg_logprob": -0.38336114480461875,
        "compression_ratio": 1.4855072463768115,
        "end": 1047.98,
        "id": 271,
        "no_speech_prob": 0.08631887286901474,
        "seek": 103014,
        "start": 1045.66,
        "temperature": 0,
        "text": " I'm going to put those in here.",
        "tokens": [
          51140,
          286,
          478,
          516,
          281,
          829,
          729,
          294,
          510,
          13,
          51256
        ]
      },
      {
        "avg_logprob": -0.38336114480461875,
        "compression_ratio": 1.4855072463768115,
        "end": 1054.8200000000002,
        "id": 272,
        "no_speech_prob": 0.08631887286901474,
        "seek": 103014,
        "start": 1047.98,
        "temperature": 0,
        "text": " Let's put those in a little folder called lib, because I'm being silly.",
        "tokens": [
          51256,
          961,
          311,
          829,
          729,
          294,
          257,
          707,
          10820,
          1219,
          22854,
          11,
          570,
          286,
          478,
          885,
          11774,
          13,
          51598
        ]
      },
      {
        "avg_logprob": -0.2823541744335278,
        "compression_ratio": 1.6967509025270757,
        "end": 1057.82,
        "id": 273,
        "no_speech_prob": 0.21999172866344452,
        "seek": 105482,
        "start": 1054.82,
        "temperature": 0,
        "text": " And then now we need to get...",
        "tokens": [
          50364,
          400,
          550,
          586,
          321,
          643,
          281,
          483,
          485,
          50514
        ]
      },
      {
        "avg_logprob": -0.2823541744335278,
        "compression_ratio": 1.6967509025270757,
        "end": 1063.3799999999999,
        "id": 274,
        "no_speech_prob": 0.21999172866344452,
        "seek": 105482,
        "start": 1057.82,
        "temperature": 0,
        "text": " One of these days, I'm going to switch to Visual Studio Code and iTerm.",
        "tokens": [
          50514,
          1485,
          295,
          613,
          1708,
          11,
          286,
          478,
          516,
          281,
          3679,
          281,
          23187,
          13500,
          15549,
          293,
          30882,
          966,
          13,
          50792
        ]
      },
      {
        "avg_logprob": -0.2823541744335278,
        "compression_ratio": 1.6967509025270757,
        "end": 1065.06,
        "id": 275,
        "no_speech_prob": 0.21999172866344452,
        "seek": 105482,
        "start": 1063.3799999999999,
        "temperature": 0,
        "text": " But I'm way behind the times.",
        "tokens": [
          50792,
          583,
          286,
          478,
          636,
          2261,
          264,
          1413,
          13,
          50876
        ]
      },
      {
        "avg_logprob": -0.2823541744335278,
        "compression_ratio": 1.6967509025270757,
        "end": 1068.8999999999999,
        "id": 276,
        "no_speech_prob": 0.21999172866344452,
        "seek": 105482,
        "start": 1065.06,
        "temperature": 0,
        "text": " I'm waiting until there's the thing that people are using that's not iTerm, then I can switch",
        "tokens": [
          50876,
          286,
          478,
          3806,
          1826,
          456,
          311,
          264,
          551,
          300,
          561,
          366,
          1228,
          300,
          311,
          406,
          30882,
          966,
          11,
          550,
          286,
          393,
          3679,
          51068
        ]
      },
      {
        "avg_logprob": -0.2823541744335278,
        "compression_ratio": 1.6967509025270757,
        "end": 1069.8999999999999,
        "id": 277,
        "no_speech_prob": 0.21999172866344452,
        "seek": 105482,
        "start": 1068.8999999999999,
        "temperature": 0,
        "text": " to iTerm.",
        "tokens": [
          51068,
          281,
          30882,
          966,
          13,
          51118
        ]
      },
      {
        "avg_logprob": -0.2823541744335278,
        "compression_ratio": 1.6967509025270757,
        "end": 1071.26,
        "id": 278,
        "no_speech_prob": 0.21999172866344452,
        "seek": 105482,
        "start": 1069.8999999999999,
        "temperature": 0,
        "text": " That's how it works with me.",
        "tokens": [
          51118,
          663,
          311,
          577,
          309,
          1985,
          365,
          385,
          13,
          51186
        ]
      },
      {
        "avg_logprob": -0.2823541744335278,
        "compression_ratio": 1.6967509025270757,
        "end": 1072.26,
        "id": 279,
        "no_speech_prob": 0.21999172866344452,
        "seek": 105482,
        "start": 1071.26,
        "temperature": 0,
        "text": " Oh, look.",
        "tokens": [
          51186,
          876,
          11,
          574,
          13,
          51236
        ]
      },
      {
        "avg_logprob": -0.2823541744335278,
        "compression_ratio": 1.6967509025270757,
        "end": 1073.62,
        "id": 280,
        "no_speech_prob": 0.21999172866344452,
        "seek": 105482,
        "start": 1072.26,
        "temperature": 0,
        "text": " And this is Jabril's.",
        "tokens": [
          51236,
          400,
          341,
          307,
          40319,
          24216,
          311,
          13,
          51304
        ]
      },
      {
        "avg_logprob": -0.2823541744335278,
        "compression_ratio": 1.6967509025270757,
        "end": 1074.62,
        "id": 281,
        "no_speech_prob": 0.21999172866344452,
        "seek": 105482,
        "start": 1073.62,
        "temperature": 0,
        "text": " Here's his code.",
        "tokens": [
          51304,
          1692,
          311,
          702,
          3089,
          13,
          51354
        ]
      },
      {
        "avg_logprob": -0.2823541744335278,
        "compression_ratio": 1.6967509025270757,
        "end": 1076.26,
        "id": 282,
        "no_speech_prob": 0.21999172866344452,
        "seek": 105482,
        "start": 1074.62,
        "temperature": 0,
        "text": " It's the last thing that was open on this computer.",
        "tokens": [
          51354,
          467,
          311,
          264,
          1036,
          551,
          300,
          390,
          1269,
          322,
          341,
          3820,
          13,
          51436
        ]
      },
      {
        "avg_logprob": -0.2823541744335278,
        "compression_ratio": 1.6967509025270757,
        "end": 1082.3799999999999,
        "id": 283,
        "no_speech_prob": 0.21999172866344452,
        "seek": 105482,
        "start": 1076.26,
        "temperature": 0,
        "text": " So maybe that's good to have that available, because I can reference it.",
        "tokens": [
          51436,
          407,
          1310,
          300,
          311,
          665,
          281,
          362,
          300,
          2435,
          11,
          570,
          286,
          393,
          6408,
          309,
          13,
          51742
        ]
      },
      {
        "avg_logprob": -0.2823541744335278,
        "compression_ratio": 1.6967509025270757,
        "end": 1083.3799999999999,
        "id": 284,
        "no_speech_prob": 0.21999172866344452,
        "seek": 105482,
        "start": 1082.3799999999999,
        "temperature": 0,
        "text": " Where is that?",
        "tokens": [
          51742,
          2305,
          307,
          300,
          30,
          51792
        ]
      },
      {
        "avg_logprob": -0.2823541744335278,
        "compression_ratio": 1.6967509025270757,
        "end": 1084.3799999999999,
        "id": 285,
        "no_speech_prob": 0.21999172866344452,
        "seek": 105482,
        "start": 1083.3799999999999,
        "temperature": 0,
        "text": " Where was that?",
        "tokens": [
          51792,
          2305,
          390,
          300,
          30,
          51842
        ]
      },
      {
        "avg_logprob": -0.37852400962752525,
        "compression_ratio": 1.4745762711864407,
        "end": 1085.94,
        "id": 286,
        "no_speech_prob": 0.7954553961753845,
        "seek": 108438,
        "start": 1084.94,
        "temperature": 0,
        "text": " I'm going to open this up also.",
        "tokens": [
          50392,
          286,
          478,
          516,
          281,
          1269,
          341,
          493,
          611,
          13,
          50442
        ]
      },
      {
        "avg_logprob": -0.37852400962752525,
        "compression_ratio": 1.4745762711864407,
        "end": 1093.3400000000001,
        "id": 287,
        "no_speech_prob": 0.7954553961753845,
        "seek": 108438,
        "start": 1085.94,
        "temperature": 0,
        "text": " It's going to be sad when, by the time I get this set up to ready to start coding, the",
        "tokens": [
          50442,
          467,
          311,
          516,
          281,
          312,
          4227,
          562,
          11,
          538,
          264,
          565,
          286,
          483,
          341,
          992,
          493,
          281,
          1919,
          281,
          722,
          17720,
          11,
          264,
          50812
        ]
      },
      {
        "avg_logprob": -0.37852400962752525,
        "compression_ratio": 1.4745762711864407,
        "end": 1094.3400000000001,
        "id": 288,
        "no_speech_prob": 0.7954553961753845,
        "seek": 108438,
        "start": 1093.3400000000001,
        "temperature": 0,
        "text": " E key doesn't...",
        "tokens": [
          50812,
          462,
          2141,
          1177,
          380,
          485,
          50862
        ]
      },
      {
        "avg_logprob": -0.37852400962752525,
        "compression_ratio": 1.4745762711864407,
        "end": 1096.94,
        "id": 289,
        "no_speech_prob": 0.7954553961753845,
        "seek": 108438,
        "start": 1094.3400000000001,
        "temperature": 0,
        "text": " I need a password with no E key.",
        "tokens": [
          50862,
          286,
          643,
          257,
          11524,
          365,
          572,
          462,
          2141,
          13,
          50992
        ]
      },
      {
        "avg_logprob": -0.37852400962752525,
        "compression_ratio": 1.4745762711864407,
        "end": 1097.94,
        "id": 290,
        "no_speech_prob": 0.7954553961753845,
        "seek": 108438,
        "start": 1096.94,
        "temperature": 0,
        "text": " That...",
        "tokens": [
          50992,
          663,
          485,
          51042
        ]
      },
      {
        "avg_logprob": -0.37852400962752525,
        "compression_ratio": 1.4745762711864407,
        "end": 1098.94,
        "id": 291,
        "no_speech_prob": 0.7954553961753845,
        "seek": 108438,
        "start": 1097.94,
        "temperature": 0,
        "text": " Yeah.",
        "tokens": [
          51042,
          865,
          13,
          51092
        ]
      },
      {
        "avg_logprob": -0.37852400962752525,
        "compression_ratio": 1.4745762711864407,
        "end": 1099.94,
        "id": 292,
        "no_speech_prob": 0.7954553961753845,
        "seek": 108438,
        "start": 1098.94,
        "temperature": 0,
        "text": " That...",
        "tokens": [
          51092,
          663,
          485,
          51142
        ]
      },
      {
        "avg_logprob": -0.37852400962752525,
        "compression_ratio": 1.4745762711864407,
        "end": 1100.94,
        "id": 293,
        "no_speech_prob": 0.7954553961753845,
        "seek": 108438,
        "start": 1099.94,
        "temperature": 0,
        "text": " There we go.",
        "tokens": [
          51142,
          821,
          321,
          352,
          13,
          51192
        ]
      },
      {
        "avg_logprob": -0.37852400962752525,
        "compression_ratio": 1.4745762711864407,
        "end": 1101.94,
        "id": 294,
        "no_speech_prob": 0.7954553961753845,
        "seek": 108438,
        "start": 1100.94,
        "temperature": 0,
        "text": " Thank you.",
        "tokens": [
          51192,
          1044,
          291,
          13,
          51242
        ]
      },
      {
        "avg_logprob": -0.37852400962752525,
        "compression_ratio": 1.4745762711864407,
        "end": 1102.94,
        "id": 295,
        "no_speech_prob": 0.7954553961753845,
        "seek": 108438,
        "start": 1101.94,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          51242,
          1033,
          13,
          51292
        ]
      },
      {
        "avg_logprob": -0.37852400962752525,
        "compression_ratio": 1.4745762711864407,
        "end": 1103.94,
        "id": 296,
        "no_speech_prob": 0.7954553961753845,
        "seek": 108438,
        "start": 1102.94,
        "temperature": 0,
        "text": " All right.",
        "tokens": [
          51292,
          1057,
          558,
          13,
          51342
        ]
      },
      {
        "avg_logprob": -0.37852400962752525,
        "compression_ratio": 1.4745762711864407,
        "end": 1111.9,
        "id": 297,
        "no_speech_prob": 0.7954553961753845,
        "seek": 108438,
        "start": 1103.94,
        "temperature": 0,
        "text": " So now, what am I doing here?",
        "tokens": [
          51342,
          407,
          586,
          11,
          437,
          669,
          286,
          884,
          510,
          30,
          51740
        ]
      },
      {
        "avg_logprob": -0.33602244583601804,
        "compression_ratio": 1.4029850746268657,
        "end": 1115.0600000000002,
        "id": 298,
        "no_speech_prob": 0.16024254262447357,
        "seek": 111190,
        "start": 1111.9,
        "temperature": 0,
        "text": " Now I need the Atom editor.",
        "tokens": [
          50364,
          823,
          286,
          643,
          264,
          1711,
          298,
          9839,
          13,
          50522
        ]
      },
      {
        "avg_logprob": -0.33602244583601804,
        "compression_ratio": 1.4029850746268657,
        "end": 1117.94,
        "id": 299,
        "no_speech_prob": 0.16024254262447357,
        "seek": 111190,
        "start": 1115.0600000000002,
        "temperature": 0,
        "text": " I want to open...",
        "tokens": [
          50522,
          286,
          528,
          281,
          1269,
          485,
          50666
        ]
      },
      {
        "avg_logprob": -0.33602244583601804,
        "compression_ratio": 1.4029850746268657,
        "end": 1122.3400000000001,
        "id": 300,
        "no_speech_prob": 0.16024254262447357,
        "seek": 111190,
        "start": 1117.94,
        "temperature": 0,
        "text": " Why do computers never work?",
        "tokens": [
          50666,
          1545,
          360,
          10807,
          1128,
          589,
          30,
          50886
        ]
      },
      {
        "avg_logprob": -0.33602244583601804,
        "compression_ratio": 1.4029850746268657,
        "end": 1123.3400000000001,
        "id": 301,
        "no_speech_prob": 0.16024254262447357,
        "seek": 111190,
        "start": 1122.3400000000001,
        "temperature": 0,
        "text": " Huh?",
        "tokens": [
          50886,
          8063,
          30,
          50936
        ]
      },
      {
        "avg_logprob": -0.33602244583601804,
        "compression_ratio": 1.4029850746268657,
        "end": 1124.3400000000001,
        "id": 302,
        "no_speech_prob": 0.16024254262447357,
        "seek": 111190,
        "start": 1123.3400000000001,
        "temperature": 0,
        "text": " Someone tell me that.",
        "tokens": [
          50936,
          8734,
          980,
          385,
          300,
          13,
          50986
        ]
      },
      {
        "avg_logprob": -0.33602244583601804,
        "compression_ratio": 1.4029850746268657,
        "end": 1126.22,
        "id": 303,
        "no_speech_prob": 0.16024254262447357,
        "seek": 111190,
        "start": 1124.3400000000001,
        "temperature": 0,
        "text": " Why do they not work the way they're supposed to?",
        "tokens": [
          50986,
          1545,
          360,
          436,
          406,
          589,
          264,
          636,
          436,
          434,
          3442,
          281,
          30,
          51080
        ]
      },
      {
        "avg_logprob": -0.33602244583601804,
        "compression_ratio": 1.4029850746268657,
        "end": 1127.94,
        "id": 304,
        "no_speech_prob": 0.16024254262447357,
        "seek": 111190,
        "start": 1126.22,
        "temperature": 0,
        "text": " Come on, Atom.",
        "tokens": [
          51080,
          2492,
          322,
          11,
          1711,
          298,
          13,
          51166
        ]
      },
      {
        "avg_logprob": -0.33602244583601804,
        "compression_ratio": 1.4029850746268657,
        "end": 1128.94,
        "id": 305,
        "no_speech_prob": 0.16024254262447357,
        "seek": 111190,
        "start": 1127.94,
        "temperature": 0,
        "text": " There you are.",
        "tokens": [
          51166,
          821,
          291,
          366,
          13,
          51216
        ]
      },
      {
        "avg_logprob": -0.33602244583601804,
        "compression_ratio": 1.4029850746268657,
        "end": 1132.3400000000001,
        "id": 306,
        "no_speech_prob": 0.16024254262447357,
        "seek": 111190,
        "start": 1128.94,
        "temperature": 0,
        "text": " Let's open the color predictor code, which is nothing right now.",
        "tokens": [
          51216,
          961,
          311,
          1269,
          264,
          2017,
          6069,
          284,
          3089,
          11,
          597,
          307,
          1825,
          558,
          586,
          13,
          51386
        ]
      },
      {
        "avg_logprob": -0.33602244583601804,
        "compression_ratio": 1.4029850746268657,
        "end": 1137.46,
        "id": 307,
        "no_speech_prob": 0.16024254262447357,
        "seek": 111190,
        "start": 1132.3400000000001,
        "temperature": 0,
        "text": " A blank sketch.js file.",
        "tokens": [
          51386,
          316,
          8247,
          12325,
          13,
          25530,
          3991,
          13,
          51642
        ]
      },
      {
        "avg_logprob": -0.33602244583601804,
        "compression_ratio": 1.4029850746268657,
        "end": 1138.46,
        "id": 308,
        "no_speech_prob": 0.16024254262447357,
        "seek": 111190,
        "start": 1137.46,
        "temperature": 0,
        "text": " Index HTML.",
        "tokens": [
          51642,
          33552,
          17995,
          13,
          51692
        ]
      },
      {
        "avg_logprob": -0.29779894211713004,
        "compression_ratio": 1.3241379310344827,
        "end": 1147.06,
        "id": 309,
        "no_speech_prob": 0.29090964794158936,
        "seek": 113846,
        "start": 1138.46,
        "temperature": 0,
        "text": " I want to link to the P5 CDN, because I feel like that's just going to be better.",
        "tokens": [
          50364,
          286,
          528,
          281,
          2113,
          281,
          264,
          430,
          20,
          6743,
          45,
          11,
          570,
          286,
          841,
          411,
          300,
          311,
          445,
          516,
          281,
          312,
          1101,
          13,
          50794
        ]
      },
      {
        "avg_logprob": -0.29779894211713004,
        "compression_ratio": 1.3241379310344827,
        "end": 1150.06,
        "id": 310,
        "no_speech_prob": 0.29090964794158936,
        "seek": 113846,
        "start": 1147.06,
        "temperature": 0,
        "text": " So let me do that here.",
        "tokens": [
          50794,
          407,
          718,
          385,
          360,
          300,
          510,
          13,
          50944
        ]
      },
      {
        "avg_logprob": -0.29779894211713004,
        "compression_ratio": 1.3241379310344827,
        "end": 1156.74,
        "id": 311,
        "no_speech_prob": 0.29090964794158936,
        "seek": 113846,
        "start": 1150.06,
        "temperature": 0,
        "text": " And I'll put that here.",
        "tokens": [
          50944,
          400,
          286,
          603,
          829,
          300,
          510,
          13,
          51278
        ]
      },
      {
        "avg_logprob": -0.29779894211713004,
        "compression_ratio": 1.3241379310344827,
        "end": 1158.74,
        "id": 312,
        "no_speech_prob": 0.29090964794158936,
        "seek": 113846,
        "start": 1156.74,
        "temperature": 0,
        "text": " And I don't need sound.",
        "tokens": [
          51278,
          400,
          286,
          500,
          380,
          643,
          1626,
          13,
          51378
        ]
      },
      {
        "avg_logprob": -0.29779894211713004,
        "compression_ratio": 1.3241379310344827,
        "end": 1166.8600000000001,
        "id": 313,
        "no_speech_prob": 0.29090964794158936,
        "seek": 113846,
        "start": 1158.74,
        "temperature": 0,
        "text": " I probably do need DOM.",
        "tokens": [
          51378,
          286,
          1391,
          360,
          643,
          35727,
          13,
          51784
        ]
      },
      {
        "avg_logprob": -0.29779894211713004,
        "compression_ratio": 1.3241379310344827,
        "end": 1167.8600000000001,
        "id": 314,
        "no_speech_prob": 0.29090964794158936,
        "seek": 113846,
        "start": 1166.8600000000001,
        "temperature": 0,
        "text": " You know what?",
        "tokens": [
          51784,
          509,
          458,
          437,
          30,
          51834
        ]
      },
      {
        "avg_logprob": -0.30406680251612805,
        "compression_ratio": 1.4553990610328638,
        "end": 1174.86,
        "id": 315,
        "no_speech_prob": 0.7851423025131226,
        "seek": 116786,
        "start": 1168.26,
        "temperature": 0,
        "text": " Also, I should just use the minified, because I'm not going to be messing with the P5 library",
        "tokens": [
          50384,
          2743,
          11,
          286,
          820,
          445,
          764,
          264,
          923,
          2587,
          11,
          570,
          286,
          478,
          406,
          516,
          281,
          312,
          23258,
          365,
          264,
          430,
          20,
          6405,
          50714
        ]
      },
      {
        "avg_logprob": -0.30406680251612805,
        "compression_ratio": 1.4553990610328638,
        "end": 1175.86,
        "id": 316,
        "no_speech_prob": 0.7851423025131226,
        "seek": 116786,
        "start": 1174.86,
        "temperature": 0,
        "text": " itself.",
        "tokens": [
          50714,
          2564,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.30406680251612805,
        "compression_ratio": 1.4553990610328638,
        "end": 1177.86,
        "id": 317,
        "no_speech_prob": 0.7851423025131226,
        "seek": 116786,
        "start": 1175.86,
        "temperature": 0,
        "text": " So let me do this, actually.",
        "tokens": [
          50764,
          407,
          718,
          385,
          360,
          341,
          11,
          767,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.30406680251612805,
        "compression_ratio": 1.4553990610328638,
        "end": 1183.58,
        "id": 318,
        "no_speech_prob": 0.7851423025131226,
        "seek": 116786,
        "start": 1177.86,
        "temperature": 0,
        "text": " And let me link to those.",
        "tokens": [
          50864,
          400,
          718,
          385,
          2113,
          281,
          729,
          13,
          51150
        ]
      },
      {
        "avg_logprob": -0.30406680251612805,
        "compression_ratio": 1.4553990610328638,
        "end": 1185.9799999999998,
        "id": 319,
        "no_speech_prob": 0.7851423025131226,
        "seek": 116786,
        "start": 1183.58,
        "temperature": 0,
        "text": " Get rid of this extra stuff.",
        "tokens": [
          51150,
          3240,
          3973,
          295,
          341,
          2857,
          1507,
          13,
          51270
        ]
      },
      {
        "avg_logprob": -0.30406680251612805,
        "compression_ratio": 1.4553990610328638,
        "end": 1192.06,
        "id": 320,
        "no_speech_prob": 0.7851423025131226,
        "seek": 116786,
        "start": 1185.9799999999998,
        "temperature": 0,
        "text": " One of these days, I will change my template instead of just redoing it every time.",
        "tokens": [
          51270,
          1485,
          295,
          613,
          1708,
          11,
          286,
          486,
          1319,
          452,
          12379,
          2602,
          295,
          445,
          29956,
          278,
          309,
          633,
          565,
          13,
          51574
        ]
      },
      {
        "avg_logprob": -0.30406680251612805,
        "compression_ratio": 1.4553990610328638,
        "end": 1193.06,
        "id": 321,
        "no_speech_prob": 0.7851423025131226,
        "seek": 116786,
        "start": 1192.06,
        "temperature": 0,
        "text": " Neural network.js.",
        "tokens": [
          51574,
          1734,
          1807,
          3209,
          13,
          25530,
          13,
          51624
        ]
      },
      {
        "avg_logprob": -0.30406680251612805,
        "compression_ratio": 1.4553990610328638,
        "end": 1194.06,
        "id": 322,
        "no_speech_prob": 0.7851423025131226,
        "seek": 116786,
        "start": 1193.06,
        "temperature": 0,
        "text": " Matrix.js.",
        "tokens": [
          51624,
          36274,
          13,
          25530,
          13,
          51674
        ]
      },
      {
        "avg_logprob": -0.30406680251612805,
        "compression_ratio": 1.4553990610328638,
        "end": 1196.3799999999999,
        "id": 323,
        "no_speech_prob": 0.7851423025131226,
        "seek": 116786,
        "start": 1194.06,
        "temperature": 0,
        "text": " All right.",
        "tokens": [
          51674,
          1057,
          558,
          13,
          51790
        ]
      },
      {
        "avg_logprob": -0.3153362274169922,
        "compression_ratio": 1.3197278911564625,
        "end": 1200.38,
        "id": 324,
        "no_speech_prob": 0.037323564291000366,
        "seek": 119638,
        "start": 1196.38,
        "temperature": 0,
        "text": " I think we are just about ready to go.",
        "tokens": [
          50364,
          286,
          519,
          321,
          366,
          445,
          466,
          1919,
          281,
          352,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.3153362274169922,
        "compression_ratio": 1.3197278911564625,
        "end": 1202.2600000000002,
        "id": 325,
        "no_speech_prob": 0.037323564291000366,
        "seek": 119638,
        "start": 1200.38,
        "temperature": 0,
        "text": " Here I am.",
        "tokens": [
          50564,
          1692,
          286,
          669,
          13,
          50658
        ]
      },
      {
        "avg_logprob": -0.3153362274169922,
        "compression_ratio": 1.3197278911564625,
        "end": 1204.9,
        "id": 326,
        "no_speech_prob": 0.037323564291000366,
        "seek": 119638,
        "start": 1202.2600000000002,
        "temperature": 0,
        "text": " Let's run a little local web server.",
        "tokens": [
          50658,
          961,
          311,
          1190,
          257,
          707,
          2654,
          3670,
          7154,
          13,
          50790
        ]
      },
      {
        "avg_logprob": -0.3153362274169922,
        "compression_ratio": 1.3197278911564625,
        "end": 1213.3000000000002,
        "id": 327,
        "no_speech_prob": 0.037323564291000366,
        "seek": 119638,
        "start": 1204.9,
        "temperature": 0,
        "text": " I will check the chat in a second.",
        "tokens": [
          50790,
          286,
          486,
          1520,
          264,
          5081,
          294,
          257,
          1150,
          13,
          51210
        ]
      },
      {
        "avg_logprob": -0.3153362274169922,
        "compression_ratio": 1.3197278911564625,
        "end": 1216.9,
        "id": 328,
        "no_speech_prob": 0.037323564291000366,
        "seek": 119638,
        "start": 1213.3000000000002,
        "temperature": 0,
        "text": " Failed to load, because why?",
        "tokens": [
          51210,
          479,
          24731,
          281,
          3677,
          11,
          570,
          983,
          30,
          51390
        ]
      },
      {
        "avg_logprob": -0.3153362274169922,
        "compression_ratio": 1.3197278911564625,
        "end": 1220.38,
        "id": 329,
        "no_speech_prob": 0.037323564291000366,
        "seek": 119638,
        "start": 1216.9,
        "temperature": 0,
        "text": " Because I put those in a folder called lib.",
        "tokens": [
          51390,
          1436,
          286,
          829,
          729,
          294,
          257,
          10820,
          1219,
          22854,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.3775888760884603,
        "compression_ratio": 1.34375,
        "end": 1225.7,
        "id": 330,
        "no_speech_prob": 0.04958773031830788,
        "seek": 122038,
        "start": 1220.38,
        "temperature": 0,
        "text": " I think we're good.",
        "tokens": [
          50364,
          286,
          519,
          321,
          434,
          665,
          13,
          50630
        ]
      },
      {
        "avg_logprob": -0.3775888760884603,
        "compression_ratio": 1.34375,
        "end": 1229.0600000000002,
        "id": 331,
        "no_speech_prob": 0.04958773031830788,
        "seek": 122038,
        "start": 1225.7,
        "temperature": 0,
        "text": " Yep.",
        "tokens": [
          50630,
          7010,
          13,
          50798
        ]
      },
      {
        "avg_logprob": -0.3775888760884603,
        "compression_ratio": 1.34375,
        "end": 1231.14,
        "id": 332,
        "no_speech_prob": 0.04958773031830788,
        "seek": 122038,
        "start": 1229.0600000000002,
        "temperature": 0,
        "text": " Let's make this...",
        "tokens": [
          50798,
          961,
          311,
          652,
          341,
          485,
          50902
        ]
      },
      {
        "avg_logprob": -0.3775888760884603,
        "compression_ratio": 1.34375,
        "end": 1236.0200000000002,
        "id": 333,
        "no_speech_prob": 0.04958773031830788,
        "seek": 122038,
        "start": 1231.14,
        "temperature": 0,
        "text": " Let's think about the amount of space I want here.",
        "tokens": [
          50902,
          961,
          311,
          519,
          466,
          264,
          2372,
          295,
          1901,
          286,
          528,
          510,
          13,
          51146
        ]
      },
      {
        "avg_logprob": -0.3775888760884603,
        "compression_ratio": 1.34375,
        "end": 1237.5800000000002,
        "id": 334,
        "no_speech_prob": 0.04958773031830788,
        "seek": 122038,
        "start": 1236.0200000000002,
        "temperature": 0,
        "text": " Make this a little bigger.",
        "tokens": [
          51146,
          4387,
          341,
          257,
          707,
          3801,
          13,
          51224
        ]
      },
      {
        "avg_logprob": -0.3775888760884603,
        "compression_ratio": 1.34375,
        "end": 1238.5800000000002,
        "id": 335,
        "no_speech_prob": 0.04958773031830788,
        "seek": 122038,
        "start": 1237.5800000000002,
        "temperature": 0,
        "text": " All right.",
        "tokens": [
          51224,
          1057,
          558,
          13,
          51274
        ]
      },
      {
        "avg_logprob": -0.3775888760884603,
        "compression_ratio": 1.34375,
        "end": 1247.0200000000002,
        "id": 336,
        "no_speech_prob": 0.04958773031830788,
        "seek": 122038,
        "start": 1238.5800000000002,
        "temperature": 0,
        "text": " I think I am ready now to start coding.",
        "tokens": [
          51274,
          286,
          519,
          286,
          669,
          1919,
          586,
          281,
          722,
          17720,
          13,
          51696
        ]
      },
      {
        "avg_logprob": -0.385328369140625,
        "compression_ratio": 1.441988950276243,
        "end": 1251.06,
        "id": 337,
        "no_speech_prob": 0.33109211921691895,
        "seek": 124702,
        "start": 1247.02,
        "temperature": 0,
        "text": " There's some discussion in the chat going on about numbers.",
        "tokens": [
          50364,
          821,
          311,
          512,
          5017,
          294,
          264,
          5081,
          516,
          322,
          466,
          3547,
          13,
          50566
        ]
      },
      {
        "avg_logprob": -0.385328369140625,
        "compression_ratio": 1.441988950276243,
        "end": 1258.06,
        "id": 338,
        "no_speech_prob": 0.33109211921691895,
        "seek": 124702,
        "start": 1251.06,
        "temperature": 0,
        "text": " I just want this to go down a tiny bit, maybe.",
        "tokens": [
          50566,
          286,
          445,
          528,
          341,
          281,
          352,
          760,
          257,
          5870,
          857,
          11,
          1310,
          13,
          50916
        ]
      },
      {
        "avg_logprob": -0.385328369140625,
        "compression_ratio": 1.441988950276243,
        "end": 1259.06,
        "id": 339,
        "no_speech_prob": 0.33109211921691895,
        "seek": 124702,
        "start": 1258.06,
        "temperature": 0,
        "text": " Oh.",
        "tokens": [
          50916,
          876,
          13,
          50966
        ]
      },
      {
        "avg_logprob": -0.385328369140625,
        "compression_ratio": 1.441988950276243,
        "end": 1263.86,
        "id": 340,
        "no_speech_prob": 0.33109211921691895,
        "seek": 124702,
        "start": 1259.06,
        "temperature": 0,
        "text": " Camera went off.",
        "tokens": [
          50966,
          23734,
          1437,
          766,
          13,
          51206
        ]
      },
      {
        "avg_logprob": -0.385328369140625,
        "compression_ratio": 1.441988950276243,
        "end": 1270.5,
        "id": 341,
        "no_speech_prob": 0.33109211921691895,
        "seek": 124702,
        "start": 1263.86,
        "temperature": 0,
        "text": " Now I just realized something, which is that I'm going to use the whiteboard for this tutorial,",
        "tokens": [
          51206,
          823,
          286,
          445,
          5334,
          746,
          11,
          597,
          307,
          300,
          286,
          478,
          516,
          281,
          764,
          264,
          2418,
          3787,
          337,
          341,
          7073,
          11,
          51538
        ]
      },
      {
        "avg_logprob": -0.385328369140625,
        "compression_ratio": 1.441988950276243,
        "end": 1273.86,
        "id": 342,
        "no_speech_prob": 0.33109211921691895,
        "seek": 124702,
        "start": 1270.5,
        "temperature": 0,
        "text": " and I now have this whole thing here.",
        "tokens": [
          51538,
          293,
          286,
          586,
          362,
          341,
          1379,
          551,
          510,
          13,
          51706
        ]
      },
      {
        "avg_logprob": -0.3709495748792376,
        "compression_ratio": 1.4416666666666667,
        "end": 1279.4599999999998,
        "id": 343,
        "no_speech_prob": 0.18476173281669617,
        "seek": 127386,
        "start": 1273.86,
        "temperature": 0,
        "text": " I guess what I will do is screen...",
        "tokens": [
          50364,
          286,
          2041,
          437,
          286,
          486,
          360,
          307,
          2568,
          485,
          50644
        ]
      },
      {
        "avg_logprob": -0.3709495748792376,
        "compression_ratio": 1.4416666666666667,
        "end": 1280.8999999999999,
        "id": 344,
        "no_speech_prob": 0.18476173281669617,
        "seek": 127386,
        "start": 1279.4599999999998,
        "temperature": 0,
        "text": " Just screen cap this for me.",
        "tokens": [
          50644,
          1449,
          2568,
          1410,
          341,
          337,
          385,
          13,
          50716
        ]
      },
      {
        "avg_logprob": -0.3709495748792376,
        "compression_ratio": 1.4416666666666667,
        "end": 1281.9399999999998,
        "id": 345,
        "no_speech_prob": 0.18476173281669617,
        "seek": 127386,
        "start": 1280.8999999999999,
        "temperature": 0,
        "text": " We'll save it for later.",
        "tokens": [
          50716,
          492,
          603,
          3155,
          309,
          337,
          1780,
          13,
          50768
        ]
      },
      {
        "avg_logprob": -0.3709495748792376,
        "compression_ratio": 1.4416666666666667,
        "end": 1290.82,
        "id": 346,
        "no_speech_prob": 0.18476173281669617,
        "seek": 127386,
        "start": 1281.9399999999998,
        "temperature": 0,
        "text": " I guess I'm going to erase it.",
        "tokens": [
          50768,
          286,
          2041,
          286,
          478,
          516,
          281,
          23525,
          309,
          13,
          51212
        ]
      },
      {
        "avg_logprob": -0.3709495748792376,
        "compression_ratio": 1.4416666666666667,
        "end": 1297.5,
        "id": 347,
        "no_speech_prob": 0.18476173281669617,
        "seek": 127386,
        "start": 1290.82,
        "temperature": 0,
        "text": " So I'm going to remember this list for another time.",
        "tokens": [
          51212,
          407,
          286,
          478,
          516,
          281,
          1604,
          341,
          1329,
          337,
          1071,
          565,
          13,
          51546
        ]
      },
      {
        "avg_logprob": -0.454457646324521,
        "compression_ratio": 1.5030674846625767,
        "end": 1300.7,
        "id": 348,
        "no_speech_prob": 0.04272047430276871,
        "seek": 129750,
        "start": 1297.5,
        "temperature": 0,
        "text": " I'm going to remember that Suze...",
        "tokens": [
          50364,
          286,
          478,
          516,
          281,
          1604,
          300,
          2746,
          1381,
          485,
          50524
        ]
      },
      {
        "avg_logprob": -0.454457646324521,
        "compression_ratio": 1.5030674846625767,
        "end": 1312.34,
        "id": 349,
        "no_speech_prob": 0.04272047430276871,
        "seek": 129750,
        "start": 1300.7,
        "temperature": 0,
        "text": " Now I'm calling her by her name, because I'm afraid to say noopcat, noopcat, noopcat, incorrectly.",
        "tokens": [
          50524,
          823,
          286,
          478,
          5141,
          720,
          538,
          720,
          1315,
          11,
          570,
          286,
          478,
          4638,
          281,
          584,
          572,
          404,
          18035,
          11,
          572,
          404,
          18035,
          11,
          572,
          404,
          18035,
          11,
          42892,
          13,
          51106
        ]
      },
      {
        "avg_logprob": -0.454457646324521,
        "compression_ratio": 1.5030674846625767,
        "end": 1316.5,
        "id": 350,
        "no_speech_prob": 0.04272047430276871,
        "seek": 129750,
        "start": 1312.34,
        "temperature": 0,
        "text": " That's probably not noopcat.",
        "tokens": [
          51106,
          663,
          311,
          1391,
          406,
          572,
          404,
          18035,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.454457646324521,
        "compression_ratio": 1.5030674846625767,
        "end": 1321.26,
        "id": 351,
        "no_speech_prob": 0.04272047430276871,
        "seek": 129750,
        "start": 1316.5,
        "temperature": 0,
        "text": " You know, viewer meiamsome, I used to call meiamsum.",
        "tokens": [
          51314,
          509,
          458,
          11,
          16767,
          385,
          2918,
          82,
          423,
          11,
          286,
          1143,
          281,
          818,
          385,
          2918,
          82,
          449,
          13,
          51552
        ]
      },
      {
        "avg_logprob": -0.454457646324521,
        "compression_ratio": 1.5030674846625767,
        "end": 1322.26,
        "id": 352,
        "no_speech_prob": 0.04272047430276871,
        "seek": 129750,
        "start": 1321.26,
        "temperature": 0,
        "text": " That's what I thought it was.",
        "tokens": [
          51552,
          663,
          311,
          437,
          286,
          1194,
          309,
          390,
          13,
          51602
        ]
      },
      {
        "avg_logprob": -0.30315471600882615,
        "compression_ratio": 1.4124293785310735,
        "end": 1328.02,
        "id": 353,
        "no_speech_prob": 0.01854393631219864,
        "seek": 132226,
        "start": 1322.26,
        "temperature": 0,
        "text": " So this is a pattern I have of misinterpreting and mispronouncing things.",
        "tokens": [
          50364,
          407,
          341,
          307,
          257,
          5102,
          286,
          362,
          295,
          3346,
          5106,
          3712,
          783,
          293,
          3346,
          1424,
          266,
          1733,
          2175,
          721,
          13,
          50652
        ]
      },
      {
        "avg_logprob": -0.30315471600882615,
        "compression_ratio": 1.4124293785310735,
        "end": 1329.3799999999999,
        "id": 354,
        "no_speech_prob": 0.01854393631219864,
        "seek": 132226,
        "start": 1328.02,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          50652,
          1033,
          13,
          50720
        ]
      },
      {
        "avg_logprob": -0.30315471600882615,
        "compression_ratio": 1.4124293785310735,
        "end": 1332.22,
        "id": 355,
        "no_speech_prob": 0.01854393631219864,
        "seek": 132226,
        "start": 1329.3799999999999,
        "temperature": 0,
        "text": " We are just about ready to get started.",
        "tokens": [
          50720,
          492,
          366,
          445,
          466,
          1919,
          281,
          483,
          1409,
          13,
          50862
        ]
      },
      {
        "avg_logprob": -0.30315471600882615,
        "compression_ratio": 1.4124293785310735,
        "end": 1336.02,
        "id": 356,
        "no_speech_prob": 0.01854393631219864,
        "seek": 132226,
        "start": 1332.22,
        "temperature": 0,
        "text": " I am going to very briefly...",
        "tokens": [
          50862,
          286,
          669,
          516,
          281,
          588,
          10515,
          485,
          51052
        ]
      },
      {
        "avg_logprob": -0.30315471600882615,
        "compression_ratio": 1.4124293785310735,
        "end": 1339.18,
        "id": 357,
        "no_speech_prob": 0.01854393631219864,
        "seek": 132226,
        "start": 1336.02,
        "temperature": 0,
        "text": " Now I just need to pull up something.",
        "tokens": [
          51052,
          823,
          286,
          445,
          643,
          281,
          2235,
          493,
          746,
          13,
          51210
        ]
      },
      {
        "avg_logprob": -0.30315471600882615,
        "compression_ratio": 1.4124293785310735,
        "end": 1340.18,
        "id": 358,
        "no_speech_prob": 0.01854393631219864,
        "seek": 132226,
        "start": 1339.18,
        "temperature": 0,
        "text": " Maybe I'll pull up...",
        "tokens": [
          51210,
          2704,
          286,
          603,
          2235,
          493,
          485,
          51260
        ]
      },
      {
        "avg_logprob": -0.30315471600882615,
        "compression_ratio": 1.4124293785310735,
        "end": 1349.9,
        "id": 359,
        "no_speech_prob": 0.01854393631219864,
        "seek": 132226,
        "start": 1340.18,
        "temperature": 0,
        "text": " Let me pull up Jabril's YouTube channel.",
        "tokens": [
          51260,
          961,
          385,
          2235,
          493,
          40319,
          24216,
          311,
          3088,
          2269,
          13,
          51746
        ]
      },
      {
        "avg_logprob": -0.3253729719864695,
        "compression_ratio": 2.089171974522293,
        "end": 1354.42,
        "id": 360,
        "no_speech_prob": 0.6756138205528259,
        "seek": 134990,
        "start": 1349.9,
        "temperature": 0,
        "text": " That can be my background here.",
        "tokens": [
          50364,
          663,
          393,
          312,
          452,
          3678,
          510,
          13,
          50590
        ]
      },
      {
        "avg_logprob": -0.3253729719864695,
        "compression_ratio": 2.089171974522293,
        "end": 1359.22,
        "id": 361,
        "no_speech_prob": 0.6756138205528259,
        "seek": 134990,
        "start": 1354.42,
        "temperature": 0,
        "text": " To start.",
        "tokens": [
          50590,
          1407,
          722,
          13,
          50830
        ]
      },
      {
        "avg_logprob": -0.3253729719864695,
        "compression_ratio": 2.089171974522293,
        "end": 1360.22,
        "id": 362,
        "no_speech_prob": 0.6756138205528259,
        "seek": 134990,
        "start": 1359.22,
        "temperature": 0,
        "text": " It's noopcat.",
        "tokens": [
          50830,
          467,
          311,
          572,
          404,
          18035,
          13,
          50880
        ]
      },
      {
        "avg_logprob": -0.3253729719864695,
        "compression_ratio": 2.089171974522293,
        "end": 1361.22,
        "id": 363,
        "no_speech_prob": 0.6756138205528259,
        "seek": 134990,
        "start": 1360.22,
        "temperature": 0,
        "text": " Noopcat.",
        "tokens": [
          50880,
          883,
          404,
          18035,
          13,
          50930
        ]
      },
      {
        "avg_logprob": -0.3253729719864695,
        "compression_ratio": 2.089171974522293,
        "end": 1362.22,
        "id": 364,
        "no_speech_prob": 0.6756138205528259,
        "seek": 134990,
        "start": 1361.22,
        "temperature": 0,
        "text": " I don't know.",
        "tokens": [
          50930,
          286,
          500,
          380,
          458,
          13,
          50980
        ]
      },
      {
        "avg_logprob": -0.3253729719864695,
        "compression_ratio": 2.089171974522293,
        "end": 1363.22,
        "id": 365,
        "no_speech_prob": 0.6756138205528259,
        "seek": 134990,
        "start": 1362.22,
        "temperature": 0,
        "text": " Noobcat.",
        "tokens": [
          50980,
          883,
          996,
          18035,
          13,
          51030
        ]
      },
      {
        "avg_logprob": -0.3253729719864695,
        "compression_ratio": 2.089171974522293,
        "end": 1364.22,
        "id": 366,
        "no_speech_prob": 0.6756138205528259,
        "seek": 134990,
        "start": 1363.22,
        "temperature": 0,
        "text": " Anyway.",
        "tokens": [
          51030,
          5684,
          13,
          51080
        ]
      },
      {
        "avg_logprob": -0.3253729719864695,
        "compression_ratio": 2.089171974522293,
        "end": 1365.22,
        "id": 367,
        "no_speech_prob": 0.6756138205528259,
        "seek": 134990,
        "start": 1364.22,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          51080,
          1033,
          13,
          51130
        ]
      },
      {
        "avg_logprob": -0.3253729719864695,
        "compression_ratio": 2.089171974522293,
        "end": 1366.22,
        "id": 368,
        "no_speech_prob": 0.6756138205528259,
        "seek": 134990,
        "start": 1365.22,
        "temperature": 0,
        "text": " Thanks for all the suggestions.",
        "tokens": [
          51130,
          2561,
          337,
          439,
          264,
          13396,
          13,
          51180
        ]
      },
      {
        "avg_logprob": -0.3253729719864695,
        "compression_ratio": 2.089171974522293,
        "end": 1367.22,
        "id": 369,
        "no_speech_prob": 0.6756138205528259,
        "seek": 134990,
        "start": 1366.22,
        "temperature": 0,
        "text": " All right.",
        "tokens": [
          51180,
          1057,
          558,
          13,
          51230
        ]
      },
      {
        "avg_logprob": -0.3253729719864695,
        "compression_ratio": 2.089171974522293,
        "end": 1368.22,
        "id": 370,
        "no_speech_prob": 0.6756138205528259,
        "seek": 134990,
        "start": 1367.22,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          51230,
          1033,
          13,
          51280
        ]
      },
      {
        "avg_logprob": -0.3253729719864695,
        "compression_ratio": 2.089171974522293,
        "end": 1369.22,
        "id": 371,
        "no_speech_prob": 0.6756138205528259,
        "seek": 134990,
        "start": 1368.22,
        "temperature": 0,
        "text": " SuperSipMe writes, I'm so bored.",
        "tokens": [
          51280,
          4548,
          50,
          647,
          12671,
          13657,
          11,
          286,
          478,
          370,
          13521,
          13,
          51330
        ]
      },
      {
        "avg_logprob": -0.3253729719864695,
        "compression_ratio": 2.089171974522293,
        "end": 1370.22,
        "id": 372,
        "no_speech_prob": 0.6756138205528259,
        "seek": 134990,
        "start": 1369.22,
        "temperature": 0,
        "text": " I don't blame you.",
        "tokens": [
          51330,
          286,
          500,
          380,
          10127,
          291,
          13,
          51380
        ]
      },
      {
        "avg_logprob": -0.3253729719864695,
        "compression_ratio": 2.089171974522293,
        "end": 1371.22,
        "id": 373,
        "no_speech_prob": 0.6756138205528259,
        "seek": 134990,
        "start": 1370.22,
        "temperature": 0,
        "text": " I'm so bored.",
        "tokens": [
          51380,
          286,
          478,
          370,
          13521,
          13,
          51430
        ]
      },
      {
        "avg_logprob": -0.3253729719864695,
        "compression_ratio": 2.089171974522293,
        "end": 1372.22,
        "id": 374,
        "no_speech_prob": 0.6756138205528259,
        "seek": 134990,
        "start": 1371.22,
        "temperature": 0,
        "text": " I'm so bored.",
        "tokens": [
          51430,
          286,
          478,
          370,
          13521,
          13,
          51480
        ]
      },
      {
        "avg_logprob": -0.3253729719864695,
        "compression_ratio": 2.089171974522293,
        "end": 1373.22,
        "id": 375,
        "no_speech_prob": 0.6756138205528259,
        "seek": 134990,
        "start": 1372.22,
        "temperature": 0,
        "text": " I'm so bored.",
        "tokens": [
          51480,
          286,
          478,
          370,
          13521,
          13,
          51530
        ]
      },
      {
        "avg_logprob": -0.3253729719864695,
        "compression_ratio": 2.089171974522293,
        "end": 1374.22,
        "id": 376,
        "no_speech_prob": 0.6756138205528259,
        "seek": 134990,
        "start": 1373.22,
        "temperature": 0,
        "text": " I'm so bored.",
        "tokens": [
          51530,
          286,
          478,
          370,
          13521,
          13,
          51580
        ]
      },
      {
        "avg_logprob": -0.3253729719864695,
        "compression_ratio": 2.089171974522293,
        "end": 1375.22,
        "id": 377,
        "no_speech_prob": 0.6756138205528259,
        "seek": 134990,
        "start": 1374.22,
        "temperature": 0,
        "text": " I'm so bored.",
        "tokens": [
          51580,
          286,
          478,
          370,
          13521,
          13,
          51630
        ]
      },
      {
        "avg_logprob": -0.3253729719864695,
        "compression_ratio": 2.089171974522293,
        "end": 1376.22,
        "id": 378,
        "no_speech_prob": 0.6756138205528259,
        "seek": 134990,
        "start": 1375.22,
        "temperature": 0,
        "text": " I'm so bored.",
        "tokens": [
          51630,
          286,
          478,
          370,
          13521,
          13,
          51680
        ]
      },
      {
        "avg_logprob": -0.3253729719864695,
        "compression_ratio": 2.089171974522293,
        "end": 1377.22,
        "id": 379,
        "no_speech_prob": 0.6756138205528259,
        "seek": 134990,
        "start": 1376.22,
        "temperature": 0,
        "text": " I'm so bored.",
        "tokens": [
          51680,
          286,
          478,
          370,
          13521,
          13,
          51730
        ]
      },
      {
        "avg_logprob": -0.3253729719864695,
        "compression_ratio": 2.089171974522293,
        "end": 1378.22,
        "id": 380,
        "no_speech_prob": 0.6756138205528259,
        "seek": 134990,
        "start": 1377.22,
        "temperature": 0,
        "text": " I'm so bored.",
        "tokens": [
          51730,
          286,
          478,
          370,
          13521,
          13,
          51780
        ]
      },
      {
        "avg_logprob": -0.3253729719864695,
        "compression_ratio": 2.089171974522293,
        "end": 1379.22,
        "id": 381,
        "no_speech_prob": 0.6756138205528259,
        "seek": 134990,
        "start": 1378.22,
        "temperature": 0,
        "text": " I'm so bored.",
        "tokens": [
          51780,
          286,
          478,
          370,
          13521,
          13,
          51830
        ]
      },
      {
        "avg_logprob": -0.4237292105691475,
        "compression_ratio": 1.48,
        "end": 1382.8,
        "id": 382,
        "no_speech_prob": 0.05418745055794716,
        "seek": 137922,
        "start": 1379.26,
        "temperature": 0.4,
        "text": " It's only been, what?",
        "tokens": [
          50366,
          467,
          311,
          787,
          668,
          11,
          437,
          30,
          50543
        ]
      },
      {
        "avg_logprob": -0.4237292105691475,
        "compression_ratio": 1.48,
        "end": 1384.68,
        "id": 383,
        "no_speech_prob": 0.05418745055794716,
        "seek": 137922,
        "start": 1382.8,
        "temperature": 0.4,
        "text": " Like an hour and I haven't done anything yet?",
        "tokens": [
          50543,
          1743,
          364,
          1773,
          293,
          286,
          2378,
          380,
          1096,
          1340,
          1939,
          30,
          50637
        ]
      },
      {
        "avg_logprob": -0.4237292105691475,
        "compression_ratio": 1.48,
        "end": 1386.38,
        "id": 384,
        "no_speech_prob": 0.05418745055794716,
        "seek": 137922,
        "start": 1384.68,
        "temperature": 0.4,
        "text": " It's like 11.53 already?",
        "tokens": [
          50637,
          467,
          311,
          411,
          2975,
          13,
          19584,
          1217,
          30,
          50722
        ]
      },
      {
        "avg_logprob": -0.4237292105691475,
        "compression_ratio": 1.48,
        "end": 1387.42,
        "id": 385,
        "no_speech_prob": 0.05418745055794716,
        "seek": 137922,
        "start": 1386.38,
        "temperature": 0.4,
        "text": " All right.",
        "tokens": [
          50722,
          1057,
          558,
          13,
          50774
        ]
      },
      {
        "avg_logprob": -0.4237292105691475,
        "compression_ratio": 1.48,
        "end": 1388.42,
        "id": 386,
        "no_speech_prob": 0.05418745055794716,
        "seek": 137922,
        "start": 1387.42,
        "temperature": 0.4,
        "text": " That was exciting, all right?",
        "tokens": [
          50774,
          663,
          390,
          4670,
          11,
          439,
          558,
          30,
          50824
        ]
      },
      {
        "avg_logprob": -0.4237292105691475,
        "compression_ratio": 1.48,
        "end": 1389.42,
        "id": 387,
        "no_speech_prob": 0.05418745055794716,
        "seek": 137922,
        "start": 1388.42,
        "temperature": 0.4,
        "text": " You're no longer bored, right?",
        "tokens": [
          50824,
          509,
          434,
          572,
          2854,
          13521,
          11,
          558,
          30,
          50874
        ]
      },
      {
        "avg_logprob": -0.4237292105691475,
        "compression_ratio": 1.48,
        "end": 1392.38,
        "id": 388,
        "no_speech_prob": 0.05418745055794716,
        "seek": 137922,
        "start": 1389.42,
        "temperature": 0.4,
        "text": " That's the suspense of whether I will catch that or not.",
        "tokens": [
          50874,
          663,
          311,
          264,
          47803,
          295,
          1968,
          286,
          486,
          3745,
          300,
          420,
          406,
          13,
          51022
        ]
      },
      {
        "avg_logprob": -0.4237292105691475,
        "compression_ratio": 1.48,
        "end": 1393.7,
        "id": 389,
        "no_speech_prob": 0.05418745055794716,
        "seek": 137922,
        "start": 1392.38,
        "temperature": 0.4,
        "text": " Here we go.",
        "tokens": [
          51022,
          1692,
          321,
          352,
          13,
          51088
        ]
      },
      {
        "avg_logprob": -0.4237292105691475,
        "compression_ratio": 1.48,
        "end": 1396.66,
        "id": 390,
        "no_speech_prob": 0.05418745055794716,
        "seek": 137922,
        "start": 1393.7,
        "temperature": 0.4,
        "text": " We are going to make a color predictor.",
        "tokens": [
          51088,
          492,
          366,
          516,
          281,
          652,
          257,
          2017,
          6069,
          284,
          13,
          51236
        ]
      },
      {
        "avg_logprob": -0.4237292105691475,
        "compression_ratio": 1.48,
        "end": 1403.24,
        "id": 391,
        "no_speech_prob": 0.05418745055794716,
        "seek": 137922,
        "start": 1396.66,
        "temperature": 0.4,
        "text": " Sip of the tea.",
        "tokens": [
          51236,
          318,
          647,
          295,
          264,
          5817,
          13,
          51565
        ]
      },
      {
        "avg_logprob": -0.4237292105691475,
        "compression_ratio": 1.48,
        "end": 1406.66,
        "id": 392,
        "no_speech_prob": 0.05418745055794716,
        "seek": 137922,
        "start": 1403.24,
        "temperature": 0.4,
        "text": " Tea goes to dangerous spot.",
        "tokens": [
          51565,
          26614,
          1709,
          281,
          5795,
          4008,
          13,
          51736
        ]
      },
      {
        "avg_logprob": -0.4237292105691475,
        "compression_ratio": 1.48,
        "end": 1408.22,
        "id": 393,
        "no_speech_prob": 0.05418745055794716,
        "seek": 137922,
        "start": 1406.66,
        "temperature": 0.4,
        "text": " And here we go.",
        "tokens": [
          51736,
          400,
          510,
          321,
          352,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.37310757683318796,
        "compression_ratio": 1.467005076142132,
        "end": 1409.22,
        "id": 394,
        "no_speech_prob": 0.06187256798148155,
        "seek": 140822,
        "start": 1408.22,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          50364,
          1033,
          13,
          50414
        ]
      },
      {
        "avg_logprob": -0.37310757683318796,
        "compression_ratio": 1.467005076142132,
        "end": 1412.22,
        "id": 395,
        "no_speech_prob": 0.06187256798148155,
        "seek": 140822,
        "start": 1409.22,
        "temperature": 0,
        "text": " There's like a thing.",
        "tokens": [
          50414,
          821,
          311,
          411,
          257,
          551,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.37310757683318796,
        "compression_ratio": 1.467005076142132,
        "end": 1416.22,
        "id": 396,
        "no_speech_prob": 0.06187256798148155,
        "seek": 140822,
        "start": 1412.22,
        "temperature": 0,
        "text": " Oh, it's actually just on my screen.",
        "tokens": [
          50564,
          876,
          11,
          309,
          311,
          767,
          445,
          322,
          452,
          2568,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.37310757683318796,
        "compression_ratio": 1.467005076142132,
        "end": 1419.26,
        "id": 397,
        "no_speech_prob": 0.06187256798148155,
        "seek": 140822,
        "start": 1416.22,
        "temperature": 0,
        "text": " That's what that is.",
        "tokens": [
          50764,
          663,
          311,
          437,
          300,
          307,
          13,
          50916
        ]
      },
      {
        "avg_logprob": -0.37310757683318796,
        "compression_ratio": 1.467005076142132,
        "end": 1423.66,
        "id": 398,
        "no_speech_prob": 0.06187256798148155,
        "seek": 140822,
        "start": 1419.26,
        "temperature": 0,
        "text": " By the way, I keep thinking it's time for me to get rid of this snowy background, but",
        "tokens": [
          50916,
          3146,
          264,
          636,
          11,
          286,
          1066,
          1953,
          309,
          311,
          565,
          337,
          385,
          281,
          483,
          3973,
          295,
          341,
          5756,
          88,
          3678,
          11,
          457,
          51136
        ]
      },
      {
        "avg_logprob": -0.37310757683318796,
        "compression_ratio": 1.467005076142132,
        "end": 1426.22,
        "id": 399,
        "no_speech_prob": 0.06187256798148155,
        "seek": 140822,
        "start": 1423.66,
        "temperature": 0,
        "text": " it just keeps snowing in New York.",
        "tokens": [
          51136,
          309,
          445,
          5965,
          5756,
          278,
          294,
          1873,
          3609,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.37310757683318796,
        "compression_ratio": 1.467005076142132,
        "end": 1429.22,
        "id": 400,
        "no_speech_prob": 0.06187256798148155,
        "seek": 140822,
        "start": 1426.22,
        "temperature": 0,
        "text": " What's going on, people?",
        "tokens": [
          51264,
          708,
          311,
          516,
          322,
          11,
          561,
          30,
          51414
        ]
      },
      {
        "avg_logprob": -0.37310757683318796,
        "compression_ratio": 1.467005076142132,
        "end": 1433.22,
        "id": 401,
        "no_speech_prob": 0.06187256798148155,
        "seek": 140822,
        "start": 1429.22,
        "temperature": 0,
        "text": " It just got very hot in here.",
        "tokens": [
          51414,
          467,
          445,
          658,
          588,
          2368,
          294,
          510,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.37310757683318796,
        "compression_ratio": 1.467005076142132,
        "end": 1434.22,
        "id": 402,
        "no_speech_prob": 0.06187256798148155,
        "seek": 140822,
        "start": 1433.22,
        "temperature": 0,
        "text": " Sweating.",
        "tokens": [
          51614,
          29918,
          990,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.37310757683318796,
        "compression_ratio": 1.467005076142132,
        "end": 1435.22,
        "id": 403,
        "no_speech_prob": 0.06187256798148155,
        "seek": 140822,
        "start": 1434.22,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          51664,
          1033,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.37310757683318796,
        "compression_ratio": 1.467005076142132,
        "end": 1436.22,
        "id": 404,
        "no_speech_prob": 0.06187256798148155,
        "seek": 140822,
        "start": 1435.22,
        "temperature": 0,
        "text": " Here we go.",
        "tokens": [
          51714,
          1692,
          321,
          352,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.3104533672332764,
        "compression_ratio": 1.553191489361702,
        "end": 1438.22,
        "id": 405,
        "no_speech_prob": 0.045351557433605194,
        "seek": 143622,
        "start": 1437.22,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          50414,
          1033,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.3104533672332764,
        "compression_ratio": 1.553191489361702,
        "end": 1443.22,
        "id": 406,
        "no_speech_prob": 0.045351557433605194,
        "seek": 143622,
        "start": 1438.22,
        "temperature": 0,
        "text": " Hello and welcome to coding challenge number 99.",
        "tokens": [
          50464,
          2425,
          293,
          2928,
          281,
          17720,
          3430,
          1230,
          11803,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.3104533672332764,
        "compression_ratio": 1.553191489361702,
        "end": 1446.22,
        "id": 407,
        "no_speech_prob": 0.045351557433605194,
        "seek": 143622,
        "start": 1443.22,
        "temperature": 0,
        "text": " Oh boy, we're getting close to 100.",
        "tokens": [
          50714,
          876,
          3237,
          11,
          321,
          434,
          1242,
          1998,
          281,
          2319,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.3104533672332764,
        "compression_ratio": 1.553191489361702,
        "end": 1449.22,
        "id": 408,
        "no_speech_prob": 0.045351557433605194,
        "seek": 143622,
        "start": 1446.22,
        "temperature": 0,
        "text": " I don't know what I'm going to do.",
        "tokens": [
          50864,
          286,
          500,
          380,
          458,
          437,
          286,
          478,
          516,
          281,
          360,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.3104533672332764,
        "compression_ratio": 1.553191489361702,
        "end": 1455.22,
        "id": 409,
        "no_speech_prob": 0.045351557433605194,
        "seek": 143622,
        "start": 1449.22,
        "temperature": 0,
        "text": " If you have any ideas for what coding challenge 100 should be, please put them in the comments.",
        "tokens": [
          51014,
          759,
          291,
          362,
          604,
          3487,
          337,
          437,
          17720,
          3430,
          2319,
          820,
          312,
          11,
          1767,
          829,
          552,
          294,
          264,
          3053,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.3104533672332764,
        "compression_ratio": 1.553191489361702,
        "end": 1462.22,
        "id": 410,
        "no_speech_prob": 0.045351557433605194,
        "seek": 143622,
        "start": 1455.22,
        "temperature": 0,
        "text": " But this coding challenge is to make a neural network color predictor.",
        "tokens": [
          51314,
          583,
          341,
          17720,
          3430,
          307,
          281,
          652,
          257,
          18161,
          3209,
          2017,
          6069,
          284,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.3000964660644531,
        "compression_ratio": 1.6255924170616114,
        "end": 1466.22,
        "id": 411,
        "no_speech_prob": 0.3140311539173126,
        "seek": 146222,
        "start": 1462.22,
        "temperature": 0,
        "text": " And I am basing this coding challenge off of...",
        "tokens": [
          50364,
          400,
          286,
          669,
          987,
          278,
          341,
          17720,
          3430,
          766,
          295,
          485,
          50564
        ]
      },
      {
        "avg_logprob": -0.3000964660644531,
        "compression_ratio": 1.6255924170616114,
        "end": 1467.22,
        "id": 412,
        "no_speech_prob": 0.3140311539173126,
        "seek": 146222,
        "start": 1466.22,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          50564,
          1033,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.3000964660644531,
        "compression_ratio": 1.6255924170616114,
        "end": 1473.22,
        "id": 413,
        "no_speech_prob": 0.3140311539173126,
        "seek": 146222,
        "start": 1467.22,
        "temperature": 0,
        "text": " Matu, you're just going to have to do an edit there.",
        "tokens": [
          50614,
          6789,
          84,
          11,
          291,
          434,
          445,
          516,
          281,
          362,
          281,
          360,
          364,
          8129,
          456,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.3000964660644531,
        "compression_ratio": 1.6255924170616114,
        "end": 1475.22,
        "id": 414,
        "no_speech_prob": 0.3140311539173126,
        "seek": 146222,
        "start": 1473.22,
        "temperature": 0,
        "text": " And I'm going to figure it out here.",
        "tokens": [
          50914,
          400,
          286,
          478,
          516,
          281,
          2573,
          309,
          484,
          510,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.3000964660644531,
        "compression_ratio": 1.6255924170616114,
        "end": 1477.22,
        "id": 415,
        "no_speech_prob": 0.3140311539173126,
        "seek": 146222,
        "start": 1475.22,
        "temperature": 0,
        "text": " I liked my beginning, so I'm going to keep it.",
        "tokens": [
          51014,
          286,
          4501,
          452,
          2863,
          11,
          370,
          286,
          478,
          516,
          281,
          1066,
          309,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.3000964660644531,
        "compression_ratio": 1.6255924170616114,
        "end": 1479.22,
        "id": 416,
        "no_speech_prob": 0.3140311539173126,
        "seek": 146222,
        "start": 1477.22,
        "temperature": 0,
        "text": " How does he say it?",
        "tokens": [
          51114,
          1012,
          775,
          415,
          584,
          309,
          30,
          51214
        ]
      },
      {
        "avg_logprob": -0.3000964660644531,
        "compression_ratio": 1.6255924170616114,
        "end": 1480.22,
        "id": 417,
        "no_speech_prob": 0.3140311539173126,
        "seek": 146222,
        "start": 1479.22,
        "temperature": 0,
        "text": " S science.",
        "tokens": [
          51214,
          318,
          3497,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.3000964660644531,
        "compression_ratio": 1.6255924170616114,
        "end": 1481.22,
        "id": 418,
        "no_speech_prob": 0.3140311539173126,
        "seek": 146222,
        "start": 1480.22,
        "temperature": 0,
        "text": " Sef science.",
        "tokens": [
          51264,
          318,
          5666,
          3497,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.3000964660644531,
        "compression_ratio": 1.6255924170616114,
        "end": 1482.22,
        "id": 419,
        "no_speech_prob": 0.3140311539173126,
        "seek": 146222,
        "start": 1481.22,
        "temperature": 0,
        "text": " Sef science?",
        "tokens": [
          51314,
          318,
          5666,
          3497,
          30,
          51364
        ]
      },
      {
        "avg_logprob": -0.3000964660644531,
        "compression_ratio": 1.6255924170616114,
        "end": 1483.22,
        "id": 420,
        "no_speech_prob": 0.3140311539173126,
        "seek": 146222,
        "start": 1482.22,
        "temperature": 0,
        "text": " I can't say it.",
        "tokens": [
          51364,
          286,
          393,
          380,
          584,
          309,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.3000964660644531,
        "compression_ratio": 1.6255924170616114,
        "end": 1484.22,
        "id": 421,
        "no_speech_prob": 0.3140311539173126,
        "seek": 146222,
        "start": 1483.22,
        "temperature": 0,
        "text": " Anybody tell me?",
        "tokens": [
          51414,
          19082,
          980,
          385,
          30,
          51464
        ]
      },
      {
        "avg_logprob": -0.3000964660644531,
        "compression_ratio": 1.6255924170616114,
        "end": 1487.22,
        "id": 422,
        "no_speech_prob": 0.3140311539173126,
        "seek": 146222,
        "start": 1484.22,
        "temperature": 0,
        "text": " He told me this before.",
        "tokens": [
          51464,
          634,
          1907,
          385,
          341,
          949,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.3000964660644531,
        "compression_ratio": 1.6255924170616114,
        "end": 1488.22,
        "id": 423,
        "no_speech_prob": 0.3140311539173126,
        "seek": 146222,
        "start": 1487.22,
        "temperature": 0,
        "text": " Sef science?",
        "tokens": [
          51614,
          318,
          5666,
          3497,
          30,
          51664
        ]
      },
      {
        "avg_logprob": -0.3000964660644531,
        "compression_ratio": 1.6255924170616114,
        "end": 1489.22,
        "id": 424,
        "no_speech_prob": 0.3140311539173126,
        "seek": 146222,
        "start": 1488.22,
        "temperature": 0,
        "text": " I should just say Jabril.",
        "tokens": [
          51664,
          286,
          820,
          445,
          584,
          40319,
          24216,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.18857499172813014,
        "compression_ratio": 1.5810810810810811,
        "end": 1493.22,
        "id": 425,
        "no_speech_prob": 0.4415736794471741,
        "seek": 148922,
        "start": 1489.22,
        "temperature": 0,
        "text": " I'm just going to say Jabril.",
        "tokens": [
          50364,
          286,
          478,
          445,
          516,
          281,
          584,
          40319,
          24216,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.18857499172813014,
        "compression_ratio": 1.5810810810810811,
        "end": 1499.22,
        "id": 426,
        "no_speech_prob": 0.4415736794471741,
        "seek": 148922,
        "start": 1493.22,
        "temperature": 0,
        "text": " This coding challenge is based off of Jabril's YouTube channel and his color predictor machine",
        "tokens": [
          50564,
          639,
          17720,
          3430,
          307,
          2361,
          766,
          295,
          40319,
          24216,
          311,
          3088,
          2269,
          293,
          702,
          2017,
          6069,
          284,
          3479,
          50864
        ]
      },
      {
        "avg_logprob": -0.18857499172813014,
        "compression_ratio": 1.5810810810810811,
        "end": 1500.22,
        "id": 427,
        "no_speech_prob": 0.4415736794471741,
        "seek": 148922,
        "start": 1499.22,
        "temperature": 0,
        "text": " learning demo.",
        "tokens": [
          50864,
          2539,
          10723,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.18857499172813014,
        "compression_ratio": 1.5810810810810811,
        "end": 1502.22,
        "id": 428,
        "no_speech_prob": 0.4415736794471741,
        "seek": 148922,
        "start": 1500.22,
        "temperature": 0,
        "text": " So I encourage you to check out that video.",
        "tokens": [
          50914,
          407,
          286,
          5373,
          291,
          281,
          1520,
          484,
          300,
          960,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.18857499172813014,
        "compression_ratio": 1.5810810810810811,
        "end": 1504.22,
        "id": 429,
        "no_speech_prob": 0.4415736794471741,
        "seek": 148922,
        "start": 1502.22,
        "temperature": 0,
        "text": " He also did a live stream.",
        "tokens": [
          51014,
          634,
          611,
          630,
          257,
          1621,
          4309,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.18857499172813014,
        "compression_ratio": 1.5810810810810811,
        "end": 1506.22,
        "id": 430,
        "no_speech_prob": 0.4415736794471741,
        "seek": 148922,
        "start": 1504.22,
        "temperature": 0,
        "text": " I actually have...",
        "tokens": [
          51114,
          286,
          767,
          362,
          485,
          51214
        ]
      },
      {
        "avg_logprob": -0.18857499172813014,
        "compression_ratio": 1.5810810810810811,
        "end": 1507.22,
        "id": 431,
        "no_speech_prob": 0.4415736794471741,
        "seek": 148922,
        "start": 1506.22,
        "temperature": 0,
        "text": " Sef stuff.",
        "tokens": [
          51214,
          318,
          5666,
          1507,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.18857499172813014,
        "compression_ratio": 1.5810810810810811,
        "end": 1508.22,
        "id": 432,
        "no_speech_prob": 0.4415736794471741,
        "seek": 148922,
        "start": 1507.22,
        "temperature": 0,
        "text": " Sef stuff.",
        "tokens": [
          51264,
          318,
          5666,
          1507,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.18857499172813014,
        "compression_ratio": 1.5810810810810811,
        "end": 1509.22,
        "id": 433,
        "no_speech_prob": 0.4415736794471741,
        "seek": 148922,
        "start": 1508.22,
        "temperature": 0,
        "text": " I think I just say Sef stuff.",
        "tokens": [
          51314,
          286,
          519,
          286,
          445,
          584,
          318,
          5666,
          1507,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.18857499172813014,
        "compression_ratio": 1.5810810810810811,
        "end": 1510.22,
        "id": 434,
        "no_speech_prob": 0.4415736794471741,
        "seek": 148922,
        "start": 1509.22,
        "temperature": 0,
        "text": " That's what it is.",
        "tokens": [
          51364,
          663,
          311,
          437,
          309,
          307,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.18857499172813014,
        "compression_ratio": 1.5810810810810811,
        "end": 1514.22,
        "id": 435,
        "no_speech_prob": 0.4415736794471741,
        "seek": 148922,
        "start": 1510.22,
        "temperature": 0,
        "text": " I'm going to do the whole thing again.",
        "tokens": [
          51414,
          286,
          478,
          516,
          281,
          360,
          264,
          1379,
          551,
          797,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.18857499172813014,
        "compression_ratio": 1.5810810810810811,
        "end": 1516.22,
        "id": 436,
        "no_speech_prob": 0.4415736794471741,
        "seek": 148922,
        "start": 1514.22,
        "temperature": 0,
        "text": " Here we go.",
        "tokens": [
          51614,
          1692,
          321,
          352,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.2411697478521438,
        "compression_ratio": 1.7836257309941521,
        "end": 1522.22,
        "id": 437,
        "no_speech_prob": 0.052614860236644745,
        "seek": 151622,
        "start": 1517.22,
        "temperature": 0,
        "text": " It won't be as natural when I redo the whole 99 thing, but...",
        "tokens": [
          50414,
          467,
          1582,
          380,
          312,
          382,
          3303,
          562,
          286,
          29956,
          264,
          1379,
          11803,
          551,
          11,
          457,
          485,
          50664
        ]
      },
      {
        "avg_logprob": -0.2411697478521438,
        "compression_ratio": 1.7836257309941521,
        "end": 1528.22,
        "id": 438,
        "no_speech_prob": 0.052614860236644745,
        "seek": 151622,
        "start": 1522.22,
        "temperature": 0,
        "text": " Hello, and welcome to coding challenge number 99.",
        "tokens": [
          50664,
          2425,
          11,
          293,
          2928,
          281,
          17720,
          3430,
          1230,
          11803,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.2411697478521438,
        "compression_ratio": 1.7836257309941521,
        "end": 1530.22,
        "id": 439,
        "no_speech_prob": 0.052614860236644745,
        "seek": 151622,
        "start": 1528.22,
        "temperature": 0,
        "text": " No, the bell comes later.",
        "tokens": [
          50964,
          883,
          11,
          264,
          4549,
          1487,
          1780,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.2411697478521438,
        "compression_ratio": 1.7836257309941521,
        "end": 1532.22,
        "id": 440,
        "no_speech_prob": 0.052614860236644745,
        "seek": 151622,
        "start": 1530.22,
        "temperature": 0,
        "text": " I've reversed this.",
        "tokens": [
          51064,
          286,
          600,
          30563,
          341,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.2411697478521438,
        "compression_ratio": 1.7836257309941521,
        "end": 1533.22,
        "id": 441,
        "no_speech_prob": 0.052614860236644745,
        "seek": 151622,
        "start": 1532.22,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          51164,
          1033,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.2411697478521438,
        "compression_ratio": 1.7836257309941521,
        "end": 1536.22,
        "id": 442,
        "no_speech_prob": 0.052614860236644745,
        "seek": 151622,
        "start": 1533.22,
        "temperature": 0,
        "text": " Hello, and welcome to another coding challenge.",
        "tokens": [
          51214,
          2425,
          11,
          293,
          2928,
          281,
          1071,
          17720,
          3430,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.2411697478521438,
        "compression_ratio": 1.7836257309941521,
        "end": 1544.22,
        "id": 443,
        "no_speech_prob": 0.052614860236644745,
        "seek": 151622,
        "start": 1536.22,
        "temperature": 0,
        "text": " Now, this coding challenge is number 99, which means the next coding challenge is number 100.",
        "tokens": [
          51364,
          823,
          11,
          341,
          17720,
          3430,
          307,
          1230,
          11803,
          11,
          597,
          1355,
          264,
          958,
          17720,
          3430,
          307,
          1230,
          2319,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.2024931474165483,
        "compression_ratio": 1.6220238095238095,
        "end": 1546.22,
        "id": 444,
        "no_speech_prob": 0.2068583071231842,
        "seek": 154422,
        "start": 1544.22,
        "temperature": 0,
        "text": " And I have no idea what to do.",
        "tokens": [
          50364,
          400,
          286,
          362,
          572,
          1558,
          437,
          281,
          360,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.2024931474165483,
        "compression_ratio": 1.6220238095238095,
        "end": 1548.22,
        "id": 445,
        "no_speech_prob": 0.2068583071231842,
        "seek": 154422,
        "start": 1546.22,
        "temperature": 0,
        "text": " I feel this pressure to do something special.",
        "tokens": [
          50464,
          286,
          841,
          341,
          3321,
          281,
          360,
          746,
          2121,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.2024931474165483,
        "compression_ratio": 1.6220238095238095,
        "end": 1552.22,
        "id": 446,
        "no_speech_prob": 0.2068583071231842,
        "seek": 154422,
        "start": 1548.22,
        "temperature": 0,
        "text": " So please, in the comments, write your suggestions for coding challenge number 100, and maybe",
        "tokens": [
          50564,
          407,
          1767,
          11,
          294,
          264,
          3053,
          11,
          2464,
          428,
          13396,
          337,
          17720,
          3430,
          1230,
          2319,
          11,
          293,
          1310,
          50764
        ]
      },
      {
        "avg_logprob": -0.2024931474165483,
        "compression_ratio": 1.6220238095238095,
        "end": 1555.22,
        "id": 447,
        "no_speech_prob": 0.2068583071231842,
        "seek": 154422,
        "start": 1552.22,
        "temperature": 0,
        "text": " I'll think of something, or you'll help me think of something.",
        "tokens": [
          50764,
          286,
          603,
          519,
          295,
          746,
          11,
          420,
          291,
          603,
          854,
          385,
          519,
          295,
          746,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.2024931474165483,
        "compression_ratio": 1.6220238095238095,
        "end": 1556.22,
        "id": 448,
        "no_speech_prob": 0.2068583071231842,
        "seek": 154422,
        "start": 1555.22,
        "temperature": 0,
        "text": " Okay, so what's happening now?",
        "tokens": [
          50914,
          1033,
          11,
          370,
          437,
          311,
          2737,
          586,
          30,
          50964
        ]
      },
      {
        "avg_logprob": -0.2024931474165483,
        "compression_ratio": 1.6220238095238095,
        "end": 1560.22,
        "id": 449,
        "no_speech_prob": 0.2068583071231842,
        "seek": 154422,
        "start": 1556.22,
        "temperature": 0,
        "text": " I am going to do a coding challenge to make a neural network color predictor.",
        "tokens": [
          50964,
          286,
          669,
          516,
          281,
          360,
          257,
          17720,
          3430,
          281,
          652,
          257,
          18161,
          3209,
          2017,
          6069,
          284,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.2024931474165483,
        "compression_ratio": 1.6220238095238095,
        "end": 1563.22,
        "id": 450,
        "no_speech_prob": 0.2068583071231842,
        "seek": 154422,
        "start": 1560.22,
        "temperature": 0,
        "text": " This is based off of a project made by Jabril.",
        "tokens": [
          51164,
          639,
          307,
          2361,
          766,
          295,
          257,
          1716,
          1027,
          538,
          40319,
          24216,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.2024931474165483,
        "compression_ratio": 1.6220238095238095,
        "end": 1565.22,
        "id": 451,
        "no_speech_prob": 0.2068583071231842,
        "seek": 154422,
        "start": 1563.22,
        "temperature": 0,
        "text": " Check out his YouTube channel.",
        "tokens": [
          51314,
          6881,
          484,
          702,
          3088,
          2269,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.2024931474165483,
        "compression_ratio": 1.6220238095238095,
        "end": 1568.22,
        "id": 452,
        "no_speech_prob": 0.2068583071231842,
        "seek": 154422,
        "start": 1565.22,
        "temperature": 0,
        "text": " Link in this video's description.",
        "tokens": [
          51414,
          8466,
          294,
          341,
          960,
          311,
          3855,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.2024931474165483,
        "compression_ratio": 1.6220238095238095,
        "end": 1572.22,
        "id": 453,
        "no_speech_prob": 0.2068583071231842,
        "seek": 154422,
        "start": 1568.22,
        "temperature": 0,
        "text": " He has a video called Color Predictor Machine Learning Demo that I encourage you to watch.",
        "tokens": [
          51564,
          634,
          575,
          257,
          960,
          1219,
          10458,
          430,
          24945,
          284,
          22155,
          15205,
          4686,
          78,
          300,
          286,
          5373,
          291,
          281,
          1159,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.20612827936808267,
        "compression_ratio": 1.6280701754385964,
        "end": 1577.22,
        "id": 454,
        "no_speech_prob": 0.1347539871931076,
        "seek": 157222,
        "start": 1572.22,
        "temperature": 0,
        "text": " He also actually came on as a guest, and I'll link to a video with Jabril where he talks through this color predictor.",
        "tokens": [
          50364,
          634,
          611,
          767,
          1361,
          322,
          382,
          257,
          8341,
          11,
          293,
          286,
          603,
          2113,
          281,
          257,
          960,
          365,
          40319,
          24216,
          689,
          415,
          6686,
          807,
          341,
          2017,
          6069,
          284,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.20612827936808267,
        "compression_ratio": 1.6280701754385964,
        "end": 1583.22,
        "id": 455,
        "no_speech_prob": 0.1347539871931076,
        "seek": 157222,
        "start": 1577.22,
        "temperature": 0,
        "text": " But I'm going to make my own version of it, and I'm going to use my toy neural network JavaScript library.",
        "tokens": [
          50614,
          583,
          286,
          478,
          516,
          281,
          652,
          452,
          1065,
          3037,
          295,
          309,
          11,
          293,
          286,
          478,
          516,
          281,
          764,
          452,
          12058,
          18161,
          3209,
          15778,
          6405,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.20612827936808267,
        "compression_ratio": 1.6280701754385964,
        "end": 1595.22,
        "id": 456,
        "no_speech_prob": 0.1347539871931076,
        "seek": 157222,
        "start": 1583.22,
        "temperature": 0,
        "text": " Okay, so first, before I start coding, I want to spend some time with you, the viewer, just taking deep breaths together, thinking about flowers.",
        "tokens": [
          50914,
          1033,
          11,
          370,
          700,
          11,
          949,
          286,
          722,
          17720,
          11,
          286,
          528,
          281,
          3496,
          512,
          565,
          365,
          291,
          11,
          264,
          16767,
          11,
          445,
          1940,
          2452,
          33769,
          1214,
          11,
          1953,
          466,
          8085,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.20612827936808267,
        "compression_ratio": 1.6280701754385964,
        "end": 1598.22,
        "id": 457,
        "no_speech_prob": 0.1347539871931076,
        "seek": 157222,
        "start": 1595.22,
        "temperature": 0,
        "text": " Okay, I guess I should talk through what the problem is.",
        "tokens": [
          51514,
          1033,
          11,
          286,
          2041,
          286,
          820,
          751,
          807,
          437,
          264,
          1154,
          307,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.20612827936808267,
        "compression_ratio": 1.6280701754385964,
        "end": 1601.22,
        "id": 458,
        "no_speech_prob": 0.1347539871931076,
        "seek": 157222,
        "start": 1598.22,
        "temperature": 0,
        "text": " So here's the problem, so to speak.",
        "tokens": [
          51664,
          407,
          510,
          311,
          264,
          1154,
          11,
          370,
          281,
          1710,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.21680164337158203,
        "compression_ratio": 1.6389891696750902,
        "end": 1612.22,
        "id": 459,
        "no_speech_prob": 0.00043732597259804606,
        "seek": 160122,
        "start": 1601.22,
        "temperature": 0,
        "text": " Now, one of the reasons why I love this idea, which came from Jabril, is that I'm always looking for really simple, almost trivial scenarios to demonstrate a machine learning concept.",
        "tokens": [
          50364,
          823,
          11,
          472,
          295,
          264,
          4112,
          983,
          286,
          959,
          341,
          1558,
          11,
          597,
          1361,
          490,
          40319,
          24216,
          11,
          307,
          300,
          286,
          478,
          1009,
          1237,
          337,
          534,
          2199,
          11,
          1920,
          26703,
          15077,
          281,
          11698,
          257,
          3479,
          2539,
          3410,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.21680164337158203,
        "compression_ratio": 1.6389891696750902,
        "end": 1628.22,
        "id": 460,
        "no_speech_prob": 0.00043732597259804606,
        "seek": 160122,
        "start": 1612.22,
        "temperature": 0,
        "text": " Where all the pieces of how the algorithm works, it's visual, it involves interaction, it involves drawing, because this, to me, is a good basis for people watching and learning to then build their own more complex or sophisticated design machine learning system things.",
        "tokens": [
          50914,
          2305,
          439,
          264,
          3755,
          295,
          577,
          264,
          9284,
          1985,
          11,
          309,
          311,
          5056,
          11,
          309,
          11626,
          9285,
          11,
          309,
          11626,
          6316,
          11,
          570,
          341,
          11,
          281,
          385,
          11,
          307,
          257,
          665,
          5143,
          337,
          561,
          1976,
          293,
          2539,
          281,
          550,
          1322,
          641,
          1065,
          544,
          3997,
          420,
          16950,
          1715,
          3479,
          2539,
          1185,
          721,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.18328179664982175,
        "compression_ratio": 1.8384279475982532,
        "end": 1633.22,
        "id": 461,
        "no_speech_prob": 0.026758259162306786,
        "seek": 162822,
        "start": 1628.22,
        "temperature": 0,
        "text": " So this is incredibly simple, and in fact, just to be clear, you do not need a neural network for this.",
        "tokens": [
          50364,
          407,
          341,
          307,
          6252,
          2199,
          11,
          293,
          294,
          1186,
          11,
          445,
          281,
          312,
          1850,
          11,
          291,
          360,
          406,
          643,
          257,
          18161,
          3209,
          337,
          341,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.18328179664982175,
        "compression_ratio": 1.8384279475982532,
        "end": 1636.22,
        "id": 462,
        "no_speech_prob": 0.026758259162306786,
        "seek": 162822,
        "start": 1633.22,
        "temperature": 0,
        "text": " It almost makes no sense at all to use a neural network for this.",
        "tokens": [
          50614,
          467,
          1920,
          1669,
          572,
          2020,
          412,
          439,
          281,
          764,
          257,
          18161,
          3209,
          337,
          341,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.18328179664982175,
        "compression_ratio": 1.8384279475982532,
        "end": 1647.22,
        "id": 463,
        "no_speech_prob": 0.026758259162306786,
        "seek": 162822,
        "start": 1636.22,
        "temperature": 0,
        "text": " But it makes the point, you might have heard this, you might have heard this idea that a neural network is a universal function approximator.",
        "tokens": [
          50764,
          583,
          309,
          1669,
          264,
          935,
          11,
          291,
          1062,
          362,
          2198,
          341,
          11,
          291,
          1062,
          362,
          2198,
          341,
          1558,
          300,
          257,
          18161,
          3209,
          307,
          257,
          11455,
          2445,
          8542,
          1639,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.18328179664982175,
        "compression_ratio": 1.8384279475982532,
        "end": 1657.22,
        "id": 464,
        "no_speech_prob": 0.026758259162306786,
        "seek": 162822,
        "start": 1647.22,
        "temperature": 0,
        "text": " So I think that this video, and this topic, and this demonstration will unpack what this means in a nice way.",
        "tokens": [
          51314,
          407,
          286,
          519,
          300,
          341,
          960,
          11,
          293,
          341,
          4829,
          11,
          293,
          341,
          16520,
          486,
          26699,
          437,
          341,
          1355,
          294,
          257,
          1481,
          636,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.19758005284551364,
        "compression_ratio": 1.4779411764705883,
        "end": 1659.22,
        "id": 465,
        "no_speech_prob": 0.06559944897890091,
        "seek": 165722,
        "start": 1657.22,
        "temperature": 0,
        "text": " So, what do I mean by that?",
        "tokens": [
          50364,
          407,
          11,
          437,
          360,
          286,
          914,
          538,
          300,
          30,
          50464
        ]
      },
      {
        "avg_logprob": -0.19758005284551364,
        "compression_ratio": 1.4779411764705883,
        "end": 1662.22,
        "id": 466,
        "no_speech_prob": 0.06559944897890091,
        "seek": 165722,
        "start": 1659.22,
        "temperature": 0,
        "text": " So, what is the problem that we're trying to solve?",
        "tokens": [
          50464,
          407,
          11,
          437,
          307,
          264,
          1154,
          300,
          321,
          434,
          1382,
          281,
          5039,
          30,
          50614
        ]
      },
      {
        "avg_logprob": -0.19758005284551364,
        "compression_ratio": 1.4779411764705883,
        "end": 1668.22,
        "id": 467,
        "no_speech_prob": 0.06559944897890091,
        "seek": 165722,
        "start": 1662.22,
        "temperature": 0,
        "text": " So the problem is, let's say I have a color, some RGB color.",
        "tokens": [
          50614,
          407,
          264,
          1154,
          307,
          11,
          718,
          311,
          584,
          286,
          362,
          257,
          2017,
          11,
          512,
          31231,
          2017,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.19758005284551364,
        "compression_ratio": 1.4779411764705883,
        "end": 1671.22,
        "id": 468,
        "no_speech_prob": 0.06559944897890091,
        "seek": 165722,
        "start": 1668.22,
        "temperature": 0,
        "text": " Some RGB color.",
        "tokens": [
          50914,
          2188,
          31231,
          2017,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.19758005284551364,
        "compression_ratio": 1.4779411764705883,
        "end": 1674.22,
        "id": 469,
        "no_speech_prob": 0.06559944897890091,
        "seek": 165722,
        "start": 1671.22,
        "temperature": 0,
        "text": " And I want to put text on top of that color.",
        "tokens": [
          51064,
          400,
          286,
          528,
          281,
          829,
          2487,
          322,
          1192,
          295,
          300,
          2017,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.2330518780332623,
        "compression_ratio": 1.5810276679841897,
        "end": 1679.22,
        "id": 470,
        "no_speech_prob": 0.12760141491889954,
        "seek": 167422,
        "start": 1674.22,
        "temperature": 0,
        "text": " So I could make a more complex problem, which I would encourage you to do as an exercise after watching this.",
        "tokens": [
          50364,
          407,
          286,
          727,
          652,
          257,
          544,
          3997,
          1154,
          11,
          597,
          286,
          576,
          5373,
          291,
          281,
          360,
          382,
          364,
          5380,
          934,
          1976,
          341,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.2330518780332623,
        "compression_ratio": 1.5810276679841897,
        "end": 1687.22,
        "id": 471,
        "no_speech_prob": 0.12760141491889954,
        "seek": 167422,
        "start": 1679.22,
        "temperature": 0,
        "text": " What would be the most pleasantly looking or complementary, that's an actual thing, color to overlay on that RGB color?",
        "tokens": [
          50614,
          708,
          576,
          312,
          264,
          881,
          35122,
          3627,
          1237,
          420,
          40705,
          11,
          300,
          311,
          364,
          3539,
          551,
          11,
          2017,
          281,
          31741,
          322,
          300,
          31231,
          2017,
          30,
          51014
        ]
      },
      {
        "avg_logprob": -0.2330518780332623,
        "compression_ratio": 1.5810276679841897,
        "end": 1689.22,
        "id": 472,
        "no_speech_prob": 0.12760141491889954,
        "seek": 167422,
        "start": 1687.22,
        "temperature": 0,
        "text": " But I'm just going to ask a simple question.",
        "tokens": [
          51014,
          583,
          286,
          478,
          445,
          516,
          281,
          1029,
          257,
          2199,
          1168,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.2330518780332623,
        "compression_ratio": 1.5810276679841897,
        "end": 1694.22,
        "id": 473,
        "no_speech_prob": 0.12760141491889954,
        "seek": 167422,
        "start": 1689.22,
        "temperature": 0,
        "text": " Which looks better? Black or white?",
        "tokens": [
          51114,
          3013,
          1542,
          1101,
          30,
          4076,
          420,
          2418,
          30,
          51364
        ]
      },
      {
        "avg_logprob": -0.2330518780332623,
        "compression_ratio": 1.5810276679841897,
        "end": 1699.22,
        "id": 474,
        "no_speech_prob": 0.12760141491889954,
        "seek": 167422,
        "start": 1694.22,
        "temperature": 0,
        "text": " And we could get into a whole discussion of why, you know, perception, what looks better.",
        "tokens": [
          51364,
          400,
          321,
          727,
          483,
          666,
          257,
          1379,
          5017,
          295,
          983,
          11,
          291,
          458,
          11,
          12860,
          11,
          437,
          1542,
          1101,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.2212484147813585,
        "compression_ratio": 1.6457142857142857,
        "end": 1704.22,
        "id": 475,
        "no_speech_prob": 0.09669288992881775,
        "seek": 169922,
        "start": 1699.22,
        "temperature": 0,
        "text": " But I just mean in the sort of arbitrary sense, which is easier to read, which is more legible.",
        "tokens": [
          50364,
          583,
          286,
          445,
          914,
          294,
          264,
          1333,
          295,
          23211,
          2020,
          11,
          597,
          307,
          3571,
          281,
          1401,
          11,
          597,
          307,
          544,
          1676,
          964,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.2212484147813585,
        "compression_ratio": 1.6457142857142857,
        "end": 1707.22,
        "id": 476,
        "no_speech_prob": 0.09669288992881775,
        "seek": 169922,
        "start": 1704.22,
        "temperature": 0,
        "text": " And we could write a function, right?",
        "tokens": [
          50614,
          400,
          321,
          727,
          2464,
          257,
          2445,
          11,
          558,
          30,
          50764
        ]
      },
      {
        "avg_logprob": -0.2212484147813585,
        "compression_ratio": 1.6457142857142857,
        "end": 1712.22,
        "id": 477,
        "no_speech_prob": 0.09669288992881775,
        "seek": 169922,
        "start": 1707.22,
        "temperature": 0,
        "text": " We could write a function, a JavaScript function.",
        "tokens": [
          50764,
          492,
          727,
          2464,
          257,
          2445,
          11,
          257,
          15778,
          2445,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.2212484147813585,
        "compression_ratio": 1.6457142857142857,
        "end": 1714.22,
        "id": 478,
        "no_speech_prob": 0.09669288992881775,
        "seek": 169922,
        "start": 1712.22,
        "temperature": 0,
        "text": " I'm just checking to see, right?",
        "tokens": [
          51014,
          286,
          478,
          445,
          8568,
          281,
          536,
          11,
          558,
          30,
          51114
        ]
      },
      {
        "avg_logprob": -0.2212484147813585,
        "compression_ratio": 1.6457142857142857,
        "end": 1720.22,
        "id": 479,
        "no_speech_prob": 0.09669288992881775,
        "seek": 169922,
        "start": 1714.22,
        "temperature": 0,
        "text": " And that JavaScript function takes as its arguments an R, a G, and a B.",
        "tokens": [
          51114,
          400,
          300,
          15778,
          2445,
          2516,
          382,
          1080,
          12869,
          364,
          497,
          11,
          257,
          460,
          11,
          293,
          257,
          363,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.20417680131628158,
        "compression_ratio": 1.702020202020202,
        "end": 1726.22,
        "id": 480,
        "no_speech_prob": 0.11918698251247406,
        "seek": 172022,
        "start": 1720.22,
        "temperature": 0,
        "text": " And what it does is it returns, maybe it returns, I mean, black.",
        "tokens": [
          50364,
          400,
          437,
          309,
          775,
          307,
          309,
          11247,
          11,
          1310,
          309,
          11247,
          11,
          286,
          914,
          11,
          2211,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.20417680131628158,
        "compression_ratio": 1.702020202020202,
        "end": 1730.22,
        "id": 481,
        "no_speech_prob": 0.11918698251247406,
        "seek": 172022,
        "start": 1726.22,
        "temperature": 0,
        "text": " Or maybe somewhere else in the function it returns white.",
        "tokens": [
          50664,
          1610,
          1310,
          4079,
          1646,
          294,
          264,
          2445,
          309,
          11247,
          2418,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.20417680131628158,
        "compression_ratio": 1.702020202020202,
        "end": 1733.22,
        "id": 482,
        "no_speech_prob": 0.11918698251247406,
        "seek": 172022,
        "start": 1730.22,
        "temperature": 0,
        "text": " And maybe we just have like this if statement.",
        "tokens": [
          50864,
          400,
          1310,
          321,
          445,
          362,
          411,
          341,
          498,
          5629,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.20417680131628158,
        "compression_ratio": 1.702020202020202,
        "end": 1742.22,
        "id": 483,
        "no_speech_prob": 0.11918698251247406,
        "seek": 172022,
        "start": 1733.22,
        "temperature": 0,
        "text": " And maybe I'm doing something like if R plus G plus B is less than 100 or less than 200, return black.",
        "tokens": [
          51014,
          400,
          1310,
          286,
          478,
          884,
          746,
          411,
          498,
          497,
          1804,
          460,
          1804,
          363,
          307,
          1570,
          813,
          2319,
          420,
          1570,
          813,
          2331,
          11,
          2736,
          2211,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.20417680131628158,
        "compression_ratio": 1.702020202020202,
        "end": 1744.22,
        "id": 484,
        "no_speech_prob": 0.11918698251247406,
        "seek": 172022,
        "start": 1742.22,
        "temperature": 0,
        "text": " Otherwise return white.",
        "tokens": [
          51464,
          10328,
          2736,
          2418,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.20417680131628158,
        "compression_ratio": 1.702020202020202,
        "end": 1745.22,
        "id": 485,
        "no_speech_prob": 0.11918698251247406,
        "seek": 172022,
        "start": 1744.22,
        "temperature": 0,
        "text": " So this is the idea.",
        "tokens": [
          51564,
          407,
          341,
          307,
          264,
          1558,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.20417680131628158,
        "compression_ratio": 1.702020202020202,
        "end": 1747.22,
        "id": 486,
        "no_speech_prob": 0.11918698251247406,
        "seek": 172022,
        "start": 1745.22,
        "temperature": 0,
        "text": " This is a function.",
        "tokens": [
          51614,
          639,
          307,
          257,
          2445,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.18177889706043715,
        "compression_ratio": 1.7444444444444445,
        "end": 1750.22,
        "id": 487,
        "no_speech_prob": 0.001524771680124104,
        "seek": 174722,
        "start": 1747.22,
        "temperature": 0,
        "text": " It takes inputs.",
        "tokens": [
          50364,
          467,
          2516,
          15743,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.18177889706043715,
        "compression_ratio": 1.7444444444444445,
        "end": 1752.22,
        "id": 488,
        "no_speech_prob": 0.001524771680124104,
        "seek": 174722,
        "start": 1750.22,
        "temperature": 0,
        "text": " How many inputs? Three.",
        "tokens": [
          50514,
          1012,
          867,
          15743,
          30,
          6244,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.18177889706043715,
        "compression_ratio": 1.7444444444444445,
        "end": 1754.22,
        "id": 489,
        "no_speech_prob": 0.001524771680124104,
        "seek": 174722,
        "start": 1752.22,
        "temperature": 0,
        "text": " And it returns an output.",
        "tokens": [
          50614,
          400,
          309,
          11247,
          364,
          5598,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.18177889706043715,
        "compression_ratio": 1.7444444444444445,
        "end": 1756.22,
        "id": 490,
        "no_speech_prob": 0.001524771680124104,
        "seek": 174722,
        "start": 1754.22,
        "temperature": 0,
        "text": " How many outputs? One.",
        "tokens": [
          50714,
          1012,
          867,
          23930,
          30,
          1485,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.18177889706043715,
        "compression_ratio": 1.7444444444444445,
        "end": 1759.22,
        "id": 491,
        "no_speech_prob": 0.001524771680124104,
        "seek": 174722,
        "start": 1756.22,
        "temperature": 0,
        "text": " But out of two possibilities is important here.",
        "tokens": [
          50814,
          583,
          484,
          295,
          732,
          12178,
          307,
          1021,
          510,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.18177889706043715,
        "compression_ratio": 1.7444444444444445,
        "end": 1763.22,
        "id": 492,
        "no_speech_prob": 0.001524771680124104,
        "seek": 174722,
        "start": 1759.22,
        "temperature": 0,
        "text": " There are two possible, out to two possibilities.",
        "tokens": [
          50964,
          821,
          366,
          732,
          1944,
          11,
          484,
          281,
          732,
          12178,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.18177889706043715,
        "compression_ratio": 1.7444444444444445,
        "end": 1765.22,
        "id": 493,
        "no_speech_prob": 0.001524771680124104,
        "seek": 174722,
        "start": 1763.22,
        "temperature": 0,
        "text": " It takes one output.",
        "tokens": [
          51164,
          467,
          2516,
          472,
          5598,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.18177889706043715,
        "compression_ratio": 1.7444444444444445,
        "end": 1769.22,
        "id": 494,
        "no_speech_prob": 0.001524771680124104,
        "seek": 174722,
        "start": 1765.22,
        "temperature": 0,
        "text": " It's a function that takes three inputs and returns one output.",
        "tokens": [
          51264,
          467,
          311,
          257,
          2445,
          300,
          2516,
          1045,
          15743,
          293,
          11247,
          472,
          5598,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.18177889706043715,
        "compression_ratio": 1.7444444444444445,
        "end": 1774.22,
        "id": 495,
        "no_speech_prob": 0.001524771680124104,
        "seek": 174722,
        "start": 1769.22,
        "temperature": 0,
        "text": " The inputs are numbers between 0 and 255.",
        "tokens": [
          51464,
          440,
          15743,
          366,
          3547,
          1296,
          1958,
          293,
          3552,
          20,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.2118181259401383,
        "compression_ratio": 1.786259541984733,
        "end": 1778.22,
        "id": 496,
        "no_speech_prob": 0.0006263310206122696,
        "seek": 177422,
        "start": 1774.22,
        "temperature": 0,
        "text": " And the output is one label, which is a string.",
        "tokens": [
          50364,
          400,
          264,
          5598,
          307,
          472,
          7645,
          11,
          597,
          307,
          257,
          6798,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.2118181259401383,
        "compression_ratio": 1.786259541984733,
        "end": 1782.22,
        "id": 497,
        "no_speech_prob": 0.0006263310206122696,
        "seek": 177422,
        "start": 1778.22,
        "temperature": 0,
        "text": " But another way I could think about this is it could return a kind of probability value.",
        "tokens": [
          50564,
          583,
          1071,
          636,
          286,
          727,
          519,
          466,
          341,
          307,
          309,
          727,
          2736,
          257,
          733,
          295,
          8482,
          2158,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.2118181259401383,
        "compression_ratio": 1.786259541984733,
        "end": 1787.22,
        "id": 498,
        "no_speech_prob": 0.0006263310206122696,
        "seek": 177422,
        "start": 1782.22,
        "temperature": 0,
        "text": " How likely is it that black looks better and how likely is it that white looks better?",
        "tokens": [
          50764,
          1012,
          3700,
          307,
          309,
          300,
          2211,
          1542,
          1101,
          293,
          577,
          3700,
          307,
          309,
          300,
          2418,
          1542,
          1101,
          30,
          51014
        ]
      },
      {
        "avg_logprob": -0.2118181259401383,
        "compression_ratio": 1.786259541984733,
        "end": 1792.22,
        "id": 499,
        "no_speech_prob": 0.0006263310206122696,
        "seek": 177422,
        "start": 1787.22,
        "temperature": 0,
        "text": " And that would be kind of also two floating point numbers.",
        "tokens": [
          51014,
          400,
          300,
          576,
          312,
          733,
          295,
          611,
          732,
          12607,
          935,
          3547,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.2118181259401383,
        "compression_ratio": 1.786259541984733,
        "end": 1793.22,
        "id": 500,
        "no_speech_prob": 0.0006263310206122696,
        "seek": 177422,
        "start": 1792.22,
        "temperature": 0,
        "text": " You could think of it that way.",
        "tokens": [
          51264,
          509,
          727,
          519,
          295,
          309,
          300,
          636,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.2118181259401383,
        "compression_ratio": 1.786259541984733,
        "end": 1795.22,
        "id": 501,
        "no_speech_prob": 0.0006263310206122696,
        "seek": 177422,
        "start": 1793.22,
        "temperature": 0,
        "text": " So this is a function.",
        "tokens": [
          51314,
          407,
          341,
          307,
          257,
          2445,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.2118181259401383,
        "compression_ratio": 1.786259541984733,
        "end": 1797.22,
        "id": 502,
        "no_speech_prob": 0.0006263310206122696,
        "seek": 177422,
        "start": 1795.22,
        "temperature": 0,
        "text": " So a lot of machine, like imagine this.",
        "tokens": [
          51414,
          407,
          257,
          688,
          295,
          3479,
          11,
          411,
          3811,
          341,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.2118181259401383,
        "compression_ratio": 1.786259541984733,
        "end": 1799.22,
        "id": 503,
        "no_speech_prob": 0.0006263310206122696,
        "seek": 177422,
        "start": 1797.22,
        "temperature": 0,
        "text": " So now I have this function that takes an RGB color.",
        "tokens": [
          51514,
          407,
          586,
          286,
          362,
          341,
          2445,
          300,
          2516,
          364,
          31231,
          2017,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.2118181259401383,
        "compression_ratio": 1.786259541984733,
        "end": 1801.22,
        "id": 504,
        "no_speech_prob": 0.0006263310206122696,
        "seek": 177422,
        "start": 1799.22,
        "temperature": 0,
        "text": " Now let me give you another function.",
        "tokens": [
          51614,
          823,
          718,
          385,
          976,
          291,
          1071,
          2445,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.2086065129716267,
        "compression_ratio": 1.7660377358490567,
        "end": 1809.22,
        "id": 505,
        "no_speech_prob": 0.1581544429063797,
        "seek": 180122,
        "start": 1801.22,
        "temperature": 0,
        "text": " Write a function that takes an image data, a 200 by 200 pixel image, and then returns what's in that image.",
        "tokens": [
          50364,
          23499,
          257,
          2445,
          300,
          2516,
          364,
          3256,
          1412,
          11,
          257,
          2331,
          538,
          2331,
          19261,
          3256,
          11,
          293,
          550,
          11247,
          437,
          311,
          294,
          300,
          3256,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.2086065129716267,
        "compression_ratio": 1.7660377358490567,
        "end": 1815.22,
        "id": 506,
        "no_speech_prob": 0.1581544429063797,
        "seek": 180122,
        "start": 1809.22,
        "temperature": 0,
        "text": " Now you could imagine, in this case, deciding whether it should be black or white is just a matter of,",
        "tokens": [
          50764,
          823,
          291,
          727,
          3811,
          11,
          294,
          341,
          1389,
          11,
          17990,
          1968,
          309,
          820,
          312,
          2211,
          420,
          2418,
          307,
          445,
          257,
          1871,
          295,
          11,
          51064
        ]
      },
      {
        "avg_logprob": -0.2086065129716267,
        "compression_ratio": 1.7660377358490567,
        "end": 1818.22,
        "id": 507,
        "no_speech_prob": 0.1581544429063797,
        "seek": 180122,
        "start": 1815.22,
        "temperature": 0,
        "text": " okay, is it bright, is it dark, which color is going to be?",
        "tokens": [
          51064,
          1392,
          11,
          307,
          309,
          4730,
          11,
          307,
          309,
          2877,
          11,
          597,
          2017,
          307,
          516,
          281,
          312,
          30,
          51214
        ]
      },
      {
        "avg_logprob": -0.2086065129716267,
        "compression_ratio": 1.7660377358490567,
        "end": 1820.22,
        "id": 508,
        "no_speech_prob": 0.1581544429063797,
        "seek": 180122,
        "start": 1818.22,
        "temperature": 0,
        "text": " Like a bright color looks better on a dark color.",
        "tokens": [
          51214,
          1743,
          257,
          4730,
          2017,
          1542,
          1101,
          322,
          257,
          2877,
          2017,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.2086065129716267,
        "compression_ratio": 1.7660377358490567,
        "end": 1822.22,
        "id": 509,
        "no_speech_prob": 0.1581544429063797,
        "seek": 180122,
        "start": 1820.22,
        "temperature": 0,
        "text": " A dark color looks better on a bright color.",
        "tokens": [
          51314,
          316,
          2877,
          2017,
          1542,
          1101,
          322,
          257,
          4730,
          2017,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.2086065129716267,
        "compression_ratio": 1.7660377358490567,
        "end": 1827.22,
        "id": 510,
        "no_speech_prob": 0.1581544429063797,
        "seek": 180122,
        "start": 1822.22,
        "temperature": 0,
        "text": " But if I took in a full image and needed to return, whether it's a cat, a dog, a turtle, a coffee mug,",
        "tokens": [
          51414,
          583,
          498,
          286,
          1890,
          294,
          257,
          1577,
          3256,
          293,
          2978,
          281,
          2736,
          11,
          1968,
          309,
          311,
          257,
          3857,
          11,
          257,
          3000,
          11,
          257,
          22866,
          11,
          257,
          4982,
          23610,
          11,
          51664
        ]
      },
      {
        "avg_logprob": -0.20068416992823282,
        "compression_ratio": 1.5508474576271187,
        "end": 1837.22,
        "id": 511,
        "no_speech_prob": 0.015188765712082386,
        "seek": 182722,
        "start": 1827.22,
        "temperature": 0,
        "text": " a cell phone, a walking stick, a conductor's baton, I don't know where my brain is going here, a toy train.",
        "tokens": [
          50364,
          257,
          2815,
          2593,
          11,
          257,
          4494,
          2897,
          11,
          257,
          29957,
          311,
          7362,
          266,
          11,
          286,
          500,
          380,
          458,
          689,
          452,
          3567,
          307,
          516,
          510,
          11,
          257,
          12058,
          3847,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.20068416992823282,
        "compression_ratio": 1.5508474576271187,
        "end": 1841.22,
        "id": 512,
        "no_speech_prob": 0.015188765712082386,
        "seek": 182722,
        "start": 1837.22,
        "temperature": 0,
        "text": " Try writing a bunch of if statements to do that.",
        "tokens": [
          50864,
          6526,
          3579,
          257,
          3840,
          295,
          498,
          12363,
          281,
          360,
          300,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.20068416992823282,
        "compression_ratio": 1.5508474576271187,
        "end": 1847.22,
        "id": 513,
        "no_speech_prob": 0.015188765712082386,
        "seek": 182722,
        "start": 1841.22,
        "temperature": 0,
        "text": " Well, if the pixel colors are this and shaped like this, having to hard code an algorithm,",
        "tokens": [
          51064,
          1042,
          11,
          498,
          264,
          19261,
          4577,
          366,
          341,
          293,
          13475,
          411,
          341,
          11,
          1419,
          281,
          1152,
          3089,
          364,
          9284,
          11,
          51364
        ]
      },
      {
        "avg_logprob": -0.20068416992823282,
        "compression_ratio": 1.5508474576271187,
        "end": 1852.22,
        "id": 514,
        "no_speech_prob": 0.015188765712082386,
        "seek": 182722,
        "start": 1847.22,
        "temperature": 0,
        "text": " a function that takes inputs and generates an output, would be really difficult.",
        "tokens": [
          51364,
          257,
          2445,
          300,
          2516,
          15743,
          293,
          23815,
          364,
          5598,
          11,
          576,
          312,
          534,
          2252,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.20068416992823282,
        "compression_ratio": 1.5508474576271187,
        "end": 1856.22,
        "id": 515,
        "no_speech_prob": 0.015188765712082386,
        "seek": 182722,
        "start": 1852.22,
        "temperature": 0,
        "text": " This is what a neural network is for.",
        "tokens": [
          51614,
          639,
          307,
          437,
          257,
          18161,
          3209,
          307,
          337,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.20962964752574026,
        "compression_ratio": 1.5841584158415842,
        "end": 1866.22,
        "id": 516,
        "no_speech_prob": 0.0001713069068500772,
        "seek": 185622,
        "start": 1856.22,
        "temperature": 0,
        "text": " And just to make this case here, the idea here is that a neural network can approximate any function.",
        "tokens": [
          50364,
          400,
          445,
          281,
          652,
          341,
          1389,
          510,
          11,
          264,
          1558,
          510,
          307,
          300,
          257,
          18161,
          3209,
          393,
          30874,
          604,
          2445,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.20962964752574026,
        "compression_ratio": 1.5841584158415842,
        "end": 1874.22,
        "id": 517,
        "no_speech_prob": 0.0001713069068500772,
        "seek": 185622,
        "start": 1866.22,
        "temperature": 0,
        "text": " It can learn to receive inputs and return the outputs for any input data for any sort of problem.",
        "tokens": [
          50864,
          467,
          393,
          1466,
          281,
          4774,
          15743,
          293,
          2736,
          264,
          23930,
          337,
          604,
          4846,
          1412,
          337,
          604,
          1333,
          295,
          1154,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.20962964752574026,
        "compression_ratio": 1.5841584158415842,
        "end": 1880.22,
        "id": 518,
        "no_speech_prob": 0.0001713069068500772,
        "seek": 185622,
        "start": 1874.22,
        "temperature": 0,
        "text": " Is this true that any, in capital letters, the big underline is true?",
        "tokens": [
          51264,
          1119,
          341,
          2074,
          300,
          604,
          11,
          294,
          4238,
          7825,
          11,
          264,
          955,
          833,
          1889,
          307,
          2074,
          30,
          51564
        ]
      },
      {
        "avg_logprob": -0.20962964752574026,
        "compression_ratio": 1.5841584158415842,
        "end": 1881.22,
        "id": 519,
        "no_speech_prob": 0.0001713069068500772,
        "seek": 185622,
        "start": 1880.22,
        "temperature": 0,
        "text": " That's an open question.",
        "tokens": [
          51564,
          663,
          311,
          364,
          1269,
          1168,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.20962964752574026,
        "compression_ratio": 1.5841584158415842,
        "end": 1882.22,
        "id": 520,
        "no_speech_prob": 0.0001713069068500772,
        "seek": 185622,
        "start": 1881.22,
        "temperature": 0,
        "text": " What are the limitations?",
        "tokens": [
          51614,
          708,
          366,
          264,
          15705,
          30,
          51664
        ]
      },
      {
        "avg_logprob": -0.18991322671213456,
        "compression_ratio": 1.6325581395348838,
        "end": 1884.22,
        "id": 521,
        "no_speech_prob": 0.5116062760353088,
        "seek": 188222,
        "start": 1882.22,
        "temperature": 0,
        "text": " What should and should not we be doing?",
        "tokens": [
          50364,
          708,
          820,
          293,
          820,
          406,
          321,
          312,
          884,
          30,
          50464
        ]
      },
      {
        "avg_logprob": -0.18991322671213456,
        "compression_ratio": 1.6325581395348838,
        "end": 1887.22,
        "id": 522,
        "no_speech_prob": 0.5116062760353088,
        "seek": 188222,
        "start": 1884.22,
        "temperature": 0,
        "text": " Should we even be using a neural network for this task?",
        "tokens": [
          50464,
          6454,
          321,
          754,
          312,
          1228,
          257,
          18161,
          3209,
          337,
          341,
          5633,
          30,
          50614
        ]
      },
      {
        "avg_logprob": -0.18991322671213456,
        "compression_ratio": 1.6325581395348838,
        "end": 1890.22,
        "id": 523,
        "no_speech_prob": 0.5116062760353088,
        "seek": 188222,
        "start": 1887.22,
        "temperature": 0,
        "text": " Are we causing harm by doing this machine learning task?",
        "tokens": [
          50614,
          2014,
          321,
          9853,
          6491,
          538,
          884,
          341,
          3479,
          2539,
          5633,
          30,
          50764
        ]
      },
      {
        "avg_logprob": -0.18991322671213456,
        "compression_ratio": 1.6325581395348838,
        "end": 1896.22,
        "id": 524,
        "no_speech_prob": 0.5116062760353088,
        "seek": 188222,
        "start": 1890.22,
        "temperature": 0,
        "text": " But those questions aside, now we can say, well, if I have this quote unquote neural network thing,",
        "tokens": [
          50764,
          583,
          729,
          1651,
          7359,
          11,
          586,
          321,
          393,
          584,
          11,
          731,
          11,
          498,
          286,
          362,
          341,
          6513,
          37557,
          18161,
          3209,
          551,
          11,
          51064
        ]
      },
      {
        "avg_logprob": -0.18991322671213456,
        "compression_ratio": 1.6325581395348838,
        "end": 1908.22,
        "id": 525,
        "no_speech_prob": 0.5116062760353088,
        "seek": 188222,
        "start": 1896.22,
        "temperature": 0,
        "text": " what if I were to just send three inputs into it, R, G, B, and then I want to receive two outputs,",
        "tokens": [
          51064,
          437,
          498,
          286,
          645,
          281,
          445,
          2845,
          1045,
          15743,
          666,
          309,
          11,
          497,
          11,
          460,
          11,
          363,
          11,
          293,
          550,
          286,
          528,
          281,
          4774,
          732,
          23930,
          11,
          51664
        ]
      },
      {
        "avg_logprob": -0.2240475905568976,
        "compression_ratio": 1.6508620689655173,
        "end": 1914.22,
        "id": 526,
        "no_speech_prob": 0.001548743573948741,
        "seek": 190822,
        "start": 1908.22,
        "temperature": 0,
        "text": " probability of black, probability of white.",
        "tokens": [
          50364,
          8482,
          295,
          2211,
          11,
          8482,
          295,
          2418,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.2240475905568976,
        "compression_ratio": 1.6508620689655173,
        "end": 1918.22,
        "id": 527,
        "no_speech_prob": 0.001548743573948741,
        "seek": 190822,
        "start": 1914.22,
        "temperature": 0,
        "text": " This is now a universal function approximator.",
        "tokens": [
          50664,
          639,
          307,
          586,
          257,
          11455,
          2445,
          8542,
          1639,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.2240475905568976,
        "compression_ratio": 1.6508620689655173,
        "end": 1923.22,
        "id": 528,
        "no_speech_prob": 0.001548743573948741,
        "seek": 190822,
        "start": 1918.22,
        "temperature": 0,
        "text": " It is going to stand in, so what is neural net, machine learning doesn't necessarily replace,",
        "tokens": [
          50864,
          467,
          307,
          516,
          281,
          1463,
          294,
          11,
          370,
          437,
          307,
          18161,
          2533,
          11,
          3479,
          2539,
          1177,
          380,
          4725,
          7406,
          11,
          51114
        ]
      },
      {
        "avg_logprob": -0.2240475905568976,
        "compression_ratio": 1.6508620689655173,
        "end": 1927.22,
        "id": 529,
        "no_speech_prob": 0.001548743573948741,
        "seek": 190822,
        "start": 1923.22,
        "temperature": 0,
        "text": " you can think of it as, I mean, will machine learning replace the need to write code completely at some point?",
        "tokens": [
          51114,
          291,
          393,
          519,
          295,
          309,
          382,
          11,
          286,
          914,
          11,
          486,
          3479,
          2539,
          7406,
          264,
          643,
          281,
          2464,
          3089,
          2584,
          412,
          512,
          935,
          30,
          51314
        ]
      },
      {
        "avg_logprob": -0.2240475905568976,
        "compression_ratio": 1.6508620689655173,
        "end": 1928.22,
        "id": 530,
        "no_speech_prob": 0.001548743573948741,
        "seek": 190822,
        "start": 1927.22,
        "temperature": 0,
        "text": " Maybe.",
        "tokens": [
          51314,
          2704,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.2240475905568976,
        "compression_ratio": 1.6508620689655173,
        "end": 1932.22,
        "id": 531,
        "no_speech_prob": 0.001548743573948741,
        "seek": 190822,
        "start": 1928.22,
        "temperature": 0,
        "text": " But here, what I would make the case is that machine learning, a neural network,",
        "tokens": [
          51364,
          583,
          510,
          11,
          437,
          286,
          576,
          652,
          264,
          1389,
          307,
          300,
          3479,
          2539,
          11,
          257,
          18161,
          3209,
          11,
          51564
        ]
      },
      {
        "avg_logprob": -0.22495938418956285,
        "compression_ratio": 1.5116279069767442,
        "end": 1937.22,
        "id": 532,
        "no_speech_prob": 0.6958497166633606,
        "seek": 193222,
        "start": 1932.22,
        "temperature": 0,
        "text": " might replace the guts of a function that you might hard code otherwise.",
        "tokens": [
          50364,
          1062,
          7406,
          264,
          28560,
          295,
          257,
          2445,
          300,
          291,
          1062,
          1152,
          3089,
          5911,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.22495938418956285,
        "compression_ratio": 1.5116279069767442,
        "end": 1941.22,
        "id": 533,
        "no_speech_prob": 0.6958497166633606,
        "seek": 193222,
        "start": 1937.22,
        "temperature": 0,
        "text": " Okay, boy, am I spending a long time explaining this.",
        "tokens": [
          50614,
          1033,
          11,
          3237,
          11,
          669,
          286,
          6434,
          257,
          938,
          565,
          13468,
          341,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.22495938418956285,
        "compression_ratio": 1.5116279069767442,
        "end": 1944.22,
        "id": 534,
        "no_speech_prob": 0.6958497166633606,
        "seek": 193222,
        "start": 1941.22,
        "temperature": 0,
        "text": " So now, what goes here?",
        "tokens": [
          50814,
          407,
          586,
          11,
          437,
          1709,
          510,
          30,
          50964
        ]
      },
      {
        "avg_logprob": -0.22495938418956285,
        "compression_ratio": 1.5116279069767442,
        "end": 1949.22,
        "id": 535,
        "no_speech_prob": 0.6958497166633606,
        "seek": 193222,
        "start": 1944.22,
        "temperature": 0,
        "text": " Now, if you want to learn more about the structure of a neural network and the internals of it,",
        "tokens": [
          50964,
          823,
          11,
          498,
          291,
          528,
          281,
          1466,
          544,
          466,
          264,
          3877,
          295,
          257,
          18161,
          3209,
          293,
          264,
          2154,
          1124,
          295,
          309,
          11,
          51214
        ]
      },
      {
        "avg_logprob": -0.22495938418956285,
        "compression_ratio": 1.5116279069767442,
        "end": 1954.22,
        "id": 536,
        "no_speech_prob": 0.6958497166633606,
        "seek": 193222,
        "start": 1949.22,
        "temperature": 0,
        "text": " I would refer you to the 3Blue1Brown video series, as well as my video series.",
        "tokens": [
          51214,
          286,
          576,
          2864,
          291,
          281,
          264,
          805,
          45231,
          16,
          22170,
          648,
          960,
          2638,
          11,
          382,
          731,
          382,
          452,
          960,
          2638,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.25322777032852173,
        "compression_ratio": 1.5178571428571428,
        "end": 1959.22,
        "id": 537,
        "no_speech_prob": 0.03358542546629906,
        "seek": 195422,
        "start": 1954.22,
        "temperature": 0,
        "text": " I would refer you to the 3Blue1Brown video series, as well as my video series,",
        "tokens": [
          50364,
          286,
          576,
          2864,
          291,
          281,
          264,
          805,
          45231,
          16,
          22170,
          648,
          960,
          2638,
          11,
          382,
          731,
          382,
          452,
          960,
          2638,
          11,
          50614
        ]
      },
      {
        "avg_logprob": -0.25322777032852173,
        "compression_ratio": 1.5178571428571428,
        "end": 1963.22,
        "id": 538,
        "no_speech_prob": 0.03358542546629906,
        "seek": 195422,
        "start": 1959.22,
        "temperature": 0,
        "text": " which goes through building this neural network library in JavaScript.",
        "tokens": [
          50614,
          597,
          1709,
          807,
          2390,
          341,
          18161,
          3209,
          6405,
          294,
          15778,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.25322777032852173,
        "compression_ratio": 1.5178571428571428,
        "end": 1973.22,
        "id": 539,
        "no_speech_prob": 0.03358542546629906,
        "seek": 195422,
        "start": 1963.22,
        "temperature": 0,
        "text": " For us, as the user of the neural network library, the only things we need to decide are how many inputs,",
        "tokens": [
          50814,
          1171,
          505,
          11,
          382,
          264,
          4195,
          295,
          264,
          18161,
          3209,
          6405,
          11,
          264,
          787,
          721,
          321,
          643,
          281,
          4536,
          366,
          577,
          867,
          15743,
          11,
          51314
        ]
      },
      {
        "avg_logprob": -0.20639712993915266,
        "compression_ratio": 2.301775147928994,
        "end": 1978.22,
        "id": 540,
        "no_speech_prob": 0.04884691163897514,
        "seek": 197322,
        "start": 1973.22,
        "temperature": 0,
        "text": " sorry, the only things we need to decide are how many inputs,",
        "tokens": [
          50364,
          2597,
          11,
          264,
          787,
          721,
          321,
          643,
          281,
          4536,
          366,
          577,
          867,
          15743,
          11,
          50614
        ]
      },
      {
        "avg_logprob": -0.20639712993915266,
        "compression_ratio": 2.301775147928994,
        "end": 1983.22,
        "id": 541,
        "no_speech_prob": 0.04884691163897514,
        "seek": 197322,
        "start": 1981.22,
        "temperature": 0,
        "text": " and how many outputs,",
        "tokens": [
          50764,
          293,
          577,
          867,
          23930,
          11,
          50864
        ]
      },
      {
        "avg_logprob": -0.20639712993915266,
        "compression_ratio": 2.301775147928994,
        "end": 1991.22,
        "id": 542,
        "no_speech_prob": 0.04884691163897514,
        "seek": 197322,
        "start": 1985.22,
        "temperature": 0,
        "text": " and then, so this is, inputs and outputs are the things we, as the end user of the neural network,",
        "tokens": [
          50964,
          293,
          550,
          11,
          370,
          341,
          307,
          11,
          15743,
          293,
          23930,
          366,
          264,
          721,
          321,
          11,
          382,
          264,
          917,
          4195,
          295,
          264,
          18161,
          3209,
          11,
          51264
        ]
      },
      {
        "avg_logprob": -0.20639712993915266,
        "compression_ratio": 2.301775147928994,
        "end": 1993.22,
        "id": 543,
        "no_speech_prob": 0.04884691163897514,
        "seek": 197322,
        "start": 1991.22,
        "temperature": 0,
        "text": " look at and control.",
        "tokens": [
          51264,
          574,
          412,
          293,
          1969,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.20639712993915266,
        "compression_ratio": 2.301775147928994,
        "end": 1997.22,
        "id": 544,
        "no_speech_prob": 0.04884691163897514,
        "seek": 197322,
        "start": 1993.22,
        "temperature": 0,
        "text": " We're sending in the input, we're reading the output, we're doing something with the output.",
        "tokens": [
          51364,
          492,
          434,
          7750,
          294,
          264,
          4846,
          11,
          321,
          434,
          3760,
          264,
          5598,
          11,
          321,
          434,
          884,
          746,
          365,
          264,
          5598,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.20639712993915266,
        "compression_ratio": 2.301775147928994,
        "end": 2001.22,
        "id": 545,
        "no_speech_prob": 0.04884691163897514,
        "seek": 197322,
        "start": 1997.22,
        "temperature": 0,
        "text": " We're sending in the input, we're reading the output, we're doing something with the output.",
        "tokens": [
          51564,
          492,
          434,
          7750,
          294,
          264,
          4846,
          11,
          321,
          434,
          3760,
          264,
          5598,
          11,
          321,
          434,
          884,
          746,
          365,
          264,
          5598,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.21101485358344185,
        "compression_ratio": 1.7782101167315174,
        "end": 2005.22,
        "id": 546,
        "no_speech_prob": 0.0015487089985981584,
        "seek": 200122,
        "start": 2001.22,
        "temperature": 0,
        "text": " But, the sort of quote-unquote magic, which isn't magic, it's just math,",
        "tokens": [
          50364,
          583,
          11,
          264,
          1333,
          295,
          6513,
          12,
          409,
          25016,
          5585,
          11,
          597,
          1943,
          380,
          5585,
          11,
          309,
          311,
          445,
          5221,
          11,
          50564
        ]
      },
      {
        "avg_logprob": -0.21101485358344185,
        "compression_ratio": 1.7782101167315174,
        "end": 2009.22,
        "id": 547,
        "no_speech_prob": 0.0015487089985981584,
        "seek": 200122,
        "start": 2005.22,
        "temperature": 0,
        "text": " numbers multiplied and added together, all sorts of other stuff,",
        "tokens": [
          50564,
          3547,
          17207,
          293,
          3869,
          1214,
          11,
          439,
          7527,
          295,
          661,
          1507,
          11,
          50764
        ]
      },
      {
        "avg_logprob": -0.21101485358344185,
        "compression_ratio": 1.7782101167315174,
        "end": 2012.22,
        "id": 548,
        "no_speech_prob": 0.0015487089985981584,
        "seek": 200122,
        "start": 2009.22,
        "temperature": 0,
        "text": " is this idea of a hidden layer.",
        "tokens": [
          50764,
          307,
          341,
          1558,
          295,
          257,
          7633,
          4583,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.21101485358344185,
        "compression_ratio": 1.7782101167315174,
        "end": 2016.22,
        "id": 549,
        "no_speech_prob": 0.0015487089985981584,
        "seek": 200122,
        "start": 2012.22,
        "temperature": 0,
        "text": " And there can be multiple hidden layer, there can be hidden layers of different nodes,",
        "tokens": [
          50914,
          400,
          456,
          393,
          312,
          3866,
          7633,
          4583,
          11,
          456,
          393,
          312,
          7633,
          7914,
          295,
          819,
          13891,
          11,
          51114
        ]
      },
      {
        "avg_logprob": -0.21101485358344185,
        "compression_ratio": 1.7782101167315174,
        "end": 2019.22,
        "id": 550,
        "no_speech_prob": 0.0015487089985981584,
        "seek": 200122,
        "start": 2016.22,
        "temperature": 0,
        "text": " but for the sake of argument, this is such an incredibly simple problem,",
        "tokens": [
          51114,
          457,
          337,
          264,
          9717,
          295,
          6770,
          11,
          341,
          307,
          1270,
          364,
          6252,
          2199,
          1154,
          11,
          51264
        ]
      },
      {
        "avg_logprob": -0.21101485358344185,
        "compression_ratio": 1.7782101167315174,
        "end": 2023.22,
        "id": 551,
        "no_speech_prob": 0.0015487089985981584,
        "seek": 200122,
        "start": 2019.22,
        "temperature": 0,
        "text": " who knows if we even need the hidden layer for it, we probably do,",
        "tokens": [
          51264,
          567,
          3255,
          498,
          321,
          754,
          643,
          264,
          7633,
          4583,
          337,
          309,
          11,
          321,
          1391,
          360,
          11,
          51464
        ]
      },
      {
        "avg_logprob": -0.21101485358344185,
        "compression_ratio": 1.7782101167315174,
        "end": 2027.22,
        "id": 552,
        "no_speech_prob": 0.0015487089985981584,
        "seek": 200122,
        "start": 2023.22,
        "temperature": 0,
        "text": " but we can just kind of pick something somewhat arbitrarily.",
        "tokens": [
          51464,
          457,
          321,
          393,
          445,
          733,
          295,
          1888,
          746,
          8344,
          19071,
          3289,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.20883460998535155,
        "compression_ratio": 1.8020304568527918,
        "end": 2030.22,
        "id": 553,
        "no_speech_prob": 0.008576671592891216,
        "seek": 202722,
        "start": 2027.22,
        "temperature": 0,
        "text": " So I'm going to say there are three inputs,",
        "tokens": [
          50364,
          407,
          286,
          478,
          516,
          281,
          584,
          456,
          366,
          1045,
          15743,
          11,
          50514
        ]
      },
      {
        "avg_logprob": -0.20883460998535155,
        "compression_ratio": 1.8020304568527918,
        "end": 2034.22,
        "id": 554,
        "no_speech_prob": 0.008576671592891216,
        "seek": 202722,
        "start": 2032.22,
        "temperature": 0,
        "text": " there are two outputs,",
        "tokens": [
          50614,
          456,
          366,
          732,
          23930,
          11,
          50714
        ]
      },
      {
        "avg_logprob": -0.20883460998535155,
        "compression_ratio": 1.8020304568527918,
        "end": 2040.22,
        "id": 555,
        "no_speech_prob": 0.008576671592891216,
        "seek": 202722,
        "start": 2035.22,
        "temperature": 0,
        "text": " and what I'm going to do is just say, this is what Jabril used, so why not use the same?",
        "tokens": [
          50764,
          293,
          437,
          286,
          478,
          516,
          281,
          360,
          307,
          445,
          584,
          11,
          341,
          307,
          437,
          40319,
          24216,
          1143,
          11,
          370,
          983,
          406,
          764,
          264,
          912,
          30,
          51014
        ]
      },
      {
        "avg_logprob": -0.20883460998535155,
        "compression_ratio": 1.8020304568527918,
        "end": 2042.22,
        "id": 556,
        "no_speech_prob": 0.008576671592891216,
        "seek": 202722,
        "start": 2040.22,
        "temperature": 0,
        "text": " I'm going to add three hidden nodes.",
        "tokens": [
          51014,
          286,
          478,
          516,
          281,
          909,
          1045,
          7633,
          13891,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.20883460998535155,
        "compression_ratio": 1.8020304568527918,
        "end": 2050.2200000000003,
        "id": 557,
        "no_speech_prob": 0.008576671592891216,
        "seek": 202722,
        "start": 2043.22,
        "temperature": 0,
        "text": " And the idea of a neural network is the inputs all go into each hidden node,",
        "tokens": [
          51164,
          400,
          264,
          1558,
          295,
          257,
          18161,
          3209,
          307,
          264,
          15743,
          439,
          352,
          666,
          1184,
          7633,
          9984,
          11,
          51514
        ]
      },
      {
        "avg_logprob": -0.20883460998535155,
        "compression_ratio": 1.8020304568527918,
        "end": 2052.2200000000003,
        "id": 558,
        "no_speech_prob": 0.008576671592891216,
        "seek": 202722,
        "start": 2050.2200000000003,
        "temperature": 0,
        "text": " they get processed by the hidden node,",
        "tokens": [
          51514,
          436,
          483,
          18846,
          538,
          264,
          7633,
          9984,
          11,
          51614
        ]
      },
      {
        "avg_logprob": -0.20883460998535155,
        "compression_ratio": 1.8020304568527918,
        "end": 2055.2200000000003,
        "id": 559,
        "no_speech_prob": 0.008576671592891216,
        "seek": 202722,
        "start": 2052.2200000000003,
        "temperature": 0,
        "text": " and each hidden node connects to every output,",
        "tokens": [
          51614,
          293,
          1184,
          7633,
          9984,
          16967,
          281,
          633,
          5598,
          11,
          51764
        ]
      },
      {
        "avg_logprob": -0.203918845790207,
        "compression_ratio": 1.728658536585366,
        "end": 2058.22,
        "id": 560,
        "no_speech_prob": 0.0012842633295804262,
        "seek": 205522,
        "start": 2055.22,
        "temperature": 0,
        "text": " whoops, I did that, and then they get processed by the outputs,",
        "tokens": [
          50364,
          567,
          3370,
          11,
          286,
          630,
          300,
          11,
          293,
          550,
          436,
          483,
          18846,
          538,
          264,
          23930,
          11,
          50514
        ]
      },
      {
        "avg_logprob": -0.203918845790207,
        "compression_ratio": 1.728658536585366,
        "end": 2059.22,
        "id": 561,
        "no_speech_prob": 0.0012842633295804262,
        "seek": 205522,
        "start": 2058.22,
        "temperature": 0,
        "text": " and we get the results.",
        "tokens": [
          50514,
          293,
          321,
          483,
          264,
          3542,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.203918845790207,
        "compression_ratio": 1.728658536585366,
        "end": 2061.22,
        "id": 562,
        "no_speech_prob": 0.0012842633295804262,
        "seek": 205522,
        "start": 2059.22,
        "temperature": 0,
        "text": " That's known as feedforward.",
        "tokens": [
          50564,
          663,
          311,
          2570,
          382,
          3154,
          13305,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.203918845790207,
        "compression_ratio": 1.728658536585366,
        "end": 2063.22,
        "id": 563,
        "no_speech_prob": 0.0012842633295804262,
        "seek": 205522,
        "start": 2061.22,
        "temperature": 0,
        "text": " What is that processing?",
        "tokens": [
          50664,
          708,
          307,
          300,
          9007,
          30,
          50764
        ]
      },
      {
        "avg_logprob": -0.203918845790207,
        "compression_ratio": 1.728658536585366,
        "end": 2065.22,
        "id": 564,
        "no_speech_prob": 0.0012842633295804262,
        "seek": 205522,
        "start": 2063.22,
        "temperature": 0,
        "text": " It has to do with the weights of the connections,",
        "tokens": [
          50764,
          467,
          575,
          281,
          360,
          365,
          264,
          17443,
          295,
          264,
          9271,
          11,
          50864
        ]
      },
      {
        "avg_logprob": -0.203918845790207,
        "compression_ratio": 1.728658536585366,
        "end": 2068.22,
        "id": 565,
        "no_speech_prob": 0.0012842633295804262,
        "seek": 205522,
        "start": 2065.22,
        "temperature": 0,
        "text": " the summing of the values, the activation of the neural network.",
        "tokens": [
          50864,
          264,
          2408,
          2810,
          295,
          264,
          4190,
          11,
          264,
          24433,
          295,
          264,
          18161,
          3209,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.203918845790207,
        "compression_ratio": 1.728658536585366,
        "end": 2071.22,
        "id": 566,
        "no_speech_prob": 0.0012842633295804262,
        "seek": 205522,
        "start": 2068.22,
        "temperature": 0,
        "text": " I think at this point, it probably makes more sense for me to refer you",
        "tokens": [
          51014,
          286,
          519,
          412,
          341,
          935,
          11,
          309,
          1391,
          1669,
          544,
          2020,
          337,
          385,
          281,
          2864,
          291,
          51164
        ]
      },
      {
        "avg_logprob": -0.203918845790207,
        "compression_ratio": 1.728658536585366,
        "end": 2074.22,
        "id": 567,
        "no_speech_prob": 0.0012842633295804262,
        "seek": 205522,
        "start": 2071.22,
        "temperature": 0,
        "text": " to my other tutorials that go through the mechanics of this.",
        "tokens": [
          51164,
          281,
          452,
          661,
          17616,
          300,
          352,
          807,
          264,
          12939,
          295,
          341,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.203918845790207,
        "compression_ratio": 1.728658536585366,
        "end": 2078.22,
        "id": 568,
        "no_speech_prob": 0.0012842633295804262,
        "seek": 205522,
        "start": 2074.22,
        "temperature": 0,
        "text": " I just want to now use it in a sort of higher level way,",
        "tokens": [
          51314,
          286,
          445,
          528,
          281,
          586,
          764,
          309,
          294,
          257,
          1333,
          295,
          2946,
          1496,
          636,
          11,
          51514
        ]
      },
      {
        "avg_logprob": -0.203918845790207,
        "compression_ratio": 1.728658536585366,
        "end": 2082.22,
        "id": 569,
        "no_speech_prob": 0.0012842633295804262,
        "seek": 205522,
        "start": 2078.22,
        "temperature": 0,
        "text": " as a library where I'm going to send in my inputs and look at the outputs.",
        "tokens": [
          51514,
          382,
          257,
          6405,
          689,
          286,
          478,
          516,
          281,
          2845,
          294,
          452,
          15743,
          293,
          574,
          412,
          264,
          23930,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.203918845790207,
        "compression_ratio": 1.728658536585366,
        "end": 2084.22,
        "id": 570,
        "no_speech_prob": 0.0012842633295804262,
        "seek": 205522,
        "start": 2082.22,
        "temperature": 0,
        "text": " And of course, I'm going to have to train it.",
        "tokens": [
          51714,
          400,
          295,
          1164,
          11,
          286,
          478,
          516,
          281,
          362,
          281,
          3847,
          309,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.19936736611758962,
        "compression_ratio": 1.5023696682464456,
        "end": 2088.22,
        "id": 571,
        "no_speech_prob": 0.000984988990239799,
        "seek": 208422,
        "start": 2084.22,
        "temperature": 0,
        "text": " I'm going to have to teach the neural network to give me certain outputs that I want.",
        "tokens": [
          50364,
          286,
          478,
          516,
          281,
          362,
          281,
          2924,
          264,
          18161,
          3209,
          281,
          976,
          385,
          1629,
          23930,
          300,
          286,
          528,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.19936736611758962,
        "compression_ratio": 1.5023696682464456,
        "end": 2092.22,
        "id": 572,
        "no_speech_prob": 0.000984988990239799,
        "seek": 208422,
        "start": 2088.22,
        "temperature": 0,
        "text": " So that's what I'm going to get into when I go and write the code right now.",
        "tokens": [
          50564,
          407,
          300,
          311,
          437,
          286,
          478,
          516,
          281,
          483,
          666,
          562,
          286,
          352,
          293,
          2464,
          264,
          3089,
          558,
          586,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.19936736611758962,
        "compression_ratio": 1.5023696682464456,
        "end": 2102.22,
        "id": 573,
        "no_speech_prob": 0.000984988990239799,
        "seek": 208422,
        "start": 2098.22,
        "temperature": 0,
        "text": " Okay, boy, how was that, like half an hour?",
        "tokens": [
          51064,
          1033,
          11,
          3237,
          11,
          577,
          390,
          300,
          11,
          411,
          1922,
          364,
          1773,
          30,
          51264
        ]
      },
      {
        "avg_logprob": -0.19936736611758962,
        "compression_ratio": 1.5023696682464456,
        "end": 2105.22,
        "id": 574,
        "no_speech_prob": 0.000984988990239799,
        "seek": 208422,
        "start": 2103.22,
        "temperature": 0,
        "text": " But I kind of wanted to make that explanation,",
        "tokens": [
          51314,
          583,
          286,
          733,
          295,
          1415,
          281,
          652,
          300,
          10835,
          11,
          51414
        ]
      },
      {
        "avg_logprob": -0.19936736611758962,
        "compression_ratio": 1.5023696682464456,
        "end": 2110.22,
        "id": 575,
        "no_speech_prob": 0.000984988990239799,
        "seek": 208422,
        "start": 2105.22,
        "temperature": 0,
        "text": " because I feel like people say universal function approximator,",
        "tokens": [
          51414,
          570,
          286,
          841,
          411,
          561,
          584,
          11455,
          2445,
          8542,
          1639,
          11,
          51664
        ]
      },
      {
        "avg_logprob": -0.16593053605821398,
        "compression_ratio": 1.5720338983050848,
        "end": 2114.22,
        "id": 576,
        "no_speech_prob": 0.0015486334450542927,
        "seek": 211022,
        "start": 2110.22,
        "temperature": 0,
        "text": " I hear that all the time, and I wanted to make some sort of connection",
        "tokens": [
          50364,
          286,
          1568,
          300,
          439,
          264,
          565,
          11,
          293,
          286,
          1415,
          281,
          652,
          512,
          1333,
          295,
          4984,
          50564
        ]
      },
      {
        "avg_logprob": -0.16593053605821398,
        "compression_ratio": 1.5720338983050848,
        "end": 2115.22,
        "id": 577,
        "no_speech_prob": 0.0015486334450542927,
        "seek": 211022,
        "start": 2114.22,
        "temperature": 0,
        "text": " of what that actually means.",
        "tokens": [
          50564,
          295,
          437,
          300,
          767,
          1355,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.16593053605821398,
        "compression_ratio": 1.5720338983050848,
        "end": 2116.22,
        "id": 578,
        "no_speech_prob": 0.0015486334450542927,
        "seek": 211022,
        "start": 2115.22,
        "temperature": 0,
        "text": " Was that helpful?",
        "tokens": [
          50614,
          3027,
          300,
          4961,
          30,
          50664
        ]
      },
      {
        "avg_logprob": -0.16593053605821398,
        "compression_ratio": 1.5720338983050848,
        "end": 2118.22,
        "id": 579,
        "no_speech_prob": 0.0015486334450542927,
        "seek": 211022,
        "start": 2116.22,
        "temperature": 0,
        "text": " Give me a little feedback here before I move on.",
        "tokens": [
          50664,
          5303,
          385,
          257,
          707,
          5824,
          510,
          949,
          286,
          1286,
          322,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.16593053605821398,
        "compression_ratio": 1.5720338983050848,
        "end": 2120.22,
        "id": 580,
        "no_speech_prob": 0.0015486334450542927,
        "seek": 211022,
        "start": 2118.22,
        "temperature": 0,
        "text": " Should this now be part two?",
        "tokens": [
          50764,
          6454,
          341,
          586,
          312,
          644,
          732,
          30,
          50864
        ]
      },
      {
        "avg_logprob": -0.16593053605821398,
        "compression_ratio": 1.5720338983050848,
        "end": 2121.22,
        "id": 581,
        "no_speech_prob": 0.0015486334450542927,
        "seek": 211022,
        "start": 2120.22,
        "temperature": 0,
        "text": " I don't think so.",
        "tokens": [
          50864,
          286,
          500,
          380,
          519,
          370,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.16593053605821398,
        "compression_ratio": 1.5720338983050848,
        "end": 2124.22,
        "id": 582,
        "no_speech_prob": 0.0015486334450542927,
        "seek": 211022,
        "start": 2121.22,
        "temperature": 0,
        "text": " I think this can all still be in one video.",
        "tokens": [
          50914,
          286,
          519,
          341,
          393,
          439,
          920,
          312,
          294,
          472,
          960,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.16593053605821398,
        "compression_ratio": 1.5720338983050848,
        "end": 2134.22,
        "id": 583,
        "no_speech_prob": 0.0015486334450542927,
        "seek": 211022,
        "start": 2130.22,
        "temperature": 0,
        "text": " And by the way, I really should be adding Softmax to my neural network library,",
        "tokens": [
          51364,
          400,
          538,
          264,
          636,
          11,
          286,
          534,
          820,
          312,
          5127,
          16985,
          41167,
          281,
          452,
          18161,
          3209,
          6405,
          11,
          51564
        ]
      },
      {
        "avg_logprob": -0.16593053605821398,
        "compression_ratio": 1.5720338983050848,
        "end": 2136.22,
        "id": 584,
        "no_speech_prob": 0.0015486334450542927,
        "seek": 211022,
        "start": 2134.22,
        "temperature": 0,
        "text": " but I don't have time to do that.",
        "tokens": [
          51564,
          457,
          286,
          500,
          380,
          362,
          565,
          281,
          360,
          300,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.15688492766523784,
        "compression_ratio": 1.5735294117647058,
        "end": 2143.22,
        "id": 585,
        "no_speech_prob": 0.00011959745461354032,
        "seek": 214022,
        "start": 2141.22,
        "temperature": 0,
        "text": " Oh, yes, yes, yes, yes, yes.",
        "tokens": [
          50414,
          876,
          11,
          2086,
          11,
          2086,
          11,
          2086,
          11,
          2086,
          11,
          2086,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.15688492766523784,
        "compression_ratio": 1.5735294117647058,
        "end": 2144.22,
        "id": 586,
        "no_speech_prob": 0.00011959745461354032,
        "seek": 214022,
        "start": 2143.22,
        "temperature": 0,
        "text": " The normalization.",
        "tokens": [
          50514,
          440,
          2710,
          2144,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.15688492766523784,
        "compression_ratio": 1.5735294117647058,
        "end": 2146.22,
        "id": 587,
        "no_speech_prob": 0.00011959745461354032,
        "seek": 214022,
        "start": 2144.22,
        "temperature": 0,
        "text": " So that will come up.",
        "tokens": [
          50564,
          407,
          300,
          486,
          808,
          493,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.15688492766523784,
        "compression_ratio": 1.5735294117647058,
        "end": 2148.22,
        "id": 588,
        "no_speech_prob": 0.00011959745461354032,
        "seek": 214022,
        "start": 2146.22,
        "temperature": 0,
        "text": " I should have mentioned that here.",
        "tokens": [
          50664,
          286,
          820,
          362,
          2835,
          300,
          510,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.15688492766523784,
        "compression_ratio": 1.5735294117647058,
        "end": 2151.22,
        "id": 589,
        "no_speech_prob": 0.00011959745461354032,
        "seek": 214022,
        "start": 2148.22,
        "temperature": 0,
        "text": " Thank you for pointing that out, but I'll just have to get to that",
        "tokens": [
          50764,
          1044,
          291,
          337,
          12166,
          300,
          484,
          11,
          457,
          286,
          603,
          445,
          362,
          281,
          483,
          281,
          300,
          50914
        ]
      },
      {
        "avg_logprob": -0.15688492766523784,
        "compression_ratio": 1.5735294117647058,
        "end": 2152.22,
        "id": 590,
        "no_speech_prob": 0.00011959745461354032,
        "seek": 214022,
        "start": 2151.22,
        "temperature": 0,
        "text": " when I start doing the coding.",
        "tokens": [
          50914,
          562,
          286,
          722,
          884,
          264,
          17720,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.15688492766523784,
        "compression_ratio": 1.5735294117647058,
        "end": 2153.22,
        "id": 591,
        "no_speech_prob": 0.00011959745461354032,
        "seek": 214022,
        "start": 2152.22,
        "temperature": 0,
        "text": " That will come up.",
        "tokens": [
          50964,
          663,
          486,
          808,
          493,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.15688492766523784,
        "compression_ratio": 1.5735294117647058,
        "end": 2158.22,
        "id": 592,
        "no_speech_prob": 0.00011959745461354032,
        "seek": 214022,
        "start": 2157.22,
        "temperature": 0,
        "text": " All right.",
        "tokens": [
          51214,
          1057,
          558,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.15688492766523784,
        "compression_ratio": 1.5735294117647058,
        "end": 2160.22,
        "id": 593,
        "no_speech_prob": 0.00011959745461354032,
        "seek": 214022,
        "start": 2158.22,
        "temperature": 0,
        "text": " What time are we at?",
        "tokens": [
          51264,
          708,
          565,
          366,
          321,
          412,
          30,
          51364
        ]
      },
      {
        "avg_logprob": -0.15688492766523784,
        "compression_ratio": 1.5735294117647058,
        "end": 2161.22,
        "id": 594,
        "no_speech_prob": 0.00011959745461354032,
        "seek": 214022,
        "start": 2160.22,
        "temperature": 0,
        "text": " 12.06.",
        "tokens": [
          51364,
          2272,
          13,
          12791,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.15688492766523784,
        "compression_ratio": 1.5735294117647058,
        "end": 2163.22,
        "id": 595,
        "no_speech_prob": 0.00011959745461354032,
        "seek": 214022,
        "start": 2161.22,
        "temperature": 0,
        "text": " Ah, that's a lot of time.",
        "tokens": [
          51414,
          2438,
          11,
          300,
          311,
          257,
          688,
          295,
          565,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.15688492766523784,
        "compression_ratio": 1.5735294117647058,
        "end": 2166.22,
        "id": 596,
        "no_speech_prob": 0.00011959745461354032,
        "seek": 214022,
        "start": 2163.22,
        "temperature": 0,
        "text": " Let me do a little camera cycling.",
        "tokens": [
          51514,
          961,
          385,
          360,
          257,
          707,
          2799,
          22425,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.15367497624577703,
        "compression_ratio": 1.6008771929824561,
        "end": 2170.22,
        "id": 597,
        "no_speech_prob": 0.020022695884108543,
        "seek": 216622,
        "start": 2167.22,
        "temperature": 0,
        "text": " Maybe if I had time in between during lunch today,",
        "tokens": [
          50414,
          2704,
          498,
          286,
          632,
          565,
          294,
          1296,
          1830,
          6349,
          965,
          11,
          50564
        ]
      },
      {
        "avg_logprob": -0.15367497624577703,
        "compression_ratio": 1.6008771929824561,
        "end": 2177.22,
        "id": 598,
        "no_speech_prob": 0.020022695884108543,
        "seek": 216622,
        "start": 2170.22,
        "temperature": 0,
        "text": " if I had time to try to install that firmware to fix the camera finally.",
        "tokens": [
          50564,
          498,
          286,
          632,
          565,
          281,
          853,
          281,
          3625,
          300,
          30289,
          281,
          3191,
          264,
          2799,
          2721,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.15367497624577703,
        "compression_ratio": 1.6008771929824561,
        "end": 2179.22,
        "id": 599,
        "no_speech_prob": 0.020022695884108543,
        "seek": 216622,
        "start": 2177.22,
        "temperature": 0,
        "text": " Oh, that was only eight minutes at the whiteboard?",
        "tokens": [
          50914,
          876,
          11,
          300,
          390,
          787,
          3180,
          2077,
          412,
          264,
          2418,
          3787,
          30,
          51014
        ]
      },
      {
        "avg_logprob": -0.15367497624577703,
        "compression_ratio": 1.6008771929824561,
        "end": 2180.22,
        "id": 600,
        "no_speech_prob": 0.020022695884108543,
        "seek": 216622,
        "start": 2179.22,
        "temperature": 0,
        "text": " Oh, that's not bad at all.",
        "tokens": [
          51014,
          876,
          11,
          300,
          311,
          406,
          1578,
          412,
          439,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.15367497624577703,
        "compression_ratio": 1.6008771929824561,
        "end": 2181.22,
        "id": 601,
        "no_speech_prob": 0.020022695884108543,
        "seek": 216622,
        "start": 2180.22,
        "temperature": 0,
        "text": " That's fine.",
        "tokens": [
          51064,
          663,
          311,
          2489,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.15367497624577703,
        "compression_ratio": 1.6008771929824561,
        "end": 2184.22,
        "id": 602,
        "no_speech_prob": 0.020022695884108543,
        "seek": 216622,
        "start": 2181.22,
        "temperature": 0,
        "text": " Okay, great.",
        "tokens": [
          51114,
          1033,
          11,
          869,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.15367497624577703,
        "compression_ratio": 1.6008771929824561,
        "end": 2185.22,
        "id": 603,
        "no_speech_prob": 0.020022695884108543,
        "seek": 216622,
        "start": 2184.22,
        "temperature": 0,
        "text": " Oh, yeah.",
        "tokens": [
          51264,
          876,
          11,
          1338,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.15367497624577703,
        "compression_ratio": 1.6008771929824561,
        "end": 2187.22,
        "id": 604,
        "no_speech_prob": 0.020022695884108543,
        "seek": 216622,
        "start": 2185.22,
        "temperature": 0,
        "text": " Tim, I apologize.",
        "tokens": [
          51314,
          7172,
          11,
          286,
          12328,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.15367497624577703,
        "compression_ratio": 1.6008771929824561,
        "end": 2191.22,
        "id": 605,
        "no_speech_prob": 0.020022695884108543,
        "seek": 216622,
        "start": 2187.22,
        "temperature": 0,
        "text": " So let me just touch on this for a second because this is a really good question.",
        "tokens": [
          51414,
          407,
          718,
          385,
          445,
          2557,
          322,
          341,
          337,
          257,
          1150,
          570,
          341,
          307,
          257,
          534,
          665,
          1168,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.15367497624577703,
        "compression_ratio": 1.6008771929824561,
        "end": 2193.22,
        "id": 606,
        "no_speech_prob": 0.020022695884108543,
        "seek": 216622,
        "start": 2191.22,
        "temperature": 0,
        "text": " I have to really apologize.",
        "tokens": [
          51614,
          286,
          362,
          281,
          534,
          12328,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.199431341521594,
        "compression_ratio": 1.550387596899225,
        "end": 2197.22,
        "id": 607,
        "no_speech_prob": 0.06371045857667923,
        "seek": 219322,
        "start": 2194.22,
        "temperature": 0,
        "text": " I did not expect – I mean, maybe I should have.",
        "tokens": [
          50414,
          286,
          630,
          406,
          2066,
          220,
          5815,
          286,
          914,
          11,
          1310,
          286,
          820,
          362,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.199431341521594,
        "compression_ratio": 1.550387596899225,
        "end": 2204.22,
        "id": 608,
        "no_speech_prob": 0.06371045857667923,
        "seek": 219322,
        "start": 2197.22,
        "temperature": 0,
        "text": " I sometimes don't realize that the audience for this channel is kind of large.",
        "tokens": [
          50564,
          286,
          2171,
          500,
          380,
          4325,
          300,
          264,
          4034,
          337,
          341,
          2269,
          307,
          733,
          295,
          2416,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.199431341521594,
        "compression_ratio": 1.550387596899225,
        "end": 2207.22,
        "id": 609,
        "no_speech_prob": 0.06371045857667923,
        "seek": 219322,
        "start": 2204.22,
        "temperature": 0,
        "text": " And when I release something, people really are excited to contribute,",
        "tokens": [
          50914,
          400,
          562,
          286,
          4374,
          746,
          11,
          561,
          534,
          366,
          2919,
          281,
          10586,
          11,
          51064
        ]
      },
      {
        "avg_logprob": -0.199431341521594,
        "compression_ratio": 1.550387596899225,
        "end": 2213.22,
        "id": 610,
        "no_speech_prob": 0.06371045857667923,
        "seek": 219322,
        "start": 2207.22,
        "temperature": 0,
        "text": " and there are currently 32 outstanding pull requests here on this neural network library.",
        "tokens": [
          51064,
          293,
          456,
          366,
          4362,
          8858,
          14485,
          2235,
          12475,
          510,
          322,
          341,
          18161,
          3209,
          6405,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.199431341521594,
        "compression_ratio": 1.550387596899225,
        "end": 2219.22,
        "id": 611,
        "no_speech_prob": 0.06371045857667923,
        "seek": 219322,
        "start": 2213.22,
        "temperature": 0,
        "text": " I just honestly haven't really had the time to go through them,",
        "tokens": [
          51364,
          286,
          445,
          6095,
          2378,
          380,
          534,
          632,
          264,
          565,
          281,
          352,
          807,
          552,
          11,
          51664
        ]
      },
      {
        "avg_logprob": -0.199431341521594,
        "compression_ratio": 1.550387596899225,
        "end": 2221.22,
        "id": 612,
        "no_speech_prob": 0.06371045857667923,
        "seek": 219322,
        "start": 2219.22,
        "temperature": 0,
        "text": " and I also want to add some stuff to it first.",
        "tokens": [
          51664,
          293,
          286,
          611,
          528,
          281,
          909,
          512,
          1507,
          281,
          309,
          700,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.17831985155741373,
        "compression_ratio": 1.3762376237623761,
        "end": 2224.22,
        "id": 613,
        "no_speech_prob": 0.050328489392995834,
        "seek": 222122,
        "start": 2221.22,
        "temperature": 0,
        "text": " I really appreciate all of these contributions,",
        "tokens": [
          50364,
          286,
          534,
          4449,
          439,
          295,
          613,
          15725,
          11,
          50514
        ]
      },
      {
        "avg_logprob": -0.17831985155741373,
        "compression_ratio": 1.3762376237623761,
        "end": 2228.22,
        "id": 614,
        "no_speech_prob": 0.050328489392995834,
        "seek": 222122,
        "start": 2224.22,
        "temperature": 0,
        "text": " and I've got to figure out a way to manage that.",
        "tokens": [
          50514,
          293,
          286,
          600,
          658,
          281,
          2573,
          484,
          257,
          636,
          281,
          3067,
          300,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.17831985155741373,
        "compression_ratio": 1.3762376237623761,
        "end": 2231.22,
        "id": 615,
        "no_speech_prob": 0.050328489392995834,
        "seek": 222122,
        "start": 2228.22,
        "temperature": 0,
        "text": " The truth of the matter is I just don't really have one right now.",
        "tokens": [
          50714,
          440,
          3494,
          295,
          264,
          1871,
          307,
          286,
          445,
          500,
          380,
          534,
          362,
          472,
          558,
          586,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.17831985155741373,
        "compression_ratio": 1.3762376237623761,
        "end": 2236.22,
        "id": 616,
        "no_speech_prob": 0.050328489392995834,
        "seek": 222122,
        "start": 2231.22,
        "temperature": 0,
        "text": " Coding Challenge 100 should be fixing the camera.",
        "tokens": [
          50864,
          383,
          8616,
          17517,
          2319,
          820,
          312,
          19442,
          264,
          2799,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.17831985155741373,
        "compression_ratio": 1.3762376237623761,
        "end": 2238.22,
        "id": 617,
        "no_speech_prob": 0.050328489392995834,
        "seek": 222122,
        "start": 2236.22,
        "temperature": 0,
        "text": " That's good.",
        "tokens": [
          51114,
          663,
          311,
          665,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.17831985155741373,
        "compression_ratio": 1.3762376237623761,
        "end": 2240.22,
        "id": 618,
        "no_speech_prob": 0.050328489392995834,
        "seek": 222122,
        "start": 2238.22,
        "temperature": 0,
        "text": " Get a bell for that.",
        "tokens": [
          51214,
          3240,
          257,
          4549,
          337,
          300,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.17831985155741373,
        "compression_ratio": 1.3762376237623761,
        "end": 2246.22,
        "id": 619,
        "no_speech_prob": 0.050328489392995834,
        "seek": 222122,
        "start": 2240.22,
        "temperature": 0,
        "text": " All right.",
        "tokens": [
          51314,
          1057,
          558,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.17831985155741373,
        "compression_ratio": 1.3762376237623761,
        "end": 2250.22,
        "id": 620,
        "no_speech_prob": 0.050328489392995834,
        "seek": 222122,
        "start": 2246.22,
        "temperature": 0,
        "text": " Okay, so let me –",
        "tokens": [
          51614,
          1033,
          11,
          370,
          718,
          385,
          1662,
          51814
        ]
      },
      {
        "avg_logprob": -0.16367331795070483,
        "compression_ratio": 1.565040650406504,
        "end": 2253.22,
        "id": 621,
        "no_speech_prob": 0.0005792795564047992,
        "seek": 225022,
        "start": 2250.22,
        "temperature": 0,
        "text": " all right, all right.",
        "tokens": [
          50364,
          439,
          558,
          11,
          439,
          558,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.16367331795070483,
        "compression_ratio": 1.565040650406504,
        "end": 2254.22,
        "id": 622,
        "no_speech_prob": 0.0005792795564047992,
        "seek": 225022,
        "start": 2253.22,
        "temperature": 0,
        "text": " There's a lot of messages retracted.",
        "tokens": [
          50514,
          821,
          311,
          257,
          688,
          295,
          7897,
          41107,
          292,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.16367331795070483,
        "compression_ratio": 1.565040650406504,
        "end": 2255.22,
        "id": 623,
        "no_speech_prob": 0.0005792795564047992,
        "seek": 225022,
        "start": 2254.22,
        "temperature": 0,
        "text": " I don't know what that means.",
        "tokens": [
          50564,
          286,
          500,
          380,
          458,
          437,
          300,
          1355,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.16367331795070483,
        "compression_ratio": 1.565040650406504,
        "end": 2259.22,
        "id": 624,
        "no_speech_prob": 0.0005792795564047992,
        "seek": 225022,
        "start": 2255.22,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          50614,
          1033,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.16367331795070483,
        "compression_ratio": 1.565040650406504,
        "end": 2262.22,
        "id": 625,
        "no_speech_prob": 0.0005792795564047992,
        "seek": 225022,
        "start": 2259.22,
        "temperature": 0,
        "text": " Okay, so first let's take a look at Jabril's code.",
        "tokens": [
          50814,
          1033,
          11,
          370,
          700,
          718,
          311,
          747,
          257,
          574,
          412,
          40319,
          24216,
          311,
          3089,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.16367331795070483,
        "compression_ratio": 1.565040650406504,
        "end": 2264.22,
        "id": 626,
        "no_speech_prob": 0.0005792795564047992,
        "seek": 225022,
        "start": 2262.22,
        "temperature": 0,
        "text": " He might have a newer version by now,",
        "tokens": [
          50964,
          634,
          1062,
          362,
          257,
          17628,
          3037,
          538,
          586,
          11,
          51064
        ]
      },
      {
        "avg_logprob": -0.16367331795070483,
        "compression_ratio": 1.565040650406504,
        "end": 2268.22,
        "id": 627,
        "no_speech_prob": 0.0005792795564047992,
        "seek": 225022,
        "start": 2264.22,
        "temperature": 0,
        "text": " but this is what he demonstrated last week on the coding train.",
        "tokens": [
          51064,
          457,
          341,
          307,
          437,
          415,
          18772,
          1036,
          1243,
          322,
          264,
          17720,
          3847,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.16367331795070483,
        "compression_ratio": 1.565040650406504,
        "end": 2272.22,
        "id": 628,
        "no_speech_prob": 0.0005792795564047992,
        "seek": 225022,
        "start": 2268.22,
        "temperature": 0,
        "text": " So I could say, like, oh, I think white looks better on this color.",
        "tokens": [
          51264,
          407,
          286,
          727,
          584,
          11,
          411,
          11,
          1954,
          11,
          286,
          519,
          2418,
          1542,
          1101,
          322,
          341,
          2017,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.16367331795070483,
        "compression_ratio": 1.565040650406504,
        "end": 2279.22,
        "id": 629,
        "no_speech_prob": 0.0005792795564047992,
        "seek": 225022,
        "start": 2272.22,
        "temperature": 0,
        "text": " By the way, I have no ability or talent for visual design whatsoever,",
        "tokens": [
          51464,
          3146,
          264,
          636,
          11,
          286,
          362,
          572,
          3485,
          420,
          8301,
          337,
          5056,
          1715,
          17076,
          11,
          51814
        ]
      },
      {
        "avg_logprob": -0.16875750058657163,
        "compression_ratio": 1.8466666666666667,
        "end": 2280.22,
        "id": 630,
        "no_speech_prob": 0.003593544941395521,
        "seek": 227922,
        "start": 2279.22,
        "temperature": 0,
        "text": " so I'm going to get all this wrong.",
        "tokens": [
          50364,
          370,
          286,
          478,
          516,
          281,
          483,
          439,
          341,
          2085,
          13,
          50414
        ]
      },
      {
        "avg_logprob": -0.16875750058657163,
        "compression_ratio": 1.8466666666666667,
        "end": 2281.22,
        "id": 631,
        "no_speech_prob": 0.003593544941395521,
        "seek": 227922,
        "start": 2280.22,
        "temperature": 0,
        "text": " I don't know.",
        "tokens": [
          50414,
          286,
          500,
          380,
          458,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.16875750058657163,
        "compression_ratio": 1.8466666666666667,
        "end": 2282.22,
        "id": 632,
        "no_speech_prob": 0.003593544941395521,
        "seek": 227922,
        "start": 2281.22,
        "temperature": 0,
        "text": " Black looks better.",
        "tokens": [
          50464,
          4076,
          1542,
          1101,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.16875750058657163,
        "compression_ratio": 1.8466666666666667,
        "end": 2283.22,
        "id": 633,
        "no_speech_prob": 0.003593544941395521,
        "seek": 227922,
        "start": 2282.22,
        "temperature": 0,
        "text": " Black looks better.",
        "tokens": [
          50514,
          4076,
          1542,
          1101,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.16875750058657163,
        "compression_ratio": 1.8466666666666667,
        "end": 2284.22,
        "id": 634,
        "no_speech_prob": 0.003593544941395521,
        "seek": 227922,
        "start": 2283.22,
        "temperature": 0,
        "text": " White looks better.",
        "tokens": [
          50564,
          5552,
          1542,
          1101,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.16875750058657163,
        "compression_ratio": 1.8466666666666667,
        "end": 2286.22,
        "id": 635,
        "no_speech_prob": 0.003593544941395521,
        "seek": 227922,
        "start": 2284.22,
        "temperature": 0,
        "text": " So you can see this is me active.",
        "tokens": [
          50614,
          407,
          291,
          393,
          536,
          341,
          307,
          385,
          4967,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.16875750058657163,
        "compression_ratio": 1.8466666666666667,
        "end": 2292.22,
        "id": 636,
        "no_speech_prob": 0.003593544941395521,
        "seek": 227922,
        "start": 2286.22,
        "temperature": 0,
        "text": " This dot represents the computer guessing which ones it thinks it should be,",
        "tokens": [
          50714,
          639,
          5893,
          8855,
          264,
          3820,
          17939,
          597,
          2306,
          309,
          7309,
          309,
          820,
          312,
          11,
          51014
        ]
      },
      {
        "avg_logprob": -0.16875750058657163,
        "compression_ratio": 1.8466666666666667,
        "end": 2297.22,
        "id": 637,
        "no_speech_prob": 0.003593544941395521,
        "seek": 227922,
        "start": 2292.22,
        "temperature": 0,
        "text": " and me clicking has to do with me giving this sort of, like, training information,",
        "tokens": [
          51014,
          293,
          385,
          9697,
          575,
          281,
          360,
          365,
          385,
          2902,
          341,
          1333,
          295,
          11,
          411,
          11,
          3097,
          1589,
          11,
          51264
        ]
      },
      {
        "avg_logprob": -0.16875750058657163,
        "compression_ratio": 1.8466666666666667,
        "end": 2299.22,
        "id": 638,
        "no_speech_prob": 0.003593544941395521,
        "seek": 227922,
        "start": 2297.22,
        "temperature": 0,
        "text": " like, hey, neural network, it should be this one.",
        "tokens": [
          51264,
          411,
          11,
          4177,
          11,
          18161,
          3209,
          11,
          309,
          820,
          312,
          341,
          472,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.16875750058657163,
        "compression_ratio": 1.8466666666666667,
        "end": 2301.22,
        "id": 639,
        "no_speech_prob": 0.003593544941395521,
        "seek": 227922,
        "start": 2299.22,
        "temperature": 0,
        "text": " So I'm going to go through and build all the pieces of this.",
        "tokens": [
          51364,
          407,
          286,
          478,
          516,
          281,
          352,
          807,
          293,
          1322,
          439,
          264,
          3755,
          295,
          341,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.16875750058657163,
        "compression_ratio": 1.8466666666666667,
        "end": 2305.22,
        "id": 640,
        "no_speech_prob": 0.003593544941395521,
        "seek": 227922,
        "start": 2301.22,
        "temperature": 0,
        "text": " There's some other stuff going on in here where Jabril is using a genetic algorithm,",
        "tokens": [
          51464,
          821,
          311,
          512,
          661,
          1507,
          516,
          322,
          294,
          510,
          689,
          40319,
          24216,
          307,
          1228,
          257,
          12462,
          9284,
          11,
          51664
        ]
      },
      {
        "avg_logprob": -0.16875750058657163,
        "compression_ratio": 1.8466666666666667,
        "end": 2307.22,
        "id": 641,
        "no_speech_prob": 0.003593544941395521,
        "seek": 227922,
        "start": 2305.22,
        "temperature": 0,
        "text": " and there's, like, this sort of voting thing going on,",
        "tokens": [
          51664,
          293,
          456,
          311,
          11,
          411,
          11,
          341,
          1333,
          295,
          10419,
          551,
          516,
          322,
          11,
          51764
        ]
      },
      {
        "avg_logprob": -0.20328029833341899,
        "compression_ratio": 1.6141078838174274,
        "end": 2310.22,
        "id": 642,
        "no_speech_prob": 0.006192766595631838,
        "seek": 230722,
        "start": 2307.22,
        "temperature": 0,
        "text": " but let's just start building some code from scratch,",
        "tokens": [
          50364,
          457,
          718,
          311,
          445,
          722,
          2390,
          512,
          3089,
          490,
          8459,
          11,
          50514
        ]
      },
      {
        "avg_logprob": -0.20328029833341899,
        "compression_ratio": 1.6141078838174274,
        "end": 2312.22,
        "id": 643,
        "no_speech_prob": 0.006192766595631838,
        "seek": 230722,
        "start": 2310.22,
        "temperature": 0,
        "text": " and we can kind of compare and contrast.",
        "tokens": [
          50514,
          293,
          321,
          393,
          733,
          295,
          6794,
          293,
          8712,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.20328029833341899,
        "compression_ratio": 1.6141078838174274,
        "end": 2314.22,
        "id": 644,
        "no_speech_prob": 0.006192766595631838,
        "seek": 230722,
        "start": 2312.22,
        "temperature": 0,
        "text": " Oh, you can compare and contrast on your own later.",
        "tokens": [
          50614,
          876,
          11,
          291,
          393,
          6794,
          293,
          8712,
          322,
          428,
          1065,
          1780,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.20328029833341899,
        "compression_ratio": 1.6141078838174274,
        "end": 2316.22,
        "id": 645,
        "no_speech_prob": 0.006192766595631838,
        "seek": 230722,
        "start": 2314.22,
        "temperature": 0,
        "text": " Okay, so this is my color predictor.",
        "tokens": [
          50714,
          1033,
          11,
          370,
          341,
          307,
          452,
          2017,
          6069,
          284,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.20328029833341899,
        "compression_ratio": 1.6141078838174274,
        "end": 2318.22,
        "id": 646,
        "no_speech_prob": 0.006192766595631838,
        "seek": 230722,
        "start": 2316.22,
        "temperature": 0,
        "text": " I'm going to go to an empty sketch.",
        "tokens": [
          50814,
          286,
          478,
          516,
          281,
          352,
          281,
          364,
          6707,
          12325,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.20328029833341899,
        "compression_ratio": 1.6141078838174274,
        "end": 2324.22,
        "id": 647,
        "no_speech_prob": 0.006192766595631838,
        "seek": 230722,
        "start": 2318.22,
        "temperature": 0,
        "text": " The first thing that I want to do is I'm just going to create variables for R, G, and B.",
        "tokens": [
          50914,
          440,
          700,
          551,
          300,
          286,
          528,
          281,
          360,
          307,
          286,
          478,
          445,
          516,
          281,
          1884,
          9102,
          337,
          497,
          11,
          460,
          11,
          293,
          363,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.20328029833341899,
        "compression_ratio": 1.6141078838174274,
        "end": 2331.22,
        "id": 648,
        "no_speech_prob": 0.006192766595631838,
        "seek": 230722,
        "start": 2324.22,
        "temperature": 0,
        "text": " And when the pro- I'm going to write a- maybe I'll write a function, pick color,",
        "tokens": [
          51214,
          400,
          562,
          264,
          447,
          12,
          286,
          478,
          516,
          281,
          2464,
          257,
          12,
          1310,
          286,
          603,
          2464,
          257,
          2445,
          11,
          1888,
          2017,
          11,
          51564
        ]
      },
      {
        "avg_logprob": -0.1690363401777289,
        "compression_ratio": 1.5026178010471205,
        "end": 2338.22,
        "id": 649,
        "no_speech_prob": 0.0014550364576280117,
        "seek": 233122,
        "start": 2331.22,
        "temperature": 0,
        "text": " and I'm just going to say R equals random, 255, G, B,",
        "tokens": [
          50364,
          293,
          286,
          478,
          445,
          516,
          281,
          584,
          497,
          6915,
          4974,
          11,
          3552,
          20,
          11,
          460,
          11,
          363,
          11,
          50714
        ]
      },
      {
        "avg_logprob": -0.1690363401777289,
        "compression_ratio": 1.5026178010471205,
        "end": 2345.22,
        "id": 650,
        "no_speech_prob": 0.0014550364576280117,
        "seek": 233122,
        "start": 2338.22,
        "temperature": 0,
        "text": " and I am going to then draw the background, R, G, B,",
        "tokens": [
          50714,
          293,
          286,
          669,
          516,
          281,
          550,
          2642,
          264,
          3678,
          11,
          497,
          11,
          460,
          11,
          363,
          11,
          51064
        ]
      },
      {
        "avg_logprob": -0.1690363401777289,
        "compression_ratio": 1.5026178010471205,
        "end": 2352.22,
        "id": 651,
        "no_speech_prob": 0.0014550364576280117,
        "seek": 233122,
        "start": 2345.22,
        "temperature": 0,
        "text": " and I'm going to say mouse pressed, pick color.",
        "tokens": [
          51064,
          293,
          286,
          478,
          516,
          281,
          584,
          9719,
          17355,
          11,
          1888,
          2017,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.1690363401777289,
        "compression_ratio": 1.5026178010471205,
        "end": 2355.22,
        "id": 652,
        "no_speech_prob": 0.0014550364576280117,
        "seek": 233122,
        "start": 2352.22,
        "temperature": 0,
        "text": " So let me make a few key points here.",
        "tokens": [
          51414,
          407,
          718,
          385,
          652,
          257,
          1326,
          2141,
          2793,
          510,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.1690363401777289,
        "compression_ratio": 1.5026178010471205,
        "end": 2357.22,
        "id": 653,
        "no_speech_prob": 0.0014550364576280117,
        "seek": 233122,
        "start": 2355.22,
        "temperature": 0,
        "text": " Me, in creating this example and writing this code,",
        "tokens": [
          51564,
          1923,
          11,
          294,
          4084,
          341,
          1365,
          293,
          3579,
          341,
          3089,
          11,
          51664
        ]
      },
      {
        "avg_logprob": -0.1690363401777289,
        "compression_ratio": 1.5026178010471205,
        "end": 2359.22,
        "id": 654,
        "no_speech_prob": 0.0014550364576280117,
        "seek": 233122,
        "start": 2357.22,
        "temperature": 0,
        "text": " I'm not thinking about interaction design.",
        "tokens": [
          51664,
          286,
          478,
          406,
          1953,
          466,
          9285,
          1715,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.17999349560653954,
        "compression_ratio": 1.6548042704626333,
        "end": 2361.22,
        "id": 655,
        "no_speech_prob": 0.00857730582356453,
        "seek": 235922,
        "start": 2359.22,
        "temperature": 0,
        "text": " I'm not thinking about visual design.",
        "tokens": [
          50364,
          286,
          478,
          406,
          1953,
          466,
          5056,
          1715,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.17999349560653954,
        "compression_ratio": 1.6548042704626333,
        "end": 2364.22,
        "id": 656,
        "no_speech_prob": 0.00857730582356453,
        "seek": 235922,
        "start": 2361.22,
        "temperature": 0,
        "text": " I'm not thinking about optimized, efficient code.",
        "tokens": [
          50464,
          286,
          478,
          406,
          1953,
          466,
          26941,
          11,
          7148,
          3089,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.17999349560653954,
        "compression_ratio": 1.6548042704626333,
        "end": 2368.22,
        "id": 657,
        "no_speech_prob": 0.00857730582356453,
        "seek": 235922,
        "start": 2364.22,
        "temperature": 0,
        "text": " I just want to sort of demonstrate the idea and get something up and working quickly.",
        "tokens": [
          50614,
          286,
          445,
          528,
          281,
          1333,
          295,
          11698,
          264,
          1558,
          293,
          483,
          746,
          493,
          293,
          1364,
          2661,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.17999349560653954,
        "compression_ratio": 1.6548042704626333,
        "end": 2375.22,
        "id": 658,
        "no_speech_prob": 0.00857730582356453,
        "seek": 235922,
        "start": 2368.22,
        "temperature": 0,
        "text": " You, the viewer, can then take this and make a more interesting, thoughtful, designed version of it,",
        "tokens": [
          50814,
          509,
          11,
          264,
          16767,
          11,
          393,
          550,
          747,
          341,
          293,
          652,
          257,
          544,
          1880,
          11,
          21566,
          11,
          4761,
          3037,
          295,
          309,
          11,
          51164
        ]
      },
      {
        "avg_logprob": -0.17999349560653954,
        "compression_ratio": 1.6548042704626333,
        "end": 2378.22,
        "id": 659,
        "no_speech_prob": 0.00857730582356453,
        "seek": 235922,
        "start": 2375.22,
        "temperature": 0,
        "text": " even perhaps with a different algorithm or a different problem altogether.",
        "tokens": [
          51164,
          754,
          4317,
          365,
          257,
          819,
          9284,
          420,
          257,
          819,
          1154,
          19051,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.17999349560653954,
        "compression_ratio": 1.6548042704626333,
        "end": 2380.22,
        "id": 660,
        "no_speech_prob": 0.00857730582356453,
        "seek": 235922,
        "start": 2378.22,
        "temperature": 0,
        "text": " But let's just see now.",
        "tokens": [
          51314,
          583,
          718,
          311,
          445,
          536,
          586,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.17999349560653954,
        "compression_ratio": 1.6548042704626333,
        "end": 2385.22,
        "id": 661,
        "no_speech_prob": 0.00857730582356453,
        "seek": 235922,
        "start": 2380.22,
        "temperature": 0,
        "text": " This should be enough code for me to, every time I click the mouse, get a new random color.",
        "tokens": [
          51414,
          639,
          820,
          312,
          1547,
          3089,
          337,
          385,
          281,
          11,
          633,
          565,
          286,
          2052,
          264,
          9719,
          11,
          483,
          257,
          777,
          4974,
          2017,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.23541169638162132,
        "compression_ratio": 1.489247311827957,
        "end": 2389.22,
        "id": 662,
        "no_speech_prob": 0.010169487446546555,
        "seek": 238522,
        "start": 2385.22,
        "temperature": 0,
        "text": " Okay, so I might as well also pick that color in setup.",
        "tokens": [
          50364,
          1033,
          11,
          370,
          286,
          1062,
          382,
          731,
          611,
          1888,
          300,
          2017,
          294,
          8657,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.23541169638162132,
        "compression_ratio": 1.489247311827957,
        "end": 2395.22,
        "id": 663,
        "no_speech_prob": 0.010169487446546555,
        "seek": 238522,
        "start": 2389.22,
        "temperature": 0,
        "text": " Now, I also want to draw, let me say text size, 64.",
        "tokens": [
          50564,
          823,
          11,
          286,
          611,
          528,
          281,
          2642,
          11,
          718,
          385,
          584,
          2487,
          2744,
          11,
          12145,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.23541169638162132,
        "compression_ratio": 1.489247311827957,
        "end": 2399.22,
        "id": 664,
        "no_speech_prob": 0.010169487446546555,
        "seek": 238522,
        "start": 2395.22,
        "temperature": 0,
        "text": " Then I want to say- let me do no stroke, I think.",
        "tokens": [
          50864,
          1396,
          286,
          528,
          281,
          584,
          12,
          718,
          385,
          360,
          572,
          12403,
          11,
          286,
          519,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.23541169638162132,
        "compression_ratio": 1.489247311827957,
        "end": 2401.22,
        "id": 665,
        "no_speech_prob": 0.010169487446546555,
        "seek": 238522,
        "start": 2399.22,
        "temperature": 0,
        "text": " A text can have an outline and a fill.",
        "tokens": [
          51064,
          316,
          2487,
          393,
          362,
          364,
          16387,
          293,
          257,
          2836,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.23541169638162132,
        "compression_ratio": 1.489247311827957,
        "end": 2411.22,
        "id": 666,
        "no_speech_prob": 0.010169487446546555,
        "seek": 238522,
        "start": 2401.22,
        "temperature": 0,
        "text": " I'm going to do fill, zero, text, black, and let me do text align, center, also.",
        "tokens": [
          51164,
          286,
          478,
          516,
          281,
          360,
          2836,
          11,
          4018,
          11,
          2487,
          11,
          2211,
          11,
          293,
          718,
          385,
          360,
          2487,
          7975,
          11,
          3056,
          11,
          611,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.2484731172260485,
        "compression_ratio": 1.44375,
        "end": 2417.22,
        "id": 667,
        "no_speech_prob": 0.024050746113061905,
        "seek": 241122,
        "start": 2412.22,
        "temperature": 0,
        "text": " Black, and that should be- what is my- let me make the dimensions of this a little simpler.",
        "tokens": [
          50414,
          4076,
          11,
          293,
          300,
          820,
          312,
          12,
          437,
          307,
          452,
          12,
          718,
          385,
          652,
          264,
          12819,
          295,
          341,
          257,
          707,
          18587,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.2484731172260485,
        "compression_ratio": 1.44375,
        "end": 2423.22,
        "id": 668,
        "no_speech_prob": 0.024050746113061905,
        "seek": 241122,
        "start": 2417.22,
        "temperature": 0,
        "text": " 400 by 300, so this would be 150 then, I guess.",
        "tokens": [
          50664,
          8423,
          538,
          6641,
          11,
          370,
          341,
          576,
          312,
          8451,
          550,
          11,
          286,
          2041,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.2484731172260485,
        "compression_ratio": 1.44375,
        "end": 2427.22,
        "id": 669,
        "no_speech_prob": 0.024050746113061905,
        "seek": 241122,
        "start": 2423.22,
        "temperature": 0,
        "text": " 150, 150, I don't know.",
        "tokens": [
          50964,
          8451,
          11,
          8451,
          11,
          286,
          500,
          380,
          458,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.2484731172260485,
        "compression_ratio": 1.44375,
        "end": 2431.22,
        "id": 670,
        "no_speech_prob": 0.024050746113061905,
        "seek": 241122,
        "start": 2427.22,
        "temperature": 0,
        "text": " And 250, 150, and this would say white.",
        "tokens": [
          51164,
          400,
          11650,
          11,
          8451,
          11,
          293,
          341,
          576,
          584,
          2418,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.2484731172260485,
        "compression_ratio": 1.44375,
        "end": 2433.22,
        "id": 671,
        "no_speech_prob": 0.024050746113061905,
        "seek": 241122,
        "start": 2431.22,
        "temperature": 0,
        "text": " So let's see how this goes.",
        "tokens": [
          51364,
          407,
          718,
          311,
          536,
          577,
          341,
          1709,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.22062564540553736,
        "compression_ratio": 1.387878787878788,
        "end": 2439.22,
        "id": 672,
        "no_speech_prob": 0.15607337653636932,
        "seek": 243322,
        "start": 2434.22,
        "temperature": 0,
        "text": " Alright, so that's a little bit too big, but I could also just make it wider.",
        "tokens": [
          50414,
          2798,
          11,
          370,
          300,
          311,
          257,
          707,
          857,
          886,
          955,
          11,
          457,
          286,
          727,
          611,
          445,
          652,
          309,
          11842,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.22062564540553736,
        "compression_ratio": 1.387878787878788,
        "end": 2446.22,
        "id": 673,
        "no_speech_prob": 0.15607337653636932,
        "seek": 243322,
        "start": 2439.22,
        "temperature": 0,
        "text": " 600, and then this would be 200, and 400, right?",
        "tokens": [
          50664,
          11849,
          11,
          293,
          550,
          341,
          576,
          312,
          2331,
          11,
          293,
          8423,
          11,
          558,
          30,
          51014
        ]
      },
      {
        "avg_logprob": -0.22062564540553736,
        "compression_ratio": 1.387878787878788,
        "end": 2448.22,
        "id": 674,
        "no_speech_prob": 0.15607337653636932,
        "seek": 243322,
        "start": 2446.22,
        "temperature": 0,
        "text": " There we go.",
        "tokens": [
          51014,
          821,
          321,
          352,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.22062564540553736,
        "compression_ratio": 1.387878787878788,
        "end": 2455.22,
        "id": 675,
        "no_speech_prob": 0.15607337653636932,
        "seek": 243322,
        "start": 2448.22,
        "temperature": 0,
        "text": " And this one should be fill, 255.",
        "tokens": [
          51114,
          400,
          341,
          472,
          820,
          312,
          2836,
          11,
          3552,
          20,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.22062564540553736,
        "compression_ratio": 1.387878787878788,
        "end": 2460.22,
        "id": 676,
        "no_speech_prob": 0.15607337653636932,
        "seek": 243322,
        "start": 2455.22,
        "temperature": 0,
        "text": " Okay, so now I have a system where at least I am seeing",
        "tokens": [
          51464,
          1033,
          11,
          370,
          586,
          286,
          362,
          257,
          1185,
          689,
          412,
          1935,
          286,
          669,
          2577,
          51714
        ]
      },
      {
        "avg_logprob": -0.2061802899395978,
        "compression_ratio": 1.5755102040816327,
        "end": 2465.22,
        "id": 677,
        "no_speech_prob": 0.04535123333334923,
        "seek": 246022,
        "start": 2461.22,
        "temperature": 0,
        "text": " which one it should be, black or white.",
        "tokens": [
          50414,
          597,
          472,
          309,
          820,
          312,
          11,
          2211,
          420,
          2418,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.2061802899395978,
        "compression_ratio": 1.5755102040816327,
        "end": 2468.22,
        "id": 678,
        "no_speech_prob": 0.04535123333334923,
        "seek": 246022,
        "start": 2465.22,
        "temperature": 0,
        "text": " I'm seeing both colors written on top of the background.",
        "tokens": [
          50614,
          286,
          478,
          2577,
          1293,
          4577,
          3720,
          322,
          1192,
          295,
          264,
          3678,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.2061802899395978,
        "compression_ratio": 1.5755102040816327,
        "end": 2470.22,
        "id": 679,
        "no_speech_prob": 0.04535123333334923,
        "seek": 246022,
        "start": 2468.22,
        "temperature": 0,
        "text": " Let's draw a line down the middle.",
        "tokens": [
          50764,
          961,
          311,
          2642,
          257,
          1622,
          760,
          264,
          2808,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.2061802899395978,
        "compression_ratio": 1.5755102040816327,
        "end": 2472.22,
        "id": 680,
        "no_speech_prob": 0.04535123333334923,
        "seek": 246022,
        "start": 2470.22,
        "temperature": 0,
        "text": " I think maybe visually it needs that.",
        "tokens": [
          50864,
          286,
          519,
          1310,
          19622,
          309,
          2203,
          300,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.2061802899395978,
        "compression_ratio": 1.5755102040816327,
        "end": 2475.22,
        "id": 681,
        "no_speech_prob": 0.04535123333334923,
        "seek": 246022,
        "start": 2472.22,
        "temperature": 0,
        "text": " I don't think I centered these correctly, but whatever.",
        "tokens": [
          50964,
          286,
          500,
          380,
          519,
          286,
          18988,
          613,
          8944,
          11,
          457,
          2035,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.2061802899395978,
        "compression_ratio": 1.5755102040816327,
        "end": 2481.22,
        "id": 682,
        "no_speech_prob": 0.04535123333334923,
        "seek": 246022,
        "start": 2475.22,
        "temperature": 0,
        "text": " Okay, okay, we're getting somewhere.",
        "tokens": [
          51114,
          1033,
          11,
          1392,
          11,
          321,
          434,
          1242,
          4079,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.2061802899395978,
        "compression_ratio": 1.5755102040816327,
        "end": 2484.22,
        "id": 683,
        "no_speech_prob": 0.04535123333334923,
        "seek": 246022,
        "start": 2481.22,
        "temperature": 0,
        "text": " Center, center, someone in the chat is telling me to use center, center.",
        "tokens": [
          51414,
          5169,
          11,
          3056,
          11,
          1580,
          294,
          264,
          5081,
          307,
          3585,
          385,
          281,
          764,
          3056,
          11,
          3056,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.2061802899395978,
        "compression_ratio": 1.5755102040816327,
        "end": 2486.22,
        "id": 684,
        "no_speech_prob": 0.04535123333334923,
        "seek": 246022,
        "start": 2484.22,
        "temperature": 0,
        "text": " Why not?",
        "tokens": [
          51564,
          1545,
          406,
          30,
          51664
        ]
      },
      {
        "avg_logprob": -0.2061802899395978,
        "compression_ratio": 1.5755102040816327,
        "end": 2488.22,
        "id": 685,
        "no_speech_prob": 0.04535123333334923,
        "seek": 246022,
        "start": 2486.22,
        "temperature": 0,
        "text": " So that aligned it center vertically too.",
        "tokens": [
          51664,
          407,
          300,
          17962,
          309,
          3056,
          28450,
          886,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.18606043573635728,
        "compression_ratio": 1.7538461538461538,
        "end": 2489.22,
        "id": 686,
        "no_speech_prob": 0.0024343677796423435,
        "seek": 248822,
        "start": 2488.22,
        "temperature": 0,
        "text": " Beautiful, thank you.",
        "tokens": [
          50364,
          14724,
          11,
          1309,
          291,
          13,
          50414
        ]
      },
      {
        "avg_logprob": -0.18606043573635728,
        "compression_ratio": 1.7538461538461538,
        "end": 2491.22,
        "id": 687,
        "no_speech_prob": 0.0024343677796423435,
        "seek": 248822,
        "start": 2489.22,
        "temperature": 0,
        "text": " That was an excellent suggestion.",
        "tokens": [
          50414,
          663,
          390,
          364,
          7103,
          16541,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.18606043573635728,
        "compression_ratio": 1.7538461538461538,
        "end": 2493.22,
        "id": 688,
        "no_speech_prob": 0.0024343677796423435,
        "seek": 248822,
        "start": 2491.22,
        "temperature": 0,
        "text": " Okay, so now what I want to do is, guess what?",
        "tokens": [
          50514,
          1033,
          11,
          370,
          586,
          437,
          286,
          528,
          281,
          360,
          307,
          11,
          2041,
          437,
          30,
          50614
        ]
      },
      {
        "avg_logprob": -0.18606043573635728,
        "compression_ratio": 1.7538461538461538,
        "end": 2495.22,
        "id": 689,
        "no_speech_prob": 0.0024343677796423435,
        "seek": 248822,
        "start": 2493.22,
        "temperature": 0,
        "text": " We're ready.",
        "tokens": [
          50614,
          492,
          434,
          1919,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.18606043573635728,
        "compression_ratio": 1.7538461538461538,
        "end": 2497.22,
        "id": 690,
        "no_speech_prob": 0.0024343677796423435,
        "seek": 248822,
        "start": 2495.22,
        "temperature": 0,
        "text": " This is what I love about this problem.",
        "tokens": [
          50714,
          639,
          307,
          437,
          286,
          959,
          466,
          341,
          1154,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.18606043573635728,
        "compression_ratio": 1.7538461538461538,
        "end": 2504.22,
        "id": 691,
        "no_speech_prob": 0.0024343677796423435,
        "seek": 248822,
        "start": 2497.22,
        "temperature": 0,
        "text": " We're ready for the neural network because we can do it.",
        "tokens": [
          50814,
          492,
          434,
          1919,
          337,
          264,
          18161,
          3209,
          570,
          321,
          393,
          360,
          309,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.18606043573635728,
        "compression_ratio": 1.7538461538461538,
        "end": 2506.22,
        "id": 692,
        "no_speech_prob": 0.0024343677796423435,
        "seek": 248822,
        "start": 2504.22,
        "temperature": 0,
        "text": " So what do I need?",
        "tokens": [
          51164,
          407,
          437,
          360,
          286,
          643,
          30,
          51264
        ]
      },
      {
        "avg_logprob": -0.18606043573635728,
        "compression_ratio": 1.7538461538461538,
        "end": 2509.22,
        "id": 693,
        "no_speech_prob": 0.0024343677796423435,
        "seek": 248822,
        "start": 2506.22,
        "temperature": 0,
        "text": " I want to make a, I'm going to call it brain.",
        "tokens": [
          51264,
          286,
          528,
          281,
          652,
          257,
          11,
          286,
          478,
          516,
          281,
          818,
          309,
          3567,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.18606043573635728,
        "compression_ratio": 1.7538461538461538,
        "end": 2510.22,
        "id": 694,
        "no_speech_prob": 0.0024343677796423435,
        "seek": 248822,
        "start": 2509.22,
        "temperature": 0,
        "text": " I'm going to make a variable called brain.",
        "tokens": [
          51414,
          286,
          478,
          516,
          281,
          652,
          257,
          7006,
          1219,
          3567,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.18606043573635728,
        "compression_ratio": 1.7538461538461538,
        "end": 2512.22,
        "id": 695,
        "no_speech_prob": 0.0024343677796423435,
        "seek": 248822,
        "start": 2510.22,
        "temperature": 0,
        "text": " It's going to be the neural network.",
        "tokens": [
          51464,
          467,
          311,
          516,
          281,
          312,
          264,
          18161,
          3209,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.18606043573635728,
        "compression_ratio": 1.7538461538461538,
        "end": 2517.22,
        "id": 696,
        "no_speech_prob": 0.0024343677796423435,
        "seek": 248822,
        "start": 2512.22,
        "temperature": 0,
        "text": " Now, I just don't get a neural network in JavaScript just by the nature of programming JavaScript.",
        "tokens": [
          51564,
          823,
          11,
          286,
          445,
          500,
          380,
          483,
          257,
          18161,
          3209,
          294,
          15778,
          445,
          538,
          264,
          3687,
          295,
          9410,
          15778,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.18674145156531025,
        "compression_ratio": 1.6822429906542056,
        "end": 2524.22,
        "id": 697,
        "no_speech_prob": 0.08151643723249435,
        "seek": 251722,
        "start": 2517.22,
        "temperature": 0,
        "text": " I'm getting it because I have imported already into my HTML file two files, nn.js and matrix.js.",
        "tokens": [
          50364,
          286,
          478,
          1242,
          309,
          570,
          286,
          362,
          25524,
          1217,
          666,
          452,
          17995,
          3991,
          732,
          7098,
          11,
          297,
          77,
          13,
          25530,
          293,
          8141,
          13,
          25530,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.18674145156531025,
        "compression_ratio": 1.6822429906542056,
        "end": 2528.22,
        "id": 698,
        "no_speech_prob": 0.08151643723249435,
        "seek": 251722,
        "start": 2524.22,
        "temperature": 0,
        "text": " This is a little toy neural network library that I developed and a whole set of video tutorials.",
        "tokens": [
          50714,
          639,
          307,
          257,
          707,
          12058,
          18161,
          3209,
          6405,
          300,
          286,
          4743,
          293,
          257,
          1379,
          992,
          295,
          960,
          17616,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.18674145156531025,
        "compression_ratio": 1.6822429906542056,
        "end": 2533.22,
        "id": 699,
        "no_speech_prob": 0.08151643723249435,
        "seek": 251722,
        "start": 2528.22,
        "temperature": 0,
        "text": " At some point in the future, I'm going to replace this with this new project called TensorFlow.js,",
        "tokens": [
          50914,
          1711,
          512,
          935,
          294,
          264,
          2027,
          11,
          286,
          478,
          516,
          281,
          7406,
          341,
          365,
          341,
          777,
          1716,
          1219,
          37624,
          13,
          25530,
          11,
          51164
        ]
      },
      {
        "avg_logprob": -0.18674145156531025,
        "compression_ratio": 1.6822429906542056,
        "end": 2537.22,
        "id": 700,
        "no_speech_prob": 0.08151643723249435,
        "seek": 251722,
        "start": 2533.22,
        "temperature": 0,
        "text": " which is a lower level machine learning library and also ml5 is this other library,",
        "tokens": [
          51164,
          597,
          307,
          257,
          3126,
          1496,
          3479,
          2539,
          6405,
          293,
          611,
          23271,
          20,
          307,
          341,
          661,
          6405,
          11,
          51364
        ]
      },
      {
        "avg_logprob": -0.18674145156531025,
        "compression_ratio": 1.6822429906542056,
        "end": 2539.22,
        "id": 701,
        "no_speech_prob": 0.08151643723249435,
        "seek": 251722,
        "start": 2537.22,
        "temperature": 0,
        "text": " but I'll come back to that another time.",
        "tokens": [
          51364,
          457,
          286,
          603,
          808,
          646,
          281,
          300,
          1071,
          565,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.18674145156531025,
        "compression_ratio": 1.6822429906542056,
        "end": 2541.22,
        "id": 702,
        "no_speech_prob": 0.08151643723249435,
        "seek": 251722,
        "start": 2539.22,
        "temperature": 0,
        "text": " I'm still using this little toy neural network.",
        "tokens": [
          51464,
          286,
          478,
          920,
          1228,
          341,
          707,
          12058,
          18161,
          3209,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.18674145156531025,
        "compression_ratio": 1.6822429906542056,
        "end": 2545.22,
        "id": 703,
        "no_speech_prob": 0.08151643723249435,
        "seek": 251722,
        "start": 2541.22,
        "temperature": 0,
        "text": " So what I want to do now in the code is I just want to say brain in setup.",
        "tokens": [
          51564,
          407,
          437,
          286,
          528,
          281,
          360,
          586,
          294,
          264,
          3089,
          307,
          286,
          445,
          528,
          281,
          584,
          3567,
          294,
          8657,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.18229195731026784,
        "compression_ratio": 1.7813953488372094,
        "end": 2549.22,
        "id": 704,
        "no_speech_prob": 0.00022341581643559039,
        "seek": 254522,
        "start": 2545.22,
        "temperature": 0,
        "text": " I want to say brain equals a new neural network.",
        "tokens": [
          50364,
          286,
          528,
          281,
          584,
          3567,
          6915,
          257,
          777,
          18161,
          3209,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.18229195731026784,
        "compression_ratio": 1.7813953488372094,
        "end": 2554.22,
        "id": 705,
        "no_speech_prob": 0.00022341581643559039,
        "seek": 254522,
        "start": 2549.22,
        "temperature": 0,
        "text": " Now, it expects three arguments, three arguments.",
        "tokens": [
          50564,
          823,
          11,
          309,
          33280,
          1045,
          12869,
          11,
          1045,
          12869,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.18229195731026784,
        "compression_ratio": 1.7813953488372094,
        "end": 2558.22,
        "id": 706,
        "no_speech_prob": 0.00022341581643559039,
        "seek": 254522,
        "start": 2554.22,
        "temperature": 0,
        "text": " Now, this is not universal to how neural network libraries work.",
        "tokens": [
          50814,
          823,
          11,
          341,
          307,
          406,
          11455,
          281,
          577,
          18161,
          3209,
          15148,
          589,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.18229195731026784,
        "compression_ratio": 1.7813953488372094,
        "end": 2561.22,
        "id": 707,
        "no_speech_prob": 0.00022341581643559039,
        "seek": 254522,
        "start": 2558.22,
        "temperature": 0,
        "text": " This is a very simple one that has very basic features,",
        "tokens": [
          51014,
          639,
          307,
          257,
          588,
          2199,
          472,
          300,
          575,
          588,
          3875,
          4122,
          11,
          51164
        ]
      },
      {
        "avg_logprob": -0.18229195731026784,
        "compression_ratio": 1.7813953488372094,
        "end": 2568.22,
        "id": 708,
        "no_speech_prob": 0.00022341581643559039,
        "seek": 254522,
        "start": 2561.22,
        "temperature": 0,
        "text": " and what it expects is how many inputs, how many outputs, and how many hidden nodes,",
        "tokens": [
          51164,
          293,
          437,
          309,
          33280,
          307,
          577,
          867,
          15743,
          11,
          577,
          867,
          23930,
          11,
          293,
          577,
          867,
          7633,
          13891,
          11,
          51514
        ]
      },
      {
        "avg_logprob": -0.18229195731026784,
        "compression_ratio": 1.7813953488372094,
        "end": 2571.22,
        "id": 709,
        "no_speech_prob": 0.00022341581643559039,
        "seek": 254522,
        "start": 2568.22,
        "temperature": 0,
        "text": " but not in that order, inputs, hidden, outputs.",
        "tokens": [
          51514,
          457,
          406,
          294,
          300,
          1668,
          11,
          15743,
          11,
          7633,
          11,
          23930,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.18229195731026784,
        "compression_ratio": 1.7813953488372094,
        "end": 2573.22,
        "id": 710,
        "no_speech_prob": 0.00022341581643559039,
        "seek": 254522,
        "start": 2571.22,
        "temperature": 0,
        "text": " So this we can see is 3, 3, 2.",
        "tokens": [
          51664,
          407,
          341,
          321,
          393,
          536,
          307,
          805,
          11,
          805,
          11,
          568,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.2215088435581752,
        "compression_ratio": 1.4879518072289157,
        "end": 2578.22,
        "id": 711,
        "no_speech_prob": 0.0003569682303350419,
        "seek": 257322,
        "start": 2573.22,
        "temperature": 0,
        "text": " That's the architecture, the model architecture that I have designed.",
        "tokens": [
          50364,
          663,
          311,
          264,
          9482,
          11,
          264,
          2316,
          9482,
          300,
          286,
          362,
          4761,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.2215088435581752,
        "compression_ratio": 1.4879518072289157,
        "end": 2580.22,
        "id": 712,
        "no_speech_prob": 0.0003569682303350419,
        "seek": 257322,
        "start": 2578.22,
        "temperature": 0,
        "text": " 3, 3, 2.",
        "tokens": [
          50614,
          805,
          11,
          805,
          11,
          568,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.2215088435581752,
        "compression_ratio": 1.4879518072289157,
        "end": 2581.22,
        "id": 713,
        "no_speech_prob": 0.0003569682303350419,
        "seek": 257322,
        "start": 2580.22,
        "temperature": 0,
        "text": " Wonderful.",
        "tokens": [
          50714,
          22768,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.2215088435581752,
        "compression_ratio": 1.4879518072289157,
        "end": 2583.22,
        "id": 714,
        "no_speech_prob": 0.0003569682303350419,
        "seek": 257322,
        "start": 2581.22,
        "temperature": 0,
        "text": " Now, I'm done.",
        "tokens": [
          50764,
          823,
          11,
          286,
          478,
          1096,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.2215088435581752,
        "compression_ratio": 1.4879518072289157,
        "end": 2584.22,
        "id": 715,
        "no_speech_prob": 0.0003569682303350419,
        "seek": 257322,
        "start": 2583.22,
        "temperature": 0,
        "text": " I got it.",
        "tokens": [
          50864,
          286,
          658,
          309,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.2215088435581752,
        "compression_ratio": 1.4879518072289157,
        "end": 2585.22,
        "id": 716,
        "no_speech_prob": 0.0003569682303350419,
        "seek": 257322,
        "start": 2584.22,
        "temperature": 0,
        "text": " Woohoo.",
        "tokens": [
          50914,
          10468,
          19069,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.2215088435581752,
        "compression_ratio": 1.4879518072289157,
        "end": 2594.22,
        "id": 717,
        "no_speech_prob": 0.0003569682303350419,
        "seek": 257322,
        "start": 2585.22,
        "temperature": 0,
        "text": " Now, what I can do is let's say every time, so let's make a variable called which,",
        "tokens": [
          50964,
          823,
          11,
          437,
          286,
          393,
          360,
          307,
          718,
          311,
          584,
          633,
          565,
          11,
          370,
          718,
          311,
          652,
          257,
          7006,
          1219,
          597,
          11,
          51414
        ]
      },
      {
        "avg_logprob": -0.2215088435581752,
        "compression_ratio": 1.4879518072289157,
        "end": 2597.22,
        "id": 718,
        "no_speech_prob": 0.0003569682303350419,
        "seek": 257322,
        "start": 2594.22,
        "temperature": 0,
        "text": " like which one is better, black or white,",
        "tokens": [
          51414,
          411,
          597,
          472,
          307,
          1101,
          11,
          2211,
          420,
          2418,
          11,
          51564
        ]
      },
      {
        "avg_logprob": -0.16865708033243815,
        "compression_ratio": 1.4428571428571428,
        "end": 2602.22,
        "id": 719,
        "no_speech_prob": 0.054194338619709015,
        "seek": 259722,
        "start": 2597.22,
        "temperature": 0,
        "text": " and I will just start with saying black,",
        "tokens": [
          50364,
          293,
          286,
          486,
          445,
          722,
          365,
          1566,
          2211,
          11,
          50614
        ]
      },
      {
        "avg_logprob": -0.16865708033243815,
        "compression_ratio": 1.4428571428571428,
        "end": 2608.22,
        "id": 720,
        "no_speech_prob": 0.054194338619709015,
        "seek": 259722,
        "start": 2602.22,
        "temperature": 0,
        "text": " and what I'm going to do is let's do the same sort of technique that Jabril did.",
        "tokens": [
          50614,
          293,
          437,
          286,
          478,
          516,
          281,
          360,
          307,
          718,
          311,
          360,
          264,
          912,
          1333,
          295,
          6532,
          300,
          40319,
          24216,
          630,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.16865708033243815,
        "compression_ratio": 1.4428571428571428,
        "end": 2620.22,
        "id": 721,
        "no_speech_prob": 0.054194338619709015,
        "seek": 259722,
        "start": 2608.22,
        "temperature": 0,
        "text": " If which equals black, then I'm going to draw a circle,",
        "tokens": [
          50914,
          759,
          597,
          6915,
          2211,
          11,
          550,
          286,
          478,
          516,
          281,
          2642,
          257,
          6329,
          11,
          51514
        ]
      },
      {
        "avg_logprob": -0.16865708033243815,
        "compression_ratio": 1.4428571428571428,
        "end": 2622.22,
        "id": 722,
        "no_speech_prob": 0.054194338619709015,
        "seek": 259722,
        "start": 2620.22,
        "temperature": 0,
        "text": " a circle which is where?",
        "tokens": [
          51514,
          257,
          6329,
          597,
          307,
          689,
          30,
          51614
        ]
      },
      {
        "avg_logprob": -0.2667062710493039,
        "compression_ratio": 1.4527027027027026,
        "end": 2627.22,
        "id": 723,
        "no_speech_prob": 0.27820032835006714,
        "seek": 262222,
        "start": 2622.22,
        "temperature": 0,
        "text": " At 200, 200, 300, 60, 60.",
        "tokens": [
          50364,
          1711,
          2331,
          11,
          2331,
          11,
          6641,
          11,
          4060,
          11,
          4060,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.2667062710493039,
        "compression_ratio": 1.4527027027027026,
        "end": 2637.22,
        "id": 724,
        "no_speech_prob": 0.27820032835006714,
        "seek": 262222,
        "start": 2627.22,
        "temperature": 0,
        "text": " And I'll, there, and then else if it's white, then draw it at 400,",
        "tokens": [
          50614,
          400,
          286,
          603,
          11,
          456,
          11,
          293,
          550,
          1646,
          498,
          309,
          311,
          2418,
          11,
          550,
          2642,
          309,
          412,
          8423,
          11,
          51114
        ]
      },
      {
        "avg_logprob": -0.2667062710493039,
        "compression_ratio": 1.4527027027027026,
        "end": 2643.22,
        "id": 725,
        "no_speech_prob": 0.27820032835006714,
        "seek": 262222,
        "start": 2637.22,
        "temperature": 0,
        "text": " and so this would be fill 0, this would be fill 255, and we're still no stroke.",
        "tokens": [
          51114,
          293,
          370,
          341,
          576,
          312,
          2836,
          1958,
          11,
          341,
          576,
          312,
          2836,
          3552,
          20,
          11,
          293,
          321,
          434,
          920,
          572,
          12403,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.2667062710493039,
        "compression_ratio": 1.4527027027027026,
        "end": 2644.22,
        "id": 726,
        "no_speech_prob": 0.27820032835006714,
        "seek": 262222,
        "start": 2643.22,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          51414,
          1033,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.2667062710493039,
        "compression_ratio": 1.4527027027027026,
        "end": 2648.22,
        "id": 727,
        "no_speech_prob": 0.27820032835006714,
        "seek": 262222,
        "start": 2644.22,
        "temperature": 0,
        "text": " So now, we see that's very far down.",
        "tokens": [
          51464,
          407,
          586,
          11,
          321,
          536,
          300,
          311,
          588,
          1400,
          760,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.16859093956325366,
        "compression_ratio": 1.505813953488372,
        "end": 2655.22,
        "id": 728,
        "no_speech_prob": 0.1777905523777008,
        "seek": 264822,
        "start": 2648.22,
        "temperature": 0,
        "text": " So let me move this up to 200.",
        "tokens": [
          50364,
          407,
          718,
          385,
          1286,
          341,
          493,
          281,
          2331,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.16859093956325366,
        "compression_ratio": 1.505813953488372,
        "end": 2659.22,
        "id": 729,
        "no_speech_prob": 0.1777905523777008,
        "seek": 264822,
        "start": 2655.22,
        "temperature": 0,
        "text": " That's too, I have no sense of dimensions whatsoever.",
        "tokens": [
          50714,
          663,
          311,
          886,
          11,
          286,
          362,
          572,
          2020,
          295,
          12819,
          17076,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.16859093956325366,
        "compression_ratio": 1.505813953488372,
        "end": 2660.22,
        "id": 730,
        "no_speech_prob": 0.1777905523777008,
        "seek": 264822,
        "start": 2659.22,
        "temperature": 0,
        "text": " Perfect.",
        "tokens": [
          50914,
          10246,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.16859093956325366,
        "compression_ratio": 1.505813953488372,
        "end": 2661.22,
        "id": 731,
        "no_speech_prob": 0.1777905523777008,
        "seek": 264822,
        "start": 2660.22,
        "temperature": 0,
        "text": " Oh, this looks weird now.",
        "tokens": [
          50964,
          876,
          11,
          341,
          1542,
          3657,
          586,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.16859093956325366,
        "compression_ratio": 1.505813953488372,
        "end": 2663.22,
        "id": 732,
        "no_speech_prob": 0.1777905523777008,
        "seek": 264822,
        "start": 2661.22,
        "temperature": 0,
        "text": " It's not all centered, but fine.",
        "tokens": [
          51014,
          467,
          311,
          406,
          439,
          18988,
          11,
          457,
          2489,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.16859093956325366,
        "compression_ratio": 1.505813953488372,
        "end": 2665.22,
        "id": 733,
        "no_speech_prob": 0.1777905523777008,
        "seek": 264822,
        "start": 2663.22,
        "temperature": 0,
        "text": " Oh, I can't take it.",
        "tokens": [
          51114,
          876,
          11,
          286,
          393,
          380,
          747,
          309,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.16859093956325366,
        "compression_ratio": 1.505813953488372,
        "end": 2666.22,
        "id": 734,
        "no_speech_prob": 0.1777905523777008,
        "seek": 264822,
        "start": 2665.22,
        "temperature": 0,
        "text": " I can't take it.",
        "tokens": [
          51214,
          286,
          393,
          380,
          747,
          309,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.16859093956325366,
        "compression_ratio": 1.505813953488372,
        "end": 2668.22,
        "id": 735,
        "no_speech_prob": 0.1777905523777008,
        "seek": 264822,
        "start": 2666.22,
        "temperature": 0,
        "text": " Let's move this.",
        "tokens": [
          51264,
          961,
          311,
          1286,
          341,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.16859093956325366,
        "compression_ratio": 1.505813953488372,
        "end": 2671.22,
        "id": 736,
        "no_speech_prob": 0.1777905523777008,
        "seek": 264822,
        "start": 2668.22,
        "temperature": 0,
        "text": " I really shouldn't be doing this, but I'm going to.",
        "tokens": [
          51364,
          286,
          534,
          4659,
          380,
          312,
          884,
          341,
          11,
          457,
          286,
          478,
          516,
          281,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.15560886297333107,
        "compression_ratio": 1.664864864864865,
        "end": 2679.22,
        "id": 737,
        "no_speech_prob": 0.05419699847698212,
        "seek": 267122,
        "start": 2671.22,
        "temperature": 0,
        "text": " Let's make this 100, 100, and let's make this 200, 200.",
        "tokens": [
          50364,
          961,
          311,
          652,
          341,
          2319,
          11,
          2319,
          11,
          293,
          718,
          311,
          652,
          341,
          2331,
          11,
          2331,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.15560886297333107,
        "compression_ratio": 1.664864864864865,
        "end": 2682.22,
        "id": 738,
        "no_speech_prob": 0.05419699847698212,
        "seek": 267122,
        "start": 2679.22,
        "temperature": 0,
        "text": " Okay, I feel better now.",
        "tokens": [
          50764,
          1033,
          11,
          286,
          841,
          1101,
          586,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.15560886297333107,
        "compression_ratio": 1.664864864864865,
        "end": 2689.22,
        "id": 739,
        "no_speech_prob": 0.05419699847698212,
        "seek": 267122,
        "start": 2682.22,
        "temperature": 0,
        "text": " Okay, so it's always going to pick black right now because no matter what,",
        "tokens": [
          50914,
          1033,
          11,
          370,
          309,
          311,
          1009,
          516,
          281,
          1888,
          2211,
          558,
          586,
          570,
          572,
          1871,
          437,
          11,
          51264
        ]
      },
      {
        "avg_logprob": -0.15560886297333107,
        "compression_ratio": 1.664864864864865,
        "end": 2694.22,
        "id": 740,
        "no_speech_prob": 0.05419699847698212,
        "seek": 267122,
        "start": 2689.22,
        "temperature": 0,
        "text": " I've just made which equal to black, but I can use the neural network now.",
        "tokens": [
          51264,
          286,
          600,
          445,
          1027,
          597,
          2681,
          281,
          2211,
          11,
          457,
          286,
          393,
          764,
          264,
          18161,
          3209,
          586,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.15560886297333107,
        "compression_ratio": 1.664864864864865,
        "end": 2695.22,
        "id": 741,
        "no_speech_prob": 0.05419699847698212,
        "seek": 267122,
        "start": 2694.22,
        "temperature": 0,
        "text": " I can use the neural network.",
        "tokens": [
          51514,
          286,
          393,
          764,
          264,
          18161,
          3209,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.15560886297333107,
        "compression_ratio": 1.664864864864865,
        "end": 2698.22,
        "id": 742,
        "no_speech_prob": 0.05419699847698212,
        "seek": 267122,
        "start": 2695.22,
        "temperature": 0,
        "text": " The neural network is my function approximator.",
        "tokens": [
          51564,
          440,
          18161,
          3209,
          307,
          452,
          2445,
          8542,
          1639,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.18490731595742582,
        "compression_ratio": 1.602803738317757,
        "end": 2704.22,
        "id": 743,
        "no_speech_prob": 0.010652421973645687,
        "seek": 269822,
        "start": 2698.22,
        "temperature": 0,
        "text": " Let's actually write this code with our own non-neural network first just to make this case.",
        "tokens": [
          50364,
          961,
          311,
          767,
          2464,
          341,
          3089,
          365,
          527,
          1065,
          2107,
          12,
          716,
          1807,
          3209,
          700,
          445,
          281,
          652,
          341,
          1389,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.18490731595742582,
        "compression_ratio": 1.602803738317757,
        "end": 2709.22,
        "id": 744,
        "no_speech_prob": 0.010652421973645687,
        "seek": 269822,
        "start": 2704.22,
        "temperature": 0,
        "text": " I'm going to write color predictor, and I'm going to say get an RGB,",
        "tokens": [
          50664,
          286,
          478,
          516,
          281,
          2464,
          2017,
          6069,
          284,
          11,
          293,
          286,
          478,
          516,
          281,
          584,
          483,
          364,
          31231,
          11,
          50914
        ]
      },
      {
        "avg_logprob": -0.18490731595742582,
        "compression_ratio": 1.602803738317757,
        "end": 2715.22,
        "id": 745,
        "no_speech_prob": 0.010652421973645687,
        "seek": 269822,
        "start": 2709.22,
        "temperature": 0,
        "text": " and now I'm going to just say if R plus G plus B is greater than 300,",
        "tokens": [
          50914,
          293,
          586,
          286,
          478,
          516,
          281,
          445,
          584,
          498,
          497,
          1804,
          460,
          1804,
          363,
          307,
          5044,
          813,
          6641,
          11,
          51214
        ]
      },
      {
        "avg_logprob": -0.18490731595742582,
        "compression_ratio": 1.602803738317757,
        "end": 2721.22,
        "id": 746,
        "no_speech_prob": 0.010652421973645687,
        "seek": 269822,
        "start": 2715.22,
        "temperature": 0,
        "text": " then return black, else return white.",
        "tokens": [
          51214,
          550,
          2736,
          2211,
          11,
          1646,
          2736,
          2418,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.18490731595742582,
        "compression_ratio": 1.602803738317757,
        "end": 2725.22,
        "id": 747,
        "no_speech_prob": 0.010652421973645687,
        "seek": 269822,
        "start": 2721.22,
        "temperature": 0,
        "text": " So I'm going to do a hard-coded, this is my own human learning algorithm.",
        "tokens": [
          51514,
          407,
          286,
          478,
          516,
          281,
          360,
          257,
          1152,
          12,
          66,
          12340,
          11,
          341,
          307,
          452,
          1065,
          1952,
          2539,
          9284,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.1423703124842693,
        "compression_ratio": 1.5919282511210762,
        "end": 2729.22,
        "id": 748,
        "no_speech_prob": 0.007345736958086491,
        "seek": 272522,
        "start": 2725.22,
        "temperature": 0,
        "text": " I've decided that this is what it means to predict which color would be better,",
        "tokens": [
          50364,
          286,
          600,
          3047,
          300,
          341,
          307,
          437,
          309,
          1355,
          281,
          6069,
          597,
          2017,
          576,
          312,
          1101,
          11,
          50564
        ]
      },
      {
        "avg_logprob": -0.1423703124842693,
        "compression_ratio": 1.5919282511210762,
        "end": 2736.22,
        "id": 749,
        "no_speech_prob": 0.007345736958086491,
        "seek": 272522,
        "start": 2729.22,
        "temperature": 0,
        "text": " and then I'm going to say let which equal color predictor RGB.",
        "tokens": [
          50564,
          293,
          550,
          286,
          478,
          516,
          281,
          584,
          718,
          597,
          2681,
          2017,
          6069,
          284,
          31231,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.1423703124842693,
        "compression_ratio": 1.5919282511210762,
        "end": 2742.22,
        "id": 750,
        "no_speech_prob": 0.007345736958086491,
        "seek": 272522,
        "start": 2736.22,
        "temperature": 0,
        "text": " So now we can see it's making that prediction based on my algorithm.",
        "tokens": [
          50914,
          407,
          586,
          321,
          393,
          536,
          309,
          311,
          1455,
          300,
          17630,
          2361,
          322,
          452,
          9284,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.1423703124842693,
        "compression_ratio": 1.5919282511210762,
        "end": 2745.22,
        "id": 751,
        "no_speech_prob": 0.007345736958086491,
        "seek": 272522,
        "start": 2742.22,
        "temperature": 0,
        "text": " I wrote an algorithm to make that prediction.",
        "tokens": [
          51214,
          286,
          4114,
          364,
          9284,
          281,
          652,
          300,
          17630,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.1423703124842693,
        "compression_ratio": 1.5919282511210762,
        "end": 2747.22,
        "id": 752,
        "no_speech_prob": 0.007345736958086491,
        "seek": 272522,
        "start": 2745.22,
        "temperature": 0,
        "text": " Now, so we've got this.",
        "tokens": [
          51364,
          823,
          11,
          370,
          321,
          600,
          658,
          341,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.1423703124842693,
        "compression_ratio": 1.5919282511210762,
        "end": 2748.22,
        "id": 753,
        "no_speech_prob": 0.007345736958086491,
        "seek": 272522,
        "start": 2747.22,
        "temperature": 0,
        "text": " We could be done.",
        "tokens": [
          51464,
          492,
          727,
          312,
          1096,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.1423703124842693,
        "compression_ratio": 1.5919282511210762,
        "end": 2749.22,
        "id": 754,
        "no_speech_prob": 0.007345736958086491,
        "seek": 272522,
        "start": 2748.22,
        "temperature": 0,
        "text": " No machine learning necessary.",
        "tokens": [
          51514,
          883,
          3479,
          2539,
          4818,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.1423703124842693,
        "compression_ratio": 1.5919282511210762,
        "end": 2751.22,
        "id": 755,
        "no_speech_prob": 0.007345736958086491,
        "seek": 272522,
        "start": 2749.22,
        "temperature": 0,
        "text": " I finished this project.",
        "tokens": [
          51564,
          286,
          4335,
          341,
          1716,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.17177974053148953,
        "compression_ratio": 1.7105263157894737,
        "end": 2755.22,
        "id": 756,
        "no_speech_prob": 0.0009253835887648165,
        "seek": 275122,
        "start": 2751.22,
        "temperature": 0,
        "text": " Now what I want to do, though, is I want to comment this out,",
        "tokens": [
          50364,
          823,
          437,
          286,
          528,
          281,
          360,
          11,
          1673,
          11,
          307,
          286,
          528,
          281,
          2871,
          341,
          484,
          11,
          50564
        ]
      },
      {
        "avg_logprob": -0.17177974053148953,
        "compression_ratio": 1.7105263157894737,
        "end": 2758.22,
        "id": 757,
        "no_speech_prob": 0.0009253835887648165,
        "seek": 275122,
        "start": 2755.22,
        "temperature": 0,
        "text": " and I'm going to say, what am I going to say?",
        "tokens": [
          50564,
          293,
          286,
          478,
          516,
          281,
          584,
          11,
          437,
          669,
          286,
          516,
          281,
          584,
          30,
          50714
        ]
      },
      {
        "avg_logprob": -0.17177974053148953,
        "compression_ratio": 1.7105263157894737,
        "end": 2761.22,
        "id": 758,
        "no_speech_prob": 0.0009253835887648165,
        "seek": 275122,
        "start": 2758.22,
        "temperature": 0,
        "text": " I'm going to say first I need to make some inputs.",
        "tokens": [
          50714,
          286,
          478,
          516,
          281,
          584,
          700,
          286,
          643,
          281,
          652,
          512,
          15743,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.17177974053148953,
        "compression_ratio": 1.7105263157894737,
        "end": 2766.22,
        "id": 759,
        "no_speech_prob": 0.0009253835887648165,
        "seek": 275122,
        "start": 2761.22,
        "temperature": 0,
        "text": " So the neural network library expects as inputs, right?",
        "tokens": [
          50864,
          407,
          264,
          18161,
          3209,
          6405,
          33280,
          382,
          15743,
          11,
          558,
          30,
          51114
        ]
      },
      {
        "avg_logprob": -0.17177974053148953,
        "compression_ratio": 1.7105263157894737,
        "end": 2772.22,
        "id": 760,
        "no_speech_prob": 0.0009253835887648165,
        "seek": 275122,
        "start": 2766.22,
        "temperature": 0,
        "text": " My library expects, and this is pretty typical of any kind of machine learning-based library that you might use.",
        "tokens": [
          51114,
          1222,
          6405,
          33280,
          11,
          293,
          341,
          307,
          1238,
          7476,
          295,
          604,
          733,
          295,
          3479,
          2539,
          12,
          6032,
          6405,
          300,
          291,
          1062,
          764,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.17177974053148953,
        "compression_ratio": 1.7105263157894737,
        "end": 2778.22,
        "id": 761,
        "no_speech_prob": 0.0009253835887648165,
        "seek": 275122,
        "start": 2772.22,
        "temperature": 0,
        "text": " It expects the inputs to come in as an array of three numbers,",
        "tokens": [
          51414,
          467,
          33280,
          264,
          15743,
          281,
          808,
          294,
          382,
          364,
          10225,
          295,
          1045,
          3547,
          11,
          51714
        ]
      },
      {
        "avg_logprob": -0.17310327953762478,
        "compression_ratio": 1.5752895752895753,
        "end": 2783.22,
        "id": 762,
        "no_speech_prob": 0.00004469402847462334,
        "seek": 277822,
        "start": 2778.22,
        "temperature": 0,
        "text": " and typically you're going to want to have those numbers normalized between 0 and 1.",
        "tokens": [
          50364,
          293,
          5850,
          291,
          434,
          516,
          281,
          528,
          281,
          362,
          729,
          3547,
          48704,
          1296,
          1958,
          293,
          502,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.17310327953762478,
        "compression_ratio": 1.5752895752895753,
        "end": 2788.22,
        "id": 763,
        "no_speech_prob": 0.00004469402847462334,
        "seek": 277822,
        "start": 2783.22,
        "temperature": 0,
        "text": " So this is what I need to send into the neural network.",
        "tokens": [
          50614,
          407,
          341,
          307,
          437,
          286,
          643,
          281,
          2845,
          666,
          264,
          18161,
          3209,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.17310327953762478,
        "compression_ratio": 1.5752895752895753,
        "end": 2792.22,
        "id": 764,
        "no_speech_prob": 0.00004469402847462334,
        "seek": 277822,
        "start": 2788.22,
        "temperature": 0,
        "text": " So inputs equals an array, and so how do I normalize these values?",
        "tokens": [
          50864,
          407,
          15743,
          6915,
          364,
          10225,
          11,
          293,
          370,
          577,
          360,
          286,
          2710,
          1125,
          613,
          4190,
          30,
          51064
        ]
      },
      {
        "avg_logprob": -0.17310327953762478,
        "compression_ratio": 1.5752895752895753,
        "end": 2795.22,
        "id": 765,
        "no_speech_prob": 0.00004469402847462334,
        "seek": 277822,
        "start": 2792.22,
        "temperature": 0,
        "text": " I can just divide them all by 255,",
        "tokens": [
          51064,
          286,
          393,
          445,
          9845,
          552,
          439,
          538,
          3552,
          20,
          11,
          51214
        ]
      },
      {
        "avg_logprob": -0.17310327953762478,
        "compression_ratio": 1.5752895752895753,
        "end": 2801.22,
        "id": 766,
        "no_speech_prob": 0.00004469402847462334,
        "seek": 277822,
        "start": 2795.22,
        "temperature": 0,
        "text": " and again, more likely there's going to be a much longer process of sort of cleaning and normalizing your data,",
        "tokens": [
          51214,
          293,
          797,
          11,
          544,
          3700,
          456,
          311,
          516,
          281,
          312,
          257,
          709,
          2854,
          1399,
          295,
          1333,
          295,
          8924,
          293,
          2710,
          3319,
          428,
          1412,
          11,
          51514
        ]
      },
      {
        "avg_logprob": -0.17310327953762478,
        "compression_ratio": 1.5752895752895753,
        "end": 2804.22,
        "id": 767,
        "no_speech_prob": 0.00004469402847462334,
        "seek": 277822,
        "start": 2801.22,
        "temperature": 0,
        "text": " but in this case of a single color, super easy to do.",
        "tokens": [
          51514,
          457,
          294,
          341,
          1389,
          295,
          257,
          2167,
          2017,
          11,
          1687,
          1858,
          281,
          360,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.20514410369250238,
        "compression_ratio": 1.696035242290749,
        "end": 2809.22,
        "id": 768,
        "no_speech_prob": 0.01384833361953497,
        "seek": 280422,
        "start": 2804.22,
        "temperature": 0,
        "text": " Now what I'm going to do is I'm going to ask for the output from the neural network.",
        "tokens": [
          50364,
          823,
          437,
          286,
          478,
          516,
          281,
          360,
          307,
          286,
          478,
          516,
          281,
          1029,
          337,
          264,
          5598,
          490,
          264,
          18161,
          3209,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.20514410369250238,
        "compression_ratio": 1.696035242290749,
        "end": 2814.22,
        "id": 769,
        "no_speech_prob": 0.01384833361953497,
        "seek": 280422,
        "start": 2809.22,
        "temperature": 0,
        "text": " Let outputs equal, and I'm going to say brain.",
        "tokens": [
          50614,
          961,
          23930,
          2681,
          11,
          293,
          286,
          478,
          516,
          281,
          584,
          3567,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.20514410369250238,
        "compression_ratio": 1.696035242290749,
        "end": 2823.22,
        "id": 770,
        "no_speech_prob": 0.01384833361953497,
        "seek": 280422,
        "start": 2814.22,
        "temperature": 0,
        "text": " And the function, right, the function to do the feedforward algorithm to send the data through and get the result back in my library is called predict,",
        "tokens": [
          50864,
          400,
          264,
          2445,
          11,
          558,
          11,
          264,
          2445,
          281,
          360,
          264,
          3154,
          13305,
          9284,
          281,
          2845,
          264,
          1412,
          807,
          293,
          483,
          264,
          1874,
          646,
          294,
          452,
          6405,
          307,
          1219,
          6069,
          11,
          51314
        ]
      },
      {
        "avg_logprob": -0.20514410369250238,
        "compression_ratio": 1.696035242290749,
        "end": 2824.22,
        "id": 771,
        "no_speech_prob": 0.01384833361953497,
        "seek": 280422,
        "start": 2823.22,
        "temperature": 0,
        "text": " because I'm making a prediction.",
        "tokens": [
          51314,
          570,
          286,
          478,
          1455,
          257,
          17630,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.20514410369250238,
        "compression_ratio": 1.696035242290749,
        "end": 2828.22,
        "id": 772,
        "no_speech_prob": 0.01384833361953497,
        "seek": 280422,
        "start": 2824.22,
        "temperature": 0,
        "text": " Another term for this might be inference, guess, that type of thing.",
        "tokens": [
          51364,
          3996,
          1433,
          337,
          341,
          1062,
          312,
          38253,
          11,
          2041,
          11,
          300,
          2010,
          295,
          551,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.2226183527991885,
        "compression_ratio": 1.5561797752808988,
        "end": 2834.22,
        "id": 773,
        "no_speech_prob": 0.043364375829696655,
        "seek": 282822,
        "start": 2829.22,
        "temperature": 0,
        "text": " So I'm going to say brain.predict, and I'm going to pass in the inputs.",
        "tokens": [
          50414,
          407,
          286,
          478,
          516,
          281,
          584,
          3567,
          13,
          79,
          24945,
          11,
          293,
          286,
          478,
          516,
          281,
          1320,
          294,
          264,
          15743,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.2226183527991885,
        "compression_ratio": 1.5561797752808988,
        "end": 2842.22,
        "id": 774,
        "no_speech_prob": 0.043364375829696655,
        "seek": 282822,
        "start": 2834.22,
        "temperature": 0,
        "text": " Now let me just console log those outputs just so we can see,",
        "tokens": [
          50664,
          823,
          718,
          385,
          445,
          11076,
          3565,
          729,
          23930,
          445,
          370,
          321,
          393,
          536,
          11,
          51064
        ]
      },
      {
        "avg_logprob": -0.2226183527991885,
        "compression_ratio": 1.5561797752808988,
        "end": 2846.22,
        "id": 775,
        "no_speech_prob": 0.043364375829696655,
        "seek": 282822,
        "start": 2842.22,
        "temperature": 0,
        "text": " and this is going to sort of break, but let's just see what the outputs look like.",
        "tokens": [
          51064,
          293,
          341,
          307,
          516,
          281,
          1333,
          295,
          1821,
          11,
          457,
          718,
          311,
          445,
          536,
          437,
          264,
          23930,
          574,
          411,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.2226183527991885,
        "compression_ratio": 1.5561797752808988,
        "end": 2850.22,
        "id": 776,
        "no_speech_prob": 0.043364375829696655,
        "seek": 282822,
        "start": 2846.22,
        "temperature": 0,
        "text": " Whoa, hold on.",
        "tokens": [
          51264,
          7521,
          11,
          1797,
          322,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.2226183527991885,
        "compression_ratio": 1.5561797752808988,
        "end": 2852.22,
        "id": 777,
        "no_speech_prob": 0.043364375829696655,
        "seek": 282822,
        "start": 2850.22,
        "temperature": 0,
        "text": " Why is this doing, oh, because draw is right.",
        "tokens": [
          51464,
          1545,
          307,
          341,
          884,
          11,
          1954,
          11,
          570,
          2642,
          307,
          558,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.18255555334170004,
        "compression_ratio": 1.7782608695652173,
        "end": 2858.22,
        "id": 778,
        "no_speech_prob": 0.15609943866729736,
        "seek": 285222,
        "start": 2852.22,
        "temperature": 0,
        "text": " So one thing I just realized is I'm kind of, I'm doing all this in the draw loop, which is sort of silly,",
        "tokens": [
          50364,
          407,
          472,
          551,
          286,
          445,
          5334,
          307,
          286,
          478,
          733,
          295,
          11,
          286,
          478,
          884,
          439,
          341,
          294,
          264,
          2642,
          6367,
          11,
          597,
          307,
          1333,
          295,
          11774,
          11,
          50664
        ]
      },
      {
        "avg_logprob": -0.18255555334170004,
        "compression_ratio": 1.7782608695652173,
        "end": 2869.22,
        "id": 779,
        "no_speech_prob": 0.15609943866729736,
        "seek": 285222,
        "start": 2858.22,
        "temperature": 0,
        "text": " so let me actually just say no loop, and then in pick color, in pick color, which is where, where's the pick color?",
        "tokens": [
          50664,
          370,
          718,
          385,
          767,
          445,
          584,
          572,
          6367,
          11,
          293,
          550,
          294,
          1888,
          2017,
          11,
          294,
          1888,
          2017,
          11,
          597,
          307,
          689,
          11,
          689,
          311,
          264,
          1888,
          2017,
          30,
          51214
        ]
      },
      {
        "avg_logprob": -0.18255555334170004,
        "compression_ratio": 1.7782608695652173,
        "end": 2870.22,
        "id": 780,
        "no_speech_prob": 0.15609943866729736,
        "seek": 285222,
        "start": 2869.22,
        "temperature": 0,
        "text": " Oh, right here.",
        "tokens": [
          51214,
          876,
          11,
          558,
          510,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.18255555334170004,
        "compression_ratio": 1.7782608695652173,
        "end": 2871.22,
        "id": 781,
        "no_speech_prob": 0.15609943866729736,
        "seek": 285222,
        "start": 2870.22,
        "temperature": 0,
        "text": " I'm going to say redraw.",
        "tokens": [
          51264,
          286,
          478,
          516,
          281,
          584,
          2182,
          5131,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.18255555334170004,
        "compression_ratio": 1.7782608695652173,
        "end": 2873.22,
        "id": 782,
        "no_speech_prob": 0.15609943866729736,
        "seek": 285222,
        "start": 2871.22,
        "temperature": 0,
        "text": " So I only want to like redraw the canvas up there.",
        "tokens": [
          51314,
          407,
          286,
          787,
          528,
          281,
          411,
          2182,
          5131,
          264,
          16267,
          493,
          456,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.18255555334170004,
        "compression_ratio": 1.7782608695652173,
        "end": 2878.22,
        "id": 783,
        "no_speech_prob": 0.15609943866729736,
        "seek": 285222,
        "start": 2873.22,
        "temperature": 0,
        "text": " I don't have anything animating, so I don't need the draw loop to be going over and over again.",
        "tokens": [
          51414,
          286,
          500,
          380,
          362,
          1340,
          2383,
          990,
          11,
          370,
          286,
          500,
          380,
          643,
          264,
          2642,
          6367,
          281,
          312,
          516,
          670,
          293,
          670,
          797,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.18902045314751784,
        "compression_ratio": 1.599078341013825,
        "end": 2885.22,
        "id": 784,
        "no_speech_prob": 0.010328083299100399,
        "seek": 287822,
        "start": 2879.22,
        "temperature": 0,
        "text": " So cannot read property predict of undefined sketch.js.",
        "tokens": [
          50414,
          407,
          2644,
          1401,
          4707,
          6069,
          295,
          674,
          5666,
          2001,
          12325,
          13,
          25530,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.18902045314751784,
        "compression_ratio": 1.599078341013825,
        "end": 2887.22,
        "id": 785,
        "no_speech_prob": 0.010328083299100399,
        "seek": 287822,
        "start": 2885.22,
        "temperature": 0,
        "text": " Oh, you know what?",
        "tokens": [
          50714,
          876,
          11,
          291,
          458,
          437,
          30,
          50814
        ]
      },
      {
        "avg_logprob": -0.18902045314751784,
        "compression_ratio": 1.599078341013825,
        "end": 2888.22,
        "id": 786,
        "no_speech_prob": 0.010328083299100399,
        "seek": 287822,
        "start": 2887.22,
        "temperature": 0,
        "text": " Why do I have that bug?",
        "tokens": [
          50814,
          1545,
          360,
          286,
          362,
          300,
          7426,
          30,
          50864
        ]
      },
      {
        "avg_logprob": -0.18902045314751784,
        "compression_ratio": 1.599078341013825,
        "end": 2891.22,
        "id": 787,
        "no_speech_prob": 0.010328083299100399,
        "seek": 287822,
        "start": 2888.22,
        "temperature": 0,
        "text": " I created the neural network after I called pick color.",
        "tokens": [
          50864,
          286,
          2942,
          264,
          18161,
          3209,
          934,
          286,
          1219,
          1888,
          2017,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.18902045314751784,
        "compression_ratio": 1.599078341013825,
        "end": 2894.22,
        "id": 788,
        "no_speech_prob": 0.010328083299100399,
        "seek": 287822,
        "start": 2891.22,
        "temperature": 0,
        "text": " The neural network needs to exist before I call pick color.",
        "tokens": [
          51014,
          440,
          18161,
          3209,
          2203,
          281,
          2514,
          949,
          286,
          818,
          1888,
          2017,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.18902045314751784,
        "compression_ratio": 1.599078341013825,
        "end": 2896.22,
        "id": 789,
        "no_speech_prob": 0.010328083299100399,
        "seek": 287822,
        "start": 2894.22,
        "temperature": 0,
        "text": " Okay, that's good to know.",
        "tokens": [
          51164,
          1033,
          11,
          300,
          311,
          665,
          281,
          458,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.18902045314751784,
        "compression_ratio": 1.599078341013825,
        "end": 2900.22,
        "id": 790,
        "no_speech_prob": 0.010328083299100399,
        "seek": 287822,
        "start": 2896.22,
        "temperature": 0,
        "text": " Great, so we can see, look at this, and why do I have this happen twice?",
        "tokens": [
          51264,
          3769,
          11,
          370,
          321,
          393,
          536,
          11,
          574,
          412,
          341,
          11,
          293,
          983,
          360,
          286,
          362,
          341,
          1051,
          6091,
          30,
          51464
        ]
      },
      {
        "avg_logprob": -0.18902045314751784,
        "compression_ratio": 1.599078341013825,
        "end": 2905.22,
        "id": 791,
        "no_speech_prob": 0.010328083299100399,
        "seek": 287822,
        "start": 2900.22,
        "temperature": 0,
        "text": " 29, why is that happening twice?",
        "tokens": [
          51464,
          9413,
          11,
          983,
          307,
          300,
          2737,
          6091,
          30,
          51714
        ]
      },
      {
        "avg_logprob": -0.1807891845703125,
        "compression_ratio": 1.5982905982905984,
        "end": 2914.22,
        "id": 792,
        "no_speech_prob": 0.015424421057105064,
        "seek": 290522,
        "start": 2905.22,
        "temperature": 0,
        "text": " No, I guess it's going through the draw loop once, so maybe, yeah, interestingly.",
        "tokens": [
          50364,
          883,
          11,
          286,
          2041,
          309,
          311,
          516,
          807,
          264,
          2642,
          6367,
          1564,
          11,
          370,
          1310,
          11,
          1338,
          11,
          25873,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.1807891845703125,
        "compression_ratio": 1.5982905982905984,
        "end": 2915.22,
        "id": 793,
        "no_speech_prob": 0.015424421057105064,
        "seek": 290522,
        "start": 2914.22,
        "temperature": 0,
        "text": " Okay, I'm not going to worry about it.",
        "tokens": [
          50814,
          1033,
          11,
          286,
          478,
          406,
          516,
          281,
          3292,
          466,
          309,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.1807891845703125,
        "compression_ratio": 1.5982905982905984,
        "end": 2918.22,
        "id": 794,
        "no_speech_prob": 0.015424421057105064,
        "seek": 290522,
        "start": 2915.22,
        "temperature": 0,
        "text": " I'm not going to get, I'll fiddle with that later.",
        "tokens": [
          50864,
          286,
          478,
          406,
          516,
          281,
          483,
          11,
          286,
          603,
          24553,
          2285,
          365,
          300,
          1780,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.1807891845703125,
        "compression_ratio": 1.5982905982905984,
        "end": 2927.22,
        "id": 795,
        "no_speech_prob": 0.015424421057105064,
        "seek": 290522,
        "start": 2918.22,
        "temperature": 0,
        "text": " The point is, whoops, every time I click, we can see this is the output of the neural network.",
        "tokens": [
          51014,
          440,
          935,
          307,
          11,
          567,
          3370,
          11,
          633,
          565,
          286,
          2052,
          11,
          321,
          393,
          536,
          341,
          307,
          264,
          5598,
          295,
          264,
          18161,
          3209,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.1807891845703125,
        "compression_ratio": 1.5982905982905984,
        "end": 2934.22,
        "id": 796,
        "no_speech_prob": 0.015424421057105064,
        "seek": 290522,
        "start": 2927.22,
        "temperature": 0,
        "text": " It's an array with two floating point numbers, and those I'm considering to be like the probability, right?",
        "tokens": [
          51464,
          467,
          311,
          364,
          10225,
          365,
          732,
          12607,
          935,
          3547,
          11,
          293,
          729,
          286,
          478,
          8079,
          281,
          312,
          411,
          264,
          8482,
          11,
          558,
          30,
          51814
        ]
      },
      {
        "avg_logprob": -0.19044025127704328,
        "compression_ratio": 1.778877887788779,
        "end": 2939.22,
        "id": 797,
        "no_speech_prob": 0.008985333144664764,
        "seek": 293422,
        "start": 2934.22,
        "temperature": 0,
        "text": " If this number is higher, it should be a white, maybe black is the correct color.",
        "tokens": [
          50364,
          759,
          341,
          1230,
          307,
          2946,
          11,
          309,
          820,
          312,
          257,
          2418,
          11,
          1310,
          2211,
          307,
          264,
          3006,
          2017,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.19044025127704328,
        "compression_ratio": 1.778877887788779,
        "end": 2944.22,
        "id": 798,
        "no_speech_prob": 0.008985333144664764,
        "seek": 293422,
        "start": 2939.22,
        "temperature": 0,
        "text": " If this number is higher, the other one, whoops, my hand disappeared, the white color should be the one.",
        "tokens": [
          50614,
          759,
          341,
          1230,
          307,
          2946,
          11,
          264,
          661,
          472,
          11,
          567,
          3370,
          11,
          452,
          1011,
          13954,
          11,
          264,
          2418,
          2017,
          820,
          312,
          264,
          472,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.19044025127704328,
        "compression_ratio": 1.778877887788779,
        "end": 2946.22,
        "id": 799,
        "no_speech_prob": 0.008985333144664764,
        "seek": 293422,
        "start": 2944.22,
        "temperature": 0,
        "text": " Now, I haven't implemented some things.",
        "tokens": [
          50864,
          823,
          11,
          286,
          2378,
          380,
          12270,
          512,
          721,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.19044025127704328,
        "compression_ratio": 1.778877887788779,
        "end": 2950.22,
        "id": 800,
        "no_speech_prob": 0.008985333144664764,
        "seek": 293422,
        "start": 2946.22,
        "temperature": 0,
        "text": " There's a particular algorithm which I really should put into my neural network library called softmax.",
        "tokens": [
          50964,
          821,
          311,
          257,
          1729,
          9284,
          597,
          286,
          534,
          820,
          829,
          666,
          452,
          18161,
          3209,
          6405,
          1219,
          2787,
          41167,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.19044025127704328,
        "compression_ratio": 1.778877887788779,
        "end": 2956.22,
        "id": 801,
        "no_speech_prob": 0.008985333144664764,
        "seek": 293422,
        "start": 2950.22,
        "temperature": 0,
        "text": " I'll have to make a video tutorial about that in the future, which would ensure that these two numbers,",
        "tokens": [
          51164,
          286,
          603,
          362,
          281,
          652,
          257,
          960,
          7073,
          466,
          300,
          294,
          264,
          2027,
          11,
          597,
          576,
          5586,
          300,
          613,
          732,
          3547,
          11,
          51464
        ]
      },
      {
        "avg_logprob": -0.19044025127704328,
        "compression_ratio": 1.778877887788779,
        "end": 2961.22,
        "id": 802,
        "no_speech_prob": 0.008985333144664764,
        "seek": 293422,
        "start": 2956.22,
        "temperature": 0,
        "text": " these add up to a total of one and really represent a probability, but my neural network is very simple.",
        "tokens": [
          51464,
          613,
          909,
          493,
          281,
          257,
          3217,
          295,
          472,
          293,
          534,
          2906,
          257,
          8482,
          11,
          457,
          452,
          18161,
          3209,
          307,
          588,
          2199,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.21885332010560116,
        "compression_ratio": 1.4899328859060403,
        "end": 2964.22,
        "id": 803,
        "no_speech_prob": 0.013428120873868465,
        "seek": 296122,
        "start": 2961.22,
        "temperature": 0,
        "text": " I can just look at which of these output numbers is bigger.",
        "tokens": [
          50364,
          286,
          393,
          445,
          574,
          412,
          597,
          295,
          613,
          5598,
          3547,
          307,
          3801,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.21885332010560116,
        "compression_ratio": 1.4899328859060403,
        "end": 2974.22,
        "id": 804,
        "no_speech_prob": 0.013428120873868465,
        "seek": 296122,
        "start": 2964.22,
        "temperature": 0,
        "text": " So I can say then, right here, I can say now, if outputs index zero is greater than outputs index one,",
        "tokens": [
          50514,
          407,
          286,
          393,
          584,
          550,
          11,
          558,
          510,
          11,
          286,
          393,
          584,
          586,
          11,
          498,
          23930,
          8186,
          4018,
          307,
          5044,
          813,
          23930,
          8186,
          472,
          11,
          51014
        ]
      },
      {
        "avg_logprob": -0.21885332010560116,
        "compression_ratio": 1.4899328859060403,
        "end": 2984.22,
        "id": 805,
        "no_speech_prob": 0.013428120873868465,
        "seek": 296122,
        "start": 2974.22,
        "temperature": 0,
        "text": " we'll make that mean return black, otherwise, return white.",
        "tokens": [
          51014,
          321,
          603,
          652,
          300,
          914,
          2736,
          2211,
          11,
          5911,
          11,
          2736,
          2418,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.17621512248598295,
        "compression_ratio": 1.738197424892704,
        "end": 2991.22,
        "id": 806,
        "no_speech_prob": 0.018832525238394737,
        "seek": 298422,
        "start": 2984.22,
        "temperature": 0,
        "text": " So now, I have my color predictor function no longer uses a hard-coded algorithm.",
        "tokens": [
          50364,
          407,
          586,
          11,
          286,
          362,
          452,
          2017,
          6069,
          284,
          2445,
          572,
          2854,
          4960,
          257,
          1152,
          12,
          66,
          12340,
          9284,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.17621512248598295,
        "compression_ratio": 1.738197424892704,
        "end": 2995.22,
        "id": 807,
        "no_speech_prob": 0.018832525238394737,
        "seek": 298422,
        "start": 2991.22,
        "temperature": 0,
        "text": " It uses the results of sending the input data through a neural network.",
        "tokens": [
          50714,
          467,
          4960,
          264,
          3542,
          295,
          7750,
          264,
          4846,
          1412,
          807,
          257,
          18161,
          3209,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.17621512248598295,
        "compression_ratio": 1.738197424892704,
        "end": 3000.22,
        "id": 808,
        "no_speech_prob": 0.018832525238394737,
        "seek": 298422,
        "start": 2995.22,
        "temperature": 0,
        "text": " So let's go ahead and run this, and I can click.",
        "tokens": [
          50914,
          407,
          718,
          311,
          352,
          2286,
          293,
          1190,
          341,
          11,
          293,
          286,
          393,
          2052,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.17621512248598295,
        "compression_ratio": 1.738197424892704,
        "end": 3003.22,
        "id": 809,
        "no_speech_prob": 0.018832525238394737,
        "seek": 298422,
        "start": 3000.22,
        "temperature": 0,
        "text": " Now, you can see here, it's kind of always picking white.",
        "tokens": [
          51164,
          823,
          11,
          291,
          393,
          536,
          510,
          11,
          309,
          311,
          733,
          295,
          1009,
          8867,
          2418,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.17621512248598295,
        "compression_ratio": 1.738197424892704,
        "end": 3006.22,
        "id": 810,
        "no_speech_prob": 0.018832525238394737,
        "seek": 298422,
        "start": 3003.22,
        "temperature": 0,
        "text": " If I refresh, still always picking white.",
        "tokens": [
          51314,
          759,
          286,
          15134,
          11,
          920,
          1009,
          8867,
          2418,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.17621512248598295,
        "compression_ratio": 1.738197424892704,
        "end": 3009.22,
        "id": 811,
        "no_speech_prob": 0.018832525238394737,
        "seek": 298422,
        "start": 3006.22,
        "temperature": 0,
        "text": " If I refresh, it's kind of always picking black.",
        "tokens": [
          51464,
          759,
          286,
          15134,
          11,
          309,
          311,
          733,
          295,
          1009,
          8867,
          2211,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.17621512248598295,
        "compression_ratio": 1.738197424892704,
        "end": 3010.22,
        "id": 812,
        "no_speech_prob": 0.018832525238394737,
        "seek": 298422,
        "start": 3009.22,
        "temperature": 0,
        "text": " So what's going on here?",
        "tokens": [
          51614,
          407,
          437,
          311,
          516,
          322,
          510,
          30,
          51664
        ]
      },
      {
        "avg_logprob": -0.17621512248598295,
        "compression_ratio": 1.738197424892704,
        "end": 3012.22,
        "id": 813,
        "no_speech_prob": 0.018832525238394737,
        "seek": 298422,
        "start": 3010.22,
        "temperature": 0,
        "text": " How come this isn't working?",
        "tokens": [
          51664,
          1012,
          808,
          341,
          1943,
          380,
          1364,
          30,
          51764
        ]
      },
      {
        "avg_logprob": -0.1763449169340588,
        "compression_ratio": 1.7098039215686274,
        "end": 3014.22,
        "id": 814,
        "no_speech_prob": 0.010986756533384323,
        "seek": 301222,
        "start": 3012.22,
        "temperature": 0,
        "text": " Why is this not learned properly?",
        "tokens": [
          50364,
          1545,
          307,
          341,
          406,
          3264,
          6108,
          30,
          50464
        ]
      },
      {
        "avg_logprob": -0.1763449169340588,
        "compression_ratio": 1.7098039215686274,
        "end": 3017.22,
        "id": 815,
        "no_speech_prob": 0.010986756533384323,
        "seek": 301222,
        "start": 3014.22,
        "temperature": 0,
        "text": " Which color should go on top of the other color?",
        "tokens": [
          50464,
          3013,
          2017,
          820,
          352,
          322,
          1192,
          295,
          264,
          661,
          2017,
          30,
          50614
        ]
      },
      {
        "avg_logprob": -0.1763449169340588,
        "compression_ratio": 1.7098039215686274,
        "end": 3019.22,
        "id": 816,
        "no_speech_prob": 0.010986756533384323,
        "seek": 301222,
        "start": 3017.22,
        "temperature": 0,
        "text": " Guess what?",
        "tokens": [
          50614,
          17795,
          437,
          30,
          50714
        ]
      },
      {
        "avg_logprob": -0.1763449169340588,
        "compression_ratio": 1.7098039215686274,
        "end": 3025.22,
        "id": 817,
        "no_speech_prob": 0.010986756533384323,
        "seek": 301222,
        "start": 3019.22,
        "temperature": 0,
        "text": " The entire mechanic, all of the settings, all of the parameters, all of the weights of all these connections",
        "tokens": [
          50714,
          440,
          2302,
          23860,
          11,
          439,
          295,
          264,
          6257,
          11,
          439,
          295,
          264,
          9834,
          11,
          439,
          295,
          264,
          17443,
          295,
          439,
          613,
          9271,
          51014
        ]
      },
      {
        "avg_logprob": -0.1763449169340588,
        "compression_ratio": 1.7098039215686274,
        "end": 3029.22,
        "id": 818,
        "no_speech_prob": 0.010986756533384323,
        "seek": 301222,
        "start": 3025.22,
        "temperature": 0,
        "text": " of the neural network were initialized completely randomly.",
        "tokens": [
          51014,
          295,
          264,
          18161,
          3209,
          645,
          5883,
          1602,
          2584,
          16979,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.1763449169340588,
        "compression_ratio": 1.7098039215686274,
        "end": 3033.22,
        "id": 819,
        "no_speech_prob": 0.010986756533384323,
        "seek": 301222,
        "start": 3029.22,
        "temperature": 0,
        "text": " A neural network isn't just going to learn as if by magic.",
        "tokens": [
          51214,
          316,
          18161,
          3209,
          1943,
          380,
          445,
          516,
          281,
          1466,
          382,
          498,
          538,
          5585,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.1763449169340588,
        "compression_ratio": 1.7098039215686274,
        "end": 3039.22,
        "id": 820,
        "no_speech_prob": 0.010986756533384323,
        "seek": 301222,
        "start": 3033.22,
        "temperature": 0,
        "text": " It needs to be taught, and there are lots of different strategies for training and working with a neural network.",
        "tokens": [
          51414,
          467,
          2203,
          281,
          312,
          5928,
          11,
          293,
          456,
          366,
          3195,
          295,
          819,
          9029,
          337,
          3097,
          293,
          1364,
          365,
          257,
          18161,
          3209,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.19456905399987456,
        "compression_ratio": 1.5658362989323844,
        "end": 3043.22,
        "id": 821,
        "no_speech_prob": 0.0028008967638015747,
        "seek": 303922,
        "start": 3039.22,
        "temperature": 0,
        "text": " One of those strategies is something called supervised learning.",
        "tokens": [
          50364,
          1485,
          295,
          729,
          9029,
          307,
          746,
          1219,
          46533,
          2539,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.19456905399987456,
        "compression_ratio": 1.5658362989323844,
        "end": 3047.22,
        "id": 822,
        "no_speech_prob": 0.0028008967638015747,
        "seek": 303922,
        "start": 3043.22,
        "temperature": 0,
        "text": " You probably can't supervise learning, which I have covered in other videos,",
        "tokens": [
          50564,
          509,
          1391,
          393,
          380,
          37971,
          908,
          2539,
          11,
          597,
          286,
          362,
          5343,
          294,
          661,
          2145,
          11,
          50764
        ]
      },
      {
        "avg_logprob": -0.19456905399987456,
        "compression_ratio": 1.5658362989323844,
        "end": 3051.22,
        "id": 823,
        "no_speech_prob": 0.0028008967638015747,
        "seek": 303922,
        "start": 3047.22,
        "temperature": 0,
        "text": " in particular, my doodle classification coding challenge.",
        "tokens": [
          50764,
          294,
          1729,
          11,
          452,
          360,
          30013,
          21538,
          17720,
          3430,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.19456905399987456,
        "compression_ratio": 1.5658362989323844,
        "end": 3054.22,
        "id": 824,
        "no_speech_prob": 0.0028008967638015747,
        "seek": 303922,
        "start": 3051.22,
        "temperature": 0,
        "text": " So you might look at that as an example.",
        "tokens": [
          50964,
          407,
          291,
          1062,
          574,
          412,
          300,
          382,
          364,
          1365,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.19456905399987456,
        "compression_ratio": 1.5658362989323844,
        "end": 3055.22,
        "id": 825,
        "no_speech_prob": 0.0028008967638015747,
        "seek": 303922,
        "start": 3054.22,
        "temperature": 0,
        "text": " But what's going on here?",
        "tokens": [
          51114,
          583,
          437,
          311,
          516,
          322,
          510,
          30,
          51164
        ]
      },
      {
        "avg_logprob": -0.19456905399987456,
        "compression_ratio": 1.5658362989323844,
        "end": 3060.22,
        "id": 826,
        "no_speech_prob": 0.0028008967638015747,
        "seek": 303922,
        "start": 3055.22,
        "temperature": 0,
        "text": " In a normal, more data science-driven machine learning context,",
        "tokens": [
          51164,
          682,
          257,
          2710,
          11,
          544,
          1412,
          3497,
          12,
          25456,
          3479,
          2539,
          4319,
          11,
          51414
        ]
      },
      {
        "avg_logprob": -0.19456905399987456,
        "compression_ratio": 1.5658362989323844,
        "end": 3063.22,
        "id": 827,
        "no_speech_prob": 0.0028008967638015747,
        "seek": 303922,
        "start": 3060.22,
        "temperature": 0,
        "text": " we might prepare a giant training set.",
        "tokens": [
          51414,
          321,
          1062,
          5940,
          257,
          7410,
          3097,
          992,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.19456905399987456,
        "compression_ratio": 1.5658362989323844,
        "end": 3067.22,
        "id": 828,
        "no_speech_prob": 0.0028008967638015747,
        "seek": 303922,
        "start": 3063.22,
        "temperature": 0,
        "text": " I'm going to make a big spreadsheet of every RGB color I can think of,",
        "tokens": [
          51564,
          286,
          478,
          516,
          281,
          652,
          257,
          955,
          27733,
          295,
          633,
          31231,
          2017,
          286,
          393,
          519,
          295,
          11,
          51764
        ]
      },
      {
        "avg_logprob": -0.16240713331434461,
        "compression_ratio": 1.962962962962963,
        "end": 3069.22,
        "id": 829,
        "no_speech_prob": 0.016402656212449074,
        "seek": 306722,
        "start": 3067.22,
        "temperature": 0,
        "text": " and which one looks better, black or white.",
        "tokens": [
          50364,
          293,
          597,
          472,
          1542,
          1101,
          11,
          2211,
          420,
          2418,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.16240713331434461,
        "compression_ratio": 1.962962962962963,
        "end": 3074.22,
        "id": 830,
        "no_speech_prob": 0.016402656212449074,
        "seek": 306722,
        "start": 3069.22,
        "temperature": 0,
        "text": " That's my training data set to pass through and train this neural network with.",
        "tokens": [
          50464,
          663,
          311,
          452,
          3097,
          1412,
          992,
          281,
          1320,
          807,
          293,
          3847,
          341,
          18161,
          3209,
          365,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.16240713331434461,
        "compression_ratio": 1.962962962962963,
        "end": 3076.22,
        "id": 831,
        "no_speech_prob": 0.016402656212449074,
        "seek": 306722,
        "start": 3074.22,
        "temperature": 0,
        "text": " Then I'm going to have a testing data set,",
        "tokens": [
          50714,
          1396,
          286,
          478,
          516,
          281,
          362,
          257,
          4997,
          1412,
          992,
          11,
          50814
        ]
      },
      {
        "avg_logprob": -0.16240713331434461,
        "compression_ratio": 1.962962962962963,
        "end": 3080.22,
        "id": 832,
        "no_speech_prob": 0.016402656212449074,
        "seek": 306722,
        "start": 3076.22,
        "temperature": 0,
        "text": " and that testing data set is not part of the training data set",
        "tokens": [
          50814,
          293,
          300,
          4997,
          1412,
          992,
          307,
          406,
          644,
          295,
          264,
          3097,
          1412,
          992,
          51014
        ]
      },
      {
        "avg_logprob": -0.16240713331434461,
        "compression_ratio": 1.962962962962963,
        "end": 3082.22,
        "id": 833,
        "no_speech_prob": 0.016402656212449074,
        "seek": 306722,
        "start": 3080.22,
        "temperature": 0,
        "text": " because I don't want the neural network to know about it,",
        "tokens": [
          51014,
          570,
          286,
          500,
          380,
          528,
          264,
          18161,
          3209,
          281,
          458,
          466,
          309,
          11,
          51114
        ]
      },
      {
        "avg_logprob": -0.16240713331434461,
        "compression_ratio": 1.962962962962963,
        "end": 3087.22,
        "id": 834,
        "no_speech_prob": 0.016402656212449074,
        "seek": 306722,
        "start": 3082.22,
        "temperature": 0,
        "text": " but it also has a bunch of labeled data, colors with black or white labels.",
        "tokens": [
          51114,
          457,
          309,
          611,
          575,
          257,
          3840,
          295,
          21335,
          1412,
          11,
          4577,
          365,
          2211,
          420,
          2418,
          16949,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.16240713331434461,
        "compression_ratio": 1.962962962962963,
        "end": 3092.22,
        "id": 835,
        "no_speech_prob": 0.016402656212449074,
        "seek": 306722,
        "start": 3087.22,
        "temperature": 0,
        "text": " Then I'm going to pass that through and see how well the neural network does guessing against those.",
        "tokens": [
          51364,
          1396,
          286,
          478,
          516,
          281,
          1320,
          300,
          807,
          293,
          536,
          577,
          731,
          264,
          18161,
          3209,
          775,
          17939,
          1970,
          729,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.16240713331434461,
        "compression_ratio": 1.962962962962963,
        "end": 3095.22,
        "id": 836,
        "no_speech_prob": 0.016402656212449074,
        "seek": 306722,
        "start": 3092.22,
        "temperature": 0,
        "text": " And if it starts to do well, then I can say my model is complete,",
        "tokens": [
          51614,
          400,
          498,
          309,
          3719,
          281,
          360,
          731,
          11,
          550,
          286,
          393,
          584,
          452,
          2316,
          307,
          3566,
          11,
          51764
        ]
      },
      {
        "avg_logprob": -0.1267158334905451,
        "compression_ratio": 1.7898832684824904,
        "end": 3099.22,
        "id": 837,
        "no_speech_prob": 0.00521996570751071,
        "seek": 309522,
        "start": 3095.22,
        "temperature": 0,
        "text": " it has been trained, I can save it, and I can deploy it in some application",
        "tokens": [
          50364,
          309,
          575,
          668,
          8895,
          11,
          286,
          393,
          3155,
          309,
          11,
          293,
          286,
          393,
          7274,
          309,
          294,
          512,
          3861,
          50564
        ]
      },
      {
        "avg_logprob": -0.1267158334905451,
        "compression_ratio": 1.7898832684824904,
        "end": 3101.22,
        "id": 838,
        "no_speech_prob": 0.00521996570751071,
        "seek": 309522,
        "start": 3099.22,
        "temperature": 0,
        "text": " which has to pick black or white on the fly.",
        "tokens": [
          50564,
          597,
          575,
          281,
          1888,
          2211,
          420,
          2418,
          322,
          264,
          3603,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.1267158334905451,
        "compression_ratio": 1.7898832684824904,
        "end": 3103.22,
        "id": 839,
        "no_speech_prob": 0.00521996570751071,
        "seek": 309522,
        "start": 3101.22,
        "temperature": 0,
        "text": " But I'm not going to do any of that in this video.",
        "tokens": [
          50664,
          583,
          286,
          478,
          406,
          516,
          281,
          360,
          604,
          295,
          300,
          294,
          341,
          960,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.1267158334905451,
        "compression_ratio": 1.7898832684824904,
        "end": 3107.22,
        "id": 840,
        "no_speech_prob": 0.00521996570751071,
        "seek": 309522,
        "start": 3103.22,
        "temperature": 0,
        "text": " I'm going to live in sort of a loosey-goosey interactive world",
        "tokens": [
          50764,
          286,
          478,
          516,
          281,
          1621,
          294,
          1333,
          295,
          257,
          9612,
          88,
          12,
          1571,
          541,
          88,
          15141,
          1002,
          50964
        ]
      },
      {
        "avg_logprob": -0.1267158334905451,
        "compression_ratio": 1.7898832684824904,
        "end": 3109.22,
        "id": 841,
        "no_speech_prob": 0.00521996570751071,
        "seek": 309522,
        "start": 3107.22,
        "temperature": 0,
        "text": " where I'm just going to let it guess randomly,",
        "tokens": [
          50964,
          689,
          286,
          478,
          445,
          516,
          281,
          718,
          309,
          2041,
          16979,
          11,
          51064
        ]
      },
      {
        "avg_logprob": -0.1267158334905451,
        "compression_ratio": 1.7898832684824904,
        "end": 3112.22,
        "id": 842,
        "no_speech_prob": 0.00521996570751071,
        "seek": 309522,
        "start": 3109.22,
        "temperature": 0,
        "text": " and I'm going to click in order to correct it.",
        "tokens": [
          51064,
          293,
          286,
          478,
          516,
          281,
          2052,
          294,
          1668,
          281,
          3006,
          309,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.1267158334905451,
        "compression_ratio": 1.7898832684824904,
        "end": 3117.22,
        "id": 843,
        "no_speech_prob": 0.00521996570751071,
        "seek": 309522,
        "start": 3112.22,
        "temperature": 0,
        "text": " So I'm going to train the neural network one data point at a time",
        "tokens": [
          51214,
          407,
          286,
          478,
          516,
          281,
          3847,
          264,
          18161,
          3209,
          472,
          1412,
          935,
          412,
          257,
          565,
          51464
        ]
      },
      {
        "avg_logprob": -0.1267158334905451,
        "compression_ratio": 1.7898832684824904,
        "end": 3121.22,
        "id": 844,
        "no_speech_prob": 0.00521996570751071,
        "seek": 309522,
        "start": 3117.22,
        "temperature": 0,
        "text": " with no training data, no testing data, just random data as I go.",
        "tokens": [
          51464,
          365,
          572,
          3097,
          1412,
          11,
          572,
          4997,
          1412,
          11,
          445,
          4974,
          1412,
          382,
          286,
          352,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.1857905711942506,
        "compression_ratio": 1.6037735849056605,
        "end": 3124.22,
        "id": 845,
        "no_speech_prob": 0.000034807948395609856,
        "seek": 312122,
        "start": 3121.22,
        "temperature": 0,
        "text": " So you might think about how would you restructure this",
        "tokens": [
          50364,
          407,
          291,
          1062,
          519,
          466,
          577,
          576,
          291,
          1472,
          2885,
          341,
          50514
        ]
      },
      {
        "avg_logprob": -0.1857905711942506,
        "compression_ratio": 1.6037735849056605,
        "end": 3131.22,
        "id": 846,
        "no_speech_prob": 0.000034807948395609856,
        "seek": 312122,
        "start": 3124.22,
        "temperature": 0,
        "text": " in a more sort of traditional training, testing, deployment context.",
        "tokens": [
          50514,
          294,
          257,
          544,
          1333,
          295,
          5164,
          3097,
          11,
          4997,
          11,
          19317,
          4319,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.1857905711942506,
        "compression_ratio": 1.6037735849056605,
        "end": 3133.22,
        "id": 847,
        "no_speech_prob": 0.000034807948395609856,
        "seek": 312122,
        "start": 3131.22,
        "temperature": 0,
        "text": " So what do I mean by that?",
        "tokens": [
          50864,
          407,
          437,
          360,
          286,
          914,
          538,
          300,
          30,
          50964
        ]
      },
      {
        "avg_logprob": -0.1857905711942506,
        "compression_ratio": 1.6037735849056605,
        "end": 3135.22,
        "id": 848,
        "no_speech_prob": 0.000034807948395609856,
        "seek": 312122,
        "start": 3133.22,
        "temperature": 0,
        "text": " What I want to do is I'm going to create two buttons.",
        "tokens": [
          50964,
          708,
          286,
          528,
          281,
          360,
          307,
          286,
          478,
          516,
          281,
          1884,
          732,
          9905,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.1857905711942506,
        "compression_ratio": 1.6037735849056605,
        "end": 3139.22,
        "id": 849,
        "no_speech_prob": 0.000034807948395609856,
        "seek": 312122,
        "start": 3137.22,
        "temperature": 0,
        "text": " I am going to... let's just do this here.",
        "tokens": [
          51164,
          286,
          669,
          516,
          281,
          485,
          718,
          311,
          445,
          360,
          341,
          510,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.1857905711942506,
        "compression_ratio": 1.6037735849056605,
        "end": 3145.22,
        "id": 850,
        "no_speech_prob": 0.000034807948395609856,
        "seek": 312122,
        "start": 3139.22,
        "temperature": 0,
        "text": " Let's do let wButton.",
        "tokens": [
          51264,
          961,
          311,
          360,
          718,
          261,
          7835,
          1756,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.1857905711942506,
        "compression_ratio": 1.6037735849056605,
        "end": 3149.22,
        "id": 851,
        "no_speech_prob": 0.000034807948395609856,
        "seek": 312122,
        "start": 3145.22,
        "temperature": 0,
        "text": " I'm going to have a wButton and a bButton, white button, black button.",
        "tokens": [
          51564,
          286,
          478,
          516,
          281,
          362,
          257,
          261,
          7835,
          1756,
          293,
          257,
          272,
          7835,
          1756,
          11,
          2418,
          2960,
          11,
          2211,
          2960,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.1789669925219392,
        "compression_ratio": 1.4569536423841059,
        "end": 3156.22,
        "id": 852,
        "no_speech_prob": 0.000031692616175860167,
        "seek": 314922,
        "start": 3149.22,
        "temperature": 0,
        "text": " I'm going to say wButton equals createButton, white,",
        "tokens": [
          50364,
          286,
          478,
          516,
          281,
          584,
          261,
          7835,
          1756,
          6915,
          1884,
          7835,
          1756,
          11,
          2418,
          11,
          50714
        ]
      },
      {
        "avg_logprob": -0.1789669925219392,
        "compression_ratio": 1.4569536423841059,
        "end": 3163.22,
        "id": 853,
        "no_speech_prob": 0.000031692616175860167,
        "seek": 314922,
        "start": 3156.22,
        "temperature": 0,
        "text": " and bButton equals createButton, black.",
        "tokens": [
          50714,
          293,
          272,
          7835,
          1756,
          6915,
          1884,
          7835,
          1756,
          11,
          2211,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.1789669925219392,
        "compression_ratio": 1.4569536423841059,
        "end": 3168.22,
        "id": 854,
        "no_speech_prob": 0.000031692616175860167,
        "seek": 314922,
        "start": 3166.22,
        "temperature": 0,
        "text": " And let's take a look here.",
        "tokens": [
          51214,
          400,
          718,
          311,
          747,
          257,
          574,
          510,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.1789669925219392,
        "compression_ratio": 1.4569536423841059,
        "end": 3172.22,
        "id": 855,
        "no_speech_prob": 0.000031692616175860167,
        "seek": 314922,
        "start": 3168.22,
        "temperature": 0,
        "text": " Now, let's see if I can make this...",
        "tokens": [
          51314,
          823,
          11,
          718,
          311,
          536,
          498,
          286,
          393,
          652,
          341,
          485,
          51514
        ]
      },
      {
        "avg_logprob": -0.1789669925219392,
        "compression_ratio": 1.4569536423841059,
        "end": 3178.22,
        "id": 856,
        "no_speech_prob": 0.000031692616175860167,
        "seek": 314922,
        "start": 3174.22,
        "temperature": 0,
        "text": " Let me... I know I don't want to get lost in DOM manipulation,",
        "tokens": [
          51614,
          961,
          385,
          485,
          286,
          458,
          286,
          500,
          380,
          528,
          281,
          483,
          2731,
          294,
          35727,
          26475,
          11,
          51814
        ]
      },
      {
        "avg_logprob": -0.20044123937213232,
        "compression_ratio": 1.811659192825112,
        "end": 3180.22,
        "id": 857,
        "no_speech_prob": 0.0010322215966880322,
        "seek": 317822,
        "start": 3178.22,
        "temperature": 0,
        "text": " but really, really briefly...",
        "tokens": [
          50364,
          457,
          534,
          11,
          534,
          10515,
          485,
          50464
        ]
      },
      {
        "avg_logprob": -0.20044123937213232,
        "compression_ratio": 1.811659192825112,
        "end": 3184.22,
        "id": 858,
        "no_speech_prob": 0.0010322215966880322,
        "seek": 317822,
        "start": 3182.22,
        "temperature": 0,
        "text": " Style...",
        "tokens": [
          50564,
          27004,
          485,
          50664
        ]
      },
      {
        "avg_logprob": -0.20044123937213232,
        "compression_ratio": 1.811659192825112,
        "end": 3187.22,
        "id": 859,
        "no_speech_prob": 0.0010322215966880322,
        "seek": 317822,
        "start": 3185.22,
        "temperature": 0,
        "text": " No, no, I'm not going to get lost in DOM manipulation.",
        "tokens": [
          50714,
          883,
          11,
          572,
          11,
          286,
          478,
          406,
          516,
          281,
          483,
          2731,
          294,
          35727,
          26475,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.20044123937213232,
        "compression_ratio": 1.811659192825112,
        "end": 3188.22,
        "id": 860,
        "no_speech_prob": 0.0010322215966880322,
        "seek": 317822,
        "start": 3187.22,
        "temperature": 0,
        "text": " I'm just going to leave it.",
        "tokens": [
          50814,
          286,
          478,
          445,
          516,
          281,
          1856,
          309,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.20044123937213232,
        "compression_ratio": 1.811659192825112,
        "end": 3189.22,
        "id": 861,
        "no_speech_prob": 0.0010322215966880322,
        "seek": 317822,
        "start": 3188.22,
        "temperature": 0,
        "text": " Okay? I'm going to leave it.",
        "tokens": [
          50864,
          1033,
          30,
          286,
          478,
          516,
          281,
          1856,
          309,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.20044123937213232,
        "compression_ratio": 1.811659192825112,
        "end": 3190.22,
        "id": 862,
        "no_speech_prob": 0.0010322215966880322,
        "seek": 317822,
        "start": 3189.22,
        "temperature": 0,
        "text": " Oh, you can't see that.",
        "tokens": [
          50914,
          876,
          11,
          291,
          393,
          380,
          536,
          300,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.20044123937213232,
        "compression_ratio": 1.811659192825112,
        "end": 3191.22,
        "id": 863,
        "no_speech_prob": 0.0010322215966880322,
        "seek": 317822,
        "start": 3190.22,
        "temperature": 0,
        "text": " I'm going to move this over.",
        "tokens": [
          50964,
          286,
          478,
          516,
          281,
          1286,
          341,
          670,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.20044123937213232,
        "compression_ratio": 1.811659192825112,
        "end": 3193.22,
        "id": 864,
        "no_speech_prob": 0.0010322215966880322,
        "seek": 317822,
        "start": 3191.22,
        "temperature": 0,
        "text": " I'm going to make everything a little smaller.",
        "tokens": [
          51014,
          286,
          478,
          516,
          281,
          652,
          1203,
          257,
          707,
          4356,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.20044123937213232,
        "compression_ratio": 1.811659192825112,
        "end": 3195.22,
        "id": 865,
        "no_speech_prob": 0.0010322215966880322,
        "seek": 317822,
        "start": 3193.22,
        "temperature": 0,
        "text": " No, no, no. No, no, no. Stop, stop.",
        "tokens": [
          51114,
          883,
          11,
          572,
          11,
          572,
          13,
          883,
          11,
          572,
          11,
          572,
          13,
          5535,
          11,
          1590,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.20044123937213232,
        "compression_ratio": 1.811659192825112,
        "end": 3203.22,
        "id": 866,
        "no_speech_prob": 0.0010322215966880322,
        "seek": 317822,
        "start": 3199.22,
        "temperature": 0,
        "text": " The coding train does not spend hours and hours and hours",
        "tokens": [
          51414,
          440,
          17720,
          3847,
          775,
          406,
          3496,
          2496,
          293,
          2496,
          293,
          2496,
          51614
        ]
      },
      {
        "avg_logprob": -0.20044123937213232,
        "compression_ratio": 1.811659192825112,
        "end": 3207.22,
        "id": 867,
        "no_speech_prob": 0.0010322215966880322,
        "seek": 317822,
        "start": 3203.22,
        "temperature": 0,
        "text": " during tutorials trying to style and layout simple examples",
        "tokens": [
          51614,
          1830,
          17616,
          1382,
          281,
          3758,
          293,
          13333,
          2199,
          5110,
          51814
        ]
      },
      {
        "avg_logprob": -0.1774940837513317,
        "compression_ratio": 1.7025316455696202,
        "end": 3208.22,
        "id": 868,
        "no_speech_prob": 0.00027802755357697606,
        "seek": 320722,
        "start": 3207.22,
        "temperature": 0,
        "text": " where it really doesn't matter.",
        "tokens": [
          50364,
          689,
          309,
          534,
          1177,
          380,
          1871,
          13,
          50414
        ]
      },
      {
        "avg_logprob": -0.1774940837513317,
        "compression_ratio": 1.7025316455696202,
        "end": 3210.22,
        "id": 869,
        "no_speech_prob": 0.00027802755357697606,
        "seek": 320722,
        "start": 3208.22,
        "temperature": 0,
        "text": " Say this to yourself over and over again.",
        "tokens": [
          50414,
          6463,
          341,
          281,
          1803,
          670,
          293,
          670,
          797,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.1774940837513317,
        "compression_ratio": 1.7025316455696202,
        "end": 3212.22,
        "id": 870,
        "no_speech_prob": 0.00027802755357697606,
        "seek": 320722,
        "start": 3210.22,
        "temperature": 0,
        "text": " Okay, I'm just going to keep going.",
        "tokens": [
          50514,
          1033,
          11,
          286,
          478,
          445,
          516,
          281,
          1066,
          516,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.1774940837513317,
        "compression_ratio": 1.7025316455696202,
        "end": 3213.22,
        "id": 871,
        "no_speech_prob": 0.00027802755357697606,
        "seek": 320722,
        "start": 3212.22,
        "temperature": 0,
        "text": " It doesn't matter.",
        "tokens": [
          50614,
          467,
          1177,
          380,
          1871,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.1774940837513317,
        "compression_ratio": 1.7025316455696202,
        "end": 3214.22,
        "id": 872,
        "no_speech_prob": 0.00027802755357697606,
        "seek": 320722,
        "start": 3213.22,
        "temperature": 0,
        "text": " It doesn't matter if it's a little bit off.",
        "tokens": [
          50664,
          467,
          1177,
          380,
          1871,
          498,
          309,
          311,
          257,
          707,
          857,
          766,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.1774940837513317,
        "compression_ratio": 1.7025316455696202,
        "end": 3217.22,
        "id": 873,
        "no_speech_prob": 0.00027802755357697606,
        "seek": 320722,
        "start": 3214.22,
        "temperature": 0,
        "text": " If you can't see it perfectly, you get the idea.",
        "tokens": [
          50714,
          759,
          291,
          393,
          380,
          536,
          309,
          6239,
          11,
          291,
          483,
          264,
          1558,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.1774940837513317,
        "compression_ratio": 1.7025316455696202,
        "end": 3220.22,
        "id": 874,
        "no_speech_prob": 0.00027802755357697606,
        "seek": 320722,
        "start": 3218.22,
        "temperature": 0,
        "text": " These are my buttons over here.",
        "tokens": [
          50914,
          1981,
          366,
          452,
          9905,
          670,
          510,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.1774940837513317,
        "compression_ratio": 1.7025316455696202,
        "end": 3222.22,
        "id": 875,
        "no_speech_prob": 0.00027802755357697606,
        "seek": 320722,
        "start": 3220.22,
        "temperature": 0,
        "text": " White, black.",
        "tokens": [
          51014,
          5552,
          11,
          2211,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.1774940837513317,
        "compression_ratio": 1.7025316455696202,
        "end": 3224.22,
        "id": 876,
        "no_speech_prob": 0.00027802755357697606,
        "seek": 320722,
        "start": 3222.22,
        "temperature": 0,
        "text": " The idea is that... Oh, and look at this.",
        "tokens": [
          51114,
          440,
          1558,
          307,
          300,
          485,
          876,
          11,
          293,
          574,
          412,
          341,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.1774940837513317,
        "compression_ratio": 1.7025316455696202,
        "end": 3226.22,
        "id": 877,
        "no_speech_prob": 0.00027802755357697606,
        "seek": 320722,
        "start": 3224.22,
        "temperature": 0,
        "text": " Each time I press, it goes on to the next color,",
        "tokens": [
          51214,
          6947,
          565,
          286,
          1886,
          11,
          309,
          1709,
          322,
          281,
          264,
          958,
          2017,
          11,
          51314
        ]
      },
      {
        "avg_logprob": -0.1774940837513317,
        "compression_ratio": 1.7025316455696202,
        "end": 3227.22,
        "id": 878,
        "no_speech_prob": 0.00027802755357697606,
        "seek": 320722,
        "start": 3226.22,
        "temperature": 0,
        "text": " which is kind of interesting.",
        "tokens": [
          51314,
          597,
          307,
          733,
          295,
          1880,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.1774940837513317,
        "compression_ratio": 1.7025316455696202,
        "end": 3228.22,
        "id": 879,
        "no_speech_prob": 0.00027802755357697606,
        "seek": 320722,
        "start": 3227.22,
        "temperature": 0,
        "text": " I'm actually fine with that.",
        "tokens": [
          51364,
          286,
          478,
          767,
          2489,
          365,
          300,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.1774940837513317,
        "compression_ratio": 1.7025316455696202,
        "end": 3230.22,
        "id": 880,
        "no_speech_prob": 0.00027802755357697606,
        "seek": 320722,
        "start": 3228.22,
        "temperature": 0,
        "text": " So, what I want to do now...",
        "tokens": [
          51414,
          407,
          11,
          437,
          286,
          528,
          281,
          360,
          586,
          485,
          51514
        ]
      },
      {
        "avg_logprob": -0.1774940837513317,
        "compression_ratio": 1.7025316455696202,
        "end": 3233.22,
        "id": 881,
        "no_speech_prob": 0.00027802755357697606,
        "seek": 320722,
        "start": 3230.22,
        "temperature": 0,
        "text": " And it probably would be a nicer interaction",
        "tokens": [
          51514,
          400,
          309,
          1391,
          576,
          312,
          257,
          22842,
          9285,
          51664
        ]
      },
      {
        "avg_logprob": -0.1774940837513317,
        "compression_ratio": 1.7025316455696202,
        "end": 3235.22,
        "id": 882,
        "no_speech_prob": 0.00027802755357697606,
        "seek": 320722,
        "start": 3233.22,
        "temperature": 0,
        "text": " if I just sort of clicked in the window there.",
        "tokens": [
          51664,
          498,
          286,
          445,
          1333,
          295,
          23370,
          294,
          264,
          4910,
          456,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.19304140205057257,
        "compression_ratio": 1.614678899082569,
        "end": 3237.22,
        "id": 883,
        "no_speech_prob": 0.00009314563794760033,
        "seek": 323522,
        "start": 3235.22,
        "temperature": 0,
        "text": " But what I want to do is I want to do some events.",
        "tokens": [
          50364,
          583,
          437,
          286,
          528,
          281,
          360,
          307,
          286,
          528,
          281,
          360,
          512,
          3931,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.19304140205057257,
        "compression_ratio": 1.614678899082569,
        "end": 3241.22,
        "id": 884,
        "no_speech_prob": 0.00009314563794760033,
        "seek": 323522,
        "start": 3239.22,
        "temperature": 0,
        "text": " I'm going to say mouse pressed.",
        "tokens": [
          50564,
          286,
          478,
          516,
          281,
          584,
          9719,
          17355,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.19304140205057257,
        "compression_ratio": 1.614678899082569,
        "end": 3245.22,
        "id": 885,
        "no_speech_prob": 0.00009314563794760033,
        "seek": 323522,
        "start": 3243.22,
        "temperature": 0,
        "text": " Oh, this is so silly.",
        "tokens": [
          50764,
          876,
          11,
          341,
          307,
          370,
          11774,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.19304140205057257,
        "compression_ratio": 1.614678899082569,
        "end": 3247.22,
        "id": 886,
        "no_speech_prob": 0.00009314563794760033,
        "seek": 323522,
        "start": 3245.22,
        "temperature": 0,
        "text": " But it's fine. It's fine. It's fine.",
        "tokens": [
          50864,
          583,
          309,
          311,
          2489,
          13,
          467,
          311,
          2489,
          13,
          467,
          311,
          2489,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.19304140205057257,
        "compression_ratio": 1.614678899082569,
        "end": 3248.22,
        "id": 887,
        "no_speech_prob": 0.00009314563794760033,
        "seek": 323522,
        "start": 3247.22,
        "temperature": 0,
        "text": " I'm going to keep going.",
        "tokens": [
          50964,
          286,
          478,
          516,
          281,
          1066,
          516,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.19304140205057257,
        "compression_ratio": 1.614678899082569,
        "end": 3250.22,
        "id": 888,
        "no_speech_prob": 0.00009314563794760033,
        "seek": 323522,
        "start": 3248.22,
        "temperature": 0,
        "text": " Pause. Just give me a timeout for a second.",
        "tokens": [
          51014,
          31973,
          13,
          1449,
          976,
          385,
          257,
          565,
          346,
          337,
          257,
          1150,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.19304140205057257,
        "compression_ratio": 1.614678899082569,
        "end": 3251.22,
        "id": 889,
        "no_speech_prob": 0.00009314563794760033,
        "seek": 323522,
        "start": 3250.22,
        "temperature": 0,
        "text": " I need an edit point.",
        "tokens": [
          51114,
          286,
          643,
          364,
          8129,
          935,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.19304140205057257,
        "compression_ratio": 1.614678899082569,
        "end": 3253.22,
        "id": 890,
        "no_speech_prob": 0.00009314563794760033,
        "seek": 323522,
        "start": 3251.22,
        "temperature": 0,
        "text": " I've got to take a deep breath.",
        "tokens": [
          51164,
          286,
          600,
          658,
          281,
          747,
          257,
          2452,
          6045,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.19304140205057257,
        "compression_ratio": 1.614678899082569,
        "end": 3257.22,
        "id": 891,
        "no_speech_prob": 0.00009314563794760033,
        "seek": 323522,
        "start": 3254.22,
        "temperature": 0,
        "text": " Yeah, on click, figure out which side of the canvas is clicked.",
        "tokens": [
          51314,
          865,
          11,
          322,
          2052,
          11,
          2573,
          484,
          597,
          1252,
          295,
          264,
          16267,
          307,
          23370,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.19304140205057257,
        "compression_ratio": 1.614678899082569,
        "end": 3259.22,
        "id": 892,
        "no_speech_prob": 0.00009314563794760033,
        "seek": 323522,
        "start": 3257.22,
        "temperature": 0,
        "text": " That seems much better.",
        "tokens": [
          51464,
          663,
          2544,
          709,
          1101,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.21090437987140406,
        "compression_ratio": 1.5186915887850467,
        "end": 3268.22,
        "id": 893,
        "no_speech_prob": 0.00000966607785812812,
        "seek": 326522,
        "start": 3266.22,
        "temperature": 0,
        "text": " Yeah, I think I'm going to back up here.",
        "tokens": [
          50414,
          865,
          11,
          286,
          519,
          286,
          478,
          516,
          281,
          646,
          493,
          510,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.21090437987140406,
        "compression_ratio": 1.5186915887850467,
        "end": 3270.22,
        "id": 894,
        "no_speech_prob": 0.00000966607785812812,
        "seek": 326522,
        "start": 3268.22,
        "temperature": 0,
        "text": " Let's back up. Let's forget about the buttons.",
        "tokens": [
          50514,
          961,
          311,
          646,
          493,
          13,
          961,
          311,
          2870,
          466,
          264,
          9905,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.21090437987140406,
        "compression_ratio": 1.5186915887850467,
        "end": 3273.22,
        "id": 895,
        "no_speech_prob": 0.00000966607785812812,
        "seek": 326522,
        "start": 3270.22,
        "temperature": 0,
        "text": " Buttons were like an attempt in my mind to make this simpler.",
        "tokens": [
          50614,
          40801,
          892,
          645,
          411,
          364,
          5217,
          294,
          452,
          1575,
          281,
          652,
          341,
          18587,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.21090437987140406,
        "compression_ratio": 1.5186915887850467,
        "end": 3276.22,
        "id": 896,
        "no_speech_prob": 0.00000966607785812812,
        "seek": 326522,
        "start": 3274.22,
        "temperature": 0,
        "text": " But there's really no point to them.",
        "tokens": [
          50814,
          583,
          456,
          311,
          534,
          572,
          935,
          281,
          552,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.21090437987140406,
        "compression_ratio": 1.5186915887850467,
        "end": 3278.22,
        "id": 897,
        "no_speech_prob": 0.00000966607785812812,
        "seek": 326522,
        "start": 3276.22,
        "temperature": 0,
        "text": " Let's draw that line down the middle.",
        "tokens": [
          50914,
          961,
          311,
          2642,
          300,
          1622,
          760,
          264,
          2808,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.21090437987140406,
        "compression_ratio": 1.5186915887850467,
        "end": 3280.22,
        "id": 898,
        "no_speech_prob": 0.00000966607785812812,
        "seek": 326522,
        "start": 3278.22,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          51014,
          1033,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.21090437987140406,
        "compression_ratio": 1.5186915887850467,
        "end": 3287.22,
        "id": 899,
        "no_speech_prob": 0.00000966607785812812,
        "seek": 326522,
        "start": 3286.22,
        "temperature": 0,
        "text": " What time is it?",
        "tokens": [
          51414,
          708,
          565,
          307,
          309,
          30,
          51464
        ]
      },
      {
        "avg_logprob": -0.21090437987140406,
        "compression_ratio": 1.5186915887850467,
        "end": 3289.22,
        "id": 900,
        "no_speech_prob": 0.00000966607785812812,
        "seek": 326522,
        "start": 3287.22,
        "temperature": 0,
        "text": " I've got 35 minutes. Let's keep going.",
        "tokens": [
          51464,
          286,
          600,
          658,
          6976,
          2077,
          13,
          961,
          311,
          1066,
          516,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.21090437987140406,
        "compression_ratio": 1.5186915887850467,
        "end": 3290.22,
        "id": 901,
        "no_speech_prob": 0.00000966607785812812,
        "seek": 326522,
        "start": 3289.22,
        "temperature": 0,
        "text": " All right.",
        "tokens": [
          51564,
          1057,
          558,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.21090437987140406,
        "compression_ratio": 1.5186915887850467,
        "end": 3293.22,
        "id": 902,
        "no_speech_prob": 0.00000966607785812812,
        "seek": 326522,
        "start": 3291.22,
        "temperature": 0,
        "text": " Okay, so I want to click...",
        "tokens": [
          51664,
          1033,
          11,
          370,
          286,
          528,
          281,
          2052,
          485,
          51764
        ]
      },
      {
        "avg_logprob": -0.23818323347303602,
        "compression_ratio": 1.815,
        "end": 3295.22,
        "id": 903,
        "no_speech_prob": 0.00010889533587032929,
        "seek": 329322,
        "start": 3293.22,
        "temperature": 0,
        "text": " What I'm going to do here is as the trainer,",
        "tokens": [
          50364,
          708,
          286,
          478,
          516,
          281,
          360,
          510,
          307,
          382,
          264,
          21110,
          11,
          50464
        ]
      },
      {
        "avg_logprob": -0.23818323347303602,
        "compression_ratio": 1.815,
        "end": 3299.22,
        "id": 904,
        "no_speech_prob": 0.00010889533587032929,
        "seek": 329322,
        "start": 3295.22,
        "temperature": 0,
        "text": " I'm going to click on the side of the canvas that I think looks better.",
        "tokens": [
          50464,
          286,
          478,
          516,
          281,
          2052,
          322,
          264,
          1252,
          295,
          264,
          16267,
          300,
          286,
          519,
          1542,
          1101,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.23818323347303602,
        "compression_ratio": 1.815,
        "end": 3302.22,
        "id": 905,
        "no_speech_prob": 0.00010889533587032929,
        "seek": 329322,
        "start": 3299.22,
        "temperature": 0,
        "text": " I think white looks better, so I'm going to click over here.",
        "tokens": [
          50664,
          286,
          519,
          2418,
          1542,
          1101,
          11,
          370,
          286,
          478,
          516,
          281,
          2052,
          670,
          510,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.23818323347303602,
        "compression_ratio": 1.815,
        "end": 3305.22,
        "id": 906,
        "no_speech_prob": 0.00010889533587032929,
        "seek": 329322,
        "start": 3302.22,
        "temperature": 0,
        "text": " Just to make this a little bit easier to follow,",
        "tokens": [
          50814,
          1449,
          281,
          652,
          341,
          257,
          707,
          857,
          3571,
          281,
          1524,
          11,
          50964
        ]
      },
      {
        "avg_logprob": -0.23818323347303602,
        "compression_ratio": 1.815,
        "end": 3316.22,
        "id": 907,
        "no_speech_prob": 0.00010889533587032929,
        "seek": 329322,
        "start": 3305.22,
        "temperature": 0,
        "text": " I'm also going to draw a stroke weight 4, stroke 255, 0.",
        "tokens": [
          50964,
          286,
          478,
          611,
          516,
          281,
          2642,
          257,
          12403,
          3364,
          1017,
          11,
          12403,
          3552,
          20,
          11,
          1958,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.23818323347303602,
        "compression_ratio": 1.815,
        "end": 3322.22,
        "id": 908,
        "no_speech_prob": 0.00010889533587032929,
        "seek": 329322,
        "start": 3316.22,
        "temperature": 0,
        "text": " I guess I'm going to align width divided by 2, 0, width divided by 2, height 0.",
        "tokens": [
          51514,
          286,
          2041,
          286,
          478,
          516,
          281,
          7975,
          11402,
          6666,
          538,
          568,
          11,
          1958,
          11,
          11402,
          6666,
          538,
          568,
          11,
          6681,
          1958,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.1571720060238168,
        "compression_ratio": 1.502262443438914,
        "end": 3324.22,
        "id": 909,
        "no_speech_prob": 0.00030534627148881555,
        "seek": 332222,
        "start": 3322.22,
        "temperature": 0,
        "text": " Width divided by 2, height.",
        "tokens": [
          50364,
          28331,
          392,
          6666,
          538,
          568,
          11,
          6681,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.1571720060238168,
        "compression_ratio": 1.502262443438914,
        "end": 3328.22,
        "id": 910,
        "no_speech_prob": 0.00030534627148881555,
        "seek": 332222,
        "start": 3327.22,
        "temperature": 0,
        "text": " There we go.",
        "tokens": [
          50614,
          821,
          321,
          352,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.1571720060238168,
        "compression_ratio": 1.502262443438914,
        "end": 3330.22,
        "id": 911,
        "no_speech_prob": 0.00030534627148881555,
        "seek": 332222,
        "start": 3328.22,
        "temperature": 0,
        "text": " So I'm going to draw this so I can click...",
        "tokens": [
          50664,
          407,
          286,
          478,
          516,
          281,
          2642,
          341,
          370,
          286,
          393,
          2052,
          485,
          50764
        ]
      },
      {
        "avg_logprob": -0.1571720060238168,
        "compression_ratio": 1.502262443438914,
        "end": 3333.22,
        "id": 912,
        "no_speech_prob": 0.00030534627148881555,
        "seek": 332222,
        "start": 3330.22,
        "temperature": 0,
        "text": " Why is these are totally not centered at all?",
        "tokens": [
          50764,
          1545,
          307,
          613,
          366,
          3879,
          406,
          18988,
          412,
          439,
          30,
          50914
        ]
      },
      {
        "avg_logprob": -0.1571720060238168,
        "compression_ratio": 1.502262443438914,
        "end": 3335.22,
        "id": 913,
        "no_speech_prob": 0.00030534627148881555,
        "seek": 332222,
        "start": 3333.22,
        "temperature": 0,
        "text": " I'm like a lunatic.",
        "tokens": [
          50914,
          286,
          478,
          411,
          257,
          19039,
          2399,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.1571720060238168,
        "compression_ratio": 1.502262443438914,
        "end": 3337.22,
        "id": 914,
        "no_speech_prob": 0.00030534627148881555,
        "seek": 332222,
        "start": 3335.22,
        "temperature": 0,
        "text": " These are not in the right place.",
        "tokens": [
          51014,
          1981,
          366,
          406,
          294,
          264,
          558,
          1081,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.1571720060238168,
        "compression_ratio": 1.502262443438914,
        "end": 3339.22,
        "id": 915,
        "no_speech_prob": 0.00030534627148881555,
        "seek": 332222,
        "start": 3337.22,
        "temperature": 0,
        "text": " I'm sorry. I have to correct that.",
        "tokens": [
          51114,
          286,
          478,
          2597,
          13,
          286,
          362,
          281,
          3006,
          300,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.1571720060238168,
        "compression_ratio": 1.502262443438914,
        "end": 3341.22,
        "id": 916,
        "no_speech_prob": 0.00030534627148881555,
        "seek": 332222,
        "start": 3339.22,
        "temperature": 0,
        "text": " It's making me crazy.",
        "tokens": [
          51214,
          467,
          311,
          1455,
          385,
          3219,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.1571720060238168,
        "compression_ratio": 1.502262443438914,
        "end": 3343.22,
        "id": 917,
        "no_speech_prob": 0.00030534627148881555,
        "seek": 332222,
        "start": 3341.22,
        "temperature": 0,
        "text": " It is... How wide is the window?",
        "tokens": [
          51314,
          467,
          307,
          485,
          1012,
          4874,
          307,
          264,
          4910,
          30,
          51414
        ]
      },
      {
        "avg_logprob": -0.1571720060238168,
        "compression_ratio": 1.502262443438914,
        "end": 3345.22,
        "id": 918,
        "no_speech_prob": 0.00030534627148881555,
        "seek": 332222,
        "start": 3343.22,
        "temperature": 0,
        "text": " It's 600 wide.",
        "tokens": [
          51414,
          467,
          311,
          11849,
          4874,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.1571720060238168,
        "compression_ratio": 1.502262443438914,
        "end": 3347.22,
        "id": 919,
        "no_speech_prob": 0.00030534627148881555,
        "seek": 332222,
        "start": 3345.22,
        "temperature": 0,
        "text": " 300 is the middle.",
        "tokens": [
          51514,
          6641,
          307,
          264,
          2808,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.1571720060238168,
        "compression_ratio": 1.502262443438914,
        "end": 3348.22,
        "id": 920,
        "no_speech_prob": 0.00030534627148881555,
        "seek": 332222,
        "start": 3347.22,
        "temperature": 0,
        "text": " Oh, silly me.",
        "tokens": [
          51614,
          876,
          11,
          11774,
          385,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.1571720060238168,
        "compression_ratio": 1.502262443438914,
        "end": 3351.22,
        "id": 921,
        "no_speech_prob": 0.00030534627148881555,
        "seek": 332222,
        "start": 3348.22,
        "temperature": 0,
        "text": " 150, 350.",
        "tokens": [
          51664,
          8451,
          11,
          18065,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.17294561862945557,
        "compression_ratio": 1.565217391304348,
        "end": 3352.22,
        "id": 922,
        "no_speech_prob": 0.0001088961580535397,
        "seek": 335122,
        "start": 3351.22,
        "temperature": 0,
        "text": " Thank you very much.",
        "tokens": [
          50364,
          1044,
          291,
          588,
          709,
          13,
          50414
        ]
      },
      {
        "avg_logprob": -0.17294561862945557,
        "compression_ratio": 1.565217391304348,
        "end": 3354.22,
        "id": 923,
        "no_speech_prob": 0.0001088961580535397,
        "seek": 335122,
        "start": 3352.22,
        "temperature": 0,
        "text": " No, 450.",
        "tokens": [
          50414,
          883,
          11,
          26034,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.17294561862945557,
        "compression_ratio": 1.565217391304348,
        "end": 3355.22,
        "id": 924,
        "no_speech_prob": 0.0001088961580535397,
        "seek": 335122,
        "start": 3354.22,
        "temperature": 0,
        "text": " 450.",
        "tokens": [
          50514,
          26034,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.17294561862945557,
        "compression_ratio": 1.565217391304348,
        "end": 3357.22,
        "id": 925,
        "no_speech_prob": 0.0001088961580535397,
        "seek": 335122,
        "start": 3355.22,
        "temperature": 0,
        "text": " Thank you very much.",
        "tokens": [
          50564,
          1044,
          291,
          588,
          709,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.17294561862945557,
        "compression_ratio": 1.565217391304348,
        "end": 3358.22,
        "id": 926,
        "no_speech_prob": 0.0001088961580535397,
        "seek": 335122,
        "start": 3357.22,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          50664,
          1033,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.17294561862945557,
        "compression_ratio": 1.565217391304348,
        "end": 3359.22,
        "id": 927,
        "no_speech_prob": 0.0001088961580535397,
        "seek": 335122,
        "start": 3358.22,
        "temperature": 0,
        "text": " 150.",
        "tokens": [
          50714,
          8451,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.17294561862945557,
        "compression_ratio": 1.565217391304348,
        "end": 3361.22,
        "id": 928,
        "no_speech_prob": 0.0001088961580535397,
        "seek": 335122,
        "start": 3359.22,
        "temperature": 0,
        "text": " Just please bear with me.",
        "tokens": [
          50764,
          1449,
          1767,
          6155,
          365,
          385,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.17294561862945557,
        "compression_ratio": 1.565217391304348,
        "end": 3363.22,
        "id": 929,
        "no_speech_prob": 0.0001088961580535397,
        "seek": 335122,
        "start": 3361.22,
        "temperature": 0,
        "text": " 450.",
        "tokens": [
          50864,
          26034,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.17294561862945557,
        "compression_ratio": 1.565217391304348,
        "end": 3365.22,
        "id": 930,
        "no_speech_prob": 0.0001088961580535397,
        "seek": 335122,
        "start": 3363.22,
        "temperature": 0,
        "text": " Okay, now we're doing well.",
        "tokens": [
          50964,
          1033,
          11,
          586,
          321,
          434,
          884,
          731,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.17294561862945557,
        "compression_ratio": 1.565217391304348,
        "end": 3369.22,
        "id": 931,
        "no_speech_prob": 0.0001088961580535397,
        "seek": 335122,
        "start": 3365.22,
        "temperature": 0,
        "text": " Okay, so now the idea here is every time I click over here,",
        "tokens": [
          51064,
          1033,
          11,
          370,
          586,
          264,
          1558,
          510,
          307,
          633,
          565,
          286,
          2052,
          670,
          510,
          11,
          51264
        ]
      },
      {
        "avg_logprob": -0.17294561862945557,
        "compression_ratio": 1.565217391304348,
        "end": 3373.22,
        "id": 932,
        "no_speech_prob": 0.0001088961580535397,
        "seek": 335122,
        "start": 3369.22,
        "temperature": 0,
        "text": " I want to teach the neural network which one I think it should be.",
        "tokens": [
          51264,
          286,
          528,
          281,
          2924,
          264,
          18161,
          3209,
          597,
          472,
          286,
          519,
          309,
          820,
          312,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.17294561862945557,
        "compression_ratio": 1.565217391304348,
        "end": 3375.22,
        "id": 933,
        "no_speech_prob": 0.0001088961580535397,
        "seek": 335122,
        "start": 3373.22,
        "temperature": 0,
        "text": " So how do I do that?",
        "tokens": [
          51464,
          407,
          577,
          360,
          286,
          360,
          300,
          30,
          51564
        ]
      },
      {
        "avg_logprob": -0.17294561862945557,
        "compression_ratio": 1.565217391304348,
        "end": 3378.22,
        "id": 934,
        "no_speech_prob": 0.0001088961580535397,
        "seek": 335122,
        "start": 3375.22,
        "temperature": 0,
        "text": " So I told you there was a function called predict,",
        "tokens": [
          51564,
          407,
          286,
          1907,
          291,
          456,
          390,
          257,
          2445,
          1219,
          6069,
          11,
          51714
        ]
      },
      {
        "avg_logprob": -0.17719359624953496,
        "compression_ratio": 1.7149321266968325,
        "end": 3383.22,
        "id": 935,
        "no_speech_prob": 0.00009761541878106073,
        "seek": 337822,
        "start": 3378.22,
        "temperature": 0,
        "text": " and the function called predict would send in the input data",
        "tokens": [
          50364,
          293,
          264,
          2445,
          1219,
          6069,
          576,
          2845,
          294,
          264,
          4846,
          1412,
          50614
        ]
      },
      {
        "avg_logprob": -0.17719359624953496,
        "compression_ratio": 1.7149321266968325,
        "end": 3385.22,
        "id": 936,
        "no_speech_prob": 0.00009761541878106073,
        "seek": 337822,
        "start": 3383.22,
        "temperature": 0,
        "text": " and give me an output prediction.",
        "tokens": [
          50614,
          293,
          976,
          385,
          364,
          5598,
          17630,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.17719359624953496,
        "compression_ratio": 1.7149321266968325,
        "end": 3389.22,
        "id": 937,
        "no_speech_prob": 0.00009761541878106073,
        "seek": 337822,
        "start": 3385.22,
        "temperature": 0,
        "text": " Now what I want to do is I want to use a different function called train.",
        "tokens": [
          50714,
          823,
          437,
          286,
          528,
          281,
          360,
          307,
          286,
          528,
          281,
          764,
          257,
          819,
          2445,
          1219,
          3847,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.17719359624953496,
        "compression_ratio": 1.7149321266968325,
        "end": 3391.22,
        "id": 938,
        "no_speech_prob": 0.00009761541878106073,
        "seek": 337822,
        "start": 3389.22,
        "temperature": 0,
        "text": " So each time I click the mouse...",
        "tokens": [
          50914,
          407,
          1184,
          565,
          286,
          2052,
          264,
          9719,
          485,
          51014
        ]
      },
      {
        "avg_logprob": -0.17719359624953496,
        "compression_ratio": 1.7149321266968325,
        "end": 3393.22,
        "id": 939,
        "no_speech_prob": 0.00009761541878106073,
        "seek": 337822,
        "start": 3391.22,
        "temperature": 0,
        "text": " Where is that mouse, Pris?",
        "tokens": [
          51014,
          2305,
          307,
          300,
          9719,
          11,
          2114,
          271,
          30,
          51114
        ]
      },
      {
        "avg_logprob": -0.17719359624953496,
        "compression_ratio": 1.7149321266968325,
        "end": 3395.22,
        "id": 940,
        "no_speech_prob": 0.00009761541878106073,
        "seek": 337822,
        "start": 3393.22,
        "temperature": 0,
        "text": " Before I pick the new color,",
        "tokens": [
          51114,
          4546,
          286,
          1888,
          264,
          777,
          2017,
          11,
          51214
        ]
      },
      {
        "avg_logprob": -0.17719359624953496,
        "compression_ratio": 1.7149321266968325,
        "end": 3400.22,
        "id": 941,
        "no_speech_prob": 0.00009761541878106073,
        "seek": 337822,
        "start": 3395.22,
        "temperature": 0,
        "text": " I want to determine is the mouse on the right side or the left side.",
        "tokens": [
          51214,
          286,
          528,
          281,
          6997,
          307,
          264,
          9719,
          322,
          264,
          558,
          1252,
          420,
          264,
          1411,
          1252,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.17719359624953496,
        "compression_ratio": 1.7149321266968325,
        "end": 3407.22,
        "id": 942,
        "no_speech_prob": 0.00009761541878106073,
        "seek": 337822,
        "start": 3400.22,
        "temperature": 0,
        "text": " So I want to create some inputs, which is an array.",
        "tokens": [
          51464,
          407,
          286,
          528,
          281,
          1884,
          512,
          15743,
          11,
          597,
          307,
          364,
          10225,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.2086462644067141,
        "compression_ratio": 1.610091743119266,
        "end": 3410.22,
        "id": 943,
        "no_speech_prob": 0.00017130743071902543,
        "seek": 340722,
        "start": 3407.22,
        "temperature": 0,
        "text": " Let me just... let puts, inputs.",
        "tokens": [
          50364,
          961,
          385,
          445,
          485,
          718,
          8137,
          11,
          15743,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.2086462644067141,
        "compression_ratio": 1.610091743119266,
        "end": 3415.22,
        "id": 944,
        "no_speech_prob": 0.00017130743071902543,
        "seek": 340722,
        "start": 3410.22,
        "temperature": 0,
        "text": " And if mouseX is greater than width divided by 2,",
        "tokens": [
          50514,
          400,
          498,
          9719,
          55,
          307,
          5044,
          813,
          11402,
          6666,
          538,
          568,
          11,
          50764
        ]
      },
      {
        "avg_logprob": -0.2086462644067141,
        "compression_ratio": 1.610091743119266,
        "end": 3419.22,
        "id": 945,
        "no_speech_prob": 0.00017130743071902543,
        "seek": 340722,
        "start": 3415.22,
        "temperature": 0,
        "text": " then the correct...",
        "tokens": [
          50764,
          550,
          264,
          3006,
          485,
          50964
        ]
      },
      {
        "avg_logprob": -0.2086462644067141,
        "compression_ratio": 1.610091743119266,
        "end": 3421.22,
        "id": 946,
        "no_speech_prob": 0.00017130743071902543,
        "seek": 340722,
        "start": 3419.22,
        "temperature": 0,
        "text": " Actually, I'm sorry, I want to create some targets.",
        "tokens": [
          50964,
          5135,
          11,
          286,
          478,
          2597,
          11,
          286,
          528,
          281,
          1884,
          512,
          12911,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.2086462644067141,
        "compression_ratio": 1.610091743119266,
        "end": 3422.22,
        "id": 947,
        "no_speech_prob": 0.00017130743071902543,
        "seek": 340722,
        "start": 3421.22,
        "temperature": 0,
        "text": " This is known as targets.",
        "tokens": [
          51064,
          639,
          307,
          2570,
          382,
          12911,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.2086462644067141,
        "compression_ratio": 1.610091743119266,
        "end": 3424.22,
        "id": 948,
        "no_speech_prob": 0.00017130743071902543,
        "seek": 340722,
        "start": 3422.22,
        "temperature": 0,
        "text": " I mean, you can use different terms for all these things,",
        "tokens": [
          51114,
          286,
          914,
          11,
          291,
          393,
          764,
          819,
          2115,
          337,
          439,
          613,
          721,
          11,
          51214
        ]
      },
      {
        "avg_logprob": -0.2086462644067141,
        "compression_ratio": 1.610091743119266,
        "end": 3427.22,
        "id": 949,
        "no_speech_prob": 0.00017130743071902543,
        "seek": 340722,
        "start": 3424.22,
        "temperature": 0,
        "text": " but targets are the target outputs I want.",
        "tokens": [
          51214,
          457,
          12911,
          366,
          264,
          3779,
          23930,
          286,
          528,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.2086462644067141,
        "compression_ratio": 1.610091743119266,
        "end": 3432.22,
        "id": 950,
        "no_speech_prob": 0.00017130743071902543,
        "seek": 340722,
        "start": 3427.22,
        "temperature": 0,
        "text": " So if I click on the right side, I want the target outputs for white,",
        "tokens": [
          51364,
          407,
          498,
          286,
          2052,
          322,
          264,
          558,
          1252,
          11,
          286,
          528,
          264,
          3779,
          23930,
          337,
          2418,
          11,
          51614
        ]
      },
      {
        "avg_logprob": -0.19131312432227196,
        "compression_ratio": 1.6626506024096386,
        "end": 3437.22,
        "id": 951,
        "no_speech_prob": 0.10087378323078156,
        "seek": 343222,
        "start": 3432.22,
        "temperature": 0,
        "text": " and white means the second number is greater than the first number.",
        "tokens": [
          50364,
          293,
          2418,
          1355,
          264,
          1150,
          1230,
          307,
          5044,
          813,
          264,
          700,
          1230,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.19131312432227196,
        "compression_ratio": 1.6626506024096386,
        "end": 3442.22,
        "id": 952,
        "no_speech_prob": 0.10087378323078156,
        "seek": 343222,
        "start": 3437.22,
        "temperature": 0,
        "text": " So the targets, if I click on the right, should be 0, 1.",
        "tokens": [
          50614,
          407,
          264,
          12911,
          11,
          498,
          286,
          2052,
          322,
          264,
          558,
          11,
          820,
          312,
          1958,
          11,
          502,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.19131312432227196,
        "compression_ratio": 1.6626506024096386,
        "end": 3446.22,
        "id": 953,
        "no_speech_prob": 0.10087378323078156,
        "seek": 343222,
        "start": 3442.22,
        "temperature": 0,
        "text": " This is the correct...",
        "tokens": [
          50864,
          639,
          307,
          264,
          3006,
          485,
          51064
        ]
      },
      {
        "avg_logprob": -0.19131312432227196,
        "compression_ratio": 1.6626506024096386,
        "end": 3451.22,
        "id": 954,
        "no_speech_prob": 0.10087378323078156,
        "seek": 343222,
        "start": 3446.22,
        "temperature": 0,
        "text": " This is the correct output that I'm telling the neural network should be",
        "tokens": [
          51064,
          639,
          307,
          264,
          3006,
          5598,
          300,
          286,
          478,
          3585,
          264,
          18161,
          3209,
          820,
          312,
          51314
        ]
      },
      {
        "avg_logprob": -0.19131312432227196,
        "compression_ratio": 1.6626506024096386,
        "end": 3454.22,
        "id": 955,
        "no_speech_prob": 0.10087378323078156,
        "seek": 343222,
        "start": 3451.22,
        "temperature": 0,
        "text": " if I'm clicking on the right side.",
        "tokens": [
          51314,
          498,
          286,
          478,
          9697,
          322,
          264,
          558,
          1252,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.19131312432227196,
        "compression_ratio": 1.6626506024096386,
        "end": 3459.22,
        "id": 956,
        "no_speech_prob": 0.10087378323078156,
        "seek": 343222,
        "start": 3454.22,
        "temperature": 0,
        "text": " Else, the targets...",
        "tokens": [
          51464,
          45472,
          11,
          264,
          12911,
          485,
          51714
        ]
      },
      {
        "avg_logprob": -0.16476147191054155,
        "compression_ratio": 1.673913043478261,
        "end": 3462.22,
        "id": 957,
        "no_speech_prob": 0.001867513288743794,
        "seek": 345922,
        "start": 3459.22,
        "temperature": 0,
        "text": " And I know I could use one of those ternary blah, blah, blah things,",
        "tokens": [
          50364,
          400,
          286,
          458,
          286,
          727,
          764,
          472,
          295,
          729,
          256,
          1248,
          822,
          12288,
          11,
          12288,
          11,
          12288,
          721,
          11,
          50514
        ]
      },
      {
        "avg_logprob": -0.16476147191054155,
        "compression_ratio": 1.673913043478261,
        "end": 3464.22,
        "id": 958,
        "no_speech_prob": 0.001867513288743794,
        "seek": 345922,
        "start": 3462.22,
        "temperature": 0,
        "text": " but this is just going to have to do.",
        "tokens": [
          50514,
          457,
          341,
          307,
          445,
          516,
          281,
          362,
          281,
          360,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.16476147191054155,
        "compression_ratio": 1.673913043478261,
        "end": 3467.22,
        "id": 959,
        "no_speech_prob": 0.001867513288743794,
        "seek": 345922,
        "start": 3464.22,
        "temperature": 0,
        "text": " The targets are...",
        "tokens": [
          50614,
          440,
          12911,
          366,
          485,
          50764
        ]
      },
      {
        "avg_logprob": -0.16476147191054155,
        "compression_ratio": 1.673913043478261,
        "end": 3469.22,
        "id": 960,
        "no_speech_prob": 0.001867513288743794,
        "seek": 345922,
        "start": 3467.22,
        "temperature": 0,
        "text": " If they're on the left, should be 1, 0.",
        "tokens": [
          50764,
          759,
          436,
          434,
          322,
          264,
          1411,
          11,
          820,
          312,
          502,
          11,
          1958,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.16476147191054155,
        "compression_ratio": 1.673913043478261,
        "end": 3471.22,
        "id": 961,
        "no_speech_prob": 0.001867513288743794,
        "seek": 345922,
        "start": 3469.22,
        "temperature": 0,
        "text": " Let's pick up the pace here, people.",
        "tokens": [
          50864,
          961,
          311,
          1888,
          493,
          264,
          11638,
          510,
          11,
          561,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.16476147191054155,
        "compression_ratio": 1.673913043478261,
        "end": 3473.22,
        "id": 962,
        "no_speech_prob": 0.001867513288743794,
        "seek": 345922,
        "start": 3471.22,
        "temperature": 0,
        "text": " By people, I mean me, not you.",
        "tokens": [
          50964,
          3146,
          561,
          11,
          286,
          914,
          385,
          11,
          406,
          291,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.16476147191054155,
        "compression_ratio": 1.673913043478261,
        "end": 3476.22,
        "id": 963,
        "no_speech_prob": 0.001867513288743794,
        "seek": 345922,
        "start": 3473.22,
        "temperature": 0,
        "text": " You're doing great if you're actually still watching this.",
        "tokens": [
          51064,
          509,
          434,
          884,
          869,
          498,
          291,
          434,
          767,
          920,
          1976,
          341,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.16476147191054155,
        "compression_ratio": 1.673913043478261,
        "end": 3480.22,
        "id": 964,
        "no_speech_prob": 0.001867513288743794,
        "seek": 345922,
        "start": 3476.22,
        "temperature": 0,
        "text": " And now what I'm going to do is I'm going to say brain.train.",
        "tokens": [
          51214,
          400,
          586,
          437,
          286,
          478,
          516,
          281,
          360,
          307,
          286,
          478,
          516,
          281,
          584,
          3567,
          13,
          83,
          7146,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.16476147191054155,
        "compression_ratio": 1.673913043478261,
        "end": 3482.22,
        "id": 965,
        "no_speech_prob": 0.001867513288743794,
        "seek": 345922,
        "start": 3480.22,
        "temperature": 0,
        "text": " Oh, I need those inputs.",
        "tokens": [
          51414,
          876,
          11,
          286,
          643,
          729,
          15743,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.16476147191054155,
        "compression_ratio": 1.673913043478261,
        "end": 3485.22,
        "id": 966,
        "no_speech_prob": 0.001867513288743794,
        "seek": 345922,
        "start": 3482.22,
        "temperature": 0,
        "text": " So the inputs are the same exact thing I did here.",
        "tokens": [
          51514,
          407,
          264,
          15743,
          366,
          264,
          912,
          1900,
          551,
          286,
          630,
          510,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.16476147191054155,
        "compression_ratio": 1.673913043478261,
        "end": 3487.22,
        "id": 967,
        "no_speech_prob": 0.001867513288743794,
        "seek": 345922,
        "start": 3485.22,
        "temperature": 0,
        "text": " The inputs are the current RGB.",
        "tokens": [
          51664,
          440,
          15743,
          366,
          264,
          2190,
          31231,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.19221012408916766,
        "compression_ratio": 1.7932203389830508,
        "end": 3491.22,
        "id": 968,
        "no_speech_prob": 0.00046552298590540886,
        "seek": 348722,
        "start": 3487.22,
        "temperature": 0,
        "text": " And what I want to do is I want to say, hey, brain, train yourself",
        "tokens": [
          50364,
          400,
          437,
          286,
          528,
          281,
          360,
          307,
          286,
          528,
          281,
          584,
          11,
          4177,
          11,
          3567,
          11,
          3847,
          1803,
          50564
        ]
      },
      {
        "avg_logprob": -0.19221012408916766,
        "compression_ratio": 1.7932203389830508,
        "end": 3495.22,
        "id": 969,
        "no_speech_prob": 0.00046552298590540886,
        "seek": 348722,
        "start": 3491.22,
        "temperature": 0,
        "text": " with these inputs with these targets.",
        "tokens": [
          50564,
          365,
          613,
          15743,
          365,
          613,
          12911,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.19221012408916766,
        "compression_ratio": 1.7932203389830508,
        "end": 3498.22,
        "id": 970,
        "no_speech_prob": 0.00046552298590540886,
        "seek": 348722,
        "start": 3495.22,
        "temperature": 0,
        "text": " And in fact, this now is going to...",
        "tokens": [
          50764,
          400,
          294,
          1186,
          11,
          341,
          586,
          307,
          516,
          281,
          485,
          50914
        ]
      },
      {
        "avg_logprob": -0.19221012408916766,
        "compression_ratio": 1.7932203389830508,
        "end": 3500.22,
        "id": 971,
        "no_speech_prob": 0.00046552298590540886,
        "seek": 348722,
        "start": 3498.22,
        "temperature": 0,
        "text": " The neural network is going to... What is it going to do?",
        "tokens": [
          50914,
          440,
          18161,
          3209,
          307,
          516,
          281,
          485,
          708,
          307,
          309,
          516,
          281,
          360,
          30,
          51014
        ]
      },
      {
        "avg_logprob": -0.19221012408916766,
        "compression_ratio": 1.7932203389830508,
        "end": 3502.22,
        "id": 972,
        "no_speech_prob": 0.00046552298590540886,
        "seek": 348722,
        "start": 3500.22,
        "temperature": 0,
        "text": " I'm saying here are the inputs,",
        "tokens": [
          51014,
          286,
          478,
          1566,
          510,
          366,
          264,
          15743,
          11,
          51114
        ]
      },
      {
        "avg_logprob": -0.19221012408916766,
        "compression_ratio": 1.7932203389830508,
        "end": 3504.22,
        "id": 973,
        "no_speech_prob": 0.00046552298590540886,
        "seek": 348722,
        "start": 3502.22,
        "temperature": 0,
        "text": " here are the correct outputs that go with those inputs.",
        "tokens": [
          51114,
          510,
          366,
          264,
          3006,
          23930,
          300,
          352,
          365,
          729,
          15743,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.19221012408916766,
        "compression_ratio": 1.7932203389830508,
        "end": 3506.22,
        "id": 974,
        "no_speech_prob": 0.00046552298590540886,
        "seek": 348722,
        "start": 3504.22,
        "temperature": 0,
        "text": " Do whatever adjustments you need to do,",
        "tokens": [
          51214,
          1144,
          2035,
          18624,
          291,
          643,
          281,
          360,
          11,
          51314
        ]
      },
      {
        "avg_logprob": -0.19221012408916766,
        "compression_ratio": 1.7932203389830508,
        "end": 3509.22,
        "id": 975,
        "no_speech_prob": 0.00046552298590540886,
        "seek": 348722,
        "start": 3506.22,
        "temperature": 0,
        "text": " whether you were right or wrong, just figure it out.",
        "tokens": [
          51314,
          1968,
          291,
          645,
          558,
          420,
          2085,
          11,
          445,
          2573,
          309,
          484,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.19221012408916766,
        "compression_ratio": 1.7932203389830508,
        "end": 3511.22,
        "id": 976,
        "no_speech_prob": 0.00046552298590540886,
        "seek": 348722,
        "start": 3509.22,
        "temperature": 0,
        "text": " And what is that figuring out?",
        "tokens": [
          51464,
          400,
          437,
          307,
          300,
          15213,
          484,
          30,
          51564
        ]
      },
      {
        "avg_logprob": -0.19221012408916766,
        "compression_ratio": 1.7932203389830508,
        "end": 3513.22,
        "id": 977,
        "no_speech_prob": 0.00046552298590540886,
        "seek": 348722,
        "start": 3511.22,
        "temperature": 0,
        "text": " So interestingly enough, I think this is worth...",
        "tokens": [
          51564,
          407,
          25873,
          1547,
          11,
          286,
          519,
          341,
          307,
          3163,
          485,
          51664
        ]
      },
      {
        "avg_logprob": -0.19221012408916766,
        "compression_ratio": 1.7932203389830508,
        "end": 3516.22,
        "id": 978,
        "no_speech_prob": 0.00046552298590540886,
        "seek": 348722,
        "start": 3513.22,
        "temperature": 0,
        "text": " Even though this is covered in much more detail in my other videos,",
        "tokens": [
          51664,
          2754,
          1673,
          341,
          307,
          5343,
          294,
          709,
          544,
          2607,
          294,
          452,
          661,
          2145,
          11,
          51814
        ]
      },
      {
        "avg_logprob": -0.1667823598842428,
        "compression_ratio": 1.6666666666666667,
        "end": 3521.22,
        "id": 979,
        "no_speech_prob": 0.0000426472797698807,
        "seek": 351622,
        "start": 3516.22,
        "temperature": 0,
        "text": " let's say the neural network, I feed in some inputs.",
        "tokens": [
          50364,
          718,
          311,
          584,
          264,
          18161,
          3209,
          11,
          286,
          3154,
          294,
          512,
          15743,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.1667823598842428,
        "compression_ratio": 1.6666666666666667,
        "end": 3527.22,
        "id": 980,
        "no_speech_prob": 0.0000426472797698807,
        "seek": 351622,
        "start": 3521.22,
        "temperature": 0,
        "text": " And what it actually gives me is like 0.8, 0.2.",
        "tokens": [
          50614,
          400,
          437,
          309,
          767,
          2709,
          385,
          307,
          411,
          1958,
          13,
          23,
          11,
          1958,
          13,
          17,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.1667823598842428,
        "compression_ratio": 1.6666666666666667,
        "end": 3530.22,
        "id": 981,
        "no_speech_prob": 0.0000426472797698807,
        "seek": 351622,
        "start": 3527.22,
        "temperature": 0,
        "text": " This is what it gives me as the outputs.",
        "tokens": [
          50914,
          639,
          307,
          437,
          309,
          2709,
          385,
          382,
          264,
          23930,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.1667823598842428,
        "compression_ratio": 1.6666666666666667,
        "end": 3534.22,
        "id": 982,
        "no_speech_prob": 0.0000426472797698807,
        "seek": 351622,
        "start": 3530.22,
        "temperature": 0,
        "text": " But I scave it, I'm training it, I'm going to give it targets.",
        "tokens": [
          51064,
          583,
          286,
          4216,
          303,
          309,
          11,
          286,
          478,
          3097,
          309,
          11,
          286,
          478,
          516,
          281,
          976,
          309,
          12911,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.1667823598842428,
        "compression_ratio": 1.6666666666666667,
        "end": 3539.22,
        "id": 983,
        "no_speech_prob": 0.0000426472797698807,
        "seek": 351622,
        "start": 3534.22,
        "temperature": 0,
        "text": " And the correct targets are 0, 1.",
        "tokens": [
          51264,
          400,
          264,
          3006,
          12911,
          366,
          1958,
          11,
          502,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.1667823598842428,
        "compression_ratio": 1.6666666666666667,
        "end": 3542.22,
        "id": 984,
        "no_speech_prob": 0.0000426472797698807,
        "seek": 351622,
        "start": 3539.22,
        "temperature": 0,
        "text": " That's the output that I wanted to get.",
        "tokens": [
          51514,
          663,
          311,
          264,
          5598,
          300,
          286,
          1415,
          281,
          483,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.1667823598842428,
        "compression_ratio": 1.6666666666666667,
        "end": 3544.22,
        "id": 985,
        "no_speech_prob": 0.0000426472797698807,
        "seek": 351622,
        "start": 3542.22,
        "temperature": 0,
        "text": " That's the correct output.",
        "tokens": [
          51664,
          663,
          311,
          264,
          3006,
          5598,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.20262844727771118,
        "compression_ratio": 1.7361111111111112,
        "end": 3548.22,
        "id": 986,
        "no_speech_prob": 0.003945354372262955,
        "seek": 354422,
        "start": 3544.22,
        "temperature": 0,
        "text": " So what the neural network does is actually calculate something called an error.",
        "tokens": [
          50364,
          407,
          437,
          264,
          18161,
          3209,
          775,
          307,
          767,
          8873,
          746,
          1219,
          364,
          6713,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.20262844727771118,
        "compression_ratio": 1.7361111111111112,
        "end": 3550.22,
        "id": 987,
        "no_speech_prob": 0.003945354372262955,
        "seek": 354422,
        "start": 3548.22,
        "temperature": 0,
        "text": " And the error is really simple.",
        "tokens": [
          50564,
          400,
          264,
          6713,
          307,
          534,
          2199,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.20262844727771118,
        "compression_ratio": 1.7361111111111112,
        "end": 3555.22,
        "id": 988,
        "no_speech_prob": 0.003945354372262955,
        "seek": 354422,
        "start": 3550.22,
        "temperature": 0,
        "text": " It's simply the desired minus the guess.",
        "tokens": [
          50664,
          467,
          311,
          2935,
          264,
          14721,
          3175,
          264,
          2041,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.20262844727771118,
        "compression_ratio": 1.7361111111111112,
        "end": 3558.22,
        "id": 989,
        "no_speech_prob": 0.003945354372262955,
        "seek": 354422,
        "start": 3555.22,
        "temperature": 0,
        "text": " Or the targets minus the prediction.",
        "tokens": [
          50914,
          1610,
          264,
          12911,
          3175,
          264,
          17630,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.20262844727771118,
        "compression_ratio": 1.7361111111111112,
        "end": 3560.22,
        "id": 990,
        "no_speech_prob": 0.003945354372262955,
        "seek": 354422,
        "start": 3558.22,
        "temperature": 0,
        "text": " Or the targets minus the outputs.",
        "tokens": [
          51064,
          1610,
          264,
          12911,
          3175,
          264,
          23930,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.20262844727771118,
        "compression_ratio": 1.7361111111111112,
        "end": 3564.22,
        "id": 991,
        "no_speech_prob": 0.003945354372262955,
        "seek": 354422,
        "start": 3560.22,
        "temperature": 0,
        "text": " So the error would actually be negative 0.8.",
        "tokens": [
          51164,
          407,
          264,
          6713,
          576,
          767,
          312,
          3671,
          1958,
          13,
          23,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.20262844727771118,
        "compression_ratio": 1.7361111111111112,
        "end": 3568.22,
        "id": 992,
        "no_speech_prob": 0.003945354372262955,
        "seek": 354422,
        "start": 3564.22,
        "temperature": 0,
        "text": " And 0.8, interestingly enough.",
        "tokens": [
          51364,
          400,
          1958,
          13,
          23,
          11,
          25873,
          1547,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.20262844727771118,
        "compression_ratio": 1.7361111111111112,
        "end": 3569.22,
        "id": 993,
        "no_speech_prob": 0.003945354372262955,
        "seek": 354422,
        "start": 3568.22,
        "temperature": 0,
        "text": " Very symmetrical there.",
        "tokens": [
          51564,
          4372,
          40360,
          456,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.20262844727771118,
        "compression_ratio": 1.7361111111111112,
        "end": 3570.22,
        "id": 994,
        "no_speech_prob": 0.003945354372262955,
        "seek": 354422,
        "start": 3569.22,
        "temperature": 0,
        "text": " So this would be the error.",
        "tokens": [
          51614,
          407,
          341,
          576,
          312,
          264,
          6713,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.20262844727771118,
        "compression_ratio": 1.7361111111111112,
        "end": 3572.22,
        "id": 995,
        "no_speech_prob": 0.003945354372262955,
        "seek": 354422,
        "start": 3570.22,
        "temperature": 0,
        "text": " And then what happens?",
        "tokens": [
          51664,
          400,
          550,
          437,
          2314,
          30,
          51764
        ]
      },
      {
        "avg_logprob": -0.18327454787034256,
        "compression_ratio": 1.8724137931034484,
        "end": 3576.22,
        "id": 996,
        "no_speech_prob": 0.048854708671569824,
        "seek": 357222,
        "start": 3572.22,
        "temperature": 0,
        "text": " Inside that train function, an algorithm called backpropagation happens.",
        "tokens": [
          50364,
          15123,
          300,
          3847,
          2445,
          11,
          364,
          9284,
          1219,
          646,
          79,
          1513,
          559,
          399,
          2314,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.18327454787034256,
        "compression_ratio": 1.8724137931034484,
        "end": 3580.22,
        "id": 997,
        "no_speech_prob": 0.048854708671569824,
        "seek": 357222,
        "start": 3576.22,
        "temperature": 0,
        "text": " The backpropagation takes this error and sends it backwards.",
        "tokens": [
          50564,
          440,
          646,
          79,
          1513,
          559,
          399,
          2516,
          341,
          6713,
          293,
          14790,
          309,
          12204,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.18327454787034256,
        "compression_ratio": 1.8724137931034484,
        "end": 3584.22,
        "id": 998,
        "no_speech_prob": 0.048854708671569824,
        "seek": 357222,
        "start": 3580.22,
        "temperature": 0,
        "text": " So when I do prediction, I'm sending the data forward through the neural network.",
        "tokens": [
          50764,
          407,
          562,
          286,
          360,
          17630,
          11,
          286,
          478,
          7750,
          264,
          1412,
          2128,
          807,
          264,
          18161,
          3209,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.18327454787034256,
        "compression_ratio": 1.8724137931034484,
        "end": 3588.22,
        "id": 999,
        "no_speech_prob": 0.048854708671569824,
        "seek": 357222,
        "start": 3584.22,
        "temperature": 0,
        "text": " The training process is about looking at the outputs, calculating an error,",
        "tokens": [
          50964,
          440,
          3097,
          1399,
          307,
          466,
          1237,
          412,
          264,
          23930,
          11,
          28258,
          364,
          6713,
          11,
          51164
        ]
      },
      {
        "avg_logprob": -0.18327454787034256,
        "compression_ratio": 1.8724137931034484,
        "end": 3590.22,
        "id": 1000,
        "no_speech_prob": 0.048854708671569824,
        "seek": 357222,
        "start": 3588.22,
        "temperature": 0,
        "text": " and sending the error backwards through the network.",
        "tokens": [
          51164,
          293,
          7750,
          264,
          6713,
          12204,
          807,
          264,
          3209,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.18327454787034256,
        "compression_ratio": 1.8724137931034484,
        "end": 3594.22,
        "id": 1001,
        "no_speech_prob": 0.048854708671569824,
        "seek": 357222,
        "start": 3590.22,
        "temperature": 0,
        "text": " And all these little changes, all these weights that are adding up numbers and doing all this math,",
        "tokens": [
          51264,
          400,
          439,
          613,
          707,
          2962,
          11,
          439,
          613,
          17443,
          300,
          366,
          5127,
          493,
          3547,
          293,
          884,
          439,
          341,
          5221,
          11,
          51464
        ]
      },
      {
        "avg_logprob": -0.18327454787034256,
        "compression_ratio": 1.8724137931034484,
        "end": 3595.22,
        "id": 1002,
        "no_speech_prob": 0.048854708671569824,
        "seek": 357222,
        "start": 3594.22,
        "temperature": 0,
        "text": " they all get adjusted.",
        "tokens": [
          51464,
          436,
          439,
          483,
          19871,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.18327454787034256,
        "compression_ratio": 1.8724137931034484,
        "end": 3597.22,
        "id": 1003,
        "no_speech_prob": 0.048854708671569824,
        "seek": 357222,
        "start": 3595.22,
        "temperature": 0,
        "text": " So the errors would adjust all the parameters.",
        "tokens": [
          51514,
          407,
          264,
          13603,
          576,
          4369,
          439,
          264,
          9834,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.18327454787034256,
        "compression_ratio": 1.8724137931034484,
        "end": 3598.22,
        "id": 1004,
        "no_speech_prob": 0.048854708671569824,
        "seek": 357222,
        "start": 3597.22,
        "temperature": 0,
        "text": " And that's what's happening.",
        "tokens": [
          51614,
          400,
          300,
          311,
          437,
          311,
          2737,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.1819381013922735,
        "compression_ratio": 1.6756756756756757,
        "end": 3602.22,
        "id": 1005,
        "no_speech_prob": 0.13294924795627594,
        "seek": 359822,
        "start": 3598.22,
        "temperature": 0,
        "text": " Again, you can dive into my other tutorials which go through this in more detail.",
        "tokens": [
          50364,
          3764,
          11,
          291,
          393,
          9192,
          666,
          452,
          661,
          17616,
          597,
          352,
          807,
          341,
          294,
          544,
          2607,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.1819381013922735,
        "compression_ratio": 1.6756756756756757,
        "end": 3605.22,
        "id": 1006,
        "no_speech_prob": 0.13294924795627594,
        "seek": 359822,
        "start": 3602.22,
        "temperature": 0,
        "text": " But that's what's happening right here in this function.",
        "tokens": [
          50564,
          583,
          300,
          311,
          437,
          311,
          2737,
          558,
          510,
          294,
          341,
          2445,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.1819381013922735,
        "compression_ratio": 1.6756756756756757,
        "end": 3611.22,
        "id": 1007,
        "no_speech_prob": 0.13294924795627594,
        "seek": 359822,
        "start": 3605.22,
        "temperature": 0,
        "text": " So we are ready to go.",
        "tokens": [
          50714,
          407,
          321,
          366,
          1919,
          281,
          352,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.1819381013922735,
        "compression_ratio": 1.6756756756756757,
        "end": 3612.22,
        "id": 1008,
        "no_speech_prob": 0.13294924795627594,
        "seek": 359822,
        "start": 3611.22,
        "temperature": 0,
        "text": " Right?",
        "tokens": [
          51014,
          1779,
          30,
          51064
        ]
      },
      {
        "avg_logprob": -0.1819381013922735,
        "compression_ratio": 1.6756756756756757,
        "end": 3613.22,
        "id": 1009,
        "no_speech_prob": 0.13294924795627594,
        "seek": 359822,
        "start": 3612.22,
        "temperature": 0,
        "text": " All right.",
        "tokens": [
          51064,
          1057,
          558,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.1819381013922735,
        "compression_ratio": 1.6756756756756757,
        "end": 3618.22,
        "id": 1010,
        "no_speech_prob": 0.13294924795627594,
        "seek": 359822,
        "start": 3613.22,
        "temperature": 0,
        "text": " So what I'm going to do, maybe we'll do, I'm going to train this for a while.",
        "tokens": [
          51114,
          407,
          437,
          286,
          478,
          516,
          281,
          360,
          11,
          1310,
          321,
          603,
          360,
          11,
          286,
          478,
          516,
          281,
          3847,
          341,
          337,
          257,
          1339,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.1819381013922735,
        "compression_ratio": 1.6756756756756757,
        "end": 3621.22,
        "id": 1011,
        "no_speech_prob": 0.13294924795627594,
        "seek": 359822,
        "start": 3618.22,
        "temperature": 0,
        "text": " If you're watching the edited version of this, it'll speed through fast.",
        "tokens": [
          51364,
          759,
          291,
          434,
          1976,
          264,
          23016,
          3037,
          295,
          341,
          11,
          309,
          603,
          3073,
          807,
          2370,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.1819381013922735,
        "compression_ratio": 1.6756756756756757,
        "end": 3625.22,
        "id": 1012,
        "no_speech_prob": 0.13294924795627594,
        "seek": 359822,
        "start": 3621.22,
        "temperature": 0,
        "text": " If you're watching this live, here we go.",
        "tokens": [
          51514,
          759,
          291,
          434,
          1976,
          341,
          1621,
          11,
          510,
          321,
          352,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.15546319725808133,
        "compression_ratio": 1.7131147540983607,
        "end": 3626.22,
        "id": 1013,
        "no_speech_prob": 0.21728570759296417,
        "seek": 362522,
        "start": 3625.22,
        "temperature": 0,
        "text": " White.",
        "tokens": [
          50364,
          5552,
          13,
          50414
        ]
      },
      {
        "avg_logprob": -0.15546319725808133,
        "compression_ratio": 1.7131147540983607,
        "end": 3627.22,
        "id": 1014,
        "no_speech_prob": 0.21728570759296417,
        "seek": 362522,
        "start": 3626.22,
        "temperature": 0,
        "text": " White.",
        "tokens": [
          50414,
          5552,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.15546319725808133,
        "compression_ratio": 1.7131147540983607,
        "end": 3629.22,
        "id": 1015,
        "no_speech_prob": 0.21728570759296417,
        "seek": 362522,
        "start": 3627.22,
        "temperature": 0,
        "text": " White.",
        "tokens": [
          50464,
          5552,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.15546319725808133,
        "compression_ratio": 1.7131147540983607,
        "end": 3630.22,
        "id": 1016,
        "no_speech_prob": 0.21728570759296417,
        "seek": 362522,
        "start": 3629.22,
        "temperature": 0,
        "text": " Black.",
        "tokens": [
          50564,
          4076,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.15546319725808133,
        "compression_ratio": 1.7131147540983607,
        "end": 3632.22,
        "id": 1017,
        "no_speech_prob": 0.21728570759296417,
        "seek": 362522,
        "start": 3630.22,
        "temperature": 0,
        "text": " Black.",
        "tokens": [
          50614,
          4076,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.15546319725808133,
        "compression_ratio": 1.7131147540983607,
        "end": 3634.22,
        "id": 1018,
        "no_speech_prob": 0.21728570759296417,
        "seek": 362522,
        "start": 3632.22,
        "temperature": 0,
        "text": " White.",
        "tokens": [
          50714,
          5552,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.15546319725808133,
        "compression_ratio": 1.7131147540983607,
        "end": 3635.22,
        "id": 1019,
        "no_speech_prob": 0.21728570759296417,
        "seek": 362522,
        "start": 3634.22,
        "temperature": 0,
        "text": " White.",
        "tokens": [
          50814,
          5552,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.15546319725808133,
        "compression_ratio": 1.7131147540983607,
        "end": 3639.22,
        "id": 1020,
        "no_speech_prob": 0.21728570759296417,
        "seek": 362522,
        "start": 3635.22,
        "temperature": 0,
        "text": " White.",
        "tokens": [
          50864,
          5552,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.15546319725808133,
        "compression_ratio": 1.7131147540983607,
        "end": 3640.22,
        "id": 1021,
        "no_speech_prob": 0.21728570759296417,
        "seek": 362522,
        "start": 3639.22,
        "temperature": 0,
        "text": " Black.",
        "tokens": [
          51064,
          4076,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.15546319725808133,
        "compression_ratio": 1.7131147540983607,
        "end": 3641.22,
        "id": 1022,
        "no_speech_prob": 0.21728570759296417,
        "seek": 362522,
        "start": 3640.22,
        "temperature": 0,
        "text": " Black.",
        "tokens": [
          51114,
          4076,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.15546319725808133,
        "compression_ratio": 1.7131147540983607,
        "end": 3642.22,
        "id": 1023,
        "no_speech_prob": 0.21728570759296417,
        "seek": 362522,
        "start": 3641.22,
        "temperature": 0,
        "text": " Black.",
        "tokens": [
          51164,
          4076,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.15546319725808133,
        "compression_ratio": 1.7131147540983607,
        "end": 3643.22,
        "id": 1024,
        "no_speech_prob": 0.21728570759296417,
        "seek": 362522,
        "start": 3642.22,
        "temperature": 0,
        "text": " White.",
        "tokens": [
          51214,
          5552,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.15546319725808133,
        "compression_ratio": 1.7131147540983607,
        "end": 3646.22,
        "id": 1025,
        "no_speech_prob": 0.21728570759296417,
        "seek": 362522,
        "start": 3643.22,
        "temperature": 0,
        "text": " White.",
        "tokens": [
          51264,
          5552,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.15546319725808133,
        "compression_ratio": 1.7131147540983607,
        "end": 3647.22,
        "id": 1026,
        "no_speech_prob": 0.21728570759296417,
        "seek": 362522,
        "start": 3646.22,
        "temperature": 0,
        "text": " Can anybody see these numbers?",
        "tokens": [
          51414,
          1664,
          4472,
          536,
          613,
          3547,
          30,
          51464
        ]
      },
      {
        "avg_logprob": -0.15546319725808133,
        "compression_ratio": 1.7131147540983607,
        "end": 3648.22,
        "id": 1027,
        "no_speech_prob": 0.21728570759296417,
        "seek": 362522,
        "start": 3647.22,
        "temperature": 0,
        "text": " Are they really adjusting?",
        "tokens": [
          51464,
          2014,
          436,
          534,
          23559,
          30,
          51514
        ]
      },
      {
        "avg_logprob": -0.15546319725808133,
        "compression_ratio": 1.7131147540983607,
        "end": 3650.22,
        "id": 1028,
        "no_speech_prob": 0.21728570759296417,
        "seek": 362522,
        "start": 3648.22,
        "temperature": 0,
        "text": " This isn't really working very well, is it?",
        "tokens": [
          51514,
          639,
          1943,
          380,
          534,
          1364,
          588,
          731,
          11,
          307,
          309,
          30,
          51614
        ]
      },
      {
        "avg_logprob": -0.15546319725808133,
        "compression_ratio": 1.7131147540983607,
        "end": 3651.22,
        "id": 1029,
        "no_speech_prob": 0.21728570759296417,
        "seek": 362522,
        "start": 3650.22,
        "temperature": 0,
        "text": " But don't worry.",
        "tokens": [
          51614,
          583,
          500,
          380,
          3292,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.22058484583725163,
        "compression_ratio": 1.5314285714285714,
        "end": 3656.22,
        "id": 1030,
        "no_speech_prob": 0.41105586290359497,
        "seek": 365122,
        "start": 3652.22,
        "temperature": 0,
        "text": " White.",
        "tokens": [
          50414,
          5552,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.22058484583725163,
        "compression_ratio": 1.5314285714285714,
        "end": 3657.22,
        "id": 1031,
        "no_speech_prob": 0.41105586290359497,
        "seek": 365122,
        "start": 3656.22,
        "temperature": 0,
        "text": " White.",
        "tokens": [
          50614,
          5552,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.22058484583725163,
        "compression_ratio": 1.5314285714285714,
        "end": 3658.22,
        "id": 1032,
        "no_speech_prob": 0.41105586290359497,
        "seek": 365122,
        "start": 3657.22,
        "temperature": 0,
        "text": " Black.",
        "tokens": [
          50664,
          4076,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.22058484583725163,
        "compression_ratio": 1.5314285714285714,
        "end": 3660.22,
        "id": 1033,
        "no_speech_prob": 0.41105586290359497,
        "seek": 365122,
        "start": 3658.22,
        "temperature": 0,
        "text": " White.",
        "tokens": [
          50714,
          5552,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.22058484583725163,
        "compression_ratio": 1.5314285714285714,
        "end": 3666.22,
        "id": 1034,
        "no_speech_prob": 0.41105586290359497,
        "seek": 365122,
        "start": 3660.22,
        "temperature": 0,
        "text": " Just talk amongst yourselves.",
        "tokens": [
          50814,
          1449,
          751,
          12918,
          14791,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.22058484583725163,
        "compression_ratio": 1.5314285714285714,
        "end": 3670.22,
        "id": 1035,
        "no_speech_prob": 0.41105586290359497,
        "seek": 365122,
        "start": 3666.22,
        "temperature": 0,
        "text": " I probably need to have like, the interesting thing is like,",
        "tokens": [
          51114,
          286,
          1391,
          643,
          281,
          362,
          411,
          11,
          264,
          1880,
          551,
          307,
          411,
          11,
          51314
        ]
      },
      {
        "avg_logprob": -0.22058484583725163,
        "compression_ratio": 1.5314285714285714,
        "end": 3673.22,
        "id": 1036,
        "no_speech_prob": 0.41105586290359497,
        "seek": 365122,
        "start": 3670.22,
        "temperature": 0,
        "text": " this is why you need a lot of data for this stuff to work, do anything.",
        "tokens": [
          51314,
          341,
          307,
          983,
          291,
          643,
          257,
          688,
          295,
          1412,
          337,
          341,
          1507,
          281,
          589,
          11,
          360,
          1340,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.22058484583725163,
        "compression_ratio": 1.5314285714285714,
        "end": 3675.22,
        "id": 1037,
        "no_speech_prob": 0.41105586290359497,
        "seek": 365122,
        "start": 3673.22,
        "temperature": 0,
        "text": " I could make the learning rate much higher.",
        "tokens": [
          51464,
          286,
          727,
          652,
          264,
          2539,
          3314,
          709,
          2946,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.22058484583725163,
        "compression_ratio": 1.5314285714285714,
        "end": 3678.22,
        "id": 1038,
        "no_speech_prob": 0.41105586290359497,
        "seek": 365122,
        "start": 3675.22,
        "temperature": 0,
        "text": " That's probably what I should do.",
        "tokens": [
          51564,
          663,
          311,
          1391,
          437,
          286,
          820,
          360,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.23007137775421144,
        "compression_ratio": 1.4437869822485208,
        "end": 3682.22,
        "id": 1039,
        "no_speech_prob": 0.21728335320949554,
        "seek": 367822,
        "start": 3678.22,
        "temperature": 0,
        "text": " You can see here, let me just keep going.",
        "tokens": [
          50364,
          509,
          393,
          536,
          510,
          11,
          718,
          385,
          445,
          1066,
          516,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.23007137775421144,
        "compression_ratio": 1.4437869822485208,
        "end": 3685.22,
        "id": 1040,
        "no_speech_prob": 0.21728335320949554,
        "seek": 367822,
        "start": 3682.22,
        "temperature": 0,
        "text": " Hold on, let me at least just tell everything to be white.",
        "tokens": [
          50564,
          6962,
          322,
          11,
          718,
          385,
          412,
          1935,
          445,
          980,
          1203,
          281,
          312,
          2418,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.23007137775421144,
        "compression_ratio": 1.4437869822485208,
        "end": 3686.22,
        "id": 1041,
        "no_speech_prob": 0.21728335320949554,
        "seek": 367822,
        "start": 3685.22,
        "temperature": 0,
        "text": " Yeah, okay.",
        "tokens": [
          50714,
          865,
          11,
          1392,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.23007137775421144,
        "compression_ratio": 1.4437869822485208,
        "end": 3687.22,
        "id": 1042,
        "no_speech_prob": 0.21728335320949554,
        "seek": 367822,
        "start": 3686.22,
        "temperature": 0,
        "text": " So it is sort of learning.",
        "tokens": [
          50764,
          407,
          309,
          307,
          1333,
          295,
          2539,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.23007137775421144,
        "compression_ratio": 1.4437869822485208,
        "end": 3690.22,
        "id": 1043,
        "no_speech_prob": 0.21728335320949554,
        "seek": 367822,
        "start": 3687.22,
        "temperature": 0,
        "text": " Whoa.",
        "tokens": [
          50814,
          7521,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.23007137775421144,
        "compression_ratio": 1.4437869822485208,
        "end": 3697.22,
        "id": 1044,
        "no_speech_prob": 0.21728335320949554,
        "seek": 367822,
        "start": 3690.22,
        "temperature": 0,
        "text": " And I'm probably using like, Softmax and it's going to have much more.",
        "tokens": [
          50964,
          400,
          286,
          478,
          1391,
          1228,
          411,
          11,
          16985,
          41167,
          293,
          309,
          311,
          516,
          281,
          362,
          709,
          544,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.23007137775421144,
        "compression_ratio": 1.4437869822485208,
        "end": 3704.22,
        "id": 1045,
        "no_speech_prob": 0.21728335320949554,
        "seek": 367822,
        "start": 3697.22,
        "temperature": 0,
        "text": " Okay, so let me keep going.",
        "tokens": [
          51314,
          1033,
          11,
          370,
          718,
          385,
          1066,
          516,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.2322057088216146,
        "compression_ratio": 0.8431372549019608,
        "end": 3714.22,
        "id": 1046,
        "no_speech_prob": 0.09807635098695755,
        "seek": 370422,
        "start": 3704.22,
        "temperature": 0,
        "text": " I don't know.",
        "tokens": [
          50364,
          286,
          500,
          380,
          458,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.2322057088216146,
        "compression_ratio": 0.8431372549019608,
        "end": 3722.22,
        "id": 1047,
        "no_speech_prob": 0.09807635098695755,
        "seek": 370422,
        "start": 3714.22,
        "temperature": 0,
        "text": " Do I have an error somewhere?",
        "tokens": [
          50864,
          1144,
          286,
          362,
          364,
          6713,
          4079,
          30,
          51264
        ]
      },
      {
        "avg_logprob": -0.19259574495512863,
        "compression_ratio": 1.3015873015873016,
        "end": 3740.22,
        "id": 1048,
        "no_speech_prob": 0.06853540986776352,
        "seek": 372222,
        "start": 3722.22,
        "temperature": 0,
        "text": " Good news is I have a half an hour left.",
        "tokens": [
          50364,
          2205,
          2583,
          307,
          286,
          362,
          257,
          1922,
          364,
          1773,
          1411,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.19259574495512863,
        "compression_ratio": 1.3015873015873016,
        "end": 3744.22,
        "id": 1049,
        "no_speech_prob": 0.06853540986776352,
        "seek": 372222,
        "start": 3740.22,
        "temperature": 0,
        "text": " All right, so one thing I want to try to do, let's see if I can train it.",
        "tokens": [
          51264,
          1057,
          558,
          11,
          370,
          472,
          551,
          286,
          528,
          281,
          853,
          281,
          360,
          11,
          718,
          311,
          536,
          498,
          286,
          393,
          3847,
          309,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.19259574495512863,
        "compression_ratio": 1.3015873015873016,
        "end": 3749.22,
        "id": 1050,
        "no_speech_prob": 0.06853540986776352,
        "seek": 372222,
        "start": 3744.22,
        "temperature": 0,
        "text": " Okay, I have an idea.",
        "tokens": [
          51464,
          1033,
          11,
          286,
          362,
          364,
          1558,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.19259574495512863,
        "compression_ratio": 1.3015873015873016,
        "end": 3751.22,
        "id": 1051,
        "no_speech_prob": 0.06853540986776352,
        "seek": 372222,
        "start": 3749.22,
        "temperature": 0,
        "text": " Yeah, I mean it is working.",
        "tokens": [
          51714,
          865,
          11,
          286,
          914,
          309,
          307,
          1364,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.2150255091050092,
        "compression_ratio": 1.7721518987341771,
        "end": 3754.22,
        "id": 1052,
        "no_speech_prob": 0.09946851432323456,
        "seek": 375122,
        "start": 3751.22,
        "temperature": 0,
        "text": " The problem is, like for this to actually, so first of all,",
        "tokens": [
          50364,
          440,
          1154,
          307,
          11,
          411,
          337,
          341,
          281,
          767,
          11,
          370,
          700,
          295,
          439,
          11,
          50514
        ]
      },
      {
        "avg_logprob": -0.2150255091050092,
        "compression_ratio": 1.7721518987341771,
        "end": 3756.22,
        "id": 1053,
        "no_speech_prob": 0.09946851432323456,
        "seek": 375122,
        "start": 3754.22,
        "temperature": 0,
        "text": " maybe I need more than three hidden nodes.",
        "tokens": [
          50514,
          1310,
          286,
          643,
          544,
          813,
          1045,
          7633,
          13891,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.2150255091050092,
        "compression_ratio": 1.7721518987341771,
        "end": 3757.22,
        "id": 1054,
        "no_speech_prob": 0.09946851432323456,
        "seek": 375122,
        "start": 3756.22,
        "temperature": 0,
        "text": " I don't think so.",
        "tokens": [
          50614,
          286,
          500,
          380,
          519,
          370,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.2150255091050092,
        "compression_ratio": 1.7721518987341771,
        "end": 3759.22,
        "id": 1055,
        "no_speech_prob": 0.09946851432323456,
        "seek": 375122,
        "start": 3757.22,
        "temperature": 0,
        "text": " It's such a simple problem.",
        "tokens": [
          50664,
          467,
          311,
          1270,
          257,
          2199,
          1154,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.2150255091050092,
        "compression_ratio": 1.7721518987341771,
        "end": 3763.22,
        "id": 1056,
        "no_speech_prob": 0.09946851432323456,
        "seek": 375122,
        "start": 3759.22,
        "temperature": 0,
        "text": " And I think it probably just needs a lot of training data.",
        "tokens": [
          50764,
          400,
          286,
          519,
          309,
          1391,
          445,
          2203,
          257,
          688,
          295,
          3097,
          1412,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.2150255091050092,
        "compression_ratio": 1.7721518987341771,
        "end": 3766.22,
        "id": 1057,
        "no_speech_prob": 0.09946851432323456,
        "seek": 375122,
        "start": 3763.22,
        "temperature": 0,
        "text": " So let's actually, let's train it.",
        "tokens": [
          50964,
          407,
          718,
          311,
          767,
          11,
          718,
          311,
          3847,
          309,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.2150255091050092,
        "compression_ratio": 1.7721518987341771,
        "end": 3768.22,
        "id": 1058,
        "no_speech_prob": 0.09946851432323456,
        "seek": 375122,
        "start": 3766.22,
        "temperature": 0,
        "text": " Let's train it with a lot of training data.",
        "tokens": [
          51114,
          961,
          311,
          3847,
          309,
          365,
          257,
          688,
          295,
          3097,
          1412,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.2150255091050092,
        "compression_ratio": 1.7721518987341771,
        "end": 3770.22,
        "id": 1059,
        "no_speech_prob": 0.09946851432323456,
        "seek": 375122,
        "start": 3768.22,
        "temperature": 0,
        "text": " So I'm going to go through and do that.",
        "tokens": [
          51214,
          407,
          286,
          478,
          516,
          281,
          352,
          807,
          293,
          360,
          300,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.2150255091050092,
        "compression_ratio": 1.7721518987341771,
        "end": 3772.22,
        "id": 1060,
        "no_speech_prob": 0.09946851432323456,
        "seek": 375122,
        "start": 3770.22,
        "temperature": 0,
        "text": " So I'm going to add this.",
        "tokens": [
          51314,
          407,
          286,
          478,
          516,
          281,
          909,
          341,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.2150255091050092,
        "compression_ratio": 1.7721518987341771,
        "end": 3774.22,
        "id": 1061,
        "no_speech_prob": 0.09946851432323456,
        "seek": 375122,
        "start": 3772.22,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          51414,
          1033,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.2150255091050092,
        "compression_ratio": 1.7721518987341771,
        "end": 3779.22,
        "id": 1062,
        "no_speech_prob": 0.09946851432323456,
        "seek": 375122,
        "start": 3774.22,
        "temperature": 0,
        "text": " So, Mateo, this is going to be the end of that sped up thing.",
        "tokens": [
          51514,
          407,
          11,
          6789,
          68,
          78,
          11,
          341,
          307,
          516,
          281,
          312,
          264,
          917,
          295,
          300,
          637,
          292,
          493,
          551,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.19729771485199799,
        "compression_ratio": 1.801418439716312,
        "end": 3782.22,
        "id": 1063,
        "no_speech_prob": 0.07369442284107208,
        "seek": 377922,
        "start": 3779.22,
        "temperature": 0,
        "text": " So, and I'll come back.",
        "tokens": [
          50364,
          407,
          11,
          293,
          286,
          603,
          808,
          646,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.19729771485199799,
        "compression_ratio": 1.801418439716312,
        "end": 3783.22,
        "id": 1064,
        "no_speech_prob": 0.07369442284107208,
        "seek": 377922,
        "start": 3782.22,
        "temperature": 0,
        "text": " All right, I'm back.",
        "tokens": [
          50514,
          1057,
          558,
          11,
          286,
          478,
          646,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.19729771485199799,
        "compression_ratio": 1.801418439716312,
        "end": 3784.22,
        "id": 1065,
        "no_speech_prob": 0.07369442284107208,
        "seek": 377922,
        "start": 3783.22,
        "temperature": 0,
        "text": " Actually, you know, so guess what?",
        "tokens": [
          50564,
          5135,
          11,
          291,
          458,
          11,
          370,
          2041,
          437,
          30,
          50614
        ]
      },
      {
        "avg_logprob": -0.19729771485199799,
        "compression_ratio": 1.801418439716312,
        "end": 3785.22,
        "id": 1066,
        "no_speech_prob": 0.07369442284107208,
        "seek": 377922,
        "start": 3784.22,
        "temperature": 0,
        "text": " This didn't work very well.",
        "tokens": [
          50614,
          639,
          994,
          380,
          589,
          588,
          731,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.19729771485199799,
        "compression_ratio": 1.801418439716312,
        "end": 3790.22,
        "id": 1067,
        "no_speech_prob": 0.07369442284107208,
        "seek": 377922,
        "start": 3785.22,
        "temperature": 0,
        "text": " I mean I think it is working, working with air quotes because if I start teaching it,",
        "tokens": [
          50664,
          286,
          914,
          286,
          519,
          309,
          307,
          1364,
          11,
          1364,
          365,
          1988,
          19963,
          570,
          498,
          286,
          722,
          4571,
          309,
          11,
          50914
        ]
      },
      {
        "avg_logprob": -0.19729771485199799,
        "compression_ratio": 1.801418439716312,
        "end": 3794.22,
        "id": 1068,
        "no_speech_prob": 0.07369442284107208,
        "seek": 377922,
        "start": 3790.22,
        "temperature": 0,
        "text": " like hey, I think black looks better over everything, it's eventually going to switch.",
        "tokens": [
          50914,
          411,
          4177,
          11,
          286,
          519,
          2211,
          1542,
          1101,
          670,
          1203,
          11,
          309,
          311,
          4728,
          516,
          281,
          3679,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.19729771485199799,
        "compression_ratio": 1.801418439716312,
        "end": 3796.22,
        "id": 1069,
        "no_speech_prob": 0.07369442284107208,
        "seek": 377922,
        "start": 3794.22,
        "temperature": 0,
        "text": " And then if I just click on white for a while, it's going to switch.",
        "tokens": [
          51114,
          400,
          550,
          498,
          286,
          445,
          2052,
          322,
          2418,
          337,
          257,
          1339,
          11,
          309,
          311,
          516,
          281,
          3679,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.19729771485199799,
        "compression_ratio": 1.801418439716312,
        "end": 3799.22,
        "id": 1070,
        "no_speech_prob": 0.07369442284107208,
        "seek": 377922,
        "start": 3796.22,
        "temperature": 0,
        "text": " Oh, and it's kind of, you can see it's sort of switching back and forth.",
        "tokens": [
          51214,
          876,
          11,
          293,
          309,
          311,
          733,
          295,
          11,
          291,
          393,
          536,
          309,
          311,
          1333,
          295,
          16493,
          646,
          293,
          5220,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.19729771485199799,
        "compression_ratio": 1.801418439716312,
        "end": 3802.22,
        "id": 1071,
        "no_speech_prob": 0.07369442284107208,
        "seek": 377922,
        "start": 3799.22,
        "temperature": 0,
        "text": " But I think I'd have to sit here and click like for a really, really, really, really,",
        "tokens": [
          51364,
          583,
          286,
          519,
          286,
          1116,
          362,
          281,
          1394,
          510,
          293,
          2052,
          411,
          337,
          257,
          534,
          11,
          534,
          11,
          534,
          11,
          534,
          11,
          51514
        ]
      },
      {
        "avg_logprob": -0.19377550934300278,
        "compression_ratio": 1.7685950413223142,
        "end": 3809.22,
        "id": 1072,
        "no_speech_prob": 0.6891807913780212,
        "seek": 380222,
        "start": 3802.22,
        "temperature": 0,
        "text": " really, really, really long time to get it to really like learn to make an optimal decision.",
        "tokens": [
          50364,
          534,
          11,
          534,
          11,
          534,
          938,
          565,
          281,
          483,
          309,
          281,
          534,
          411,
          1466,
          281,
          652,
          364,
          16252,
          3537,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.19377550934300278,
        "compression_ratio": 1.7685950413223142,
        "end": 3810.22,
        "id": 1073,
        "no_speech_prob": 0.6891807913780212,
        "seek": 380222,
        "start": 3809.22,
        "temperature": 0,
        "text": " I need like a lot of training data.",
        "tokens": [
          50714,
          286,
          643,
          411,
          257,
          688,
          295,
          3097,
          1412,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.19377550934300278,
        "compression_ratio": 1.7685950413223142,
        "end": 3813.22,
        "id": 1074,
        "no_speech_prob": 0.6891807913780212,
        "seek": 380222,
        "start": 3810.22,
        "temperature": 0,
        "text": " This is a thing.",
        "tokens": [
          50764,
          639,
          307,
          257,
          551,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.19377550934300278,
        "compression_ratio": 1.7685950413223142,
        "end": 3815.22,
        "id": 1075,
        "no_speech_prob": 0.6891807913780212,
        "seek": 380222,
        "start": 3813.22,
        "temperature": 0,
        "text": " I don't know what the discussion is going on in the chat.",
        "tokens": [
          50914,
          286,
          500,
          380,
          458,
          437,
          264,
          5017,
          307,
          516,
          322,
          294,
          264,
          5081,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.19377550934300278,
        "compression_ratio": 1.7685950413223142,
        "end": 3819.22,
        "id": 1076,
        "no_speech_prob": 0.6891807913780212,
        "seek": 380222,
        "start": 3815.22,
        "temperature": 0,
        "text": " You're really messing with me.",
        "tokens": [
          51014,
          509,
          434,
          534,
          23258,
          365,
          385,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.19377550934300278,
        "compression_ratio": 1.7685950413223142,
        "end": 3823.22,
        "id": 1077,
        "no_speech_prob": 0.6891807913780212,
        "seek": 380222,
        "start": 3819.22,
        "temperature": 0,
        "text": " I just, I guess I just shouldn't look at it when it's like not about what I'm talking about.",
        "tokens": [
          51214,
          286,
          445,
          11,
          286,
          2041,
          286,
          445,
          4659,
          380,
          574,
          412,
          309,
          562,
          309,
          311,
          411,
          406,
          466,
          437,
          286,
          478,
          1417,
          466,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.19377550934300278,
        "compression_ratio": 1.7685950413223142,
        "end": 3824.22,
        "id": 1078,
        "no_speech_prob": 0.6891807913780212,
        "seek": 380222,
        "start": 3823.22,
        "temperature": 0,
        "text": " It's like emojis?",
        "tokens": [
          51414,
          467,
          311,
          411,
          19611,
          40371,
          30,
          51464
        ]
      },
      {
        "avg_logprob": -0.19377550934300278,
        "compression_ratio": 1.7685950413223142,
        "end": 3825.22,
        "id": 1079,
        "no_speech_prob": 0.6891807913780212,
        "seek": 380222,
        "start": 3824.22,
        "temperature": 0,
        "text": " What have I done?",
        "tokens": [
          51464,
          708,
          362,
          286,
          1096,
          30,
          51514
        ]
      },
      {
        "avg_logprob": -0.19377550934300278,
        "compression_ratio": 1.7685950413223142,
        "end": 3826.22,
        "id": 1080,
        "no_speech_prob": 0.6891807913780212,
        "seek": 380222,
        "start": 3825.22,
        "temperature": 0,
        "text": " What have I done wrong?",
        "tokens": [
          51514,
          708,
          362,
          286,
          1096,
          2085,
          30,
          51564
        ]
      },
      {
        "avg_logprob": -0.19377550934300278,
        "compression_ratio": 1.7685950413223142,
        "end": 3830.22,
        "id": 1081,
        "no_speech_prob": 0.6891807913780212,
        "seek": 380222,
        "start": 3826.22,
        "temperature": 0,
        "text": " All right, let me, let me, I don't know.",
        "tokens": [
          51564,
          1057,
          558,
          11,
          718,
          385,
          11,
          718,
          385,
          11,
          286,
          500,
          380,
          458,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.19252038646388697,
        "compression_ratio": 1.7074074074074075,
        "end": 3835.22,
        "id": 1082,
        "no_speech_prob": 0.00007722173177171499,
        "seek": 383022,
        "start": 3831.22,
        "temperature": 0,
        "text": " You can use all this as like some more fast forwarding time.",
        "tokens": [
          50414,
          509,
          393,
          764,
          439,
          341,
          382,
          411,
          512,
          544,
          2370,
          2128,
          278,
          565,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.19252038646388697,
        "compression_ratio": 1.7074074074074075,
        "end": 3836.22,
        "id": 1083,
        "no_speech_prob": 0.00007722173177171499,
        "seek": 383022,
        "start": 3835.22,
        "temperature": 0,
        "text": " I'm going to start over.",
        "tokens": [
          50614,
          286,
          478,
          516,
          281,
          722,
          670,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.19252038646388697,
        "compression_ratio": 1.7074074074074075,
        "end": 3837.22,
        "id": 1084,
        "no_speech_prob": 0.00007722173177171499,
        "seek": 383022,
        "start": 3836.22,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          50664,
          1033,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.19252038646388697,
        "compression_ratio": 1.7074074074074075,
        "end": 3843.22,
        "id": 1085,
        "no_speech_prob": 0.00007722173177171499,
        "seek": 383022,
        "start": 3837.22,
        "temperature": 0,
        "text": " Okay, I'm back.",
        "tokens": [
          50714,
          1033,
          11,
          286,
          478,
          646,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.19252038646388697,
        "compression_ratio": 1.7074074074074075,
        "end": 3844.22,
        "id": 1086,
        "no_speech_prob": 0.00007722173177171499,
        "seek": 383022,
        "start": 3843.22,
        "temperature": 0,
        "text": " So I tried training this for a while.",
        "tokens": [
          51014,
          407,
          286,
          3031,
          3097,
          341,
          337,
          257,
          1339,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.19252038646388697,
        "compression_ratio": 1.7074074074074075,
        "end": 3846.22,
        "id": 1087,
        "no_speech_prob": 0.00007722173177171499,
        "seek": 383022,
        "start": 3844.22,
        "temperature": 0,
        "text": " I tried talking about it for a little bit.",
        "tokens": [
          51064,
          286,
          3031,
          1417,
          466,
          309,
          337,
          257,
          707,
          857,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.19252038646388697,
        "compression_ratio": 1.7074074074074075,
        "end": 3851.22,
        "id": 1088,
        "no_speech_prob": 0.00007722173177171499,
        "seek": 383022,
        "start": 3846.22,
        "temperature": 0,
        "text": " I didn't really get very far, even though I think you can see like, ah, I'm going to like, I'm picking.",
        "tokens": [
          51164,
          286,
          994,
          380,
          534,
          483,
          588,
          1400,
          11,
          754,
          1673,
          286,
          519,
          291,
          393,
          536,
          411,
          11,
          3716,
          11,
          286,
          478,
          516,
          281,
          411,
          11,
          286,
          478,
          8867,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.19252038646388697,
        "compression_ratio": 1.7074074074074075,
        "end": 3853.22,
        "id": 1089,
        "no_speech_prob": 0.00007722173177171499,
        "seek": 383022,
        "start": 3851.22,
        "temperature": 0,
        "text": " And it's kind of actually, oops, no, I should really move.",
        "tokens": [
          51414,
          400,
          309,
          311,
          733,
          295,
          767,
          11,
          34166,
          11,
          572,
          11,
          286,
          820,
          534,
          1286,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.19252038646388697,
        "compression_ratio": 1.7074074074074075,
        "end": 3855.22,
        "id": 1090,
        "no_speech_prob": 0.00007722173177171499,
        "seek": 383022,
        "start": 3853.22,
        "temperature": 0,
        "text": " It's giving me sort of different results.",
        "tokens": [
          51514,
          467,
          311,
          2902,
          385,
          1333,
          295,
          819,
          3542,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.19252038646388697,
        "compression_ratio": 1.7074074074074075,
        "end": 3856.22,
        "id": 1091,
        "no_speech_prob": 0.00007722173177171499,
        "seek": 383022,
        "start": 3855.22,
        "temperature": 0,
        "text": " That's black.",
        "tokens": [
          51614,
          663,
          311,
          2211,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.19252038646388697,
        "compression_ratio": 1.7074074074074075,
        "end": 3857.22,
        "id": 1092,
        "no_speech_prob": 0.00007722173177171499,
        "seek": 383022,
        "start": 3856.22,
        "temperature": 0,
        "text": " This one is black.",
        "tokens": [
          51664,
          639,
          472,
          307,
          2211,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.19252038646388697,
        "compression_ratio": 1.7074074074074075,
        "end": 3858.22,
        "id": 1093,
        "no_speech_prob": 0.00007722173177171499,
        "seek": 383022,
        "start": 3857.22,
        "temperature": 0,
        "text": " That's correct.",
        "tokens": [
          51714,
          663,
          311,
          3006,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.19252038646388697,
        "compression_ratio": 1.7074074074074075,
        "end": 3859.22,
        "id": 1094,
        "no_speech_prob": 0.00007722173177171499,
        "seek": 383022,
        "start": 3858.22,
        "temperature": 0,
        "text": " That one is white.",
        "tokens": [
          51764,
          663,
          472,
          307,
          2418,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.17899167006182823,
        "compression_ratio": 1.8784313725490196,
        "end": 3860.22,
        "id": 1095,
        "no_speech_prob": 0.28455355763435364,
        "seek": 385922,
        "start": 3859.22,
        "temperature": 0,
        "text": " That one is correct.",
        "tokens": [
          50364,
          663,
          472,
          307,
          3006,
          13,
          50414
        ]
      },
      {
        "avg_logprob": -0.17899167006182823,
        "compression_ratio": 1.8784313725490196,
        "end": 3861.22,
        "id": 1096,
        "no_speech_prob": 0.28455355763435364,
        "seek": 385922,
        "start": 3860.22,
        "temperature": 0,
        "text": " Look at this.",
        "tokens": [
          50414,
          2053,
          412,
          341,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.17899167006182823,
        "compression_ratio": 1.8784313725490196,
        "end": 3862.22,
        "id": 1097,
        "no_speech_prob": 0.28455355763435364,
        "seek": 385922,
        "start": 3861.22,
        "temperature": 0,
        "text": " Yeah.",
        "tokens": [
          50464,
          865,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.17899167006182823,
        "compression_ratio": 1.8784313725490196,
        "end": 3863.22,
        "id": 1098,
        "no_speech_prob": 0.28455355763435364,
        "seek": 385922,
        "start": 3862.22,
        "temperature": 0,
        "text": " Hey, I think we're good.",
        "tokens": [
          50514,
          1911,
          11,
          286,
          519,
          321,
          434,
          665,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.17899167006182823,
        "compression_ratio": 1.8784313725490196,
        "end": 3864.22,
        "id": 1099,
        "no_speech_prob": 0.28455355763435364,
        "seek": 385922,
        "start": 3863.22,
        "temperature": 0,
        "text": " We can see that it's kind of making some decisions.",
        "tokens": [
          50564,
          492,
          393,
          536,
          300,
          309,
          311,
          733,
          295,
          1455,
          512,
          5327,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.17899167006182823,
        "compression_ratio": 1.8784313725490196,
        "end": 3865.22,
        "id": 1100,
        "no_speech_prob": 0.28455355763435364,
        "seek": 385922,
        "start": 3864.22,
        "temperature": 0,
        "text": " We think this one should be white.",
        "tokens": [
          50614,
          492,
          519,
          341,
          472,
          820,
          312,
          2418,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.17899167006182823,
        "compression_ratio": 1.8784313725490196,
        "end": 3866.22,
        "id": 1101,
        "no_speech_prob": 0.28455355763435364,
        "seek": 385922,
        "start": 3865.22,
        "temperature": 0,
        "text": " Let's correct it.",
        "tokens": [
          50664,
          961,
          311,
          3006,
          309,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.17899167006182823,
        "compression_ratio": 1.8784313725490196,
        "end": 3867.22,
        "id": 1102,
        "no_speech_prob": 0.28455355763435364,
        "seek": 385922,
        "start": 3866.22,
        "temperature": 0,
        "text": " That seems right.",
        "tokens": [
          50714,
          663,
          2544,
          558,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.17899167006182823,
        "compression_ratio": 1.8784313725490196,
        "end": 3868.22,
        "id": 1103,
        "no_speech_prob": 0.28455355763435364,
        "seek": 385922,
        "start": 3867.22,
        "temperature": 0,
        "text": " This is definitely right.",
        "tokens": [
          50764,
          639,
          307,
          2138,
          558,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.17899167006182823,
        "compression_ratio": 1.8784313725490196,
        "end": 3869.22,
        "id": 1104,
        "no_speech_prob": 0.28455355763435364,
        "seek": 385922,
        "start": 3868.22,
        "temperature": 0,
        "text": " That seems right.",
        "tokens": [
          50814,
          663,
          2544,
          558,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.17899167006182823,
        "compression_ratio": 1.8784313725490196,
        "end": 3870.22,
        "id": 1105,
        "no_speech_prob": 0.28455355763435364,
        "seek": 385922,
        "start": 3869.22,
        "temperature": 0,
        "text": " This seems right.",
        "tokens": [
          50864,
          639,
          2544,
          558,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.17899167006182823,
        "compression_ratio": 1.8784313725490196,
        "end": 3871.22,
        "id": 1106,
        "no_speech_prob": 0.28455355763435364,
        "seek": 385922,
        "start": 3870.22,
        "temperature": 0,
        "text": " This seems right.",
        "tokens": [
          50914,
          639,
          2544,
          558,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.17899167006182823,
        "compression_ratio": 1.8784313725490196,
        "end": 3872.22,
        "id": 1107,
        "no_speech_prob": 0.28455355763435364,
        "seek": 385922,
        "start": 3871.22,
        "temperature": 0,
        "text": " Right.",
        "tokens": [
          50964,
          1779,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.17899167006182823,
        "compression_ratio": 1.8784313725490196,
        "end": 3873.22,
        "id": 1108,
        "no_speech_prob": 0.28455355763435364,
        "seek": 385922,
        "start": 3872.22,
        "temperature": 0,
        "text": " Right.",
        "tokens": [
          51014,
          1779,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.17899167006182823,
        "compression_ratio": 1.8784313725490196,
        "end": 3876.22,
        "id": 1109,
        "no_speech_prob": 0.28455355763435364,
        "seek": 385922,
        "start": 3873.22,
        "temperature": 0,
        "text": " Black is better with this one.",
        "tokens": [
          51064,
          4076,
          307,
          1101,
          365,
          341,
          472,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.17899167006182823,
        "compression_ratio": 1.8784313725490196,
        "end": 3878.22,
        "id": 1110,
        "no_speech_prob": 0.28455355763435364,
        "seek": 385922,
        "start": 3876.22,
        "temperature": 0,
        "text": " White is better.",
        "tokens": [
          51214,
          5552,
          307,
          1101,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.17899167006182823,
        "compression_ratio": 1.8784313725490196,
        "end": 3879.22,
        "id": 1111,
        "no_speech_prob": 0.28455355763435364,
        "seek": 385922,
        "start": 3878.22,
        "temperature": 0,
        "text": " I don't know.",
        "tokens": [
          51314,
          286,
          500,
          380,
          458,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.17899167006182823,
        "compression_ratio": 1.8784313725490196,
        "end": 3880.22,
        "id": 1112,
        "no_speech_prob": 0.28455355763435364,
        "seek": 385922,
        "start": 3879.22,
        "temperature": 0,
        "text": " White.",
        "tokens": [
          51364,
          5552,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.17899167006182823,
        "compression_ratio": 1.8784313725490196,
        "end": 3887.22,
        "id": 1113,
        "no_speech_prob": 0.28455355763435364,
        "seek": 385922,
        "start": 3880.22,
        "temperature": 0,
        "text": " Anyway, you can see it's kind of getting, I don't know that I've really given it enough training data to really work optimally.",
        "tokens": [
          51414,
          5684,
          11,
          291,
          393,
          536,
          309,
          311,
          733,
          295,
          1242,
          11,
          286,
          500,
          380,
          458,
          300,
          286,
          600,
          534,
          2212,
          309,
          1547,
          3097,
          1412,
          281,
          534,
          589,
          5028,
          379,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.1936456805369893,
        "compression_ratio": 1.7288732394366197,
        "end": 3899.22,
        "id": 1114,
        "no_speech_prob": 0.017176371067762375,
        "seek": 388722,
        "start": 3887.22,
        "temperature": 0,
        "text": " Maybe I, this could be an interesting project if this were like deployed in a distributed way on the web and thousands of people could all come and click on it and like through and train it together as a group of people in the world.",
        "tokens": [
          50364,
          2704,
          286,
          11,
          341,
          727,
          312,
          364,
          1880,
          1716,
          498,
          341,
          645,
          411,
          17826,
          294,
          257,
          12631,
          636,
          322,
          264,
          3670,
          293,
          5383,
          295,
          561,
          727,
          439,
          808,
          293,
          2052,
          322,
          309,
          293,
          411,
          807,
          293,
          3847,
          309,
          1214,
          382,
          257,
          1594,
          295,
          561,
          294,
          264,
          1002,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.1936456805369893,
        "compression_ratio": 1.7288732394366197,
        "end": 3903.22,
        "id": 1115,
        "no_speech_prob": 0.017176371067762375,
        "seek": 388722,
        "start": 3899.22,
        "temperature": 0,
        "text": " But let's try training it automatically to see if that works a little bit better.",
        "tokens": [
          50964,
          583,
          718,
          311,
          853,
          3097,
          309,
          6772,
          281,
          536,
          498,
          300,
          1985,
          257,
          707,
          857,
          1101,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.1936456805369893,
        "compression_ratio": 1.7288732394366197,
        "end": 3905.22,
        "id": 1116,
        "no_speech_prob": 0.017176371067762375,
        "seek": 388722,
        "start": 3903.22,
        "temperature": 0,
        "text": " So how are we going to do that?",
        "tokens": [
          51164,
          407,
          577,
          366,
          321,
          516,
          281,
          360,
          300,
          30,
          51264
        ]
      },
      {
        "avg_logprob": -0.1936456805369893,
        "compression_ratio": 1.7288732394366197,
        "end": 3907.22,
        "id": 1117,
        "no_speech_prob": 0.017176371067762375,
        "seek": 388722,
        "start": 3905.22,
        "temperature": 0,
        "text": " So let me go back to the code.",
        "tokens": [
          51264,
          407,
          718,
          385,
          352,
          646,
          281,
          264,
          3089,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.1936456805369893,
        "compression_ratio": 1.7288732394366197,
        "end": 3910.22,
        "id": 1118,
        "no_speech_prob": 0.017176371067762375,
        "seek": 388722,
        "start": 3907.22,
        "temperature": 0,
        "text": " Remember this nice little bit of code I had here?",
        "tokens": [
          51364,
          5459,
          341,
          1481,
          707,
          857,
          295,
          3089,
          286,
          632,
          510,
          30,
          51514
        ]
      },
      {
        "avg_logprob": -0.1936456805369893,
        "compression_ratio": 1.7288732394366197,
        "end": 3914.22,
        "id": 1119,
        "no_speech_prob": 0.017176371067762375,
        "seek": 388722,
        "start": 3910.22,
        "temperature": 0,
        "text": " Why not, let's train it to actually learn a certain threshold.",
        "tokens": [
          51514,
          1545,
          406,
          11,
          718,
          311,
          3847,
          309,
          281,
          767,
          1466,
          257,
          1629,
          14678,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.20409605719826437,
        "compression_ratio": 1.4947368421052631,
        "end": 3927.22,
        "id": 1120,
        "no_speech_prob": 0.015663467347621918,
        "seek": 391422,
        "start": 3915.22,
        "temperature": 0,
        "text": " So I'm going to write a function here called train color.",
        "tokens": [
          50414,
          407,
          286,
          478,
          516,
          281,
          2464,
          257,
          2445,
          510,
          1219,
          3847,
          2017,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.20409605719826437,
        "compression_ratio": 1.4947368421052631,
        "end": 3929.22,
        "id": 1121,
        "no_speech_prob": 0.015663467347621918,
        "seek": 391422,
        "start": 3927.22,
        "temperature": 0,
        "text": " And it gets an R, G, and B.",
        "tokens": [
          51014,
          400,
          309,
          2170,
          364,
          497,
          11,
          460,
          11,
          293,
          363,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.20409605719826437,
        "compression_ratio": 1.4947368421052631,
        "end": 3933.22,
        "id": 1122,
        "no_speech_prob": 0.015663467347621918,
        "seek": 391422,
        "start": 3929.22,
        "temperature": 0,
        "text": " And it's going to return black or white.",
        "tokens": [
          51114,
          400,
          309,
          311,
          516,
          281,
          2736,
          2211,
          420,
          2418,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.20409605719826437,
        "compression_ratio": 1.4947368421052631,
        "end": 3943.22,
        "id": 1123,
        "no_speech_prob": 0.015663467347621918,
        "seek": 391422,
        "start": 3933.22,
        "temperature": 0,
        "text": " And what I'm going to do now is in setup, this is a little bit silly, before I do anything, I'm just going to say for let i equal zero, i is less than 1,000.",
        "tokens": [
          51314,
          400,
          437,
          286,
          478,
          516,
          281,
          360,
          586,
          307,
          294,
          8657,
          11,
          341,
          307,
          257,
          707,
          857,
          11774,
          11,
          949,
          286,
          360,
          1340,
          11,
          286,
          478,
          445,
          516,
          281,
          584,
          337,
          718,
          741,
          2681,
          4018,
          11,
          741,
          307,
          1570,
          813,
          502,
          11,
          1360,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.347172807764124,
        "compression_ratio": 1.3012048192771084,
        "end": 3956.22,
        "id": 1124,
        "no_speech_prob": 0.04602941870689392,
        "seek": 394322,
        "start": 3944.22,
        "temperature": 0,
        "text": " i++ and I'm going to pick a different set of random colors that are different from the global random colors.",
        "tokens": [
          50414,
          741,
          25472,
          293,
          286,
          478,
          516,
          281,
          1888,
          257,
          819,
          992,
          295,
          4974,
          4577,
          300,
          366,
          819,
          490,
          264,
          4338,
          4974,
          4577,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.46124873161315916,
        "compression_ratio": 1,
        "end": 3971.22,
        "id": 1125,
        "no_speech_prob": 0.3450372517108917,
        "seek": 395622,
        "start": 3957.22,
        "temperature": 0,
        "text": " Then I'm going to say the correct answer or the answer, oh shoot.",
        "tokens": [
          50414,
          1396,
          286,
          478,
          516,
          281,
          584,
          264,
          3006,
          1867,
          420,
          264,
          1867,
          11,
          1954,
          3076,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.23132807991721413,
        "compression_ratio": 1.3421052631578947,
        "end": 3992.22,
        "id": 1126,
        "no_speech_prob": 0.02442122809588909,
        "seek": 397122,
        "start": 3971.22,
        "temperature": 0,
        "text": " I'm going to say the answer is, what is it, train color.",
        "tokens": [
          50364,
          286,
          478,
          516,
          281,
          584,
          264,
          1867,
          307,
          11,
          437,
          307,
          309,
          11,
          3847,
          2017,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.23132807991721413,
        "compression_ratio": 1.3421052631578947,
        "end": 3996.22,
        "id": 1127,
        "no_speech_prob": 0.02442122809588909,
        "seek": 397122,
        "start": 3992.22,
        "temperature": 0,
        "text": " Train color with R, G, B.",
        "tokens": [
          51414,
          28029,
          2017,
          365,
          497,
          11,
          460,
          11,
          363,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.23132807991721413,
        "compression_ratio": 1.3421052631578947,
        "end": 3998.22,
        "id": 1128,
        "no_speech_prob": 0.02442122809588909,
        "seek": 397122,
        "start": 3996.22,
        "temperature": 0,
        "text": " And you know what I'm going to do?",
        "tokens": [
          51614,
          400,
          291,
          458,
          437,
          286,
          478,
          516,
          281,
          360,
          30,
          51714
        ]
      },
      {
        "avg_logprob": -0.23132807991721413,
        "compression_ratio": 1.3421052631578947,
        "end": 4000.22,
        "id": 1129,
        "no_speech_prob": 0.02442122809588909,
        "seek": 397122,
        "start": 3998.22,
        "temperature": 0,
        "text": " I'm just going to do this, targets.",
        "tokens": [
          51714,
          286,
          478,
          445,
          516,
          281,
          360,
          341,
          11,
          12911,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.19002243257918447,
        "compression_ratio": 1.6431924882629108,
        "end": 4003.22,
        "id": 1130,
        "no_speech_prob": 0.1460718810558319,
        "seek": 400022,
        "start": 4000.22,
        "temperature": 0,
        "text": " Let's skip a step here.",
        "tokens": [
          50364,
          961,
          311,
          10023,
          257,
          1823,
          510,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.19002243257918447,
        "compression_ratio": 1.6431924882629108,
        "end": 4006.22,
        "id": 1131,
        "no_speech_prob": 0.1460718810558319,
        "seek": 400022,
        "start": 4003.22,
        "temperature": 0,
        "text": " And this, I can't remember which is which.",
        "tokens": [
          50514,
          400,
          341,
          11,
          286,
          393,
          380,
          1604,
          597,
          307,
          597,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.19002243257918447,
        "compression_ratio": 1.6431924882629108,
        "end": 4007.22,
        "id": 1132,
        "no_speech_prob": 0.1460718810558319,
        "seek": 400022,
        "start": 4006.22,
        "temperature": 0,
        "text": " Whoops.",
        "tokens": [
          50664,
          45263,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.19002243257918447,
        "compression_ratio": 1.6431924882629108,
        "end": 4009.22,
        "id": 1133,
        "no_speech_prob": 0.1460718810558319,
        "seek": 400022,
        "start": 4007.22,
        "temperature": 0,
        "text": " Let's just return the targets.",
        "tokens": [
          50714,
          961,
          311,
          445,
          2736,
          264,
          12911,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.19002243257918447,
        "compression_ratio": 1.6431924882629108,
        "end": 4010.22,
        "id": 1134,
        "no_speech_prob": 0.1460718810558319,
        "seek": 400022,
        "start": 4009.22,
        "temperature": 0,
        "text": " Is this right?",
        "tokens": [
          50814,
          1119,
          341,
          558,
          30,
          50864
        ]
      },
      {
        "avg_logprob": -0.19002243257918447,
        "compression_ratio": 1.6431924882629108,
        "end": 4013.22,
        "id": 1135,
        "no_speech_prob": 0.1460718810558319,
        "seek": 400022,
        "start": 4010.22,
        "temperature": 0,
        "text": " Somebody in the chat tell me if I've got these backwards or not.",
        "tokens": [
          50864,
          13463,
          294,
          264,
          5081,
          980,
          385,
          498,
          286,
          600,
          658,
          613,
          12204,
          420,
          406,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.19002243257918447,
        "compression_ratio": 1.6431924882629108,
        "end": 4015.22,
        "id": 1136,
        "no_speech_prob": 0.1460718810558319,
        "seek": 400022,
        "start": 4013.22,
        "temperature": 0,
        "text": " Let's just return the targets.",
        "tokens": [
          51014,
          961,
          311,
          445,
          2736,
          264,
          12911,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.19002243257918447,
        "compression_ratio": 1.6431924882629108,
        "end": 4017.22,
        "id": 1137,
        "no_speech_prob": 0.1460718810558319,
        "seek": 400022,
        "start": 4015.22,
        "temperature": 0,
        "text": " I'm kind of skipping some steps here.",
        "tokens": [
          51114,
          286,
          478,
          733,
          295,
          31533,
          512,
          4439,
          510,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.19002243257918447,
        "compression_ratio": 1.6431924882629108,
        "end": 4019.22,
        "id": 1138,
        "no_speech_prob": 0.1460718810558319,
        "seek": 400022,
        "start": 4017.22,
        "temperature": 0,
        "text": " Now I'm not being as thoughtful about how I'm organizing this.",
        "tokens": [
          51214,
          823,
          286,
          478,
          406,
          885,
          382,
          21566,
          466,
          577,
          286,
          478,
          17608,
          341,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.19002243257918447,
        "compression_ratio": 1.6431924882629108,
        "end": 4021.22,
        "id": 1139,
        "no_speech_prob": 0.1460718810558319,
        "seek": 400022,
        "start": 4019.22,
        "temperature": 0,
        "text": " But I want to get those targets.",
        "tokens": [
          51314,
          583,
          286,
          528,
          281,
          483,
          729,
          12911,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.1961629367569118,
        "compression_ratio": 1.6422413793103448,
        "end": 4030.22,
        "id": 1140,
        "no_speech_prob": 0.4300821125507355,
        "seek": 402122,
        "start": 4022.22,
        "temperature": 0,
        "text": " Then I want to say the inputs are R divided by 255 G, G divided by 255 B divided by 255.",
        "tokens": [
          50414,
          1396,
          286,
          528,
          281,
          584,
          264,
          15743,
          366,
          497,
          6666,
          538,
          3552,
          20,
          460,
          11,
          460,
          6666,
          538,
          3552,
          20,
          363,
          6666,
          538,
          3552,
          20,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.1961629367569118,
        "compression_ratio": 1.6422413793103448,
        "end": 4033.22,
        "id": 1141,
        "no_speech_prob": 0.4300821125507355,
        "seek": 402122,
        "start": 4030.22,
        "temperature": 0,
        "text": " And this should say inputs.",
        "tokens": [
          50814,
          400,
          341,
          820,
          584,
          15743,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.1961629367569118,
        "compression_ratio": 1.6422413793103448,
        "end": 4038.22,
        "id": 1142,
        "no_speech_prob": 0.4300821125507355,
        "seek": 402122,
        "start": 4033.22,
        "temperature": 0,
        "text": " And then I'm going to say brain train inputs with these targets.",
        "tokens": [
          50964,
          400,
          550,
          286,
          478,
          516,
          281,
          584,
          3567,
          3847,
          15743,
          365,
          613,
          12911,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.1961629367569118,
        "compression_ratio": 1.6422413793103448,
        "end": 4044.22,
        "id": 1143,
        "no_speech_prob": 0.4300821125507355,
        "seek": 402122,
        "start": 4038.22,
        "temperature": 0,
        "text": " So this is me just running through and kind of quickly using 1,000 colors to train it.",
        "tokens": [
          51214,
          407,
          341,
          307,
          385,
          445,
          2614,
          807,
          293,
          733,
          295,
          2661,
          1228,
          502,
          11,
          1360,
          4577,
          281,
          3847,
          309,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.1961629367569118,
        "compression_ratio": 1.6422413793103448,
        "end": 4047.22,
        "id": 1144,
        "no_speech_prob": 0.4300821125507355,
        "seek": 402122,
        "start": 4044.22,
        "temperature": 0,
        "text": " And I'm being told that this is probably backwards.",
        "tokens": [
          51514,
          400,
          286,
          478,
          885,
          1907,
          300,
          341,
          307,
          1391,
          12204,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.1961629367569118,
        "compression_ratio": 1.6422413793103448,
        "end": 4050.22,
        "id": 1145,
        "no_speech_prob": 0.4300821125507355,
        "seek": 402122,
        "start": 4047.22,
        "temperature": 0,
        "text": " There's no way I could have possibly guessed that correctly.",
        "tokens": [
          51664,
          821,
          311,
          572,
          636,
          286,
          727,
          362,
          6264,
          21852,
          300,
          8944,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.2418162993022374,
        "compression_ratio": 1.7981220657276995,
        "end": 4051.22,
        "id": 1146,
        "no_speech_prob": 0.0001852249406510964,
        "seek": 405022,
        "start": 4050.22,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          50364,
          1033,
          13,
          50414
        ]
      },
      {
        "avg_logprob": -0.2418162993022374,
        "compression_ratio": 1.7981220657276995,
        "end": 4055.22,
        "id": 1147,
        "no_speech_prob": 0.0001852249406510964,
        "seek": 405022,
        "start": 4051.22,
        "temperature": 0,
        "text": " So let's ‑‑ and actually I'm going to even ‑‑ I'm just going to ‑‑ let's let it run 10,000 times.",
        "tokens": [
          50414,
          407,
          718,
          311,
          220,
          27392,
          27392,
          293,
          767,
          286,
          478,
          516,
          281,
          754,
          45217,
          286,
          478,
          445,
          516,
          281,
          45217,
          718,
          311,
          718,
          309,
          1190,
          1266,
          11,
          1360,
          1413,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.2418162993022374,
        "compression_ratio": 1.7981220657276995,
        "end": 4062.22,
        "id": 1148,
        "no_speech_prob": 0.0001852249406510964,
        "seek": 405022,
        "start": 4055.22,
        "temperature": 0,
        "text": " So I'm going to run 10,000 colors through the network right in setup as like training data basically.",
        "tokens": [
          50614,
          407,
          286,
          478,
          516,
          281,
          1190,
          1266,
          11,
          1360,
          4577,
          807,
          264,
          3209,
          558,
          294,
          8657,
          382,
          411,
          3097,
          1412,
          1936,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.2418162993022374,
        "compression_ratio": 1.7981220657276995,
        "end": 4064.22,
        "id": 1149,
        "no_speech_prob": 0.0001852249406510964,
        "seek": 405022,
        "start": 4062.22,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          50964,
          1033,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.2418162993022374,
        "compression_ratio": 1.7981220657276995,
        "end": 4071.22,
        "id": 1150,
        "no_speech_prob": 0.0001852249406510964,
        "seek": 405022,
        "start": 4064.22,
        "temperature": 0,
        "text": " So now let's just ‑‑ and actually in a way what I'm going to do now, just to see, I'm not even going to click.",
        "tokens": [
          51064,
          407,
          586,
          718,
          311,
          445,
          45217,
          293,
          767,
          294,
          257,
          636,
          437,
          286,
          478,
          516,
          281,
          360,
          586,
          11,
          445,
          281,
          536,
          11,
          286,
          478,
          406,
          754,
          516,
          281,
          2052,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.2418162993022374,
        "compression_ratio": 1.7981220657276995,
        "end": 4075.22,
        "id": 1151,
        "no_speech_prob": 0.0001852249406510964,
        "seek": 405022,
        "start": 4071.22,
        "temperature": 0,
        "text": " I'm going to not bother to train it anymore.",
        "tokens": [
          51414,
          286,
          478,
          516,
          281,
          406,
          8677,
          281,
          3847,
          309,
          3602,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.18025999670630102,
        "compression_ratio": 1.5461538461538462,
        "end": 4080.22,
        "id": 1152,
        "no_speech_prob": 0.001957000931724906,
        "seek": 407522,
        "start": 4075.22,
        "temperature": 0,
        "text": " I'm just going to pick ‑‑ let me comment out my own interactive training.",
        "tokens": [
          50364,
          286,
          478,
          445,
          516,
          281,
          1888,
          45217,
          718,
          385,
          2871,
          484,
          452,
          1065,
          15141,
          3097,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.18025999670630102,
        "compression_ratio": 1.5461538461538462,
        "end": 4082.22,
        "id": 1153,
        "no_speech_prob": 0.001957000931724906,
        "seek": 407522,
        "start": 4080.22,
        "temperature": 0,
        "text": " And let me just pick new colors.",
        "tokens": [
          50614,
          400,
          718,
          385,
          445,
          1888,
          777,
          4577,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.18025999670630102,
        "compression_ratio": 1.5461538461538462,
        "end": 4084.22,
        "id": 1154,
        "no_speech_prob": 0.001957000931724906,
        "seek": 407522,
        "start": 4082.22,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          50714,
          1033,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.18025999670630102,
        "compression_ratio": 1.5461538461538462,
        "end": 4088.22,
        "id": 1155,
        "no_speech_prob": 0.001957000931724906,
        "seek": 407522,
        "start": 4084.22,
        "temperature": 0,
        "text": " So every time I click, yeah, you can see it's making guesses.",
        "tokens": [
          50814,
          407,
          633,
          565,
          286,
          2052,
          11,
          1338,
          11,
          291,
          393,
          536,
          309,
          311,
          1455,
          42703,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.18025999670630102,
        "compression_ratio": 1.5461538461538462,
        "end": 4089.22,
        "id": 1156,
        "no_speech_prob": 0.001957000931724906,
        "seek": 407522,
        "start": 4088.22,
        "temperature": 0,
        "text": " Are they good guesses?",
        "tokens": [
          51014,
          2014,
          436,
          665,
          42703,
          30,
          51064
        ]
      },
      {
        "avg_logprob": -0.18025999670630102,
        "compression_ratio": 1.5461538461538462,
        "end": 4090.22,
        "id": 1157,
        "no_speech_prob": 0.001957000931724906,
        "seek": 407522,
        "start": 4089.22,
        "temperature": 0,
        "text": " I don't know.",
        "tokens": [
          51064,
          286,
          500,
          380,
          458,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.18025999670630102,
        "compression_ratio": 1.5461538461538462,
        "end": 4096.219999999999,
        "id": 1158,
        "no_speech_prob": 0.001957000931724906,
        "seek": 407522,
        "start": 4090.22,
        "temperature": 0,
        "text": " But I bet you those guesses are pretty accurately aligned with that threshold of 300.",
        "tokens": [
          51114,
          583,
          286,
          778,
          291,
          729,
          42703,
          366,
          1238,
          20095,
          17962,
          365,
          300,
          14678,
          295,
          6641,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.18025999670630102,
        "compression_ratio": 1.5461538461538462,
        "end": 4098.219999999999,
        "id": 1159,
        "no_speech_prob": 0.001957000931724906,
        "seek": 407522,
        "start": 4096.219999999999,
        "temperature": 0,
        "text": " So I could continue to train it a little bit.",
        "tokens": [
          51414,
          407,
          286,
          727,
          2354,
          281,
          3847,
          309,
          257,
          707,
          857,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.18025999670630102,
        "compression_ratio": 1.5461538461538462,
        "end": 4103.219999999999,
        "id": 1160,
        "no_speech_prob": 0.001957000931724906,
        "seek": 407522,
        "start": 4098.219999999999,
        "temperature": 0,
        "text": " But I feel pretty happy now with this color predictor.",
        "tokens": [
          51514,
          583,
          286,
          841,
          1238,
          2055,
          586,
          365,
          341,
          2017,
          6069,
          284,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.173354456247377,
        "compression_ratio": 1.5601374570446735,
        "end": 4104.22,
        "id": 1161,
        "no_speech_prob": 0.013222676701843739,
        "seek": 410322,
        "start": 4103.22,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          50364,
          1033,
          13,
          50414
        ]
      },
      {
        "avg_logprob": -0.173354456247377,
        "compression_ratio": 1.5601374570446735,
        "end": 4106.22,
        "id": 1162,
        "no_speech_prob": 0.013222676701843739,
        "seek": 410322,
        "start": 4104.22,
        "temperature": 0,
        "text": " What's going on?",
        "tokens": [
          50414,
          708,
          311,
          516,
          322,
          30,
          50514
        ]
      },
      {
        "avg_logprob": -0.173354456247377,
        "compression_ratio": 1.5601374570446735,
        "end": 4108.22,
        "id": 1163,
        "no_speech_prob": 0.013222676701843739,
        "seek": 410322,
        "start": 4106.22,
        "temperature": 0,
        "text": " I finished this coding challenge.",
        "tokens": [
          50514,
          286,
          4335,
          341,
          17720,
          3430,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.173354456247377,
        "compression_ratio": 1.5601374570446735,
        "end": 4110.22,
        "id": 1164,
        "no_speech_prob": 0.013222676701843739,
        "seek": 410322,
        "start": 4108.22,
        "temperature": 0,
        "text": " I'm going to release this code.",
        "tokens": [
          50614,
          286,
          478,
          516,
          281,
          4374,
          341,
          3089,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.173354456247377,
        "compression_ratio": 1.5601374570446735,
        "end": 4111.22,
        "id": 1165,
        "no_speech_prob": 0.013222676701843739,
        "seek": 410322,
        "start": 4110.22,
        "temperature": 0,
        "text": " What can you do with it?",
        "tokens": [
          50714,
          708,
          393,
          291,
          360,
          365,
          309,
          30,
          50764
        ]
      },
      {
        "avg_logprob": -0.173354456247377,
        "compression_ratio": 1.5601374570446735,
        "end": 4112.22,
        "id": 1166,
        "no_speech_prob": 0.013222676701843739,
        "seek": 410322,
        "start": 4111.22,
        "temperature": 0,
        "text": " So a couple things.",
        "tokens": [
          50764,
          407,
          257,
          1916,
          721,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.173354456247377,
        "compression_ratio": 1.5601374570446735,
        "end": 4120.22,
        "id": 1167,
        "no_speech_prob": 0.013222676701843739,
        "seek": 410322,
        "start": 4112.22,
        "temperature": 0,
        "text": " One is could you make this same exact project, but instead of having it just pick whether black or white goes on top,",
        "tokens": [
          50814,
          1485,
          307,
          727,
          291,
          652,
          341,
          912,
          1900,
          1716,
          11,
          457,
          2602,
          295,
          1419,
          309,
          445,
          1888,
          1968,
          2211,
          420,
          2418,
          1709,
          322,
          1192,
          11,
          51214
        ]
      },
      {
        "avg_logprob": -0.173354456247377,
        "compression_ratio": 1.5601374570446735,
        "end": 4123.22,
        "id": 1168,
        "no_speech_prob": 0.013222676701843739,
        "seek": 410322,
        "start": 4120.22,
        "temperature": 0,
        "text": " could you pick a RGB color that looks nice?",
        "tokens": [
          51214,
          727,
          291,
          1888,
          257,
          31231,
          2017,
          300,
          1542,
          1481,
          30,
          51364
        ]
      },
      {
        "avg_logprob": -0.173354456247377,
        "compression_ratio": 1.5601374570446735,
        "end": 4129.22,
        "id": 1169,
        "no_speech_prob": 0.013222676701843739,
        "seek": 410322,
        "start": 4123.22,
        "temperature": 0,
        "text": " Maybe it's a ‑‑ maybe you could have a neural network solve the formula for complementary colors.",
        "tokens": [
          51364,
          2704,
          309,
          311,
          257,
          45217,
          1310,
          291,
          727,
          362,
          257,
          18161,
          3209,
          5039,
          264,
          8513,
          337,
          40705,
          4577,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.173354456247377,
        "compression_ratio": 1.5601374570446735,
        "end": 4132.22,
        "id": 1170,
        "no_speech_prob": 0.013222676701843739,
        "seek": 410322,
        "start": 4129.22,
        "temperature": 0,
        "text": " Could you think of a more thoughtful way to design this?",
        "tokens": [
          51664,
          7497,
          291,
          519,
          295,
          257,
          544,
          21566,
          636,
          281,
          1715,
          341,
          30,
          51814
        ]
      },
      {
        "avg_logprob": -0.18787478612474173,
        "compression_ratio": 1.7311827956989247,
        "end": 4134.22,
        "id": 1171,
        "no_speech_prob": 0.031616002321243286,
        "seek": 413222,
        "start": 4132.22,
        "temperature": 0,
        "text": " Could you use some other data entirely?",
        "tokens": [
          50364,
          7497,
          291,
          764,
          512,
          661,
          1412,
          7696,
          30,
          50464
        ]
      },
      {
        "avg_logprob": -0.18787478612474173,
        "compression_ratio": 1.7311827956989247,
        "end": 4138.22,
        "id": 1172,
        "no_speech_prob": 0.031616002321243286,
        "seek": 413222,
        "start": 4134.22,
        "temperature": 0,
        "text": " Could you train based on, like, font, which font to pick?",
        "tokens": [
          50464,
          7497,
          291,
          3847,
          2361,
          322,
          11,
          411,
          11,
          10703,
          11,
          597,
          10703,
          281,
          1888,
          30,
          50664
        ]
      },
      {
        "avg_logprob": -0.18787478612474173,
        "compression_ratio": 1.7311827956989247,
        "end": 4146.22,
        "id": 1173,
        "no_speech_prob": 0.031616002321243286,
        "seek": 413222,
        "start": 4138.22,
        "temperature": 0,
        "text": " Could you train a system to make design decisions based on some set of training data or some user interaction, something like that?",
        "tokens": [
          50664,
          7497,
          291,
          3847,
          257,
          1185,
          281,
          652,
          1715,
          5327,
          2361,
          322,
          512,
          992,
          295,
          3097,
          1412,
          420,
          512,
          4195,
          9285,
          11,
          746,
          411,
          300,
          30,
          51064
        ]
      },
      {
        "avg_logprob": -0.18787478612474173,
        "compression_ratio": 1.7311827956989247,
        "end": 4153.22,
        "id": 1174,
        "no_speech_prob": 0.031616002321243286,
        "seek": 413222,
        "start": 4146.22,
        "temperature": 0,
        "text": " So I hope you make your own neural network design predictor thingy and share it with me.",
        "tokens": [
          51064,
          407,
          286,
          1454,
          291,
          652,
          428,
          1065,
          18161,
          3209,
          1715,
          6069,
          284,
          551,
          88,
          293,
          2073,
          309,
          365,
          385,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.18787478612474173,
        "compression_ratio": 1.7311827956989247,
        "end": 4155.22,
        "id": 1175,
        "no_speech_prob": 0.031616002321243286,
        "seek": 413222,
        "start": 4153.22,
        "temperature": 0,
        "text": " You can go to the CodingTrain.com website.",
        "tokens": [
          51414,
          509,
          393,
          352,
          281,
          264,
          383,
          8616,
          51,
          7146,
          13,
          1112,
          3144,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.18787478612474173,
        "compression_ratio": 1.7311827956989247,
        "end": 4160.22,
        "id": 1176,
        "no_speech_prob": 0.031616002321243286,
        "seek": 413222,
        "start": 4155.22,
        "temperature": 0,
        "text": " There's some instructions there for how to contribute your version of a project like this.",
        "tokens": [
          51514,
          821,
          311,
          512,
          9415,
          456,
          337,
          577,
          281,
          10586,
          428,
          3037,
          295,
          257,
          1716,
          411,
          341,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.18787478612474173,
        "compression_ratio": 1.7311827956989247,
        "end": 4161.22,
        "id": 1177,
        "no_speech_prob": 0.031616002321243286,
        "seek": 413222,
        "start": 4160.22,
        "temperature": 0,
        "text": " You can write in the comments.",
        "tokens": [
          51764,
          509,
          393,
          2464,
          294,
          264,
          3053,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.16061082253089318,
        "compression_ratio": 1.7065217391304348,
        "end": 4163.22,
        "id": 1178,
        "no_speech_prob": 0.0384618304669857,
        "seek": 416122,
        "start": 4161.22,
        "temperature": 0,
        "text": " You can tweet me at Schiffman.",
        "tokens": [
          50364,
          509,
          393,
          15258,
          385,
          412,
          2065,
          3661,
          1601,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.16061082253089318,
        "compression_ratio": 1.7065217391304348,
        "end": 4167.22,
        "id": 1179,
        "no_speech_prob": 0.0384618304669857,
        "seek": 416122,
        "start": 4163.22,
        "temperature": 0,
        "text": " I guess I'm supposed to say you should subscribe to the channel, blah, blah, blah, blah, blah.",
        "tokens": [
          50464,
          286,
          2041,
          286,
          478,
          3442,
          281,
          584,
          291,
          820,
          3022,
          281,
          264,
          2269,
          11,
          12288,
          11,
          12288,
          11,
          12288,
          11,
          12288,
          11,
          12288,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.16061082253089318,
        "compression_ratio": 1.7065217391304348,
        "end": 4168.22,
        "id": 1180,
        "no_speech_prob": 0.0384618304669857,
        "seek": 416122,
        "start": 4167.22,
        "temperature": 0,
        "text": " Thank you for tuning in.",
        "tokens": [
          50664,
          1044,
          291,
          337,
          15164,
          294,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.16061082253089318,
        "compression_ratio": 1.7065217391304348,
        "end": 4173.22,
        "id": 1181,
        "no_speech_prob": 0.0384618304669857,
        "seek": 416122,
        "start": 4168.22,
        "temperature": 0,
        "text": " And there is the color predictor.",
        "tokens": [
          50714,
          400,
          456,
          307,
          264,
          2017,
          6069,
          284,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.16061082253089318,
        "compression_ratio": 1.7065217391304348,
        "end": 4174.22,
        "id": 1182,
        "no_speech_prob": 0.0384618304669857,
        "seek": 416122,
        "start": 4173.22,
        "temperature": 0,
        "text": " Wait, hold on.",
        "tokens": [
          50964,
          3802,
          11,
          1797,
          322,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.16061082253089318,
        "compression_ratio": 1.7065217391304348,
        "end": 4175.22,
        "id": 1183,
        "no_speech_prob": 0.0384618304669857,
        "seek": 416122,
        "start": 4174.22,
        "temperature": 0,
        "text": " Stop.",
        "tokens": [
          51014,
          5535,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.16061082253089318,
        "compression_ratio": 1.7065217391304348,
        "end": 4176.22,
        "id": 1184,
        "no_speech_prob": 0.0384618304669857,
        "seek": 416122,
        "start": 4175.22,
        "temperature": 0,
        "text": " Time out.",
        "tokens": [
          51064,
          6161,
          484,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.16061082253089318,
        "compression_ratio": 1.7065217391304348,
        "end": 4178.22,
        "id": 1185,
        "no_speech_prob": 0.0384618304669857,
        "seek": 416122,
        "start": 4176.22,
        "temperature": 0,
        "text": " I'm getting a good suggestion in the chat.",
        "tokens": [
          51114,
          286,
          478,
          1242,
          257,
          665,
          16541,
          294,
          264,
          5081,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.16061082253089318,
        "compression_ratio": 1.7065217391304348,
        "end": 4181.22,
        "id": 1186,
        "no_speech_prob": 0.0384618304669857,
        "seek": 416122,
        "start": 4178.22,
        "temperature": 0,
        "text": " It might be nice to see, like, what the number is.",
        "tokens": [
          51214,
          467,
          1062,
          312,
          1481,
          281,
          536,
          11,
          411,
          11,
          437,
          264,
          1230,
          307,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.16061082253089318,
        "compression_ratio": 1.7065217391304348,
        "end": 4182.22,
        "id": 1187,
        "no_speech_prob": 0.0384618304669857,
        "seek": 416122,
        "start": 4181.22,
        "temperature": 0,
        "text": " So hold on.",
        "tokens": [
          51364,
          407,
          1797,
          322,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.16061082253089318,
        "compression_ratio": 1.7065217391304348,
        "end": 4184.22,
        "id": 1188,
        "no_speech_prob": 0.0384618304669857,
        "seek": 416122,
        "start": 4182.22,
        "temperature": 0,
        "text": " Let's ‑‑ this is a good idea.",
        "tokens": [
          51414,
          961,
          311,
          45217,
          341,
          307,
          257,
          665,
          1558,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.16061082253089318,
        "compression_ratio": 1.7065217391304348,
        "end": 4185.22,
        "id": 1189,
        "no_speech_prob": 0.0384618304669857,
        "seek": 416122,
        "start": 4184.22,
        "temperature": 0,
        "text": " Let's do this.",
        "tokens": [
          51514,
          961,
          311,
          360,
          341,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.16061082253089318,
        "compression_ratio": 1.7065217391304348,
        "end": 4186.22,
        "id": 1190,
        "no_speech_prob": 0.0384618304669857,
        "seek": 416122,
        "start": 4185.22,
        "temperature": 0,
        "text": " Hold on, hold on.",
        "tokens": [
          51564,
          6962,
          322,
          11,
          1797,
          322,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.16061082253089318,
        "compression_ratio": 1.7065217391304348,
        "end": 4187.22,
        "id": 1191,
        "no_speech_prob": 0.0384618304669857,
        "seek": 416122,
        "start": 4186.22,
        "temperature": 0,
        "text": " Time out, everybody.",
        "tokens": [
          51614,
          6161,
          484,
          11,
          2201,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.16061082253089318,
        "compression_ratio": 1.7065217391304348,
        "end": 4190.22,
        "id": 1192,
        "no_speech_prob": 0.0384618304669857,
        "seek": 416122,
        "start": 4187.22,
        "temperature": 0,
        "text": " Where do I have ‑‑ I have some console log going on here.",
        "tokens": [
          51664,
          2305,
          360,
          286,
          362,
          45217,
          286,
          362,
          512,
          11076,
          3565,
          516,
          322,
          510,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.14887443243288526,
        "compression_ratio": 1.5308056872037914,
        "end": 4192.22,
        "id": 1193,
        "no_speech_prob": 0.001345846918411553,
        "seek": 419022,
        "start": 4190.22,
        "temperature": 0,
        "text": " Let me get rid of this console log.",
        "tokens": [
          50364,
          961,
          385,
          483,
          3973,
          295,
          341,
          11076,
          3565,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.14887443243288526,
        "compression_ratio": 1.5308056872037914,
        "end": 4201.22,
        "id": 1194,
        "no_speech_prob": 0.001345846918411553,
        "seek": 419022,
        "start": 4192.22,
        "temperature": 0,
        "text": " And let me in here, let's console log R plus G plus B.",
        "tokens": [
          50464,
          400,
          718,
          385,
          294,
          510,
          11,
          718,
          311,
          11076,
          3565,
          497,
          1804,
          460,
          1804,
          363,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.14887443243288526,
        "compression_ratio": 1.5308056872037914,
        "end": 4204.22,
        "id": 1195,
        "no_speech_prob": 0.001345846918411553,
        "seek": 419022,
        "start": 4201.22,
        "temperature": 0,
        "text": " So let's see if this value is bigger.",
        "tokens": [
          50914,
          407,
          718,
          311,
          536,
          498,
          341,
          2158,
          307,
          3801,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.14887443243288526,
        "compression_ratio": 1.5308056872037914,
        "end": 4209.22,
        "id": 1196,
        "no_speech_prob": 0.001345846918411553,
        "seek": 419022,
        "start": 4204.22,
        "temperature": 0,
        "text": " And I'm just going to floor it so it looks ‑‑ I don't need to see the decimal.",
        "tokens": [
          51064,
          400,
          286,
          478,
          445,
          516,
          281,
          4123,
          309,
          370,
          309,
          1542,
          45217,
          286,
          500,
          380,
          643,
          281,
          536,
          264,
          26601,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.14887443243288526,
        "compression_ratio": 1.5308056872037914,
        "end": 4216.22,
        "id": 1197,
        "no_speech_prob": 0.001345846918411553,
        "seek": 419022,
        "start": 4209.22,
        "temperature": 0,
        "text": " Let's see if this ‑‑ let's see if it really learned the threshold of 300.",
        "tokens": [
          51314,
          961,
          311,
          536,
          498,
          341,
          45217,
          718,
          311,
          536,
          498,
          309,
          534,
          3264,
          264,
          14678,
          295,
          6641,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.14887443243288526,
        "compression_ratio": 1.5308056872037914,
        "end": 4217.22,
        "id": 1198,
        "no_speech_prob": 0.001345846918411553,
        "seek": 419022,
        "start": 4216.22,
        "temperature": 0,
        "text": " Right?",
        "tokens": [
          51664,
          1779,
          30,
          51714
        ]
      },
      {
        "avg_logprob": -0.14887443243288526,
        "compression_ratio": 1.5308056872037914,
        "end": 4218.22,
        "id": 1199,
        "no_speech_prob": 0.001345846918411553,
        "seek": 419022,
        "start": 4217.22,
        "temperature": 0,
        "text": " 319.",
        "tokens": [
          51714,
          805,
          3405,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.14887443243288526,
        "compression_ratio": 1.5308056872037914,
        "end": 4219.22,
        "id": 1200,
        "no_speech_prob": 0.001345846918411553,
        "seek": 419022,
        "start": 4218.22,
        "temperature": 0,
        "text": " That should be white.",
        "tokens": [
          51764,
          663,
          820,
          312,
          2418,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.137878127720045,
        "compression_ratio": 1.5931372549019607,
        "end": 4220.22,
        "id": 1201,
        "no_speech_prob": 0.01016938779503107,
        "seek": 421922,
        "start": 4219.22,
        "temperature": 0,
        "text": " So it didn't get that right.",
        "tokens": [
          50364,
          407,
          309,
          994,
          380,
          483,
          300,
          558,
          13,
          50414
        ]
      },
      {
        "avg_logprob": -0.137878127720045,
        "compression_ratio": 1.5931372549019607,
        "end": 4221.22,
        "id": 1202,
        "no_speech_prob": 0.01016938779503107,
        "seek": 421922,
        "start": 4220.22,
        "temperature": 0,
        "text": " Whoops.",
        "tokens": [
          50414,
          45263,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.137878127720045,
        "compression_ratio": 1.5931372549019607,
        "end": 4222.22,
        "id": 1203,
        "no_speech_prob": 0.01016938779503107,
        "seek": 421922,
        "start": 4221.22,
        "temperature": 0,
        "text": " 376.",
        "tokens": [
          50464,
          13435,
          21,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.137878127720045,
        "compression_ratio": 1.5931372549019607,
        "end": 4223.22,
        "id": 1204,
        "no_speech_prob": 0.01016938779503107,
        "seek": 421922,
        "start": 4222.22,
        "temperature": 0,
        "text": " Ah.",
        "tokens": [
          50514,
          2438,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.137878127720045,
        "compression_ratio": 1.5931372549019607,
        "end": 4224.22,
        "id": 1205,
        "no_speech_prob": 0.01016938779503107,
        "seek": 421922,
        "start": 4223.22,
        "temperature": 0,
        "text": " 442.",
        "tokens": [
          50564,
          1017,
          15628,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.137878127720045,
        "compression_ratio": 1.5931372549019607,
        "end": 4225.22,
        "id": 1206,
        "no_speech_prob": 0.01016938779503107,
        "seek": 421922,
        "start": 4224.22,
        "temperature": 0,
        "text": " 289.",
        "tokens": [
          50614,
          7562,
          24,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.137878127720045,
        "compression_ratio": 1.5931372549019607,
        "end": 4226.22,
        "id": 1207,
        "no_speech_prob": 0.01016938779503107,
        "seek": 421922,
        "start": 4225.22,
        "temperature": 0,
        "text": " Oh, wait.",
        "tokens": [
          50664,
          876,
          11,
          1699,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.137878127720045,
        "compression_ratio": 1.5931372549019607,
        "end": 4227.22,
        "id": 1208,
        "no_speech_prob": 0.01016938779503107,
        "seek": 421922,
        "start": 4226.22,
        "temperature": 0,
        "text": " No, no, no.",
        "tokens": [
          50714,
          883,
          11,
          572,
          11,
          572,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.137878127720045,
        "compression_ratio": 1.5931372549019607,
        "end": 4228.22,
        "id": 1209,
        "no_speech_prob": 0.01016938779503107,
        "seek": 421922,
        "start": 4227.22,
        "temperature": 0,
        "text": " It did get it right.",
        "tokens": [
          50764,
          467,
          630,
          483,
          309,
          558,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.137878127720045,
        "compression_ratio": 1.5931372549019607,
        "end": 4229.22,
        "id": 1210,
        "no_speech_prob": 0.01016938779503107,
        "seek": 421922,
        "start": 4228.22,
        "temperature": 0,
        "text": " I've got it backwards.",
        "tokens": [
          50814,
          286,
          600,
          658,
          309,
          12204,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.137878127720045,
        "compression_ratio": 1.5931372549019607,
        "end": 4232.22,
        "id": 1211,
        "no_speech_prob": 0.01016938779503107,
        "seek": 421922,
        "start": 4229.22,
        "temperature": 0,
        "text": " If it's higher than 300, it should be over black.",
        "tokens": [
          50864,
          759,
          309,
          311,
          2946,
          813,
          6641,
          11,
          309,
          820,
          312,
          670,
          2211,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.137878127720045,
        "compression_ratio": 1.5931372549019607,
        "end": 4235.22,
        "id": 1212,
        "no_speech_prob": 0.01016938779503107,
        "seek": 421922,
        "start": 4232.22,
        "temperature": 0,
        "text": " If it's lower than 300, it should be over white.",
        "tokens": [
          51014,
          759,
          309,
          311,
          3126,
          813,
          6641,
          11,
          309,
          820,
          312,
          670,
          2418,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.137878127720045,
        "compression_ratio": 1.5931372549019607,
        "end": 4244.22,
        "id": 1213,
        "no_speech_prob": 0.01016938779503107,
        "seek": 421922,
        "start": 4235.22,
        "temperature": 0,
        "text": " And we can see here, right, 289, white, 431, black, 513, black, 561, black, 527.",
        "tokens": [
          51164,
          400,
          321,
          393,
          536,
          510,
          11,
          558,
          11,
          7562,
          24,
          11,
          2418,
          11,
          1017,
          12967,
          11,
          2211,
          11,
          1025,
          7668,
          11,
          2211,
          11,
          19687,
          16,
          11,
          2211,
          11,
          1025,
          10076,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.137878127720045,
        "compression_ratio": 1.5931372549019607,
        "end": 4245.22,
        "id": 1214,
        "no_speech_prob": 0.01016938779503107,
        "seek": 421922,
        "start": 4244.22,
        "temperature": 0,
        "text": " Right?",
        "tokens": [
          51614,
          1779,
          30,
          51664
        ]
      },
      {
        "avg_logprob": -0.137878127720045,
        "compression_ratio": 1.5931372549019607,
        "end": 4246.22,
        "id": 1215,
        "no_speech_prob": 0.01016938779503107,
        "seek": 421922,
        "start": 4245.22,
        "temperature": 0,
        "text": " This is working.",
        "tokens": [
          51664,
          639,
          307,
          1364,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.21979818036479334,
        "compression_ratio": 1.5338078291814947,
        "end": 4253.22,
        "id": 1216,
        "no_speech_prob": 0.4998895227909088,
        "seek": 424622,
        "start": 4246.22,
        "temperature": 0,
        "text": " So let me run it again with a different threshold.",
        "tokens": [
          50364,
          407,
          718,
          385,
          1190,
          309,
          797,
          365,
          257,
          819,
          14678,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.21979818036479334,
        "compression_ratio": 1.5338078291814947,
        "end": 4254.22,
        "id": 1217,
        "no_speech_prob": 0.4998895227909088,
        "seek": 424622,
        "start": 4253.22,
        "temperature": 0,
        "text": " Where do I add that?",
        "tokens": [
          50714,
          2305,
          360,
          286,
          909,
          300,
          30,
          50764
        ]
      },
      {
        "avg_logprob": -0.21979818036479334,
        "compression_ratio": 1.5338078291814947,
        "end": 4256.22,
        "id": 1218,
        "no_speech_prob": 0.4998895227909088,
        "seek": 424622,
        "start": 4254.22,
        "temperature": 0,
        "text": " In the training.",
        "tokens": [
          50764,
          682,
          264,
          3097,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.21979818036479334,
        "compression_ratio": 1.5338078291814947,
        "end": 4258.22,
        "id": 1219,
        "no_speech_prob": 0.4998895227909088,
        "seek": 424622,
        "start": 4256.22,
        "temperature": 0,
        "text": " Let me give it a silly threshold of 100.",
        "tokens": [
          50864,
          961,
          385,
          976,
          309,
          257,
          11774,
          14678,
          295,
          2319,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.21979818036479334,
        "compression_ratio": 1.5338078291814947,
        "end": 4262.22,
        "id": 1220,
        "no_speech_prob": 0.4998895227909088,
        "seek": 424622,
        "start": 4258.22,
        "temperature": 0,
        "text": " That's much too low for it to be visually correct, probably, whatever that means.",
        "tokens": [
          50964,
          663,
          311,
          709,
          886,
          2295,
          337,
          309,
          281,
          312,
          19622,
          3006,
          11,
          1391,
          11,
          2035,
          300,
          1355,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.21979818036479334,
        "compression_ratio": 1.5338078291814947,
        "end": 4268.22,
        "id": 1221,
        "no_speech_prob": 0.4998895227909088,
        "seek": 424622,
        "start": 4262.22,
        "temperature": 0,
        "text": " But we can see now it's going to only go to white if it's below 100.",
        "tokens": [
          51164,
          583,
          321,
          393,
          536,
          586,
          309,
          311,
          516,
          281,
          787,
          352,
          281,
          2418,
          498,
          309,
          311,
          2507,
          2319,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.21979818036479334,
        "compression_ratio": 1.5338078291814947,
        "end": 4271.22,
        "id": 1222,
        "no_speech_prob": 0.4998895227909088,
        "seek": 424622,
        "start": 4268.22,
        "temperature": 0,
        "text": " Oh, it didn't ‑‑ actually, 97, it didn't even get there.",
        "tokens": [
          51464,
          876,
          11,
          309,
          994,
          380,
          45217,
          767,
          11,
          23399,
          11,
          309,
          994,
          380,
          754,
          483,
          456,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.21979818036479334,
        "compression_ratio": 1.5338078291814947,
        "end": 4275.22,
        "id": 1223,
        "no_speech_prob": 0.4998895227909088,
        "seek": 424622,
        "start": 4271.22,
        "temperature": 0,
        "text": " Now, I'm going to have to do this for quite a while to get lucky enough to pick something",
        "tokens": [
          51614,
          823,
          11,
          286,
          478,
          516,
          281,
          362,
          281,
          360,
          341,
          337,
          1596,
          257,
          1339,
          281,
          483,
          6356,
          1547,
          281,
          1888,
          746,
          51814
        ]
      },
      {
        "avg_logprob": -0.2566569507985875,
        "compression_ratio": 1.8615384615384616,
        "end": 4278.22,
        "id": 1224,
        "no_speech_prob": 0.12591391801834106,
        "seek": 427522,
        "start": 4275.22,
        "temperature": 0,
        "text": " lower than 100.",
        "tokens": [
          50364,
          3126,
          813,
          2319,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.2566569507985875,
        "compression_ratio": 1.8615384615384616,
        "end": 4281.22,
        "id": 1225,
        "no_speech_prob": 0.12591391801834106,
        "seek": 427522,
        "start": 4278.22,
        "temperature": 0,
        "text": " Boy, it really doesn't want to ‑‑ how long do I have to ‑‑ shouldn't I have",
        "tokens": [
          50514,
          9486,
          11,
          309,
          534,
          1177,
          380,
          528,
          281,
          45217,
          577,
          938,
          360,
          286,
          362,
          281,
          45217,
          4659,
          380,
          286,
          362,
          50664
        ]
      },
      {
        "avg_logprob": -0.2566569507985875,
        "compression_ratio": 1.8615384615384616,
        "end": 4285.22,
        "id": 1226,
        "no_speech_prob": 0.12591391801834106,
        "seek": 427522,
        "start": 4281.22,
        "temperature": 0,
        "text": " like a one out of, I guess, seven or eight chance?",
        "tokens": [
          50664,
          411,
          257,
          472,
          484,
          295,
          11,
          286,
          2041,
          11,
          3407,
          420,
          3180,
          2931,
          30,
          50864
        ]
      },
      {
        "avg_logprob": -0.2566569507985875,
        "compression_ratio": 1.8615384615384616,
        "end": 4289.22,
        "id": 1227,
        "no_speech_prob": 0.12591391801834106,
        "seek": 427522,
        "start": 4285.22,
        "temperature": 0,
        "text": " My goodness.",
        "tokens": [
          50864,
          1222,
          8387,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.2566569507985875,
        "compression_ratio": 1.8615384615384616,
        "end": 4290.22,
        "id": 1228,
        "no_speech_prob": 0.12591391801834106,
        "seek": 427522,
        "start": 4289.22,
        "temperature": 0,
        "text": " I'll speed this up again.",
        "tokens": [
          51064,
          286,
          603,
          3073,
          341,
          493,
          797,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.2566569507985875,
        "compression_ratio": 1.8615384615384616,
        "end": 4291.22,
        "id": 1229,
        "no_speech_prob": 0.12591391801834106,
        "seek": 427522,
        "start": 4290.22,
        "temperature": 0,
        "text": " I'll speed this up.",
        "tokens": [
          51114,
          286,
          603,
          3073,
          341,
          493,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.2566569507985875,
        "compression_ratio": 1.8615384615384616,
        "end": 4292.22,
        "id": 1230,
        "no_speech_prob": 0.12591391801834106,
        "seek": 427522,
        "start": 4291.22,
        "temperature": 0,
        "text": " I'll keep going.",
        "tokens": [
          51164,
          286,
          603,
          1066,
          516,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.2566569507985875,
        "compression_ratio": 1.8615384615384616,
        "end": 4293.22,
        "id": 1231,
        "no_speech_prob": 0.12591391801834106,
        "seek": 427522,
        "start": 4292.22,
        "temperature": 0,
        "text": " I can edit this out.",
        "tokens": [
          51214,
          286,
          393,
          8129,
          341,
          484,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.2566569507985875,
        "compression_ratio": 1.8615384615384616,
        "end": 4294.22,
        "id": 1232,
        "no_speech_prob": 0.12591391801834106,
        "seek": 427522,
        "start": 4293.22,
        "temperature": 0,
        "text": " Come on, give me something.",
        "tokens": [
          51264,
          2492,
          322,
          11,
          976,
          385,
          746,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.2566569507985875,
        "compression_ratio": 1.8615384615384616,
        "end": 4300.22,
        "id": 1233,
        "no_speech_prob": 0.12591391801834106,
        "seek": 427522,
        "start": 4294.22,
        "temperature": 0,
        "text": " Oh, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no,",
        "tokens": [
          51314,
          876,
          11,
          572,
          11,
          572,
          11,
          572,
          11,
          572,
          11,
          572,
          11,
          572,
          11,
          572,
          11,
          572,
          11,
          572,
          11,
          572,
          11,
          572,
          11,
          572,
          11,
          572,
          11,
          572,
          11,
          572,
          11,
          572,
          11,
          572,
          11,
          572,
          11,
          572,
          11,
          572,
          11,
          572,
          11,
          51614
        ]
      },
      {
        "avg_logprob": -0.21311319002541163,
        "compression_ratio": 1.5707762557077625,
        "end": 4307.22,
        "id": 1234,
        "no_speech_prob": 0.6721299290657043,
        "seek": 430022,
        "start": 4301.22,
        "temperature": 0,
        "text": " I'm very unlikely to get a number lower than 100 because I'm picking three random numbers",
        "tokens": [
          50414,
          286,
          478,
          588,
          17518,
          281,
          483,
          257,
          1230,
          3126,
          813,
          2319,
          570,
          286,
          478,
          8867,
          1045,
          4974,
          3547,
          50714
        ]
      },
      {
        "avg_logprob": -0.21311319002541163,
        "compression_ratio": 1.5707762557077625,
        "end": 4309.22,
        "id": 1235,
        "no_speech_prob": 0.6721299290657043,
        "seek": 430022,
        "start": 4307.22,
        "temperature": 0,
        "text": " between 0 and 255.",
        "tokens": [
          50714,
          1296,
          1958,
          293,
          3552,
          20,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.21311319002541163,
        "compression_ratio": 1.5707762557077625,
        "end": 4315.22,
        "id": 1236,
        "no_speech_prob": 0.6721299290657043,
        "seek": 430022,
        "start": 4309.22,
        "temperature": 0,
        "text": " So I actually have ‑‑ I'd have to pick three random numbers basically lower than",
        "tokens": [
          50814,
          407,
          286,
          767,
          362,
          45217,
          286,
          1116,
          362,
          281,
          1888,
          1045,
          4974,
          3547,
          1936,
          3126,
          813,
          51114
        ]
      },
      {
        "avg_logprob": -0.21311319002541163,
        "compression_ratio": 1.5707762557077625,
        "end": 4319.22,
        "id": 1237,
        "no_speech_prob": 0.6721299290657043,
        "seek": 430022,
        "start": 4315.22,
        "temperature": 0,
        "text": " 33, which has a pretty low probability of doing that in a row.",
        "tokens": [
          51114,
          11816,
          11,
          597,
          575,
          257,
          1238,
          2295,
          8482,
          295,
          884,
          300,
          294,
          257,
          5386,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.21311319002541163,
        "compression_ratio": 1.5707762557077625,
        "end": 4321.22,
        "id": 1238,
        "no_speech_prob": 0.6721299290657043,
        "seek": 430022,
        "start": 4319.22,
        "temperature": 0,
        "text": " So let's do the opposite thing.",
        "tokens": [
          51314,
          407,
          718,
          311,
          360,
          264,
          6182,
          551,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.21311319002541163,
        "compression_ratio": 1.5707762557077625,
        "end": 4327.22,
        "id": 1239,
        "no_speech_prob": 0.6721299290657043,
        "seek": 430022,
        "start": 4321.22,
        "temperature": 0,
        "text": " Let's say, let's do this only if it's greater than 500.",
        "tokens": [
          51414,
          961,
          311,
          584,
          11,
          718,
          311,
          360,
          341,
          787,
          498,
          309,
          311,
          5044,
          813,
          5923,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.22643030217263552,
        "compression_ratio": 1.5959183673469388,
        "end": 4332.22,
        "id": 1240,
        "no_speech_prob": 0.1347643882036209,
        "seek": 432722,
        "start": 4327.22,
        "temperature": 0,
        "text": " 296, white, so if I ever get it greater than 500, black, right?",
        "tokens": [
          50364,
          9413,
          21,
          11,
          2418,
          11,
          370,
          498,
          286,
          1562,
          483,
          309,
          5044,
          813,
          5923,
          11,
          2211,
          11,
          558,
          30,
          50614
        ]
      },
      {
        "avg_logprob": -0.22643030217263552,
        "compression_ratio": 1.5959183673469388,
        "end": 4333.22,
        "id": 1241,
        "no_speech_prob": 0.1347643882036209,
        "seek": 432722,
        "start": 4332.22,
        "temperature": 0,
        "text": " 393 is white.",
        "tokens": [
          50614,
          15238,
          18,
          307,
          2418,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.22643030217263552,
        "compression_ratio": 1.5959183673469388,
        "end": 4338.22,
        "id": 1242,
        "no_speech_prob": 0.1347643882036209,
        "seek": 432722,
        "start": 4333.22,
        "temperature": 0,
        "text": " So it is learning that threshold, whatever I kind of, whatever I had.",
        "tokens": [
          50664,
          407,
          309,
          307,
          2539,
          300,
          14678,
          11,
          2035,
          286,
          733,
          295,
          11,
          2035,
          286,
          632,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.22643030217263552,
        "compression_ratio": 1.5959183673469388,
        "end": 4339.22,
        "id": 1243,
        "no_speech_prob": 0.1347643882036209,
        "seek": 432722,
        "start": 4338.22,
        "temperature": 0,
        "text": " I picked 300.",
        "tokens": [
          50914,
          286,
          6183,
          6641,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.22643030217263552,
        "compression_ratio": 1.5959183673469388,
        "end": 4345.22,
        "id": 1244,
        "no_speech_prob": 0.1347643882036209,
        "seek": 432722,
        "start": 4339.22,
        "temperature": 0,
        "text": " And probably what would make sense for me to pick is just, you know, 256 or 255 times",
        "tokens": [
          50964,
          400,
          1391,
          437,
          576,
          652,
          2020,
          337,
          385,
          281,
          1888,
          307,
          445,
          11,
          291,
          458,
          11,
          38882,
          420,
          3552,
          20,
          1413,
          51264
        ]
      },
      {
        "avg_logprob": -0.22643030217263552,
        "compression_ratio": 1.5959183673469388,
        "end": 4350.22,
        "id": 1245,
        "no_speech_prob": 0.1347643882036209,
        "seek": 432722,
        "start": 4345.22,
        "temperature": 0,
        "text": " three divided by, yeah, 255 times three divided by two.",
        "tokens": [
          51264,
          1045,
          6666,
          538,
          11,
          1338,
          11,
          3552,
          20,
          1413,
          1045,
          6666,
          538,
          732,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.22643030217263552,
        "compression_ratio": 1.5959183673469388,
        "end": 4355.22,
        "id": 1246,
        "no_speech_prob": 0.1347643882036209,
        "seek": 432722,
        "start": 4350.22,
        "temperature": 0,
        "text": " I really should have stopped this video two or three minutes ago when I had the chance.",
        "tokens": [
          51514,
          286,
          534,
          820,
          362,
          5936,
          341,
          960,
          732,
          420,
          1045,
          2077,
          2057,
          562,
          286,
          632,
          264,
          2931,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.20879247914189877,
        "compression_ratio": 1.5919117647058822,
        "end": 4358.22,
        "id": 1247,
        "no_speech_prob": 0.14031580090522766,
        "seek": 435522,
        "start": 4355.22,
        "temperature": 0,
        "text": " So we can see now, here's my color predictor.",
        "tokens": [
          50364,
          407,
          321,
          393,
          536,
          586,
          11,
          510,
          311,
          452,
          2017,
          6069,
          284,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.20879247914189877,
        "compression_ratio": 1.5919117647058822,
        "end": 4362.22,
        "id": 1248,
        "no_speech_prob": 0.14031580090522766,
        "seek": 435522,
        "start": 4358.22,
        "temperature": 0,
        "text": " It's trying to predict which text looks better over the color behind the scenes.",
        "tokens": [
          50514,
          467,
          311,
          1382,
          281,
          6069,
          597,
          2487,
          1542,
          1101,
          670,
          264,
          2017,
          2261,
          264,
          8026,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.20879247914189877,
        "compression_ratio": 1.5919117647058822,
        "end": 4363.22,
        "id": 1249,
        "no_speech_prob": 0.14031580090522766,
        "seek": 435522,
        "start": 4362.22,
        "temperature": 0,
        "text": " Now we're finally done.",
        "tokens": [
          50714,
          823,
          321,
          434,
          2721,
          1096,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.20879247914189877,
        "compression_ratio": 1.5919117647058822,
        "end": 4367.22,
        "id": 1250,
        "no_speech_prob": 0.14031580090522766,
        "seek": 435522,
        "start": 4363.22,
        "temperature": 0,
        "text": " Oh, please, please, creative, wonderful people of the internet, make a more interesting,",
        "tokens": [
          50764,
          876,
          11,
          1767,
          11,
          1767,
          11,
          5880,
          11,
          3715,
          561,
          295,
          264,
          4705,
          11,
          652,
          257,
          544,
          1880,
          11,
          50964
        ]
      },
      {
        "avg_logprob": -0.20879247914189877,
        "compression_ratio": 1.5919117647058822,
        "end": 4370.22,
        "id": 1251,
        "no_speech_prob": 0.14031580090522766,
        "seek": 435522,
        "start": 4367.22,
        "temperature": 0,
        "text": " better version of this, and I will see you in a future coding challenge.",
        "tokens": [
          50964,
          1101,
          3037,
          295,
          341,
          11,
          293,
          286,
          486,
          536,
          291,
          294,
          257,
          2027,
          17720,
          3430,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.20879247914189877,
        "compression_ratio": 1.5919117647058822,
        "end": 4371.22,
        "id": 1252,
        "no_speech_prob": 0.14031580090522766,
        "seek": 435522,
        "start": 4370.22,
        "temperature": 0,
        "text": " Goodbye.",
        "tokens": [
          51114,
          15528,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.20879247914189877,
        "compression_ratio": 1.5919117647058822,
        "end": 4374.22,
        "id": 1253,
        "no_speech_prob": 0.14031580090522766,
        "seek": 435522,
        "start": 4371.22,
        "temperature": 0,
        "text": " Thank you again to Jabril for this particular idea.",
        "tokens": [
          51164,
          1044,
          291,
          797,
          281,
          40319,
          24216,
          337,
          341,
          1729,
          1558,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.20879247914189877,
        "compression_ratio": 1.5919117647058822,
        "end": 4375.22,
        "id": 1254,
        "no_speech_prob": 0.14031580090522766,
        "seek": 435522,
        "start": 4374.22,
        "temperature": 0,
        "text": " Subscribe to his channel.",
        "tokens": [
          51314,
          10611,
          281,
          702,
          2269,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.20879247914189877,
        "compression_ratio": 1.5919117647058822,
        "end": 4377.22,
        "id": 1255,
        "no_speech_prob": 0.14031580090522766,
        "seek": 435522,
        "start": 4375.22,
        "temperature": 0,
        "text": " Link in this video's description.",
        "tokens": [
          51364,
          8466,
          294,
          341,
          960,
          311,
          3855,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.21773846944173178,
        "compression_ratio": 1.6578947368421053,
        "end": 4380.22,
        "id": 1256,
        "no_speech_prob": 0.44933202862739563,
        "seek": 437722,
        "start": 4378.22,
        "temperature": 0,
        "text": " Yes, hard code the colors.",
        "tokens": [
          50414,
          1079,
          11,
          1152,
          3089,
          264,
          4577,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.21773846944173178,
        "compression_ratio": 1.6578947368421053,
        "end": 4382.22,
        "id": 1257,
        "no_speech_prob": 0.44933202862739563,
        "seek": 437722,
        "start": 4380.22,
        "temperature": 0,
        "text": " I could have hard coded the colors, yes.",
        "tokens": [
          50514,
          286,
          727,
          362,
          1152,
          34874,
          264,
          4577,
          11,
          2086,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.21773846944173178,
        "compression_ratio": 1.6578947368421053,
        "end": 4391.22,
        "id": 1258,
        "no_speech_prob": 0.44933202862739563,
        "seek": 437722,
        "start": 4390.22,
        "temperature": 0,
        "text": " Yes.",
        "tokens": [
          51014,
          1079,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.21773846944173178,
        "compression_ratio": 1.6578947368421053,
        "end": 4393.22,
        "id": 1259,
        "no_speech_prob": 0.44933202862739563,
        "seek": 437722,
        "start": 4391.22,
        "temperature": 0,
        "text": " Oh, Tim makes a great suggestion.",
        "tokens": [
          51064,
          876,
          11,
          7172,
          1669,
          257,
          869,
          16541,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.21773846944173178,
        "compression_ratio": 1.6578947368421053,
        "end": 4398.22,
        "id": 1260,
        "no_speech_prob": 0.44933202862739563,
        "seek": 437722,
        "start": 4393.22,
        "temperature": 0,
        "text": " You should use softmax and set the circle's x position based on the output to visualize",
        "tokens": [
          51164,
          509,
          820,
          764,
          2787,
          41167,
          293,
          992,
          264,
          6329,
          311,
          2031,
          2535,
          2361,
          322,
          264,
          5598,
          281,
          23273,
          51414
        ]
      },
      {
        "avg_logprob": -0.21773846944173178,
        "compression_ratio": 1.6578947368421053,
        "end": 4399.22,
        "id": 1261,
        "no_speech_prob": 0.44933202862739563,
        "seek": 437722,
        "start": 4398.22,
        "temperature": 0,
        "text": " the confidence.",
        "tokens": [
          51414,
          264,
          6687,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.21773846944173178,
        "compression_ratio": 1.6578947368421053,
        "end": 4403.22,
        "id": 1262,
        "no_speech_prob": 0.44933202862739563,
        "seek": 437722,
        "start": 4399.22,
        "temperature": 0,
        "text": " If it's more confident, put the circle more to the left and vice versa.",
        "tokens": [
          51464,
          759,
          309,
          311,
          544,
          6679,
          11,
          829,
          264,
          6329,
          544,
          281,
          264,
          1411,
          293,
          11964,
          25650,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.21773846944173178,
        "compression_ratio": 1.6578947368421053,
        "end": 4405.22,
        "id": 1263,
        "no_speech_prob": 0.44933202862739563,
        "seek": 437722,
        "start": 4403.22,
        "temperature": 0,
        "text": " That is such a great suggestion.",
        "tokens": [
          51664,
          663,
          307,
          1270,
          257,
          869,
          16541,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.2029251005591416,
        "compression_ratio": 1.5,
        "end": 4406.22,
        "id": 1264,
        "no_speech_prob": 0.01518839318305254,
        "seek": 440522,
        "start": 4405.22,
        "temperature": 0,
        "text": " More to the left and vice versa.",
        "tokens": [
          50364,
          5048,
          281,
          264,
          1411,
          293,
          11964,
          25650,
          13,
          50414
        ]
      },
      {
        "avg_logprob": -0.2029251005591416,
        "compression_ratio": 1.5,
        "end": 4408.22,
        "id": 1265,
        "no_speech_prob": 0.01518839318305254,
        "seek": 440522,
        "start": 4406.22,
        "temperature": 0,
        "text": " That is such a good idea.",
        "tokens": [
          50414,
          663,
          307,
          1270,
          257,
          665,
          1558,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.2029251005591416,
        "compression_ratio": 1.5,
        "end": 4411.22,
        "id": 1266,
        "no_speech_prob": 0.01518839318305254,
        "seek": 440522,
        "start": 4408.22,
        "temperature": 0,
        "text": " Somebody please go do that as their own project.",
        "tokens": [
          50514,
          13463,
          1767,
          352,
          360,
          300,
          382,
          641,
          1065,
          1716,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.2029251005591416,
        "compression_ratio": 1.5,
        "end": 4412.22,
        "id": 1267,
        "no_speech_prob": 0.01518839318305254,
        "seek": 440522,
        "start": 4411.22,
        "temperature": 0,
        "text": " All right, I think I finished for today.",
        "tokens": [
          50664,
          1057,
          558,
          11,
          286,
          519,
          286,
          4335,
          337,
          965,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.2029251005591416,
        "compression_ratio": 1.5,
        "end": 4414.22,
        "id": 1268,
        "no_speech_prob": 0.01518839318305254,
        "seek": 440522,
        "start": 4412.22,
        "temperature": 0,
        "text": " It's 12.43.",
        "tokens": [
          50714,
          467,
          311,
          2272,
          13,
          17201,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.2029251005591416,
        "compression_ratio": 1.5,
        "end": 4419.22,
        "id": 1269,
        "no_speech_prob": 0.01518839318305254,
        "seek": 440522,
        "start": 4414.22,
        "temperature": 0,
        "text": " Oh, boy, do I want to try to do that quadtree thing.",
        "tokens": [
          50814,
          876,
          11,
          3237,
          11,
          360,
          286,
          528,
          281,
          853,
          281,
          360,
          300,
          10787,
          83,
          701,
          551,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.2029251005591416,
        "compression_ratio": 1.5,
        "end": 4423.22,
        "id": 1270,
        "no_speech_prob": 0.01518839318305254,
        "seek": 440522,
        "start": 4419.22,
        "temperature": 0,
        "text": " This is probably going to be like a 45-minute to an hour coding challenge, I would guess.",
        "tokens": [
          51064,
          639,
          307,
          1391,
          516,
          281,
          312,
          411,
          257,
          6905,
          12,
          18256,
          281,
          364,
          1773,
          17720,
          3430,
          11,
          286,
          576,
          2041,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.2029251005591416,
        "compression_ratio": 1.5,
        "end": 4429.22,
        "id": 1271,
        "no_speech_prob": 0.01518839318305254,
        "seek": 440522,
        "start": 4423.22,
        "temperature": 0,
        "text": " But hopefully there's a lot that can be edited out when it gets to that point.",
        "tokens": [
          51264,
          583,
          4696,
          456,
          311,
          257,
          688,
          300,
          393,
          312,
          23016,
          484,
          562,
          309,
          2170,
          281,
          300,
          935,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.2029251005591416,
        "compression_ratio": 1.5,
        "end": 4434.22,
        "id": 1272,
        "no_speech_prob": 0.01518839318305254,
        "seek": 440522,
        "start": 4431.22,
        "temperature": 0,
        "text": " I was getting some messages.",
        "tokens": [
          51664,
          286,
          390,
          1242,
          512,
          7897,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.17275737313663259,
        "compression_ratio": 1.7608695652173914,
        "end": 4436.22,
        "id": 1273,
        "no_speech_prob": 0.0008167336927726865,
        "seek": 443422,
        "start": 4434.22,
        "temperature": 0,
        "text": " Let me see if there's anything super important here.",
        "tokens": [
          50364,
          961,
          385,
          536,
          498,
          456,
          311,
          1340,
          1687,
          1021,
          510,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.17275737313663259,
        "compression_ratio": 1.7608695652173914,
        "end": 4445.22,
        "id": 1274,
        "no_speech_prob": 0.0008167336927726865,
        "seek": 443422,
        "start": 4443.22,
        "temperature": 0,
        "text": " Okay, everything seems good.",
        "tokens": [
          50814,
          1033,
          11,
          1203,
          2544,
          665,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.17275737313663259,
        "compression_ratio": 1.7608695652173914,
        "end": 4448.22,
        "id": 1275,
        "no_speech_prob": 0.0008167336927726865,
        "seek": 443422,
        "start": 4445.22,
        "temperature": 0,
        "text": " I'm just checking my email.",
        "tokens": [
          50914,
          286,
          478,
          445,
          8568,
          452,
          3796,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.17275737313663259,
        "compression_ratio": 1.7608695652173914,
        "end": 4449.22,
        "id": 1276,
        "no_speech_prob": 0.0008167336927726865,
        "seek": 443422,
        "start": 4448.22,
        "temperature": 0,
        "text": " I'm not checking my email.",
        "tokens": [
          51064,
          286,
          478,
          406,
          8568,
          452,
          3796,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.17275737313663259,
        "compression_ratio": 1.7608695652173914,
        "end": 4450.22,
        "id": 1277,
        "no_speech_prob": 0.0008167336927726865,
        "seek": 443422,
        "start": 4449.22,
        "temperature": 0,
        "text": " I'm not checking my email.",
        "tokens": [
          51114,
          286,
          478,
          406,
          8568,
          452,
          3796,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.17275737313663259,
        "compression_ratio": 1.7608695652173914,
        "end": 4453.22,
        "id": 1278,
        "no_speech_prob": 0.0008167336927726865,
        "seek": 443422,
        "start": 4450.22,
        "temperature": 0,
        "text": " I got a super chat.",
        "tokens": [
          51164,
          286,
          658,
          257,
          1687,
          5081,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.17275737313663259,
        "compression_ratio": 1.7608695652173914,
        "end": 4454.22,
        "id": 1279,
        "no_speech_prob": 0.0008167336927726865,
        "seek": 443422,
        "start": 4453.22,
        "temperature": 0,
        "text": " Thank you for alerting me.",
        "tokens": [
          51314,
          1044,
          291,
          337,
          419,
          27187,
          385,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.17275737313663259,
        "compression_ratio": 1.7608695652173914,
        "end": 4456.22,
        "id": 1280,
        "no_speech_prob": 0.0008167336927726865,
        "seek": 443422,
        "start": 4454.22,
        "temperature": 0,
        "text": " Let me look in my dashboard here.",
        "tokens": [
          51364,
          961,
          385,
          574,
          294,
          452,
          18342,
          510,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.17275737313663259,
        "compression_ratio": 1.7608695652173914,
        "end": 4458.22,
        "id": 1281,
        "no_speech_prob": 0.0008167336927726865,
        "seek": 443422,
        "start": 4456.22,
        "temperature": 0,
        "text": " That might be an easier way so I can thank the super chat.",
        "tokens": [
          51464,
          663,
          1062,
          312,
          364,
          3571,
          636,
          370,
          286,
          393,
          1309,
          264,
          1687,
          5081,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.17275737313663259,
        "compression_ratio": 1.7608695652173914,
        "end": 4462.22,
        "id": 1282,
        "no_speech_prob": 0.0008167336927726865,
        "seek": 443422,
        "start": 4458.22,
        "temperature": 0,
        "text": " Oh, uncreative name.",
        "tokens": [
          51564,
          876,
          11,
          6219,
          620,
          488,
          1315,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.17801293702883142,
        "compression_ratio": 1.6302521008403361,
        "end": 4466.22,
        "id": 1283,
        "no_speech_prob": 0.01048820186406374,
        "seek": 446222,
        "start": 4462.22,
        "temperature": 0,
        "text": " Thank you for your super chat message and your donation.",
        "tokens": [
          50364,
          1044,
          291,
          337,
          428,
          1687,
          5081,
          3636,
          293,
          428,
          19724,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.17801293702883142,
        "compression_ratio": 1.6302521008403361,
        "end": 4467.22,
        "id": 1284,
        "no_speech_prob": 0.01048820186406374,
        "seek": 446222,
        "start": 4466.22,
        "temperature": 0,
        "text": " It is much appreciated.",
        "tokens": [
          50564,
          467,
          307,
          709,
          17169,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.17801293702883142,
        "compression_ratio": 1.6302521008403361,
        "end": 4468.22,
        "id": 1285,
        "no_speech_prob": 0.01048820186406374,
        "seek": 446222,
        "start": 4467.22,
        "temperature": 0,
        "text": " Thank you.",
        "tokens": [
          50614,
          1044,
          291,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.17801293702883142,
        "compression_ratio": 1.6302521008403361,
        "end": 4477.22,
        "id": 1286,
        "no_speech_prob": 0.01048820186406374,
        "seek": 446222,
        "start": 4468.22,
        "temperature": 0,
        "text": " If you want to support the work that I'm doing, you can subscribe also to the Patreon and join our little Slack community,",
        "tokens": [
          50664,
          759,
          291,
          528,
          281,
          1406,
          264,
          589,
          300,
          286,
          478,
          884,
          11,
          291,
          393,
          3022,
          611,
          281,
          264,
          15692,
          293,
          3917,
          527,
          707,
          37211,
          1768,
          11,
          51114
        ]
      },
      {
        "avg_logprob": -0.17801293702883142,
        "compression_ratio": 1.6302521008403361,
        "end": 4480.22,
        "id": 1287,
        "no_speech_prob": 0.01048820186406374,
        "seek": 446222,
        "start": 4477.22,
        "temperature": 0,
        "text": " which is a fun place to discuss and ask questions and that sort of thing.",
        "tokens": [
          51114,
          597,
          307,
          257,
          1019,
          1081,
          281,
          2248,
          293,
          1029,
          1651,
          293,
          300,
          1333,
          295,
          551,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.17801293702883142,
        "compression_ratio": 1.6302521008403361,
        "end": 4483.22,
        "id": 1288,
        "no_speech_prob": 0.01048820186406374,
        "seek": 446222,
        "start": 4480.22,
        "temperature": 0,
        "text": " I should work on the p5 pull request.",
        "tokens": [
          51264,
          286,
          820,
          589,
          322,
          264,
          280,
          20,
          2235,
          5308,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.17801293702883142,
        "compression_ratio": 1.6302521008403361,
        "end": 4485.22,
        "id": 1289,
        "no_speech_prob": 0.01048820186406374,
        "seek": 446222,
        "start": 4483.22,
        "temperature": 0,
        "text": " I could do that.",
        "tokens": [
          51414,
          286,
          727,
          360,
          300,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.17801293702883142,
        "compression_ratio": 1.6302521008403361,
        "end": 4488.22,
        "id": 1290,
        "no_speech_prob": 0.01048820186406374,
        "seek": 446222,
        "start": 4485.22,
        "temperature": 0,
        "text": " I kind of feel like I could do the quadtree.",
        "tokens": [
          51514,
          286,
          733,
          295,
          841,
          411,
          286,
          727,
          360,
          264,
          10787,
          83,
          701,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.22121720016002655,
        "compression_ratio": 1.4315068493150684,
        "end": 4492.22,
        "id": 1291,
        "no_speech_prob": 0.0032224515452980995,
        "seek": 448822,
        "start": 4488.22,
        "temperature": 0,
        "text": " I don't have 45.",
        "tokens": [
          50364,
          286,
          500,
          380,
          362,
          6905,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.22121720016002655,
        "compression_ratio": 1.4315068493150684,
        "end": 4494.22,
        "id": 1292,
        "no_speech_prob": 0.0032224515452980995,
        "seek": 448822,
        "start": 4492.22,
        "temperature": 0,
        "text": " Let me take a look at the quadtree thing for a second.",
        "tokens": [
          50564,
          961,
          385,
          747,
          257,
          574,
          412,
          264,
          10787,
          83,
          701,
          551,
          337,
          257,
          1150,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.22121720016002655,
        "compression_ratio": 1.4315068493150684,
        "end": 4505.22,
        "id": 1293,
        "no_speech_prob": 0.0032224515452980995,
        "seek": 448822,
        "start": 4502.22,
        "temperature": 0,
        "text": " Just hold your horses.",
        "tokens": [
          51064,
          1449,
          1797,
          428,
          13112,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.22121720016002655,
        "compression_ratio": 1.4315068493150684,
        "end": 4507.22,
        "id": 1294,
        "no_speech_prob": 0.0032224515452980995,
        "seek": 448822,
        "start": 4505.22,
        "temperature": 0,
        "text": " Let's be ambitious here for a second.",
        "tokens": [
          51214,
          961,
          311,
          312,
          20239,
          510,
          337,
          257,
          1150,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.22121720016002655,
        "compression_ratio": 1.4315068493150684,
        "end": 4510.22,
        "id": 1295,
        "no_speech_prob": 0.0032224515452980995,
        "seek": 448822,
        "start": 4507.22,
        "temperature": 0,
        "text": " I really should give myself more time to do other things I need to do today.",
        "tokens": [
          51314,
          286,
          534,
          820,
          976,
          2059,
          544,
          565,
          281,
          360,
          661,
          721,
          286,
          643,
          281,
          360,
          965,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.437567999196607,
        "compression_ratio": 1.173913043478261,
        "end": 4515.22,
        "id": 1296,
        "no_speech_prob": 0.028867043554782867,
        "seek": 451022,
        "start": 4511.22,
        "temperature": 0,
        "text": " Is this the this is just the example.",
        "tokens": [
          50414,
          1119,
          341,
          264,
          341,
          307,
          445,
          264,
          1365,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.437567999196607,
        "compression_ratio": 1.173913043478261,
        "end": 4518.22,
        "id": 1297,
        "no_speech_prob": 0.028867043554782867,
        "seek": 451022,
        "start": 4515.22,
        "temperature": 0,
        "text": " So hold on.",
        "tokens": [
          50614,
          407,
          1797,
          322,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.437567999196607,
        "compression_ratio": 1.173913043478261,
        "end": 4521.22,
        "id": 1298,
        "no_speech_prob": 0.028867043554782867,
        "seek": 451022,
        "start": 4518.22,
        "temperature": 0,
        "text": " Quadtree.",
        "tokens": [
          50764,
          29619,
          83,
          701,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.437567999196607,
        "compression_ratio": 1.173913043478261,
        "end": 4523.22,
        "id": 1299,
        "no_speech_prob": 0.028867043554782867,
        "seek": 451022,
        "start": 4521.22,
        "temperature": 0,
        "text": " Let me grab this repo real quick.",
        "tokens": [
          50914,
          961,
          385,
          4444,
          341,
          49040,
          957,
          1702,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.437567999196607,
        "compression_ratio": 1.173913043478261,
        "end": 4534.22,
        "id": 1300,
        "no_speech_prob": 0.028867043554782867,
        "seek": 451022,
        "start": 4531.22,
        "temperature": 0,
        "text": " Oh, oh, right.",
        "tokens": [
          51414,
          876,
          11,
          1954,
          11,
          558,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.4926574508865158,
        "compression_ratio": 1.5317460317460319,
        "end": 4538.22,
        "id": 1301,
        "no_speech_prob": 0.004981850273907185,
        "seek": 453422,
        "start": 4535.22,
        "temperature": 0,
        "text": " Quadtree.",
        "tokens": [
          50414,
          29619,
          83,
          701,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.4926574508865158,
        "compression_ratio": 1.5317460317460319,
        "end": 4545.22,
        "id": 1302,
        "no_speech_prob": 0.004981850273907185,
        "seek": 453422,
        "start": 4542.22,
        "temperature": 0,
        "text": " Why I think I should do this, I don't know.",
        "tokens": [
          50764,
          1545,
          286,
          519,
          286,
          820,
          360,
          341,
          11,
          286,
          500,
          380,
          458,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.4926574508865158,
        "compression_ratio": 1.5317460317460319,
        "end": 4548.22,
        "id": 1303,
        "no_speech_prob": 0.004981850273907185,
        "seek": 453422,
        "start": 4545.22,
        "temperature": 0,
        "text": " I just kind of wanted that to be done.",
        "tokens": [
          50914,
          286,
          445,
          733,
          295,
          1415,
          300,
          281,
          312,
          1096,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.4926574508865158,
        "compression_ratio": 1.5317460317460319,
        "end": 4551.22,
        "id": 1304,
        "no_speech_prob": 0.004981850273907185,
        "seek": 453422,
        "start": 4548.22,
        "temperature": 0,
        "text": " Do I still need to fix the quadtree bug?",
        "tokens": [
          51064,
          1144,
          286,
          920,
          643,
          281,
          3191,
          264,
          10787,
          83,
          701,
          7426,
          30,
          51214
        ]
      },
      {
        "avg_logprob": -0.4926574508865158,
        "compression_ratio": 1.5317460317460319,
        "end": 4553.22,
        "id": 1305,
        "no_speech_prob": 0.004981850273907185,
        "seek": 453422,
        "start": 4551.22,
        "temperature": 0,
        "text": " What was the bug?",
        "tokens": [
          51214,
          708,
          390,
          264,
          7426,
          30,
          51314
        ]
      },
      {
        "avg_logprob": -0.4926574508865158,
        "compression_ratio": 1.5317460317460319,
        "end": 4555.22,
        "id": 1306,
        "no_speech_prob": 0.004981850273907185,
        "seek": 453422,
        "start": 4553.22,
        "temperature": 0,
        "text": " I don't know.",
        "tokens": [
          51314,
          286,
          500,
          380,
          458,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.4926574508865158,
        "compression_ratio": 1.5317460317460319,
        "end": 4557.22,
        "id": 1307,
        "no_speech_prob": 0.004981850273907185,
        "seek": 453422,
        "start": 4555.22,
        "temperature": 0,
        "text": " I don't know.",
        "tokens": [
          51414,
          286,
          500,
          380,
          458,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.4926574508865158,
        "compression_ratio": 1.5317460317460319,
        "end": 4559.22,
        "id": 1308,
        "no_speech_prob": 0.004981850273907185,
        "seek": 453422,
        "start": 4557.22,
        "temperature": 0,
        "text": " I don't know.",
        "tokens": [
          51514,
          286,
          500,
          380,
          458,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -2.484181140718006,
        "compression_ratio": 1.7755102040816326,
        "end": 4563.22,
        "id": 1309,
        "no_speech_prob": 0.021947558969259262,
        "seek": 455922,
        "start": 4560.22,
        "temperature": 1,
        "text": " How many people got the best four in the party again?",
        "tokens": [
          50414,
          1012,
          867,
          561,
          658,
          264,
          1151,
          1451,
          294,
          264,
          3595,
          797,
          30,
          50564
        ]
      },
      {
        "avg_logprob": -2.484181140718006,
        "compression_ratio": 1.7755102040816326,
        "end": 4566.22,
        "id": 1310,
        "no_speech_prob": 0.021947558969259262,
        "seek": 455922,
        "start": 4563.22,
        "temperature": 1,
        "text": " Probably not as many people as we would have liked those.",
        "tokens": [
          50564,
          9210,
          406,
          382,
          867,
          561,
          382,
          321,
          576,
          362,
          411,
          67,
          729,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -2.484181140718006,
        "compression_ratio": 1.7755102040816326,
        "end": 4570.22,
        "id": 1311,
        "no_speech_prob": 0.021947558969259262,
        "seek": 455922,
        "start": 4566.22,
        "temperature": 1,
        "text": " They're quite aggressive with their, as many people as we would have liked.",
        "tokens": [
          50714,
          314,
          17230,
          434,
          1596,
          10762,
          365,
          641,
          11,
          382,
          867,
          561,
          382,
          321,
          261,
          3298,
          67,
          362,
          375,
          34601,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -2.484181140718006,
        "compression_ratio": 1.7755102040816326,
        "end": 4579.22,
        "id": 1312,
        "no_speech_prob": 0.021947558969259262,
        "seek": 455922,
        "start": 4576.22,
        "temperature": 1,
        "text": " So I should probably need to fix the bug, too.",
        "tokens": [
          51214,
          407,
          286,
          820,
          1391,
          643,
          281,
          3191,
          264,
          7426,
          11,
          886,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -2.484181140718006,
        "compression_ratio": 1.7755102040816326,
        "end": 4581.22,
        "id": 1313,
        "no_speech_prob": 0.021947558969259262,
        "seek": 455922,
        "start": 4579.22,
        "temperature": 1,
        "text": " I'm going to leave this because we didn't typo.",
        "tokens": [
          51364,
          286,
          478,
          516,
          281,
          1856,
          256,
          18300,
          570,
          321,
          1026,
          67,
          77,
          380,
          2125,
          78,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -2.484181140718006,
        "compression_ratio": 1.7755102040816326,
        "end": 4584.22,
        "id": 1314,
        "no_speech_prob": 0.021947558969259262,
        "seek": 455922,
        "start": 4581.22,
        "temperature": 1,
        "text": " I'm going to leave this because I think it's better toasted less.",
        "tokens": [
          51464,
          286,
          478,
          516,
          281,
          1856,
          30994,
          82,
          570,
          286,
          519,
          309,
          311,
          1101,
          281,
          296,
          14727,
          1570,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.24215476026812804,
        "compression_ratio": 1.6335403726708075,
        "end": 4586.22,
        "id": 1315,
        "no_speech_prob": 0.008187059313058853,
        "seek": 458422,
        "start": 4584.22,
        "temperature": 0,
        "text": " So, um...",
        "tokens": [
          50364,
          407,
          11,
          1105,
          485,
          50464
        ]
      },
      {
        "avg_logprob": -0.24215476026812804,
        "compression_ratio": 1.6335403726708075,
        "end": 4594.22,
        "id": 1316,
        "no_speech_prob": 0.008187059313058853,
        "seek": 458422,
        "start": 4592.22,
        "temperature": 0,
        "text": " Let me do this.",
        "tokens": [
          50764,
          961,
          385,
          360,
          341,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.24215476026812804,
        "compression_ratio": 1.6335403726708075,
        "end": 4598.22,
        "id": 1317,
        "no_speech_prob": 0.008187059313058853,
        "seek": 458422,
        "start": 4596.22,
        "temperature": 0,
        "text": " Oh, but that's not a real...",
        "tokens": [
          50964,
          876,
          11,
          457,
          300,
          311,
          406,
          257,
          957,
          485,
          51064
        ]
      },
      {
        "avg_logprob": -0.24215476026812804,
        "compression_ratio": 1.6335403726708075,
        "end": 4600.22,
        "id": 1318,
        "no_speech_prob": 0.008187059313058853,
        "seek": 458422,
        "start": 4598.22,
        "temperature": 0,
        "text": " Okay, so that's not a...",
        "tokens": [
          51064,
          1033,
          11,
          370,
          300,
          311,
          406,
          257,
          485,
          51164
        ]
      },
      {
        "avg_logprob": -0.24215476026812804,
        "compression_ratio": 1.6335403726708075,
        "end": 4602.22,
        "id": 1319,
        "no_speech_prob": 0.008187059313058853,
        "seek": 458422,
        "start": 4600.22,
        "temperature": 0,
        "text": " I was going to say that's not a real bug. It is a real bug.",
        "tokens": [
          51164,
          286,
          390,
          516,
          281,
          584,
          300,
          311,
          406,
          257,
          957,
          7426,
          13,
          467,
          307,
          257,
          957,
          7426,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.24215476026812804,
        "compression_ratio": 1.6335403726708075,
        "end": 4605.22,
        "id": 1320,
        "no_speech_prob": 0.008187059313058853,
        "seek": 458422,
        "start": 4602.22,
        "temperature": 0,
        "text": " But it's not a bug that I feel that I need to fix.",
        "tokens": [
          51264,
          583,
          309,
          311,
          406,
          257,
          7426,
          300,
          286,
          841,
          300,
          286,
          643,
          281,
          3191,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.24215476026812804,
        "compression_ratio": 1.6335403726708075,
        "end": 4607.22,
        "id": 1321,
        "no_speech_prob": 0.008187059313058853,
        "seek": 458422,
        "start": 4605.22,
        "temperature": 0,
        "text": " It is... So let me go to this.",
        "tokens": [
          51414,
          467,
          307,
          485,
          407,
          718,
          385,
          352,
          281,
          341,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.24215476026812804,
        "compression_ratio": 1.6335403726708075,
        "end": 4609.22,
        "id": 1322,
        "no_speech_prob": 0.008187059313058853,
        "seek": 458422,
        "start": 4607.22,
        "temperature": 0,
        "text": " I mean, now I'm sort of...",
        "tokens": [
          51514,
          286,
          914,
          11,
          586,
          286,
          478,
          1333,
          295,
          485,
          51614
        ]
      },
      {
        "avg_logprob": -0.24215476026812804,
        "compression_ratio": 1.6335403726708075,
        "end": 4613.22,
        "id": 1323,
        "no_speech_prob": 0.008187059313058853,
        "seek": 458422,
        "start": 4611.22,
        "temperature": 0,
        "text": " Oh, number 98.",
        "tokens": [
          51714,
          876,
          11,
          1230,
          20860,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.16406581166026357,
        "compression_ratio": 1.4689265536723164,
        "end": 4615.22,
        "id": 1324,
        "no_speech_prob": 0.001410347525961697,
        "seek": 461322,
        "start": 4613.22,
        "temperature": 0,
        "text": " Where did all the issues go?",
        "tokens": [
          50364,
          2305,
          630,
          439,
          264,
          2663,
          352,
          30,
          50464
        ]
      },
      {
        "avg_logprob": -0.16406581166026357,
        "compression_ratio": 1.4689265536723164,
        "end": 4617.22,
        "id": 1325,
        "no_speech_prob": 0.001410347525961697,
        "seek": 461322,
        "start": 4615.22,
        "temperature": 0,
        "text": " Oh, that's on CodingTrain website.",
        "tokens": [
          50464,
          876,
          11,
          300,
          311,
          322,
          383,
          8616,
          51,
          7146,
          3144,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.16406581166026357,
        "compression_ratio": 1.4689265536723164,
        "end": 4621.22,
        "id": 1326,
        "no_speech_prob": 0.001410347525961697,
        "seek": 461322,
        "start": 4619.22,
        "temperature": 0,
        "text": " So let's discuss this for a second.",
        "tokens": [
          50664,
          407,
          718,
          311,
          2248,
          341,
          337,
          257,
          1150,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.16406581166026357,
        "compression_ratio": 1.4689265536723164,
        "end": 4626.22,
        "id": 1327,
        "no_speech_prob": 0.001410347525961697,
        "seek": 461322,
        "start": 4624.22,
        "temperature": 0,
        "text": " Yeah.",
        "tokens": [
          50914,
          865,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.16406581166026357,
        "compression_ratio": 1.4689265536723164,
        "end": 4628.22,
        "id": 1328,
        "no_speech_prob": 0.001410347525961697,
        "seek": 461322,
        "start": 4626.22,
        "temperature": 0,
        "text": " So this, I don't...",
        "tokens": [
          51014,
          407,
          341,
          11,
          286,
          500,
          380,
          485,
          51114
        ]
      },
      {
        "avg_logprob": -0.16406581166026357,
        "compression_ratio": 1.4689265536723164,
        "end": 4630.22,
        "id": 1329,
        "no_speech_prob": 0.001410347525961697,
        "seek": 461322,
        "start": 4628.22,
        "temperature": 0,
        "text": " This is a great...",
        "tokens": [
          51114,
          639,
          307,
          257,
          869,
          485,
          51214
        ]
      },
      {
        "avg_logprob": -0.16406581166026357,
        "compression_ratio": 1.4689265536723164,
        "end": 4631.22,
        "id": 1330,
        "no_speech_prob": 0.001410347525961697,
        "seek": 461322,
        "start": 4630.22,
        "temperature": 0,
        "text": " Whoa.",
        "tokens": [
          51214,
          7521,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.16406581166026357,
        "compression_ratio": 1.4689265536723164,
        "end": 4633.22,
        "id": 1331,
        "no_speech_prob": 0.001410347525961697,
        "seek": 461322,
        "start": 4631.22,
        "temperature": 0,
        "text": " So this is a really great point.",
        "tokens": [
          51264,
          407,
          341,
          307,
          257,
          534,
          869,
          935,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.16406581166026357,
        "compression_ratio": 1.4689265536723164,
        "end": 4636.22,
        "id": 1332,
        "no_speech_prob": 0.001410347525961697,
        "seek": 461322,
        "start": 4633.22,
        "temperature": 0,
        "text": " And maybe I should open the video with this.",
        "tokens": [
          51364,
          400,
          1310,
          286,
          820,
          1269,
          264,
          960,
          365,
          341,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.16406581166026357,
        "compression_ratio": 1.4689265536723164,
        "end": 4640.22,
        "id": 1333,
        "no_speech_prob": 0.001410347525961697,
        "seek": 461322,
        "start": 4638.22,
        "temperature": 0,
        "text": " And let me try to explain this.",
        "tokens": [
          51614,
          400,
          718,
          385,
          853,
          281,
          2903,
          341,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.2418625986474192,
        "compression_ratio": 1.7366255144032923,
        "end": 4645.22,
        "id": 1334,
        "no_speech_prob": 0.0014550096821039915,
        "seek": 464022,
        "start": 4640.22,
        "temperature": 0,
        "text": " So the quadTree that I made does not continuously pass...",
        "tokens": [
          50364,
          407,
          264,
          10787,
          51,
          701,
          300,
          286,
          1027,
          775,
          406,
          15684,
          1320,
          485,
          50614
        ]
      },
      {
        "avg_logprob": -0.2418625986474192,
        "compression_ratio": 1.7366255144032923,
        "end": 4647.22,
        "id": 1335,
        "no_speech_prob": 0.0014550096821039915,
        "seek": 464022,
        "start": 4645.22,
        "temperature": 0,
        "text": " And I apologize.",
        "tokens": [
          50614,
          400,
          286,
          12328,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.2418625986474192,
        "compression_ratio": 1.7366255144032923,
        "end": 4650.22,
        "id": 1336,
        "no_speech_prob": 0.0014550096821039915,
        "seek": 464022,
        "start": 4647.22,
        "temperature": 0,
        "text": " If you're tuning in this live stream and you didn't watch the quadTree live stream",
        "tokens": [
          50714,
          759,
          291,
          434,
          15164,
          294,
          341,
          1621,
          4309,
          293,
          291,
          994,
          380,
          1159,
          264,
          10787,
          51,
          701,
          1621,
          4309,
          50864
        ]
      },
      {
        "avg_logprob": -0.2418625986474192,
        "compression_ratio": 1.7366255144032923,
        "end": 4653.22,
        "id": 1337,
        "no_speech_prob": 0.0014550096821039915,
        "seek": 464022,
        "start": 4650.22,
        "temperature": 0,
        "text": " or the quadTree videos, you probably have no idea what I'm talking about.",
        "tokens": [
          50864,
          420,
          264,
          10787,
          51,
          701,
          2145,
          11,
          291,
          1391,
          362,
          572,
          1558,
          437,
          286,
          478,
          1417,
          466,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.2418625986474192,
        "compression_ratio": 1.7366255144032923,
        "end": 4655.22,
        "id": 1338,
        "no_speech_prob": 0.0014550096821039915,
        "seek": 464022,
        "start": 4653.22,
        "temperature": 0,
        "text": " So I apologize for that.",
        "tokens": [
          51014,
          407,
          286,
          12328,
          337,
          300,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.2418625986474192,
        "compression_ratio": 1.7366255144032923,
        "end": 4657.22,
        "id": 1339,
        "no_speech_prob": 0.0014550096821039915,
        "seek": 464022,
        "start": 4655.22,
        "temperature": 0,
        "text": " But I suggest you go back and watch those if you're interested.",
        "tokens": [
          51114,
          583,
          286,
          3402,
          291,
          352,
          646,
          293,
          1159,
          729,
          498,
          291,
          434,
          3102,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.2418625986474192,
        "compression_ratio": 1.7366255144032923,
        "end": 4662.22,
        "id": 1340,
        "no_speech_prob": 0.0014550096821039915,
        "seek": 464022,
        "start": 4657.22,
        "temperature": 0,
        "text": " But the quadTree is a data structure that stores...",
        "tokens": [
          51214,
          583,
          264,
          10787,
          51,
          701,
          307,
          257,
          1412,
          3877,
          300,
          9512,
          485,
          51464
        ]
      },
      {
        "avg_logprob": -0.2418625986474192,
        "compression_ratio": 1.7366255144032923,
        "end": 4667.22,
        "id": 1341,
        "no_speech_prob": 0.0014550096821039915,
        "seek": 464022,
        "start": 4664.22,
        "temperature": 0,
        "text": "...points in, in my case, in two-dimensional space",
        "tokens": [
          51564,
          1097,
          20552,
          294,
          11,
          294,
          452,
          1389,
          11,
          294,
          732,
          12,
          18759,
          1901,
          51714
        ]
      },
      {
        "avg_logprob": -0.1946640383812689,
        "compression_ratio": 1.9710144927536233,
        "end": 4669.22,
        "id": 1342,
        "no_speech_prob": 0.0002652981202118099,
        "seek": 466722,
        "start": 4667.22,
        "temperature": 0,
        "text": " into the leaves of this tree.",
        "tokens": [
          50364,
          666,
          264,
          5510,
          295,
          341,
          4230,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.1946640383812689,
        "compression_ratio": 1.9710144927536233,
        "end": 4675.22,
        "id": 1343,
        "no_speech_prob": 0.0002652981202118099,
        "seek": 466722,
        "start": 4669.22,
        "temperature": 0,
        "text": " It's constantly subdividing sections of the canvas into fours.",
        "tokens": [
          50464,
          467,
          311,
          6460,
          31662,
          1843,
          278,
          10863,
          295,
          264,
          16267,
          666,
          1451,
          82,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.1946640383812689,
        "compression_ratio": 1.9710144927536233,
        "end": 4678.22,
        "id": 1344,
        "no_speech_prob": 0.0002652981202118099,
        "seek": 466722,
        "start": 4675.22,
        "temperature": 0,
        "text": " And then if there's too many points there, it subdivides again into fours.",
        "tokens": [
          50764,
          400,
          550,
          498,
          456,
          311,
          886,
          867,
          2793,
          456,
          11,
          309,
          31662,
          1843,
          279,
          797,
          666,
          1451,
          82,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.1946640383812689,
        "compression_ratio": 1.9710144927536233,
        "end": 4680.22,
        "id": 1345,
        "no_speech_prob": 0.0002652981202118099,
        "seek": 466722,
        "start": 4678.22,
        "temperature": 0,
        "text": " If there's too many points there, it subdivides again into fours.",
        "tokens": [
          50914,
          759,
          456,
          311,
          886,
          867,
          2793,
          456,
          11,
          309,
          31662,
          1843,
          279,
          797,
          666,
          1451,
          82,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.1946640383812689,
        "compression_ratio": 1.9710144927536233,
        "end": 4682.22,
        "id": 1346,
        "no_speech_prob": 0.0002652981202118099,
        "seek": 466722,
        "start": 4680.22,
        "temperature": 0,
        "text": " And it has a capacity variable like four.",
        "tokens": [
          51014,
          400,
          309,
          575,
          257,
          6042,
          7006,
          411,
          1451,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.1946640383812689,
        "compression_ratio": 1.9710144927536233,
        "end": 4684.22,
        "id": 1347,
        "no_speech_prob": 0.0002652981202118099,
        "seek": 466722,
        "start": 4682.22,
        "temperature": 0,
        "text": " I actually used... I mean, that's a coincidence.",
        "tokens": [
          51114,
          286,
          767,
          1143,
          485,
          286,
          914,
          11,
          300,
          311,
          257,
          22137,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.1946640383812689,
        "compression_ratio": 1.9710144927536233,
        "end": 4686.22,
        "id": 1348,
        "no_speech_prob": 0.0002652981202118099,
        "seek": 466722,
        "start": 4684.22,
        "temperature": 0,
        "text": " I could have made it five, could have made it three.",
        "tokens": [
          51214,
          286,
          727,
          362,
          1027,
          309,
          1732,
          11,
          727,
          362,
          1027,
          309,
          1045,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.1946640383812689,
        "compression_ratio": 1.9710144927536233,
        "end": 4688.22,
        "id": 1349,
        "no_speech_prob": 0.0002652981202118099,
        "seek": 466722,
        "start": 4686.22,
        "temperature": 0,
        "text": " QuadTree is dividing into four.",
        "tokens": [
          51314,
          29619,
          51,
          701,
          307,
          26764,
          666,
          1451,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.1946640383812689,
        "compression_ratio": 1.9710144927536233,
        "end": 4691.22,
        "id": 1350,
        "no_speech_prob": 0.0002652981202118099,
        "seek": 466722,
        "start": 4688.22,
        "temperature": 0,
        "text": " But I also have to use that capacity for each leaf as having four.",
        "tokens": [
          51414,
          583,
          286,
          611,
          362,
          281,
          764,
          300,
          6042,
          337,
          1184,
          10871,
          382,
          1419,
          1451,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.1946640383812689,
        "compression_ratio": 1.9710144927536233,
        "end": 4693.22,
        "id": 1351,
        "no_speech_prob": 0.0002652981202118099,
        "seek": 466722,
        "start": 4691.22,
        "temperature": 0,
        "text": " So this looks like this should be a mistake, right?",
        "tokens": [
          51564,
          407,
          341,
          1542,
          411,
          341,
          820,
          312,
          257,
          6146,
          11,
          558,
          30,
          51664
        ]
      },
      {
        "avg_logprob": -0.1946640383812689,
        "compression_ratio": 1.9710144927536233,
        "end": 4695.22,
        "id": 1352,
        "no_speech_prob": 0.0002652981202118099,
        "seek": 466722,
        "start": 4693.22,
        "temperature": 0,
        "text": " This is a leaf.",
        "tokens": [
          51664,
          639,
          307,
          257,
          10871,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.17987245226663257,
        "compression_ratio": 1.739622641509434,
        "end": 4697.22,
        "id": 1353,
        "no_speech_prob": 0.05032903701066971,
        "seek": 469522,
        "start": 4695.22,
        "temperature": 0,
        "text": " How could there possibly be more than four?",
        "tokens": [
          50364,
          1012,
          727,
          456,
          6264,
          312,
          544,
          813,
          1451,
          30,
          50464
        ]
      },
      {
        "avg_logprob": -0.17987245226663257,
        "compression_ratio": 1.739622641509434,
        "end": 4700.22,
        "id": 1354,
        "no_speech_prob": 0.05032903701066971,
        "seek": 469522,
        "start": 4697.22,
        "temperature": 0,
        "text": " Even if we kind of are generous and say that these are in...",
        "tokens": [
          50464,
          2754,
          498,
          321,
          733,
          295,
          366,
          14537,
          293,
          584,
          300,
          613,
          366,
          294,
          485,
          50614
        ]
      },
      {
        "avg_logprob": -0.17987245226663257,
        "compression_ratio": 1.739622641509434,
        "end": 4703.22,
        "id": 1355,
        "no_speech_prob": 0.05032903701066971,
        "seek": 469522,
        "start": 4700.22,
        "temperature": 0,
        "text": "...these are just drawn in a weird way and they're actually in the other ones,",
        "tokens": [
          50614,
          1097,
          42678,
          366,
          445,
          10117,
          294,
          257,
          3657,
          636,
          293,
          436,
          434,
          767,
          294,
          264,
          661,
          2306,
          11,
          50764
        ]
      },
      {
        "avg_logprob": -0.17987245226663257,
        "compression_ratio": 1.739622641509434,
        "end": 4706.22,
        "id": 1356,
        "no_speech_prob": 0.05032903701066971,
        "seek": 469522,
        "start": 4703.22,
        "temperature": 0,
        "text": " there's still one, two, three, four, five, six.",
        "tokens": [
          50764,
          456,
          311,
          920,
          472,
          11,
          732,
          11,
          1045,
          11,
          1451,
          11,
          1732,
          11,
          2309,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.17987245226663257,
        "compression_ratio": 1.739622641509434,
        "end": 4710.22,
        "id": 1357,
        "no_speech_prob": 0.05032903701066971,
        "seek": 469522,
        "start": 4706.22,
        "temperature": 0,
        "text": " And the reason that this is the case is that a bunch of these",
        "tokens": [
          50914,
          400,
          264,
          1778,
          300,
          341,
          307,
          264,
          1389,
          307,
          300,
          257,
          3840,
          295,
          613,
          51114
        ]
      },
      {
        "avg_logprob": -0.17987245226663257,
        "compression_ratio": 1.739622641509434,
        "end": 4715.22,
        "id": 1358,
        "no_speech_prob": 0.05032903701066971,
        "seek": 469522,
        "start": 4710.22,
        "temperature": 0,
        "text": " are likely actually in this node, this larger space.",
        "tokens": [
          51114,
          366,
          3700,
          767,
          294,
          341,
          9984,
          11,
          341,
          4833,
          1901,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.17987245226663257,
        "compression_ratio": 1.739622641509434,
        "end": 4718.22,
        "id": 1359,
        "no_speech_prob": 0.05032903701066971,
        "seek": 469522,
        "start": 4715.22,
        "temperature": 0,
        "text": " Because when I subdivide a node into four,",
        "tokens": [
          51364,
          1436,
          562,
          286,
          45331,
          482,
          257,
          9984,
          666,
          1451,
          11,
          51514
        ]
      },
      {
        "avg_logprob": -0.17987245226663257,
        "compression_ratio": 1.739622641509434,
        "end": 4722.22,
        "id": 1360,
        "no_speech_prob": 0.05032903701066971,
        "seek": 469522,
        "start": 4718.22,
        "temperature": 0,
        "text": " I don't take the points that are in that parent node and pass them down.",
        "tokens": [
          51514,
          286,
          500,
          380,
          747,
          264,
          2793,
          300,
          366,
          294,
          300,
          2596,
          9984,
          293,
          1320,
          552,
          760,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.16298059054783412,
        "compression_ratio": 1.7004219409282701,
        "end": 4724.22,
        "id": 1361,
        "no_speech_prob": 0.00041731371311470866,
        "seek": 472222,
        "start": 4722.22,
        "temperature": 0,
        "text": " I could do that.",
        "tokens": [
          50364,
          286,
          727,
          360,
          300,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.16298059054783412,
        "compression_ratio": 1.7004219409282701,
        "end": 4729.22,
        "id": 1362,
        "no_speech_prob": 0.00041731371311470866,
        "seek": 472222,
        "start": 4724.22,
        "temperature": 0,
        "text": " And there's a case to be made for that being more correct or more efficient.",
        "tokens": [
          50464,
          400,
          456,
          311,
          257,
          1389,
          281,
          312,
          1027,
          337,
          300,
          885,
          544,
          3006,
          420,
          544,
          7148,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.16298059054783412,
        "compression_ratio": 1.7004219409282701,
        "end": 4732.22,
        "id": 1363,
        "no_speech_prob": 0.00041731371311470866,
        "seek": 472222,
        "start": 4729.22,
        "temperature": 0,
        "text": " But in terms of writing the code in a simple way,",
        "tokens": [
          50714,
          583,
          294,
          2115,
          295,
          3579,
          264,
          3089,
          294,
          257,
          2199,
          636,
          11,
          50864
        ]
      },
      {
        "avg_logprob": -0.16298059054783412,
        "compression_ratio": 1.7004219409282701,
        "end": 4734.22,
        "id": 1364,
        "no_speech_prob": 0.00041731371311470866,
        "seek": 472222,
        "start": 4732.22,
        "temperature": 0,
        "text": " it's much easier to just not bother with that.",
        "tokens": [
          50864,
          309,
          311,
          709,
          3571,
          281,
          445,
          406,
          8677,
          365,
          300,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.16298059054783412,
        "compression_ratio": 1.7004219409282701,
        "end": 4739.22,
        "id": 1365,
        "no_speech_prob": 0.00041731371311470866,
        "seek": 472222,
        "start": 4734.22,
        "temperature": 0,
        "text": " And I get enough of a speed improvement without doing that",
        "tokens": [
          50964,
          400,
          286,
          483,
          1547,
          295,
          257,
          3073,
          10444,
          1553,
          884,
          300,
          51214
        ]
      },
      {
        "avg_logprob": -0.16298059054783412,
        "compression_ratio": 1.7004219409282701,
        "end": 4743.22,
        "id": 1366,
        "no_speech_prob": 0.00041731371311470866,
        "seek": 472222,
        "start": 4739.22,
        "temperature": 0,
        "text": " that I don't need to. I didn't bother.",
        "tokens": [
          51214,
          300,
          286,
          500,
          380,
          643,
          281,
          13,
          286,
          994,
          380,
          8677,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.16298059054783412,
        "compression_ratio": 1.7004219409282701,
        "end": 4746.22,
        "id": 1367,
        "no_speech_prob": 0.00041731371311470866,
        "seek": 472222,
        "start": 4743.22,
        "temperature": 0,
        "text": " I'm not doing this to try to make this perfect visualization.",
        "tokens": [
          51414,
          286,
          478,
          406,
          884,
          341,
          281,
          853,
          281,
          652,
          341,
          2176,
          25801,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.16298059054783412,
        "compression_ratio": 1.7004219409282701,
        "end": 4749.22,
        "id": 1368,
        "no_speech_prob": 0.00041731371311470866,
        "seek": 472222,
        "start": 4746.22,
        "temperature": 0,
        "text": " I'm just trying to do this to make looking at the...",
        "tokens": [
          51564,
          286,
          478,
          445,
          1382,
          281,
          360,
          341,
          281,
          652,
          1237,
          412,
          264,
          485,
          51714
        ]
      },
      {
        "avg_logprob": -0.18418539724042338,
        "compression_ratio": 1.7276595744680852,
        "end": 4752.22,
        "id": 1369,
        "no_speech_prob": 0.00003647777339210734,
        "seek": 474922,
        "start": 4750.22,
        "temperature": 0,
        "text": " I'm just doing this to...",
        "tokens": [
          50414,
          286,
          478,
          445,
          884,
          341,
          281,
          485,
          50514
        ]
      },
      {
        "avg_logprob": -0.18418539724042338,
        "compression_ratio": 1.7276595744680852,
        "end": 4755.22,
        "id": 1370,
        "no_speech_prob": 0.00003647777339210734,
        "seek": 474922,
        "start": 4752.22,
        "temperature": 0,
        "text": " I'm reading the chat at the same time, which I should never do.",
        "tokens": [
          50514,
          286,
          478,
          3760,
          264,
          5081,
          412,
          264,
          912,
          565,
          11,
          597,
          286,
          820,
          1128,
          360,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.18418539724042338,
        "compression_ratio": 1.7276595744680852,
        "end": 4757.22,
        "id": 1371,
        "no_speech_prob": 0.00003647777339210734,
        "seek": 474922,
        "start": 4755.22,
        "temperature": 0,
        "text": " I'm doing this to...",
        "tokens": [
          50664,
          286,
          478,
          884,
          341,
          281,
          485,
          50764
        ]
      },
      {
        "avg_logprob": -0.18418539724042338,
        "compression_ratio": 1.7276595744680852,
        "end": 4759.22,
        "id": 1372,
        "no_speech_prob": 0.00003647777339210734,
        "seek": 474922,
        "start": 4757.22,
        "temperature": 0,
        "text": " Why am I doing this?",
        "tokens": [
          50764,
          1545,
          669,
          286,
          884,
          341,
          30,
          50864
        ]
      },
      {
        "avg_logprob": -0.18418539724042338,
        "compression_ratio": 1.7276595744680852,
        "end": 4762.22,
        "id": 1373,
        "no_speech_prob": 0.00003647777339210734,
        "seek": 474922,
        "start": 4759.22,
        "temperature": 0,
        "text": " I'm doing this to try to make a collision detection example faster.",
        "tokens": [
          50864,
          286,
          478,
          884,
          341,
          281,
          853,
          281,
          652,
          257,
          24644,
          17784,
          1365,
          4663,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.18418539724042338,
        "compression_ratio": 1.7276595744680852,
        "end": 4766.22,
        "id": 1374,
        "no_speech_prob": 0.00003647777339210734,
        "seek": 474922,
        "start": 4762.22,
        "temperature": 0,
        "text": " And I can show you that even with this quote-unquote bug,",
        "tokens": [
          51014,
          400,
          286,
          393,
          855,
          291,
          300,
          754,
          365,
          341,
          6513,
          12,
          409,
          25016,
          7426,
          11,
          51214
        ]
      },
      {
        "avg_logprob": -0.18418539724042338,
        "compression_ratio": 1.7276595744680852,
        "end": 4769.22,
        "id": 1375,
        "no_speech_prob": 0.00003647777339210734,
        "seek": 474922,
        "start": 4766.22,
        "temperature": 0,
        "text": " if I go to my quadtree repo...",
        "tokens": [
          51214,
          498,
          286,
          352,
          281,
          452,
          10787,
          83,
          701,
          49040,
          485,
          51364
        ]
      },
      {
        "avg_logprob": -0.18418539724042338,
        "compression_ratio": 1.7276595744680852,
        "end": 4775.22,
        "id": 1376,
        "no_speech_prob": 0.00003647777339210734,
        "seek": 474922,
        "start": 4771.22,
        "temperature": 0,
        "text": "...and I go here, I've actually made this example already",
        "tokens": [
          51464,
          1097,
          474,
          286,
          352,
          510,
          11,
          286,
          600,
          767,
          1027,
          341,
          1365,
          1217,
          51664
        ]
      },
      {
        "avg_logprob": -0.18418539724042338,
        "compression_ratio": 1.7276595744680852,
        "end": 4778.22,
        "id": 1377,
        "no_speech_prob": 0.00003647777339210734,
        "seek": 474922,
        "start": 4775.22,
        "temperature": 0,
        "text": " just to test if it would even work. I'm going to go to demo.",
        "tokens": [
          51664,
          445,
          281,
          1500,
          498,
          309,
          576,
          754,
          589,
          13,
          286,
          478,
          516,
          281,
          352,
          281,
          10723,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.15276932201797155,
        "compression_ratio": 1.814516129032258,
        "end": 4785.22,
        "id": 1378,
        "no_speech_prob": 0.00011060958058806136,
        "seek": 477822,
        "start": 4778.22,
        "temperature": 0,
        "text": " So this is now a p5 sketch, which has 1,000 dots in it.",
        "tokens": [
          50364,
          407,
          341,
          307,
          586,
          257,
          280,
          20,
          12325,
          11,
          597,
          575,
          502,
          11,
          1360,
          15026,
          294,
          309,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.15276932201797155,
        "compression_ratio": 1.814516129032258,
        "end": 4788.22,
        "id": 1379,
        "no_speech_prob": 0.00011060958058806136,
        "seek": 477822,
        "start": 4785.22,
        "temperature": 0,
        "text": " And every dot is checking if it's intersecting another dot.",
        "tokens": [
          50714,
          400,
          633,
          5893,
          307,
          8568,
          498,
          309,
          311,
          27815,
          278,
          1071,
          5893,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.15276932201797155,
        "compression_ratio": 1.814516129032258,
        "end": 4790.22,
        "id": 1380,
        "no_speech_prob": 0.00011060958058806136,
        "seek": 477822,
        "start": 4788.22,
        "temperature": 0,
        "text": " And if it is, it lights up.",
        "tokens": [
          50864,
          400,
          498,
          309,
          307,
          11,
          309,
          5811,
          493,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.15276932201797155,
        "compression_ratio": 1.814516129032258,
        "end": 4792.22,
        "id": 1381,
        "no_speech_prob": 0.00011060958058806136,
        "seek": 477822,
        "start": 4790.22,
        "temperature": 0,
        "text": " And it's using the quadtree data structure right now.",
        "tokens": [
          50964,
          400,
          309,
          311,
          1228,
          264,
          10787,
          83,
          701,
          1412,
          3877,
          558,
          586,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.15276932201797155,
        "compression_ratio": 1.814516129032258,
        "end": 4794.22,
        "id": 1382,
        "no_speech_prob": 0.00011060958058806136,
        "seek": 477822,
        "start": 4792.22,
        "temperature": 0,
        "text": " Let me just uncheck this checkmark.",
        "tokens": [
          51064,
          961,
          385,
          445,
          46672,
          341,
          1520,
          5638,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.15276932201797155,
        "compression_ratio": 1.814516129032258,
        "end": 4797.22,
        "id": 1383,
        "no_speech_prob": 0.00011060958058806136,
        "seek": 477822,
        "start": 4794.22,
        "temperature": 0,
        "text": " And you can see right now, without the quadtree data structure,",
        "tokens": [
          51164,
          400,
          291,
          393,
          536,
          558,
          586,
          11,
          1553,
          264,
          10787,
          83,
          701,
          1412,
          3877,
          11,
          51314
        ]
      },
      {
        "avg_logprob": -0.15276932201797155,
        "compression_ratio": 1.814516129032258,
        "end": 4799.22,
        "id": 1384,
        "no_speech_prob": 0.00011060958058806136,
        "seek": 477822,
        "start": 4797.22,
        "temperature": 0,
        "text": " I'm getting a frame rate of 5.",
        "tokens": [
          51314,
          286,
          478,
          1242,
          257,
          3920,
          3314,
          295,
          1025,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.15276932201797155,
        "compression_ratio": 1.814516129032258,
        "end": 4801.22,
        "id": 1385,
        "no_speech_prob": 0.00011060958058806136,
        "seek": 477822,
        "start": 4799.22,
        "temperature": 0,
        "text": " With the quadtree data structure, I'm getting...",
        "tokens": [
          51414,
          2022,
          264,
          10787,
          83,
          701,
          1412,
          3877,
          11,
          286,
          478,
          1242,
          485,
          51514
        ]
      },
      {
        "avg_logprob": -0.15276932201797155,
        "compression_ratio": 1.814516129032258,
        "end": 4804.22,
        "id": 1386,
        "no_speech_prob": 0.00011060958058806136,
        "seek": 477822,
        "start": 4801.22,
        "temperature": 0,
        "text": " And let's just move down and see if we can...",
        "tokens": [
          51514,
          400,
          718,
          311,
          445,
          1286,
          760,
          293,
          536,
          498,
          321,
          393,
          485,
          51664
        ]
      },
      {
        "avg_logprob": -0.15276932201797155,
        "compression_ratio": 1.814516129032258,
        "end": 4806.22,
        "id": 1387,
        "no_speech_prob": 0.00011060958058806136,
        "seek": 477822,
        "start": 4804.22,
        "temperature": 0,
        "text": " Oh, I think it might be...",
        "tokens": [
          51664,
          876,
          11,
          286,
          519,
          309,
          1062,
          312,
          485,
          51764
        ]
      },
      {
        "avg_logprob": -0.2006104656101502,
        "compression_ratio": 1.4837209302325582,
        "end": 4811.22,
        "id": 1388,
        "no_speech_prob": 0.00001922308911161963,
        "seek": 480622,
        "start": 4806.22,
        "temperature": 0,
        "text": " You can see, even with 2,500, I'm getting a pretty decent frame rate.",
        "tokens": [
          50364,
          509,
          393,
          536,
          11,
          754,
          365,
          568,
          11,
          7526,
          11,
          286,
          478,
          1242,
          257,
          1238,
          8681,
          3920,
          3314,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.2006104656101502,
        "compression_ratio": 1.4837209302325582,
        "end": 4813.22,
        "id": 1389,
        "no_speech_prob": 0.00001922308911161963,
        "seek": 480622,
        "start": 4811.22,
        "temperature": 0,
        "text": " If I take off the quadtree...",
        "tokens": [
          50614,
          759,
          286,
          747,
          766,
          264,
          10787,
          83,
          701,
          485,
          50714
        ]
      },
      {
        "avg_logprob": -0.2006104656101502,
        "compression_ratio": 1.4837209302325582,
        "end": 4818.22,
        "id": 1390,
        "no_speech_prob": 0.00001922308911161963,
        "seek": 480622,
        "start": 4813.22,
        "temperature": 0,
        "text": " Forget it. The frame rate is basically one frame per second, even at best.",
        "tokens": [
          50714,
          18675,
          309,
          13,
          440,
          3920,
          3314,
          307,
          1936,
          472,
          3920,
          680,
          1150,
          11,
          754,
          412,
          1151,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.2006104656101502,
        "compression_ratio": 1.4837209302325582,
        "end": 4822.22,
        "id": 1391,
        "no_speech_prob": 0.00001922308911161963,
        "seek": 480622,
        "start": 4820.22,
        "temperature": 0,
        "text": " I feel that my code does the job.",
        "tokens": [
          51064,
          286,
          841,
          300,
          452,
          3089,
          775,
          264,
          1691,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.2006104656101502,
        "compression_ratio": 1.4837209302325582,
        "end": 4827.22,
        "id": 1392,
        "no_speech_prob": 0.00001922308911161963,
        "seek": 480622,
        "start": 4822.22,
        "temperature": 0,
        "text": " Does it do it the best way, the most optimal way?",
        "tokens": [
          51164,
          4402,
          309,
          360,
          309,
          264,
          1151,
          636,
          11,
          264,
          881,
          16252,
          636,
          30,
          51414
        ]
      },
      {
        "avg_logprob": -0.2006104656101502,
        "compression_ratio": 1.4837209302325582,
        "end": 4829.22,
        "id": 1393,
        "no_speech_prob": 0.00001922308911161963,
        "seek": 480622,
        "start": 4827.22,
        "temperature": 0,
        "text": " I'm not entirely sure.",
        "tokens": [
          51414,
          286,
          478,
          406,
          7696,
          988,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.2006104656101502,
        "compression_ratio": 1.4837209302325582,
        "end": 4834.22,
        "id": 1394,
        "no_speech_prob": 0.00001922308911161963,
        "seek": 480622,
        "start": 4832.22,
        "temperature": 0,
        "text": " Okay, so hopefully that explained it.",
        "tokens": [
          51664,
          1033,
          11,
          370,
          4696,
          300,
          8825,
          309,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.19143562657492502,
        "compression_ratio": 1.4959016393442623,
        "end": 4837.22,
        "id": 1395,
        "no_speech_prob": 0.00009461163426749408,
        "seek": 483422,
        "start": 4834.22,
        "temperature": 0,
        "text": " Oh, there are flocking examples in the poll requests.",
        "tokens": [
          50364,
          876,
          11,
          456,
          366,
          2591,
          25723,
          5110,
          294,
          264,
          6418,
          12475,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.19143562657492502,
        "compression_ratio": 1.4959016393442623,
        "end": 4842.22,
        "id": 1396,
        "no_speech_prob": 0.00009461163426749408,
        "seek": 483422,
        "start": 4840.22,
        "temperature": 0,
        "text": " Empirist Academy, what is your idea?",
        "tokens": [
          50664,
          8599,
          347,
          468,
          11735,
          11,
          437,
          307,
          428,
          1558,
          30,
          50764
        ]
      },
      {
        "avg_logprob": -0.19143562657492502,
        "compression_ratio": 1.4959016393442623,
        "end": 4845.22,
        "id": 1397,
        "no_speech_prob": 0.00009461163426749408,
        "seek": 483422,
        "start": 4842.22,
        "temperature": 0,
        "text": " I missed it. I'm really not following the chat, I should say.",
        "tokens": [
          50764,
          286,
          6721,
          309,
          13,
          286,
          478,
          534,
          406,
          3480,
          264,
          5081,
          11,
          286,
          820,
          584,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.19143562657492502,
        "compression_ratio": 1.4959016393442623,
        "end": 4847.22,
        "id": 1398,
        "no_speech_prob": 0.00009461163426749408,
        "seek": 483422,
        "start": 4845.22,
        "temperature": 0,
        "text": " I look over here every once in a while.",
        "tokens": [
          50914,
          286,
          574,
          670,
          510,
          633,
          1564,
          294,
          257,
          1339,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.19143562657492502,
        "compression_ratio": 1.4959016393442623,
        "end": 4850.22,
        "id": 1399,
        "no_speech_prob": 0.00009461163426749408,
        "seek": 483422,
        "start": 4847.22,
        "temperature": 0,
        "text": " So the question now is, with my 10 minutes,",
        "tokens": [
          51014,
          407,
          264,
          1168,
          586,
          307,
          11,
          365,
          452,
          1266,
          2077,
          11,
          51164
        ]
      },
      {
        "avg_logprob": -0.19143562657492502,
        "compression_ratio": 1.4959016393442623,
        "end": 4852.22,
        "id": 1400,
        "no_speech_prob": 0.00009461163426749408,
        "seek": 483422,
        "start": 4850.22,
        "temperature": 0,
        "text": " can I create this demonstration?",
        "tokens": [
          51164,
          393,
          286,
          1884,
          341,
          16520,
          30,
          51264
        ]
      },
      {
        "avg_logprob": -0.19143562657492502,
        "compression_ratio": 1.4959016393442623,
        "end": 4854.22,
        "id": 1401,
        "no_speech_prob": 0.00009461163426749408,
        "seek": 483422,
        "start": 4852.22,
        "temperature": 0,
        "text": " And I think that I can.",
        "tokens": [
          51264,
          400,
          286,
          519,
          300,
          286,
          393,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.19143562657492502,
        "compression_ratio": 1.4959016393442623,
        "end": 4858.22,
        "id": 1402,
        "no_speech_prob": 0.00009461163426749408,
        "seek": 483422,
        "start": 4856.22,
        "temperature": 0,
        "text": " I did have some other real bugs.",
        "tokens": [
          51464,
          286,
          630,
          362,
          512,
          661,
          957,
          15120,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.19143562657492502,
        "compression_ratio": 1.4959016393442623,
        "end": 4861.22,
        "id": 1403,
        "no_speech_prob": 0.00009461163426749408,
        "seek": 483422,
        "start": 4858.22,
        "temperature": 0,
        "text": " I'm sorry. I don't mean to say that...",
        "tokens": [
          51564,
          286,
          478,
          2597,
          13,
          286,
          500,
          380,
          914,
          281,
          584,
          300,
          485,
          51714
        ]
      },
      {
        "avg_logprob": -0.19630975341796875,
        "compression_ratio": 1.643939393939394,
        "end": 4865.22,
        "id": 1404,
        "no_speech_prob": 0.0010321587324142456,
        "seek": 486122,
        "start": 4861.22,
        "temperature": 0,
        "text": " If I'm not thoughtfully...",
        "tokens": [
          50364,
          759,
          286,
          478,
          406,
          1194,
          2277,
          485,
          50564
        ]
      },
      {
        "avg_logprob": -0.19630975341796875,
        "compression_ratio": 1.643939393939394,
        "end": 4870.22,
        "id": 1405,
        "no_speech_prob": 0.0010321587324142456,
        "seek": 486122,
        "start": 4867.22,
        "temperature": 0,
        "text": " I'm worried that I'm not being kind in my reply to this bug report,",
        "tokens": [
          50664,
          286,
          478,
          5804,
          300,
          286,
          478,
          406,
          885,
          733,
          294,
          452,
          16972,
          281,
          341,
          7426,
          2275,
          11,
          50814
        ]
      },
      {
        "avg_logprob": -0.19630975341796875,
        "compression_ratio": 1.643939393939394,
        "end": 4873.22,
        "id": 1406,
        "no_speech_prob": 0.0010321587324142456,
        "seek": 486122,
        "start": 4870.22,
        "temperature": 0,
        "text": " because that is an excellent GitHub issue to post,",
        "tokens": [
          50814,
          570,
          300,
          307,
          364,
          7103,
          23331,
          2734,
          281,
          2183,
          11,
          50964
        ]
      },
      {
        "avg_logprob": -0.19630975341796875,
        "compression_ratio": 1.643939393939394,
        "end": 4877.22,
        "id": 1407,
        "no_speech_prob": 0.0010321587324142456,
        "seek": 486122,
        "start": 4873.22,
        "temperature": 0,
        "text": " and merits a lot of discussion, and I don't even know if I'm right about this.",
        "tokens": [
          50964,
          293,
          40923,
          257,
          688,
          295,
          5017,
          11,
          293,
          286,
          500,
          380,
          754,
          458,
          498,
          286,
          478,
          558,
          466,
          341,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.19630975341796875,
        "compression_ratio": 1.643939393939394,
        "end": 4879.22,
        "id": 1408,
        "no_speech_prob": 0.0010321587324142456,
        "seek": 486122,
        "start": 4877.22,
        "temperature": 0,
        "text": " So that is an appropriate bug report.",
        "tokens": [
          51164,
          407,
          300,
          307,
          364,
          6854,
          7426,
          2275,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.19630975341796875,
        "compression_ratio": 1.643939393939394,
        "end": 4882.22,
        "id": 1409,
        "no_speech_prob": 0.0010321587324142456,
        "seek": 486122,
        "start": 4879.22,
        "temperature": 0,
        "text": " But in my point of view, I'm wondering if that's a bug,",
        "tokens": [
          51264,
          583,
          294,
          452,
          935,
          295,
          1910,
          11,
          286,
          478,
          6359,
          498,
          300,
          311,
          257,
          7426,
          11,
          51414
        ]
      },
      {
        "avg_logprob": -0.19630975341796875,
        "compression_ratio": 1.643939393939394,
        "end": 4885.22,
        "id": 1410,
        "no_speech_prob": 0.0010321587324142456,
        "seek": 486122,
        "start": 4882.22,
        "temperature": 0,
        "text": " or more of a question of how I want to design the algorithm.",
        "tokens": [
          51414,
          420,
          544,
          295,
          257,
          1168,
          295,
          577,
          286,
          528,
          281,
          1715,
          264,
          9284,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.19630975341796875,
        "compression_ratio": 1.643939393939394,
        "end": 4889.22,
        "id": 1411,
        "no_speech_prob": 0.0010321587324142456,
        "seek": 486122,
        "start": 4885.22,
        "temperature": 0,
        "text": " And in fact, if you go to the quadtree Wikipedia page,",
        "tokens": [
          51564,
          400,
          294,
          1186,
          11,
          498,
          291,
          352,
          281,
          264,
          10787,
          83,
          701,
          28999,
          3028,
          11,
          51764
        ]
      },
      {
        "avg_logprob": -0.16240057451971646,
        "compression_ratio": 1.768361581920904,
        "end": 4895.22,
        "id": 1412,
        "no_speech_prob": 0.000004157347575528547,
        "seek": 488922,
        "start": 4890.22,
        "temperature": 0,
        "text": " and you look at the pseudocode for the quadtree down here,",
        "tokens": [
          50414,
          293,
          291,
          574,
          412,
          264,
          25505,
          532,
          905,
          1429,
          337,
          264,
          10787,
          83,
          701,
          760,
          510,
          11,
          50664
        ]
      },
      {
        "avg_logprob": -0.16240057451971646,
        "compression_ratio": 1.768361581920904,
        "end": 4899.22,
        "id": 1413,
        "no_speech_prob": 0.000004157347575528547,
        "seek": 488922,
        "start": 4895.22,
        "temperature": 0,
        "text": " you will find that the insert function",
        "tokens": [
          50664,
          291,
          486,
          915,
          300,
          264,
          8969,
          2445,
          50864
        ]
      },
      {
        "avg_logprob": -0.16240057451971646,
        "compression_ratio": 1.768361581920904,
        "end": 4903.22,
        "id": 1414,
        "no_speech_prob": 0.000004157347575528547,
        "seek": 488922,
        "start": 4901.22,
        "temperature": 0,
        "text": " does not redistribute the points.",
        "tokens": [
          50964,
          775,
          406,
          36198,
          2024,
          1169,
          264,
          2793,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.16240057451971646,
        "compression_ratio": 1.768361581920904,
        "end": 4908.22,
        "id": 1415,
        "no_speech_prob": 0.000004157347575528547,
        "seek": 488922,
        "start": 4903.22,
        "temperature": 0,
        "text": " So this example Wikipedia version, pseudocode version of the quadtree algorithm",
        "tokens": [
          51064,
          407,
          341,
          1365,
          28999,
          3037,
          11,
          25505,
          532,
          905,
          1429,
          3037,
          295,
          264,
          10787,
          83,
          701,
          9284,
          51314
        ]
      },
      {
        "avg_logprob": -0.16240057451971646,
        "compression_ratio": 1.768361581920904,
        "end": 4911.22,
        "id": 1416,
        "no_speech_prob": 0.000004157347575528547,
        "seek": 488922,
        "start": 4908.22,
        "temperature": 0,
        "text": " does not redistribute points at the subdivision point.",
        "tokens": [
          51314,
          775,
          406,
          36198,
          2024,
          1169,
          2793,
          412,
          264,
          45331,
          1991,
          935,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.16240057451971646,
        "compression_ratio": 1.768361581920904,
        "end": 4914.22,
        "id": 1417,
        "no_speech_prob": 0.000004157347575528547,
        "seek": 488922,
        "start": 4911.22,
        "temperature": 0,
        "text": " So that's kind of my point of view about that.",
        "tokens": [
          51464,
          407,
          300,
          311,
          733,
          295,
          452,
          935,
          295,
          1910,
          466,
          300,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.29492611080021053,
        "compression_ratio": 1.5833333333333333,
        "end": 4918.22,
        "id": 1418,
        "no_speech_prob": 0.0032223097514361143,
        "seek": 491422,
        "start": 4915.22,
        "temperature": 0,
        "text": " Alright. So let's see.",
        "tokens": [
          50414,
          2798,
          13,
          407,
          718,
          311,
          536,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.29492611080021053,
        "compression_ratio": 1.5833333333333333,
        "end": 4921.22,
        "id": 1419,
        "no_speech_prob": 0.0032223097514361143,
        "seek": 491422,
        "start": 4918.22,
        "temperature": 0,
        "text": " This is a bad idea. Terrible idea. Terrible idea.",
        "tokens": [
          50564,
          639,
          307,
          257,
          1578,
          1558,
          13,
          6564,
          4457,
          1558,
          13,
          6564,
          4457,
          1558,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.29492611080021053,
        "compression_ratio": 1.5833333333333333,
        "end": 4923.22,
        "id": 1420,
        "no_speech_prob": 0.0032223097514361143,
        "seek": 491422,
        "start": 4921.22,
        "temperature": 0,
        "text": " But we're going to do it anyway.",
        "tokens": [
          50714,
          583,
          321,
          434,
          516,
          281,
          360,
          309,
          4033,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.29492611080021053,
        "compression_ratio": 1.5833333333333333,
        "end": 4928.22,
        "id": 1421,
        "no_speech_prob": 0.0032223097514361143,
        "seek": 491422,
        "start": 4923.22,
        "temperature": 0,
        "text": " So what I'm going to do is I'm going to go into examples.",
        "tokens": [
          50814,
          407,
          437,
          286,
          478,
          516,
          281,
          360,
          307,
          286,
          478,
          516,
          281,
          352,
          666,
          5110,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.29492611080021053,
        "compression_ratio": 1.5833333333333333,
        "end": 4932.22,
        "id": 1422,
        "no_speech_prob": 0.0032223097514361143,
        "seek": 491422,
        "start": 4928.22,
        "temperature": 0,
        "text": " I'm going to rebuild this intersection quadtree.",
        "tokens": [
          51064,
          286,
          478,
          516,
          281,
          16877,
          341,
          15236,
          10787,
          83,
          701,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.29492611080021053,
        "compression_ratio": 1.5833333333333333,
        "end": 4940.22,
        "id": 1423,
        "no_speech_prob": 0.0032223097514361143,
        "seek": 491422,
        "start": 4937.22,
        "temperature": 0,
        "text": " No. Copy of it.",
        "tokens": [
          51514,
          883,
          13,
          25653,
          295,
          309,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.2963893362816344,
        "compression_ratio": 1.6685393258426966,
        "end": 4944.22,
        "id": 1424,
        "no_speech_prob": 0.0009547105873934925,
        "seek": 494022,
        "start": 4940.22,
        "temperature": 0,
        "text": " I'm going to just delete that.",
        "tokens": [
          50364,
          286,
          478,
          516,
          281,
          445,
          12097,
          300,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.2963893362816344,
        "compression_ratio": 1.6685393258426966,
        "end": 4953.22,
        "id": 1425,
        "no_speech_prob": 0.0009547105873934925,
        "seek": 494022,
        "start": 4948.22,
        "temperature": 0,
        "text": " I just literally copied a folder, deleted it, and then renamed it.",
        "tokens": [
          50764,
          286,
          445,
          3736,
          25365,
          257,
          10820,
          11,
          22981,
          309,
          11,
          293,
          550,
          319,
          629,
          1912,
          309,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.2963893362816344,
        "compression_ratio": 1.6685393258426966,
        "end": 4957.22,
        "id": 1426,
        "no_speech_prob": 0.0009547105873934925,
        "seek": 494022,
        "start": 4953.22,
        "temperature": 0,
        "text": " I wanted to save a backup of it, but there's really no point in me doing that.",
        "tokens": [
          51014,
          286,
          1415,
          281,
          3155,
          257,
          14807,
          295,
          309,
          11,
          457,
          456,
          311,
          534,
          572,
          935,
          294,
          385,
          884,
          300,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.2963893362816344,
        "compression_ratio": 1.6685393258426966,
        "end": 4960.22,
        "id": 1427,
        "no_speech_prob": 0.0009547105873934925,
        "seek": 494022,
        "start": 4957.22,
        "temperature": 0,
        "text": " It's so silly what I just did.",
        "tokens": [
          51214,
          467,
          311,
          370,
          11774,
          437,
          286,
          445,
          630,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.2963893362816344,
        "compression_ratio": 1.6685393258426966,
        "end": 4962.22,
        "id": 1428,
        "no_speech_prob": 0.0009547105873934925,
        "seek": 494022,
        "start": 4960.22,
        "temperature": 0,
        "text": " I remember what I was going to do.",
        "tokens": [
          51364,
          286,
          1604,
          437,
          286,
          390,
          516,
          281,
          360,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.2963893362816344,
        "compression_ratio": 1.6685393258426966,
        "end": 4965.22,
        "id": 1429,
        "no_speech_prob": 0.0009547105873934925,
        "seek": 494022,
        "start": 4962.22,
        "temperature": 0,
        "text": " What I was doing is, ah, I don't have time to do this.",
        "tokens": [
          51464,
          708,
          286,
          390,
          884,
          307,
          11,
          3716,
          11,
          286,
          500,
          380,
          362,
          565,
          281,
          360,
          341,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.3479286775750629,
        "compression_ratio": 1.5789473684210527,
        "end": 4970.22,
        "id": 1430,
        "no_speech_prob": 0.005469231866300106,
        "seek": 496522,
        "start": 4965.22,
        "temperature": 0,
        "text": " I meant to do this. Take this, put this on the desktop,",
        "tokens": [
          50364,
          286,
          4140,
          281,
          360,
          341,
          13,
          3664,
          341,
          11,
          829,
          341,
          322,
          264,
          14502,
          11,
          50614
        ]
      },
      {
        "avg_logprob": -0.3479286775750629,
        "compression_ratio": 1.5789473684210527,
        "end": 4975.22,
        "id": 1431,
        "no_speech_prob": 0.005469231866300106,
        "seek": 496522,
        "start": 4970.22,
        "temperature": 0,
        "text": " then go grab this quadtree.js, put that in here,",
        "tokens": [
          50614,
          550,
          352,
          4444,
          341,
          10787,
          83,
          701,
          13,
          25530,
          11,
          829,
          300,
          294,
          510,
          11,
          50864
        ]
      },
      {
        "avg_logprob": -0.3479286775750629,
        "compression_ratio": 1.5789473684210527,
        "end": 4979.22,
        "id": 1432,
        "no_speech_prob": 0.005469231866300106,
        "seek": 496522,
        "start": 4975.22,
        "temperature": 0,
        "text": " then go and open this on the desktop.",
        "tokens": [
          50864,
          550,
          352,
          293,
          1269,
          341,
          322,
          264,
          14502,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.3479286775750629,
        "compression_ratio": 1.5789473684210527,
        "end": 4989.22,
        "id": 1433,
        "no_speech_prob": 0.005469231866300106,
        "seek": 496522,
        "start": 4983.22,
        "temperature": 0,
        "text": " Go into Sketch and go into Sketch.js.",
        "tokens": [
          51264,
          1037,
          666,
          49245,
          293,
          352,
          666,
          49245,
          13,
          25530,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.296589109632704,
        "compression_ratio": 1.04,
        "end": 5001.22,
        "id": 1434,
        "no_speech_prob": 0.0006361656705848873,
        "seek": 498922,
        "start": 4990.22,
        "temperature": 0,
        "text": " Go into Sketch and go into index.html and do that.",
        "tokens": [
          50414,
          1037,
          666,
          49245,
          293,
          352,
          666,
          8186,
          13,
          357,
          15480,
          293,
          360,
          300,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.296589109632704,
        "compression_ratio": 1.04,
        "end": 5004.22,
        "id": 1435,
        "no_speech_prob": 0.0006361656705848873,
        "seek": 498922,
        "start": 5001.22,
        "temperature": 0,
        "text": " Then I'm going to terminal.",
        "tokens": [
          50964,
          1396,
          286,
          478,
          516,
          281,
          14709,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.29521919118947,
        "compression_ratio": 1.5137614678899083,
        "end": 5009.22,
        "id": 1436,
        "no_speech_prob": 0.0014550271444022655,
        "seek": 500422,
        "start": 5004.22,
        "temperature": 0,
        "text": " No.",
        "tokens": [
          50364,
          883,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.29521919118947,
        "compression_ratio": 1.5137614678899083,
        "end": 5018.22,
        "id": 1437,
        "no_speech_prob": 0.0014550271444022655,
        "seek": 500422,
        "start": 5009.22,
        "temperature": 0,
        "text": " Then I'm going to say, oh, then I'm going to run a server.",
        "tokens": [
          50614,
          1396,
          286,
          478,
          516,
          281,
          584,
          11,
          1954,
          11,
          550,
          286,
          478,
          516,
          281,
          1190,
          257,
          7154,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.29521919118947,
        "compression_ratio": 1.5137614678899083,
        "end": 5027.22,
        "id": 1438,
        "no_speech_prob": 0.0014550271444022655,
        "seek": 500422,
        "start": 5024.22,
        "temperature": 0,
        "text": " That's there.",
        "tokens": [
          51364,
          663,
          311,
          456,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.29521919118947,
        "compression_ratio": 1.5137614678899083,
        "end": 5032.22,
        "id": 1439,
        "no_speech_prob": 0.0014550271444022655,
        "seek": 500422,
        "start": 5027.22,
        "temperature": 0,
        "text": " What I'm going to do now, I think what I'll do is I'm going to leave this particle code.",
        "tokens": [
          51514,
          708,
          286,
          478,
          516,
          281,
          360,
          586,
          11,
          286,
          519,
          437,
          286,
          603,
          360,
          307,
          286,
          478,
          516,
          281,
          1856,
          341,
          12359,
          3089,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.21847698606293778,
        "compression_ratio": 1.6218487394957983,
        "end": 5036.22,
        "id": 1440,
        "no_speech_prob": 0.00019715882081072778,
        "seek": 503222,
        "start": 5033.22,
        "temperature": 0,
        "text": " I'm going to leave this simple particle code.",
        "tokens": [
          50414,
          286,
          478,
          516,
          281,
          1856,
          341,
          2199,
          12359,
          3089,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.21847698606293778,
        "compression_ratio": 1.6218487394957983,
        "end": 5039.22,
        "id": 1441,
        "no_speech_prob": 0.00019715882081072778,
        "seek": 503222,
        "start": 5036.22,
        "temperature": 0,
        "text": " I'm going to take this out. I'm going to take the highlight thing out.",
        "tokens": [
          50564,
          286,
          478,
          516,
          281,
          747,
          341,
          484,
          13,
          286,
          478,
          516,
          281,
          747,
          264,
          5078,
          551,
          484,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.21847698606293778,
        "compression_ratio": 1.6218487394957983,
        "end": 5042.22,
        "id": 1442,
        "no_speech_prob": 0.00019715882081072778,
        "seek": 503222,
        "start": 5039.22,
        "temperature": 0,
        "text": " I'll add that.",
        "tokens": [
          50714,
          286,
          603,
          909,
          300,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.21847698606293778,
        "compression_ratio": 1.6218487394957983,
        "end": 5053.22,
        "id": 1443,
        "no_speech_prob": 0.00019715882081072778,
        "seek": 503222,
        "start": 5047.22,
        "temperature": 0,
        "text": " Leave that, and then I'm going to get rid of everything here.",
        "tokens": [
          51114,
          9825,
          300,
          11,
          293,
          550,
          286,
          478,
          516,
          281,
          483,
          3973,
          295,
          1203,
          510,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.2259969139099121,
        "compression_ratio": 1.5368421052631578,
        "end": 5061.22,
        "id": 1444,
        "no_speech_prob": 0.001987725729122758,
        "seek": 505322,
        "start": 5054.22,
        "temperature": 0,
        "text": " Whoa, there's a lot of code I'm going to have to write, apparently.",
        "tokens": [
          50414,
          7521,
          11,
          456,
          311,
          257,
          688,
          295,
          3089,
          286,
          478,
          516,
          281,
          362,
          281,
          2464,
          11,
          7970,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.2259969139099121,
        "compression_ratio": 1.5368421052631578,
        "end": 5064.22,
        "id": 1445,
        "no_speech_prob": 0.001987725729122758,
        "seek": 505322,
        "start": 5061.22,
        "temperature": 0,
        "text": " Oh, no, I don't need to show the quadtree stuff.",
        "tokens": [
          50764,
          876,
          11,
          572,
          11,
          286,
          500,
          380,
          643,
          281,
          855,
          264,
          10787,
          83,
          701,
          1507,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.2259969139099121,
        "compression_ratio": 1.5368421052631578,
        "end": 5067.22,
        "id": 1446,
        "no_speech_prob": 0.001987725729122758,
        "seek": 505322,
        "start": 5064.22,
        "temperature": 0,
        "text": " Okay, that's great.",
        "tokens": [
          50914,
          1033,
          11,
          300,
          311,
          869,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.2259969139099121,
        "compression_ratio": 1.5368421052631578,
        "end": 5070.22,
        "id": 1447,
        "no_speech_prob": 0.001987725729122758,
        "seek": 505322,
        "start": 5067.22,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          51064,
          1033,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.2259969139099121,
        "compression_ratio": 1.5368421052631578,
        "end": 5073.22,
        "id": 1448,
        "no_speech_prob": 0.001987725729122758,
        "seek": 505322,
        "start": 5070.22,
        "temperature": 0,
        "text": " Okay, so I think I'm ready for this.",
        "tokens": [
          51214,
          1033,
          11,
          370,
          286,
          519,
          286,
          478,
          1919,
          337,
          341,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.2259969139099121,
        "compression_ratio": 1.5368421052631578,
        "end": 5077.22,
        "id": 1449,
        "no_speech_prob": 0.001987725729122758,
        "seek": 505322,
        "start": 5073.22,
        "temperature": 0,
        "text": " This could be, I think, six minutes left and I gave myself until 1 o'clock.",
        "tokens": [
          51364,
          639,
          727,
          312,
          11,
          286,
          519,
          11,
          2309,
          2077,
          1411,
          293,
          286,
          2729,
          2059,
          1826,
          502,
          277,
          6,
          9023,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.2259969139099121,
        "compression_ratio": 1.5368421052631578,
        "end": 5080.22,
        "id": 1450,
        "no_speech_prob": 0.001987725729122758,
        "seek": 505322,
        "start": 5077.22,
        "temperature": 0,
        "text": " I'm going to give myself until 1.15.",
        "tokens": [
          51564,
          286,
          478,
          516,
          281,
          976,
          2059,
          1826,
          502,
          13,
          5211,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.19831872540850973,
        "compression_ratio": 1.25,
        "end": 5090.22,
        "id": 1451,
        "no_speech_prob": 0.0001713046367513016,
        "seek": 508022,
        "start": 5080.22,
        "temperature": 0,
        "text": " If this is not done at 1.15, I really can't do this now.",
        "tokens": [
          50364,
          759,
          341,
          307,
          406,
          1096,
          412,
          502,
          13,
          5211,
          11,
          286,
          534,
          393,
          380,
          360,
          341,
          586,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.19831872540850973,
        "compression_ratio": 1.25,
        "end": 5093.22,
        "id": 1452,
        "no_speech_prob": 0.0001713046367513016,
        "seek": 508022,
        "start": 5090.22,
        "temperature": 0,
        "text": " I'm going to try.",
        "tokens": [
          50864,
          286,
          478,
          516,
          281,
          853,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.19831872540850973,
        "compression_ratio": 1.25,
        "end": 5096.22,
        "id": 1453,
        "no_speech_prob": 0.0001713046367513016,
        "seek": 508022,
        "start": 5093.22,
        "temperature": 0,
        "text": " Against my better judgment, I'm going to try.",
        "tokens": [
          51014,
          29995,
          452,
          1101,
          12216,
          11,
          286,
          478,
          516,
          281,
          853,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.5160704781027401,
        "compression_ratio": 0.8222222222222222,
        "end": 5101.22,
        "id": 1454,
        "no_speech_prob": 0.010327846743166447,
        "seek": 509622,
        "start": 5097.22,
        "temperature": 0,
        "text": " What I'm going to do here is...",
        "tokens": [
          50414,
          708,
          286,
          478,
          516,
          281,
          360,
          510,
          307,
          485,
          50614
        ]
      },
      {
        "avg_logprob": -0.5160704781027401,
        "compression_ratio": 0.8222222222222222,
        "end": 5119.22,
        "id": 1455,
        "no_speech_prob": 0.010327846743166447,
        "seek": 509622,
        "start": 5116.22,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          51364,
          1033,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.20516028631301153,
        "compression_ratio": 1.6899563318777293,
        "end": 5122.22,
        "id": 1456,
        "no_speech_prob": 0.0022517950274050236,
        "seek": 511922,
        "start": 5120.22,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          50414,
          1033,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.20516028631301153,
        "compression_ratio": 1.6899563318777293,
        "end": 5126.22,
        "id": 1457,
        "no_speech_prob": 0.0022517950274050236,
        "seek": 511922,
        "start": 5122.22,
        "temperature": 0,
        "text": " Hello, and welcome to part three of my quadtree coding challenge.",
        "tokens": [
          50514,
          2425,
          11,
          293,
          2928,
          281,
          644,
          1045,
          295,
          452,
          10787,
          83,
          701,
          17720,
          3430,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.20516028631301153,
        "compression_ratio": 1.6899563318777293,
        "end": 5130.22,
        "id": 1458,
        "no_speech_prob": 0.0022517950274050236,
        "seek": 511922,
        "start": 5126.22,
        "temperature": 0,
        "text": " In this coding challenge, what I want to do is I want to see, can this work?",
        "tokens": [
          50714,
          682,
          341,
          17720,
          3430,
          11,
          437,
          286,
          528,
          281,
          360,
          307,
          286,
          528,
          281,
          536,
          11,
          393,
          341,
          589,
          30,
          50914
        ]
      },
      {
        "avg_logprob": -0.20516028631301153,
        "compression_ratio": 1.6899563318777293,
        "end": 5132.22,
        "id": 1459,
        "no_speech_prob": 0.0022517950274050236,
        "seek": 511922,
        "start": 5130.22,
        "temperature": 0,
        "text": " Will this work?",
        "tokens": [
          50914,
          3099,
          341,
          589,
          30,
          51014
        ]
      },
      {
        "avg_logprob": -0.20516028631301153,
        "compression_ratio": 1.6899563318777293,
        "end": 5137.22,
        "id": 1460,
        "no_speech_prob": 0.0022517950274050236,
        "seek": 511922,
        "start": 5132.22,
        "temperature": 0,
        "text": " I have this very, very, very slow sketch that has 1,000 particles.",
        "tokens": [
          51014,
          286,
          362,
          341,
          588,
          11,
          588,
          11,
          588,
          2964,
          12325,
          300,
          575,
          502,
          11,
          1360,
          10007,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.20516028631301153,
        "compression_ratio": 1.6899563318777293,
        "end": 5143.22,
        "id": 1461,
        "no_speech_prob": 0.0022517950274050236,
        "seek": 511922,
        "start": 5137.22,
        "temperature": 0,
        "text": " Each particle is checking every other particle where it is in the window.",
        "tokens": [
          51264,
          6947,
          12359,
          307,
          8568,
          633,
          661,
          12359,
          689,
          309,
          307,
          294,
          264,
          4910,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.20516028631301153,
        "compression_ratio": 1.6899563318777293,
        "end": 5148.22,
        "id": 1462,
        "no_speech_prob": 0.0022517950274050236,
        "seek": 511922,
        "start": 5143.22,
        "temperature": 0,
        "text": " If it is overlapping or intersecting one of them, it's highlighting itself white.",
        "tokens": [
          51564,
          759,
          309,
          307,
          33535,
          420,
          27815,
          278,
          472,
          295,
          552,
          11,
          309,
          311,
          26551,
          2564,
          2418,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.1866579246520996,
        "compression_ratio": 1.6343612334801763,
        "end": 5151.22,
        "id": 1463,
        "no_speech_prob": 0.0010649396572262049,
        "seek": 514822,
        "start": 5148.22,
        "temperature": 0,
        "text": " If it's not, it's keeping its color to gray.",
        "tokens": [
          50364,
          759,
          309,
          311,
          406,
          11,
          309,
          311,
          5145,
          1080,
          2017,
          281,
          10855,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.1866579246520996,
        "compression_ratio": 1.6343612334801763,
        "end": 5154.22,
        "id": 1464,
        "no_speech_prob": 0.0010649396572262049,
        "seek": 514822,
        "start": 5151.22,
        "temperature": 0,
        "text": " You'll notice this is running at about five frames per second.",
        "tokens": [
          50514,
          509,
          603,
          3449,
          341,
          307,
          2614,
          412,
          466,
          1732,
          12083,
          680,
          1150,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.1866579246520996,
        "compression_ratio": 1.6343612334801763,
        "end": 5160.22,
        "id": 1465,
        "no_speech_prob": 0.0010649396572262049,
        "seek": 514822,
        "start": 5154.22,
        "temperature": 0,
        "text": " Can I use a quadtree to reduce the number of cycles, computational cycles,",
        "tokens": [
          50664,
          1664,
          286,
          764,
          257,
          10787,
          83,
          701,
          281,
          5407,
          264,
          1230,
          295,
          17796,
          11,
          28270,
          17796,
          11,
          50964
        ]
      },
      {
        "avg_logprob": -0.1866579246520996,
        "compression_ratio": 1.6343612334801763,
        "end": 5164.22,
        "id": 1466,
        "no_speech_prob": 0.0010649396572262049,
        "seek": 514822,
        "start": 5160.22,
        "temperature": 0,
        "text": " I need to do to check every particle's location against every other particle's location",
        "tokens": [
          50964,
          286,
          643,
          281,
          360,
          281,
          1520,
          633,
          12359,
          311,
          4914,
          1970,
          633,
          661,
          12359,
          311,
          4914,
          51164
        ]
      },
      {
        "avg_logprob": -0.1866579246520996,
        "compression_ratio": 1.6343612334801763,
        "end": 5169.22,
        "id": 1467,
        "no_speech_prob": 0.0010649396572262049,
        "seek": 514822,
        "start": 5164.22,
        "temperature": 0,
        "text": " and get this running at 30 frames per second?",
        "tokens": [
          51164,
          293,
          483,
          341,
          2614,
          412,
          2217,
          12083,
          680,
          1150,
          30,
          51414
        ]
      },
      {
        "avg_logprob": -0.1866579246520996,
        "compression_ratio": 1.6343612334801763,
        "end": 5171.22,
        "id": 1468,
        "no_speech_prob": 0.0010649396572262049,
        "seek": 514822,
        "start": 5169.22,
        "temperature": 0,
        "text": " Let's go.",
        "tokens": [
          51414,
          961,
          311,
          352,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.1866579246520996,
        "compression_ratio": 1.6343612334801763,
        "end": 5174.22,
        "id": 1469,
        "no_speech_prob": 0.0010649396572262049,
        "seek": 514822,
        "start": 5171.22,
        "temperature": 0,
        "text": " Okay, so I'm actually going to refresh this.",
        "tokens": [
          51514,
          1033,
          11,
          370,
          286,
          478,
          767,
          516,
          281,
          15134,
          341,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.2130154291788737,
        "compression_ratio": 1.669603524229075,
        "end": 5180.22,
        "id": 1470,
        "no_speech_prob": 0.04602804780006409,
        "seek": 517422,
        "start": 5174.22,
        "temperature": 0,
        "text": " There's nothing there now because I had all that code and I deleted it because I'm going to write it now.",
        "tokens": [
          50364,
          821,
          311,
          1825,
          456,
          586,
          570,
          286,
          632,
          439,
          300,
          3089,
          293,
          286,
          22981,
          309,
          570,
          286,
          478,
          516,
          281,
          2464,
          309,
          586,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.2130154291788737,
        "compression_ratio": 1.669603524229075,
        "end": 5183.22,
        "id": 1471,
        "no_speech_prob": 0.04602804780006409,
        "seek": 517422,
        "start": 5180.22,
        "temperature": 0,
        "text": " What I do have already is a particle class.",
        "tokens": [
          50664,
          708,
          286,
          360,
          362,
          1217,
          307,
          257,
          12359,
          1508,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.2130154291788737,
        "compression_ratio": 1.669603524229075,
        "end": 5187.22,
        "id": 1472,
        "no_speech_prob": 0.04602804780006409,
        "seek": 517422,
        "start": 5183.22,
        "temperature": 0,
        "text": " I have a very simple particle. It just has an x, a y, and a size.",
        "tokens": [
          50814,
          286,
          362,
          257,
          588,
          2199,
          12359,
          13,
          467,
          445,
          575,
          364,
          2031,
          11,
          257,
          288,
          11,
          293,
          257,
          2744,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.2130154291788737,
        "compression_ratio": 1.669603524229075,
        "end": 5189.22,
        "id": 1473,
        "no_speech_prob": 0.04602804780006409,
        "seek": 517422,
        "start": 5187.22,
        "temperature": 0,
        "text": " It's drawn as a circle.",
        "tokens": [
          51014,
          467,
          311,
          10117,
          382,
          257,
          6329,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.2130154291788737,
        "compression_ratio": 1.669603524229075,
        "end": 5191.22,
        "id": 1474,
        "no_speech_prob": 0.04602804780006409,
        "seek": 517422,
        "start": 5189.22,
        "temperature": 0,
        "text": " Let's do this.",
        "tokens": [
          51114,
          961,
          311,
          360,
          341,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.2130154291788737,
        "compression_ratio": 1.669603524229075,
        "end": 5194.22,
        "id": 1475,
        "no_speech_prob": 0.04602804780006409,
        "seek": 517422,
        "start": 5191.22,
        "temperature": 0,
        "text": " Let's say... I'm thinking about this.",
        "tokens": [
          51214,
          961,
          311,
          584,
          485,
          286,
          478,
          1953,
          466,
          341,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.2130154291788737,
        "compression_ratio": 1.669603524229075,
        "end": 5197.22,
        "id": 1476,
        "no_speech_prob": 0.04602804780006409,
        "seek": 517422,
        "start": 5194.22,
        "temperature": 0,
        "text": " Let's make an array of particles.",
        "tokens": [
          51364,
          961,
          311,
          652,
          364,
          10225,
          295,
          10007,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.2130154291788737,
        "compression_ratio": 1.669603524229075,
        "end": 5200.22,
        "id": 1477,
        "no_speech_prob": 0.04602804780006409,
        "seek": 517422,
        "start": 5197.22,
        "temperature": 0,
        "text": " I'm going to say 4, let i equal 0, i is less than 1.",
        "tokens": [
          51514,
          286,
          478,
          516,
          281,
          584,
          1017,
          11,
          718,
          741,
          2681,
          1958,
          11,
          741,
          307,
          1570,
          813,
          502,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.21226179895322184,
        "compression_ratio": 1.6771653543307086,
        "end": 5205.22,
        "id": 1478,
        "no_speech_prob": 0.0063881645910441875,
        "seek": 520022,
        "start": 5200.22,
        "temperature": 0,
        "text": " Let's just start with 100 because I don't want to deal with it running slow until it's time to really implement the quadtree.",
        "tokens": [
          50364,
          961,
          311,
          445,
          722,
          365,
          2319,
          570,
          286,
          500,
          380,
          528,
          281,
          2028,
          365,
          309,
          2614,
          2964,
          1826,
          309,
          311,
          565,
          281,
          534,
          4445,
          264,
          10787,
          83,
          701,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.21226179895322184,
        "compression_ratio": 1.6771653543307086,
        "end": 5208.22,
        "id": 1479,
        "no_speech_prob": 0.0063881645910441875,
        "seek": 520022,
        "start": 5205.22,
        "temperature": 0,
        "text": " I'm going to say particles index i is a new particle.",
        "tokens": [
          50614,
          286,
          478,
          516,
          281,
          584,
          10007,
          8186,
          741,
          307,
          257,
          777,
          12359,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.21226179895322184,
        "compression_ratio": 1.6771653543307086,
        "end": 5213.22,
        "id": 1480,
        "no_speech_prob": 0.0063881645910441875,
        "seek": 520022,
        "start": 5208.22,
        "temperature": 0,
        "text": " I'm going to give the particle a random location on the window.",
        "tokens": [
          50764,
          286,
          478,
          516,
          281,
          976,
          264,
          12359,
          257,
          4974,
          4914,
          322,
          264,
          4910,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.21226179895322184,
        "compression_ratio": 1.6771653543307086,
        "end": 5218.22,
        "id": 1481,
        "no_speech_prob": 0.0063881645910441875,
        "seek": 520022,
        "start": 5213.22,
        "temperature": 0,
        "text": " Then I'm going to say 4, let p of particles...",
        "tokens": [
          51014,
          1396,
          286,
          478,
          516,
          281,
          584,
          1017,
          11,
          718,
          280,
          295,
          10007,
          485,
          51264
        ]
      },
      {
        "avg_logprob": -0.21226179895322184,
        "compression_ratio": 1.6771653543307086,
        "end": 5224.22,
        "id": 1482,
        "no_speech_prob": 0.0063881645910441875,
        "seek": 520022,
        "start": 5218.22,
        "temperature": 0,
        "text": " I think it's like p.update probably and p.... I don't know what it is. Let's look.",
        "tokens": [
          51264,
          286,
          519,
          309,
          311,
          411,
          280,
          13,
          1010,
          17393,
          1391,
          293,
          280,
          13,
          485,
          286,
          500,
          380,
          458,
          437,
          309,
          307,
          13,
          961,
          311,
          574,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.21226179895322184,
        "compression_ratio": 1.6771653543307086,
        "end": 5227.22,
        "id": 1483,
        "no_speech_prob": 0.0063881645910441875,
        "seek": 520022,
        "start": 5224.22,
        "temperature": 0,
        "text": " Move and render. Who knows what I call these things?",
        "tokens": [
          51564,
          10475,
          293,
          15529,
          13,
          2102,
          3255,
          437,
          286,
          818,
          613,
          721,
          30,
          51714
        ]
      },
      {
        "avg_logprob": -0.2928961411263179,
        "compression_ratio": 1.6199095022624435,
        "end": 5229.22,
        "id": 1484,
        "no_speech_prob": 0.02758323773741722,
        "seek": 522722,
        "start": 5227.22,
        "temperature": 0,
        "text": " Move and render.",
        "tokens": [
          50364,
          10475,
          293,
          15529,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.2928961411263179,
        "compression_ratio": 1.6199095022624435,
        "end": 5232.22,
        "id": 1485,
        "no_speech_prob": 0.02758323773741722,
        "seek": 522722,
        "start": 5229.22,
        "temperature": 0,
        "text": " I'm going to say background 0.",
        "tokens": [
          50464,
          286,
          478,
          516,
          281,
          584,
          3678,
          1958,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.2928961411263179,
        "compression_ratio": 1.6199095022624435,
        "end": 5236.22,
        "id": 1486,
        "no_speech_prob": 0.02758323773741722,
        "seek": 522722,
        "start": 5232.22,
        "temperature": 0,
        "text": " Now we can see... there we go. No problem.",
        "tokens": [
          50614,
          823,
          321,
          393,
          536,
          485,
          456,
          321,
          352,
          13,
          883,
          1154,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.2928961411263179,
        "compression_ratio": 1.6199095022624435,
        "end": 5239.22,
        "id": 1487,
        "no_speech_prob": 0.02758323773741722,
        "seek": 522722,
        "start": 5236.22,
        "temperature": 0,
        "text": " Look at all my beautiful particles. I'm moving around.",
        "tokens": [
          50814,
          2053,
          412,
          439,
          452,
          2238,
          10007,
          13,
          286,
          478,
          2684,
          926,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.2928961411263179,
        "compression_ratio": 1.6199095022624435,
        "end": 5246.22,
        "id": 1488,
        "no_speech_prob": 0.02758323773741722,
        "seek": 522722,
        "start": 5239.22,
        "temperature": 0,
        "text": " We can see, by the way, even with a thousand of them, drawing a thousand particles is no problem.",
        "tokens": [
          50964,
          492,
          393,
          536,
          11,
          538,
          264,
          636,
          11,
          754,
          365,
          257,
          4714,
          295,
          552,
          11,
          6316,
          257,
          4714,
          10007,
          307,
          572,
          1154,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.2928961411263179,
        "compression_ratio": 1.6199095022624435,
        "end": 5250.22,
        "id": 1489,
        "no_speech_prob": 0.02758323773741722,
        "seek": 522722,
        "start": 5246.22,
        "temperature": 0,
        "text": " P5, canvas, I can draw a thousand circles any old day of the week.",
        "tokens": [
          51314,
          430,
          20,
          11,
          16267,
          11,
          286,
          393,
          2642,
          257,
          4714,
          13040,
          604,
          1331,
          786,
          295,
          264,
          1243,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.2928961411263179,
        "compression_ratio": 1.6199095022624435,
        "end": 5253.22,
        "id": 1490,
        "no_speech_prob": 0.02758323773741722,
        "seek": 522722,
        "start": 5250.22,
        "temperature": 0,
        "text": " 30 frames per second, whatever nice frame rate.",
        "tokens": [
          51514,
          2217,
          12083,
          680,
          1150,
          11,
          2035,
          1481,
          3920,
          3314,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.2665960577469838,
        "compression_ratio": 1.6602564102564104,
        "end": 5257.22,
        "id": 1491,
        "no_speech_prob": 0.019418705254793167,
        "seek": 525322,
        "start": 5253.22,
        "temperature": 0,
        "text": " But now, what if I were to say 4...",
        "tokens": [
          50364,
          583,
          586,
          11,
          437,
          498,
          286,
          645,
          281,
          584,
          1017,
          485,
          50564
        ]
      },
      {
        "avg_logprob": -0.2665960577469838,
        "compression_ratio": 1.6602564102564104,
        "end": 5262.22,
        "id": 1492,
        "no_speech_prob": 0.019418705254793167,
        "seek": 525322,
        "start": 5257.22,
        "temperature": 0,
        "text": " I'm going to do this again. I'm going to separate this out into a separate loop.",
        "tokens": [
          50564,
          286,
          478,
          516,
          281,
          360,
          341,
          797,
          13,
          286,
          478,
          516,
          281,
          4994,
          341,
          484,
          666,
          257,
          4994,
          6367,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.2665960577469838,
        "compression_ratio": 1.6602564102564104,
        "end": 5267.22,
        "id": 1493,
        "no_speech_prob": 0.019418705254793167,
        "seek": 525322,
        "start": 5262.22,
        "temperature": 0,
        "text": " Let p of particles for let other of particles.",
        "tokens": [
          50814,
          961,
          280,
          295,
          10007,
          337,
          718,
          661,
          295,
          10007,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.2665960577469838,
        "compression_ratio": 1.6602564102564104,
        "end": 5277.22,
        "id": 1494,
        "no_speech_prob": 0.019418705254793167,
        "seek": 525322,
        "start": 5267.22,
        "temperature": 0,
        "text": " I want to now check if p.intersects other, then I want to highlight this particle.",
        "tokens": [
          51064,
          286,
          528,
          281,
          586,
          1520,
          498,
          280,
          13,
          5106,
          9632,
          82,
          661,
          11,
          550,
          286,
          528,
          281,
          5078,
          341,
          12359,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.2665960577469838,
        "compression_ratio": 1.6602564102564104,
        "end": 5280.22,
        "id": 1495,
        "no_speech_prob": 0.019418705254793167,
        "seek": 525322,
        "start": 5277.22,
        "temperature": 0,
        "text": " p.highlight.",
        "tokens": [
          51564,
          280,
          13,
          21454,
          2764,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.19288096957736545,
        "compression_ratio": 1.7153558052434457,
        "end": 5285.22,
        "id": 1496,
        "no_speech_prob": 0.010488703846931458,
        "seek": 528022,
        "start": 5281.22,
        "temperature": 0,
        "text": " This is the idea. I want to do a nested loop.",
        "tokens": [
          50414,
          639,
          307,
          264,
          1558,
          13,
          286,
          528,
          281,
          360,
          257,
          15646,
          292,
          6367,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.19288096957736545,
        "compression_ratio": 1.7153558052434457,
        "end": 5290.22,
        "id": 1497,
        "no_speech_prob": 0.010488703846931458,
        "seek": 528022,
        "start": 5285.22,
        "temperature": 0,
        "text": " Also, I got to make sure as long as p is not equal to other.",
        "tokens": [
          50614,
          2743,
          11,
          286,
          658,
          281,
          652,
          988,
          382,
          938,
          382,
          280,
          307,
          406,
          2681,
          281,
          661,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.19288096957736545,
        "compression_ratio": 1.7153558052434457,
        "end": 5292.22,
        "id": 1498,
        "no_speech_prob": 0.010488703846931458,
        "seek": 528022,
        "start": 5290.22,
        "temperature": 0,
        "text": " p shouldn't check itself.",
        "tokens": [
          50864,
          280,
          4659,
          380,
          1520,
          2564,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.19288096957736545,
        "compression_ratio": 1.7153558052434457,
        "end": 5295.22,
        "id": 1499,
        "no_speech_prob": 0.010488703846931458,
        "seek": 528022,
        "start": 5292.22,
        "temperature": 0,
        "text": " Again, there are plenty of ways to optimize this nested loop.",
        "tokens": [
          50964,
          3764,
          11,
          456,
          366,
          7140,
          295,
          2098,
          281,
          19719,
          341,
          15646,
          292,
          6367,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.19288096957736545,
        "compression_ratio": 1.7153558052434457,
        "end": 5298.22,
        "id": 1500,
        "no_speech_prob": 0.010488703846931458,
        "seek": 528022,
        "start": 5295.22,
        "temperature": 0,
        "text": " If p is checking other, I don't need other to check p.",
        "tokens": [
          51114,
          759,
          280,
          307,
          8568,
          661,
          11,
          286,
          500,
          380,
          643,
          661,
          281,
          1520,
          280,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.19288096957736545,
        "compression_ratio": 1.7153558052434457,
        "end": 5302.22,
        "id": 1501,
        "no_speech_prob": 0.010488703846931458,
        "seek": 528022,
        "start": 5298.22,
        "temperature": 0,
        "text": " But that's not the point here. I'm going to let this be as inefficient as possible.",
        "tokens": [
          51264,
          583,
          300,
          311,
          406,
          264,
          935,
          510,
          13,
          286,
          478,
          516,
          281,
          718,
          341,
          312,
          382,
          43495,
          382,
          1944,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.19288096957736545,
        "compression_ratio": 1.7153558052434457,
        "end": 5305.22,
        "id": 1502,
        "no_speech_prob": 0.010488703846931458,
        "seek": 528022,
        "start": 5302.22,
        "temperature": 0,
        "text": " Do I have an intersects function? Do I have a highlight function?",
        "tokens": [
          51464,
          1144,
          286,
          362,
          364,
          27815,
          82,
          2445,
          30,
          1144,
          286,
          362,
          257,
          5078,
          2445,
          30,
          51614
        ]
      },
      {
        "avg_logprob": -0.19288096957736545,
        "compression_ratio": 1.7153558052434457,
        "end": 5308.22,
        "id": 1503,
        "no_speech_prob": 0.010488703846931458,
        "seek": 528022,
        "start": 5305.22,
        "temperature": 0,
        "text": " I don't think so. It would have been nice if I kept those.",
        "tokens": [
          51614,
          286,
          500,
          380,
          519,
          370,
          13,
          467,
          576,
          362,
          668,
          1481,
          498,
          286,
          4305,
          729,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.18290402168451353,
        "compression_ratio": 1.7088607594936709,
        "end": 5311.22,
        "id": 1504,
        "no_speech_prob": 0.0011335450690239668,
        "seek": 530822,
        "start": 5308.22,
        "temperature": 0,
        "text": " Let's write an intersects function.",
        "tokens": [
          50364,
          961,
          311,
          2464,
          364,
          27815,
          82,
          2445,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.18290402168451353,
        "compression_ratio": 1.7088607594936709,
        "end": 5314.22,
        "id": 1505,
        "no_speech_prob": 0.0011335450690239668,
        "seek": 530822,
        "start": 5311.22,
        "temperature": 0,
        "text": " intersects other.",
        "tokens": [
          50514,
          27815,
          82,
          661,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.18290402168451353,
        "compression_ratio": 1.7088607594936709,
        "end": 5316.22,
        "id": 1506,
        "no_speech_prob": 0.0011335450690239668,
        "seek": 530822,
        "start": 5314.22,
        "temperature": 0,
        "text": " What do I need to do?",
        "tokens": [
          50664,
          708,
          360,
          286,
          643,
          281,
          360,
          30,
          50764
        ]
      },
      {
        "avg_logprob": -0.18290402168451353,
        "compression_ratio": 1.7088607594936709,
        "end": 5322.22,
        "id": 1507,
        "no_speech_prob": 0.0011335450690239668,
        "seek": 530822,
        "start": 5316.22,
        "temperature": 0,
        "text": " I need to know the distance between this.x, this.y, and other.x, other.y.",
        "tokens": [
          50764,
          286,
          643,
          281,
          458,
          264,
          4560,
          1296,
          341,
          13,
          87,
          11,
          341,
          13,
          88,
          11,
          293,
          661,
          13,
          87,
          11,
          661,
          13,
          88,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.18290402168451353,
        "compression_ratio": 1.7088607594936709,
        "end": 5326.22,
        "id": 1508,
        "no_speech_prob": 0.0011335450690239668,
        "seek": 530822,
        "start": 5322.22,
        "temperature": 0,
        "text": " Then I'm going to return distance is less than...",
        "tokens": [
          51064,
          1396,
          286,
          478,
          516,
          281,
          2736,
          4560,
          307,
          1570,
          813,
          485,
          51264
        ]
      },
      {
        "avg_logprob": -0.18290402168451353,
        "compression_ratio": 1.7088607594936709,
        "end": 5332.22,
        "id": 1509,
        "no_speech_prob": 0.0011335450690239668,
        "seek": 530822,
        "start": 5326.22,
        "temperature": 0,
        "text": " They're intersecting if the distance is less than this.r plus other.r.",
        "tokens": [
          51264,
          814,
          434,
          27815,
          278,
          498,
          264,
          4560,
          307,
          1570,
          813,
          341,
          13,
          81,
          1804,
          661,
          13,
          81,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.2870821808323716,
        "compression_ratio": 1.5238095238095237,
        "end": 5335.22,
        "id": 1510,
        "no_speech_prob": 0.2688705027103424,
        "seek": 533222,
        "start": 5333.22,
        "temperature": 0,
        "text": " This is going to tell me...",
        "tokens": [
          50414,
          639,
          307,
          516,
          281,
          980,
          385,
          485,
          50514
        ]
      },
      {
        "avg_logprob": -0.2870821808323716,
        "compression_ratio": 1.5238095238095237,
        "end": 5339.22,
        "id": 1511,
        "no_speech_prob": 0.2688705027103424,
        "seek": 533222,
        "start": 5335.22,
        "temperature": 0,
        "text": " Then I'm going to make a variable called highlight.",
        "tokens": [
          50514,
          1396,
          286,
          478,
          516,
          281,
          652,
          257,
          7006,
          1219,
          5078,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.2870821808323716,
        "compression_ratio": 1.5238095238095237,
        "end": 5342.22,
        "id": 1512,
        "no_speech_prob": 0.2688705027103424,
        "seek": 533222,
        "start": 5339.22,
        "temperature": 0,
        "text": " Set that equal to false.",
        "tokens": [
          50714,
          8928,
          300,
          2681,
          281,
          7908,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.2870821808323716,
        "compression_ratio": 1.5238095238095237,
        "end": 5349.22,
        "id": 1513,
        "no_speech_prob": 0.2688705027103424,
        "seek": 533222,
        "start": 5342.22,
        "temperature": 0,
        "text": " I'm going to in render if highlight fill white.",
        "tokens": [
          50864,
          286,
          478,
          516,
          281,
          294,
          15529,
          498,
          5078,
          2836,
          2418,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.2870821808323716,
        "compression_ratio": 1.5238095238095237,
        "end": 5353.22,
        "id": 1514,
        "no_speech_prob": 0.2688705027103424,
        "seek": 533222,
        "start": 5349.22,
        "temperature": 0,
        "text": " Otherwise, fill just this grayish color.",
        "tokens": [
          51214,
          10328,
          11,
          2836,
          445,
          341,
          10855,
          742,
          2017,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.2870821808323716,
        "compression_ratio": 1.5238095238095237,
        "end": 5355.22,
        "id": 1515,
        "no_speech_prob": 0.2688705027103424,
        "seek": 533222,
        "start": 5353.22,
        "temperature": 0,
        "text": " That should be this.highlight.",
        "tokens": [
          51414,
          663,
          820,
          312,
          341,
          13,
          21454,
          2764,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.2551955969437309,
        "compression_ratio": 1.7083333333333333,
        "end": 5360.22,
        "id": 1516,
        "no_speech_prob": 0.010169239714741707,
        "seek": 535522,
        "start": 5355.22,
        "temperature": 0,
        "text": " Then set highlight.",
        "tokens": [
          50364,
          1396,
          992,
          5078,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.2551955969437309,
        "compression_ratio": 1.7083333333333333,
        "end": 5366.22,
        "id": 1517,
        "no_speech_prob": 0.010169239714741707,
        "seek": 535522,
        "start": 5360.22,
        "temperature": 0,
        "text": " I'm going to say this highlight equals and then value.",
        "tokens": [
          50614,
          286,
          478,
          516,
          281,
          584,
          341,
          5078,
          6915,
          293,
          550,
          2158,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.2551955969437309,
        "compression_ratio": 1.7083333333333333,
        "end": 5369.22,
        "id": 1518,
        "no_speech_prob": 0.010169239714741707,
        "seek": 535522,
        "start": 5366.22,
        "temperature": 0,
        "text": " I'm going to write a function that's like set highlight.",
        "tokens": [
          50914,
          286,
          478,
          516,
          281,
          2464,
          257,
          2445,
          300,
          311,
          411,
          992,
          5078,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.2551955969437309,
        "compression_ratio": 1.7083333333333333,
        "end": 5372.22,
        "id": 1519,
        "no_speech_prob": 0.010169239714741707,
        "seek": 535522,
        "start": 5369.22,
        "temperature": 0,
        "text": " That's going to turn highlighting on or off.",
        "tokens": [
          51064,
          663,
          311,
          516,
          281,
          1261,
          26551,
          322,
          420,
          766,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.2551955969437309,
        "compression_ratio": 1.7083333333333333,
        "end": 5375.22,
        "id": 1520,
        "no_speech_prob": 0.010169239714741707,
        "seek": 535522,
        "start": 5372.22,
        "temperature": 0,
        "text": " I could do a better job of this, but this will work.",
        "tokens": [
          51214,
          286,
          727,
          360,
          257,
          1101,
          1691,
          295,
          341,
          11,
          457,
          341,
          486,
          589,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.2551955969437309,
        "compression_ratio": 1.7083333333333333,
        "end": 5378.22,
        "id": 1521,
        "no_speech_prob": 0.010169239714741707,
        "seek": 535522,
        "start": 5375.22,
        "temperature": 0,
        "text": " Basically, what I want to do is...",
        "tokens": [
          51364,
          8537,
          11,
          437,
          286,
          528,
          281,
          360,
          307,
          485,
          51514
        ]
      },
      {
        "avg_logprob": -0.2551955969437309,
        "compression_ratio": 1.7083333333333333,
        "end": 5384.22,
        "id": 1522,
        "no_speech_prob": 0.010169239714741707,
        "seek": 535522,
        "start": 5378.22,
        "temperature": 0,
        "text": " First, I want to set the highlight false for all the particles.",
        "tokens": [
          51514,
          2386,
          11,
          286,
          528,
          281,
          992,
          264,
          5078,
          7908,
          337,
          439,
          264,
          10007,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.21420630762132548,
        "compression_ratio": 1.5951417004048583,
        "end": 5386.22,
        "id": 1523,
        "no_speech_prob": 0.0010162376565858722,
        "seek": 538422,
        "start": 5384.22,
        "temperature": 0,
        "text": " They're all not highlighted.",
        "tokens": [
          50364,
          814,
          434,
          439,
          406,
          17173,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.21420630762132548,
        "compression_ratio": 1.5951417004048583,
        "end": 5393.22,
        "id": 1524,
        "no_speech_prob": 0.0010162376565858722,
        "seek": 538422,
        "start": 5386.22,
        "temperature": 0,
        "text": " Then when I'm doing the check, if it actually is intersecting, I can set the highlight to true.",
        "tokens": [
          50464,
          1396,
          562,
          286,
          478,
          884,
          264,
          1520,
          11,
          498,
          309,
          767,
          307,
          27815,
          278,
          11,
          286,
          393,
          992,
          264,
          5078,
          281,
          2074,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.21420630762132548,
        "compression_ratio": 1.5951417004048583,
        "end": 5397.22,
        "id": 1525,
        "no_speech_prob": 0.0010162376565858722,
        "seek": 538422,
        "start": 5393.22,
        "temperature": 0,
        "text": " Now, let's go back to just 100 particles.",
        "tokens": [
          50814,
          823,
          11,
          718,
          311,
          352,
          646,
          281,
          445,
          2319,
          10007,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.21420630762132548,
        "compression_ratio": 1.5951417004048583,
        "end": 5399.22,
        "id": 1526,
        "no_speech_prob": 0.0010162376565858722,
        "seek": 538422,
        "start": 5397.22,
        "temperature": 0,
        "text": " We can see. Perfect.",
        "tokens": [
          51014,
          492,
          393,
          536,
          13,
          10246,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.21420630762132548,
        "compression_ratio": 1.5951417004048583,
        "end": 5401.22,
        "id": 1527,
        "no_speech_prob": 0.0010162376565858722,
        "seek": 538422,
        "start": 5399.22,
        "temperature": 0,
        "text": " When they're... Okay.",
        "tokens": [
          51114,
          1133,
          436,
          434,
          485,
          1033,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.21420630762132548,
        "compression_ratio": 1.5951417004048583,
        "end": 5403.22,
        "id": 1528,
        "no_speech_prob": 0.0010162376565858722,
        "seek": 538422,
        "start": 5401.22,
        "temperature": 0,
        "text": " Now, the distance... Oh, you know what?",
        "tokens": [
          51214,
          823,
          11,
          264,
          4560,
          485,
          876,
          11,
          291,
          458,
          437,
          30,
          51314
        ]
      },
      {
        "avg_logprob": -0.21420630762132548,
        "compression_ratio": 1.5951417004048583,
        "end": 5405.22,
        "id": 1529,
        "no_speech_prob": 0.0010162376565858722,
        "seek": 538422,
        "start": 5403.22,
        "temperature": 0,
        "text": " I'm not drawing them.",
        "tokens": [
          51314,
          286,
          478,
          406,
          6316,
          552,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.21420630762132548,
        "compression_ratio": 1.5951417004048583,
        "end": 5408.22,
        "id": 1530,
        "no_speech_prob": 0.0010162376565858722,
        "seek": 538422,
        "start": 5405.22,
        "temperature": 0,
        "text": " I'm drawing them with the radius as the diameter.",
        "tokens": [
          51414,
          286,
          478,
          6316,
          552,
          365,
          264,
          15845,
          382,
          264,
          14196,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.21420630762132548,
        "compression_ratio": 1.5951417004048583,
        "end": 5410.22,
        "id": 1531,
        "no_speech_prob": 0.0010162376565858722,
        "seek": 538422,
        "start": 5408.22,
        "temperature": 0,
        "text": " They're actually half the size.",
        "tokens": [
          51564,
          814,
          434,
          767,
          1922,
          264,
          2744,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.21420630762132548,
        "compression_ratio": 1.5951417004048583,
        "end": 5412.22,
        "id": 1532,
        "no_speech_prob": 0.0010162376565858722,
        "seek": 538422,
        "start": 5410.22,
        "temperature": 0,
        "text": " I should fix that in my render function.",
        "tokens": [
          51664,
          286,
          820,
          3191,
          300,
          294,
          452,
          15529,
          2445,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.20273175577479086,
        "compression_ratio": 1.6346153846153846,
        "end": 5414.22,
        "id": 1533,
        "no_speech_prob": 0.16024906933307648,
        "seek": 541222,
        "start": 5412.22,
        "temperature": 0,
        "text": " I'm not being consistent.",
        "tokens": [
          50364,
          286,
          478,
          406,
          885,
          8398,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.20273175577479086,
        "compression_ratio": 1.6346153846153846,
        "end": 5418.22,
        "id": 1534,
        "no_speech_prob": 0.16024906933307648,
        "seek": 541222,
        "start": 5414.22,
        "temperature": 0,
        "text": " This should really be radius times 2 if I'm using r as a radius for the math.",
        "tokens": [
          50464,
          639,
          820,
          534,
          312,
          15845,
          1413,
          568,
          498,
          286,
          478,
          1228,
          367,
          382,
          257,
          15845,
          337,
          264,
          5221,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.20273175577479086,
        "compression_ratio": 1.6346153846153846,
        "end": 5421.22,
        "id": 1535,
        "no_speech_prob": 0.16024906933307648,
        "seek": 541222,
        "start": 5418.22,
        "temperature": 0,
        "text": " Now we can see, right?",
        "tokens": [
          50664,
          823,
          321,
          393,
          536,
          11,
          558,
          30,
          50814
        ]
      },
      {
        "avg_logprob": -0.20273175577479086,
        "compression_ratio": 1.6346153846153846,
        "end": 5423.22,
        "id": 1536,
        "no_speech_prob": 0.16024906933307648,
        "seek": 541222,
        "start": 5421.22,
        "temperature": 0,
        "text": " When they are overlapping, they're highlighted white.",
        "tokens": [
          50814,
          1133,
          436,
          366,
          33535,
          11,
          436,
          434,
          17173,
          2418,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.20273175577479086,
        "compression_ratio": 1.6346153846153846,
        "end": 5425.22,
        "id": 1537,
        "no_speech_prob": 0.16024906933307648,
        "seek": 541222,
        "start": 5423.22,
        "temperature": 0,
        "text": " When they're not overlapping, they're not.",
        "tokens": [
          50914,
          1133,
          436,
          434,
          406,
          33535,
          11,
          436,
          434,
          406,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.20273175577479086,
        "compression_ratio": 1.6346153846153846,
        "end": 5427.22,
        "id": 1538,
        "no_speech_prob": 0.16024906933307648,
        "seek": 541222,
        "start": 5425.22,
        "temperature": 0,
        "text": " Okay. This is working fine.",
        "tokens": [
          51014,
          1033,
          13,
          639,
          307,
          1364,
          2489,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.20273175577479086,
        "compression_ratio": 1.6346153846153846,
        "end": 5432.22,
        "id": 1539,
        "no_speech_prob": 0.16024906933307648,
        "seek": 541222,
        "start": 5427.22,
        "temperature": 0,
        "text": " I can actually... Let me look here in the...",
        "tokens": [
          51114,
          286,
          393,
          767,
          485,
          961,
          385,
          574,
          510,
          294,
          264,
          485,
          51364
        ]
      },
      {
        "avg_logprob": -0.20273175577479086,
        "compression_ratio": 1.6346153846153846,
        "end": 5434.22,
        "id": 1540,
        "no_speech_prob": 0.16024906933307648,
        "seek": 541222,
        "start": 5432.22,
        "temperature": 0,
        "text": " Oh, there's like a...",
        "tokens": [
          51364,
          876,
          11,
          456,
          311,
          411,
          257,
          485,
          51464
        ]
      },
      {
        "avg_logprob": -0.20273175577479086,
        "compression_ratio": 1.6346153846153846,
        "end": 5438.22,
        "id": 1541,
        "no_speech_prob": 0.16024906933307648,
        "seek": 541222,
        "start": 5434.22,
        "temperature": 0,
        "text": " Oh, I got to deal with that for a second. Hold on.",
        "tokens": [
          51464,
          876,
          11,
          286,
          658,
          281,
          2028,
          365,
          300,
          337,
          257,
          1150,
          13,
          6962,
          322,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.20273175577479086,
        "compression_ratio": 1.6346153846153846,
        "end": 5441.22,
        "id": 1542,
        "no_speech_prob": 0.16024906933307648,
        "seek": 541222,
        "start": 5438.22,
        "temperature": 0,
        "text": " I have a little extra bit of code in there by accident.",
        "tokens": [
          51664,
          286,
          362,
          257,
          707,
          2857,
          857,
          295,
          3089,
          294,
          456,
          538,
          6398,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.1559701185960036,
        "compression_ratio": 1.7608695652173914,
        "end": 5443.22,
        "id": 1543,
        "no_speech_prob": 0.0009547251393087208,
        "seek": 544122,
        "start": 5441.22,
        "temperature": 0,
        "text": " I can look at the frame rate. No problem.",
        "tokens": [
          50364,
          286,
          393,
          574,
          412,
          264,
          3920,
          3314,
          13,
          883,
          1154,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.1559701185960036,
        "compression_ratio": 1.7608695652173914,
        "end": 5445.22,
        "id": 1544,
        "no_speech_prob": 0.0009547251393087208,
        "seek": 544122,
        "start": 5443.22,
        "temperature": 0,
        "text": " 27 frames per second.",
        "tokens": [
          50464,
          7634,
          12083,
          680,
          1150,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.1559701185960036,
        "compression_ratio": 1.7608695652173914,
        "end": 5449.22,
        "id": 1545,
        "no_speech_prob": 0.0009547251393087208,
        "seek": 544122,
        "start": 5445.22,
        "temperature": 0,
        "text": " Let me just ignore what I'm doing for a second in my quadtree code.",
        "tokens": [
          50564,
          961,
          385,
          445,
          11200,
          437,
          286,
          478,
          884,
          337,
          257,
          1150,
          294,
          452,
          10787,
          83,
          701,
          3089,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.1559701185960036,
        "compression_ratio": 1.7608695652173914,
        "end": 5451.22,
        "id": 1546,
        "no_speech_prob": 0.0009547251393087208,
        "seek": 544122,
        "start": 5449.22,
        "temperature": 0,
        "text": " I was adding some unit tests and stuff.",
        "tokens": [
          50764,
          286,
          390,
          5127,
          512,
          4985,
          6921,
          293,
          1507,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.1559701185960036,
        "compression_ratio": 1.7608695652173914,
        "end": 5453.22,
        "id": 1547,
        "no_speech_prob": 0.0009547251393087208,
        "seek": 544122,
        "start": 5451.22,
        "temperature": 0,
        "text": " I'm going to just get rid of that.",
        "tokens": [
          50864,
          286,
          478,
          516,
          281,
          445,
          483,
          3973,
          295,
          300,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.1559701185960036,
        "compression_ratio": 1.7608695652173914,
        "end": 5455.22,
        "id": 1548,
        "no_speech_prob": 0.0009547251393087208,
        "seek": 544122,
        "start": 5453.22,
        "temperature": 0,
        "text": " Okay. We can see here, look at the frame rate.",
        "tokens": [
          50964,
          1033,
          13,
          492,
          393,
          536,
          510,
          11,
          574,
          412,
          264,
          3920,
          3314,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.1559701185960036,
        "compression_ratio": 1.7608695652173914,
        "end": 5457.22,
        "id": 1549,
        "no_speech_prob": 0.0009547251393087208,
        "seek": 544122,
        "start": 5455.22,
        "temperature": 0,
        "text": " 26 frames per second.",
        "tokens": [
          51064,
          7551,
          12083,
          680,
          1150,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.1559701185960036,
        "compression_ratio": 1.7608695652173914,
        "end": 5461.22,
        "id": 1550,
        "no_speech_prob": 0.0009547251393087208,
        "seek": 544122,
        "start": 5457.22,
        "temperature": 0,
        "text": " Now, let's see that if I go back to my sketch",
        "tokens": [
          51164,
          823,
          11,
          718,
          311,
          536,
          300,
          498,
          286,
          352,
          646,
          281,
          452,
          12325,
          51364
        ]
      },
      {
        "avg_logprob": -0.1559701185960036,
        "compression_ratio": 1.7608695652173914,
        "end": 5465.22,
        "id": 1551,
        "no_speech_prob": 0.0009547251393087208,
        "seek": 544122,
        "start": 5461.22,
        "temperature": 0,
        "text": " and I add 1,000 particles...",
        "tokens": [
          51364,
          293,
          286,
          909,
          502,
          11,
          1360,
          10007,
          485,
          51564
        ]
      },
      {
        "avg_logprob": -0.1559701185960036,
        "compression_ratio": 1.7608695652173914,
        "end": 5467.22,
        "id": 1552,
        "no_speech_prob": 0.0009547251393087208,
        "seek": 544122,
        "start": 5465.22,
        "temperature": 0,
        "text": " Let's look at the frame rate now.",
        "tokens": [
          51564,
          961,
          311,
          574,
          412,
          264,
          3920,
          3314,
          586,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.1559701185960036,
        "compression_ratio": 1.7608695652173914,
        "end": 5469.22,
        "id": 1553,
        "no_speech_prob": 0.0009547251393087208,
        "seek": 544122,
        "start": 5467.22,
        "temperature": 0,
        "text": " 5 frames per second.",
        "tokens": [
          51664,
          1025,
          12083,
          680,
          1150,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.20302106373345674,
        "compression_ratio": 1.6360153256704981,
        "end": 5471.22,
        "id": 1554,
        "no_speech_prob": 0.0013885145308449864,
        "seek": 546922,
        "start": 5469.22,
        "temperature": 0,
        "text": " Also, now that I have so many,",
        "tokens": [
          50364,
          2743,
          11,
          586,
          300,
          286,
          362,
          370,
          867,
          11,
          50464
        ]
      },
      {
        "avg_logprob": -0.20302106373345674,
        "compression_ratio": 1.6360153256704981,
        "end": 5474.22,
        "id": 1555,
        "no_speech_prob": 0.0013885145308449864,
        "seek": 546922,
        "start": 5471.22,
        "temperature": 0,
        "text": " I probably want them not to be as big.",
        "tokens": [
          50464,
          286,
          1391,
          528,
          552,
          406,
          281,
          312,
          382,
          955,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.20302106373345674,
        "compression_ratio": 1.6360153256704981,
        "end": 5476.22,
        "id": 1556,
        "no_speech_prob": 0.0013885145308449864,
        "seek": 546922,
        "start": 5474.22,
        "temperature": 0,
        "text": " Because...",
        "tokens": [
          50614,
          1436,
          485,
          50714
        ]
      },
      {
        "avg_logprob": -0.20302106373345674,
        "compression_ratio": 1.6360153256704981,
        "end": 5479.22,
        "id": 1557,
        "no_speech_prob": 0.0013885145308449864,
        "seek": 546922,
        "start": 5476.22,
        "temperature": 0,
        "text": " Let's actually make them half the size.",
        "tokens": [
          50714,
          961,
          311,
          767,
          652,
          552,
          1922,
          264,
          2744,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.20302106373345674,
        "compression_ratio": 1.6360153256704981,
        "end": 5482.22,
        "id": 1558,
        "no_speech_prob": 0.0013885145308449864,
        "seek": 546922,
        "start": 5479.22,
        "temperature": 0,
        "text": " And now, frame rate is still 5 frames per second.",
        "tokens": [
          50864,
          400,
          586,
          11,
          3920,
          3314,
          307,
          920,
          1025,
          12083,
          680,
          1150,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.20302106373345674,
        "compression_ratio": 1.6360153256704981,
        "end": 5485.22,
        "id": 1559,
        "no_speech_prob": 0.0013885145308449864,
        "seek": 546922,
        "start": 5482.22,
        "temperature": 0,
        "text": " Okay! We're here for the quadtree, right?",
        "tokens": [
          51014,
          1033,
          0,
          492,
          434,
          510,
          337,
          264,
          10787,
          83,
          701,
          11,
          558,
          30,
          51164
        ]
      },
      {
        "avg_logprob": -0.20302106373345674,
        "compression_ratio": 1.6360153256704981,
        "end": 5487.22,
        "id": 1560,
        "no_speech_prob": 0.0013885145308449864,
        "seek": 546922,
        "start": 5485.22,
        "temperature": 0,
        "text": " Let's add the quadtree.",
        "tokens": [
          51164,
          961,
          311,
          909,
          264,
          10787,
          83,
          701,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.20302106373345674,
        "compression_ratio": 1.6360153256704981,
        "end": 5490.22,
        "id": 1561,
        "no_speech_prob": 0.0013885145308449864,
        "seek": 546922,
        "start": 5487.22,
        "temperature": 0,
        "text": " The thing is, what do I need to do?",
        "tokens": [
          51264,
          440,
          551,
          307,
          11,
          437,
          360,
          286,
          643,
          281,
          360,
          30,
          51414
        ]
      },
      {
        "avg_logprob": -0.20302106373345674,
        "compression_ratio": 1.6360153256704981,
        "end": 5492.22,
        "id": 1562,
        "no_speech_prob": 0.0013885145308449864,
        "seek": 546922,
        "start": 5490.22,
        "temperature": 0,
        "text": " Right here, this is what I need to replace.",
        "tokens": [
          51414,
          1779,
          510,
          11,
          341,
          307,
          437,
          286,
          643,
          281,
          7406,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.20302106373345674,
        "compression_ratio": 1.6360153256704981,
        "end": 5495.22,
        "id": 1563,
        "no_speech_prob": 0.0013885145308449864,
        "seek": 546922,
        "start": 5492.22,
        "temperature": 0,
        "text": " I still want to go through every particle.",
        "tokens": [
          51514,
          286,
          920,
          528,
          281,
          352,
          807,
          633,
          12359,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.20302106373345674,
        "compression_ratio": 1.6360153256704981,
        "end": 5498.22,
        "id": 1564,
        "no_speech_prob": 0.0013885145308449864,
        "seek": 546922,
        "start": 5495.22,
        "temperature": 0,
        "text": " But now, instead of looking at every, every, every, every particle,",
        "tokens": [
          51664,
          583,
          586,
          11,
          2602,
          295,
          1237,
          412,
          633,
          11,
          633,
          11,
          633,
          11,
          633,
          12359,
          11,
          51814
        ]
      },
      {
        "avg_logprob": -0.18531076447302555,
        "compression_ratio": 1.73,
        "end": 5500.22,
        "id": 1565,
        "no_speech_prob": 0.0002531537029426545,
        "seek": 549822,
        "start": 5498.22,
        "temperature": 0,
        "text": " I want to just query.",
        "tokens": [
          50364,
          286,
          528,
          281,
          445,
          14581,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.18531076447302555,
        "compression_ratio": 1.73,
        "end": 5502.22,
        "id": 1566,
        "no_speech_prob": 0.0002531537029426545,
        "seek": 549822,
        "start": 5500.22,
        "temperature": 0,
        "text": " I'm going to say, let others equal...",
        "tokens": [
          50464,
          286,
          478,
          516,
          281,
          584,
          11,
          718,
          2357,
          2681,
          485,
          50564
        ]
      },
      {
        "avg_logprob": -0.18531076447302555,
        "compression_ratio": 1.73,
        "end": 5505.22,
        "id": 1567,
        "no_speech_prob": 0.0002531537029426545,
        "seek": 549822,
        "start": 5502.22,
        "temperature": 0,
        "text": " Oh, wait! I have to create a quadtree!",
        "tokens": [
          50564,
          876,
          11,
          1699,
          0,
          286,
          362,
          281,
          1884,
          257,
          10787,
          83,
          701,
          0,
          50714
        ]
      },
      {
        "avg_logprob": -0.18531076447302555,
        "compression_ratio": 1.73,
        "end": 5508.22,
        "id": 1568,
        "no_speech_prob": 0.0002531537029426545,
        "seek": 549822,
        "start": 5505.22,
        "temperature": 0,
        "text": " So, first I need a quadtree variable.",
        "tokens": [
          50714,
          407,
          11,
          700,
          286,
          643,
          257,
          10787,
          83,
          701,
          7006,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.18531076447302555,
        "compression_ratio": 1.73,
        "end": 5510.22,
        "id": 1569,
        "no_speech_prob": 0.0002531537029426545,
        "seek": 549822,
        "start": 5508.22,
        "temperature": 0,
        "text": " Quadtree.",
        "tokens": [
          50864,
          29619,
          83,
          701,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.18531076447302555,
        "compression_ratio": 1.73,
        "end": 5514.22,
        "id": 1570,
        "no_speech_prob": 0.0002531537029426545,
        "seek": 549822,
        "start": 5510.22,
        "temperature": 0,
        "text": " Then I'm going to say, quadtree is a new quadtree.",
        "tokens": [
          50964,
          1396,
          286,
          478,
          516,
          281,
          584,
          11,
          10787,
          83,
          701,
          307,
          257,
          777,
          10787,
          83,
          701,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.18531076447302555,
        "compression_ratio": 1.73,
        "end": 5518.22,
        "id": 1571,
        "no_speech_prob": 0.0002531537029426545,
        "seek": 549822,
        "start": 5514.22,
        "temperature": 0,
        "text": " I did that coding challenge so long ago, I've forgotten what I need.",
        "tokens": [
          51164,
          286,
          630,
          300,
          17720,
          3430,
          370,
          938,
          2057,
          11,
          286,
          600,
          11832,
          437,
          286,
          643,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.18531076447302555,
        "compression_ratio": 1.73,
        "end": 5520.22,
        "id": 1572,
        "no_speech_prob": 0.0002531537029426545,
        "seek": 549822,
        "start": 5518.22,
        "temperature": 0,
        "text": " I think I need a boundary.",
        "tokens": [
          51364,
          286,
          519,
          286,
          643,
          257,
          12866,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.18531076447302555,
        "compression_ratio": 1.73,
        "end": 5524.22,
        "id": 1573,
        "no_speech_prob": 0.0002531537029426545,
        "seek": 549822,
        "start": 5520.22,
        "temperature": 0,
        "text": " So, I'm going to say, a boundary is a new rectangle.",
        "tokens": [
          51464,
          407,
          11,
          286,
          478,
          516,
          281,
          584,
          11,
          257,
          12866,
          307,
          257,
          777,
          21930,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.2019180067433607,
        "compression_ratio": 1.749090909090909,
        "end": 5528.22,
        "id": 1574,
        "no_speech_prob": 0.006589635740965605,
        "seek": 552422,
        "start": 5524.22,
        "temperature": 0,
        "text": " My quadtree example has some geometry classes, like a rectangle.",
        "tokens": [
          50364,
          1222,
          10787,
          83,
          701,
          1365,
          575,
          512,
          18426,
          5359,
          11,
          411,
          257,
          21930,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.2019180067433607,
        "compression_ratio": 1.749090909090909,
        "end": 5531.22,
        "id": 1575,
        "no_speech_prob": 0.006589635740965605,
        "seek": 552422,
        "start": 5528.22,
        "temperature": 0,
        "text": " And the rectangle, I'm going to make it 300, 200.",
        "tokens": [
          50564,
          400,
          264,
          21930,
          11,
          286,
          478,
          516,
          281,
          652,
          309,
          6641,
          11,
          2331,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.2019180067433607,
        "compression_ratio": 1.749090909090909,
        "end": 5533.22,
        "id": 1576,
        "no_speech_prob": 0.006589635740965605,
        "seek": 552422,
        "start": 5531.22,
        "temperature": 0,
        "text": " That's the center.",
        "tokens": [
          50714,
          663,
          311,
          264,
          3056,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.2019180067433607,
        "compression_ratio": 1.749090909090909,
        "end": 5535.22,
        "id": 1577,
        "no_speech_prob": 0.006589635740965605,
        "seek": 552422,
        "start": 5533.22,
        "temperature": 0,
        "text": " And it's 600, 400.",
        "tokens": [
          50814,
          400,
          309,
          311,
          11849,
          11,
          8423,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.2019180067433607,
        "compression_ratio": 1.749090909090909,
        "end": 5538.22,
        "id": 1578,
        "no_speech_prob": 0.006589635740965605,
        "seek": 552422,
        "start": 5535.22,
        "temperature": 0,
        "text": " So, I probably should use width divided by 2, height divided by 2, width, height.",
        "tokens": [
          50914,
          407,
          11,
          286,
          1391,
          820,
          764,
          11402,
          6666,
          538,
          568,
          11,
          6681,
          6666,
          538,
          568,
          11,
          11402,
          11,
          6681,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.2019180067433607,
        "compression_ratio": 1.749090909090909,
        "end": 5540.22,
        "id": 1579,
        "no_speech_prob": 0.006589635740965605,
        "seek": 552422,
        "start": 5538.22,
        "temperature": 0,
        "text": " But, that's fine. I'm just going to leave that.",
        "tokens": [
          51064,
          583,
          11,
          300,
          311,
          2489,
          13,
          286,
          478,
          445,
          516,
          281,
          1856,
          300,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.2019180067433607,
        "compression_ratio": 1.749090909090909,
        "end": 5543.22,
        "id": 1580,
        "no_speech_prob": 0.006589635740965605,
        "seek": 552422,
        "start": 5540.22,
        "temperature": 0,
        "text": " So, I'm going to make a new quadtree with that boundary.",
        "tokens": [
          51164,
          407,
          11,
          286,
          478,
          516,
          281,
          652,
          257,
          777,
          10787,
          83,
          701,
          365,
          300,
          12866,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.2019180067433607,
        "compression_ratio": 1.749090909090909,
        "end": 5546.22,
        "id": 1581,
        "no_speech_prob": 0.006589635740965605,
        "seek": 552422,
        "start": 5543.22,
        "temperature": 0,
        "text": " Then, what I'm going to do...",
        "tokens": [
          51314,
          1396,
          11,
          437,
          286,
          478,
          516,
          281,
          360,
          485,
          51464
        ]
      },
      {
        "avg_logprob": -0.2019180067433607,
        "compression_ratio": 1.749090909090909,
        "end": 5549.22,
        "id": 1582,
        "no_speech_prob": 0.006589635740965605,
        "seek": 552422,
        "start": 5546.22,
        "temperature": 0,
        "text": " And I think this got added after...",
        "tokens": [
          51464,
          400,
          286,
          519,
          341,
          658,
          3869,
          934,
          485,
          51614
        ]
      },
      {
        "avg_logprob": -0.2019180067433607,
        "compression_ratio": 1.749090909090909,
        "end": 5551.22,
        "id": 1583,
        "no_speech_prob": 0.006589635740965605,
        "seek": 552422,
        "start": 5549.22,
        "temperature": 0,
        "text": " So, one of the things that actually...",
        "tokens": [
          51614,
          407,
          11,
          472,
          295,
          264,
          721,
          300,
          767,
          485,
          51714
        ]
      },
      {
        "avg_logprob": -0.2019180067433607,
        "compression_ratio": 1.749090909090909,
        "end": 5553.22,
        "id": 1584,
        "no_speech_prob": 0.006589635740965605,
        "seek": 552422,
        "start": 5551.22,
        "temperature": 0,
        "text": " I can't believe I forgot about this.",
        "tokens": [
          51714,
          286,
          393,
          380,
          1697,
          286,
          5298,
          466,
          341,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.1622705654222138,
        "compression_ratio": 1.6605839416058394,
        "end": 5555.22,
        "id": 1585,
        "no_speech_prob": 0.0006361842388287187,
        "seek": 555322,
        "start": 5553.22,
        "temperature": 0,
        "text": " But, these things are moving.",
        "tokens": [
          50364,
          583,
          11,
          613,
          721,
          366,
          2684,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.1622705654222138,
        "compression_ratio": 1.6605839416058394,
        "end": 5558.22,
        "id": 1586,
        "no_speech_prob": 0.0006361842388287187,
        "seek": 555322,
        "start": 5555.22,
        "temperature": 0,
        "text": " So, if I build the quadtree with all of those particles,",
        "tokens": [
          50464,
          407,
          11,
          498,
          286,
          1322,
          264,
          10787,
          83,
          701,
          365,
          439,
          295,
          729,
          10007,
          11,
          50614
        ]
      },
      {
        "avg_logprob": -0.1622705654222138,
        "compression_ratio": 1.6605839416058394,
        "end": 5560.22,
        "id": 1587,
        "no_speech_prob": 0.0006361842388287187,
        "seek": 555322,
        "start": 5558.22,
        "temperature": 0,
        "text": " as soon as they move...",
        "tokens": [
          50614,
          382,
          2321,
          382,
          436,
          1286,
          485,
          50714
        ]
      },
      {
        "avg_logprob": -0.1622705654222138,
        "compression_ratio": 1.6605839416058394,
        "end": 5562.22,
        "id": 1588,
        "no_speech_prob": 0.0006361842388287187,
        "seek": 555322,
        "start": 5560.22,
        "temperature": 0,
        "text": " Oh my god, I'm missing so many pieces here.",
        "tokens": [
          50714,
          876,
          452,
          3044,
          11,
          286,
          478,
          5361,
          370,
          867,
          3755,
          510,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.1622705654222138,
        "compression_ratio": 1.6605839416058394,
        "end": 5564.22,
        "id": 1589,
        "no_speech_prob": 0.0006361842388287187,
        "seek": 555322,
        "start": 5562.22,
        "temperature": 0,
        "text": " Ah, there's more to this video than I thought.",
        "tokens": [
          50814,
          2438,
          11,
          456,
          311,
          544,
          281,
          341,
          960,
          813,
          286,
          1194,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.1622705654222138,
        "compression_ratio": 1.6605839416058394,
        "end": 5566.22,
        "id": 1590,
        "no_speech_prob": 0.0006361842388287187,
        "seek": 555322,
        "start": 5564.22,
        "temperature": 0,
        "text": " Alright, hold on. Here we go.",
        "tokens": [
          50914,
          2798,
          11,
          1797,
          322,
          13,
          1692,
          321,
          352,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.1622705654222138,
        "compression_ratio": 1.6605839416058394,
        "end": 5567.22,
        "id": 1591,
        "no_speech_prob": 0.0006361842388287187,
        "seek": 555322,
        "start": 5566.22,
        "temperature": 0,
        "text": " This is going to be good.",
        "tokens": [
          51014,
          639,
          307,
          516,
          281,
          312,
          665,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.1622705654222138,
        "compression_ratio": 1.6605839416058394,
        "end": 5569.22,
        "id": 1592,
        "no_speech_prob": 0.0006361842388287187,
        "seek": 555322,
        "start": 5567.22,
        "temperature": 0,
        "text": " I knew there was something going on here.",
        "tokens": [
          51064,
          286,
          2586,
          456,
          390,
          746,
          516,
          322,
          510,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.1622705654222138,
        "compression_ratio": 1.6605839416058394,
        "end": 5570.22,
        "id": 1593,
        "no_speech_prob": 0.0006361842388287187,
        "seek": 555322,
        "start": 5569.22,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          51164,
          1033,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.1622705654222138,
        "compression_ratio": 1.6605839416058394,
        "end": 5573.22,
        "id": 1594,
        "no_speech_prob": 0.0006361842388287187,
        "seek": 555322,
        "start": 5570.22,
        "temperature": 0,
        "text": " So, what does this quadtree expect?",
        "tokens": [
          51214,
          407,
          11,
          437,
          775,
          341,
          10787,
          83,
          701,
          2066,
          30,
          51364
        ]
      },
      {
        "avg_logprob": -0.1622705654222138,
        "compression_ratio": 1.6605839416058394,
        "end": 5578.22,
        "id": 1595,
        "no_speech_prob": 0.0006361842388287187,
        "seek": 555322,
        "start": 5573.22,
        "temperature": 0,
        "text": " The quadtree, if I look at it, it expects me to insert a point.",
        "tokens": [
          51364,
          440,
          10787,
          83,
          701,
          11,
          498,
          286,
          574,
          412,
          309,
          11,
          309,
          33280,
          385,
          281,
          8969,
          257,
          935,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.1622705654222138,
        "compression_ratio": 1.6605839416058394,
        "end": 5582.22,
        "id": 1596,
        "no_speech_prob": 0.0006361842388287187,
        "seek": 555322,
        "start": 5578.22,
        "temperature": 0,
        "text": " A point is a particular object with an x and a y.",
        "tokens": [
          51614,
          316,
          935,
          307,
          257,
          1729,
          2657,
          365,
          364,
          2031,
          293,
          257,
          288,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.17264780461393445,
        "compression_ratio": 1.8076923076923077,
        "end": 5584.22,
        "id": 1597,
        "no_speech_prob": 0.001956992782652378,
        "seek": 558222,
        "start": 5582.22,
        "temperature": 0,
        "text": " Oh, look. I already added this.",
        "tokens": [
          50364,
          876,
          11,
          574,
          13,
          286,
          1217,
          3869,
          341,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.17264780461393445,
        "compression_ratio": 1.8076923076923077,
        "end": 5587.22,
        "id": 1598,
        "no_speech_prob": 0.001956992782652378,
        "seek": 558222,
        "start": 5584.22,
        "temperature": 0,
        "text": " So, if you follow the last tutorial, this won't be there.",
        "tokens": [
          50464,
          407,
          11,
          498,
          291,
          1524,
          264,
          1036,
          7073,
          11,
          341,
          1582,
          380,
          312,
          456,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.17264780461393445,
        "compression_ratio": 1.8076923076923077,
        "end": 5589.22,
        "id": 1599,
        "no_speech_prob": 0.001956992782652378,
        "seek": 558222,
        "start": 5587.22,
        "temperature": 0,
        "text": " Let's take this out.",
        "tokens": [
          50614,
          961,
          311,
          747,
          341,
          484,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.17264780461393445,
        "compression_ratio": 1.8076923076923077,
        "end": 5590.22,
        "id": 1600,
        "no_speech_prob": 0.001956992782652378,
        "seek": 558222,
        "start": 5589.22,
        "temperature": 0,
        "text": " So, here's the idea.",
        "tokens": [
          50714,
          407,
          11,
          510,
          311,
          264,
          1558,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.17264780461393445,
        "compression_ratio": 1.8076923076923077,
        "end": 5592.22,
        "id": 1601,
        "no_speech_prob": 0.001956992782652378,
        "seek": 558222,
        "start": 5590.22,
        "temperature": 0,
        "text": " Let's watch and learn.",
        "tokens": [
          50764,
          961,
          311,
          1159,
          293,
          1466,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.17264780461393445,
        "compression_ratio": 1.8076923076923077,
        "end": 5593.22,
        "id": 1602,
        "no_speech_prob": 0.001956992782652378,
        "seek": 558222,
        "start": 5592.22,
        "temperature": 0,
        "text": " Okay, here we go.",
        "tokens": [
          50864,
          1033,
          11,
          510,
          321,
          352,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.17264780461393445,
        "compression_ratio": 1.8076923076923077,
        "end": 5595.22,
        "id": 1603,
        "no_speech_prob": 0.001956992782652378,
        "seek": 558222,
        "start": 5593.22,
        "temperature": 0,
        "text": " This is where I left off in the last tutorial.",
        "tokens": [
          50914,
          639,
          307,
          689,
          286,
          1411,
          766,
          294,
          264,
          1036,
          7073,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.17264780461393445,
        "compression_ratio": 1.8076923076923077,
        "end": 5596.22,
        "id": 1604,
        "no_speech_prob": 0.001956992782652378,
        "seek": 558222,
        "start": 5595.22,
        "temperature": 0,
        "text": " Oh, I forgot about this.",
        "tokens": [
          51014,
          876,
          11,
          286,
          5298,
          466,
          341,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.17264780461393445,
        "compression_ratio": 1.8076923076923077,
        "end": 5598.22,
        "id": 1605,
        "no_speech_prob": 0.001956992782652378,
        "seek": 558222,
        "start": 5596.22,
        "temperature": 0,
        "text": " Now, I'm going to go back to my code.",
        "tokens": [
          51064,
          823,
          11,
          286,
          478,
          516,
          281,
          352,
          646,
          281,
          452,
          3089,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.17264780461393445,
        "compression_ratio": 1.8076923076923077,
        "end": 5599.22,
        "id": 1606,
        "no_speech_prob": 0.001956992782652378,
        "seek": 558222,
        "start": 5598.22,
        "temperature": 0,
        "text": " Save this.",
        "tokens": [
          51164,
          15541,
          341,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.17264780461393445,
        "compression_ratio": 1.8076923076923077,
        "end": 5600.22,
        "id": 1607,
        "no_speech_prob": 0.001956992782652378,
        "seek": 558222,
        "start": 5599.22,
        "temperature": 0,
        "text": " And I'm going to say...",
        "tokens": [
          51214,
          400,
          286,
          478,
          516,
          281,
          584,
          485,
          51264
        ]
      },
      {
        "avg_logprob": -0.17264780461393445,
        "compression_ratio": 1.8076923076923077,
        "end": 5601.22,
        "id": 1608,
        "no_speech_prob": 0.001956992782652378,
        "seek": 558222,
        "start": 5600.22,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          51264,
          1033,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.17264780461393445,
        "compression_ratio": 1.8076923076923077,
        "end": 5603.22,
        "id": 1609,
        "no_speech_prob": 0.001956992782652378,
        "seek": 558222,
        "start": 5601.22,
        "temperature": 0,
        "text": " What I want to do is I want to build this quadtree.",
        "tokens": [
          51314,
          708,
          286,
          528,
          281,
          360,
          307,
          286,
          528,
          281,
          1322,
          341,
          10787,
          83,
          701,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.17264780461393445,
        "compression_ratio": 1.8076923076923077,
        "end": 5605.22,
        "id": 1610,
        "no_speech_prob": 0.001956992782652378,
        "seek": 558222,
        "start": 5603.22,
        "temperature": 0,
        "text": " So, what I'm going to do is I'm going to say...",
        "tokens": [
          51414,
          407,
          11,
          437,
          286,
          478,
          516,
          281,
          360,
          307,
          286,
          478,
          516,
          281,
          584,
          485,
          51514
        ]
      },
      {
        "avg_logprob": -0.17255499928267962,
        "compression_ratio": 1.7105263157894737,
        "end": 5607.22,
        "id": 1611,
        "no_speech_prob": 0.013020261190831661,
        "seek": 560522,
        "start": 5606.22,
        "temperature": 0,
        "text": " I'm going to say...",
        "tokens": [
          50414,
          286,
          478,
          516,
          281,
          584,
          485,
          50464
        ]
      },
      {
        "avg_logprob": -0.17255499928267962,
        "compression_ratio": 1.7105263157894737,
        "end": 5620.22,
        "id": 1612,
        "no_speech_prob": 0.013020261190831661,
        "seek": 560522,
        "start": 5619.22,
        "temperature": 0,
        "text": " Right?",
        "tokens": [
          51064,
          1779,
          30,
          51114
        ]
      },
      {
        "avg_logprob": -0.17255499928267962,
        "compression_ratio": 1.7105263157894737,
        "end": 5621.22,
        "id": 1613,
        "no_speech_prob": 0.013020261190831661,
        "seek": 560522,
        "start": 5620.22,
        "temperature": 0,
        "text": " This is where I last left off.",
        "tokens": [
          51114,
          639,
          307,
          689,
          286,
          1036,
          1411,
          766,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.17255499928267962,
        "compression_ratio": 1.7105263157894737,
        "end": 5624.22,
        "id": 1614,
        "no_speech_prob": 0.013020261190831661,
        "seek": 560522,
        "start": 5621.22,
        "temperature": 0,
        "text": " I'm creating a point object and putting the point object in the quadtree.",
        "tokens": [
          51164,
          286,
          478,
          4084,
          257,
          935,
          2657,
          293,
          3372,
          264,
          935,
          2657,
          294,
          264,
          10787,
          83,
          701,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.17255499928267962,
        "compression_ratio": 1.7105263157894737,
        "end": 5628.22,
        "id": 1615,
        "no_speech_prob": 0.013020261190831661,
        "seek": 560522,
        "start": 5624.22,
        "temperature": 0,
        "text": " The quadtree is going to organize itself to keep points together that need to be together.",
        "tokens": [
          51314,
          440,
          10787,
          83,
          701,
          307,
          516,
          281,
          13859,
          2564,
          281,
          1066,
          2793,
          1214,
          300,
          643,
          281,
          312,
          1214,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.17255499928267962,
        "compression_ratio": 1.7105263157894737,
        "end": 5630.22,
        "id": 1616,
        "no_speech_prob": 0.013020261190831661,
        "seek": 560522,
        "start": 5628.22,
        "temperature": 0,
        "text": " But here's the thing.",
        "tokens": [
          51514,
          583,
          510,
          311,
          264,
          551,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.17255499928267962,
        "compression_ratio": 1.7105263157894737,
        "end": 5632.22,
        "id": 1617,
        "no_speech_prob": 0.013020261190831661,
        "seek": 560522,
        "start": 5630.22,
        "temperature": 0,
        "text": " I've now made this new point object.",
        "tokens": [
          51614,
          286,
          600,
          586,
          1027,
          341,
          777,
          935,
          2657,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.17255499928267962,
        "compression_ratio": 1.7105263157894737,
        "end": 5634.22,
        "id": 1618,
        "no_speech_prob": 0.013020261190831661,
        "seek": 560522,
        "start": 5632.22,
        "temperature": 0,
        "text": " I want to put the particle in the quadtree.",
        "tokens": [
          51714,
          286,
          528,
          281,
          829,
          264,
          12359,
          294,
          264,
          10787,
          83,
          701,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.17156341448933088,
        "compression_ratio": 1.7234726688102895,
        "end": 5637.22,
        "id": 1619,
        "no_speech_prob": 0.000896936864592135,
        "seek": 563422,
        "start": 5634.22,
        "temperature": 0,
        "text": " So, really, I want my quadtree to store the particles.",
        "tokens": [
          50364,
          407,
          11,
          534,
          11,
          286,
          528,
          452,
          10787,
          83,
          701,
          281,
          3531,
          264,
          10007,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.17156341448933088,
        "compression_ratio": 1.7234726688102895,
        "end": 5639.22,
        "id": 1620,
        "no_speech_prob": 0.000896936864592135,
        "seek": 563422,
        "start": 5637.22,
        "temperature": 0,
        "text": " And then the particles are moving.",
        "tokens": [
          50514,
          400,
          550,
          264,
          10007,
          366,
          2684,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.17156341448933088,
        "compression_ratio": 1.7234726688102895,
        "end": 5641.22,
        "id": 1621,
        "no_speech_prob": 0.000896936864592135,
        "seek": 563422,
        "start": 5639.22,
        "temperature": 0,
        "text": " So, I've got to update their location in the quadtree.",
        "tokens": [
          50614,
          407,
          11,
          286,
          600,
          658,
          281,
          5623,
          641,
          4914,
          294,
          264,
          10787,
          83,
          701,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.17156341448933088,
        "compression_ratio": 1.7234726688102895,
        "end": 5643.22,
        "id": 1622,
        "no_speech_prob": 0.000896936864592135,
        "seek": 563422,
        "start": 5641.22,
        "temperature": 0,
        "text": " How am I going to deal with this?",
        "tokens": [
          50714,
          1012,
          669,
          286,
          516,
          281,
          2028,
          365,
          341,
          30,
          50814
        ]
      },
      {
        "avg_logprob": -0.17156341448933088,
        "compression_ratio": 1.7234726688102895,
        "end": 5645.22,
        "id": 1623,
        "no_speech_prob": 0.000896936864592135,
        "seek": 563422,
        "start": 5643.22,
        "temperature": 0,
        "text": " Well, there are a variety of solutions to this.",
        "tokens": [
          50814,
          1042,
          11,
          456,
          366,
          257,
          5673,
          295,
          6547,
          281,
          341,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.17156341448933088,
        "compression_ratio": 1.7234726688102895,
        "end": 5651.22,
        "id": 1624,
        "no_speech_prob": 0.000896936864592135,
        "seek": 563422,
        "start": 5645.22,
        "temperature": 0,
        "text": " Number one, I wrote the quadtree code so I could just rewrite it to work with my particle object instead of the point object.",
        "tokens": [
          50914,
          5118,
          472,
          11,
          286,
          4114,
          264,
          10787,
          83,
          701,
          3089,
          370,
          286,
          727,
          445,
          28132,
          309,
          281,
          589,
          365,
          452,
          12359,
          2657,
          2602,
          295,
          264,
          935,
          2657,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.17156341448933088,
        "compression_ratio": 1.7234726688102895,
        "end": 5655.22,
        "id": 1625,
        "no_speech_prob": 0.000896936864592135,
        "seek": 563422,
        "start": 5651.22,
        "temperature": 0,
        "text": " But something I could do to make it more generic is I could add...",
        "tokens": [
          51214,
          583,
          746,
          286,
          727,
          360,
          281,
          652,
          309,
          544,
          19577,
          307,
          286,
          727,
          909,
          485,
          51414
        ]
      },
      {
        "avg_logprob": -0.17156341448933088,
        "compression_ratio": 1.7234726688102895,
        "end": 5659.22,
        "id": 1626,
        "no_speech_prob": 0.000896936864592135,
        "seek": 563422,
        "start": 5655.22,
        "temperature": 0,
        "text": " This box2d works this way and some physics libraries do.",
        "tokens": [
          51414,
          639,
          2424,
          17,
          67,
          1985,
          341,
          636,
          293,
          512,
          10649,
          15148,
          360,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.17156341448933088,
        "compression_ratio": 1.7234726688102895,
        "end": 5663.22,
        "id": 1627,
        "no_speech_prob": 0.000896936864592135,
        "seek": 563422,
        "start": 5659.22,
        "temperature": 0,
        "text": " I could add a property to the point object called userData.",
        "tokens": [
          51614,
          286,
          727,
          909,
          257,
          4707,
          281,
          264,
          935,
          2657,
          1219,
          4195,
          35,
          3274,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.18415432531856796,
        "compression_ratio": 1.775330396475771,
        "end": 5675.22,
        "id": 1628,
        "no_speech_prob": 0.00007967263809405267,
        "seek": 566322,
        "start": 5664.22,
        "temperature": 0,
        "text": " And what that means is when I create a point object, the core data that I need for the quadtree is its x, y location.",
        "tokens": [
          50414,
          400,
          437,
          300,
          1355,
          307,
          562,
          286,
          1884,
          257,
          935,
          2657,
          11,
          264,
          4965,
          1412,
          300,
          286,
          643,
          337,
          264,
          10787,
          83,
          701,
          307,
          1080,
          2031,
          11,
          288,
          4914,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.18415432531856796,
        "compression_ratio": 1.775330396475771,
        "end": 5683.22,
        "id": 1629,
        "no_speech_prob": 0.00007967263809405267,
        "seek": 566322,
        "start": 5675.22,
        "temperature": 0,
        "text": " But I could also say attach yourself to this other object so that when I find this x, y location, I can know that it's attached to this particular particle.",
        "tokens": [
          50964,
          583,
          286,
          727,
          611,
          584,
          5085,
          1803,
          281,
          341,
          661,
          2657,
          370,
          300,
          562,
          286,
          915,
          341,
          2031,
          11,
          288,
          4914,
          11,
          286,
          393,
          458,
          300,
          309,
          311,
          8570,
          281,
          341,
          1729,
          12359,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.18415432531856796,
        "compression_ratio": 1.775330396475771,
        "end": 5692.22,
        "id": 1630,
        "no_speech_prob": 0.00007967263809405267,
        "seek": 566322,
        "start": 5683.22,
        "temperature": 0,
        "text": " So, in other words, what I can do now is I can say make a new point with this particle's x and y referencing also this particle.",
        "tokens": [
          51364,
          407,
          11,
          294,
          661,
          2283,
          11,
          437,
          286,
          393,
          360,
          586,
          307,
          286,
          393,
          584,
          652,
          257,
          777,
          935,
          365,
          341,
          12359,
          311,
          2031,
          293,
          288,
          40582,
          611,
          341,
          12359,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.19144214408985083,
        "compression_ratio": 1.723021582733813,
        "end": 5695.22,
        "id": 1631,
        "no_speech_prob": 0.039046332240104675,
        "seek": 569222,
        "start": 5692.22,
        "temperature": 0,
        "text": " Again, there's some redundancy here, but this will work well enough.",
        "tokens": [
          50364,
          3764,
          11,
          456,
          311,
          512,
          27830,
          6717,
          510,
          11,
          457,
          341,
          486,
          589,
          731,
          1547,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.19144214408985083,
        "compression_ratio": 1.723021582733813,
        "end": 5696.22,
        "id": 1632,
        "no_speech_prob": 0.039046332240104675,
        "seek": 569222,
        "start": 5695.22,
        "temperature": 0,
        "text": " It's also very generic.",
        "tokens": [
          50514,
          467,
          311,
          611,
          588,
          19577,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.19144214408985083,
        "compression_ratio": 1.723021582733813,
        "end": 5703.22,
        "id": 1633,
        "no_speech_prob": 0.039046332240104675,
        "seek": 569222,
        "start": 5696.22,
        "temperature": 0,
        "text": " So, if somebody else is using this quadtree as a library, they could kind of use it with whatever classes they've created.",
        "tokens": [
          50564,
          407,
          11,
          498,
          2618,
          1646,
          307,
          1228,
          341,
          10787,
          83,
          701,
          382,
          257,
          6405,
          11,
          436,
          727,
          733,
          295,
          764,
          309,
          365,
          2035,
          5359,
          436,
          600,
          2942,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.19144214408985083,
        "compression_ratio": 1.723021582733813,
        "end": 5704.22,
        "id": 1634,
        "no_speech_prob": 0.039046332240104675,
        "seek": 569222,
        "start": 5703.22,
        "temperature": 0,
        "text": " But here's the thing.",
        "tokens": [
          50914,
          583,
          510,
          311,
          264,
          551,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.19144214408985083,
        "compression_ratio": 1.723021582733813,
        "end": 5708.22,
        "id": 1635,
        "no_speech_prob": 0.039046332240104675,
        "seek": 569222,
        "start": 5704.22,
        "temperature": 0,
        "text": " This created that quadtree, but as soon as I go, all the points move.",
        "tokens": [
          50964,
          639,
          2942,
          300,
          10787,
          83,
          701,
          11,
          457,
          382,
          2321,
          382,
          286,
          352,
          11,
          439,
          264,
          2793,
          1286,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.19144214408985083,
        "compression_ratio": 1.723021582733813,
        "end": 5709.22,
        "id": 1636,
        "no_speech_prob": 0.039046332240104675,
        "seek": 569222,
        "start": 5708.22,
        "temperature": 0,
        "text": " They're going to be in a different location.",
        "tokens": [
          51164,
          814,
          434,
          516,
          281,
          312,
          294,
          257,
          819,
          4914,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.19144214408985083,
        "compression_ratio": 1.723021582733813,
        "end": 5711.22,
        "id": 1637,
        "no_speech_prob": 0.039046332240104675,
        "seek": 569222,
        "start": 5709.22,
        "temperature": 0,
        "text": " They're not where they originally were.",
        "tokens": [
          51214,
          814,
          434,
          406,
          689,
          436,
          7993,
          645,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.19144214408985083,
        "compression_ratio": 1.723021582733813,
        "end": 5713.22,
        "id": 1638,
        "no_speech_prob": 0.039046332240104675,
        "seek": 569222,
        "start": 5711.22,
        "temperature": 0,
        "text": " So, actually, I don't want to do this here.",
        "tokens": [
          51314,
          407,
          11,
          767,
          11,
          286,
          500,
          380,
          528,
          281,
          360,
          341,
          510,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.19144214408985083,
        "compression_ratio": 1.723021582733813,
        "end": 5717.22,
        "id": 1639,
        "no_speech_prob": 0.039046332240104675,
        "seek": 569222,
        "start": 5713.22,
        "temperature": 0,
        "text": " What I want to do is do this here in draw.",
        "tokens": [
          51414,
          708,
          286,
          528,
          281,
          360,
          307,
          360,
          341,
          510,
          294,
          2642,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.18570769011084712,
        "compression_ratio": 1.7755102040816326,
        "end": 5722.22,
        "id": 1640,
        "no_speech_prob": 0.017176494002342224,
        "seek": 571722,
        "start": 5718.22,
        "temperature": 0,
        "text": " The nice thing about this is I have the particle and a variable called p.",
        "tokens": [
          50414,
          440,
          1481,
          551,
          466,
          341,
          307,
          286,
          362,
          264,
          12359,
          293,
          257,
          7006,
          1219,
          280,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.18570769011084712,
        "compression_ratio": 1.7755102040816326,
        "end": 5724.22,
        "id": 1641,
        "no_speech_prob": 0.017176494002342224,
        "seek": 571722,
        "start": 5722.22,
        "temperature": 0,
        "text": " So, I want to create a new point.",
        "tokens": [
          50614,
          407,
          11,
          286,
          528,
          281,
          1884,
          257,
          777,
          935,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.18570769011084712,
        "compression_ratio": 1.7755102040816326,
        "end": 5728.22,
        "id": 1642,
        "no_speech_prob": 0.017176494002342224,
        "seek": 571722,
        "start": 5726.22,
        "temperature": 0,
        "text": " Whoops, what is going on here?",
        "tokens": [
          50814,
          45263,
          11,
          437,
          307,
          516,
          322,
          510,
          30,
          50914
        ]
      },
      {
        "avg_logprob": -0.18570769011084712,
        "compression_ratio": 1.7755102040816326,
        "end": 5729.22,
        "id": 1643,
        "no_speech_prob": 0.017176494002342224,
        "seek": 571722,
        "start": 5728.22,
        "temperature": 0,
        "text": " Give me back my code.",
        "tokens": [
          50914,
          5303,
          385,
          646,
          452,
          3089,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.18570769011084712,
        "compression_ratio": 1.7755102040816326,
        "end": 5731.22,
        "id": 1644,
        "no_speech_prob": 0.017176494002342224,
        "seek": 571722,
        "start": 5729.22,
        "temperature": 0,
        "text": " Give me back my code!",
        "tokens": [
          50964,
          5303,
          385,
          646,
          452,
          3089,
          0,
          51064
        ]
      },
      {
        "avg_logprob": -0.18570769011084712,
        "compression_ratio": 1.7755102040816326,
        "end": 5737.22,
        "id": 1645,
        "no_speech_prob": 0.017176494002342224,
        "seek": 571722,
        "start": 5731.22,
        "temperature": 0,
        "text": " Okay, I want to create a new point at an x and y with a p, and I want to insert it into the quadtree.",
        "tokens": [
          51064,
          1033,
          11,
          286,
          528,
          281,
          1884,
          257,
          777,
          935,
          412,
          364,
          2031,
          293,
          288,
          365,
          257,
          280,
          11,
          293,
          286,
          528,
          281,
          8969,
          309,
          666,
          264,
          10787,
          83,
          701,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.18570769011084712,
        "compression_ratio": 1.7755102040816326,
        "end": 5740.22,
        "id": 1646,
        "no_speech_prob": 0.017176494002342224,
        "seek": 571722,
        "start": 5737.22,
        "temperature": 0,
        "text": " But draw is looping over and over again.",
        "tokens": [
          51364,
          583,
          2642,
          307,
          6367,
          278,
          670,
          293,
          670,
          797,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.18570769011084712,
        "compression_ratio": 1.7755102040816326,
        "end": 5743.22,
        "id": 1647,
        "no_speech_prob": 0.017176494002342224,
        "seek": 571722,
        "start": 5740.22,
        "temperature": 0,
        "text": " So, when I insert the first time, the next time I don't want to reinsert.",
        "tokens": [
          51514,
          407,
          11,
          562,
          286,
          8969,
          264,
          700,
          565,
          11,
          264,
          958,
          565,
          286,
          500,
          380,
          528,
          281,
          47200,
          911,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.18570769011084712,
        "compression_ratio": 1.7755102040816326,
        "end": 5744.22,
        "id": 1648,
        "no_speech_prob": 0.017176494002342224,
        "seek": 571722,
        "start": 5743.22,
        "temperature": 0,
        "text": " I just want to update its location.",
        "tokens": [
          51664,
          286,
          445,
          528,
          281,
          5623,
          1080,
          4914,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.14412423430896196,
        "compression_ratio": 1.71280276816609,
        "end": 5752.22,
        "id": 1649,
        "no_speech_prob": 0.0008693596464581788,
        "seek": 574422,
        "start": 5744.22,
        "temperature": 0,
        "text": " Well, the truth of the matter is while that would be a nice way of doing it, updating the locations and probably most efficient,",
        "tokens": [
          50364,
          1042,
          11,
          264,
          3494,
          295,
          264,
          1871,
          307,
          1339,
          300,
          576,
          312,
          257,
          1481,
          636,
          295,
          884,
          309,
          11,
          25113,
          264,
          9253,
          293,
          1391,
          881,
          7148,
          11,
          50764
        ]
      },
      {
        "avg_logprob": -0.14412423430896196,
        "compression_ratio": 1.71280276816609,
        "end": 5757.22,
        "id": 1650,
        "no_speech_prob": 0.0008693596464581788,
        "seek": 574422,
        "start": 5752.22,
        "temperature": 0,
        "text": " it actually is a little bit simpler if I just remake the quadtree every frame.",
        "tokens": [
          50764,
          309,
          767,
          307,
          257,
          707,
          857,
          18587,
          498,
          286,
          445,
          28582,
          264,
          10787,
          83,
          701,
          633,
          3920,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.14412423430896196,
        "compression_ratio": 1.71280276816609,
        "end": 5763.22,
        "id": 1651,
        "no_speech_prob": 0.0008693596464581788,
        "seek": 574422,
        "start": 5757.22,
        "temperature": 0,
        "text": " The quadtree is a thing that I'm just going to recreate every frame for the purpose of optimizing the collision detection.",
        "tokens": [
          51014,
          440,
          10787,
          83,
          701,
          307,
          257,
          551,
          300,
          286,
          478,
          445,
          516,
          281,
          25833,
          633,
          3920,
          337,
          264,
          4334,
          295,
          40425,
          264,
          24644,
          17784,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.14412423430896196,
        "compression_ratio": 1.71280276816609,
        "end": 5768.22,
        "id": 1652,
        "no_speech_prob": 0.0008693596464581788,
        "seek": 574422,
        "start": 5763.22,
        "temperature": 0,
        "text": " So, again, I could be more thoughtful about this and have a global quadtree.",
        "tokens": [
          51314,
          407,
          11,
          797,
          11,
          286,
          727,
          312,
          544,
          21566,
          466,
          341,
          293,
          362,
          257,
          4338,
          10787,
          83,
          701,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.14412423430896196,
        "compression_ratio": 1.71280276816609,
        "end": 5772.22,
        "id": 1653,
        "no_speech_prob": 0.0008693596464581788,
        "seek": 574422,
        "start": 5768.22,
        "temperature": 0,
        "text": " I think there's even maybe a clear function by now in that quadtree class that I wrote.",
        "tokens": [
          51564,
          286,
          519,
          456,
          311,
          754,
          1310,
          257,
          1850,
          2445,
          538,
          586,
          294,
          300,
          10787,
          83,
          701,
          1508,
          300,
          286,
          4114,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.19497441082465938,
        "compression_ratio": 1.4894736842105263,
        "end": 5776.22,
        "id": 1654,
        "no_speech_prob": 0.0006666964036412537,
        "seek": 577222,
        "start": 5772.22,
        "temperature": 0,
        "text": " But I'm just going to remake the quadtree object every frame, build it from scratch.",
        "tokens": [
          50364,
          583,
          286,
          478,
          445,
          516,
          281,
          28582,
          264,
          10787,
          83,
          701,
          2657,
          633,
          3920,
          11,
          1322,
          309,
          490,
          8459,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.19497441082465938,
        "compression_ratio": 1.4894736842105263,
        "end": 5789.22,
        "id": 1655,
        "no_speech_prob": 0.0006666964036412537,
        "seek": 577222,
        "start": 5786.22,
        "temperature": 0,
        "text": " Build it from scratch every time through draw.",
        "tokens": [
          51064,
          11875,
          309,
          490,
          8459,
          633,
          565,
          807,
          2642,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.19497441082465938,
        "compression_ratio": 1.4894736842105263,
        "end": 5793.22,
        "id": 1656,
        "no_speech_prob": 0.0006666964036412537,
        "seek": 577222,
        "start": 5789.22,
        "temperature": 0,
        "text": " Okay, so now I've inserted all of the points of the quadtree.",
        "tokens": [
          51214,
          1033,
          11,
          370,
          586,
          286,
          600,
          27992,
          439,
          295,
          264,
          2793,
          295,
          264,
          10787,
          83,
          701,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.19497441082465938,
        "compression_ratio": 1.4894736842105263,
        "end": 5796.22,
        "id": 1657,
        "no_speech_prob": 0.0006666964036412537,
        "seek": 577222,
        "start": 5793.22,
        "temperature": 0,
        "text": " Let's just run this to make sure it's still working.",
        "tokens": [
          51414,
          961,
          311,
          445,
          1190,
          341,
          281,
          652,
          988,
          309,
          311,
          920,
          1364,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.19497441082465938,
        "compression_ratio": 1.4894736842105263,
        "end": 5799.22,
        "id": 1658,
        "no_speech_prob": 0.0006666964036412537,
        "seek": 577222,
        "start": 5796.22,
        "temperature": 0,
        "text": " Oh, syntax error. Sketch.js line 29.",
        "tokens": [
          51564,
          876,
          11,
          28431,
          6713,
          13,
          49245,
          13,
          25530,
          1622,
          9413,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.1672076465927552,
        "compression_ratio": 1.5313807531380754,
        "end": 5803.22,
        "id": 1659,
        "no_speech_prob": 0.00010720833961386234,
        "seek": 579922,
        "start": 5800.22,
        "temperature": 0,
        "text": " Oh, I forgot that I was doing something down here.",
        "tokens": [
          50414,
          876,
          11,
          286,
          5298,
          300,
          286,
          390,
          884,
          746,
          760,
          510,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.1672076465927552,
        "compression_ratio": 1.5313807531380754,
        "end": 5805.22,
        "id": 1660,
        "no_speech_prob": 0.00010720833961386234,
        "seek": 579922,
        "start": 5803.22,
        "temperature": 0,
        "text": " Okay, another error.",
        "tokens": [
          50564,
          1033,
          11,
          1071,
          6713,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.1672076465927552,
        "compression_ratio": 1.5313807531380754,
        "end": 5808.22,
        "id": 1661,
        "no_speech_prob": 0.00010720833961386234,
        "seek": 579922,
        "start": 5805.22,
        "temperature": 0,
        "text": " Quadtree 90 capacity should be a number but is undefined.",
        "tokens": [
          50664,
          29619,
          83,
          701,
          4289,
          6042,
          820,
          312,
          257,
          1230,
          457,
          307,
          674,
          5666,
          2001,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.1672076465927552,
        "compression_ratio": 1.5313807531380754,
        "end": 5810.22,
        "id": 1662,
        "no_speech_prob": 0.00010720833961386234,
        "seek": 579922,
        "start": 5808.22,
        "temperature": 0,
        "text": " Ah, I forgot about the capacity.",
        "tokens": [
          50814,
          2438,
          11,
          286,
          5298,
          466,
          264,
          6042,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.1672076465927552,
        "compression_ratio": 1.5313807531380754,
        "end": 5815.22,
        "id": 1663,
        "no_speech_prob": 0.00010720833961386234,
        "seek": 579922,
        "start": 5810.22,
        "temperature": 0,
        "text": " So the quadtree, each node of the quadtree has a limit to how many particles can go in it.",
        "tokens": [
          50914,
          407,
          264,
          10787,
          83,
          701,
          11,
          1184,
          9984,
          295,
          264,
          10787,
          83,
          701,
          575,
          257,
          4948,
          281,
          577,
          867,
          10007,
          393,
          352,
          294,
          309,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.1672076465927552,
        "compression_ratio": 1.5313807531380754,
        "end": 5817.22,
        "id": 1664,
        "no_speech_prob": 0.00010720833961386234,
        "seek": 579922,
        "start": 5815.22,
        "temperature": 0,
        "text": " Let's just use four. That's what I've been using.",
        "tokens": [
          51164,
          961,
          311,
          445,
          764,
          1451,
          13,
          663,
          311,
          437,
          286,
          600,
          668,
          1228,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.1672076465927552,
        "compression_ratio": 1.5313807531380754,
        "end": 5820.22,
        "id": 1665,
        "no_speech_prob": 0.00010720833961386234,
        "seek": 579922,
        "start": 5817.22,
        "temperature": 0,
        "text": " We might get better or worse results depending on that number.",
        "tokens": [
          51264,
          492,
          1062,
          483,
          1101,
          420,
          5324,
          3542,
          5413,
          322,
          300,
          1230,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.22978705373303643,
        "compression_ratio": 1.7056451612903225,
        "end": 5823.22,
        "id": 1666,
        "no_speech_prob": 0.01590549759566784,
        "seek": 582022,
        "start": 5821.22,
        "temperature": 0,
        "text": " So let's...",
        "tokens": [
          50414,
          407,
          718,
          311,
          485,
          50514
        ]
      },
      {
        "avg_logprob": -0.22978705373303643,
        "compression_ratio": 1.7056451612903225,
        "end": 5829.22,
        "id": 1667,
        "no_speech_prob": 0.01590549759566784,
        "seek": 582022,
        "start": 5826.22,
        "temperature": 0,
        "text": " Let me give myself some more space here with all this.",
        "tokens": [
          50664,
          961,
          385,
          976,
          2059,
          512,
          544,
          1901,
          510,
          365,
          439,
          341,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.22978705373303643,
        "compression_ratio": 1.7056451612903225,
        "end": 5833.22,
        "id": 1668,
        "no_speech_prob": 0.01590549759566784,
        "seek": 582022,
        "start": 5830.22,
        "temperature": 0,
        "text": " Okay, so we can see that this is working but running slow.",
        "tokens": [
          50864,
          1033,
          11,
          370,
          321,
          393,
          536,
          300,
          341,
          307,
          1364,
          457,
          2614,
          2964,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.22978705373303643,
        "compression_ratio": 1.7056451612903225,
        "end": 5837.22,
        "id": 1669,
        "no_speech_prob": 0.01590549759566784,
        "seek": 582022,
        "start": 5833.22,
        "temperature": 0,
        "text": " So while I've got the quad... I'm building the quadtree, I haven't lost...",
        "tokens": [
          51014,
          407,
          1339,
          286,
          600,
          658,
          264,
          10787,
          485,
          286,
          478,
          2390,
          264,
          10787,
          83,
          701,
          11,
          286,
          2378,
          380,
          2731,
          485,
          51214
        ]
      },
      {
        "avg_logprob": -0.22978705373303643,
        "compression_ratio": 1.7056451612903225,
        "end": 5841.22,
        "id": 1670,
        "no_speech_prob": 0.01590549759566784,
        "seek": 582022,
        "start": 5837.22,
        "temperature": 0,
        "text": " Even though there's computation involved in building the quadtree, I have to rebuild it every frame,",
        "tokens": [
          51214,
          2754,
          1673,
          456,
          311,
          24903,
          3288,
          294,
          2390,
          264,
          10787,
          83,
          701,
          11,
          286,
          362,
          281,
          16877,
          309,
          633,
          3920,
          11,
          51414
        ]
      },
      {
        "avg_logprob": -0.22978705373303643,
        "compression_ratio": 1.7056451612903225,
        "end": 5845.22,
        "id": 1671,
        "no_speech_prob": 0.01590549759566784,
        "seek": 582022,
        "start": 5841.22,
        "temperature": 0,
        "text": " there's so much less involved in doing that than checking all the locations.",
        "tokens": [
          51414,
          456,
          311,
          370,
          709,
          1570,
          3288,
          294,
          884,
          300,
          813,
          8568,
          439,
          264,
          9253,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.22978705373303643,
        "compression_ratio": 1.7056451612903225,
        "end": 5848.22,
        "id": 1672,
        "no_speech_prob": 0.01590549759566784,
        "seek": 582022,
        "start": 5845.22,
        "temperature": 0,
        "text": " And now, here's the thing that I want to do.",
        "tokens": [
          51614,
          400,
          586,
          11,
          510,
          311,
          264,
          551,
          300,
          286,
          528,
          281,
          360,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.2344625194867452,
        "compression_ratio": 1.6323529411764706,
        "end": 5852.22,
        "id": 1673,
        "no_speech_prob": 0.00021654297597706318,
        "seek": 584822,
        "start": 5848.22,
        "temperature": 0,
        "text": " Let me just shut this off so that I don't kill my computer.",
        "tokens": [
          50364,
          961,
          385,
          445,
          5309,
          341,
          766,
          370,
          300,
          286,
          500,
          380,
          1961,
          452,
          3820,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.2344625194867452,
        "compression_ratio": 1.6323529411764706,
        "end": 5856.22,
        "id": 1674,
        "no_speech_prob": 0.00021654297597706318,
        "seek": 584822,
        "start": 5852.22,
        "temperature": 0,
        "text": " What I want to do now is here, I started here.",
        "tokens": [
          50564,
          708,
          286,
          528,
          281,
          360,
          586,
          307,
          510,
          11,
          286,
          1409,
          510,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.2344625194867452,
        "compression_ratio": 1.6323529411764706,
        "end": 5863.22,
        "id": 1675,
        "no_speech_prob": 0.00021654297597706318,
        "seek": 584822,
        "start": 5856.22,
        "temperature": 0,
        "text": " Instead of looking at every other particle in the whole particles array list, I want to query.",
        "tokens": [
          50764,
          7156,
          295,
          1237,
          412,
          633,
          661,
          12359,
          294,
          264,
          1379,
          10007,
          10225,
          1329,
          11,
          286,
          528,
          281,
          14581,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.2344625194867452,
        "compression_ratio": 1.6323529411764706,
        "end": 5868.22,
        "id": 1676,
        "no_speech_prob": 0.00021654297597706318,
        "seek": 584822,
        "start": 5863.22,
        "temperature": 0,
        "text": " I want to say, I'm going to say let others equals qt.query.",
        "tokens": [
          51114,
          286,
          528,
          281,
          584,
          11,
          286,
          478,
          516,
          281,
          584,
          718,
          2357,
          6915,
          9505,
          83,
          13,
          358,
          2109,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.2344625194867452,
        "compression_ratio": 1.6323529411764706,
        "end": 5872.22,
        "id": 1677,
        "no_speech_prob": 0.00021654297597706318,
        "seek": 584822,
        "start": 5868.22,
        "temperature": 0,
        "text": " Now what do I want to query? I think query is the name of the function.",
        "tokens": [
          51364,
          823,
          437,
          360,
          286,
          528,
          281,
          14581,
          30,
          286,
          519,
          14581,
          307,
          264,
          1315,
          295,
          264,
          2445,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.26822969283180675,
        "compression_ratio": 1.8323353293413174,
        "end": 5881.22,
        "id": 1678,
        "no_speech_prob": 0.0002165420155506581,
        "seek": 587222,
        "start": 5873.22,
        "temperature": 0,
        "text": " Query, query, class query, query, query, query, query, query, query, query, range and found.",
        "tokens": [
          50414,
          2326,
          2109,
          11,
          14581,
          11,
          1508,
          14581,
          11,
          14581,
          11,
          14581,
          11,
          14581,
          11,
          14581,
          11,
          14581,
          11,
          14581,
          11,
          14581,
          11,
          3613,
          293,
          1352,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.26822969283180675,
        "compression_ratio": 1.8323353293413174,
        "end": 5883.22,
        "id": 1679,
        "no_speech_prob": 0.0002165420155506581,
        "seek": 587222,
        "start": 5881.22,
        "temperature": 0,
        "text": " But I don't have to worry about found.",
        "tokens": [
          50814,
          583,
          286,
          500,
          380,
          362,
          281,
          3292,
          466,
          1352,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.26822969283180675,
        "compression_ratio": 1.8323353293413174,
        "end": 5887.22,
        "id": 1680,
        "no_speech_prob": 0.0002165420155506581,
        "seek": 587222,
        "start": 5883.22,
        "temperature": 0,
        "text": " Remember when I wrote that, found is the array that's being recursively added to.",
        "tokens": [
          50914,
          5459,
          562,
          286,
          4114,
          300,
          11,
          1352,
          307,
          264,
          10225,
          300,
          311,
          885,
          20560,
          3413,
          3869,
          281,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.26822969283180675,
        "compression_ratio": 1.8323353293413174,
        "end": 5890.22,
        "id": 1681,
        "no_speech_prob": 0.0002165420155506581,
        "seek": 587222,
        "start": 5887.22,
        "temperature": 0,
        "text": " But I want to query a range.",
        "tokens": [
          51114,
          583,
          286,
          528,
          281,
          14581,
          257,
          3613,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.26822969283180675,
        "compression_ratio": 1.8323353293413174,
        "end": 5897.22,
        "id": 1682,
        "no_speech_prob": 0.0002165420155506581,
        "seek": 587222,
        "start": 5890.22,
        "temperature": 0,
        "text": " And the range could be a rectangular range or a circular range.",
        "tokens": [
          51264,
          400,
          264,
          3613,
          727,
          312,
          257,
          31167,
          3613,
          420,
          257,
          16476,
          3613,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.276510214805603,
        "compression_ratio": 1.4764397905759161,
        "end": 5903.22,
        "id": 1683,
        "no_speech_prob": 0.026758158579468727,
        "seek": 589722,
        "start": 5898.22,
        "temperature": 0,
        "text": " And actually, I have this, this has been added since the last tutorial, but this geometry object for a circle.",
        "tokens": [
          50414,
          400,
          767,
          11,
          286,
          362,
          341,
          11,
          341,
          575,
          668,
          3869,
          1670,
          264,
          1036,
          7073,
          11,
          457,
          341,
          18426,
          2657,
          337,
          257,
          6329,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.276510214805603,
        "compression_ratio": 1.4764397905759161,
        "end": 5906.22,
        "id": 1684,
        "no_speech_prob": 0.026758158579468727,
        "seek": 589722,
        "start": 5903.22,
        "temperature": 0,
        "text": " I'm going to use a circular range. Why?",
        "tokens": [
          50664,
          286,
          478,
          516,
          281,
          764,
          257,
          16476,
          3613,
          13,
          1545,
          30,
          50814
        ]
      },
      {
        "avg_logprob": -0.276510214805603,
        "compression_ratio": 1.4764397905759161,
        "end": 5909.22,
        "id": 1685,
        "no_speech_prob": 0.026758158579468727,
        "seek": 589722,
        "start": 5906.22,
        "temperature": 0,
        "text": " I have to erase the whiteboard.",
        "tokens": [
          50814,
          286,
          362,
          281,
          23525,
          264,
          2418,
          3787,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.276510214805603,
        "compression_ratio": 1.4764397905759161,
        "end": 5911.22,
        "id": 1686,
        "no_speech_prob": 0.026758158579468727,
        "seek": 589722,
        "start": 5909.22,
        "temperature": 0,
        "text": " Shoot.",
        "tokens": [
          50964,
          19760,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.276510214805603,
        "compression_ratio": 1.4764397905759161,
        "end": 5915.22,
        "id": 1687,
        "no_speech_prob": 0.026758158579468727,
        "seek": 589722,
        "start": 5911.22,
        "temperature": 0,
        "text": " I think that color predictor thing was done.",
        "tokens": [
          51064,
          286,
          519,
          300,
          2017,
          6069,
          284,
          551,
          390,
          1096,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.276510214805603,
        "compression_ratio": 1.4764397905759161,
        "end": 5919.22,
        "id": 1688,
        "no_speech_prob": 0.026758158579468727,
        "seek": 589722,
        "start": 5915.22,
        "temperature": 0,
        "text": " So as long as I just erase this really quickly.",
        "tokens": [
          51264,
          407,
          382,
          938,
          382,
          286,
          445,
          23525,
          341,
          534,
          2661,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.2827118591026024,
        "compression_ratio": 1.3076923076923077,
        "end": 5926.22,
        "id": 1689,
        "no_speech_prob": 0.0034295693039894104,
        "seek": 591922,
        "start": 5919.22,
        "temperature": 0,
        "text": " I can finish this by 1.15.",
        "tokens": [
          50364,
          286,
          393,
          2413,
          341,
          538,
          502,
          13,
          5211,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.2827118591026024,
        "compression_ratio": 1.3076923076923077,
        "end": 5933.22,
        "id": 1690,
        "no_speech_prob": 0.0034295693039894104,
        "seek": 591922,
        "start": 5926.22,
        "temperature": 0,
        "text": " I'll have this video out next week sometime.",
        "tokens": [
          50714,
          286,
          603,
          362,
          341,
          960,
          484,
          958,
          1243,
          15053,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.2827118591026024,
        "compression_ratio": 1.3076923076923077,
        "end": 5935.22,
        "id": 1691,
        "no_speech_prob": 0.0034295693039894104,
        "seek": 591922,
        "start": 5933.22,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          51064,
          1033,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.2827118591026024,
        "compression_ratio": 1.3076923076923077,
        "end": 5942.22,
        "id": 1692,
        "no_speech_prob": 0.0034295693039894104,
        "seek": 591922,
        "start": 5935.22,
        "temperature": 0,
        "text": " If I have a particle, n has a given r.",
        "tokens": [
          51164,
          759,
          286,
          362,
          257,
          12359,
          11,
          297,
          575,
          257,
          2212,
          367,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.2827118591026024,
        "compression_ratio": 1.3076923076923077,
        "end": 5947.22,
        "id": 1693,
        "no_speech_prob": 0.0034295693039894104,
        "seek": 591922,
        "start": 5942.22,
        "temperature": 0,
        "text": " And my other particle has a given r.",
        "tokens": [
          51514,
          400,
          452,
          661,
          12359,
          575,
          257,
          2212,
          367,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.1966920348833192,
        "compression_ratio": 1.6535433070866141,
        "end": 5950.22,
        "id": 1694,
        "no_speech_prob": 0.0013885059161111712,
        "seek": 594722,
        "start": 5947.22,
        "temperature": 0,
        "text": " I only need to look at particles within what?",
        "tokens": [
          50364,
          286,
          787,
          643,
          281,
          574,
          412,
          10007,
          1951,
          437,
          30,
          50514
        ]
      },
      {
        "avg_logprob": -0.1966920348833192,
        "compression_ratio": 1.6535433070866141,
        "end": 5956.22,
        "id": 1695,
        "no_speech_prob": 0.0013885059161111712,
        "seek": 594722,
        "start": 5950.22,
        "temperature": 0,
        "text": " A range that is r, I drew this kind of bigger, r times 2.",
        "tokens": [
          50514,
          316,
          3613,
          300,
          307,
          367,
          11,
          286,
          12804,
          341,
          733,
          295,
          3801,
          11,
          367,
          1413,
          568,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.1966920348833192,
        "compression_ratio": 1.6535433070866141,
        "end": 5963.22,
        "id": 1696,
        "no_speech_prob": 0.0013885059161111712,
        "seek": 594722,
        "start": 5956.22,
        "temperature": 0,
        "text": " Right, because particles are intersecting only if they're within r times 2 of this particle.",
        "tokens": [
          50814,
          1779,
          11,
          570,
          10007,
          366,
          27815,
          278,
          787,
          498,
          436,
          434,
          1951,
          367,
          1413,
          568,
          295,
          341,
          12359,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.1966920348833192,
        "compression_ratio": 1.6535433070866141,
        "end": 5967.22,
        "id": 1697,
        "no_speech_prob": 0.0013885059161111712,
        "seek": 594722,
        "start": 5963.22,
        "temperature": 0,
        "text": " Now if the particles were different sizes, we'd have a more complicated problem.",
        "tokens": [
          51164,
          823,
          498,
          264,
          10007,
          645,
          819,
          11602,
          11,
          321,
          1116,
          362,
          257,
          544,
          6179,
          1154,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.1966920348833192,
        "compression_ratio": 1.6535433070866141,
        "end": 5970.22,
        "id": 1698,
        "no_speech_prob": 0.0013885059161111712,
        "seek": 594722,
        "start": 5967.22,
        "temperature": 0,
        "text": " And I encourage you to implement that as your own exercise.",
        "tokens": [
          51364,
          400,
          286,
          5373,
          291,
          281,
          4445,
          300,
          382,
          428,
          1065,
          5380,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.1966920348833192,
        "compression_ratio": 1.6535433070866141,
        "end": 5975.22,
        "id": 1699,
        "no_speech_prob": 0.0013885059161111712,
        "seek": 594722,
        "start": 5970.22,
        "temperature": 0,
        "text": " But because my particles are the same sizes, I've got a pretty easy scenario here.",
        "tokens": [
          51514,
          583,
          570,
          452,
          10007,
          366,
          264,
          912,
          11602,
          11,
          286,
          600,
          658,
          257,
          1238,
          1858,
          9005,
          510,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.21039128737016158,
        "compression_ratio": 1.5833333333333333,
        "end": 5980.22,
        "id": 1700,
        "no_speech_prob": 0.026757575571537018,
        "seek": 597522,
        "start": 5975.22,
        "temperature": 0,
        "text": " So what I can do is I can in sketch, I can say...",
        "tokens": [
          50364,
          407,
          437,
          286,
          393,
          360,
          307,
          286,
          393,
          294,
          12325,
          11,
          286,
          393,
          584,
          485,
          50614
        ]
      },
      {
        "avg_logprob": -0.21039128737016158,
        "compression_ratio": 1.5833333333333333,
        "end": 5983.22,
        "id": 1701,
        "no_speech_prob": 0.026757575571537018,
        "seek": 597522,
        "start": 5980.22,
        "temperature": 0,
        "text": " Okay, so first make a circle.",
        "tokens": [
          50614,
          1033,
          11,
          370,
          700,
          652,
          257,
          6329,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.21039128737016158,
        "compression_ratio": 1.5833333333333333,
        "end": 5988.22,
        "id": 1702,
        "no_speech_prob": 0.026757575571537018,
        "seek": 597522,
        "start": 5983.22,
        "temperature": 0,
        "text": " It's a new circle object where it should be at p.x, p.y.",
        "tokens": [
          50764,
          467,
          311,
          257,
          777,
          6329,
          2657,
          689,
          309,
          820,
          312,
          412,
          280,
          13,
          87,
          11,
          280,
          13,
          88,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.21039128737016158,
        "compression_ratio": 1.5833333333333333,
        "end": 5991.22,
        "id": 1703,
        "no_speech_prob": 0.026757575571537018,
        "seek": 597522,
        "start": 5988.22,
        "temperature": 0,
        "text": " And its size is p.r times 2.",
        "tokens": [
          51014,
          400,
          1080,
          2744,
          307,
          280,
          13,
          81,
          1413,
          568,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.21039128737016158,
        "compression_ratio": 1.5833333333333333,
        "end": 5993.22,
        "id": 1704,
        "no_speech_prob": 0.026757575571537018,
        "seek": 597522,
        "start": 5991.22,
        "temperature": 0,
        "text": " This is the range.",
        "tokens": [
          51164,
          639,
          307,
          264,
          3613,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.21039128737016158,
        "compression_ratio": 1.5833333333333333,
        "end": 5996.22,
        "id": 1705,
        "no_speech_prob": 0.026757575571537018,
        "seek": 597522,
        "start": 5993.22,
        "temperature": 0,
        "text": " I want to check for any other particles within the range.",
        "tokens": [
          51264,
          286,
          528,
          281,
          1520,
          337,
          604,
          661,
          10007,
          1951,
          264,
          3613,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.21039128737016158,
        "compression_ratio": 1.5833333333333333,
        "end": 6000.22,
        "id": 1706,
        "no_speech_prob": 0.026757575571537018,
        "seek": 597522,
        "start": 5996.22,
        "temperature": 0,
        "text": " The distance of this particle's radius times 2.",
        "tokens": [
          51414,
          440,
          4560,
          295,
          341,
          12359,
          311,
          15845,
          1413,
          568,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.21039128737016158,
        "compression_ratio": 1.5833333333333333,
        "end": 6003.22,
        "id": 1707,
        "no_speech_prob": 0.026757575571537018,
        "seek": 597522,
        "start": 6000.22,
        "temperature": 0,
        "text": " I want to query that circle. Let's call this range.",
        "tokens": [
          51614,
          286,
          528,
          281,
          14581,
          300,
          6329,
          13,
          961,
          311,
          818,
          341,
          3613,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.2023056510865219,
        "compression_ratio": 1.7325102880658436,
        "end": 6006.22,
        "id": 1708,
        "no_speech_prob": 0.000025466371880611405,
        "seek": 600322,
        "start": 6004.22,
        "temperature": 0,
        "text": " I want to query this range.",
        "tokens": [
          50414,
          286,
          528,
          281,
          14581,
          341,
          3613,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.2023056510865219,
        "compression_ratio": 1.7325102880658436,
        "end": 6009.22,
        "id": 1709,
        "no_speech_prob": 0.000025466371880611405,
        "seek": 600322,
        "start": 6006.22,
        "temperature": 0,
        "text": " Then others is now a smaller amount.",
        "tokens": [
          50514,
          1396,
          2357,
          307,
          586,
          257,
          4356,
          2372,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.2023056510865219,
        "compression_ratio": 1.7325102880658436,
        "end": 6011.22,
        "id": 1710,
        "no_speech_prob": 0.000025466371880611405,
        "seek": 600322,
        "start": 6009.22,
        "temperature": 0,
        "text": " This is all, I just need an other of others.",
        "tokens": [
          50664,
          639,
          307,
          439,
          11,
          286,
          445,
          643,
          364,
          661,
          295,
          2357,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.2023056510865219,
        "compression_ratio": 1.7325102880658436,
        "end": 6014.22,
        "id": 1711,
        "no_speech_prob": 0.000025466371880611405,
        "seek": 600322,
        "start": 6011.22,
        "temperature": 0,
        "text": " So I'm no longer checking the full particles list.",
        "tokens": [
          50764,
          407,
          286,
          478,
          572,
          2854,
          8568,
          264,
          1577,
          10007,
          1329,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.2023056510865219,
        "compression_ratio": 1.7325102880658436,
        "end": 6020.22,
        "id": 1712,
        "no_speech_prob": 0.000025466371880611405,
        "seek": 600322,
        "start": 6014.22,
        "temperature": 0,
        "text": " I'm querying the quadtree for a smaller subset of particles for me to check intersection.",
        "tokens": [
          50914,
          286,
          478,
          7083,
          1840,
          264,
          10787,
          83,
          701,
          337,
          257,
          4356,
          25993,
          295,
          10007,
          337,
          385,
          281,
          1520,
          15236,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.2023056510865219,
        "compression_ratio": 1.7325102880658436,
        "end": 6022.22,
        "id": 1713,
        "no_speech_prob": 0.000025466371880611405,
        "seek": 600322,
        "start": 6020.22,
        "temperature": 0,
        "text": " And now I think we might be done.",
        "tokens": [
          51214,
          400,
          586,
          286,
          519,
          321,
          1062,
          312,
          1096,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.2023056510865219,
        "compression_ratio": 1.7325102880658436,
        "end": 6024.22,
        "id": 1714,
        "no_speech_prob": 0.000025466371880611405,
        "seek": 600322,
        "start": 6022.22,
        "temperature": 0,
        "text": " I don't know, I don't know, I don't know.",
        "tokens": [
          51314,
          286,
          500,
          380,
          458,
          11,
          286,
          500,
          380,
          458,
          11,
          286,
          500,
          380,
          458,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.2023056510865219,
        "compression_ratio": 1.7325102880658436,
        "end": 6025.22,
        "id": 1715,
        "no_speech_prob": 0.000025466371880611405,
        "seek": 600322,
        "start": 6024.22,
        "temperature": 0,
        "text": " Look at this.",
        "tokens": [
          51414,
          2053,
          412,
          341,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.2023056510865219,
        "compression_ratio": 1.7325102880658436,
        "end": 6027.22,
        "id": 1716,
        "no_speech_prob": 0.000025466371880611405,
        "seek": 600322,
        "start": 6025.22,
        "temperature": 0,
        "text": " Remember this? Let's let this run again.",
        "tokens": [
          51464,
          5459,
          341,
          30,
          961,
          311,
          718,
          341,
          1190,
          797,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.2023056510865219,
        "compression_ratio": 1.7325102880658436,
        "end": 6031.22,
        "id": 1717,
        "no_speech_prob": 0.000025466371880611405,
        "seek": 600322,
        "start": 6028.22,
        "temperature": 0,
        "text": " This is it running before, really slow.",
        "tokens": [
          51614,
          639,
          307,
          309,
          2614,
          949,
          11,
          534,
          2964,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.2554898390898833,
        "compression_ratio": 1.3888888888888888,
        "end": 6033.22,
        "id": 1718,
        "no_speech_prob": 0.0055547296069562435,
        "seek": 603122,
        "start": 6031.22,
        "temperature": 0,
        "text": " Five frames per second.",
        "tokens": [
          50364,
          9436,
          12083,
          680,
          1150,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.2554898390898833,
        "compression_ratio": 1.3888888888888888,
        "end": 6035.22,
        "id": 1719,
        "no_speech_prob": 0.0055547296069562435,
        "seek": 603122,
        "start": 6033.22,
        "temperature": 0,
        "text": " I'm going to hit refresh.",
        "tokens": [
          50464,
          286,
          478,
          516,
          281,
          2045,
          15134,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.2554898390898833,
        "compression_ratio": 1.3888888888888888,
        "end": 6038.22,
        "id": 1720,
        "no_speech_prob": 0.0055547296069562435,
        "seek": 603122,
        "start": 6035.22,
        "temperature": 0,
        "text": " I hope I don't have any errors.",
        "tokens": [
          50564,
          286,
          1454,
          286,
          500,
          380,
          362,
          604,
          13603,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.2554898390898833,
        "compression_ratio": 1.3888888888888888,
        "end": 6040.22,
        "id": 1721,
        "no_speech_prob": 0.0055547296069562435,
        "seek": 603122,
        "start": 6038.22,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          50714,
          1033,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.2554898390898833,
        "compression_ratio": 1.3888888888888888,
        "end": 6044.22,
        "id": 1722,
        "no_speech_prob": 0.0055547296069562435,
        "seek": 603122,
        "start": 6040.22,
        "temperature": 0,
        "text": " Oh, that looks good.",
        "tokens": [
          50814,
          876,
          11,
          300,
          1542,
          665,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.2554898390898833,
        "compression_ratio": 1.3888888888888888,
        "end": 6047.22,
        "id": 1723,
        "no_speech_prob": 0.0055547296069562435,
        "seek": 603122,
        "start": 6044.22,
        "temperature": 0,
        "text": " It's running fast, but it's not highlighting.",
        "tokens": [
          51014,
          467,
          311,
          2614,
          2370,
          11,
          457,
          309,
          311,
          406,
          26551,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.2554898390898833,
        "compression_ratio": 1.3888888888888888,
        "end": 6050.22,
        "id": 1724,
        "no_speech_prob": 0.0055547296069562435,
        "seek": 603122,
        "start": 6047.22,
        "temperature": 0,
        "text": " So what happened there?",
        "tokens": [
          51164,
          407,
          437,
          2011,
          456,
          30,
          51314
        ]
      },
      {
        "avg_logprob": -0.2554898390898833,
        "compression_ratio": 1.3888888888888888,
        "end": 6054.22,
        "id": 1725,
        "no_speech_prob": 0.0055547296069562435,
        "seek": 603122,
        "start": 6050.22,
        "temperature": 0,
        "text": " p does not equal other and p intersects other.",
        "tokens": [
          51314,
          280,
          775,
          406,
          2681,
          661,
          293,
          280,
          27815,
          82,
          661,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.23292716044300008,
        "compression_ratio": 1.7333333333333334,
        "end": 6056.22,
        "id": 1726,
        "no_speech_prob": 0.019123345613479614,
        "seek": 605422,
        "start": 6055.22,
        "temperature": 0,
        "text": " Okay, hold on.",
        "tokens": [
          50414,
          1033,
          11,
          1797,
          322,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.23292716044300008,
        "compression_ratio": 1.7333333333333334,
        "end": 6059.22,
        "id": 1727,
        "no_speech_prob": 0.019123345613479614,
        "seek": 605422,
        "start": 6056.22,
        "temperature": 0,
        "text": " I have a bad feeling that...",
        "tokens": [
          50464,
          286,
          362,
          257,
          1578,
          2633,
          300,
          485,
          50614
        ]
      },
      {
        "avg_logprob": -0.23292716044300008,
        "compression_ratio": 1.7333333333333334,
        "end": 6064.22,
        "id": 1728,
        "no_speech_prob": 0.019123345613479614,
        "seek": 605422,
        "start": 6061.22,
        "temperature": 0,
        "text": " Oh, the particle! Thank you.",
        "tokens": [
          50714,
          876,
          11,
          264,
          12359,
          0,
          1044,
          291,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.23292716044300008,
        "compression_ratio": 1.7333333333333334,
        "end": 6065.22,
        "id": 1729,
        "no_speech_prob": 0.019123345613479614,
        "seek": 605422,
        "start": 6064.22,
        "temperature": 0,
        "text": " I forgot.",
        "tokens": [
          50864,
          286,
          5298,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.23292716044300008,
        "compression_ratio": 1.7333333333333334,
        "end": 6066.22,
        "id": 1730,
        "no_speech_prob": 0.019123345613479614,
        "seek": 605422,
        "start": 6065.22,
        "temperature": 0,
        "text": " So that's the thing.",
        "tokens": [
          50914,
          407,
          300,
          311,
          264,
          551,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.23292716044300008,
        "compression_ratio": 1.7333333333333334,
        "end": 6068.22,
        "id": 1731,
        "no_speech_prob": 0.019123345613479614,
        "seek": 605422,
        "start": 6066.22,
        "temperature": 0,
        "text": " Right, right, right, right, right.",
        "tokens": [
          50964,
          1779,
          11,
          558,
          11,
          558,
          11,
          558,
          11,
          558,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.23292716044300008,
        "compression_ratio": 1.7333333333333334,
        "end": 6070.22,
        "id": 1732,
        "no_speech_prob": 0.019123345613479614,
        "seek": 605422,
        "start": 6068.22,
        "temperature": 0,
        "text": " So this is the whole thing.",
        "tokens": [
          51064,
          407,
          341,
          307,
          264,
          1379,
          551,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.23292716044300008,
        "compression_ratio": 1.7333333333333334,
        "end": 6071.22,
        "id": 1733,
        "no_speech_prob": 0.019123345613479614,
        "seek": 605422,
        "start": 6070.22,
        "temperature": 0,
        "text": " These are points.",
        "tokens": [
          51164,
          1981,
          366,
          2793,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.23292716044300008,
        "compression_ratio": 1.7333333333333334,
        "end": 6073.22,
        "id": 1734,
        "no_speech_prob": 0.019123345613479614,
        "seek": 605422,
        "start": 6071.22,
        "temperature": 0,
        "text": " I called them others, but let's call them points.",
        "tokens": [
          51214,
          286,
          1219,
          552,
          2357,
          11,
          457,
          718,
          311,
          818,
          552,
          2793,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.23292716044300008,
        "compression_ratio": 1.7333333333333334,
        "end": 6075.22,
        "id": 1735,
        "no_speech_prob": 0.019123345613479614,
        "seek": 605422,
        "start": 6073.22,
        "temperature": 0,
        "text": " I'm getting the points.",
        "tokens": [
          51314,
          286,
          478,
          1242,
          264,
          2793,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.23292716044300008,
        "compression_ratio": 1.7333333333333334,
        "end": 6079.22,
        "id": 1736,
        "no_speech_prob": 0.019123345613479614,
        "seek": 605422,
        "start": 6075.22,
        "temperature": 0,
        "text": " For every other of points,",
        "tokens": [
          51414,
          1171,
          633,
          661,
          295,
          2793,
          11,
          51614
        ]
      },
      {
        "avg_logprob": -0.23292716044300008,
        "compression_ratio": 1.7333333333333334,
        "end": 6083.22,
        "id": 1737,
        "no_speech_prob": 0.019123345613479614,
        "seek": 605422,
        "start": 6079.22,
        "temperature": 0,
        "text": " for every point of points,",
        "tokens": [
          51614,
          337,
          633,
          935,
          295,
          2793,
          11,
          51814
        ]
      },
      {
        "avg_logprob": -0.2297093101169752,
        "compression_ratio": 1.6127659574468085,
        "end": 6088.22,
        "id": 1738,
        "no_speech_prob": 0.00028240642859600484,
        "seek": 608322,
        "start": 6083.22,
        "temperature": 0,
        "text": " other equals point dot user data.",
        "tokens": [
          50364,
          661,
          6915,
          935,
          5893,
          4195,
          1412,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.2297093101169752,
        "compression_ratio": 1.6127659574468085,
        "end": 6091.22,
        "id": 1739,
        "no_speech_prob": 0.00028240642859600484,
        "seek": 608322,
        "start": 6088.22,
        "temperature": 0,
        "text": " I need to actually look at that object.",
        "tokens": [
          50614,
          286,
          643,
          281,
          767,
          574,
          412,
          300,
          2657,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.2297093101169752,
        "compression_ratio": 1.6127659574468085,
        "end": 6095.22,
        "id": 1740,
        "no_speech_prob": 0.00028240642859600484,
        "seek": 608322,
        "start": 6091.22,
        "temperature": 0,
        "text": " Remember, the particle, which is the thing that works with intersects",
        "tokens": [
          50764,
          5459,
          11,
          264,
          12359,
          11,
          597,
          307,
          264,
          551,
          300,
          1985,
          365,
          27815,
          82,
          50964
        ]
      },
      {
        "avg_logprob": -0.2297093101169752,
        "compression_ratio": 1.6127659574468085,
        "end": 6097.22,
        "id": 1741,
        "no_speech_prob": 0.00028240642859600484,
        "seek": 608322,
        "start": 6095.22,
        "temperature": 0,
        "text": " and set highlight and all of that,",
        "tokens": [
          50964,
          293,
          992,
          5078,
          293,
          439,
          295,
          300,
          11,
          51064
        ]
      },
      {
        "avg_logprob": -0.2297093101169752,
        "compression_ratio": 1.6127659574468085,
        "end": 6100.22,
        "id": 1742,
        "no_speech_prob": 0.00028240642859600484,
        "seek": 608322,
        "start": 6097.22,
        "temperature": 0,
        "text": " this quadtree is giving me an array of points,",
        "tokens": [
          51064,
          341,
          10787,
          83,
          701,
          307,
          2902,
          385,
          364,
          10225,
          295,
          2793,
          11,
          51214
        ]
      },
      {
        "avg_logprob": -0.2297093101169752,
        "compression_ratio": 1.6127659574468085,
        "end": 6103.22,
        "id": 1743,
        "no_speech_prob": 0.00028240642859600484,
        "seek": 608322,
        "start": 6100.22,
        "temperature": 0,
        "text": " and as I look at each point, I need to pull out the user data.",
        "tokens": [
          51214,
          293,
          382,
          286,
          574,
          412,
          1184,
          935,
          11,
          286,
          643,
          281,
          2235,
          484,
          264,
          4195,
          1412,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.2297093101169752,
        "compression_ratio": 1.6127659574468085,
        "end": 6104.22,
        "id": 1744,
        "no_speech_prob": 0.00028240642859600484,
        "seek": 608322,
        "start": 6103.22,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          51364,
          1033,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.2297093101169752,
        "compression_ratio": 1.6127659574468085,
        "end": 6106.22,
        "id": 1745,
        "no_speech_prob": 0.00028240642859600484,
        "seek": 608322,
        "start": 6104.22,
        "temperature": 0,
        "text": " I can't bring myself to use that drummer.",
        "tokens": [
          51414,
          286,
          393,
          380,
          1565,
          2059,
          281,
          764,
          300,
          38535,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.2297093101169752,
        "compression_ratio": 1.6127659574468085,
        "end": 6108.22,
        "id": 1746,
        "no_speech_prob": 0.00028240642859600484,
        "seek": 608322,
        "start": 6106.22,
        "temperature": 0,
        "text": " There we go!",
        "tokens": [
          51514,
          821,
          321,
          352,
          0,
          51614
        ]
      },
      {
        "avg_logprob": -0.2297093101169752,
        "compression_ratio": 1.6127659574468085,
        "end": 6109.22,
        "id": 1747,
        "no_speech_prob": 0.00028240642859600484,
        "seek": 608322,
        "start": 6108.22,
        "temperature": 0,
        "text": " So now...",
        "tokens": [
          51614,
          407,
          586,
          485,
          51664
        ]
      },
      {
        "avg_logprob": -0.2297093101169752,
        "compression_ratio": 1.6127659574468085,
        "end": 6111.22,
        "id": 1748,
        "no_speech_prob": 0.00028240642859600484,
        "seek": 608322,
        "start": 6109.22,
        "temperature": 0,
        "text": " Whoops, frame rate.",
        "tokens": [
          51664,
          45263,
          11,
          3920,
          3314,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.1967468881994728,
        "compression_ratio": 1.6541353383458646,
        "end": 6115.22,
        "id": 1749,
        "no_speech_prob": 0.00011235274723730981,
        "seek": 611122,
        "start": 6112.22,
        "temperature": 0,
        "text": " Look at that! 48 frames per second!",
        "tokens": [
          50414,
          2053,
          412,
          300,
          0,
          11174,
          12083,
          680,
          1150,
          0,
          50564
        ]
      },
      {
        "avg_logprob": -0.1967468881994728,
        "compression_ratio": 1.6541353383458646,
        "end": 6116.22,
        "id": 1750,
        "no_speech_prob": 0.00011235274723730981,
        "seek": 611122,
        "start": 6115.22,
        "temperature": 0,
        "text": " It was 5 frames per second.",
        "tokens": [
          50564,
          467,
          390,
          1025,
          12083,
          680,
          1150,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.1967468881994728,
        "compression_ratio": 1.6541353383458646,
        "end": 6118.22,
        "id": 1751,
        "no_speech_prob": 0.00011235274723730981,
        "seek": 611122,
        "start": 6116.22,
        "temperature": 0,
        "text": " Now it's 48 frames per second.",
        "tokens": [
          50614,
          823,
          309,
          311,
          11174,
          12083,
          680,
          1150,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.1967468881994728,
        "compression_ratio": 1.6541353383458646,
        "end": 6120.22,
        "id": 1752,
        "no_speech_prob": 0.00011235274723730981,
        "seek": 611122,
        "start": 6118.22,
        "temperature": 0,
        "text": " So there's issues with this.",
        "tokens": [
          50714,
          407,
          456,
          311,
          2663,
          365,
          341,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.1967468881994728,
        "compression_ratio": 1.6541353383458646,
        "end": 6122.22,
        "id": 1753,
        "no_speech_prob": 0.00011235274723730981,
        "seek": 611122,
        "start": 6120.22,
        "temperature": 0,
        "text": " I've really set myself up for success here.",
        "tokens": [
          50814,
          286,
          600,
          534,
          992,
          2059,
          493,
          337,
          2245,
          510,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.1967468881994728,
        "compression_ratio": 1.6541353383458646,
        "end": 6126.22,
        "id": 1754,
        "no_speech_prob": 0.00011235274723730981,
        "seek": 611122,
        "start": 6122.22,
        "temperature": 0,
        "text": " These particles have a really nice, even, uniform distribution",
        "tokens": [
          50914,
          1981,
          10007,
          362,
          257,
          534,
          1481,
          11,
          754,
          11,
          9452,
          7316,
          51114
        ]
      },
      {
        "avg_logprob": -0.1967468881994728,
        "compression_ratio": 1.6541353383458646,
        "end": 6128.22,
        "id": 1755,
        "no_speech_prob": 0.00011235274723730981,
        "seek": 611122,
        "start": 6126.22,
        "temperature": 0,
        "text": " across the entire canvas.",
        "tokens": [
          51114,
          2108,
          264,
          2302,
          16267,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.1967468881994728,
        "compression_ratio": 1.6541353383458646,
        "end": 6130.22,
        "id": 1756,
        "no_speech_prob": 0.00011235274723730981,
        "seek": 611122,
        "start": 6128.22,
        "temperature": 0,
        "text": " They're all the same size.",
        "tokens": [
          51214,
          814,
          434,
          439,
          264,
          912,
          2744,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.1967468881994728,
        "compression_ratio": 1.6541353383458646,
        "end": 6132.22,
        "id": 1757,
        "no_speech_prob": 0.00011235274723730981,
        "seek": 611122,
        "start": 6130.22,
        "temperature": 0,
        "text": " There's only a thousand of them.",
        "tokens": [
          51314,
          821,
          311,
          787,
          257,
          4714,
          295,
          552,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.1967468881994728,
        "compression_ratio": 1.6541353383458646,
        "end": 6134.22,
        "id": 1758,
        "no_speech_prob": 0.00011235274723730981,
        "seek": 611122,
        "start": 6132.22,
        "temperature": 0,
        "text": " I'm not actually having them bounce off each other",
        "tokens": [
          51414,
          286,
          478,
          406,
          767,
          1419,
          552,
          15894,
          766,
          1184,
          661,
          51514
        ]
      },
      {
        "avg_logprob": -0.1967468881994728,
        "compression_ratio": 1.6541353383458646,
        "end": 6136.22,
        "id": 1759,
        "no_speech_prob": 0.00011235274723730981,
        "seek": 611122,
        "start": 6134.22,
        "temperature": 0,
        "text": " or any kind of complex collision resolution,",
        "tokens": [
          51514,
          420,
          604,
          733,
          295,
          3997,
          24644,
          8669,
          11,
          51614
        ]
      },
      {
        "avg_logprob": -0.1967468881994728,
        "compression_ratio": 1.6541353383458646,
        "end": 6138.22,
        "id": 1760,
        "no_speech_prob": 0.00011235274723730981,
        "seek": 611122,
        "start": 6136.22,
        "temperature": 0,
        "text": " but this is the basic idea.",
        "tokens": [
          51614,
          457,
          341,
          307,
          264,
          3875,
          1558,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.22401472417319693,
        "compression_ratio": 1.4805194805194806,
        "end": 6141.22,
        "id": 1761,
        "no_speech_prob": 0.0061929551884531975,
        "seek": 613822,
        "start": 6138.22,
        "temperature": 0,
        "text": " What you can see is that with a quadtree,",
        "tokens": [
          50364,
          708,
          291,
          393,
          536,
          307,
          300,
          365,
          257,
          10787,
          83,
          701,
          11,
          50514
        ]
      },
      {
        "avg_logprob": -0.22401472417319693,
        "compression_ratio": 1.4805194805194806,
        "end": 6143.22,
        "id": 1762,
        "no_speech_prob": 0.0061929551884531975,
        "seek": 613822,
        "start": 6141.22,
        "temperature": 0,
        "text": " if I just quickly...",
        "tokens": [
          50514,
          498,
          286,
          445,
          2661,
          485,
          50614
        ]
      },
      {
        "avg_logprob": -0.22401472417319693,
        "compression_ratio": 1.4805194805194806,
        "end": 6147.22,
        "id": 1763,
        "no_speech_prob": 0.0061929551884531975,
        "seek": 613822,
        "start": 6143.22,
        "temperature": 0,
        "text": " All I have to do now to switch them on and off",
        "tokens": [
          50614,
          1057,
          286,
          362,
          281,
          360,
          586,
          281,
          3679,
          552,
          322,
          293,
          766,
          50814
        ]
      },
      {
        "avg_logprob": -0.22401472417319693,
        "compression_ratio": 1.4805194805194806,
        "end": 6150.22,
        "id": 1764,
        "no_speech_prob": 0.0061929551884531975,
        "seek": 613822,
        "start": 6147.22,
        "temperature": 0,
        "text": " is to say...",
        "tokens": [
          50814,
          307,
          281,
          584,
          485,
          50964
        ]
      },
      {
        "avg_logprob": -0.22401472417319693,
        "compression_ratio": 1.4805194805194806,
        "end": 6152.22,
        "id": 1765,
        "no_speech_prob": 0.0061929551884531975,
        "seek": 613822,
        "start": 6150.22,
        "temperature": 0,
        "text": " Let me comment this out.",
        "tokens": [
          50964,
          961,
          385,
          2871,
          341,
          484,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.22401472417319693,
        "compression_ratio": 1.4805194805194806,
        "end": 6154.22,
        "id": 1766,
        "no_speech_prob": 0.0061929551884531975,
        "seek": 613822,
        "start": 6152.22,
        "temperature": 0,
        "text": " If I say, for other...",
        "tokens": [
          51064,
          759,
          286,
          584,
          11,
          337,
          661,
          485,
          51164
        ]
      },
      {
        "avg_logprob": -0.22401472417319693,
        "compression_ratio": 1.4805194805194806,
        "end": 6157.22,
        "id": 1767,
        "no_speech_prob": 0.0061929551884531975,
        "seek": 613822,
        "start": 6154.22,
        "temperature": 0,
        "text": " Let other of particles...",
        "tokens": [
          51164,
          961,
          661,
          295,
          10007,
          485,
          51314
        ]
      },
      {
        "avg_logprob": -0.22401472417319693,
        "compression_ratio": 1.4805194805194806,
        "end": 6162.22,
        "id": 1768,
        "no_speech_prob": 0.0061929551884531975,
        "seek": 613822,
        "start": 6161.22,
        "temperature": 0,
        "text": " This is...",
        "tokens": [
          51514,
          639,
          307,
          485,
          51564
        ]
      },
      {
        "avg_logprob": -0.22401472417319693,
        "compression_ratio": 1.4805194805194806,
        "end": 6165.22,
        "id": 1769,
        "no_speech_prob": 0.0061929551884531975,
        "seek": 613822,
        "start": 6162.22,
        "temperature": 0,
        "text": " So now, no quadtree.",
        "tokens": [
          51564,
          407,
          586,
          11,
          572,
          10787,
          83,
          701,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.21205397326536854,
        "compression_ratio": 1.5342465753424657,
        "end": 6168.22,
        "id": 1770,
        "no_speech_prob": 0.0001660350535530597,
        "seek": 616522,
        "start": 6165.22,
        "temperature": 0,
        "text": " I'm just looking at every other particle.",
        "tokens": [
          50364,
          286,
          478,
          445,
          1237,
          412,
          633,
          661,
          12359,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.21205397326536854,
        "compression_ratio": 1.5342465753424657,
        "end": 6172.22,
        "id": 1771,
        "no_speech_prob": 0.0001660350535530597,
        "seek": 616522,
        "start": 6170.22,
        "temperature": 0,
        "text": " Super slow, super slow.",
        "tokens": [
          50614,
          4548,
          2964,
          11,
          1687,
          2964,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.21205397326536854,
        "compression_ratio": 1.5342465753424657,
        "end": 6174.22,
        "id": 1772,
        "no_speech_prob": 0.0001660350535530597,
        "seek": 616522,
        "start": 6172.22,
        "temperature": 0,
        "text": " Frame rate of about 5.",
        "tokens": [
          50714,
          31628,
          3314,
          295,
          466,
          1025,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.21205397326536854,
        "compression_ratio": 1.5342465753424657,
        "end": 6177.22,
        "id": 1773,
        "no_speech_prob": 0.0001660350535530597,
        "seek": 616522,
        "start": 6174.22,
        "temperature": 0,
        "text": " And now, switch to using the quadtree.",
        "tokens": [
          50814,
          400,
          586,
          11,
          3679,
          281,
          1228,
          264,
          10787,
          83,
          701,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.21205397326536854,
        "compression_ratio": 1.5342465753424657,
        "end": 6181.22,
        "id": 1774,
        "no_speech_prob": 0.0001660350535530597,
        "seek": 616522,
        "start": 6180.22,
        "temperature": 0,
        "text": " Super fast!",
        "tokens": [
          51114,
          4548,
          2370,
          0,
          51164
        ]
      },
      {
        "avg_logprob": -0.21205397326536854,
        "compression_ratio": 1.5342465753424657,
        "end": 6183.22,
        "id": 1775,
        "no_speech_prob": 0.0001660350535530597,
        "seek": 616522,
        "start": 6181.22,
        "temperature": 0,
        "text": " So, goodbye everyone!",
        "tokens": [
          51164,
          407,
          11,
          12084,
          1518,
          0,
          51264
        ]
      },
      {
        "avg_logprob": -0.21205397326536854,
        "compression_ratio": 1.5342465753424657,
        "end": 6185.22,
        "id": 1776,
        "no_speech_prob": 0.0001660350535530597,
        "seek": 616522,
        "start": 6183.22,
        "temperature": 0,
        "text": " Thanks for watching this tutorial.",
        "tokens": [
          51264,
          2561,
          337,
          1976,
          341,
          7073,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.21205397326536854,
        "compression_ratio": 1.5342465753424657,
        "end": 6187.22,
        "id": 1777,
        "no_speech_prob": 0.0001660350535530597,
        "seek": 616522,
        "start": 6185.22,
        "temperature": 0,
        "text": " I encourage you to try to make a version of this",
        "tokens": [
          51364,
          286,
          5373,
          291,
          281,
          853,
          281,
          652,
          257,
          3037,
          295,
          341,
          51464
        ]
      },
      {
        "avg_logprob": -0.21205397326536854,
        "compression_ratio": 1.5342465753424657,
        "end": 6189.22,
        "id": 1778,
        "no_speech_prob": 0.0001660350535530597,
        "seek": 616522,
        "start": 6187.22,
        "temperature": 0,
        "text": " where the particles...",
        "tokens": [
          51464,
          689,
          264,
          10007,
          485,
          51564
        ]
      },
      {
        "avg_logprob": -0.21205397326536854,
        "compression_ratio": 1.5342465753424657,
        "end": 6192.22,
        "id": 1779,
        "no_speech_prob": 0.0001660350535530597,
        "seek": 616522,
        "start": 6189.22,
        "temperature": 0,
        "text": " Somebody already has done this, a pull request on my quadtree repo.",
        "tokens": [
          51564,
          13463,
          1217,
          575,
          1096,
          341,
          11,
          257,
          2235,
          5308,
          322,
          452,
          10787,
          83,
          701,
          49040,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.21249228804858764,
        "compression_ratio": 1.6369863013698631,
        "end": 6195.22,
        "id": 1780,
        "no_speech_prob": 0.1403058022260666,
        "seek": 619222,
        "start": 6192.22,
        "temperature": 0,
        "text": " A version of this with the flocking simulation.",
        "tokens": [
          50364,
          316,
          3037,
          295,
          341,
          365,
          264,
          2591,
          25723,
          16575,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.21249228804858764,
        "compression_ratio": 1.6369863013698631,
        "end": 6197.22,
        "id": 1781,
        "no_speech_prob": 0.1403058022260666,
        "seek": 619222,
        "start": 6195.22,
        "temperature": 0,
        "text": " How is that going to work?",
        "tokens": [
          50514,
          1012,
          307,
          300,
          516,
          281,
          589,
          30,
          50614
        ]
      },
      {
        "avg_logprob": -0.21249228804858764,
        "compression_ratio": 1.6369863013698631,
        "end": 6200.22,
        "id": 1782,
        "no_speech_prob": 0.1403058022260666,
        "seek": 619222,
        "start": 6197.22,
        "temperature": 0,
        "text": " What if the particles aren't so evenly distributed?",
        "tokens": [
          50614,
          708,
          498,
          264,
          10007,
          3212,
          380,
          370,
          17658,
          12631,
          30,
          50764
        ]
      },
      {
        "avg_logprob": -0.21249228804858764,
        "compression_ratio": 1.6369863013698631,
        "end": 6202.22,
        "id": 1783,
        "no_speech_prob": 0.1403058022260666,
        "seek": 619222,
        "start": 6200.22,
        "temperature": 0,
        "text": " How could you do it with different sizes?",
        "tokens": [
          50764,
          1012,
          727,
          291,
          360,
          309,
          365,
          819,
          11602,
          30,
          50864
        ]
      },
      {
        "avg_logprob": -0.21249228804858764,
        "compression_ratio": 1.6369863013698631,
        "end": 6204.22,
        "id": 1784,
        "no_speech_prob": 0.1403058022260666,
        "seek": 619222,
        "start": 6202.22,
        "temperature": 0,
        "text": " Could you visualize the quadtree?",
        "tokens": [
          50864,
          7497,
          291,
          23273,
          264,
          10787,
          83,
          701,
          30,
          50964
        ]
      },
      {
        "avg_logprob": -0.21249228804858764,
        "compression_ratio": 1.6369863013698631,
        "end": 6206.22,
        "id": 1785,
        "no_speech_prob": 0.1403058022260666,
        "seek": 619222,
        "start": 6204.22,
        "temperature": 0,
        "text": " So, draw the quadtree dynamically",
        "tokens": [
          50964,
          407,
          11,
          2642,
          264,
          10787,
          83,
          701,
          43492,
          51064
        ]
      },
      {
        "avg_logprob": -0.21249228804858764,
        "compression_ratio": 1.6369863013698631,
        "end": 6208.22,
        "id": 1786,
        "no_speech_prob": 0.1403058022260666,
        "seek": 619222,
        "start": 6206.22,
        "temperature": 0,
        "text": " as it's changing and updating.",
        "tokens": [
          51064,
          382,
          309,
          311,
          4473,
          293,
          25113,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.21249228804858764,
        "compression_ratio": 1.6369863013698631,
        "end": 6210.22,
        "id": 1787,
        "no_speech_prob": 0.1403058022260666,
        "seek": 619222,
        "start": 6208.22,
        "temperature": 0,
        "text": " That might be a beautiful thing to create.",
        "tokens": [
          51164,
          663,
          1062,
          312,
          257,
          2238,
          551,
          281,
          1884,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.21249228804858764,
        "compression_ratio": 1.6369863013698631,
        "end": 6212.22,
        "id": 1788,
        "no_speech_prob": 0.1403058022260666,
        "seek": 619222,
        "start": 6210.22,
        "temperature": 0,
        "text": " Make your own quadtree visualizations.",
        "tokens": [
          51264,
          4387,
          428,
          1065,
          10787,
          83,
          701,
          5056,
          14455,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.21249228804858764,
        "compression_ratio": 1.6369863013698631,
        "end": 6214.22,
        "id": 1789,
        "no_speech_prob": 0.1403058022260666,
        "seek": 619222,
        "start": 6212.22,
        "temperature": 0,
        "text": " I hope you do all those things.",
        "tokens": [
          51364,
          286,
          1454,
          291,
          360,
          439,
          729,
          721,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.21249228804858764,
        "compression_ratio": 1.6369863013698631,
        "end": 6216.22,
        "id": 1790,
        "no_speech_prob": 0.1403058022260666,
        "seek": 619222,
        "start": 6214.22,
        "temperature": 0,
        "text": " Share them with me.",
        "tokens": [
          51464,
          14945,
          552,
          365,
          385,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.21249228804858764,
        "compression_ratio": 1.6369863013698631,
        "end": 6218.22,
        "id": 1791,
        "no_speech_prob": 0.1403058022260666,
        "seek": 619222,
        "start": 6216.22,
        "temperature": 0,
        "text": " And I will see you in a future coding challenge",
        "tokens": [
          51564,
          400,
          286,
          486,
          536,
          291,
          294,
          257,
          2027,
          17720,
          3430,
          51664
        ]
      },
      {
        "avg_logprob": -0.21249228804858764,
        "compression_ratio": 1.6369863013698631,
        "end": 6220.22,
        "id": 1792,
        "no_speech_prob": 0.1403058022260666,
        "seek": 619222,
        "start": 6218.22,
        "temperature": 0,
        "text": " or something or other video.",
        "tokens": [
          51664,
          420,
          746,
          420,
          661,
          960,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.3066978454589844,
        "compression_ratio": 1.4702702702702704,
        "end": 6222.22,
        "id": 1793,
        "no_speech_prob": 0.384792298078537,
        "seek": 622022,
        "start": 6220.22,
        "temperature": 0,
        "text": " I think, I don't know, that kind of stuff.",
        "tokens": [
          50364,
          286,
          519,
          11,
          286,
          500,
          380,
          458,
          11,
          300,
          733,
          295,
          1507,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.3066978454589844,
        "compression_ratio": 1.4702702702702704,
        "end": 6223.22,
        "id": 1794,
        "no_speech_prob": 0.384792298078537,
        "seek": 622022,
        "start": 6222.22,
        "temperature": 0,
        "text": " Goodbye!",
        "tokens": [
          50464,
          15528,
          0,
          50514
        ]
      },
      {
        "avg_logprob": -0.3066978454589844,
        "compression_ratio": 1.4702702702702704,
        "end": 6229.22,
        "id": 1795,
        "no_speech_prob": 0.384792298078537,
        "seek": 622022,
        "start": 6223.22,
        "temperature": 0,
        "text": " Oh yeah, I could have done map.",
        "tokens": [
          50514,
          876,
          1338,
          11,
          286,
          727,
          362,
          1096,
          4471,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.3066978454589844,
        "compression_ratio": 1.4702702702702704,
        "end": 6231.22,
        "id": 1796,
        "no_speech_prob": 0.384792298078537,
        "seek": 622022,
        "start": 6229.22,
        "temperature": 0,
        "text": " Okay, okay, map.",
        "tokens": [
          50814,
          1033,
          11,
          1392,
          11,
          4471,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.3066978454589844,
        "compression_ratio": 1.4702702702702704,
        "end": 6233.22,
        "id": 1797,
        "no_speech_prob": 0.384792298078537,
        "seek": 622022,
        "start": 6231.22,
        "temperature": 0,
        "text": " I could have done map.",
        "tokens": [
          50914,
          286,
          727,
          362,
          1096,
          4471,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.3066978454589844,
        "compression_ratio": 1.4702702702702704,
        "end": 6234.22,
        "id": 1798,
        "no_speech_prob": 0.384792298078537,
        "seek": 622022,
        "start": 6233.22,
        "temperature": 0,
        "text": " Alright.",
        "tokens": [
          51014,
          2798,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.3066978454589844,
        "compression_ratio": 1.4702702702702704,
        "end": 6236.22,
        "id": 1799,
        "no_speech_prob": 0.384792298078537,
        "seek": 622022,
        "start": 6234.22,
        "temperature": 0,
        "text": " Grant asks,",
        "tokens": [
          51064,
          17529,
          8962,
          11,
          51164
        ]
      },
      {
        "avg_logprob": -0.3066978454589844,
        "compression_ratio": 1.4702702702702704,
        "end": 6241.22,
        "id": 1800,
        "no_speech_prob": 0.384792298078537,
        "seek": 622022,
        "start": 6236.22,
        "temperature": 0,
        "text": " Is there a forum or group where people discuss p5.js?",
        "tokens": [
          51164,
          1119,
          456,
          257,
          17542,
          420,
          1594,
          689,
          561,
          2248,
          280,
          20,
          13,
          25530,
          30,
          51414
        ]
      },
      {
        "avg_logprob": -0.3066978454589844,
        "compression_ratio": 1.4702702702702704,
        "end": 6243.22,
        "id": 1801,
        "no_speech_prob": 0.384792298078537,
        "seek": 622022,
        "start": 6241.22,
        "temperature": 0,
        "text": " Yes, forum.processing.org.",
        "tokens": [
          51414,
          1079,
          11,
          17542,
          13,
          41075,
          278,
          13,
          4646,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.3066978454589844,
        "compression_ratio": 1.4702702702702704,
        "end": 6248.22,
        "id": 1802,
        "no_speech_prob": 0.384792298078537,
        "seek": 622022,
        "start": 6246.22,
        "temperature": 0,
        "text": " Isn't there a way to share the code real time?",
        "tokens": [
          51664,
          6998,
          380,
          456,
          257,
          636,
          281,
          2073,
          264,
          3089,
          957,
          565,
          30,
          51764
        ]
      },
      {
        "avg_logprob": -0.22332141273900083,
        "compression_ratio": 1.5507246376811594,
        "end": 6250.22,
        "id": 1803,
        "no_speech_prob": 0.031141316518187523,
        "seek": 624822,
        "start": 6248.22,
        "temperature": 0,
        "text": " Typically what I do is try to upload this stuff to GitHub",
        "tokens": [
          50364,
          23129,
          437,
          286,
          360,
          307,
          853,
          281,
          6580,
          341,
          1507,
          281,
          23331,
          50464
        ]
      },
      {
        "avg_logprob": -0.22332141273900083,
        "compression_ratio": 1.5507246376811594,
        "end": 6251.22,
        "id": 1804,
        "no_speech_prob": 0.031141316518187523,
        "seek": 624822,
        "start": 6250.22,
        "temperature": 0,
        "text": " right afterwards.",
        "tokens": [
          50464,
          558,
          10543,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.22332141273900083,
        "compression_ratio": 1.5507246376811594,
        "end": 6252.22,
        "id": 1805,
        "no_speech_prob": 0.031141316518187523,
        "seek": 624822,
        "start": 6251.22,
        "temperature": 0,
        "text": " This code is already on GitHub",
        "tokens": [
          50514,
          639,
          3089,
          307,
          1217,
          322,
          23331,
          50564
        ]
      },
      {
        "avg_logprob": -0.22332141273900083,
        "compression_ratio": 1.5507246376811594,
        "end": 6254.22,
        "id": 1806,
        "no_speech_prob": 0.031141316518187523,
        "seek": 624822,
        "start": 6252.22,
        "temperature": 0,
        "text": " because it's part of the quadtree repo.",
        "tokens": [
          50564,
          570,
          309,
          311,
          644,
          295,
          264,
          10787,
          83,
          701,
          49040,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.22332141273900083,
        "compression_ratio": 1.5507246376811594,
        "end": 6258.22,
        "id": 1807,
        "no_speech_prob": 0.031141316518187523,
        "seek": 624822,
        "start": 6254.22,
        "temperature": 0,
        "text": " And, is it possible to use quadtrees with k-means clustering?",
        "tokens": [
          50664,
          400,
          11,
          307,
          309,
          1944,
          281,
          764,
          10787,
          3599,
          279,
          365,
          350,
          12,
          1398,
          599,
          596,
          48673,
          30,
          50864
        ]
      },
      {
        "avg_logprob": -0.22332141273900083,
        "compression_ratio": 1.5507246376811594,
        "end": 6260.22,
        "id": 1808,
        "no_speech_prob": 0.031141316518187523,
        "seek": 624822,
        "start": 6258.22,
        "temperature": 0,
        "text": " Probably, that would be an interesting thing.",
        "tokens": [
          50864,
          9210,
          11,
          300,
          576,
          312,
          364,
          1880,
          551,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.22332141273900083,
        "compression_ratio": 1.5507246376811594,
        "end": 6262.22,
        "id": 1809,
        "no_speech_prob": 0.031141316518187523,
        "seek": 624822,
        "start": 6260.22,
        "temperature": 0,
        "text": " Anyway, I've really got to run",
        "tokens": [
          50964,
          5684,
          11,
          286,
          600,
          534,
          658,
          281,
          1190,
          51064
        ]
      },
      {
        "avg_logprob": -0.22332141273900083,
        "compression_ratio": 1.5507246376811594,
        "end": 6265.22,
        "id": 1810,
        "no_speech_prob": 0.031141316518187523,
        "seek": 624822,
        "start": 6262.22,
        "temperature": 0,
        "text": " because I'm going to be back in an hour and 15 minutes.",
        "tokens": [
          51064,
          570,
          286,
          478,
          516,
          281,
          312,
          646,
          294,
          364,
          1773,
          293,
          2119,
          2077,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.22332141273900083,
        "compression_ratio": 1.5507246376811594,
        "end": 6271.22,
        "id": 1811,
        "no_speech_prob": 0.031141316518187523,
        "seek": 624822,
        "start": 6265.22,
        "temperature": 0,
        "text": " It will be, if I go to coding train,",
        "tokens": [
          51214,
          467,
          486,
          312,
          11,
          498,
          286,
          352,
          281,
          17720,
          3847,
          11,
          51514
        ]
      },
      {
        "avg_logprob": -0.22332141273900083,
        "compression_ratio": 1.5507246376811594,
        "end": 6273.22,
        "id": 1812,
        "no_speech_prob": 0.031141316518187523,
        "seek": 624822,
        "start": 6271.22,
        "temperature": 0,
        "text": " is it here?",
        "tokens": [
          51514,
          307,
          309,
          510,
          30,
          51614
        ]
      },
      {
        "avg_logprob": -0.22332141273900083,
        "compression_ratio": 1.5507246376811594,
        "end": 6275.22,
        "id": 1813,
        "no_speech_prob": 0.031141316518187523,
        "seek": 624822,
        "start": 6273.22,
        "temperature": 0,
        "text": " Where do I find it?",
        "tokens": [
          51614,
          2305,
          360,
          286,
          915,
          309,
          30,
          51714
        ]
      },
      {
        "avg_logprob": -0.22332141273900083,
        "compression_ratio": 1.5507246376811594,
        "end": 6277.22,
        "id": 1814,
        "no_speech_prob": 0.031141316518187523,
        "seek": 624822,
        "start": 6275.22,
        "temperature": 0,
        "text": " There's an event.",
        "tokens": [
          51714,
          821,
          311,
          364,
          2280,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.24304782983028528,
        "compression_ratio": 1.544502617801047,
        "end": 6279.22,
        "id": 1815,
        "no_speech_prob": 0.0008830058504827321,
        "seek": 627722,
        "start": 6277.22,
        "temperature": 0,
        "text": " Let me just go to Twitter.",
        "tokens": [
          50364,
          961,
          385,
          445,
          352,
          281,
          5794,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.24304782983028528,
        "compression_ratio": 1.544502617801047,
        "end": 6283.22,
        "id": 1816,
        "no_speech_prob": 0.0008830058504827321,
        "seek": 627722,
        "start": 6279.22,
        "temperature": 0,
        "text": " Twitter, noopecat, noopcat.",
        "tokens": [
          50464,
          5794,
          11,
          572,
          1114,
          18035,
          11,
          572,
          404,
          18035,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.24304782983028528,
        "compression_ratio": 1.544502617801047,
        "end": 6288.22,
        "id": 1817,
        "no_speech_prob": 0.0008830058504827321,
        "seek": 627722,
        "start": 6286.22,
        "temperature": 0,
        "text": " Here is the link.",
        "tokens": [
          50814,
          1692,
          307,
          264,
          2113,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.24304782983028528,
        "compression_ratio": 1.544502617801047,
        "end": 6294.22,
        "id": 1818,
        "no_speech_prob": 0.0008830058504827321,
        "seek": 627722,
        "start": 6290.22,
        "temperature": 0,
        "text": " Live in 74 minutes!",
        "tokens": [
          51014,
          10385,
          294,
          28868,
          2077,
          0,
          51214
        ]
      },
      {
        "avg_logprob": -0.24304782983028528,
        "compression_ratio": 1.544502617801047,
        "end": 6296.22,
        "id": 1819,
        "no_speech_prob": 0.0008830058504827321,
        "seek": 627722,
        "start": 6294.22,
        "temperature": 0,
        "text": " There will be a guest tutorial here",
        "tokens": [
          51214,
          821,
          486,
          312,
          257,
          8341,
          7073,
          510,
          51314
        ]
      },
      {
        "avg_logprob": -0.24304782983028528,
        "compression_ratio": 1.544502617801047,
        "end": 6298.22,
        "id": 1820,
        "no_speech_prob": 0.0008830058504827321,
        "seek": 627722,
        "start": 6296.22,
        "temperature": 0,
        "text": " about hardware and JavaScript.",
        "tokens": [
          51314,
          466,
          8837,
          293,
          15778,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.24304782983028528,
        "compression_ratio": 1.544502617801047,
        "end": 6299.22,
        "id": 1821,
        "no_speech_prob": 0.0008830058504827321,
        "seek": 627722,
        "start": 6298.22,
        "temperature": 0,
        "text": " So I'm going to run.",
        "tokens": [
          51414,
          407,
          286,
          478,
          516,
          281,
          1190,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.24304782983028528,
        "compression_ratio": 1.544502617801047,
        "end": 6301.22,
        "id": 1822,
        "no_speech_prob": 0.0008830058504827321,
        "seek": 627722,
        "start": 6299.22,
        "temperature": 0,
        "text": " I'm going to grab something to eat.",
        "tokens": [
          51464,
          286,
          478,
          516,
          281,
          4444,
          746,
          281,
          1862,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.24304782983028528,
        "compression_ratio": 1.544502617801047,
        "end": 6303.22,
        "id": 1823,
        "no_speech_prob": 0.0008830058504827321,
        "seek": 627722,
        "start": 6301.22,
        "temperature": 0,
        "text": " I will be back in an hour or so.",
        "tokens": [
          51564,
          286,
          486,
          312,
          646,
          294,
          364,
          1773,
          420,
          370,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.24304782983028528,
        "compression_ratio": 1.544502617801047,
        "end": 6306.22,
        "id": 1824,
        "no_speech_prob": 0.0008830058504827321,
        "seek": 627722,
        "start": 6303.22,
        "temperature": 0,
        "text": " Noopcat and I will be here for a couple hours",
        "tokens": [
          51664,
          883,
          404,
          18035,
          293,
          286,
          486,
          312,
          510,
          337,
          257,
          1916,
          2496,
          51814
        ]
      },
      {
        "avg_logprob": -0.26361202663845484,
        "compression_ratio": 1.4973821989528795,
        "end": 6308.22,
        "id": 1825,
        "no_speech_prob": 0.00115131342317909,
        "seek": 630622,
        "start": 6306.22,
        "temperature": 0,
        "text": " doing her guest tutorial.",
        "tokens": [
          50364,
          884,
          720,
          8341,
          7073,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.26361202663845484,
        "compression_ratio": 1.4973821989528795,
        "end": 6309.22,
        "id": 1826,
        "no_speech_prob": 0.00115131342317909,
        "seek": 630622,
        "start": 6308.22,
        "temperature": 0,
        "text": " And that will then be the end.",
        "tokens": [
          50464,
          400,
          300,
          486,
          550,
          312,
          264,
          917,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.26361202663845484,
        "compression_ratio": 1.4973821989528795,
        "end": 6311.22,
        "id": 1827,
        "no_speech_prob": 0.00115131342317909,
        "seek": 630622,
        "start": 6309.22,
        "temperature": 0,
        "text": " Edited versions of all these challenges and stuff",
        "tokens": [
          50514,
          3977,
          1226,
          9606,
          295,
          439,
          613,
          4759,
          293,
          1507,
          50614
        ]
      },
      {
        "avg_logprob": -0.26361202663845484,
        "compression_ratio": 1.4973821989528795,
        "end": 6313.22,
        "id": 1828,
        "no_speech_prob": 0.00115131342317909,
        "seek": 630622,
        "start": 6311.22,
        "temperature": 0,
        "text": " will come out next week.",
        "tokens": [
          50614,
          486,
          808,
          484,
          958,
          1243,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.26361202663845484,
        "compression_ratio": 1.4973821989528795,
        "end": 6315.22,
        "id": 1829,
        "no_speech_prob": 0.00115131342317909,
        "seek": 630622,
        "start": 6313.22,
        "temperature": 0,
        "text": " Yeah, alright.",
        "tokens": [
          50714,
          865,
          11,
          5845,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.26361202663845484,
        "compression_ratio": 1.4973821989528795,
        "end": 6318.22,
        "id": 1830,
        "no_speech_prob": 0.00115131342317909,
        "seek": 630622,
        "start": 6315.22,
        "temperature": 0,
        "text": " So thanks everybody for watching.",
        "tokens": [
          50814,
          407,
          3231,
          2201,
          337,
          1976,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.26361202663845484,
        "compression_ratio": 1.4973821989528795,
        "end": 6320.22,
        "id": 1831,
        "no_speech_prob": 0.00115131342317909,
        "seek": 630622,
        "start": 6318.22,
        "temperature": 0,
        "text": " And I will see you,",
        "tokens": [
          50964,
          400,
          286,
          486,
          536,
          291,
          11,
          51064
        ]
      },
      {
        "avg_logprob": -0.26361202663845484,
        "compression_ratio": 1.4973821989528795,
        "end": 6322.22,
        "id": 1832,
        "no_speech_prob": 0.00115131342317909,
        "seek": 630622,
        "start": 6320.22,
        "temperature": 0,
        "text": " I'll see you if you're going to tune in.",
        "tokens": [
          51064,
          286,
          603,
          536,
          291,
          498,
          291,
          434,
          516,
          281,
          10864,
          294,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.26361202663845484,
        "compression_ratio": 1.4973821989528795,
        "end": 6323.22,
        "id": 1833,
        "no_speech_prob": 0.00115131342317909,
        "seek": 630622,
        "start": 6322.22,
        "temperature": 0,
        "text": " I'll see you in like an hour.",
        "tokens": [
          51164,
          286,
          603,
          536,
          291,
          294,
          411,
          364,
          1773,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.26361202663845484,
        "compression_ratio": 1.4973821989528795,
        "end": 6325.22,
        "id": 1834,
        "no_speech_prob": 0.00115131342317909,
        "seek": 630622,
        "start": 6323.22,
        "temperature": 0,
        "text": " Okay, goodbye!",
        "tokens": [
          51214,
          1033,
          11,
          12084,
          0,
          51314
        ]
      }
    ],
    "transcription": " Okay, I have returned and I have restarted the computer and I have also switched some settings to, I had it set on YouTube for low latency because I like the live stream viewers to be as close in time to the actual real time of me speaking and demonstrating things, but I switched it to normal latency in the hopes that that, you know, it says there, highest viewer playback quality. So fixed. Great. All right. Ah, wonderful. Okay, so that's good to know. I guess I can't really use that low latency. What I'm curious about is to do a little bit of timing. So what I'm going to do, so I'm going to watch the patron group in the Slack channel. I'm going to clap and then I'm going to start a timer on my watch. Stop watch, reset, and I'm going to clap and then I want you to type clap into the patron Slack channel when I clap and I'll see how long the delay is. Ready? Oh, wait. Actually, I'm going to say now. I can't clap because I'm going to press into the stopwatch. Ready and now. So just type now when you hear this, although it'll be past. I'm waiting. I'm waiting. Okay, I've really botched that. So you're about 17 seconds behind, which is fine. Typically, I've been able to get the live stream lag down to less than 10 seconds, but I'd much rather have higher quality for you. Okay, we're back. All aboard. Good morning, it's the coding train with me, your host. Something or other. Oh, there's actually a thing which gives the live latency. All right. So I'm all rattled now. So what was I talking about? Let me read. Let me act as if nothing has happened and I've just started. I'm going to click over here. Now I was saying, oh, I've run out of so much time. Coming soon, next week some point, a video tutorial from Lisa Jamboree about the Connectron project. So I was talking about that earlier. I guess I won't talk about it again. I feel like I'm repeating myself, even though maybe that's all that bad quality stream thing is now gone from the internet forever. This afternoon, I want to get started with some coding because I've already lost a lot of my wasting time time. This afternoon, I am very excited to announce that Twitter.com, let me go actually Twitch Noop Cat. Let's on the live stream this afternoon will be Noop Cat from Twitch that you might know from, ah, don't make me watch this ad. Okay, okay. I'm so, okay, hold on. Let's go to Noop Cat's website. So Noop Cat, Suze Hinton, will be here this afternoon at about 2.30pm Eastern time to talk about doing stuff with hardware and JavaScript. I will stand all the way, I will have to leave the room or stand all the way in the corner or something because if I go near hardware, it spontaneously bursts into flame. There's actually downstairs in the shop, in the physical computing areas, there's various alarms that are set up. If I walk anywhere near, all the alarms go off, all the students go running. But I have the opposite effect sometimes on this like code, JavaScript code. I could just walk by a computer and the bugs kind of go away. I lead a very strange life. So I would love for you to come and tune in this afternoon. I'm really excited to have Noop Cat as a guest and I encourage you to subscribe to her Twitch channel. She typically does live streams on Sundays and I'm hoping to make an appearance on one of her live streams as well in my desire to collaborate with other people in the world of streaming, educational coding technology. I don't know. If there's anybody out there doing musical theater, I would love to collaborate with you actually. But you probably don't want to collaborate with me. Okay, is it Noop Cat or Noop Cat? I always just say Noop Cat. Am I been saying it wrong all this time? Like Noop Cat, like No Operation Cat? I have no idea. Have I been saying it wrong all this time? Well, guess what? We're going to find out this afternoon. The mystery will be solved. So what am I here to do today? I am going to talk to you about these things. First what I'm going to do while I'm talking about these things, I'm going to erase this whiteboard. Wouldn't it be nice if during a live stream I could have that like effect where it's just like me and fast forward doing it really fast. Maybe I could try to do that live because that was recently in one of my videos. Mathieu, who does the editing, put in this like speed up effect thing and everybody loved it. So I'm kind of in love with that. Okay, I'm going to attempt to do that. Maybe if I have the music on, it'll help me. Sorry, Lisa. It was a beautiful diagram. Okay. That was my exercise for the day. Let's see what my Fitbit thinks of my steps. Fitbit not officially a sponsor, but Fitbit, sponsor. Sponsorship, I'm taking sponsors now. Living in New York City is very expensive. Okay, what is it doing? I need a marker. All right, so here's what I want to do today. First of all, Suze, which now I'm apparently even saying this wrong all my life, no OP cat or noob cat, which is the way that I say it. 2.30, Eastern Daylight Time. Come for the rainbows, stars, hearts. This is the most important thing to happen today. At least, I don't know, I might have something else that's kind of important, but I don't think so. No, today in my life, this is the most important thing to happen. Now, this morning, she's coming at 2.30. We're meeting to get set up here. Before that, I need to eat some lunch. So I think that I can reasonably stream until about 1 p.m. right now, which is only an hour and 20 minutes right now, which is not a lot of time. So on my list is I wanted to finish off the quadtree challenges and do quadtree with collisions. I want to do Jabril's color predictor to finish off that collaboration. So if you're not aware, Jabril was here last Friday, did a guest spot on the Coding Train about the color predictor, then on Sunday released a video on his own channel about the color predictor that has me in it. And then I thought I would do as a last piece of that, do a tutorial about building your own neural network-based color predictor. And that's kind of my highest priority, I think, for this morning. And the third thing, as I want to follow up on my p5 load bytes pull request, and number four, oh, boy, I need to, like, come back tomorrow or something and Sunday and Monday. I've got, like, an hour. Any one of these things would probably take me the whole time. And the fourth thing is I want to talk about TensorFlow. Wait, hold on. I've got a sound effect for this somewhere. TensorFlow dot JS. So something new came out last Friday called TensorFlow dot JS, which is actually formerly known as DeepLearn dot JS, which I have referred to. And boy, am I planning a lot of sessions and tutorials and stuff about using that and how it relates to this other project, which is called ML5, I guess, dot JS, which is an open source library built on top of TensorFlow dot JS. This is kind of like a flawed analogy. But just to make the case for a second, you might say that, like, p5 is a kind of higher level API for HTML5 Canvas, sort of a lower level API for working in drawing in the browser. P5 is more than that. And the distance between these two things actually isn't even that far. But that's, I guess, that's the easiest way for me to explain what ML5 is. TensorFlow being a JavaScript version of TensorFlow with low level functionality to do machine learning algorithms and mathematics and various tasks. ML5 being a higher level layer API on top of that. Now, the other thing is I should mention in between those two things is something called Keras. Without going into a long history of what's TensorFlow, what's Keras, that would probably be an interesting topic for a video. TensorFlow dot JS supports what's called the layers API, which is Keras itself is a higher level layer on top of TensorFlow. And so ML5 is probably even higher level. So a lot of the features that I'm hoping to work on in the next month or two and certainly well over the summer is building out examples and tutorials that build on top of Keras and TensorFlow dot JS. OK, for machine learning stuff. Thank you. Good night. That's all I have. So this is my list. And I have to decide what to do. And I know if Simon is watching, Simon would say to a straw poll. The straw polls never go well for me. I think what I'm going to... I'm actually looking to see if there's any questions here in the chat. I know you're 20 seconds behind of me. And I guess I should put my secret cloaking device on top of this secondary laptop where I keep all of the answers and all of my code because that's my secret. No, I'm just kidding. And that's pretty good. This needs to be... Actually, I need to fix one thing. Let me do this. Oops, wrong thing. Sorry, I'm just fixing something in the live stream here. Moving myself down a tiny bit. There we go. That's usually how I have it. There we go. Ah, Kenneth Lim is around for an hour if you want to do the pull request first. I do. But I think that's probably not wise. But let's actually... Let me at least revisit. So I did... Since Kenneth is in the chat, let me go quickly to github.com processing p5.js. Pull requests and load bytes. Here we go. So I did just release a video this morning. This was made weeks ago. I just had a mental block with releasing it, which is this video. Adding a function to p5.js. So I wanted to, in that video, show the process of making a pull request to a larger open source project and what's involved with that. And I did that. This is the pull request. There are some nice comments from meiamsomy and from limzykenneth, who's in the chat. And so I think, actually, just scanning this over, probably what I just want to do is implement this change to how I'm finding the error. So before this can be merged... It is over here. There's some noise, but that's fine. Before this can be merged, I've got to push some more changes to the pull request. But I think I'm not going to do that right now. But I would welcome any feedback or comments here, and I'll try to get to that soon. All right. So now the question is color predictor or... Let me do a straw poll, because I can't decide. Color predictor... I really feel like I should do the color predictor, because it's following up on the livestream from last week, and doing it later will be stale. I'm going to do the color predictor. Yeah, let's do the color predictor. So let me get... We have an hour and 15 minutes for that. And I think it's going to happen. One thing, though, I'm a little bit freaked out about is the following. Let me show you what I'm freaked out about. Coding challenges. I'm going to go to this playlist. Coding challenge one. 13 minutes, Starfield in processing, many fewer gray hairs, nicer shirt. This shirt has now been gone into textile recycling, because it had two holes in it. But anyway, that's coding challenge one, whenever that was recorded. If I go all the way down to here... I'll keep scrolling. I'm going to scroll... Look at this. Quadtree 98. This means my color predictor, the color predictor, Jabril's color predictor, would be coding challenge 99. Now, I can get away with coding challenge 98.3, being Quadtree part three. But then it's going to be time for coding challenge number 100. I feel really stressed out about... But I could just say, it's just another coding challenge. It's just number 100. But I feel this pressure to do something extra special for that. Could be the neuroevolution thing, because that's kind of like a topic I've been building up to for a while. Could be Tetris, but I'm not so game-focused that that really makes sense. Anyway, I'm open to your ideas. That's what I'm thinking about these days. All right, let's do the color predictor. So let me get myself situated. Someone's going to have to wake up Jabril. He's early on the West Coast, and I know he's not a morning person. That's something I learned. I was like, let me schedule you for this thing at NYU at 10am. That's no problem for you, right? Yeah, we're going to have a Y2K issue, because suddenly now the coding challenges have three numbers instead of two. Our unit tests don't accommodate that. CD desktop, P5G-B, color predictor. I don't know if color predictor is actually the right term for this. CD color predictor open. Let's see. I don't care about... So actually, this is ridiculous what I'm doing here, but I'm going to do it anyway. I'm going to get rid of the libraries folder. I'm going to go to... I think here, I'm going to see if there's any changes to my neural network library. I'm going to grab... Come on. What the... Okay. I'm going to go grab matrix.js and neural network.js. I'm going to put those in here. Let's put those in a little folder called lib, because I'm being silly. And then now we need to get... One of these days, I'm going to switch to Visual Studio Code and iTerm. But I'm way behind the times. I'm waiting until there's the thing that people are using that's not iTerm, then I can switch to iTerm. That's how it works with me. Oh, look. And this is Jabril's. Here's his code. It's the last thing that was open on this computer. So maybe that's good to have that available, because I can reference it. Where is that? Where was that? I'm going to open this up also. It's going to be sad when, by the time I get this set up to ready to start coding, the E key doesn't... I need a password with no E key. That... Yeah. That... There we go. Thank you. Okay. All right. So now, what am I doing here? Now I need the Atom editor. I want to open... Why do computers never work? Huh? Someone tell me that. Why do they not work the way they're supposed to? Come on, Atom. There you are. Let's open the color predictor code, which is nothing right now. A blank sketch.js file. Index HTML. I want to link to the P5 CDN, because I feel like that's just going to be better. So let me do that here. And I'll put that here. And I don't need sound. I probably do need DOM. You know what? Also, I should just use the minified, because I'm not going to be messing with the P5 library itself. So let me do this, actually. And let me link to those. Get rid of this extra stuff. One of these days, I will change my template instead of just redoing it every time. Neural network.js. Matrix.js. All right. I think we are just about ready to go. Here I am. Let's run a little local web server. I will check the chat in a second. Failed to load, because why? Because I put those in a folder called lib. I think we're good. Yep. Let's make this... Let's think about the amount of space I want here. Make this a little bigger. All right. I think I am ready now to start coding. There's some discussion in the chat going on about numbers. I just want this to go down a tiny bit, maybe. Oh. Camera went off. Now I just realized something, which is that I'm going to use the whiteboard for this tutorial, and I now have this whole thing here. I guess what I will do is screen... Just screen cap this for me. We'll save it for later. I guess I'm going to erase it. So I'm going to remember this list for another time. I'm going to remember that Suze... Now I'm calling her by her name, because I'm afraid to say noopcat, noopcat, noopcat, incorrectly. That's probably not noopcat. You know, viewer meiamsome, I used to call meiamsum. That's what I thought it was. So this is a pattern I have of misinterpreting and mispronouncing things. Okay. We are just about ready to get started. I am going to very briefly... Now I just need to pull up something. Maybe I'll pull up... Let me pull up Jabril's YouTube channel. That can be my background here. To start. It's noopcat. Noopcat. I don't know. Noobcat. Anyway. Okay. Thanks for all the suggestions. All right. Okay. SuperSipMe writes, I'm so bored. I don't blame you. I'm so bored. I'm so bored. I'm so bored. I'm so bored. I'm so bored. I'm so bored. I'm so bored. I'm so bored. I'm so bored. It's only been, what? Like an hour and I haven't done anything yet? It's like 11.53 already? All right. That was exciting, all right? You're no longer bored, right? That's the suspense of whether I will catch that or not. Here we go. We are going to make a color predictor. Sip of the tea. Tea goes to dangerous spot. And here we go. Okay. There's like a thing. Oh, it's actually just on my screen. That's what that is. By the way, I keep thinking it's time for me to get rid of this snowy background, but it just keeps snowing in New York. What's going on, people? It just got very hot in here. Sweating. Okay. Here we go. Okay. Hello and welcome to coding challenge number 99. Oh boy, we're getting close to 100. I don't know what I'm going to do. If you have any ideas for what coding challenge 100 should be, please put them in the comments. But this coding challenge is to make a neural network color predictor. And I am basing this coding challenge off of... Okay. Matu, you're just going to have to do an edit there. And I'm going to figure it out here. I liked my beginning, so I'm going to keep it. How does he say it? S science. Sef science. Sef science? I can't say it. Anybody tell me? He told me this before. Sef science? I should just say Jabril. I'm just going to say Jabril. This coding challenge is based off of Jabril's YouTube channel and his color predictor machine learning demo. So I encourage you to check out that video. He also did a live stream. I actually have... Sef stuff. Sef stuff. I think I just say Sef stuff. That's what it is. I'm going to do the whole thing again. Here we go. It won't be as natural when I redo the whole 99 thing, but... Hello, and welcome to coding challenge number 99. No, the bell comes later. I've reversed this. Okay. Hello, and welcome to another coding challenge. Now, this coding challenge is number 99, which means the next coding challenge is number 100. And I have no idea what to do. I feel this pressure to do something special. So please, in the comments, write your suggestions for coding challenge number 100, and maybe I'll think of something, or you'll help me think of something. Okay, so what's happening now? I am going to do a coding challenge to make a neural network color predictor. This is based off of a project made by Jabril. Check out his YouTube channel. Link in this video's description. He has a video called Color Predictor Machine Learning Demo that I encourage you to watch. He also actually came on as a guest, and I'll link to a video with Jabril where he talks through this color predictor. But I'm going to make my own version of it, and I'm going to use my toy neural network JavaScript library. Okay, so first, before I start coding, I want to spend some time with you, the viewer, just taking deep breaths together, thinking about flowers. Okay, I guess I should talk through what the problem is. So here's the problem, so to speak. Now, one of the reasons why I love this idea, which came from Jabril, is that I'm always looking for really simple, almost trivial scenarios to demonstrate a machine learning concept. Where all the pieces of how the algorithm works, it's visual, it involves interaction, it involves drawing, because this, to me, is a good basis for people watching and learning to then build their own more complex or sophisticated design machine learning system things. So this is incredibly simple, and in fact, just to be clear, you do not need a neural network for this. It almost makes no sense at all to use a neural network for this. But it makes the point, you might have heard this, you might have heard this idea that a neural network is a universal function approximator. So I think that this video, and this topic, and this demonstration will unpack what this means in a nice way. So, what do I mean by that? So, what is the problem that we're trying to solve? So the problem is, let's say I have a color, some RGB color. Some RGB color. And I want to put text on top of that color. So I could make a more complex problem, which I would encourage you to do as an exercise after watching this. What would be the most pleasantly looking or complementary, that's an actual thing, color to overlay on that RGB color? But I'm just going to ask a simple question. Which looks better? Black or white? And we could get into a whole discussion of why, you know, perception, what looks better. But I just mean in the sort of arbitrary sense, which is easier to read, which is more legible. And we could write a function, right? We could write a function, a JavaScript function. I'm just checking to see, right? And that JavaScript function takes as its arguments an R, a G, and a B. And what it does is it returns, maybe it returns, I mean, black. Or maybe somewhere else in the function it returns white. And maybe we just have like this if statement. And maybe I'm doing something like if R plus G plus B is less than 100 or less than 200, return black. Otherwise return white. So this is the idea. This is a function. It takes inputs. How many inputs? Three. And it returns an output. How many outputs? One. But out of two possibilities is important here. There are two possible, out to two possibilities. It takes one output. It's a function that takes three inputs and returns one output. The inputs are numbers between 0 and 255. And the output is one label, which is a string. But another way I could think about this is it could return a kind of probability value. How likely is it that black looks better and how likely is it that white looks better? And that would be kind of also two floating point numbers. You could think of it that way. So this is a function. So a lot of machine, like imagine this. So now I have this function that takes an RGB color. Now let me give you another function. Write a function that takes an image data, a 200 by 200 pixel image, and then returns what's in that image. Now you could imagine, in this case, deciding whether it should be black or white is just a matter of, okay, is it bright, is it dark, which color is going to be? Like a bright color looks better on a dark color. A dark color looks better on a bright color. But if I took in a full image and needed to return, whether it's a cat, a dog, a turtle, a coffee mug, a cell phone, a walking stick, a conductor's baton, I don't know where my brain is going here, a toy train. Try writing a bunch of if statements to do that. Well, if the pixel colors are this and shaped like this, having to hard code an algorithm, a function that takes inputs and generates an output, would be really difficult. This is what a neural network is for. And just to make this case here, the idea here is that a neural network can approximate any function. It can learn to receive inputs and return the outputs for any input data for any sort of problem. Is this true that any, in capital letters, the big underline is true? That's an open question. What are the limitations? What should and should not we be doing? Should we even be using a neural network for this task? Are we causing harm by doing this machine learning task? But those questions aside, now we can say, well, if I have this quote unquote neural network thing, what if I were to just send three inputs into it, R, G, B, and then I want to receive two outputs, probability of black, probability of white. This is now a universal function approximator. It is going to stand in, so what is neural net, machine learning doesn't necessarily replace, you can think of it as, I mean, will machine learning replace the need to write code completely at some point? Maybe. But here, what I would make the case is that machine learning, a neural network, might replace the guts of a function that you might hard code otherwise. Okay, boy, am I spending a long time explaining this. So now, what goes here? Now, if you want to learn more about the structure of a neural network and the internals of it, I would refer you to the 3Blue1Brown video series, as well as my video series. I would refer you to the 3Blue1Brown video series, as well as my video series, which goes through building this neural network library in JavaScript. For us, as the user of the neural network library, the only things we need to decide are how many inputs, sorry, the only things we need to decide are how many inputs, and how many outputs, and then, so this is, inputs and outputs are the things we, as the end user of the neural network, look at and control. We're sending in the input, we're reading the output, we're doing something with the output. We're sending in the input, we're reading the output, we're doing something with the output. But, the sort of quote-unquote magic, which isn't magic, it's just math, numbers multiplied and added together, all sorts of other stuff, is this idea of a hidden layer. And there can be multiple hidden layer, there can be hidden layers of different nodes, but for the sake of argument, this is such an incredibly simple problem, who knows if we even need the hidden layer for it, we probably do, but we can just kind of pick something somewhat arbitrarily. So I'm going to say there are three inputs, there are two outputs, and what I'm going to do is just say, this is what Jabril used, so why not use the same? I'm going to add three hidden nodes. And the idea of a neural network is the inputs all go into each hidden node, they get processed by the hidden node, and each hidden node connects to every output, whoops, I did that, and then they get processed by the outputs, and we get the results. That's known as feedforward. What is that processing? It has to do with the weights of the connections, the summing of the values, the activation of the neural network. I think at this point, it probably makes more sense for me to refer you to my other tutorials that go through the mechanics of this. I just want to now use it in a sort of higher level way, as a library where I'm going to send in my inputs and look at the outputs. And of course, I'm going to have to train it. I'm going to have to teach the neural network to give me certain outputs that I want. So that's what I'm going to get into when I go and write the code right now. Okay, boy, how was that, like half an hour? But I kind of wanted to make that explanation, because I feel like people say universal function approximator, I hear that all the time, and I wanted to make some sort of connection of what that actually means. Was that helpful? Give me a little feedback here before I move on. Should this now be part two? I don't think so. I think this can all still be in one video. And by the way, I really should be adding Softmax to my neural network library, but I don't have time to do that. Oh, yes, yes, yes, yes, yes. The normalization. So that will come up. I should have mentioned that here. Thank you for pointing that out, but I'll just have to get to that when I start doing the coding. That will come up. All right. What time are we at? 12.06. Ah, that's a lot of time. Let me do a little camera cycling. Maybe if I had time in between during lunch today, if I had time to try to install that firmware to fix the camera finally. Oh, that was only eight minutes at the whiteboard? Oh, that's not bad at all. That's fine. Okay, great. Oh, yeah. Tim, I apologize. So let me just touch on this for a second because this is a really good question. I have to really apologize. I did not expect – I mean, maybe I should have. I sometimes don't realize that the audience for this channel is kind of large. And when I release something, people really are excited to contribute, and there are currently 32 outstanding pull requests here on this neural network library. I just honestly haven't really had the time to go through them, and I also want to add some stuff to it first. I really appreciate all of these contributions, and I've got to figure out a way to manage that. The truth of the matter is I just don't really have one right now. Coding Challenge 100 should be fixing the camera. That's good. Get a bell for that. All right. Okay, so let me – all right, all right. There's a lot of messages retracted. I don't know what that means. Okay. Okay, so first let's take a look at Jabril's code. He might have a newer version by now, but this is what he demonstrated last week on the coding train. So I could say, like, oh, I think white looks better on this color. By the way, I have no ability or talent for visual design whatsoever, so I'm going to get all this wrong. I don't know. Black looks better. Black looks better. White looks better. So you can see this is me active. This dot represents the computer guessing which ones it thinks it should be, and me clicking has to do with me giving this sort of, like, training information, like, hey, neural network, it should be this one. So I'm going to go through and build all the pieces of this. There's some other stuff going on in here where Jabril is using a genetic algorithm, and there's, like, this sort of voting thing going on, but let's just start building some code from scratch, and we can kind of compare and contrast. Oh, you can compare and contrast on your own later. Okay, so this is my color predictor. I'm going to go to an empty sketch. The first thing that I want to do is I'm just going to create variables for R, G, and B. And when the pro- I'm going to write a- maybe I'll write a function, pick color, and I'm just going to say R equals random, 255, G, B, and I am going to then draw the background, R, G, B, and I'm going to say mouse pressed, pick color. So let me make a few key points here. Me, in creating this example and writing this code, I'm not thinking about interaction design. I'm not thinking about visual design. I'm not thinking about optimized, efficient code. I just want to sort of demonstrate the idea and get something up and working quickly. You, the viewer, can then take this and make a more interesting, thoughtful, designed version of it, even perhaps with a different algorithm or a different problem altogether. But let's just see now. This should be enough code for me to, every time I click the mouse, get a new random color. Okay, so I might as well also pick that color in setup. Now, I also want to draw, let me say text size, 64. Then I want to say- let me do no stroke, I think. A text can have an outline and a fill. I'm going to do fill, zero, text, black, and let me do text align, center, also. Black, and that should be- what is my- let me make the dimensions of this a little simpler. 400 by 300, so this would be 150 then, I guess. 150, 150, I don't know. And 250, 150, and this would say white. So let's see how this goes. Alright, so that's a little bit too big, but I could also just make it wider. 600, and then this would be 200, and 400, right? There we go. And this one should be fill, 255. Okay, so now I have a system where at least I am seeing which one it should be, black or white. I'm seeing both colors written on top of the background. Let's draw a line down the middle. I think maybe visually it needs that. I don't think I centered these correctly, but whatever. Okay, okay, we're getting somewhere. Center, center, someone in the chat is telling me to use center, center. Why not? So that aligned it center vertically too. Beautiful, thank you. That was an excellent suggestion. Okay, so now what I want to do is, guess what? We're ready. This is what I love about this problem. We're ready for the neural network because we can do it. So what do I need? I want to make a, I'm going to call it brain. I'm going to make a variable called brain. It's going to be the neural network. Now, I just don't get a neural network in JavaScript just by the nature of programming JavaScript. I'm getting it because I have imported already into my HTML file two files, nn.js and matrix.js. This is a little toy neural network library that I developed and a whole set of video tutorials. At some point in the future, I'm going to replace this with this new project called TensorFlow.js, which is a lower level machine learning library and also ml5 is this other library, but I'll come back to that another time. I'm still using this little toy neural network. So what I want to do now in the code is I just want to say brain in setup. I want to say brain equals a new neural network. Now, it expects three arguments, three arguments. Now, this is not universal to how neural network libraries work. This is a very simple one that has very basic features, and what it expects is how many inputs, how many outputs, and how many hidden nodes, but not in that order, inputs, hidden, outputs. So this we can see is 3, 3, 2. That's the architecture, the model architecture that I have designed. 3, 3, 2. Wonderful. Now, I'm done. I got it. Woohoo. Now, what I can do is let's say every time, so let's make a variable called which, like which one is better, black or white, and I will just start with saying black, and what I'm going to do is let's do the same sort of technique that Jabril did. If which equals black, then I'm going to draw a circle, a circle which is where? At 200, 200, 300, 60, 60. And I'll, there, and then else if it's white, then draw it at 400, and so this would be fill 0, this would be fill 255, and we're still no stroke. Okay. So now, we see that's very far down. So let me move this up to 200. That's too, I have no sense of dimensions whatsoever. Perfect. Oh, this looks weird now. It's not all centered, but fine. Oh, I can't take it. I can't take it. Let's move this. I really shouldn't be doing this, but I'm going to. Let's make this 100, 100, and let's make this 200, 200. Okay, I feel better now. Okay, so it's always going to pick black right now because no matter what, I've just made which equal to black, but I can use the neural network now. I can use the neural network. The neural network is my function approximator. Let's actually write this code with our own non-neural network first just to make this case. I'm going to write color predictor, and I'm going to say get an RGB, and now I'm going to just say if R plus G plus B is greater than 300, then return black, else return white. So I'm going to do a hard-coded, this is my own human learning algorithm. I've decided that this is what it means to predict which color would be better, and then I'm going to say let which equal color predictor RGB. So now we can see it's making that prediction based on my algorithm. I wrote an algorithm to make that prediction. Now, so we've got this. We could be done. No machine learning necessary. I finished this project. Now what I want to do, though, is I want to comment this out, and I'm going to say, what am I going to say? I'm going to say first I need to make some inputs. So the neural network library expects as inputs, right? My library expects, and this is pretty typical of any kind of machine learning-based library that you might use. It expects the inputs to come in as an array of three numbers, and typically you're going to want to have those numbers normalized between 0 and 1. So this is what I need to send into the neural network. So inputs equals an array, and so how do I normalize these values? I can just divide them all by 255, and again, more likely there's going to be a much longer process of sort of cleaning and normalizing your data, but in this case of a single color, super easy to do. Now what I'm going to do is I'm going to ask for the output from the neural network. Let outputs equal, and I'm going to say brain. And the function, right, the function to do the feedforward algorithm to send the data through and get the result back in my library is called predict, because I'm making a prediction. Another term for this might be inference, guess, that type of thing. So I'm going to say brain.predict, and I'm going to pass in the inputs. Now let me just console log those outputs just so we can see, and this is going to sort of break, but let's just see what the outputs look like. Whoa, hold on. Why is this doing, oh, because draw is right. So one thing I just realized is I'm kind of, I'm doing all this in the draw loop, which is sort of silly, so let me actually just say no loop, and then in pick color, in pick color, which is where, where's the pick color? Oh, right here. I'm going to say redraw. So I only want to like redraw the canvas up there. I don't have anything animating, so I don't need the draw loop to be going over and over again. So cannot read property predict of undefined sketch.js. Oh, you know what? Why do I have that bug? I created the neural network after I called pick color. The neural network needs to exist before I call pick color. Okay, that's good to know. Great, so we can see, look at this, and why do I have this happen twice? 29, why is that happening twice? No, I guess it's going through the draw loop once, so maybe, yeah, interestingly. Okay, I'm not going to worry about it. I'm not going to get, I'll fiddle with that later. The point is, whoops, every time I click, we can see this is the output of the neural network. It's an array with two floating point numbers, and those I'm considering to be like the probability, right? If this number is higher, it should be a white, maybe black is the correct color. If this number is higher, the other one, whoops, my hand disappeared, the white color should be the one. Now, I haven't implemented some things. There's a particular algorithm which I really should put into my neural network library called softmax. I'll have to make a video tutorial about that in the future, which would ensure that these two numbers, these add up to a total of one and really represent a probability, but my neural network is very simple. I can just look at which of these output numbers is bigger. So I can say then, right here, I can say now, if outputs index zero is greater than outputs index one, we'll make that mean return black, otherwise, return white. So now, I have my color predictor function no longer uses a hard-coded algorithm. It uses the results of sending the input data through a neural network. So let's go ahead and run this, and I can click. Now, you can see here, it's kind of always picking white. If I refresh, still always picking white. If I refresh, it's kind of always picking black. So what's going on here? How come this isn't working? Why is this not learned properly? Which color should go on top of the other color? Guess what? The entire mechanic, all of the settings, all of the parameters, all of the weights of all these connections of the neural network were initialized completely randomly. A neural network isn't just going to learn as if by magic. It needs to be taught, and there are lots of different strategies for training and working with a neural network. One of those strategies is something called supervised learning. You probably can't supervise learning, which I have covered in other videos, in particular, my doodle classification coding challenge. So you might look at that as an example. But what's going on here? In a normal, more data science-driven machine learning context, we might prepare a giant training set. I'm going to make a big spreadsheet of every RGB color I can think of, and which one looks better, black or white. That's my training data set to pass through and train this neural network with. Then I'm going to have a testing data set, and that testing data set is not part of the training data set because I don't want the neural network to know about it, but it also has a bunch of labeled data, colors with black or white labels. Then I'm going to pass that through and see how well the neural network does guessing against those. And if it starts to do well, then I can say my model is complete, it has been trained, I can save it, and I can deploy it in some application which has to pick black or white on the fly. But I'm not going to do any of that in this video. I'm going to live in sort of a loosey-goosey interactive world where I'm just going to let it guess randomly, and I'm going to click in order to correct it. So I'm going to train the neural network one data point at a time with no training data, no testing data, just random data as I go. So you might think about how would you restructure this in a more sort of traditional training, testing, deployment context. So what do I mean by that? What I want to do is I'm going to create two buttons. I am going to... let's just do this here. Let's do let wButton. I'm going to have a wButton and a bButton, white button, black button. I'm going to say wButton equals createButton, white, and bButton equals createButton, black. And let's take a look here. Now, let's see if I can make this... Let me... I know I don't want to get lost in DOM manipulation, but really, really briefly... Style... No, no, I'm not going to get lost in DOM manipulation. I'm just going to leave it. Okay? I'm going to leave it. Oh, you can't see that. I'm going to move this over. I'm going to make everything a little smaller. No, no, no. No, no, no. Stop, stop. The coding train does not spend hours and hours and hours during tutorials trying to style and layout simple examples where it really doesn't matter. Say this to yourself over and over again. Okay, I'm just going to keep going. It doesn't matter. It doesn't matter if it's a little bit off. If you can't see it perfectly, you get the idea. These are my buttons over here. White, black. The idea is that... Oh, and look at this. Each time I press, it goes on to the next color, which is kind of interesting. I'm actually fine with that. So, what I want to do now... And it probably would be a nicer interaction if I just sort of clicked in the window there. But what I want to do is I want to do some events. I'm going to say mouse pressed. Oh, this is so silly. But it's fine. It's fine. It's fine. I'm going to keep going. Pause. Just give me a timeout for a second. I need an edit point. I've got to take a deep breath. Yeah, on click, figure out which side of the canvas is clicked. That seems much better. Yeah, I think I'm going to back up here. Let's back up. Let's forget about the buttons. Buttons were like an attempt in my mind to make this simpler. But there's really no point to them. Let's draw that line down the middle. Okay. What time is it? I've got 35 minutes. Let's keep going. All right. Okay, so I want to click... What I'm going to do here is as the trainer, I'm going to click on the side of the canvas that I think looks better. I think white looks better, so I'm going to click over here. Just to make this a little bit easier to follow, I'm also going to draw a stroke weight 4, stroke 255, 0. I guess I'm going to align width divided by 2, 0, width divided by 2, height 0. Width divided by 2, height. There we go. So I'm going to draw this so I can click... Why is these are totally not centered at all? I'm like a lunatic. These are not in the right place. I'm sorry. I have to correct that. It's making me crazy. It is... How wide is the window? It's 600 wide. 300 is the middle. Oh, silly me. 150, 350. Thank you very much. No, 450. 450. Thank you very much. Okay. 150. Just please bear with me. 450. Okay, now we're doing well. Okay, so now the idea here is every time I click over here, I want to teach the neural network which one I think it should be. So how do I do that? So I told you there was a function called predict, and the function called predict would send in the input data and give me an output prediction. Now what I want to do is I want to use a different function called train. So each time I click the mouse... Where is that mouse, Pris? Before I pick the new color, I want to determine is the mouse on the right side or the left side. So I want to create some inputs, which is an array. Let me just... let puts, inputs. And if mouseX is greater than width divided by 2, then the correct... Actually, I'm sorry, I want to create some targets. This is known as targets. I mean, you can use different terms for all these things, but targets are the target outputs I want. So if I click on the right side, I want the target outputs for white, and white means the second number is greater than the first number. So the targets, if I click on the right, should be 0, 1. This is the correct... This is the correct output that I'm telling the neural network should be if I'm clicking on the right side. Else, the targets... And I know I could use one of those ternary blah, blah, blah things, but this is just going to have to do. The targets are... If they're on the left, should be 1, 0. Let's pick up the pace here, people. By people, I mean me, not you. You're doing great if you're actually still watching this. And now what I'm going to do is I'm going to say brain.train. Oh, I need those inputs. So the inputs are the same exact thing I did here. The inputs are the current RGB. And what I want to do is I want to say, hey, brain, train yourself with these inputs with these targets. And in fact, this now is going to... The neural network is going to... What is it going to do? I'm saying here are the inputs, here are the correct outputs that go with those inputs. Do whatever adjustments you need to do, whether you were right or wrong, just figure it out. And what is that figuring out? So interestingly enough, I think this is worth... Even though this is covered in much more detail in my other videos, let's say the neural network, I feed in some inputs. And what it actually gives me is like 0.8, 0.2. This is what it gives me as the outputs. But I scave it, I'm training it, I'm going to give it targets. And the correct targets are 0, 1. That's the output that I wanted to get. That's the correct output. So what the neural network does is actually calculate something called an error. And the error is really simple. It's simply the desired minus the guess. Or the targets minus the prediction. Or the targets minus the outputs. So the error would actually be negative 0.8. And 0.8, interestingly enough. Very symmetrical there. So this would be the error. And then what happens? Inside that train function, an algorithm called backpropagation happens. The backpropagation takes this error and sends it backwards. So when I do prediction, I'm sending the data forward through the neural network. The training process is about looking at the outputs, calculating an error, and sending the error backwards through the network. And all these little changes, all these weights that are adding up numbers and doing all this math, they all get adjusted. So the errors would adjust all the parameters. And that's what's happening. Again, you can dive into my other tutorials which go through this in more detail. But that's what's happening right here in this function. So we are ready to go. Right? All right. So what I'm going to do, maybe we'll do, I'm going to train this for a while. If you're watching the edited version of this, it'll speed through fast. If you're watching this live, here we go. White. White. White. Black. Black. White. White. White. Black. Black. Black. White. White. Can anybody see these numbers? Are they really adjusting? This isn't really working very well, is it? But don't worry. White. White. Black. White. Just talk amongst yourselves. I probably need to have like, the interesting thing is like, this is why you need a lot of data for this stuff to work, do anything. I could make the learning rate much higher. That's probably what I should do. You can see here, let me just keep going. Hold on, let me at least just tell everything to be white. Yeah, okay. So it is sort of learning. Whoa. And I'm probably using like, Softmax and it's going to have much more. Okay, so let me keep going. I don't know. Do I have an error somewhere? Good news is I have a half an hour left. All right, so one thing I want to try to do, let's see if I can train it. Okay, I have an idea. Yeah, I mean it is working. The problem is, like for this to actually, so first of all, maybe I need more than three hidden nodes. I don't think so. It's such a simple problem. And I think it probably just needs a lot of training data. So let's actually, let's train it. Let's train it with a lot of training data. So I'm going to go through and do that. So I'm going to add this. Okay. So, Mateo, this is going to be the end of that sped up thing. So, and I'll come back. All right, I'm back. Actually, you know, so guess what? This didn't work very well. I mean I think it is working, working with air quotes because if I start teaching it, like hey, I think black looks better over everything, it's eventually going to switch. And then if I just click on white for a while, it's going to switch. Oh, and it's kind of, you can see it's sort of switching back and forth. But I think I'd have to sit here and click like for a really, really, really, really, really, really, really long time to get it to really like learn to make an optimal decision. I need like a lot of training data. This is a thing. I don't know what the discussion is going on in the chat. You're really messing with me. I just, I guess I just shouldn't look at it when it's like not about what I'm talking about. It's like emojis? What have I done? What have I done wrong? All right, let me, let me, I don't know. You can use all this as like some more fast forwarding time. I'm going to start over. Okay. Okay, I'm back. So I tried training this for a while. I tried talking about it for a little bit. I didn't really get very far, even though I think you can see like, ah, I'm going to like, I'm picking. And it's kind of actually, oops, no, I should really move. It's giving me sort of different results. That's black. This one is black. That's correct. That one is white. That one is correct. Look at this. Yeah. Hey, I think we're good. We can see that it's kind of making some decisions. We think this one should be white. Let's correct it. That seems right. This is definitely right. That seems right. This seems right. This seems right. Right. Right. Black is better with this one. White is better. I don't know. White. Anyway, you can see it's kind of getting, I don't know that I've really given it enough training data to really work optimally. Maybe I, this could be an interesting project if this were like deployed in a distributed way on the web and thousands of people could all come and click on it and like through and train it together as a group of people in the world. But let's try training it automatically to see if that works a little bit better. So how are we going to do that? So let me go back to the code. Remember this nice little bit of code I had here? Why not, let's train it to actually learn a certain threshold. So I'm going to write a function here called train color. And it gets an R, G, and B. And it's going to return black or white. And what I'm going to do now is in setup, this is a little bit silly, before I do anything, I'm just going to say for let i equal zero, i is less than 1,000. i++ and I'm going to pick a different set of random colors that are different from the global random colors. Then I'm going to say the correct answer or the answer, oh shoot. I'm going to say the answer is, what is it, train color. Train color with R, G, B. And you know what I'm going to do? I'm just going to do this, targets. Let's skip a step here. And this, I can't remember which is which. Whoops. Let's just return the targets. Is this right? Somebody in the chat tell me if I've got these backwards or not. Let's just return the targets. I'm kind of skipping some steps here. Now I'm not being as thoughtful about how I'm organizing this. But I want to get those targets. Then I want to say the inputs are R divided by 255 G, G divided by 255 B divided by 255. And this should say inputs. And then I'm going to say brain train inputs with these targets. So this is me just running through and kind of quickly using 1,000 colors to train it. And I'm being told that this is probably backwards. There's no way I could have possibly guessed that correctly. Okay. So let's ‑‑ and actually I'm going to even ‑‑ I'm just going to ‑‑ let's let it run 10,000 times. So I'm going to run 10,000 colors through the network right in setup as like training data basically. Okay. So now let's just ‑‑ and actually in a way what I'm going to do now, just to see, I'm not even going to click. I'm going to not bother to train it anymore. I'm just going to pick ‑‑ let me comment out my own interactive training. And let me just pick new colors. Okay. So every time I click, yeah, you can see it's making guesses. Are they good guesses? I don't know. But I bet you those guesses are pretty accurately aligned with that threshold of 300. So I could continue to train it a little bit. But I feel pretty happy now with this color predictor. Okay. What's going on? I finished this coding challenge. I'm going to release this code. What can you do with it? So a couple things. One is could you make this same exact project, but instead of having it just pick whether black or white goes on top, could you pick a RGB color that looks nice? Maybe it's a ‑‑ maybe you could have a neural network solve the formula for complementary colors. Could you think of a more thoughtful way to design this? Could you use some other data entirely? Could you train based on, like, font, which font to pick? Could you train a system to make design decisions based on some set of training data or some user interaction, something like that? So I hope you make your own neural network design predictor thingy and share it with me. You can go to the CodingTrain.com website. There's some instructions there for how to contribute your version of a project like this. You can write in the comments. You can tweet me at Schiffman. I guess I'm supposed to say you should subscribe to the channel, blah, blah, blah, blah, blah. Thank you for tuning in. And there is the color predictor. Wait, hold on. Stop. Time out. I'm getting a good suggestion in the chat. It might be nice to see, like, what the number is. So hold on. Let's ‑‑ this is a good idea. Let's do this. Hold on, hold on. Time out, everybody. Where do I have ‑‑ I have some console log going on here. Let me get rid of this console log. And let me in here, let's console log R plus G plus B. So let's see if this value is bigger. And I'm just going to floor it so it looks ‑‑ I don't need to see the decimal. Let's see if this ‑‑ let's see if it really learned the threshold of 300. Right? 319. That should be white. So it didn't get that right. Whoops. 376. Ah. 442. 289. Oh, wait. No, no, no. It did get it right. I've got it backwards. If it's higher than 300, it should be over black. If it's lower than 300, it should be over white. And we can see here, right, 289, white, 431, black, 513, black, 561, black, 527. Right? This is working. So let me run it again with a different threshold. Where do I add that? In the training. Let me give it a silly threshold of 100. That's much too low for it to be visually correct, probably, whatever that means. But we can see now it's going to only go to white if it's below 100. Oh, it didn't ‑‑ actually, 97, it didn't even get there. Now, I'm going to have to do this for quite a while to get lucky enough to pick something lower than 100. Boy, it really doesn't want to ‑‑ how long do I have to ‑‑ shouldn't I have like a one out of, I guess, seven or eight chance? My goodness. I'll speed this up again. I'll speed this up. I'll keep going. I can edit this out. Come on, give me something. Oh, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, I'm very unlikely to get a number lower than 100 because I'm picking three random numbers between 0 and 255. So I actually have ‑‑ I'd have to pick three random numbers basically lower than 33, which has a pretty low probability of doing that in a row. So let's do the opposite thing. Let's say, let's do this only if it's greater than 500. 296, white, so if I ever get it greater than 500, black, right? 393 is white. So it is learning that threshold, whatever I kind of, whatever I had. I picked 300. And probably what would make sense for me to pick is just, you know, 256 or 255 times three divided by, yeah, 255 times three divided by two. I really should have stopped this video two or three minutes ago when I had the chance. So we can see now, here's my color predictor. It's trying to predict which text looks better over the color behind the scenes. Now we're finally done. Oh, please, please, creative, wonderful people of the internet, make a more interesting, better version of this, and I will see you in a future coding challenge. Goodbye. Thank you again to Jabril for this particular idea. Subscribe to his channel. Link in this video's description. Yes, hard code the colors. I could have hard coded the colors, yes. Yes. Oh, Tim makes a great suggestion. You should use softmax and set the circle's x position based on the output to visualize the confidence. If it's more confident, put the circle more to the left and vice versa. That is such a great suggestion. More to the left and vice versa. That is such a good idea. Somebody please go do that as their own project. All right, I think I finished for today. It's 12.43. Oh, boy, do I want to try to do that quadtree thing. This is probably going to be like a 45-minute to an hour coding challenge, I would guess. But hopefully there's a lot that can be edited out when it gets to that point. I was getting some messages. Let me see if there's anything super important here. Okay, everything seems good. I'm just checking my email. I'm not checking my email. I'm not checking my email. I got a super chat. Thank you for alerting me. Let me look in my dashboard here. That might be an easier way so I can thank the super chat. Oh, uncreative name. Thank you for your super chat message and your donation. It is much appreciated. Thank you. If you want to support the work that I'm doing, you can subscribe also to the Patreon and join our little Slack community, which is a fun place to discuss and ask questions and that sort of thing. I should work on the p5 pull request. I could do that. I kind of feel like I could do the quadtree. I don't have 45. Let me take a look at the quadtree thing for a second. Just hold your horses. Let's be ambitious here for a second. I really should give myself more time to do other things I need to do today. Is this the this is just the example. So hold on. Quadtree. Let me grab this repo real quick. Oh, oh, right. Quadtree. Why I think I should do this, I don't know. I just kind of wanted that to be done. Do I still need to fix the quadtree bug? What was the bug? I don't know. I don't know. I don't know. How many people got the best four in the party again? Probably not as many people as we would have liked those. They're quite aggressive with their, as many people as we would have liked. So I should probably need to fix the bug, too. I'm going to leave this because we didn't typo. I'm going to leave this because I think it's better toasted less. So, um... Let me do this. Oh, but that's not a real... Okay, so that's not a... I was going to say that's not a real bug. It is a real bug. But it's not a bug that I feel that I need to fix. It is... So let me go to this. I mean, now I'm sort of... Oh, number 98. Where did all the issues go? Oh, that's on CodingTrain website. So let's discuss this for a second. Yeah. So this, I don't... This is a great... Whoa. So this is a really great point. And maybe I should open the video with this. And let me try to explain this. So the quadTree that I made does not continuously pass... And I apologize. If you're tuning in this live stream and you didn't watch the quadTree live stream or the quadTree videos, you probably have no idea what I'm talking about. So I apologize for that. But I suggest you go back and watch those if you're interested. But the quadTree is a data structure that stores......points in, in my case, in two-dimensional space into the leaves of this tree. It's constantly subdividing sections of the canvas into fours. And then if there's too many points there, it subdivides again into fours. If there's too many points there, it subdivides again into fours. And it has a capacity variable like four. I actually used... I mean, that's a coincidence. I could have made it five, could have made it three. QuadTree is dividing into four. But I also have to use that capacity for each leaf as having four. So this looks like this should be a mistake, right? This is a leaf. How could there possibly be more than four? Even if we kind of are generous and say that these are in......these are just drawn in a weird way and they're actually in the other ones, there's still one, two, three, four, five, six. And the reason that this is the case is that a bunch of these are likely actually in this node, this larger space. Because when I subdivide a node into four, I don't take the points that are in that parent node and pass them down. I could do that. And there's a case to be made for that being more correct or more efficient. But in terms of writing the code in a simple way, it's much easier to just not bother with that. And I get enough of a speed improvement without doing that that I don't need to. I didn't bother. I'm not doing this to try to make this perfect visualization. I'm just trying to do this to make looking at the... I'm just doing this to... I'm reading the chat at the same time, which I should never do. I'm doing this to... Why am I doing this? I'm doing this to try to make a collision detection example faster. And I can show you that even with this quote-unquote bug, if I go to my quadtree repo......and I go here, I've actually made this example already just to test if it would even work. I'm going to go to demo. So this is now a p5 sketch, which has 1,000 dots in it. And every dot is checking if it's intersecting another dot. And if it is, it lights up. And it's using the quadtree data structure right now. Let me just uncheck this checkmark. And you can see right now, without the quadtree data structure, I'm getting a frame rate of 5. With the quadtree data structure, I'm getting... And let's just move down and see if we can... Oh, I think it might be... You can see, even with 2,500, I'm getting a pretty decent frame rate. If I take off the quadtree... Forget it. The frame rate is basically one frame per second, even at best. I feel that my code does the job. Does it do it the best way, the most optimal way? I'm not entirely sure. Okay, so hopefully that explained it. Oh, there are flocking examples in the poll requests. Empirist Academy, what is your idea? I missed it. I'm really not following the chat, I should say. I look over here every once in a while. So the question now is, with my 10 minutes, can I create this demonstration? And I think that I can. I did have some other real bugs. I'm sorry. I don't mean to say that... If I'm not thoughtfully... I'm worried that I'm not being kind in my reply to this bug report, because that is an excellent GitHub issue to post, and merits a lot of discussion, and I don't even know if I'm right about this. So that is an appropriate bug report. But in my point of view, I'm wondering if that's a bug, or more of a question of how I want to design the algorithm. And in fact, if you go to the quadtree Wikipedia page, and you look at the pseudocode for the quadtree down here, you will find that the insert function does not redistribute the points. So this example Wikipedia version, pseudocode version of the quadtree algorithm does not redistribute points at the subdivision point. So that's kind of my point of view about that. Alright. So let's see. This is a bad idea. Terrible idea. Terrible idea. But we're going to do it anyway. So what I'm going to do is I'm going to go into examples. I'm going to rebuild this intersection quadtree. No. Copy of it. I'm going to just delete that. I just literally copied a folder, deleted it, and then renamed it. I wanted to save a backup of it, but there's really no point in me doing that. It's so silly what I just did. I remember what I was going to do. What I was doing is, ah, I don't have time to do this. I meant to do this. Take this, put this on the desktop, then go grab this quadtree.js, put that in here, then go and open this on the desktop. Go into Sketch and go into Sketch.js. Go into Sketch and go into index.html and do that. Then I'm going to terminal. No. Then I'm going to say, oh, then I'm going to run a server. That's there. What I'm going to do now, I think what I'll do is I'm going to leave this particle code. I'm going to leave this simple particle code. I'm going to take this out. I'm going to take the highlight thing out. I'll add that. Leave that, and then I'm going to get rid of everything here. Whoa, there's a lot of code I'm going to have to write, apparently. Oh, no, I don't need to show the quadtree stuff. Okay, that's great. Okay. Okay, so I think I'm ready for this. This could be, I think, six minutes left and I gave myself until 1 o'clock. I'm going to give myself until 1.15. If this is not done at 1.15, I really can't do this now. I'm going to try. Against my better judgment, I'm going to try. What I'm going to do here is... Okay. Okay. Hello, and welcome to part three of my quadtree coding challenge. In this coding challenge, what I want to do is I want to see, can this work? Will this work? I have this very, very, very slow sketch that has 1,000 particles. Each particle is checking every other particle where it is in the window. If it is overlapping or intersecting one of them, it's highlighting itself white. If it's not, it's keeping its color to gray. You'll notice this is running at about five frames per second. Can I use a quadtree to reduce the number of cycles, computational cycles, I need to do to check every particle's location against every other particle's location and get this running at 30 frames per second? Let's go. Okay, so I'm actually going to refresh this. There's nothing there now because I had all that code and I deleted it because I'm going to write it now. What I do have already is a particle class. I have a very simple particle. It just has an x, a y, and a size. It's drawn as a circle. Let's do this. Let's say... I'm thinking about this. Let's make an array of particles. I'm going to say 4, let i equal 0, i is less than 1. Let's just start with 100 because I don't want to deal with it running slow until it's time to really implement the quadtree. I'm going to say particles index i is a new particle. I'm going to give the particle a random location on the window. Then I'm going to say 4, let p of particles... I think it's like p.update probably and p.... I don't know what it is. Let's look. Move and render. Who knows what I call these things? Move and render. I'm going to say background 0. Now we can see... there we go. No problem. Look at all my beautiful particles. I'm moving around. We can see, by the way, even with a thousand of them, drawing a thousand particles is no problem. P5, canvas, I can draw a thousand circles any old day of the week. 30 frames per second, whatever nice frame rate. But now, what if I were to say 4... I'm going to do this again. I'm going to separate this out into a separate loop. Let p of particles for let other of particles. I want to now check if p.intersects other, then I want to highlight this particle. p.highlight. This is the idea. I want to do a nested loop. Also, I got to make sure as long as p is not equal to other. p shouldn't check itself. Again, there are plenty of ways to optimize this nested loop. If p is checking other, I don't need other to check p. But that's not the point here. I'm going to let this be as inefficient as possible. Do I have an intersects function? Do I have a highlight function? I don't think so. It would have been nice if I kept those. Let's write an intersects function. intersects other. What do I need to do? I need to know the distance between this.x, this.y, and other.x, other.y. Then I'm going to return distance is less than... They're intersecting if the distance is less than this.r plus other.r. This is going to tell me... Then I'm going to make a variable called highlight. Set that equal to false. I'm going to in render if highlight fill white. Otherwise, fill just this grayish color. That should be this.highlight. Then set highlight. I'm going to say this highlight equals and then value. I'm going to write a function that's like set highlight. That's going to turn highlighting on or off. I could do a better job of this, but this will work. Basically, what I want to do is... First, I want to set the highlight false for all the particles. They're all not highlighted. Then when I'm doing the check, if it actually is intersecting, I can set the highlight to true. Now, let's go back to just 100 particles. We can see. Perfect. When they're... Okay. Now, the distance... Oh, you know what? I'm not drawing them. I'm drawing them with the radius as the diameter. They're actually half the size. I should fix that in my render function. I'm not being consistent. This should really be radius times 2 if I'm using r as a radius for the math. Now we can see, right? When they are overlapping, they're highlighted white. When they're not overlapping, they're not. Okay. This is working fine. I can actually... Let me look here in the... Oh, there's like a... Oh, I got to deal with that for a second. Hold on. I have a little extra bit of code in there by accident. I can look at the frame rate. No problem. 27 frames per second. Let me just ignore what I'm doing for a second in my quadtree code. I was adding some unit tests and stuff. I'm going to just get rid of that. Okay. We can see here, look at the frame rate. 26 frames per second. Now, let's see that if I go back to my sketch and I add 1,000 particles... Let's look at the frame rate now. 5 frames per second. Also, now that I have so many, I probably want them not to be as big. Because... Let's actually make them half the size. And now, frame rate is still 5 frames per second. Okay! We're here for the quadtree, right? Let's add the quadtree. The thing is, what do I need to do? Right here, this is what I need to replace. I still want to go through every particle. But now, instead of looking at every, every, every, every particle, I want to just query. I'm going to say, let others equal... Oh, wait! I have to create a quadtree! So, first I need a quadtree variable. Quadtree. Then I'm going to say, quadtree is a new quadtree. I did that coding challenge so long ago, I've forgotten what I need. I think I need a boundary. So, I'm going to say, a boundary is a new rectangle. My quadtree example has some geometry classes, like a rectangle. And the rectangle, I'm going to make it 300, 200. That's the center. And it's 600, 400. So, I probably should use width divided by 2, height divided by 2, width, height. But, that's fine. I'm just going to leave that. So, I'm going to make a new quadtree with that boundary. Then, what I'm going to do... And I think this got added after... So, one of the things that actually... I can't believe I forgot about this. But, these things are moving. So, if I build the quadtree with all of those particles, as soon as they move... Oh my god, I'm missing so many pieces here. Ah, there's more to this video than I thought. Alright, hold on. Here we go. This is going to be good. I knew there was something going on here. Okay. So, what does this quadtree expect? The quadtree, if I look at it, it expects me to insert a point. A point is a particular object with an x and a y. Oh, look. I already added this. So, if you follow the last tutorial, this won't be there. Let's take this out. So, here's the idea. Let's watch and learn. Okay, here we go. This is where I left off in the last tutorial. Oh, I forgot about this. Now, I'm going to go back to my code. Save this. And I'm going to say... Okay. What I want to do is I want to build this quadtree. So, what I'm going to do is I'm going to say... I'm going to say... Right? This is where I last left off. I'm creating a point object and putting the point object in the quadtree. The quadtree is going to organize itself to keep points together that need to be together. But here's the thing. I've now made this new point object. I want to put the particle in the quadtree. So, really, I want my quadtree to store the particles. And then the particles are moving. So, I've got to update their location in the quadtree. How am I going to deal with this? Well, there are a variety of solutions to this. Number one, I wrote the quadtree code so I could just rewrite it to work with my particle object instead of the point object. But something I could do to make it more generic is I could add... This box2d works this way and some physics libraries do. I could add a property to the point object called userData. And what that means is when I create a point object, the core data that I need for the quadtree is its x, y location. But I could also say attach yourself to this other object so that when I find this x, y location, I can know that it's attached to this particular particle. So, in other words, what I can do now is I can say make a new point with this particle's x and y referencing also this particle. Again, there's some redundancy here, but this will work well enough. It's also very generic. So, if somebody else is using this quadtree as a library, they could kind of use it with whatever classes they've created. But here's the thing. This created that quadtree, but as soon as I go, all the points move. They're going to be in a different location. They're not where they originally were. So, actually, I don't want to do this here. What I want to do is do this here in draw. The nice thing about this is I have the particle and a variable called p. So, I want to create a new point. Whoops, what is going on here? Give me back my code. Give me back my code! Okay, I want to create a new point at an x and y with a p, and I want to insert it into the quadtree. But draw is looping over and over again. So, when I insert the first time, the next time I don't want to reinsert. I just want to update its location. Well, the truth of the matter is while that would be a nice way of doing it, updating the locations and probably most efficient, it actually is a little bit simpler if I just remake the quadtree every frame. The quadtree is a thing that I'm just going to recreate every frame for the purpose of optimizing the collision detection. So, again, I could be more thoughtful about this and have a global quadtree. I think there's even maybe a clear function by now in that quadtree class that I wrote. But I'm just going to remake the quadtree object every frame, build it from scratch. Build it from scratch every time through draw. Okay, so now I've inserted all of the points of the quadtree. Let's just run this to make sure it's still working. Oh, syntax error. Sketch.js line 29. Oh, I forgot that I was doing something down here. Okay, another error. Quadtree 90 capacity should be a number but is undefined. Ah, I forgot about the capacity. So the quadtree, each node of the quadtree has a limit to how many particles can go in it. Let's just use four. That's what I've been using. We might get better or worse results depending on that number. So let's... Let me give myself some more space here with all this. Okay, so we can see that this is working but running slow. So while I've got the quad... I'm building the quadtree, I haven't lost... Even though there's computation involved in building the quadtree, I have to rebuild it every frame, there's so much less involved in doing that than checking all the locations. And now, here's the thing that I want to do. Let me just shut this off so that I don't kill my computer. What I want to do now is here, I started here. Instead of looking at every other particle in the whole particles array list, I want to query. I want to say, I'm going to say let others equals qt.query. Now what do I want to query? I think query is the name of the function. Query, query, class query, query, query, query, query, query, query, query, range and found. But I don't have to worry about found. Remember when I wrote that, found is the array that's being recursively added to. But I want to query a range. And the range could be a rectangular range or a circular range. And actually, I have this, this has been added since the last tutorial, but this geometry object for a circle. I'm going to use a circular range. Why? I have to erase the whiteboard. Shoot. I think that color predictor thing was done. So as long as I just erase this really quickly. I can finish this by 1.15. I'll have this video out next week sometime. Okay. If I have a particle, n has a given r. And my other particle has a given r. I only need to look at particles within what? A range that is r, I drew this kind of bigger, r times 2. Right, because particles are intersecting only if they're within r times 2 of this particle. Now if the particles were different sizes, we'd have a more complicated problem. And I encourage you to implement that as your own exercise. But because my particles are the same sizes, I've got a pretty easy scenario here. So what I can do is I can in sketch, I can say... Okay, so first make a circle. It's a new circle object where it should be at p.x, p.y. And its size is p.r times 2. This is the range. I want to check for any other particles within the range. The distance of this particle's radius times 2. I want to query that circle. Let's call this range. I want to query this range. Then others is now a smaller amount. This is all, I just need an other of others. So I'm no longer checking the full particles list. I'm querying the quadtree for a smaller subset of particles for me to check intersection. And now I think we might be done. I don't know, I don't know, I don't know. Look at this. Remember this? Let's let this run again. This is it running before, really slow. Five frames per second. I'm going to hit refresh. I hope I don't have any errors. Okay. Oh, that looks good. It's running fast, but it's not highlighting. So what happened there? p does not equal other and p intersects other. Okay, hold on. I have a bad feeling that... Oh, the particle! Thank you. I forgot. So that's the thing. Right, right, right, right, right. So this is the whole thing. These are points. I called them others, but let's call them points. I'm getting the points. For every other of points, for every point of points, other equals point dot user data. I need to actually look at that object. Remember, the particle, which is the thing that works with intersects and set highlight and all of that, this quadtree is giving me an array of points, and as I look at each point, I need to pull out the user data. Okay. I can't bring myself to use that drummer. There we go! So now... Whoops, frame rate. Look at that! 48 frames per second! It was 5 frames per second. Now it's 48 frames per second. So there's issues with this. I've really set myself up for success here. These particles have a really nice, even, uniform distribution across the entire canvas. They're all the same size. There's only a thousand of them. I'm not actually having them bounce off each other or any kind of complex collision resolution, but this is the basic idea. What you can see is that with a quadtree, if I just quickly... All I have to do now to switch them on and off is to say... Let me comment this out. If I say, for other... Let other of particles... This is... So now, no quadtree. I'm just looking at every other particle. Super slow, super slow. Frame rate of about 5. And now, switch to using the quadtree. Super fast! So, goodbye everyone! Thanks for watching this tutorial. I encourage you to try to make a version of this where the particles... Somebody already has done this, a pull request on my quadtree repo. A version of this with the flocking simulation. How is that going to work? What if the particles aren't so evenly distributed? How could you do it with different sizes? Could you visualize the quadtree? So, draw the quadtree dynamically as it's changing and updating. That might be a beautiful thing to create. Make your own quadtree visualizations. I hope you do all those things. Share them with me. And I will see you in a future coding challenge or something or other video. I think, I don't know, that kind of stuff. Goodbye! Oh yeah, I could have done map. Okay, okay, map. I could have done map. Alright. Grant asks, Is there a forum or group where people discuss p5.js? Yes, forum.processing.org. Isn't there a way to share the code real time? Typically what I do is try to upload this stuff to GitHub right afterwards. This code is already on GitHub because it's part of the quadtree repo. And, is it possible to use quadtrees with k-means clustering? Probably, that would be an interesting thing. Anyway, I've really got to run because I'm going to be back in an hour and 15 minutes. It will be, if I go to coding train, is it here? Where do I find it? There's an event. Let me just go to Twitter. Twitter, noopecat, noopcat. Here is the link. Live in 74 minutes! There will be a guest tutorial here about hardware and JavaScript. So I'm going to run. I'm going to grab something to eat. I will be back in an hour or so. Noopcat and I will be here for a couple hours doing her guest tutorial. And that will then be the end. Edited versions of all these challenges and stuff will come out next week. Yeah, alright. So thanks everybody for watching. And I will see you, I'll see you if you're going to tune in. I'll see you in like an hour. Okay, goodbye!",
    "translation": null
  },
  "error": null,
  "status": "succeeded",
  "created_at": "2023-09-26T21:03:53.367236Z",
  "started_at": "2023-09-26T21:20:31.08203Z",
  "completed_at": "2023-09-26T21:43:29.630268Z",
  "webhook": "https://83ceaa0b612c.ngrok.app/?video_id=w1Np5meK4_Q",
  "webhook_events_filter": [
    "completed"
  ],
  "metrics": {
    "predict_time": 1378.548238
  },
  "urls": {
    "cancel": "https://api.replicate.com/v1/predictions/a7adopjbzdnrskl6vwab7sbb4u/cancel",
    "get": "https://api.replicate.com/v1/predictions/a7adopjbzdnrskl6vwab7sbb4u"
  }
}