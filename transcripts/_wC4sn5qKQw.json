{
  "id": "o6xmpibbmg7gkr2nu3ejppzqj4",
  "version": "91ee9c0c3df30478510ff8c8a3a545add1ad0259ad3a9f78fba57fbc05ee64f7",
  "input": {
    "audio": "https://upcdn.io/FW25b4F/raw/coding-train/_wC4sn5qKQw.m4a"
  },
  "logs": "Transcribe with large-v2 model\nDetected language: English\n  0%|          | 0/826135 [00:00<?, ?frames/s]\n  0%|          | 2650/826135 [00:46<4:03:09, 56.44frames/s]\n  1%|          | 5626/826135 [00:52<1:49:29, 124.89frames/s]\n  1%|          | 8578/826135 [00:58<1:10:52, 192.24frames/s]\n  1%|▏         | 11202/826135 [01:04<55:20, 245.43frames/s] \n  2%|▏         | 13982/826135 [01:09<43:29, 311.26frames/s]\n  2%|▏         | 16758/826135 [01:12<35:11, 383.39frames/s]\n  2%|▏         | 19600/826135 [01:18<32:07, 418.48frames/s]\n  3%|▎         | 22312/826135 [01:22<28:20, 472.62frames/s]\n  3%|▎         | 25196/826135 [01:27<25:45, 518.12frames/s]\n  3%|▎         | 28024/826135 [01:31<24:45, 537.11frames/s]\n  4%|▎         | 30732/826135 [01:36<24:06, 549.77frames/s]\n  4%|▍         | 33600/826135 [01:42<24:38, 536.12frames/s]\n  4%|▍         | 36488/826135 [01:47<24:05, 546.40frames/s]\n  5%|▍         | 39348/826135 [01:52<24:23, 537.67frames/s]\n  5%|▌         | 42348/826135 [01:57<23:28, 556.54frames/s]\n  5%|▌         | 45028/826135 [02:01<22:34, 576.62frames/s]\n  6%|▌         | 47614/826135 [02:05<20:53, 620.90frames/s]\n  6%|▌         | 50458/826135 [02:09<20:25, 633.06frames/s]\n  6%|▋         | 53226/826135 [02:15<22:25, 574.47frames/s]\n  7%|▋         | 55634/826135 [02:20<23:24, 548.42frames/s]\n  7%|▋         | 58194/826135 [02:23<21:26, 597.04frames/s]\n  7%|▋         | 61188/826135 [02:28<21:09, 602.66frames/s]\n  8%|▊         | 63776/826135 [02:33<22:01, 576.72frames/s]\n  8%|▊         | 66776/826135 [02:37<20:01, 632.12frames/s]\n  8%|▊         | 69688/826135 [02:42<20:41, 609.33frames/s]\n  9%|▉         | 72604/826135 [02:47<21:21, 587.85frames/s]\n  9%|▉         | 75466/826135 [02:53<22:24, 558.33frames/s]\n  9%|▉         | 78322/826135 [03:00<25:07, 495.91frames/s]\n 10%|▉         | 81290/826135 [03:06<23:57, 518.26frames/s]\n 10%|█         | 84290/826135 [03:13<25:55, 476.85frames/s]\n 11%|█         | 86888/826135 [03:19<26:45, 460.37frames/s]\n 11%|█         | 89888/826135 [03:24<24:35, 499.07frames/s]\n 11%|█         | 92676/826135 [03:29<23:32, 519.23frames/s]\n 12%|█▏        | 95668/826135 [03:35<23:26, 519.51frames/s]\n 12%|█▏        | 98642/826135 [03:42<24:47, 488.94frames/s]\n 12%|█▏        | 101592/826135 [03:47<24:35, 491.07frames/s]\n 13%|█▎        | 104512/826135 [03:55<26:17, 457.52frames/s]\n 13%|█▎        | 107512/826135 [04:01<25:07, 476.68frames/s]\n 13%|█▎        | 110248/826135 [04:07<26:00, 458.79frames/s]\n 14%|█▎        | 113240/826135 [04:11<23:18, 509.90frames/s]\n 14%|█▍        | 116148/826135 [04:19<25:11, 469.63frames/s]\n 14%|█▍        | 119148/826135 [04:23<22:45, 517.69frames/s]\n 15%|█▍        | 122148/826135 [04:30<23:31, 498.68frames/s]\n 15%|█▌        | 125148/826135 [04:33<20:35, 567.16frames/s]\n 16%|█▌        | 128090/826135 [04:37<18:06, 642.23frames/s]\n 16%|█▌        | 131090/826135 [04:40<16:05, 719.72frames/s]\n 16%|█▌        | 134090/826135 [04:43<15:03, 766.27frames/s]\n 17%|█▋        | 136644/826135 [04:46<14:48, 776.30frames/s]\n 17%|█▋        | 139644/826135 [04:50<14:23, 794.56frames/s]\n 17%|█▋        | 142644/826135 [04:53<14:20, 793.89frames/s]\n 18%|█▊        | 145644/826135 [04:59<15:53, 713.70frames/s]\n 18%|█▊        | 148644/826135 [05:02<14:44, 765.99frames/s]\n 18%|█▊        | 151340/826135 [05:04<13:11, 852.46frames/s]\n 19%|█▊        | 153190/826135 [05:08<15:34, 720.10frames/s]\n 19%|█▉        | 156130/826135 [05:12<15:46, 708.00frames/s]\n 19%|█▉        | 159130/826135 [05:16<14:19, 776.26frames/s]\n 20%|█▉        | 161734/826135 [05:19<14:48, 748.14frames/s]\n 20%|█▉        | 164734/826135 [05:24<15:19, 719.01frames/s]\n 20%|██        | 167558/826135 [05:28<15:12, 721.99frames/s]\n 21%|██        | 170370/826135 [05:32<15:32, 702.87frames/s]\n 21%|██        | 173370/826135 [05:36<14:42, 739.49frames/s]\n 21%|██▏       | 176222/826135 [05:38<13:26, 805.66frames/s]\n 22%|██▏       | 179222/826135 [05:43<14:47, 728.91frames/s]\n 22%|██▏       | 181506/826135 [05:48<16:27, 652.47frames/s]\n 22%|██▏       | 184386/826135 [05:51<14:44, 725.83frames/s]\n 23%|██▎       | 187258/826135 [05:55<15:20, 694.33frames/s]\n 23%|██▎       | 190118/826135 [06:01<17:21, 610.82frames/s]\n 23%|██▎       | 192990/826135 [06:08<18:54, 558.30frames/s]\n 24%|██▎       | 195822/826135 [06:16<22:11, 473.45frames/s]\n 24%|██▍       | 198778/826135 [06:24<24:25, 427.97frames/s]\n 24%|██▍       | 201738/826135 [06:31<24:35, 423.07frames/s]\n 25%|██▍       | 204434/826135 [06:38<24:43, 419.01frames/s]\n 25%|██▌       | 207040/826135 [06:44<24:06, 428.14frames/s]\n 25%|██▌       | 209680/826135 [06:48<22:25, 458.01frames/s]\n 26%|██▌       | 212476/826135 [06:52<19:51, 514.87frames/s]\n 26%|██▌       | 215300/826135 [06:57<18:26, 552.02frames/s]\n 26%|██▋       | 217976/826135 [07:02<18:46, 539.79frames/s]\n 27%|██▋       | 220976/826135 [07:07<17:50, 565.29frames/s]\n 27%|██▋       | 223942/826135 [07:13<18:57, 529.42frames/s]\n 27%|██▋       | 226942/826135 [07:15<14:48, 674.31frames/s]\n 28%|██▊       | 229942/826135 [07:19<14:26, 687.93frames/s]\n 28%|██▊       | 232802/826135 [07:23<14:08, 699.15frames/s]\n 28%|██▊       | 235434/826135 [07:26<13:36, 723.41frames/s]\n 29%|██▉       | 238314/826135 [07:32<15:06, 648.21frames/s]\n 29%|██▉       | 241094/826135 [07:38<17:22, 561.35frames/s]\n 30%|██▉       | 243806/826135 [07:43<17:24, 557.55frames/s]\n 30%|██▉       | 246630/826135 [07:48<17:03, 566.40frames/s]\n 30%|███       | 249630/826135 [07:52<15:52, 605.20frames/s]\n 31%|███       | 252366/826135 [07:55<13:59, 683.77frames/s]\n 31%|███       | 255322/826135 [08:00<14:42, 646.64frames/s]\n 31%|███▏      | 258316/826135 [08:05<15:18, 618.40frames/s]\n 32%|███▏      | 261208/826135 [08:12<17:10, 548.21frames/s]\n 32%|███▏      | 264208/826135 [08:17<16:15, 576.27frames/s]\n 32%|███▏      | 267208/826135 [08:23<17:37, 528.61frames/s]\n 33%|███▎      | 270160/826135 [08:27<15:59, 579.20frames/s]\n 33%|███▎      | 273160/826135 [08:34<17:06, 538.50frames/s]\n 33%|███▎      | 276128/826135 [08:37<15:02, 609.30frames/s]\n 34%|███▍      | 279128/826135 [08:43<15:55, 572.46frames/s]\n 34%|███▍      | 282128/826135 [08:47<14:51, 610.55frames/s]\n 35%|███▍      | 285128/826135 [08:51<13:37, 661.41frames/s]\n 35%|███▍      | 288100/826135 [08:56<14:12, 630.96frames/s]\n 35%|███▌      | 290936/826135 [09:02<15:52, 562.03frames/s]\n 36%|███▌      | 293464/826135 [09:07<16:17, 544.77frames/s]\n 36%|███▌      | 296130/826135 [09:12<16:14, 543.64frames/s]\n 36%|███▌      | 299018/826135 [09:18<16:25, 534.70frames/s]\n 37%|███▋      | 301622/826135 [09:24<17:40, 494.69frames/s]\n 37%|███▋      | 304554/826135 [09:30<17:41, 491.35frames/s]\n 37%|███▋      | 307286/826135 [09:34<15:38, 553.13frames/s]\n 38%|███▊      | 310286/826135 [09:40<16:11, 531.14frames/s]\n 38%|███▊      | 313254/826135 [09:46<16:10, 528.28frames/s]\n 38%|███▊      | 315750/826135 [09:48<14:23, 590.92frames/s]\n 39%|███▊      | 318538/826135 [09:53<14:24, 587.13frames/s]\n 39%|███▉      | 321538/826135 [09:58<13:42, 613.59frames/s]\n 39%|███▉      | 324522/826135 [10:02<13:03, 640.14frames/s]\n 40%|███▉      | 327222/826135 [10:08<14:37, 568.27frames/s]\n 40%|███▉      | 330214/826135 [10:14<14:48, 558.03frames/s]\n 40%|████      | 333150/826135 [10:20<15:31, 529.40frames/s]\n 41%|████      | 336022/826135 [10:26<15:57, 511.88frames/s]\n 41%|████      | 339022/826135 [10:29<13:38, 595.33frames/s]\n 41%|████▏     | 341918/826135 [10:33<12:38, 638.28frames/s]\n 42%|████▏     | 344846/826135 [10:38<12:41, 632.14frames/s]\n 42%|████▏     | 347646/826135 [10:43<13:29, 591.16frames/s]\n 42%|████▏     | 350438/826135 [10:49<14:04, 563.49frames/s]\n 43%|████▎     | 353438/826135 [10:53<13:41, 575.66frames/s]\n 43%|████▎     | 356438/826135 [11:04<17:42, 442.14frames/s]\n 44%|████▎     | 359438/826135 [11:09<16:14, 478.91frames/s]\n 44%|████▍     | 362438/826135 [11:13<14:22, 537.72frames/s]\n 44%|████▍     | 365438/826135 [11:16<12:00, 639.42frames/s]\n 45%|████▍     | 368430/826135 [11:19<11:01, 692.00frames/s]\n 45%|████▍     | 371210/826135 [11:24<11:59, 631.98frames/s]\n 45%|████▌     | 374098/826135 [11:30<12:45, 590.20frames/s]\n 46%|████▌     | 377082/826135 [11:35<12:34, 594.96frames/s]\n 46%|████▌     | 380082/826135 [11:41<13:20, 557.45frames/s]\n 46%|████▋     | 382826/826135 [11:47<13:50, 533.60frames/s]\n 47%|████▋     | 385814/826135 [11:53<13:50, 530.04frames/s]\n 47%|████▋     | 388702/826135 [11:57<13:03, 558.65frames/s]\n 47%|████▋     | 391462/826135 [12:03<14:04, 514.69frames/s]\n 48%|████▊     | 394286/826135 [12:10<14:26, 498.12frames/s]\n 48%|████▊     | 397230/826135 [12:16<14:33, 491.13frames/s]\n 48%|████▊     | 400218/826135 [12:21<14:06, 503.12frames/s]\n 49%|████▉     | 403218/826135 [12:26<13:07, 536.91frames/s]\n 49%|████▉     | 406138/826135 [12:31<12:18, 568.90frames/s]\n 50%|████▉     | 409138/826135 [12:36<12:34, 552.94frames/s]\n 50%|████▉     | 411726/826135 [12:41<12:20, 560.00frames/s]\n 50%|█████     | 414326/826135 [12:45<12:03, 569.02frames/s]\n 50%|█████     | 416744/826135 [12:49<12:04, 565.18frames/s]\n 51%|█████     | 419672/826135 [12:54<11:24, 594.13frames/s]\n 51%|█████     | 422424/826135 [12:59<11:42, 574.99frames/s]\n 51%|█████▏    | 425424/826135 [13:05<11:56, 558.96frames/s]\n 52%|█████▏    | 428356/826135 [13:10<11:49, 560.80frames/s]\n 52%|█████▏    | 431256/826135 [13:14<11:16, 584.10frames/s]\n 53%|█████▎    | 434256/826135 [13:19<10:59, 594.15frames/s]\n 53%|█████▎    | 437142/826135 [13:23<10:06, 641.23frames/s]\n 53%|█████▎    | 439942/826135 [13:28<10:37, 605.59frames/s]\n 54%|█████▎    | 442942/826135 [13:32<10:05, 633.26frames/s]\n 54%|█████▍    | 445902/826135 [13:38<10:38, 595.23frames/s]\n 54%|█████▍    | 448810/826135 [13:44<11:05, 567.22frames/s]\n 55%|█████▍    | 451810/826135 [13:48<10:13, 610.38frames/s]\n 55%|█████▌    | 454810/826135 [13:52<09:35, 644.96frames/s]\n 55%|█████▌    | 457730/826135 [13:58<10:34, 580.90frames/s]\n 56%|█████▌    | 460522/826135 [14:04<11:20, 536.90frames/s]\n 56%|█████▌    | 463486/826135 [14:09<10:46, 560.54frames/s]\n 56%|█████▋    | 466486/826135 [14:14<10:46, 556.69frames/s]\n 57%|█████▋    | 469374/826135 [14:18<09:55, 598.82frames/s]\n 57%|█████▋    | 472222/826135 [14:25<10:48, 545.87frames/s]\n 57%|█████▋    | 474982/826135 [14:29<10:19, 566.51frames/s]\n 58%|█████▊    | 477982/826135 [14:34<10:10, 570.58frames/s]\n 58%|█████▊    | 480954/826135 [14:39<09:55, 580.13frames/s]\n 59%|█████▊    | 483954/826135 [14:42<08:41, 656.11frames/s]\n 59%|█████▉    | 486914/826135 [14:48<08:59, 628.89frames/s]\n 59%|█████▉    | 489914/826135 [14:53<09:20, 599.85frames/s]\n 60%|█████▉    | 492822/826135 [14:58<09:11, 604.52frames/s]\n 60%|█████▉    | 494478/826135 [15:01<09:28, 583.49frames/s]\n 60%|██████    | 497330/826135 [15:05<08:48, 622.43frames/s]\n 61%|██████    | 500206/826135 [15:11<09:34, 567.33frames/s]\n 61%|██████    | 501830/826135 [15:15<10:11, 530.30frames/s]\n 61%|██████    | 504830/826135 [15:18<08:22, 639.30frames/s]\n 61%|██████▏   | 507830/826135 [15:21<07:19, 724.17frames/s]\n 62%|██████▏   | 510830/826135 [15:23<05:59, 877.12frames/s]\n 62%|██████▏   | 513830/826135 [15:24<04:48, 1081.82frames/s]\n 63%|██████▎   | 516554/826135 [15:28<05:28, 941.78frames/s] \n 63%|██████▎   | 519502/826135 [15:32<05:43, 892.43frames/s]\n 63%|██████▎   | 522502/826135 [15:34<05:09, 980.83frames/s]\n 64%|██████▎   | 525502/826135 [15:36<04:33, 1101.13frames/s]\n 64%|██████▍   | 528142/826135 [15:40<05:11, 955.89frames/s] \n 64%|██████▍   | 530366/826135 [15:44<06:15, 786.75frames/s]\n 65%|██████▍   | 533006/826135 [15:48<06:33, 745.14frames/s]\n 65%|██████▍   | 536006/826135 [15:51<05:55, 816.30frames/s]\n 65%|██████▌   | 538438/826135 [15:54<06:04, 788.98frames/s]\n 65%|██████▌   | 538438/826135 [16:10<06:04, 788.98frames/s]\n 66%|██████▌   | 541400/826135 [16:34<24:22, 194.68frames/s]\n 66%|██████▌   | 544198/826135 [16:41<20:28, 229.43frames/s]\n 66%|██████▌   | 547148/826135 [16:46<16:22, 283.92frames/s]\n 67%|██████▋   | 549990/826135 [16:51<13:52, 331.60frames/s]\n 67%|██████▋   | 552596/826135 [16:56<12:14, 372.33frames/s]\n 67%|██████▋   | 555550/826135 [17:00<10:14, 440.16frames/s]\n 68%|██████▊   | 558304/826135 [17:06<09:59, 446.48frames/s]\n 68%|██████▊   | 561304/826135 [17:08<07:39, 576.48frames/s]\n 68%|██████▊   | 564304/826135 [17:10<06:17, 693.69frames/s]\n 69%|██████▊   | 567304/826135 [17:12<05:03, 854.14frames/s]\n 69%|██████▉   | 570304/826135 [17:13<04:01, 1057.91frames/s]\n 69%|██████▉   | 573304/826135 [17:17<04:36, 915.95frames/s] \n 70%|██████▉   | 576304/826135 [17:20<04:11, 993.94frames/s]\n 70%|███████   | 578348/826135 [17:22<04:02, 1022.03frames/s]\n 70%|███████   | 580552/826135 [17:23<03:40, 1113.46frames/s]\n 71%|███████   | 583552/826135 [17:26<03:32, 1143.78frames/s]\n 71%|███████   | 586552/826135 [17:29<03:51, 1034.74frames/s]\n 71%|███████▏  | 589552/826135 [17:31<03:21, 1175.01frames/s]\n 72%|███████▏  | 592552/826135 [17:32<02:42, 1435.71frames/s]\n 72%|███████▏  | 595552/826135 [17:34<02:37, 1462.41frames/s]\n 72%|███████▏  | 598552/826135 [17:36<02:43, 1389.25frames/s]\n 73%|███████▎  | 601492/826135 [17:40<03:18, 1129.49frames/s]\n 73%|███████▎  | 604492/826135 [17:46<04:21, 847.60frames/s] \n 74%|███████▎  | 607492/826135 [17:48<03:43, 979.81frames/s]\n 74%|███████▍  | 610492/826135 [17:49<03:04, 1171.51frames/s]\n 74%|███████▍  | 613492/826135 [17:52<03:12, 1105.01frames/s]\n 75%|███████▍  | 616168/826135 [17:54<02:58, 1175.74frames/s]\n 75%|███████▍  | 618976/826135 [18:01<04:30, 765.55frames/s] \n 75%|███████▌  | 621976/826135 [18:03<03:54, 869.37frames/s]\n 75%|███████▌  | 622320/826135 [18:04<04:10, 814.41frames/s]\n 76%|███████▌  | 625320/826135 [18:05<03:03, 1091.56frames/s]\n 76%|███████▌  | 628176/826135 [18:10<03:44, 882.17frames/s] \n 76%|███████▋  | 630912/826135 [18:16<04:54, 663.97frames/s]\n 77%|███████▋  | 633876/826135 [18:22<05:24, 592.47frames/s]\n 77%|███████▋  | 636868/826135 [18:29<05:56, 530.45frames/s]\n 77%|███████▋  | 639868/826135 [18:33<05:22, 577.22frames/s]\n 78%|███████▊  | 642624/826135 [18:39<05:44, 532.17frames/s]\n 78%|███████▊  | 645428/826135 [18:44<05:19, 566.44frames/s]\n 78%|███████▊  | 648304/826135 [18:49<05:22, 551.03frames/s]\n 79%|███████▉  | 651160/826135 [18:55<05:25, 538.14frames/s]\n 79%|███████▉  | 653920/826135 [19:02<05:55, 484.11frames/s]\n 80%|███████▉  | 656784/826135 [19:06<05:20, 528.71frames/s]\n 80%|███████▉  | 659784/826135 [19:12<05:25, 510.64frames/s]\n 80%|████████  | 662784/826135 [19:16<04:43, 576.57frames/s]\n 81%|████████  | 665048/826135 [19:20<04:33, 589.25frames/s]\n 81%|████████  | 667940/826135 [19:23<03:56, 669.26frames/s]\n 81%|████████  | 670828/826135 [19:28<04:13, 612.99frames/s]\n 82%|████████▏ | 673332/826135 [19:32<03:58, 641.66frames/s]\n 82%|████████▏ | 676332/826135 [19:36<03:41, 676.05frames/s]\n 82%|████████▏ | 679212/826135 [19:38<03:14, 757.15frames/s]\n 83%|████████▎ | 681976/826135 [19:40<02:36, 922.44frames/s]\n 83%|████████▎ | 684976/826135 [19:43<02:28, 953.63frames/s]\n 83%|████████▎ | 687976/826135 [19:46<02:24, 957.80frames/s]\n 84%|████████▎ | 690976/826135 [19:48<02:06, 1070.57frames/s]\n 84%|████████▍ | 693976/826135 [19:50<01:52, 1174.50frames/s]\n 84%|████████▍ | 696976/826135 [19:53<01:57, 1101.33frames/s]\n 85%|████████▍ | 699976/826135 [19:56<01:57, 1071.71frames/s]\n 85%|████████▌ | 702976/826135 [19:57<01:37, 1269.39frames/s]\n 85%|████████▌ | 705976/826135 [20:00<01:44, 1153.92frames/s]\n 86%|████████▌ | 708976/826135 [20:06<02:11, 890.24frames/s] \n 86%|████████▌ | 711900/826135 [20:09<02:14, 850.11frames/s]\n 87%|████████▋ | 714900/826135 [20:11<01:46, 1045.95frames/s]\n 87%|████████▋ | 717704/826135 [20:15<02:01, 893.25frames/s] \n 87%|████████▋ | 720516/826135 [20:20<02:18, 762.25frames/s]\n 88%|████████▊ | 723416/826135 [20:26<02:39, 644.42frames/s]\n 88%|████████▊ | 726236/826135 [20:32<02:53, 575.70frames/s]\n 88%|████████▊ | 729236/826135 [20:37<02:44, 588.04frames/s]\n 89%|████████▊ | 732236/826135 [20:42<02:37, 597.56frames/s]\n 89%|████████▉ | 735080/826135 [20:48<02:46, 545.71frames/s]\n 89%|████████▉ | 737868/826135 [20:54<02:49, 519.68frames/s]\n 90%|████████▉ | 740608/826135 [20:58<02:26, 584.96frames/s]\n 90%|████████▉ | 743368/826135 [21:04<02:35, 532.71frames/s]\n 90%|█████████ | 746296/826135 [21:10<02:32, 522.44frames/s]\n 91%|█████████ | 748868/826135 [21:15<02:34, 499.67frames/s]\n 91%|█████████ | 751440/826135 [21:19<02:14, 554.22frames/s]\n 91%|█████████▏| 754300/826135 [21:23<02:03, 581.36frames/s]\n 92%|█████████▏| 757244/826135 [21:30<02:12, 518.87frames/s]\n 92%|█████████▏| 760066/826135 [21:33<01:51, 592.72frames/s]\n 92%|█████████▏| 763054/826135 [21:41<02:00, 522.14frames/s]\n 93%|█████████▎| 765934/826135 [21:45<01:47, 561.70frames/s]\n 93%|█████████▎| 768758/826135 [21:48<01:33, 612.39frames/s]\n 93%|█████████▎| 771704/826135 [21:52<01:23, 649.31frames/s]\n 94%|█████████▍| 774528/826135 [21:59<01:31, 562.49frames/s]\n 94%|█████████▍| 777528/826135 [22:04<01:26, 562.17frames/s]\n 94%|█████████▍| 780528/826135 [22:07<01:09, 656.03frames/s]\n 95%|█████████▍| 783528/826135 [22:18<01:30, 468.27frames/s]\n 95%|█████████▌| 785864/826135 [22:20<01:12, 557.10frames/s]\n 95%|█████████▌| 788616/826135 [22:22<00:58, 638.68frames/s]\n 96%|█████████▌| 791468/826135 [22:27<00:56, 618.06frames/s]\n 96%|█████████▌| 794468/826135 [22:32<00:49, 634.17frames/s]\n 97%|█████████▋| 797468/826135 [22:34<00:38, 740.88frames/s]\n 97%|█████████▋| 800356/826135 [22:39<00:36, 706.03frames/s]\n 97%|█████████▋| 803320/826135 [22:45<00:35, 634.97frames/s]\n 98%|█████████▊| 806068/826135 [22:51<00:36, 552.72frames/s]\n 98%|█████████▊| 808910/826135 [22:55<00:28, 603.14frames/s]\n 98%|█████████▊| 811908/826135 [23:02<00:26, 543.66frames/s]\n 99%|█████████▊| 814828/826135 [23:10<00:23, 476.68frames/s]\n 99%|█████████▉| 817744/826135 [23:18<00:19, 431.98frames/s]\n 99%|█████████▉| 820712/826135 [23:24<00:12, 435.88frames/s]\n100%|█████████▉| 823712/826135 [23:31<00:05, 434.12frames/s]\n100%|█████████▉| 826112/826135 [23:39<00:00, 397.17frames/s]\n100%|██████████| 826135/826135 [23:40<00:00, 581.69frames/s]\n",
  "output": {
    "detected_language": "english",
    "segments": [
      {
        "avg_logprob": -1.4866221567218223,
        "compression_ratio": 1.6145251396648044,
        "end": 0,
        "id": 0,
        "no_speech_prob": 0.02126356028020382,
        "seek": 0,
        "start": 0,
        "temperature": 1,
        "text": "",
        "tokens": [],
        "words": []
      },
      {
        "avg_logprob": -1.4866221567218223,
        "compression_ratio": 1.6145251396648044,
        "end": 13.88,
        "id": 1,
        "no_speech_prob": 0.02126356028020382,
        "seek": 0,
        "start": 12.34,
        "temperature": 1,
        "text": " Hello good evening. It's not the evening at all.",
        "tokens": [
          50981,
          6128,
          752,
          665,
          5634,
          13,
          467,
          311,
          406,
          264,
          1073,
          4559,
          412,
          439,
          13,
          51058
        ]
      },
      {
        "avg_logprob": -1.4866221567218223,
        "compression_ratio": 1.6145251396648044,
        "end": 13.92,
        "id": 2,
        "no_speech_prob": 0.02126356028020382,
        "seek": 0,
        "start": 13.88,
        "temperature": 1,
        "text": " Is the afternoon.",
        "tokens": [
          51058,
          1119,
          264,
          6499,
          13,
          51060
        ]
      },
      {
        "avg_logprob": -1.4866221567218223,
        "compression_ratio": 1.6145251396648044,
        "end": 18.080000000000002,
        "id": 3,
        "no_speech_prob": 0.02126356028020382,
        "seek": 0,
        "start": 15.18,
        "temperature": 1,
        "text": " Welcome to the coding train on a Friday",
        "tokens": [
          51123,
          4027,
          220,
          1353,
          264,
          17720,
          3847,
          322,
          257,
          6984,
          51268
        ]
      },
      {
        "avg_logprob": -1.4866221567218223,
        "compression_ratio": 1.6145251396648044,
        "end": 21.18,
        "id": 4,
        "no_speech_prob": 0.02126356028020382,
        "seek": 0,
        "start": 18.080000000000002,
        "temperature": 1,
        "text": " which is my usual day for the coding train",
        "tokens": [
          51268,
          597,
          307,
          452,
          7713,
          786,
          337,
          264,
          17720,
          3847,
          51423
        ]
      },
      {
        "avg_logprob": -1.4866221567218223,
        "compression_ratio": 1.6145251396648044,
        "end": 21.26,
        "id": 5,
        "no_speech_prob": 0.02126356028020382,
        "seek": 0,
        "start": 21.18,
        "temperature": 1,
        "text": " but this summer it has not been my usual day.",
        "tokens": [
          51423,
          457,
          30994,
          82,
          4266,
          309,
          575,
          406,
          668,
          452,
          220,
          301,
          901,
          786,
          13,
          51427
        ]
      },
      {
        "avg_logprob": -1.4866221567218223,
        "compression_ratio": 1.6145251396648044,
        "end": 26.42,
        "id": 6,
        "no_speech_prob": 0.02126356028020382,
        "seek": 0,
        "start": 23.16,
        "temperature": 1,
        "text": " I was having a lot of trouble getting",
        "tokens": [
          51522,
          286,
          390,
          1419,
          257,
          688,
          295,
          5253,
          1242,
          51685
        ]
      },
      {
        "avg_logprob": -1.4866221567218223,
        "compression_ratio": 1.6145251396648044,
        "end": 26.5,
        "id": 7,
        "no_speech_prob": 0.02126356028020382,
        "seek": 0,
        "start": 26.42,
        "temperature": 1,
        "text": " the start streaming button to start.",
        "tokens": [
          51685,
          264,
          262,
          1328,
          17721,
          11791,
          2960,
          281,
          722,
          13,
          51689
        ]
      },
      {
        "avg_logprob": -0.33198402041480657,
        "compression_ratio": 1.6653386454183268,
        "end": 30.16,
        "id": 8,
        "no_speech_prob": 0.0064880806021392345,
        "seek": 2650,
        "start": 27.16,
        "temperature": 0,
        "text": " I had restricted mode enabled on this laptop",
        "tokens": [
          50397,
          286,
          632,
          20608,
          4391,
          15172,
          322,
          341,
          10732,
          50547
        ]
      },
      {
        "avg_logprob": -0.33198402041480657,
        "compression_ratio": 1.6653386454183268,
        "end": 34.2,
        "id": 9,
        "no_speech_prob": 0.0064880806021392345,
        "seek": 2650,
        "start": 30.16,
        "temperature": 0,
        "text": " for a variety of reasons that I'm not entirely sure of.",
        "tokens": [
          50547,
          337,
          257,
          5673,
          295,
          4112,
          300,
          286,
          478,
          406,
          7696,
          988,
          295,
          13,
          50749
        ]
      },
      {
        "avg_logprob": -0.33198402041480657,
        "compression_ratio": 1.6653386454183268,
        "end": 37.3,
        "id": 10,
        "no_speech_prob": 0.0064880806021392345,
        "seek": 2650,
        "start": 34.2,
        "temperature": 0,
        "text": " And interestingly enough I cannot start streaming.",
        "tokens": [
          50749,
          400,
          25873,
          1547,
          286,
          2644,
          722,
          11791,
          13,
          50904
        ]
      },
      {
        "avg_logprob": -0.33198402041480657,
        "compression_ratio": 1.6653386454183268,
        "end": 39.1,
        "id": 11,
        "no_speech_prob": 0.0064880806021392345,
        "seek": 2650,
        "start": 37.3,
        "temperature": 0,
        "text": " I cannot actually I have to.",
        "tokens": [
          50904,
          286,
          2644,
          767,
          286,
          362,
          281,
          13,
          50994
        ]
      },
      {
        "avg_logprob": -0.33198402041480657,
        "compression_ratio": 1.6653386454183268,
        "end": 40.38,
        "id": 12,
        "no_speech_prob": 0.0064880806021392345,
        "seek": 2650,
        "start": 39.1,
        "temperature": 0,
        "text": " It's a long story but I couldn't get that",
        "tokens": [
          50994,
          467,
          311,
          257,
          938,
          1657,
          457,
          286,
          2809,
          380,
          483,
          300,
          51058
        ]
      },
      {
        "avg_logprob": -0.33198402041480657,
        "compression_ratio": 1.6653386454183268,
        "end": 41.7,
        "id": 13,
        "no_speech_prob": 0.0064880806021392345,
        "seek": 2650,
        "start": 40.38,
        "temperature": 0,
        "text": " start streaming button to work",
        "tokens": [
          51058,
          722,
          11791,
          2960,
          281,
          589,
          51124
        ]
      },
      {
        "avg_logprob": -0.33198402041480657,
        "compression_ratio": 1.6653386454183268,
        "end": 42.54,
        "id": 14,
        "no_speech_prob": 0.0064880806021392345,
        "seek": 2650,
        "start": 41.7,
        "temperature": 0,
        "text": " while it was in restricted mode.",
        "tokens": [
          51124,
          1339,
          309,
          390,
          294,
          20608,
          4391,
          13,
          51166
        ]
      },
      {
        "avg_logprob": -0.33198402041480657,
        "compression_ratio": 1.6653386454183268,
        "end": 43.379999999999995,
        "id": 15,
        "no_speech_prob": 0.0064880806021392345,
        "seek": 2650,
        "start": 42.54,
        "temperature": 0,
        "text": " But I fixed that.",
        "tokens": [
          51166,
          583,
          286,
          6806,
          300,
          13,
          51208
        ]
      },
      {
        "avg_logprob": -0.33198402041480657,
        "compression_ratio": 1.6653386454183268,
        "end": 44.620000000000005,
        "id": 16,
        "no_speech_prob": 0.0064880806021392345,
        "seek": 2650,
        "start": 43.379999999999995,
        "temperature": 0,
        "text": " So here I am.",
        "tokens": [
          51208,
          407,
          510,
          286,
          669,
          13,
          51270
        ]
      },
      {
        "avg_logprob": -0.33198402041480657,
        "compression_ratio": 1.6653386454183268,
        "end": 45.58,
        "id": 17,
        "no_speech_prob": 0.0064880806021392345,
        "seek": 2650,
        "start": 44.620000000000005,
        "temperature": 0,
        "text": " How are you?",
        "tokens": [
          51270,
          1012,
          366,
          291,
          30,
          51318
        ]
      },
      {
        "avg_logprob": -0.33198402041480657,
        "compression_ratio": 1.6653386454183268,
        "end": 46.42,
        "id": 18,
        "no_speech_prob": 0.0064880806021392345,
        "seek": 2650,
        "start": 45.58,
        "temperature": 0,
        "text": " What's going on?",
        "tokens": [
          51318,
          708,
          311,
          516,
          322,
          30,
          51360
        ]
      },
      {
        "avg_logprob": -0.33198402041480657,
        "compression_ratio": 1.6653386454183268,
        "end": 47.68,
        "id": 19,
        "no_speech_prob": 0.0064880806021392345,
        "seek": 2650,
        "start": 46.42,
        "temperature": 0,
        "text": " What's up?",
        "tokens": [
          51360,
          708,
          311,
          493,
          30,
          51423
        ]
      },
      {
        "avg_logprob": -0.33198402041480657,
        "compression_ratio": 1.6653386454183268,
        "end": 50.42,
        "id": 20,
        "no_speech_prob": 0.0064880806021392345,
        "seek": 2650,
        "start": 47.68,
        "temperature": 0,
        "text": " What's happening?",
        "tokens": [
          51423,
          708,
          311,
          2737,
          30,
          51560
        ]
      },
      {
        "avg_logprob": -0.33198402041480657,
        "compression_ratio": 1.6653386454183268,
        "end": 56.260000000000005,
        "id": 21,
        "no_speech_prob": 0.0064880806021392345,
        "seek": 2650,
        "start": 54.86,
        "temperature": 0,
        "text": " Totally weird how you can't speak to me.",
        "tokens": [
          51782,
          22837,
          3657,
          577,
          291,
          393,
          380,
          1710,
          281,
          385,
          13,
          51852
        ]
      },
      {
        "avg_logprob": -0.3183780246310764,
        "compression_ratio": 1.6186770428015564,
        "end": 57.92,
        "id": 22,
        "no_speech_prob": 0.000017502768969279714,
        "seek": 5626,
        "start": 57.08,
        "temperature": 0,
        "text": " Oh I guess there is a chat.",
        "tokens": [
          50405,
          876,
          286,
          2041,
          456,
          307,
          257,
          5081,
          13,
          50447
        ]
      },
      {
        "avg_logprob": -0.3183780246310764,
        "compression_ratio": 1.6186770428015564,
        "end": 60.519999999999996,
        "id": 23,
        "no_speech_prob": 0.000017502768969279714,
        "seek": 5626,
        "start": 57.92,
        "temperature": 0,
        "text": " So you sort of can type to me in the chat.",
        "tokens": [
          50447,
          407,
          291,
          1333,
          295,
          393,
          2010,
          281,
          385,
          294,
          264,
          5081,
          13,
          50577
        ]
      },
      {
        "avg_logprob": -0.3183780246310764,
        "compression_ratio": 1.6186770428015564,
        "end": 63.76,
        "id": 24,
        "no_speech_prob": 0.000017502768969279714,
        "seek": 5626,
        "start": 60.519999999999996,
        "temperature": 0,
        "text": " It's night in India writes Melvin.",
        "tokens": [
          50577,
          467,
          311,
          1818,
          294,
          5282,
          13657,
          7375,
          4796,
          13,
          50739
        ]
      },
      {
        "avg_logprob": -0.3183780246310764,
        "compression_ratio": 1.6186770428015564,
        "end": 68.75999999999999,
        "id": 25,
        "no_speech_prob": 0.000017502768969279714,
        "seek": 5626,
        "start": 63.76,
        "temperature": 0,
        "text": " In Israel it is 20 o'clock which I think is 8 p.m.",
        "tokens": [
          50739,
          682,
          5674,
          309,
          307,
          945,
          277,
          6,
          9023,
          597,
          286,
          519,
          307,
          1649,
          280,
          13,
          76,
          13,
          50989
        ]
      },
      {
        "avg_logprob": -0.3183780246310764,
        "compression_ratio": 1.6186770428015564,
        "end": 73.46,
        "id": 26,
        "no_speech_prob": 0.000017502768969279714,
        "seek": 5626,
        "start": 71.25999999999999,
        "temperature": 0,
        "text": " Alright so I have to admit something.",
        "tokens": [
          51114,
          2798,
          370,
          286,
          362,
          281,
          9796,
          746,
          13,
          51224
        ]
      },
      {
        "avg_logprob": -0.3183780246310764,
        "compression_ratio": 1.6186770428015564,
        "end": 74.94,
        "id": 27,
        "no_speech_prob": 0.000017502768969279714,
        "seek": 5626,
        "start": 73.46,
        "temperature": 0,
        "text": " Although this is nothing new.",
        "tokens": [
          51224,
          5780,
          341,
          307,
          1825,
          777,
          13,
          51298
        ]
      },
      {
        "avg_logprob": -0.3183780246310764,
        "compression_ratio": 1.6186770428015564,
        "end": 78.68,
        "id": 28,
        "no_speech_prob": 0.000017502768969279714,
        "seek": 5626,
        "start": 74.94,
        "temperature": 0,
        "text": " I mean I feel like normally I'm so well prepared",
        "tokens": [
          51298,
          286,
          914,
          286,
          841,
          411,
          5646,
          286,
          478,
          370,
          731,
          4927,
          51485
        ]
      },
      {
        "avg_logprob": -0.3183780246310764,
        "compression_ratio": 1.6186770428015564,
        "end": 81.44,
        "id": 29,
        "no_speech_prob": 0.000017502768969279714,
        "seek": 5626,
        "start": 78.68,
        "temperature": 0,
        "text": " and I spent all week making notes",
        "tokens": [
          51485,
          293,
          286,
          4418,
          439,
          1243,
          1455,
          5570,
          51623
        ]
      },
      {
        "avg_logprob": -0.3183780246310764,
        "compression_ratio": 1.6186770428015564,
        "end": 82.68,
        "id": 30,
        "no_speech_prob": 0.000017502768969279714,
        "seek": 5626,
        "start": 81.44,
        "temperature": 0,
        "text": " and scheduling things out and knowing",
        "tokens": [
          51623,
          293,
          29055,
          721,
          484,
          293,
          5276,
          51685
        ]
      },
      {
        "avg_logprob": -0.3183780246310764,
        "compression_ratio": 1.6186770428015564,
        "end": 84.02,
        "id": 31,
        "no_speech_prob": 0.000017502768969279714,
        "seek": 5626,
        "start": 82.68,
        "temperature": 0,
        "text": " exactly what I'm going to do.",
        "tokens": [
          51685,
          2293,
          437,
          286,
          478,
          516,
          281,
          360,
          13,
          51752
        ]
      },
      {
        "avg_logprob": -0.3183780246310764,
        "compression_ratio": 1.6186770428015564,
        "end": 85.78,
        "id": 32,
        "no_speech_prob": 0.000017502768969279714,
        "seek": 5626,
        "start": 84.02,
        "temperature": 0,
        "text": " And then I like I've got all this energy",
        "tokens": [
          51752,
          400,
          550,
          286,
          411,
          286,
          600,
          658,
          439,
          341,
          2281,
          51840
        ]
      },
      {
        "avg_logprob": -0.26335494995117187,
        "compression_ratio": 1.8025751072961373,
        "end": 88.6,
        "id": 33,
        "no_speech_prob": 0.00013551933807320893,
        "seek": 8578,
        "start": 86.6,
        "temperature": 0,
        "text": " and I turn on the streaming and I'm go, go, go.",
        "tokens": [
          50405,
          293,
          286,
          1261,
          322,
          264,
          11791,
          293,
          286,
          478,
          352,
          11,
          352,
          11,
          352,
          13,
          50505
        ]
      },
      {
        "avg_logprob": -0.26335494995117187,
        "compression_ratio": 1.8025751072961373,
        "end": 90.5,
        "id": 34,
        "no_speech_prob": 0.00013551933807320893,
        "seek": 8578,
        "start": 88.6,
        "temperature": 0,
        "text": " And I do a tutorial and I turn off the streaming",
        "tokens": [
          50505,
          400,
          286,
          360,
          257,
          7073,
          293,
          286,
          1261,
          766,
          264,
          11791,
          50600
        ]
      },
      {
        "avg_logprob": -0.26335494995117187,
        "compression_ratio": 1.8025751072961373,
        "end": 92.1,
        "id": 35,
        "no_speech_prob": 0.00013551933807320893,
        "seek": 8578,
        "start": 90.5,
        "temperature": 0,
        "text": " and the day is over.",
        "tokens": [
          50600,
          293,
          264,
          786,
          307,
          670,
          13,
          50680
        ]
      },
      {
        "avg_logprob": -0.26335494995117187,
        "compression_ratio": 1.8025751072961373,
        "end": 93.94,
        "id": 36,
        "no_speech_prob": 0.00013551933807320893,
        "seek": 8578,
        "start": 92.1,
        "temperature": 0,
        "text": " Right now I feel like it was a",
        "tokens": [
          50680,
          1779,
          586,
          286,
          841,
          411,
          309,
          390,
          257,
          50772
        ]
      },
      {
        "avg_logprob": -0.26335494995117187,
        "compression_ratio": 1.8025751072961373,
        "end": 96.5,
        "id": 37,
        "no_speech_prob": 0.00013551933807320893,
        "seek": 8578,
        "start": 93.94,
        "temperature": 0,
        "text": " I had to make a heroic effort just to make it here",
        "tokens": [
          50772,
          286,
          632,
          281,
          652,
          257,
          32915,
          4630,
          445,
          281,
          652,
          309,
          510,
          50900
        ]
      },
      {
        "avg_logprob": -0.26335494995117187,
        "compression_ratio": 1.8025751072961373,
        "end": 98.66,
        "id": 38,
        "no_speech_prob": 0.00013551933807320893,
        "seek": 8578,
        "start": 96.5,
        "temperature": 0,
        "text": " and press the start streaming button.",
        "tokens": [
          50900,
          293,
          1886,
          264,
          722,
          11791,
          2960,
          13,
          51008
        ]
      },
      {
        "avg_logprob": -0.26335494995117187,
        "compression_ratio": 1.8025751072961373,
        "end": 102.42,
        "id": 39,
        "no_speech_prob": 0.00013551933807320893,
        "seek": 8578,
        "start": 98.66,
        "temperature": 0,
        "text": " So I have to admit that I'm a little bit out of sorts.",
        "tokens": [
          51008,
          407,
          286,
          362,
          281,
          9796,
          300,
          286,
          478,
          257,
          707,
          857,
          484,
          295,
          7527,
          13,
          51196
        ]
      },
      {
        "avg_logprob": -0.26335494995117187,
        "compression_ratio": 1.8025751072961373,
        "end": 106.78,
        "id": 40,
        "no_speech_prob": 0.00013551933807320893,
        "seek": 8578,
        "start": 102.42,
        "temperature": 0,
        "text": " But and I have two hours today.",
        "tokens": [
          51196,
          583,
          293,
          286,
          362,
          732,
          2496,
          965,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.26335494995117187,
        "compression_ratio": 1.8025751072961373,
        "end": 109.9,
        "id": 41,
        "no_speech_prob": 0.00013551933807320893,
        "seek": 8578,
        "start": 106.78,
        "temperature": 0,
        "text": " Good news is I am planning for two live streams next week.",
        "tokens": [
          51414,
          2205,
          2583,
          307,
          286,
          669,
          5038,
          337,
          732,
          1621,
          15842,
          958,
          1243,
          13,
          51570
        ]
      },
      {
        "avg_logprob": -0.26335494995117187,
        "compression_ratio": 1.8025751072961373,
        "end": 112.02000000000001,
        "id": 42,
        "no_speech_prob": 0.00013551933807320893,
        "seek": 8578,
        "start": 109.9,
        "temperature": 0,
        "text": " So I am planning to live stream both",
        "tokens": [
          51570,
          407,
          286,
          669,
          5038,
          281,
          1621,
          4309,
          1293,
          51676
        ]
      },
      {
        "avg_logprob": -0.3215963768236565,
        "compression_ratio": 1.7395348837209301,
        "end": 116.53999999999999,
        "id": 43,
        "no_speech_prob": 0.0001376532600261271,
        "seek": 11202,
        "start": 112.17999999999999,
        "temperature": 0,
        "text": " Wednesday and Thursday it looks like next week.",
        "tokens": [
          50372,
          10579,
          293,
          10383,
          309,
          1542,
          411,
          958,
          1243,
          13,
          50590
        ]
      },
      {
        "avg_logprob": -0.3215963768236565,
        "compression_ratio": 1.7395348837209301,
        "end": 119.3,
        "id": 44,
        "no_speech_prob": 0.0001376532600261271,
        "seek": 11202,
        "start": 116.53999999999999,
        "temperature": 0,
        "text": " And I will publish times to the home page",
        "tokens": [
          50590,
          400,
          286,
          486,
          11374,
          1413,
          281,
          264,
          1280,
          3028,
          50728
        ]
      },
      {
        "avg_logprob": -0.3215963768236565,
        "compression_ratio": 1.7395348837209301,
        "end": 121.74,
        "id": 45,
        "no_speech_prob": 0.0001376532600261271,
        "seek": 11202,
        "start": 119.3,
        "temperature": 0,
        "text": " of this YouTube channel thing soon enough.",
        "tokens": [
          50728,
          295,
          341,
          3088,
          2269,
          551,
          2321,
          1547,
          13,
          50850
        ]
      },
      {
        "avg_logprob": -0.3215963768236565,
        "compression_ratio": 1.7395348837209301,
        "end": 125.74,
        "id": 46,
        "no_speech_prob": 0.0001376532600261271,
        "seek": 11202,
        "start": 123.36,
        "temperature": 0,
        "text": " And so I'm hoping I'm going to get some",
        "tokens": [
          50931,
          400,
          370,
          286,
          478,
          7159,
          286,
          478,
          516,
          281,
          483,
          512,
          51050
        ]
      },
      {
        "avg_logprob": -0.3215963768236565,
        "compression_ratio": 1.7395348837209301,
        "end": 128.48,
        "id": 47,
        "no_speech_prob": 0.0001376532600261271,
        "seek": 11202,
        "start": 125.74,
        "temperature": 0,
        "text": " get into but I really want to do.",
        "tokens": [
          51050,
          483,
          666,
          457,
          286,
          534,
          528,
          281,
          360,
          13,
          51187
        ]
      },
      {
        "avg_logprob": -0.3215963768236565,
        "compression_ratio": 1.7395348837209301,
        "end": 131.66,
        "id": 48,
        "no_speech_prob": 0.0001376532600261271,
        "seek": 11202,
        "start": 129.8,
        "temperature": 0,
        "text": " I really want to do some practical.",
        "tokens": [
          51253,
          286,
          534,
          528,
          281,
          360,
          512,
          8496,
          13,
          51346
        ]
      },
      {
        "avg_logprob": -0.3215963768236565,
        "compression_ratio": 1.7395348837209301,
        "end": 132.7,
        "id": 49,
        "no_speech_prob": 0.0001376532600261271,
        "seek": 11202,
        "start": 131.66,
        "temperature": 0,
        "text": " Ah practical is the wrong word.",
        "tokens": [
          51346,
          2438,
          8496,
          307,
          264,
          2085,
          1349,
          13,
          51398
        ]
      },
      {
        "avg_logprob": -0.3215963768236565,
        "compression_ratio": 1.7395348837209301,
        "end": 135.1,
        "id": 50,
        "no_speech_prob": 0.0001376532600261271,
        "seek": 11202,
        "start": 132.7,
        "temperature": 0,
        "text": " I don't want to do anything practical whatsoever.",
        "tokens": [
          51398,
          286,
          500,
          380,
          528,
          281,
          360,
          1340,
          8496,
          17076,
          13,
          51518
        ]
      },
      {
        "avg_logprob": -0.3215963768236565,
        "compression_ratio": 1.7395348837209301,
        "end": 139.82,
        "id": 51,
        "no_speech_prob": 0.0001376532600261271,
        "seek": 11202,
        "start": 135.94,
        "temperature": 0,
        "text": " I want to do some machine learning demonstrations",
        "tokens": [
          51560,
          286,
          528,
          281,
          360,
          512,
          3479,
          2539,
          34714,
          51754
        ]
      },
      {
        "avg_logprob": -0.2558811959766206,
        "compression_ratio": 1.6077348066298343,
        "end": 144.26,
        "id": 52,
        "no_speech_prob": 0.00004264738890924491,
        "seek": 13982,
        "start": 139.85999999999999,
        "temperature": 0,
        "text": " in the browser with data.",
        "tokens": [
          50366,
          294,
          264,
          11185,
          365,
          1412,
          13,
          50586
        ]
      },
      {
        "avg_logprob": -0.2558811959766206,
        "compression_ratio": 1.6077348066298343,
        "end": 148.73999999999998,
        "id": 53,
        "no_speech_prob": 0.00004264738890924491,
        "seek": 13982,
        "start": 145.62,
        "temperature": 0,
        "text": " And data that might interest you or inspire you",
        "tokens": [
          50654,
          400,
          1412,
          300,
          1062,
          1179,
          291,
          420,
          15638,
          291,
          50810
        ]
      },
      {
        "avg_logprob": -0.2558811959766206,
        "compression_ratio": 1.6077348066298343,
        "end": 151.06,
        "id": 54,
        "no_speech_prob": 0.00004264738890924491,
        "seek": 13982,
        "start": 148.73999999999998,
        "temperature": 0,
        "text": " to use your own data and do something else with it.",
        "tokens": [
          50810,
          281,
          764,
          428,
          1065,
          1412,
          293,
          360,
          746,
          1646,
          365,
          309,
          13,
          50926
        ]
      },
      {
        "avg_logprob": -0.2558811959766206,
        "compression_ratio": 1.6077348066298343,
        "end": 152.14,
        "id": 55,
        "no_speech_prob": 0.00004264738890924491,
        "seek": 13982,
        "start": 151.06,
        "temperature": 0,
        "text": " But I'm not there yet.",
        "tokens": [
          50926,
          583,
          286,
          478,
          406,
          456,
          1939,
          13,
          50980
        ]
      },
      {
        "avg_logprob": -0.2558811959766206,
        "compression_ratio": 1.6077348066298343,
        "end": 153.94,
        "id": 56,
        "no_speech_prob": 0.00004264738890924491,
        "seek": 13982,
        "start": 152.14,
        "temperature": 0,
        "text": " Let me try to figure out where I am.",
        "tokens": [
          50980,
          961,
          385,
          853,
          281,
          2573,
          484,
          689,
          286,
          669,
          13,
          51070
        ]
      },
      {
        "avg_logprob": -0.2558811959766206,
        "compression_ratio": 1.6077348066298343,
        "end": 160.88,
        "id": 57,
        "no_speech_prob": 0.00004264738890924491,
        "seek": 13982,
        "start": 158.29999999999998,
        "temperature": 0,
        "text": " I'm going to go to YouTube the coding train.",
        "tokens": [
          51288,
          286,
          478,
          516,
          281,
          352,
          281,
          3088,
          264,
          17720,
          3847,
          13,
          51417
        ]
      },
      {
        "avg_logprob": -0.2558811959766206,
        "compression_ratio": 1.6077348066298343,
        "end": 167.57999999999998,
        "id": 58,
        "no_speech_prob": 0.00004264738890924491,
        "seek": 13982,
        "start": 162.57999999999998,
        "temperature": 0,
        "text": " And I'm going to go to neural networks and machine learning.",
        "tokens": [
          51502,
          400,
          286,
          478,
          516,
          281,
          352,
          281,
          18161,
          9590,
          293,
          3479,
          2539,
          13,
          51752
        ]
      },
      {
        "avg_logprob": -0.2940110524495443,
        "compression_ratio": 1.6666666666666667,
        "end": 169.78,
        "id": 59,
        "no_speech_prob": 0.000050644455768633634,
        "seek": 16758,
        "start": 167.9,
        "temperature": 0,
        "text": " I'm going to go to session six.",
        "tokens": [
          50380,
          286,
          478,
          516,
          281,
          352,
          281,
          5481,
          2309,
          13,
          50474
        ]
      },
      {
        "avg_logprob": -0.2940110524495443,
        "compression_ratio": 1.6666666666666667,
        "end": 170.70000000000002,
        "id": 60,
        "no_speech_prob": 0.000050644455768633634,
        "seek": 16758,
        "start": 169.78,
        "temperature": 0,
        "text": " Hello and welcome.",
        "tokens": [
          50474,
          2425,
          293,
          2928,
          13,
          50520
        ]
      },
      {
        "avg_logprob": -0.2940110524495443,
        "compression_ratio": 1.6666666666666667,
        "end": 171.9,
        "id": 61,
        "no_speech_prob": 0.000050644455768633634,
        "seek": 16758,
        "start": 170.70000000000002,
        "temperature": 0,
        "text": " Hello and welcome.",
        "tokens": [
          50520,
          2425,
          293,
          2928,
          13,
          50580
        ]
      },
      {
        "avg_logprob": -0.2940110524495443,
        "compression_ratio": 1.6666666666666667,
        "end": 173.18,
        "id": 62,
        "no_speech_prob": 0.000050644455768633634,
        "seek": 16758,
        "start": 171.9,
        "temperature": 0,
        "text": " I'm not going to watch that.",
        "tokens": [
          50580,
          286,
          478,
          406,
          516,
          281,
          1159,
          300,
          13,
          50644
        ]
      },
      {
        "avg_logprob": -0.2940110524495443,
        "compression_ratio": 1.6666666666666667,
        "end": 176.06,
        "id": 63,
        "no_speech_prob": 0.000050644455768633634,
        "seek": 16758,
        "start": 173.18,
        "temperature": 0,
        "text": " All right so this is what I have so far.",
        "tokens": [
          50644,
          1057,
          558,
          370,
          341,
          307,
          437,
          286,
          362,
          370,
          1400,
          13,
          50788
        ]
      },
      {
        "avg_logprob": -0.2940110524495443,
        "compression_ratio": 1.6666666666666667,
        "end": 178.3,
        "id": 64,
        "no_speech_prob": 0.000050644455768633634,
        "seek": 16758,
        "start": 176.06,
        "temperature": 0,
        "text": " I have to do this at the beginning of every live stream",
        "tokens": [
          50788,
          286,
          362,
          281,
          360,
          341,
          412,
          264,
          2863,
          295,
          633,
          1621,
          4309,
          50900
        ]
      },
      {
        "avg_logprob": -0.2940110524495443,
        "compression_ratio": 1.6666666666666667,
        "end": 181.42000000000002,
        "id": 65,
        "no_speech_prob": 0.000050644455768633634,
        "seek": 16758,
        "start": 178.3,
        "temperature": 0,
        "text": " to sort of recap and reframe and recenter myself.",
        "tokens": [
          50900,
          281,
          1333,
          295,
          20928,
          293,
          13334,
          529,
          293,
          5162,
          260,
          2059,
          13,
          51056
        ]
      },
      {
        "avg_logprob": -0.2940110524495443,
        "compression_ratio": 1.6666666666666667,
        "end": 186.70000000000002,
        "id": 66,
        "no_speech_prob": 0.000050644455768633634,
        "seek": 16758,
        "start": 185.48000000000002,
        "temperature": 0,
        "text": " I am going to put this over here",
        "tokens": [
          51259,
          286,
          669,
          516,
          281,
          829,
          341,
          670,
          510,
          51320
        ]
      },
      {
        "avg_logprob": -0.2940110524495443,
        "compression_ratio": 1.6666666666666667,
        "end": 188.14000000000001,
        "id": 67,
        "no_speech_prob": 0.000050644455768633634,
        "seek": 16758,
        "start": 186.70000000000002,
        "temperature": 0,
        "text": " so it doesn't block the view.",
        "tokens": [
          51320,
          370,
          309,
          1177,
          380,
          3461,
          264,
          1910,
          13,
          51392
        ]
      },
      {
        "avg_logprob": -0.2940110524495443,
        "compression_ratio": 1.6666666666666667,
        "end": 191.5,
        "id": 68,
        "no_speech_prob": 0.000050644455768633634,
        "seek": 16758,
        "start": 189.54000000000002,
        "temperature": 0,
        "text": " You may or may not be aware.",
        "tokens": [
          51462,
          509,
          815,
          420,
          815,
          406,
          312,
          3650,
          13,
          51560
        ]
      },
      {
        "avg_logprob": -0.2940110524495443,
        "compression_ratio": 1.6666666666666667,
        "end": 196,
        "id": 69,
        "no_speech_prob": 0.000050644455768633634,
        "seek": 16758,
        "start": 191.5,
        "temperature": 0,
        "text": " There is something out in the world called TensorFlow.js.",
        "tokens": [
          51560,
          821,
          307,
          746,
          484,
          294,
          264,
          1002,
          1219,
          37624,
          13,
          25530,
          13,
          51785
        ]
      },
      {
        "avg_logprob": -0.2992203811119343,
        "compression_ratio": 1.5063829787234042,
        "end": 199.32,
        "id": 70,
        "no_speech_prob": 0.000006048896921129199,
        "seek": 19600,
        "start": 196,
        "temperature": 0,
        "text": " This is a TensorFlow,",
        "tokens": [
          50364,
          639,
          307,
          257,
          37624,
          11,
          50530
        ]
      },
      {
        "avg_logprob": -0.2992203811119343,
        "compression_ratio": 1.5063829787234042,
        "end": 204.32,
        "id": 71,
        "no_speech_prob": 0.000006048896921129199,
        "seek": 19600,
        "start": 199.32,
        "temperature": 0,
        "text": " an implementation of the TensorFlow API in JavaScript",
        "tokens": [
          50530,
          364,
          11420,
          295,
          264,
          37624,
          9362,
          294,
          15778,
          50780
        ]
      },
      {
        "avg_logprob": -0.2992203811119343,
        "compression_ratio": 1.5063829787234042,
        "end": 207.72,
        "id": 72,
        "no_speech_prob": 0.000006048896921129199,
        "seek": 19600,
        "start": 204.68,
        "temperature": 0,
        "text": " that runs in the browser with no other dependencies.",
        "tokens": [
          50798,
          300,
          6676,
          294,
          264,
          11185,
          365,
          572,
          661,
          36606,
          13,
          50950
        ]
      },
      {
        "avg_logprob": -0.2992203811119343,
        "compression_ratio": 1.5063829787234042,
        "end": 210.72,
        "id": 73,
        "no_speech_prob": 0.000006048896921129199,
        "seek": 19600,
        "start": 207.72,
        "temperature": 0,
        "text": " All of the math is done and computed using WebGL",
        "tokens": [
          50950,
          1057,
          295,
          264,
          5221,
          307,
          1096,
          293,
          40610,
          1228,
          9573,
          19440,
          51100
        ]
      },
      {
        "avg_logprob": -0.2992203811119343,
        "compression_ratio": 1.5063829787234042,
        "end": 213.14,
        "id": 74,
        "no_speech_prob": 0.000006048896921129199,
        "seek": 19600,
        "start": 210.72,
        "temperature": 0,
        "text": " and shaders and all sorts of amazing gymnastics",
        "tokens": [
          51100,
          293,
          5744,
          433,
          293,
          439,
          7527,
          295,
          2243,
          48461,
          51221
        ]
      },
      {
        "avg_logprob": -0.2992203811119343,
        "compression_ratio": 1.5063829787234042,
        "end": 215.48,
        "id": 75,
        "no_speech_prob": 0.000006048896921129199,
        "seek": 19600,
        "start": 213.14,
        "temperature": 0,
        "text": " in ways that I might never understand.",
        "tokens": [
          51221,
          294,
          2098,
          300,
          286,
          1062,
          1128,
          1223,
          13,
          51338
        ]
      },
      {
        "avg_logprob": -0.2992203811119343,
        "compression_ratio": 1.5063829787234042,
        "end": 220.26,
        "id": 76,
        "no_speech_prob": 0.000006048896921129199,
        "seek": 19600,
        "start": 215.48,
        "temperature": 0,
        "text": " But it opens the door and enables possibilities for us.",
        "tokens": [
          51338,
          583,
          309,
          9870,
          264,
          2853,
          293,
          17077,
          12178,
          337,
          505,
          13,
          51577
        ]
      },
      {
        "avg_logprob": -0.2992203811119343,
        "compression_ratio": 1.5063829787234042,
        "end": 223.12,
        "id": 77,
        "no_speech_prob": 0.000006048896921129199,
        "seek": 19600,
        "start": 220.26,
        "temperature": 0,
        "text": " The people who program like this.",
        "tokens": [
          51577,
          440,
          561,
          567,
          1461,
          411,
          341,
          13,
          51720
        ]
      },
      {
        "avg_logprob": -0.3330788863332648,
        "compression_ratio": 1.5954545454545455,
        "end": 226.4,
        "id": 78,
        "no_speech_prob": 0.000009972900443244725,
        "seek": 22312,
        "start": 223.24,
        "temperature": 0,
        "text": " It's a high program.",
        "tokens": [
          50370,
          467,
          311,
          257,
          1090,
          1461,
          13,
          50528
        ]
      },
      {
        "avg_logprob": -0.3330788863332648,
        "compression_ratio": 1.5954545454545455,
        "end": 228.98000000000002,
        "id": 79,
        "no_speech_prob": 0.000009972900443244725,
        "seek": 22312,
        "start": 226.4,
        "temperature": 0,
        "text": " To try it and experiment and learn a bit",
        "tokens": [
          50528,
          1407,
          853,
          309,
          293,
          5120,
          293,
          1466,
          257,
          857,
          50657
        ]
      },
      {
        "avg_logprob": -0.3330788863332648,
        "compression_ratio": 1.5954545454545455,
        "end": 230.20000000000002,
        "id": 80,
        "no_speech_prob": 0.000009972900443244725,
        "seek": 22312,
        "start": 228.98000000000002,
        "temperature": 0,
        "text": " about machine learning.",
        "tokens": [
          50657,
          466,
          3479,
          2539,
          13,
          50718
        ]
      },
      {
        "avg_logprob": -0.3330788863332648,
        "compression_ratio": 1.5954545454545455,
        "end": 235.4,
        "id": 81,
        "no_speech_prob": 0.000009972900443244725,
        "seek": 22312,
        "start": 231.44,
        "temperature": 0,
        "text": " And get our hands in there and ask the right questions",
        "tokens": [
          50780,
          400,
          483,
          527,
          2377,
          294,
          456,
          293,
          1029,
          264,
          558,
          1651,
          50978
        ]
      },
      {
        "avg_logprob": -0.3330788863332648,
        "compression_ratio": 1.5954545454545455,
        "end": 237.62,
        "id": 82,
        "no_speech_prob": 0.000009972900443244725,
        "seek": 22312,
        "start": 235.4,
        "temperature": 0,
        "text": " and be critical about the role of AI",
        "tokens": [
          50978,
          293,
          312,
          4924,
          466,
          264,
          3090,
          295,
          7318,
          51089
        ]
      },
      {
        "avg_logprob": -0.3330788863332648,
        "compression_ratio": 1.5954545454545455,
        "end": 240.46,
        "id": 83,
        "no_speech_prob": 0.000009972900443244725,
        "seek": 22312,
        "start": 237.62,
        "temperature": 0,
        "text": " and machine learning in our world today.",
        "tokens": [
          51089,
          293,
          3479,
          2539,
          294,
          527,
          1002,
          965,
          13,
          51231
        ]
      },
      {
        "avg_logprob": -0.3330788863332648,
        "compression_ratio": 1.5954545454545455,
        "end": 242.32,
        "id": 84,
        "no_speech_prob": 0.000009972900443244725,
        "seek": 22312,
        "start": 240.46,
        "temperature": 0,
        "text": " So that's this.",
        "tokens": [
          51231,
          407,
          300,
          311,
          341,
          13,
          51324
        ]
      },
      {
        "avg_logprob": -0.3330788863332648,
        "compression_ratio": 1.5954545454545455,
        "end": 244.8,
        "id": 85,
        "no_speech_prob": 0.000009972900443244725,
        "seek": 22312,
        "start": 242.32,
        "temperature": 0,
        "text": " I have started doing a series of tutorials.",
        "tokens": [
          51324,
          286,
          362,
          1409,
          884,
          257,
          2638,
          295,
          17616,
          13,
          51448
        ]
      },
      {
        "avg_logprob": -0.3330788863332648,
        "compression_ratio": 1.5954545454545455,
        "end": 247.46,
        "id": 86,
        "no_speech_prob": 0.000009972900443244725,
        "seek": 22312,
        "start": 244.8,
        "temperature": 0,
        "text": " These are not super beginner friendly.",
        "tokens": [
          51448,
          1981,
          366,
          406,
          1687,
          22080,
          9208,
          13,
          51581
        ]
      },
      {
        "avg_logprob": -0.3330788863332648,
        "compression_ratio": 1.5954545454545455,
        "end": 251.96,
        "id": 87,
        "no_speech_prob": 0.000009972900443244725,
        "seek": 22312,
        "start": 248.72,
        "temperature": 0,
        "text": " There's some advanced JavaScript,",
        "tokens": [
          51644,
          821,
          311,
          512,
          7339,
          15778,
          11,
          51806
        ]
      },
      {
        "avg_logprob": -0.3002337668705912,
        "compression_ratio": 1.6458333333333333,
        "end": 254.12,
        "id": 88,
        "no_speech_prob": 0.0001823535276344046,
        "seek": 25196,
        "start": 252.20000000000002,
        "temperature": 0,
        "text": " advanced aspects of the JavaScript language",
        "tokens": [
          50376,
          7339,
          7270,
          295,
          264,
          15778,
          2856,
          50472
        ]
      },
      {
        "avg_logprob": -0.3002337668705912,
        "compression_ratio": 1.6458333333333333,
        "end": 255.36,
        "id": 89,
        "no_speech_prob": 0.0001823535276344046,
        "seek": 25196,
        "start": 254.12,
        "temperature": 0,
        "text": " that I'm using that are confusing",
        "tokens": [
          50472,
          300,
          286,
          478,
          1228,
          300,
          366,
          13181,
          50534
        ]
      },
      {
        "avg_logprob": -0.3002337668705912,
        "compression_ratio": 1.6458333333333333,
        "end": 257.7,
        "id": 90,
        "no_speech_prob": 0.0001823535276344046,
        "seek": 25196,
        "start": 255.36,
        "temperature": 0,
        "text": " like promises and await and async.",
        "tokens": [
          50534,
          411,
          16403,
          293,
          19670,
          293,
          382,
          34015,
          13,
          50651
        ]
      },
      {
        "avg_logprob": -0.3002337668705912,
        "compression_ratio": 1.6458333333333333,
        "end": 260.56,
        "id": 91,
        "no_speech_prob": 0.0001823535276344046,
        "seek": 25196,
        "start": 257.7,
        "temperature": 0,
        "text": " You have to do lower level memory management yourself",
        "tokens": [
          50651,
          509,
          362,
          281,
          360,
          3126,
          1496,
          4675,
          4592,
          1803,
          50794
        ]
      },
      {
        "avg_logprob": -0.3002337668705912,
        "compression_ratio": 1.6458333333333333,
        "end": 262.78000000000003,
        "id": 92,
        "no_speech_prob": 0.0001823535276344046,
        "seek": 25196,
        "start": 260.56,
        "temperature": 0,
        "text": " when you make these arrays of data.",
        "tokens": [
          50794,
          562,
          291,
          652,
          613,
          41011,
          295,
          1412,
          13,
          50905
        ]
      },
      {
        "avg_logprob": -0.3002337668705912,
        "compression_ratio": 1.6458333333333333,
        "end": 267.36,
        "id": 93,
        "no_speech_prob": 0.0001823535276344046,
        "seek": 25196,
        "start": 262.78000000000003,
        "temperature": 0,
        "text": " You have to allocate the memory and deallocate the memory.",
        "tokens": [
          50905,
          509,
          362,
          281,
          35713,
          264,
          4675,
          293,
          368,
          336,
          42869,
          264,
          4675,
          13,
          51134
        ]
      },
      {
        "avg_logprob": -0.3002337668705912,
        "compression_ratio": 1.6458333333333333,
        "end": 270.44,
        "id": 94,
        "no_speech_prob": 0.0001823535276344046,
        "seek": 25196,
        "start": 267.36,
        "temperature": 0,
        "text": " And then there's all these scary weird terms",
        "tokens": [
          51134,
          400,
          550,
          456,
          311,
          439,
          613,
          6958,
          3657,
          2115,
          51288
        ]
      },
      {
        "avg_logprob": -0.3002337668705912,
        "compression_ratio": 1.6458333333333333,
        "end": 273.40000000000003,
        "id": 95,
        "no_speech_prob": 0.0001823535276344046,
        "seek": 25196,
        "start": 270.44,
        "temperature": 0,
        "text": " like stochastic gradient descent.",
        "tokens": [
          51288,
          411,
          342,
          8997,
          2750,
          16235,
          23475,
          13,
          51436
        ]
      },
      {
        "avg_logprob": -0.3002337668705912,
        "compression_ratio": 1.6458333333333333,
        "end": 276.56,
        "id": 96,
        "no_speech_prob": 0.0001823535276344046,
        "seek": 25196,
        "start": 274.72,
        "temperature": 0,
        "text": " Well that's one of them.",
        "tokens": [
          51502,
          1042,
          300,
          311,
          472,
          295,
          552,
          13,
          51594
        ]
      },
      {
        "avg_logprob": -0.3002337668705912,
        "compression_ratio": 1.6458333333333333,
        "end": 280.24,
        "id": 97,
        "no_speech_prob": 0.0001823535276344046,
        "seek": 25196,
        "start": 276.56,
        "temperature": 0,
        "text": " Optimizer, root mean squared.",
        "tokens": [
          51594,
          35013,
          6545,
          11,
          5593,
          914,
          8889,
          13,
          51778
        ]
      },
      {
        "avg_logprob": -0.25429946899414063,
        "compression_ratio": 1.5116279069767442,
        "end": 285.36,
        "id": 98,
        "no_speech_prob": 0.00017130747437477112,
        "seek": 28024,
        "start": 280.36,
        "temperature": 0,
        "text": " So but I'm doing this series for an audience",
        "tokens": [
          50370,
          407,
          457,
          286,
          478,
          884,
          341,
          2638,
          337,
          364,
          4034,
          50620
        ]
      },
      {
        "avg_logprob": -0.25429946899414063,
        "compression_ratio": 1.5116279069767442,
        "end": 287.76,
        "id": 99,
        "no_speech_prob": 0.00017130747437477112,
        "seek": 28024,
        "start": 285.88,
        "temperature": 0,
        "text": " who perhaps has already learned a bit",
        "tokens": [
          50646,
          567,
          4317,
          575,
          1217,
          3264,
          257,
          857,
          50740
        ]
      },
      {
        "avg_logprob": -0.25429946899414063,
        "compression_ratio": 1.5116279069767442,
        "end": 288.84000000000003,
        "id": 100,
        "no_speech_prob": 0.00017130747437477112,
        "seek": 28024,
        "start": 287.76,
        "temperature": 0,
        "text": " about JavaScript programming.",
        "tokens": [
          50740,
          466,
          15778,
          9410,
          13,
          50794
        ]
      },
      {
        "avg_logprob": -0.25429946899414063,
        "compression_ratio": 1.5116279069767442,
        "end": 291.2,
        "id": 101,
        "no_speech_prob": 0.00017130747437477112,
        "seek": 28024,
        "start": 288.84000000000003,
        "temperature": 0,
        "text": " Maybe watched some of my other basic",
        "tokens": [
          50794,
          2704,
          6337,
          512,
          295,
          452,
          661,
          3875,
          50912
        ]
      },
      {
        "avg_logprob": -0.25429946899414063,
        "compression_ratio": 1.5116279069767442,
        "end": 293.58,
        "id": 102,
        "no_speech_prob": 0.00017130747437477112,
        "seek": 28024,
        "start": 291.2,
        "temperature": 0,
        "text": " intro to neural network videos.",
        "tokens": [
          50912,
          12897,
          281,
          18161,
          3209,
          2145,
          13,
          51031
        ]
      },
      {
        "avg_logprob": -0.25429946899414063,
        "compression_ratio": 1.5116279069767442,
        "end": 294.88,
        "id": 103,
        "no_speech_prob": 0.00017130747437477112,
        "seek": 28024,
        "start": 293.58,
        "temperature": 0,
        "text": " And just kind of like follow along",
        "tokens": [
          51031,
          400,
          445,
          733,
          295,
          411,
          1524,
          2051,
          51096
        ]
      },
      {
        "avg_logprob": -0.25429946899414063,
        "compression_ratio": 1.5116279069767442,
        "end": 299.88,
        "id": 104,
        "no_speech_prob": 0.00017130747437477112,
        "seek": 28024,
        "start": 294.88,
        "temperature": 0,
        "text": " and see how a larger machine learning library works",
        "tokens": [
          51096,
          293,
          536,
          577,
          257,
          4833,
          3479,
          2539,
          6405,
          1985,
          51346
        ]
      },
      {
        "avg_logprob": -0.25429946899414063,
        "compression_ratio": 1.5116279069767442,
        "end": 301.40000000000003,
        "id": 105,
        "no_speech_prob": 0.00017130747437477112,
        "seek": 28024,
        "start": 300.48,
        "temperature": 0,
        "text": " in the browser and can be used.",
        "tokens": [
          51376,
          294,
          264,
          11185,
          293,
          393,
          312,
          1143,
          13,
          51422
        ]
      },
      {
        "avg_logprob": -0.25429946899414063,
        "compression_ratio": 1.5116279069767442,
        "end": 303.16,
        "id": 106,
        "no_speech_prob": 0.00017130747437477112,
        "seek": 28024,
        "start": 301.40000000000003,
        "temperature": 0,
        "text": " So the tutorials that I have so far",
        "tokens": [
          51422,
          407,
          264,
          17616,
          300,
          286,
          362,
          370,
          1400,
          51510
        ]
      },
      {
        "avg_logprob": -0.25429946899414063,
        "compression_ratio": 1.5116279069767442,
        "end": 307.32,
        "id": 107,
        "no_speech_prob": 0.00017130747437477112,
        "seek": 28024,
        "start": 303.16,
        "temperature": 0,
        "text": " are sort of an introduction to what TensorFlow.js is.",
        "tokens": [
          51510,
          366,
          1333,
          295,
          364,
          9339,
          281,
          437,
          37624,
          13,
          25530,
          307,
          13,
          51718
        ]
      },
      {
        "avg_logprob": -0.2534484553143261,
        "compression_ratio": 1.7751004016064258,
        "end": 310.92,
        "id": 108,
        "no_speech_prob": 0.00024923172895796597,
        "seek": 30732,
        "start": 308.32,
        "temperature": 0,
        "text": " Talking about what it is to be a tensor.",
        "tokens": [
          50414,
          22445,
          466,
          437,
          309,
          307,
          281,
          312,
          257,
          40863,
          13,
          50544
        ]
      },
      {
        "avg_logprob": -0.2534484553143261,
        "compression_ratio": 1.7751004016064258,
        "end": 312.71999999999997,
        "id": 109,
        "no_speech_prob": 0.00024923172895796597,
        "seek": 30732,
        "start": 310.92,
        "temperature": 0,
        "text": " What is it to be a tensor?",
        "tokens": [
          50544,
          708,
          307,
          309,
          281,
          312,
          257,
          40863,
          30,
          50634
        ]
      },
      {
        "avg_logprob": -0.2534484553143261,
        "compression_ratio": 1.7751004016064258,
        "end": 315.88,
        "id": 110,
        "no_speech_prob": 0.00024923172895796597,
        "seek": 30732,
        "start": 312.71999999999997,
        "temperature": 0,
        "text": " I'm a tensor, I'm very tense all the time.",
        "tokens": [
          50634,
          286,
          478,
          257,
          40863,
          11,
          286,
          478,
          588,
          18760,
          439,
          264,
          565,
          13,
          50792
        ]
      },
      {
        "avg_logprob": -0.2534484553143261,
        "compression_ratio": 1.7751004016064258,
        "end": 317.36,
        "id": 111,
        "no_speech_prob": 0.00024923172895796597,
        "seek": 30732,
        "start": 315.88,
        "temperature": 0,
        "text": " I want to be more relaxed.",
        "tokens": [
          50792,
          286,
          528,
          281,
          312,
          544,
          14628,
          13,
          50866
        ]
      },
      {
        "avg_logprob": -0.2534484553143261,
        "compression_ratio": 1.7751004016064258,
        "end": 319.44,
        "id": 112,
        "no_speech_prob": 0.00024923172895796597,
        "seek": 30732,
        "start": 317.36,
        "temperature": 0,
        "text": " I want to be a variable instead of a tensor.",
        "tokens": [
          50866,
          286,
          528,
          281,
          312,
          257,
          7006,
          2602,
          295,
          257,
          40863,
          13,
          50970
        ]
      },
      {
        "avg_logprob": -0.2534484553143261,
        "compression_ratio": 1.7751004016064258,
        "end": 322.08,
        "id": 113,
        "no_speech_prob": 0.00024923172895796597,
        "seek": 30732,
        "start": 319.44,
        "temperature": 0,
        "text": " Although a tensor, whatever, okay.",
        "tokens": [
          50970,
          5780,
          257,
          40863,
          11,
          2035,
          11,
          1392,
          13,
          51102
        ]
      },
      {
        "avg_logprob": -0.2534484553143261,
        "compression_ratio": 1.7751004016064258,
        "end": 323.52,
        "id": 114,
        "no_speech_prob": 0.00024923172895796597,
        "seek": 30732,
        "start": 322.08,
        "temperature": 0,
        "text": " Then variables and operations,",
        "tokens": [
          51102,
          1396,
          9102,
          293,
          7705,
          11,
          51174
        ]
      },
      {
        "avg_logprob": -0.2534484553143261,
        "compression_ratio": 1.7751004016064258,
        "end": 325.76,
        "id": 115,
        "no_speech_prob": 0.00024923172895796597,
        "seek": 30732,
        "start": 323.52,
        "temperature": 0,
        "text": " talking about memory management.",
        "tokens": [
          51174,
          1417,
          466,
          4675,
          4592,
          13,
          51286
        ]
      },
      {
        "avg_logprob": -0.2534484553143261,
        "compression_ratio": 1.7751004016064258,
        "end": 330.15999999999997,
        "id": 116,
        "no_speech_prob": 0.00024923172895796597,
        "seek": 30732,
        "start": 325.76,
        "temperature": 0,
        "text": " I implemented a version of linear regression",
        "tokens": [
          51286,
          286,
          12270,
          257,
          3037,
          295,
          8213,
          24590,
          51506
        ]
      },
      {
        "avg_logprob": -0.2534484553143261,
        "compression_ratio": 1.7751004016064258,
        "end": 333.44,
        "id": 117,
        "no_speech_prob": 0.00024923172895796597,
        "seek": 30732,
        "start": 330.15999999999997,
        "temperature": 0,
        "text": " which is a kind of like a classic machine learning algorithm",
        "tokens": [
          51506,
          597,
          307,
          257,
          733,
          295,
          411,
          257,
          7230,
          3479,
          2539,
          9284,
          51670
        ]
      },
      {
        "avg_logprob": -0.2534484553143261,
        "compression_ratio": 1.7751004016064258,
        "end": 336,
        "id": 118,
        "no_speech_prob": 0.00024923172895796597,
        "seek": 30732,
        "start": 333.44,
        "temperature": 0,
        "text": " where you try to fit a line to a bunch of data points.",
        "tokens": [
          51670,
          689,
          291,
          853,
          281,
          3318,
          257,
          1622,
          281,
          257,
          3840,
          295,
          1412,
          2793,
          13,
          51798
        ]
      },
      {
        "avg_logprob": -0.23465779975608544,
        "compression_ratio": 1.7956521739130435,
        "end": 337.64,
        "id": 119,
        "no_speech_prob": 0.00009027996566146612,
        "seek": 33600,
        "start": 336,
        "temperature": 0,
        "text": " Kind of serves as the foundation",
        "tokens": [
          50364,
          9242,
          295,
          13451,
          382,
          264,
          7030,
          50446
        ]
      },
      {
        "avg_logprob": -0.23465779975608544,
        "compression_ratio": 1.7956521739130435,
        "end": 340.64,
        "id": 120,
        "no_speech_prob": 0.00009027996566146612,
        "seek": 33600,
        "start": 337.64,
        "temperature": 0,
        "text": " for a lot of machine learning research.",
        "tokens": [
          50446,
          337,
          257,
          688,
          295,
          3479,
          2539,
          2132,
          13,
          50596
        ]
      },
      {
        "avg_logprob": -0.23465779975608544,
        "compression_ratio": 1.7956521739130435,
        "end": 342.36,
        "id": 121,
        "no_speech_prob": 0.00009027996566146612,
        "seek": 33600,
        "start": 340.64,
        "temperature": 0,
        "text": " I also looked at polynomial regression",
        "tokens": [
          50596,
          286,
          611,
          2956,
          412,
          26110,
          24590,
          50682
        ]
      },
      {
        "avg_logprob": -0.23465779975608544,
        "compression_ratio": 1.7956521739130435,
        "end": 345.28,
        "id": 122,
        "no_speech_prob": 0.00009027996566146612,
        "seek": 33600,
        "start": 342.36,
        "temperature": 0,
        "text": " where instead of a line we could fit a polynomial function",
        "tokens": [
          50682,
          689,
          2602,
          295,
          257,
          1622,
          321,
          727,
          3318,
          257,
          26110,
          2445,
          50828
        ]
      },
      {
        "avg_logprob": -0.23465779975608544,
        "compression_ratio": 1.7956521739130435,
        "end": 346.88,
        "id": 123,
        "no_speech_prob": 0.00009027996566146612,
        "seek": 33600,
        "start": 345.28,
        "temperature": 0,
        "text": " which curves around.",
        "tokens": [
          50828,
          597,
          19490,
          926,
          13,
          50908
        ]
      },
      {
        "avg_logprob": -0.23465779975608544,
        "compression_ratio": 1.7956521739130435,
        "end": 350.56,
        "id": 124,
        "no_speech_prob": 0.00009027996566146612,
        "seek": 33600,
        "start": 346.88,
        "temperature": 0,
        "text": " And then, ah then, then, then, then, then,",
        "tokens": [
          50908,
          400,
          550,
          11,
          3716,
          550,
          11,
          550,
          11,
          550,
          11,
          550,
          11,
          550,
          11,
          51092
        ]
      },
      {
        "avg_logprob": -0.23465779975608544,
        "compression_ratio": 1.7956521739130435,
        "end": 352.64,
        "id": 125,
        "no_speech_prob": 0.00009027996566146612,
        "seek": 33600,
        "start": 350.56,
        "temperature": 0,
        "text": " I finally, finally, finally started looking",
        "tokens": [
          51092,
          286,
          2721,
          11,
          2721,
          11,
          2721,
          1409,
          1237,
          51196
        ]
      },
      {
        "avg_logprob": -0.23465779975608544,
        "compression_ratio": 1.7956521739130435,
        "end": 353.9,
        "id": 126,
        "no_speech_prob": 0.00009027996566146612,
        "seek": 33600,
        "start": 352.64,
        "temperature": 0,
        "text": " at the layers API.",
        "tokens": [
          51196,
          412,
          264,
          7914,
          9362,
          13,
          51259
        ]
      },
      {
        "avg_logprob": -0.23465779975608544,
        "compression_ratio": 1.7956521739130435,
        "end": 359.6,
        "id": 127,
        "no_speech_prob": 0.00009027996566146612,
        "seek": 33600,
        "start": 354.84,
        "temperature": 0,
        "text": " And the layers API is a higher level API",
        "tokens": [
          51306,
          400,
          264,
          7914,
          9362,
          307,
          257,
          2946,
          1496,
          9362,
          51544
        ]
      },
      {
        "avg_logprob": -0.23465779975608544,
        "compression_ratio": 1.7956521739130435,
        "end": 362.2,
        "id": 128,
        "no_speech_prob": 0.00009027996566146612,
        "seek": 33600,
        "start": 359.6,
        "temperature": 0,
        "text": " inside of TensorFlow.js which allows you",
        "tokens": [
          51544,
          1854,
          295,
          37624,
          13,
          25530,
          597,
          4045,
          291,
          51674
        ]
      },
      {
        "avg_logprob": -0.23465779975608544,
        "compression_ratio": 1.7956521739130435,
        "end": 364.88,
        "id": 129,
        "no_speech_prob": 0.00009027996566146612,
        "seek": 33600,
        "start": 362.2,
        "temperature": 0,
        "text": " to create machine learning models",
        "tokens": [
          51674,
          281,
          1884,
          3479,
          2539,
          5245,
          51808
        ]
      },
      {
        "avg_logprob": -0.22994474202644924,
        "compression_ratio": 1.8130434782608695,
        "end": 366.88,
        "id": 130,
        "no_speech_prob": 0.00009761536057339981,
        "seek": 36488,
        "start": 364.88,
        "temperature": 0,
        "text": " as sequences of layers.",
        "tokens": [
          50364,
          382,
          22978,
          295,
          7914,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.22994474202644924,
        "compression_ratio": 1.8130434782608695,
        "end": 369.32,
        "id": 131,
        "no_speech_prob": 0.00009761536057339981,
        "seek": 36488,
        "start": 366.88,
        "temperature": 0,
        "text": " And that has, you know, how that works",
        "tokens": [
          50464,
          400,
          300,
          575,
          11,
          291,
          458,
          11,
          577,
          300,
          1985,
          50586
        ]
      },
      {
        "avg_logprob": -0.22994474202644924,
        "compression_ratio": 1.8130434782608695,
        "end": 372.86,
        "id": 132,
        "no_speech_prob": 0.00009761536057339981,
        "seek": 36488,
        "start": 369.32,
        "temperature": 0,
        "text": " has to do with how neural networks are architected",
        "tokens": [
          50586,
          575,
          281,
          360,
          365,
          577,
          18161,
          9590,
          366,
          6331,
          292,
          50763
        ]
      },
      {
        "avg_logprob": -0.22994474202644924,
        "compression_ratio": 1.8130434782608695,
        "end": 375.44,
        "id": 133,
        "no_speech_prob": 0.00009761536057339981,
        "seek": 36488,
        "start": 372.86,
        "temperature": 0,
        "text": " with inputs and outputs and layers that are in between",
        "tokens": [
          50763,
          365,
          15743,
          293,
          23930,
          293,
          7914,
          300,
          366,
          294,
          1296,
          50892
        ]
      },
      {
        "avg_logprob": -0.22994474202644924,
        "compression_ratio": 1.8130434782608695,
        "end": 376.78,
        "id": 134,
        "no_speech_prob": 0.00009761536057339981,
        "seek": 36488,
        "start": 375.44,
        "temperature": 0,
        "text": " and there's different kinds of layers",
        "tokens": [
          50892,
          293,
          456,
          311,
          819,
          3685,
          295,
          7914,
          50959
        ]
      },
      {
        "avg_logprob": -0.22994474202644924,
        "compression_ratio": 1.8130434782608695,
        "end": 378.71999999999997,
        "id": 135,
        "no_speech_prob": 0.00009761536057339981,
        "seek": 36488,
        "start": 376.78,
        "temperature": 0,
        "text": " and different kinds of math functions",
        "tokens": [
          50959,
          293,
          819,
          3685,
          295,
          5221,
          6828,
          51056
        ]
      },
      {
        "avg_logprob": -0.22994474202644924,
        "compression_ratio": 1.8130434782608695,
        "end": 381.32,
        "id": 136,
        "no_speech_prob": 0.00009761536057339981,
        "seek": 36488,
        "start": 378.71999999999997,
        "temperature": 0,
        "text": " that happen with those layers, all that sort of stuff.",
        "tokens": [
          51056,
          300,
          1051,
          365,
          729,
          7914,
          11,
          439,
          300,
          1333,
          295,
          1507,
          13,
          51186
        ]
      },
      {
        "avg_logprob": -0.22994474202644924,
        "compression_ratio": 1.8130434782608695,
        "end": 383.64,
        "id": 137,
        "no_speech_prob": 0.00009761536057339981,
        "seek": 36488,
        "start": 381.32,
        "temperature": 0,
        "text": " So this is where I am at the moment.",
        "tokens": [
          51186,
          407,
          341,
          307,
          689,
          286,
          669,
          412,
          264,
          1623,
          13,
          51302
        ]
      },
      {
        "avg_logprob": -0.22994474202644924,
        "compression_ratio": 1.8130434782608695,
        "end": 386.08,
        "id": 138,
        "no_speech_prob": 0.00009761536057339981,
        "seek": 36488,
        "start": 385.08,
        "temperature": 0,
        "text": " This is where I am.",
        "tokens": [
          51374,
          639,
          307,
          689,
          286,
          669,
          13,
          51424
        ]
      },
      {
        "avg_logprob": -0.22994474202644924,
        "compression_ratio": 1.8130434782608695,
        "end": 389.15999999999997,
        "id": 139,
        "no_speech_prob": 0.00009761536057339981,
        "seek": 36488,
        "start": 387.32,
        "temperature": 0,
        "text": " Where am I going to?",
        "tokens": [
          51486,
          2305,
          669,
          286,
          516,
          281,
          30,
          51578
        ]
      },
      {
        "avg_logprob": -0.22994474202644924,
        "compression_ratio": 1.8130434782608695,
        "end": 391.76,
        "id": 140,
        "no_speech_prob": 0.00009761536057339981,
        "seek": 36488,
        "start": 389.15999999999997,
        "temperature": 0,
        "text": " Where am I going to?",
        "tokens": [
          51578,
          2305,
          669,
          286,
          516,
          281,
          30,
          51708
        ]
      },
      {
        "avg_logprob": -0.22994474202644924,
        "compression_ratio": 1.8130434782608695,
        "end": 393.48,
        "id": 141,
        "no_speech_prob": 0.00009761536057339981,
        "seek": 36488,
        "start": 391.76,
        "temperature": 0,
        "text": " Don't ask anymore.",
        "tokens": [
          51708,
          1468,
          380,
          1029,
          3602,
          13,
          51794
        ]
      },
      {
        "avg_logprob": -0.31860429269296153,
        "compression_ratio": 1.4454976303317535,
        "end": 395.52000000000004,
        "id": 142,
        "no_speech_prob": 0.0002378208882873878,
        "seek": 39348,
        "start": 393.48,
        "temperature": 0,
        "text": " Ah, I forgot my ukulele.",
        "tokens": [
          50364,
          2438,
          11,
          286,
          5298,
          452,
          26769,
          2271,
          306,
          13,
          50466
        ]
      },
      {
        "avg_logprob": -0.31860429269296153,
        "compression_ratio": 1.4454976303317535,
        "end": 397.6,
        "id": 143,
        "no_speech_prob": 0.0002378208882873878,
        "seek": 39348,
        "start": 395.52000000000004,
        "temperature": 0,
        "text": " I learned to play the ukulele a couple weeks ago.",
        "tokens": [
          50466,
          286,
          3264,
          281,
          862,
          264,
          26769,
          2271,
          306,
          257,
          1916,
          3259,
          2057,
          13,
          50570
        ]
      },
      {
        "avg_logprob": -0.31860429269296153,
        "compression_ratio": 1.4454976303317535,
        "end": 399.48,
        "id": 144,
        "no_speech_prob": 0.0002378208882873878,
        "seek": 39348,
        "start": 397.6,
        "temperature": 0,
        "text": " Thinking I'm ruining this YouTube channel",
        "tokens": [
          50570,
          24460,
          286,
          478,
          38938,
          341,
          3088,
          2269,
          50664
        ]
      },
      {
        "avg_logprob": -0.31860429269296153,
        "compression_ratio": 1.4454976303317535,
        "end": 401.76,
        "id": 145,
        "no_speech_prob": 0.0002378208882873878,
        "seek": 39348,
        "start": 399.48,
        "temperature": 0,
        "text": " with me playing the ukulele.",
        "tokens": [
          50664,
          365,
          385,
          2433,
          264,
          26769,
          2271,
          306,
          13,
          50778
        ]
      },
      {
        "avg_logprob": -0.31860429269296153,
        "compression_ratio": 1.4454976303317535,
        "end": 405,
        "id": 146,
        "no_speech_prob": 0.0002378208882873878,
        "seek": 39348,
        "start": 401.76,
        "temperature": 0,
        "text": " Where am I going to?",
        "tokens": [
          50778,
          2305,
          669,
          286,
          516,
          281,
          30,
          50940
        ]
      },
      {
        "avg_logprob": -0.31860429269296153,
        "compression_ratio": 1.4454976303317535,
        "end": 406.8,
        "id": 147,
        "no_speech_prob": 0.0002378208882873878,
        "seek": 39348,
        "start": 405,
        "temperature": 0,
        "text": " Don't ask anymore.",
        "tokens": [
          50940,
          1468,
          380,
          1029,
          3602,
          13,
          51030
        ]
      },
      {
        "avg_logprob": -0.31860429269296153,
        "compression_ratio": 1.4454976303317535,
        "end": 407.64000000000004,
        "id": 148,
        "no_speech_prob": 0.0002378208882873878,
        "seek": 39348,
        "start": 406.8,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          51030,
          1033,
          13,
          51072
        ]
      },
      {
        "avg_logprob": -0.31860429269296153,
        "compression_ratio": 1.4454976303317535,
        "end": 409.72,
        "id": 149,
        "no_speech_prob": 0.0002378208882873878,
        "seek": 39348,
        "start": 408.68,
        "temperature": 0,
        "text": " Ah, so.",
        "tokens": [
          51124,
          2438,
          11,
          370,
          13,
          51176
        ]
      },
      {
        "avg_logprob": -0.31860429269296153,
        "compression_ratio": 1.4454976303317535,
        "end": 411.46000000000004,
        "id": 150,
        "no_speech_prob": 0.0002378208882873878,
        "seek": 39348,
        "start": 410.62,
        "temperature": 0,
        "text": " What's next?",
        "tokens": [
          51221,
          708,
          311,
          958,
          30,
          51263
        ]
      },
      {
        "avg_logprob": -0.31860429269296153,
        "compression_ratio": 1.4454976303317535,
        "end": 412.84000000000003,
        "id": 151,
        "no_speech_prob": 0.0002378208882873878,
        "seek": 39348,
        "start": 411.46000000000004,
        "temperature": 0,
        "text": " Let me make a list.",
        "tokens": [
          51263,
          961,
          385,
          652,
          257,
          1329,
          13,
          51332
        ]
      },
      {
        "avg_logprob": -0.31860429269296153,
        "compression_ratio": 1.4454976303317535,
        "end": 415.8,
        "id": 152,
        "no_speech_prob": 0.0002378208882873878,
        "seek": 39348,
        "start": 412.84000000000003,
        "temperature": 0,
        "text": " Really for me, but you're watching so you can watch.",
        "tokens": [
          51332,
          4083,
          337,
          385,
          11,
          457,
          291,
          434,
          1976,
          370,
          291,
          393,
          1159,
          13,
          51480
        ]
      },
      {
        "avg_logprob": -0.31860429269296153,
        "compression_ratio": 1.4454976303317535,
        "end": 423.04,
        "id": 153,
        "no_speech_prob": 0.0002378208882873878,
        "seek": 39348,
        "start": 418.32,
        "temperature": 0,
        "text": " XOR with TF layers.",
        "tokens": [
          51606,
          1783,
          2483,
          365,
          40964,
          7914,
          13,
          51842
        ]
      },
      {
        "avg_logprob": -0.3044646616732137,
        "compression_ratio": 1.929936305732484,
        "end": 428.90000000000003,
        "id": 154,
        "no_speech_prob": 0.000005682421942765359,
        "seek": 42348,
        "start": 424.48,
        "temperature": 0,
        "text": " I want to do a classification example.",
        "tokens": [
          50414,
          286,
          528,
          281,
          360,
          257,
          21538,
          1365,
          13,
          50635
        ]
      },
      {
        "avg_logprob": -0.3044646616732137,
        "compression_ratio": 1.929936305732484,
        "end": 433.64000000000004,
        "id": 155,
        "no_speech_prob": 0.000005682421942765359,
        "seek": 42348,
        "start": 430.96000000000004,
        "temperature": 0,
        "text": " I'm thinking of do, what I'm thinking of right now.",
        "tokens": [
          50738,
          286,
          478,
          1953,
          295,
          360,
          11,
          437,
          286,
          478,
          1953,
          295,
          558,
          586,
          13,
          50872
        ]
      },
      {
        "avg_logprob": -0.3044646616732137,
        "compression_ratio": 1.929936305732484,
        "end": 435.68,
        "id": 156,
        "no_speech_prob": 0.000005682421942765359,
        "seek": 42348,
        "start": 433.64000000000004,
        "temperature": 0,
        "text": " So I'm going to go through these one at a time.",
        "tokens": [
          50872,
          407,
          286,
          478,
          516,
          281,
          352,
          807,
          613,
          472,
          412,
          257,
          565,
          13,
          50974
        ]
      },
      {
        "avg_logprob": -0.3044646616732137,
        "compression_ratio": 1.929936305732484,
        "end": 436.92,
        "id": 157,
        "no_speech_prob": 0.000005682421942765359,
        "seek": 42348,
        "start": 435.68,
        "temperature": 0,
        "text": " Classification, and I'll come back",
        "tokens": [
          50974,
          9471,
          3774,
          11,
          293,
          286,
          603,
          808,
          646,
          51036
        ]
      },
      {
        "avg_logprob": -0.3044646616732137,
        "compression_ratio": 1.929936305732484,
        "end": 437.76,
        "id": 158,
        "no_speech_prob": 0.000005682421942765359,
        "seek": 42348,
        "start": 436.92,
        "temperature": 0,
        "text": " to the details on these.",
        "tokens": [
          51036,
          281,
          264,
          4365,
          322,
          613,
          13,
          51078
        ]
      },
      {
        "avg_logprob": -0.3044646616732137,
        "compression_ratio": 1.929936305732484,
        "end": 440.98,
        "id": 159,
        "no_speech_prob": 0.000005682421942765359,
        "seek": 42348,
        "start": 437.76,
        "temperature": 0,
        "text": " I want to do image.",
        "tokens": [
          51078,
          286,
          528,
          281,
          360,
          3256,
          13,
          51239
        ]
      },
      {
        "avg_logprob": -0.3044646616732137,
        "compression_ratio": 1.929936305732484,
        "end": 443.1,
        "id": 160,
        "no_speech_prob": 0.000005682421942765359,
        "seek": 42348,
        "start": 440.98,
        "temperature": 0,
        "text": " Then I want to do image classification.",
        "tokens": [
          51239,
          1396,
          286,
          528,
          281,
          360,
          3256,
          21538,
          13,
          51345
        ]
      },
      {
        "avg_logprob": -0.3044646616732137,
        "compression_ratio": 1.929936305732484,
        "end": 450.28000000000003,
        "id": 161,
        "no_speech_prob": 0.000005682421942765359,
        "seek": 42348,
        "start": 445.40000000000003,
        "temperature": 0,
        "text": " Then I want to do image classification again",
        "tokens": [
          51460,
          1396,
          286,
          528,
          281,
          360,
          3256,
          21538,
          797,
          51704
        ]
      },
      {
        "avg_logprob": -0.43377270905867865,
        "compression_ratio": 1.4774193548387098,
        "end": 455.44,
        "id": 162,
        "no_speech_prob": 0.000016187528672162443,
        "seek": 45028,
        "start": 450.59999999999997,
        "temperature": 0,
        "text": " with convolutional layer.",
        "tokens": [
          50380,
          365,
          45216,
          304,
          4583,
          13,
          50622
        ]
      },
      {
        "avg_logprob": -0.43377270905867865,
        "compression_ratio": 1.4774193548387098,
        "end": 459.55999999999995,
        "id": 163,
        "no_speech_prob": 0.000016187528672162443,
        "seek": 45028,
        "start": 457.44,
        "temperature": 0,
        "text": " So then I want to talk about what that is.",
        "tokens": [
          50722,
          407,
          550,
          286,
          528,
          281,
          751,
          466,
          437,
          300,
          307,
          13,
          50828
        ]
      },
      {
        "avg_logprob": -0.43377270905867865,
        "compression_ratio": 1.4774193548387098,
        "end": 465.71999999999997,
        "id": 164,
        "no_speech_prob": 0.000016187528672162443,
        "seek": 45028,
        "start": 462,
        "temperature": 0,
        "text": " Do I want to do some type of regression example?",
        "tokens": [
          50950,
          1144,
          286,
          528,
          281,
          360,
          512,
          2010,
          295,
          24590,
          1365,
          30,
          51136
        ]
      },
      {
        "avg_logprob": -0.43377270905867865,
        "compression_ratio": 1.4774193548387098,
        "end": 466.76,
        "id": 165,
        "no_speech_prob": 0.000016187528672162443,
        "seek": 45028,
        "start": 465.71999999999997,
        "temperature": 0,
        "text": " Maybe.",
        "tokens": [
          51136,
          2704,
          13,
          51188
        ]
      },
      {
        "avg_logprob": -0.43377270905867865,
        "compression_ratio": 1.4774193548387098,
        "end": 468.71999999999997,
        "id": 166,
        "no_speech_prob": 0.000016187528672162443,
        "seek": 45028,
        "start": 467.88,
        "temperature": 0,
        "text": " Maybe.",
        "tokens": [
          51244,
          2704,
          13,
          51286
        ]
      },
      {
        "avg_logprob": -0.43377270905867865,
        "compression_ratio": 1.4774193548387098,
        "end": 473.23999999999995,
        "id": 167,
        "no_speech_prob": 0.000016187528672162443,
        "seek": 45028,
        "start": 468.71999999999997,
        "temperature": 0,
        "text": " So classification, and then maybe sort of like as inside,",
        "tokens": [
          51286,
          407,
          21538,
          11,
          293,
          550,
          1310,
          1333,
          295,
          411,
          382,
          1854,
          11,
          51512
        ]
      },
      {
        "avg_logprob": -0.43377270905867865,
        "compression_ratio": 1.4774193548387098,
        "end": 476.14,
        "id": 168,
        "no_speech_prob": 0.000016187528672162443,
        "seek": 45028,
        "start": 473.23999999999995,
        "temperature": 0,
        "text": " a part of B of like a basic regression.",
        "tokens": [
          51512,
          257,
          644,
          295,
          363,
          295,
          411,
          257,
          3875,
          24590,
          13,
          51657
        ]
      },
      {
        "avg_logprob": -0.26309266981187757,
        "compression_ratio": 1.5047169811320755,
        "end": 480.06,
        "id": 169,
        "no_speech_prob": 0.000023923463231767528,
        "seek": 47614,
        "start": 477.14,
        "temperature": 0,
        "text": " So this is kind of what I want to do",
        "tokens": [
          50414,
          407,
          341,
          307,
          733,
          295,
          437,
          286,
          528,
          281,
          360,
          50560
        ]
      },
      {
        "avg_logprob": -0.26309266981187757,
        "compression_ratio": 1.5047169811320755,
        "end": 482.26,
        "id": 170,
        "no_speech_prob": 0.000023923463231767528,
        "seek": 47614,
        "start": 480.06,
        "temperature": 0,
        "text": " in terms of the basic building blocks",
        "tokens": [
          50560,
          294,
          2115,
          295,
          264,
          3875,
          2390,
          8474,
          50670
        ]
      },
      {
        "avg_logprob": -0.26309266981187757,
        "compression_ratio": 1.5047169811320755,
        "end": 484.86,
        "id": 171,
        "no_speech_prob": 0.000023923463231767528,
        "seek": 47614,
        "start": 482.26,
        "temperature": 0,
        "text": " of machine learning with neural networks.",
        "tokens": [
          50670,
          295,
          3479,
          2539,
          365,
          18161,
          9590,
          13,
          50800
        ]
      },
      {
        "avg_logprob": -0.26309266981187757,
        "compression_ratio": 1.5047169811320755,
        "end": 486.06,
        "id": 172,
        "no_speech_prob": 0.000023923463231767528,
        "seek": 47614,
        "start": 484.86,
        "temperature": 0,
        "text": " And I want to build all of these",
        "tokens": [
          50800,
          400,
          286,
          528,
          281,
          1322,
          439,
          295,
          613,
          50860
        ]
      },
      {
        "avg_logprob": -0.26309266981187757,
        "compression_ratio": 1.5047169811320755,
        "end": 491.06,
        "id": 173,
        "no_speech_prob": 0.000023923463231767528,
        "seek": 47614,
        "start": 486.06,
        "temperature": 0,
        "text": " with the TensorFlow.js library.",
        "tokens": [
          50860,
          365,
          264,
          37624,
          13,
          25530,
          6405,
          13,
          51110
        ]
      },
      {
        "avg_logprob": -0.26309266981187757,
        "compression_ratio": 1.5047169811320755,
        "end": 496.3,
        "id": 174,
        "no_speech_prob": 0.000023923463231767528,
        "seek": 47614,
        "start": 491.3,
        "temperature": 0,
        "text": " So just to lower your expectations for a minute.",
        "tokens": [
          51122,
          407,
          445,
          281,
          3126,
          428,
          9843,
          337,
          257,
          3456,
          13,
          51372
        ]
      },
      {
        "avg_logprob": -0.26309266981187757,
        "compression_ratio": 1.5047169811320755,
        "end": 502.06,
        "id": 175,
        "no_speech_prob": 0.000023923463231767528,
        "seek": 47614,
        "start": 497.94,
        "temperature": 0,
        "text": " If I were able to get even just this done today,",
        "tokens": [
          51454,
          759,
          286,
          645,
          1075,
          281,
          483,
          754,
          445,
          341,
          1096,
          965,
          11,
          51660
        ]
      },
      {
        "avg_logprob": -0.26309266981187757,
        "compression_ratio": 1.5047169811320755,
        "end": 503.74,
        "id": 176,
        "no_speech_prob": 0.000023923463231767528,
        "seek": 47614,
        "start": 502.06,
        "temperature": 0,
        "text": " I would be very happy about that.",
        "tokens": [
          51660,
          286,
          576,
          312,
          588,
          2055,
          466,
          300,
          13,
          51744
        ]
      },
      {
        "avg_logprob": -0.26309266981187757,
        "compression_ratio": 1.5047169811320755,
        "end": 504.58,
        "id": 177,
        "no_speech_prob": 0.000023923463231767528,
        "seek": 47614,
        "start": 503.74,
        "temperature": 0,
        "text": " Okay?",
        "tokens": [
          51744,
          1033,
          30,
          51786
        ]
      },
      {
        "avg_logprob": -0.26830155720082366,
        "compression_ratio": 1.6222222222222222,
        "end": 506.74,
        "id": 178,
        "no_speech_prob": 0.0000017330488617517403,
        "seek": 50458,
        "start": 504.58,
        "temperature": 0,
        "text": " So this is kind of my goal.",
        "tokens": [
          50364,
          407,
          341,
          307,
          733,
          295,
          452,
          3387,
          13,
          50472
        ]
      },
      {
        "avg_logprob": -0.26830155720082366,
        "compression_ratio": 1.6222222222222222,
        "end": 507.7,
        "id": 179,
        "no_speech_prob": 0.0000017330488617517403,
        "seek": 50458,
        "start": 506.74,
        "temperature": 0,
        "text": " That's my goal for today.",
        "tokens": [
          50472,
          663,
          311,
          452,
          3387,
          337,
          965,
          13,
          50520
        ]
      },
      {
        "avg_logprob": -0.26830155720082366,
        "compression_ratio": 1.6222222222222222,
        "end": 511.7,
        "id": 180,
        "no_speech_prob": 0.0000017330488617517403,
        "seek": 50458,
        "start": 507.7,
        "temperature": 0,
        "text": " Now, I am doing things backwards.",
        "tokens": [
          50520,
          823,
          11,
          286,
          669,
          884,
          721,
          12204,
          13,
          50720
        ]
      },
      {
        "avg_logprob": -0.26830155720082366,
        "compression_ratio": 1.6222222222222222,
        "end": 513.86,
        "id": 181,
        "no_speech_prob": 0.0000017330488617517403,
        "seek": 50458,
        "start": 511.7,
        "temperature": 0,
        "text": " In one sense, I'm doing something like that.",
        "tokens": [
          50720,
          682,
          472,
          2020,
          11,
          286,
          478,
          884,
          746,
          411,
          300,
          13,
          50828
        ]
      },
      {
        "avg_logprob": -0.26830155720082366,
        "compression_ratio": 1.6222222222222222,
        "end": 516.9399999999999,
        "id": 182,
        "no_speech_prob": 0.0000017330488617517403,
        "seek": 50458,
        "start": 513.86,
        "temperature": 0,
        "text": " These are not super beginner-friendly.",
        "tokens": [
          50828,
          1981,
          366,
          406,
          1687,
          22080,
          12,
          22864,
          13,
          50982
        ]
      },
      {
        "avg_logprob": -0.26830155720082366,
        "compression_ratio": 1.6222222222222222,
        "end": 519.18,
        "id": 183,
        "no_speech_prob": 0.0000017330488617517403,
        "seek": 50458,
        "start": 516.9399999999999,
        "temperature": 0,
        "text": " I mean, they're as beginner-friendly as I can make them.",
        "tokens": [
          50982,
          286,
          914,
          11,
          436,
          434,
          382,
          22080,
          12,
          22864,
          382,
          286,
          393,
          652,
          552,
          13,
          51094
        ]
      },
      {
        "avg_logprob": -0.26830155720082366,
        "compression_ratio": 1.6222222222222222,
        "end": 521.5799999999999,
        "id": 184,
        "no_speech_prob": 0.0000017330488617517403,
        "seek": 50458,
        "start": 519.18,
        "temperature": 0,
        "text": " I want them to be friendly.",
        "tokens": [
          51094,
          286,
          528,
          552,
          281,
          312,
          9208,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.26830155720082366,
        "compression_ratio": 1.6222222222222222,
        "end": 524.02,
        "id": 185,
        "no_speech_prob": 0.0000017330488617517403,
        "seek": 50458,
        "start": 521.5799999999999,
        "temperature": 0,
        "text": " But you know, if this was my first day",
        "tokens": [
          51214,
          583,
          291,
          458,
          11,
          498,
          341,
          390,
          452,
          700,
          786,
          51336
        ]
      },
      {
        "avg_logprob": -0.26830155720082366,
        "compression_ratio": 1.6222222222222222,
        "end": 526.5,
        "id": 186,
        "no_speech_prob": 0.0000017330488617517403,
        "seek": 50458,
        "start": 524.02,
        "temperature": 0,
        "text": " watching a coding video, I might not want to jump",
        "tokens": [
          51336,
          1976,
          257,
          17720,
          960,
          11,
          286,
          1062,
          406,
          528,
          281,
          3012,
          51460
        ]
      },
      {
        "avg_logprob": -0.26830155720082366,
        "compression_ratio": 1.6222222222222222,
        "end": 528.56,
        "id": 187,
        "no_speech_prob": 0.0000017330488617517403,
        "seek": 50458,
        "start": 526.5,
        "temperature": 0,
        "text": " into the image classification",
        "tokens": [
          51460,
          666,
          264,
          3256,
          21538,
          51563
        ]
      },
      {
        "avg_logprob": -0.26830155720082366,
        "compression_ratio": 1.6222222222222222,
        "end": 531.06,
        "id": 188,
        "no_speech_prob": 0.0000017330488617517403,
        "seek": 50458,
        "start": 528.56,
        "temperature": 0,
        "text": " with the TensorFlow Layers API video,",
        "tokens": [
          51563,
          365,
          264,
          37624,
          20084,
          433,
          9362,
          960,
          11,
          51688
        ]
      },
      {
        "avg_logprob": -0.26830155720082366,
        "compression_ratio": 1.6222222222222222,
        "end": 532.26,
        "id": 189,
        "no_speech_prob": 0.0000017330488617517403,
        "seek": 50458,
        "start": 531.06,
        "temperature": 0,
        "text": " which doesn't exist yet.",
        "tokens": [
          51688,
          597,
          1177,
          380,
          2514,
          1939,
          13,
          51748
        ]
      },
      {
        "avg_logprob": -0.25486726849992697,
        "compression_ratio": 1.5701754385964912,
        "end": 535.1,
        "id": 190,
        "no_speech_prob": 0.00002014560050156433,
        "seek": 53226,
        "start": 533.1,
        "temperature": 0,
        "text": " But once I get through this,",
        "tokens": [
          50406,
          583,
          1564,
          286,
          483,
          807,
          341,
          11,
          50506
        ]
      },
      {
        "avg_logprob": -0.25486726849992697,
        "compression_ratio": 1.5701754385964912,
        "end": 537.9,
        "id": 191,
        "no_speech_prob": 0.00002014560050156433,
        "seek": 53226,
        "start": 535.1,
        "temperature": 0,
        "text": " or actually once June 15th hits,",
        "tokens": [
          50506,
          420,
          767,
          1564,
          6928,
          2119,
          392,
          8664,
          11,
          50646
        ]
      },
      {
        "avg_logprob": -0.25486726849992697,
        "compression_ratio": 1.5701754385964912,
        "end": 539.42,
        "id": 192,
        "no_speech_prob": 0.00002014560050156433,
        "seek": 53226,
        "start": 537.9,
        "temperature": 0,
        "text": " or maybe even a little bit before June 15th,",
        "tokens": [
          50646,
          420,
          1310,
          754,
          257,
          707,
          857,
          949,
          6928,
          2119,
          392,
          11,
          50722
        ]
      },
      {
        "avg_logprob": -0.25486726849992697,
        "compression_ratio": 1.5701754385964912,
        "end": 542.02,
        "id": 193,
        "no_speech_prob": 0.00002014560050156433,
        "seek": 53226,
        "start": 539.42,
        "temperature": 0,
        "text": " that's next week, I'm going to start doing",
        "tokens": [
          50722,
          300,
          311,
          958,
          1243,
          11,
          286,
          478,
          516,
          281,
          722,
          884,
          50852
        ]
      },
      {
        "avg_logprob": -0.25486726849992697,
        "compression_ratio": 1.5701754385964912,
        "end": 544.98,
        "id": 194,
        "no_speech_prob": 0.00002014560050156433,
        "seek": 53226,
        "start": 542.02,
        "temperature": 0,
        "text": " some beginner-friendly,",
        "tokens": [
          50852,
          512,
          22080,
          12,
          22864,
          11,
          51000
        ]
      },
      {
        "avg_logprob": -0.25486726849992697,
        "compression_ratio": 1.5701754385964912,
        "end": 548.8,
        "id": 195,
        "no_speech_prob": 0.00002014560050156433,
        "seek": 53226,
        "start": 547.7,
        "temperature": 0,
        "text": " and I'm hopefully going to have guests",
        "tokens": [
          51136,
          293,
          286,
          478,
          4696,
          516,
          281,
          362,
          9804,
          51191
        ]
      },
      {
        "avg_logprob": -0.25486726849992697,
        "compression_ratio": 1.5701754385964912,
        "end": 550.02,
        "id": 196,
        "no_speech_prob": 0.00002014560050156433,
        "seek": 53226,
        "start": 548.8,
        "temperature": 0,
        "text": " come and do these with me.",
        "tokens": [
          51191,
          808,
          293,
          360,
          613,
          365,
          385,
          13,
          51252
        ]
      },
      {
        "avg_logprob": -0.25486726849992697,
        "compression_ratio": 1.5701754385964912,
        "end": 551.86,
        "id": 197,
        "no_speech_prob": 0.00002014560050156433,
        "seek": 53226,
        "start": 550.02,
        "temperature": 0,
        "text": " Maybe somebody who's watching this right now",
        "tokens": [
          51252,
          2704,
          2618,
          567,
          311,
          1976,
          341,
          558,
          586,
          51344
        ]
      },
      {
        "avg_logprob": -0.25486726849992697,
        "compression_ratio": 1.5701754385964912,
        "end": 553.26,
        "id": 198,
        "no_speech_prob": 0.00002014560050156433,
        "seek": 53226,
        "start": 551.86,
        "temperature": 0,
        "text": " who's worked on this ML5 project",
        "tokens": [
          51344,
          567,
          311,
          2732,
          322,
          341,
          21601,
          20,
          1716,
          51414
        ]
      },
      {
        "avg_logprob": -0.25486726849992697,
        "compression_ratio": 1.5701754385964912,
        "end": 554.14,
        "id": 199,
        "no_speech_prob": 0.00002014560050156433,
        "seek": 53226,
        "start": 553.26,
        "temperature": 0,
        "text": " would like to come.",
        "tokens": [
          51414,
          576,
          411,
          281,
          808,
          13,
          51458
        ]
      },
      {
        "avg_logprob": -0.25486726849992697,
        "compression_ratio": 1.5701754385964912,
        "end": 556.34,
        "id": 200,
        "no_speech_prob": 0.00002014560050156433,
        "seek": 53226,
        "start": 554.14,
        "temperature": 0,
        "text": " Beginner-friendly ML",
        "tokens": [
          51458,
          20660,
          1193,
          12,
          22864,
          21601,
          51568
        ]
      },
      {
        "avg_logprob": -0.5505105699811663,
        "compression_ratio": 1.606837606837607,
        "end": 562.34,
        "id": 201,
        "no_speech_prob": 0.00002627471440064255,
        "seek": 55634,
        "start": 557.34,
        "temperature": 0,
        "text": " with some hearts and some stars,",
        "tokens": [
          50414,
          365,
          512,
          8852,
          293,
          512,
          6105,
          11,
          50664
        ]
      },
      {
        "avg_logprob": -0.5505105699811663,
        "compression_ratio": 1.606837606837607,
        "end": 566.1,
        "id": 202,
        "no_speech_prob": 0.00002627471440064255,
        "seek": 55634,
        "start": 562.86,
        "temperature": 0,
        "text": " like a little rainbow.",
        "tokens": [
          50690,
          411,
          257,
          707,
          18526,
          13,
          50852
        ]
      },
      {
        "avg_logprob": -0.5505105699811663,
        "compression_ratio": 1.606837606837607,
        "end": 571.58,
        "id": 203,
        "no_speech_prob": 0.00002627471440064255,
        "seek": 55634,
        "start": 567.5,
        "temperature": 0,
        "text": " And then there's a train going by.",
        "tokens": [
          50922,
          400,
          550,
          456,
          311,
          257,
          3847,
          516,
          538,
          13,
          51126
        ]
      },
      {
        "avg_logprob": -0.5505105699811663,
        "compression_ratio": 1.606837606837607,
        "end": 572.9200000000001,
        "id": 204,
        "no_speech_prob": 0.00002627471440064255,
        "seek": 55634,
        "start": 571.58,
        "temperature": 0,
        "text": " I can't draw a train.",
        "tokens": [
          51126,
          286,
          393,
          380,
          2642,
          257,
          3847,
          13,
          51193
        ]
      },
      {
        "avg_logprob": -0.5505105699811663,
        "compression_ratio": 1.606837606837607,
        "end": 573.76,
        "id": 205,
        "no_speech_prob": 0.00002627471440064255,
        "seek": 55634,
        "start": 572.9200000000001,
        "temperature": 0,
        "text": " Oh yeah.",
        "tokens": [
          51193,
          876,
          1338,
          13,
          51235
        ]
      },
      {
        "avg_logprob": -0.5505105699811663,
        "compression_ratio": 1.606837606837607,
        "end": 578.76,
        "id": 206,
        "no_speech_prob": 0.00002627471440064255,
        "seek": 55634,
        "start": 573.76,
        "temperature": 0,
        "text": " Da da da da da da da da da da da da da da da da da da.",
        "tokens": [
          51235,
          3933,
          1120,
          1120,
          1120,
          1120,
          1120,
          1120,
          1120,
          1120,
          1120,
          1120,
          1120,
          1120,
          1120,
          1120,
          1120,
          1120,
          1120,
          13,
          51485
        ]
      },
      {
        "avg_logprob": -0.5505105699811663,
        "compression_ratio": 1.606837606837607,
        "end": 581.94,
        "id": 207,
        "no_speech_prob": 0.00002627471440064255,
        "seek": 55634,
        "start": 581.1,
        "temperature": 0,
        "text": " Yeah, okay.",
        "tokens": [
          51602,
          865,
          11,
          1392,
          13,
          51644
        ]
      },
      {
        "avg_logprob": -0.2737524668375651,
        "compression_ratio": 1.4607843137254901,
        "end": 587.4200000000001,
        "id": 208,
        "no_speech_prob": 0.0006771827465854585,
        "seek": 58194,
        "start": 582.4200000000001,
        "temperature": 0,
        "text": " And with a library called ml5.js.",
        "tokens": [
          50388,
          400,
          365,
          257,
          6405,
          1219,
          23271,
          20,
          13,
          25530,
          13,
          50638
        ]
      },
      {
        "avg_logprob": -0.2737524668375651,
        "compression_ratio": 1.4607843137254901,
        "end": 591.9000000000001,
        "id": 209,
        "no_speech_prob": 0.0006771827465854585,
        "seek": 58194,
        "start": 590.1,
        "temperature": 0,
        "text": " So I'm going to come back to this in a second.",
        "tokens": [
          50772,
          407,
          286,
          478,
          516,
          281,
          808,
          646,
          281,
          341,
          294,
          257,
          1150,
          13,
          50862
        ]
      },
      {
        "avg_logprob": -0.2737524668375651,
        "compression_ratio": 1.4607843137254901,
        "end": 593.9000000000001,
        "id": 210,
        "no_speech_prob": 0.0006771827465854585,
        "seek": 58194,
        "start": 591.9000000000001,
        "temperature": 0,
        "text": " So just briefly, let me just show you.",
        "tokens": [
          50862,
          407,
          445,
          10515,
          11,
          718,
          385,
          445,
          855,
          291,
          13,
          50962
        ]
      },
      {
        "avg_logprob": -0.2737524668375651,
        "compression_ratio": 1.4607843137254901,
        "end": 599.94,
        "id": 211,
        "no_speech_prob": 0.0006771827465854585,
        "seek": 58194,
        "start": 596.7,
        "temperature": 0,
        "text": " Uke.js, that's a great idea for a...",
        "tokens": [
          51102,
          624,
          330,
          13,
          25530,
          11,
          300,
          311,
          257,
          869,
          1558,
          337,
          257,
          485,
          51264
        ]
      },
      {
        "avg_logprob": -0.2737524668375651,
        "compression_ratio": 1.4607843137254901,
        "end": 602.22,
        "id": 212,
        "no_speech_prob": 0.0006771827465854585,
        "seek": 58194,
        "start": 599.94,
        "temperature": 0,
        "text": " So if you go right now on the internet",
        "tokens": [
          51264,
          407,
          498,
          291,
          352,
          558,
          586,
          322,
          264,
          4705,
          51378
        ]
      },
      {
        "avg_logprob": -0.2737524668375651,
        "compression_ratio": 1.4607843137254901,
        "end": 606.86,
        "id": 213,
        "no_speech_prob": 0.0006771827465854585,
        "seek": 58194,
        "start": 602.22,
        "temperature": 0,
        "text": " to a URL, ml5js.org,",
        "tokens": [
          51378,
          281,
          257,
          12905,
          11,
          23271,
          20,
          25530,
          13,
          4646,
          11,
          51610
        ]
      },
      {
        "avg_logprob": -0.2737524668375651,
        "compression_ratio": 1.4607843137254901,
        "end": 610.22,
        "id": 214,
        "no_speech_prob": 0.0006771827465854585,
        "seek": 58194,
        "start": 607.98,
        "temperature": 0,
        "text": " you will find this website.",
        "tokens": [
          51666,
          291,
          486,
          915,
          341,
          3144,
          13,
          51778
        ]
      },
      {
        "avg_logprob": -0.2737524668375651,
        "compression_ratio": 1.4607843137254901,
        "end": 611.0600000000001,
        "id": 215,
        "no_speech_prob": 0.0006771827465854585,
        "seek": 58194,
        "start": 610.22,
        "temperature": 0,
        "text": " This is going to be fun.",
        "tokens": [
          51778,
          639,
          307,
          516,
          281,
          312,
          1019,
          13,
          51820
        ]
      },
      {
        "avg_logprob": -0.2737524668375651,
        "compression_ratio": 1.4607843137254901,
        "end": 611.8800000000001,
        "id": 216,
        "no_speech_prob": 0.0006771827465854585,
        "seek": 58194,
        "start": 611.0600000000001,
        "temperature": 0,
        "text": " Let's do something fun here.",
        "tokens": [
          51820,
          961,
          311,
          360,
          746,
          1019,
          510,
          13,
          51861
        ]
      },
      {
        "avg_logprob": -0.31721321890287313,
        "compression_ratio": 1.4605263157894737,
        "end": 613.8,
        "id": 217,
        "no_speech_prob": 0.00008092710777418688,
        "seek": 61188,
        "start": 612.82,
        "temperature": 0,
        "text": " So what you'll see right here on the homepage",
        "tokens": [
          50411,
          407,
          437,
          291,
          603,
          536,
          558,
          510,
          322,
          264,
          31301,
          50460
        ]
      },
      {
        "avg_logprob": -0.31721321890287313,
        "compression_ratio": 1.4605263157894737,
        "end": 616.34,
        "id": 218,
        "no_speech_prob": 0.00008092710777418688,
        "seek": 61188,
        "start": 613.8,
        "temperature": 0,
        "text": " is this interactive demonstration.",
        "tokens": [
          50460,
          307,
          341,
          15141,
          16520,
          13,
          50587
        ]
      },
      {
        "avg_logprob": -0.31721321890287313,
        "compression_ratio": 1.4605263157894737,
        "end": 618.8,
        "id": 219,
        "no_speech_prob": 0.00008092710777418688,
        "seek": 61188,
        "start": 616.34,
        "temperature": 0,
        "text": " This is a picture of a robin,",
        "tokens": [
          50587,
          639,
          307,
          257,
          3036,
          295,
          257,
          3870,
          259,
          11,
          50710
        ]
      },
      {
        "avg_logprob": -0.31721321890287313,
        "compression_ratio": 1.4605263157894737,
        "end": 622.76,
        "id": 220,
        "no_speech_prob": 0.00008092710777418688,
        "seek": 61188,
        "start": 618.8,
        "temperature": 0,
        "text": " which the MobileNet model labeled this as a robin,",
        "tokens": [
          50710,
          597,
          264,
          22625,
          31890,
          2316,
          21335,
          341,
          382,
          257,
          3870,
          259,
          11,
          50908
        ]
      },
      {
        "avg_logprob": -0.31721321890287313,
        "compression_ratio": 1.4605263157894737,
        "end": 625.32,
        "id": 221,
        "no_speech_prob": 0.00008092710777418688,
        "seek": 61188,
        "start": 622.76,
        "temperature": 0,
        "text": " American robin, Turtis migratorious,",
        "tokens": [
          50908,
          2665,
          3870,
          259,
          11,
          314,
          6224,
          271,
          6186,
          19802,
          851,
          11,
          51036
        ]
      },
      {
        "avg_logprob": -0.31721321890287313,
        "compression_ratio": 1.4605263157894737,
        "end": 628.2,
        "id": 222,
        "no_speech_prob": 0.00008092710777418688,
        "seek": 61188,
        "start": 625.32,
        "temperature": 0,
        "text": " with a confidence of 98.77%.",
        "tokens": [
          51036,
          365,
          257,
          6687,
          295,
          20860,
          13,
          17512,
          6856,
          51180
        ]
      },
      {
        "avg_logprob": -0.31721321890287313,
        "compression_ratio": 1.4605263157894737,
        "end": 630.64,
        "id": 223,
        "no_speech_prob": 0.00008092710777418688,
        "seek": 61188,
        "start": 628.2,
        "temperature": 0,
        "text": " So now I'm going to upload an image.",
        "tokens": [
          51180,
          407,
          586,
          286,
          478,
          516,
          281,
          6580,
          364,
          3256,
          13,
          51302
        ]
      },
      {
        "avg_logprob": -0.31721321890287313,
        "compression_ratio": 1.4605263157894737,
        "end": 631.76,
        "id": 224,
        "no_speech_prob": 0.00008092710777418688,
        "seek": 61188,
        "start": 630.64,
        "temperature": 0,
        "text": " Do I have any images here?",
        "tokens": [
          51302,
          1144,
          286,
          362,
          604,
          5267,
          510,
          30,
          51358
        ]
      },
      {
        "avg_logprob": -0.31721321890287313,
        "compression_ratio": 1.4605263157894737,
        "end": 633.4399999999999,
        "id": 225,
        "no_speech_prob": 0.00008092710777418688,
        "seek": 61188,
        "start": 631.76,
        "temperature": 0,
        "text": " This is, hold on.",
        "tokens": [
          51358,
          639,
          307,
          11,
          1797,
          322,
          13,
          51442
        ]
      },
      {
        "avg_logprob": -0.31721321890287313,
        "compression_ratio": 1.4605263157894737,
        "end": 637.76,
        "id": 226,
        "no_speech_prob": 0.00008092710777418688,
        "seek": 61188,
        "start": 633.4399999999999,
        "temperature": 0,
        "text": " Let's go get a rainbow.",
        "tokens": [
          51442,
          961,
          311,
          352,
          483,
          257,
          18526,
          13,
          51658
        ]
      },
      {
        "avg_logprob": -0.6638953776299199,
        "compression_ratio": 1.4388489208633093,
        "end": 639.04,
        "id": 227,
        "no_speech_prob": 0.00018813798669725657,
        "seek": 63776,
        "start": 638.2,
        "temperature": 0,
        "text": " Images.",
        "tokens": [
          50386,
          4331,
          1660,
          13,
          50428
        ]
      },
      {
        "avg_logprob": -0.6638953776299199,
        "compression_ratio": 1.4388489208633093,
        "end": 641.04,
        "id": 228,
        "no_speech_prob": 0.00018813798669725657,
        "seek": 63776,
        "start": 640.2,
        "temperature": 0,
        "text": " This looks good.",
        "tokens": [
          50486,
          639,
          1542,
          665,
          13,
          50528
        ]
      },
      {
        "avg_logprob": -0.6638953776299199,
        "compression_ratio": 1.4388489208633093,
        "end": 643.2,
        "id": 229,
        "no_speech_prob": 0.00018813798669725657,
        "seek": 63776,
        "start": 642.36,
        "temperature": 0,
        "text": " Download.",
        "tokens": [
          50594,
          32282,
          13,
          50636
        ]
      },
      {
        "avg_logprob": -0.6638953776299199,
        "compression_ratio": 1.4388489208633093,
        "end": 644.6,
        "id": 230,
        "no_speech_prob": 0.00018813798669725657,
        "seek": 63776,
        "start": 643.2,
        "temperature": 0,
        "text": " Oh, I should have done a train.",
        "tokens": [
          50636,
          876,
          11,
          286,
          820,
          362,
          1096,
          257,
          3847,
          13,
          50706
        ]
      },
      {
        "avg_logprob": -0.6638953776299199,
        "compression_ratio": 1.4388489208633093,
        "end": 649.12,
        "id": 231,
        "no_speech_prob": 0.00018813798669725657,
        "seek": 63776,
        "start": 646.12,
        "temperature": 0,
        "text": " Let's try rainbow.jpg.",
        "tokens": [
          50782,
          961,
          311,
          853,
          18526,
          13,
          73,
          49861,
          13,
          50932
        ]
      },
      {
        "avg_logprob": -0.6638953776299199,
        "compression_ratio": 1.4388489208633093,
        "end": 652.84,
        "id": 232,
        "no_speech_prob": 0.00018813798669725657,
        "seek": 63776,
        "start": 652,
        "temperature": 0,
        "text": " Where am I going?",
        "tokens": [
          51076,
          2305,
          669,
          286,
          516,
          30,
          51118
        ]
      },
      {
        "avg_logprob": -0.6638953776299199,
        "compression_ratio": 1.4388489208633093,
        "end": 654.64,
        "id": 233,
        "no_speech_prob": 0.00018813798669725657,
        "seek": 63776,
        "start": 652.84,
        "temperature": 0,
        "text": " Desktop, that looks good.",
        "tokens": [
          51118,
          49044,
          11,
          300,
          1542,
          665,
          13,
          51208
        ]
      },
      {
        "avg_logprob": -0.6638953776299199,
        "compression_ratio": 1.4388489208633093,
        "end": 656.08,
        "id": 234,
        "no_speech_prob": 0.00018813798669725657,
        "seek": 63776,
        "start": 654.64,
        "temperature": 0,
        "text": " Let's go for a train.",
        "tokens": [
          51208,
          961,
          311,
          352,
          337,
          257,
          3847,
          13,
          51280
        ]
      },
      {
        "avg_logprob": -0.6638953776299199,
        "compression_ratio": 1.4388489208633093,
        "end": 661.2,
        "id": 235,
        "no_speech_prob": 0.00018813798669725657,
        "seek": 63776,
        "start": 660.36,
        "temperature": 0,
        "text": " This one looks good.",
        "tokens": [
          51494,
          639,
          472,
          1542,
          665,
          13,
          51536
        ]
      },
      {
        "avg_logprob": -0.6638953776299199,
        "compression_ratio": 1.4388489208633093,
        "end": 664.3199999999999,
        "id": 236,
        "no_speech_prob": 0.00018813798669725657,
        "seek": 63776,
        "start": 661.2,
        "temperature": 0,
        "text": " Oh, save images.",
        "tokens": [
          51536,
          876,
          11,
          3155,
          5267,
          13,
          51692
        ]
      },
      {
        "avg_logprob": -0.6638953776299199,
        "compression_ratio": 1.4388489208633093,
        "end": 665.16,
        "id": 237,
        "no_speech_prob": 0.00018813798669725657,
        "seek": 63776,
        "start": 664.3199999999999,
        "temperature": 0,
        "text": " Train.",
        "tokens": [
          51692,
          28029,
          13,
          51734
        ]
      },
      {
        "avg_logprob": -0.23635747411229588,
        "compression_ratio": 1.6091370558375635,
        "end": 668.6,
        "id": 238,
        "no_speech_prob": 0.00033015129156410694,
        "seek": 66776,
        "start": 667.76,
        "temperature": 0,
        "text": " Train.",
        "tokens": [
          50364,
          28029,
          13,
          50406
        ]
      },
      {
        "avg_logprob": -0.23635747411229588,
        "compression_ratio": 1.6091370558375635,
        "end": 673.2,
        "id": 239,
        "no_speech_prob": 0.00033015129156410694,
        "seek": 66776,
        "start": 670.4,
        "temperature": 0,
        "text": " Let's go back to the ml5 webpage,",
        "tokens": [
          50496,
          961,
          311,
          352,
          646,
          281,
          264,
          23271,
          20,
          37852,
          11,
          50636
        ]
      },
      {
        "avg_logprob": -0.23635747411229588,
        "compression_ratio": 1.6091370558375635,
        "end": 674.04,
        "id": 240,
        "no_speech_prob": 0.00033015129156410694,
        "seek": 66776,
        "start": 673.2,
        "temperature": 0,
        "text": " and what I'm going to do,",
        "tokens": [
          50636,
          293,
          437,
          286,
          478,
          516,
          281,
          360,
          11,
          50678
        ]
      },
      {
        "avg_logprob": -0.23635747411229588,
        "compression_ratio": 1.6091370558375635,
        "end": 674.86,
        "id": 241,
        "no_speech_prob": 0.00033015129156410694,
        "seek": 66776,
        "start": 674.04,
        "temperature": 0,
        "text": " I could drag and drop it,",
        "tokens": [
          50678,
          286,
          727,
          5286,
          293,
          3270,
          309,
          11,
          50719
        ]
      },
      {
        "avg_logprob": -0.23635747411229588,
        "compression_ratio": 1.6091370558375635,
        "end": 675.7,
        "id": 242,
        "no_speech_prob": 0.00033015129156410694,
        "seek": 66776,
        "start": 674.86,
        "temperature": 0,
        "text": " but I'm just going to do this.",
        "tokens": [
          50719,
          457,
          286,
          478,
          445,
          516,
          281,
          360,
          341,
          13,
          50761
        ]
      },
      {
        "avg_logprob": -0.23635747411229588,
        "compression_ratio": 1.6091370558375635,
        "end": 677.04,
        "id": 243,
        "no_speech_prob": 0.00033015129156410694,
        "seek": 66776,
        "start": 675.7,
        "temperature": 0,
        "text": " Let's try, whoops.",
        "tokens": [
          50761,
          961,
          311,
          853,
          11,
          567,
          3370,
          13,
          50828
        ]
      },
      {
        "avg_logprob": -0.23635747411229588,
        "compression_ratio": 1.6091370558375635,
        "end": 678.92,
        "id": 244,
        "no_speech_prob": 0.00033015129156410694,
        "seek": 66776,
        "start": 677.04,
        "temperature": 0,
        "text": " Let's try the,",
        "tokens": [
          50828,
          961,
          311,
          853,
          264,
          11,
          50922
        ]
      },
      {
        "avg_logprob": -0.23635747411229588,
        "compression_ratio": 1.6091370558375635,
        "end": 682.52,
        "id": 245,
        "no_speech_prob": 0.00033015129156410694,
        "seek": 66776,
        "start": 681.48,
        "temperature": 0,
        "text": " a train.",
        "tokens": [
          51050,
          257,
          3847,
          13,
          51102
        ]
      },
      {
        "avg_logprob": -0.23635747411229588,
        "compression_ratio": 1.6091370558375635,
        "end": 687.64,
        "id": 246,
        "no_speech_prob": 0.00033015129156410694,
        "seek": 66776,
        "start": 685.56,
        "temperature": 0,
        "text": " Trailer truck, tractor trailer, trucking rig,",
        "tokens": [
          51254,
          5403,
          5441,
          5898,
          11,
          31857,
          11724,
          11,
          5898,
          278,
          8329,
          11,
          51358
        ]
      },
      {
        "avg_logprob": -0.23635747411229588,
        "compression_ratio": 1.6091370558375635,
        "end": 690.24,
        "id": 247,
        "no_speech_prob": 0.00033015129156410694,
        "seek": 66776,
        "start": 687.64,
        "temperature": 0,
        "text": " rig articulated lorry,",
        "tokens": [
          51358,
          8329,
          43322,
          287,
          2005,
          11,
          51488
        ]
      },
      {
        "avg_logprob": -0.23635747411229588,
        "compression_ratio": 1.6091370558375635,
        "end": 693.88,
        "id": 248,
        "no_speech_prob": 0.00033015129156410694,
        "seek": 66776,
        "start": 690.24,
        "temperature": 0,
        "text": " semi with a confidence of 42.94%.",
        "tokens": [
          51488,
          12909,
          365,
          257,
          6687,
          295,
          14034,
          13,
          27032,
          6856,
          51670
        ]
      },
      {
        "avg_logprob": -0.23635747411229588,
        "compression_ratio": 1.6091370558375635,
        "end": 696.88,
        "id": 249,
        "no_speech_prob": 0.00033015129156410694,
        "seek": 66776,
        "start": 693.88,
        "temperature": 0,
        "text": " Let's try doing the dragging and dropping thing",
        "tokens": [
          51670,
          961,
          311,
          853,
          884,
          264,
          24385,
          293,
          13601,
          551,
          51820
        ]
      },
      {
        "avg_logprob": -0.21164564049762227,
        "compression_ratio": 1.5573122529644268,
        "end": 698.28,
        "id": 250,
        "no_speech_prob": 0.000015689540305174887,
        "seek": 69688,
        "start": 696.88,
        "temperature": 0,
        "text": " with the rainbow.",
        "tokens": [
          50364,
          365,
          264,
          18526,
          13,
          50434
        ]
      },
      {
        "avg_logprob": -0.21164564049762227,
        "compression_ratio": 1.5573122529644268,
        "end": 699.32,
        "id": 251,
        "no_speech_prob": 0.000015689540305174887,
        "seek": 69688,
        "start": 698.28,
        "temperature": 0,
        "text": " Bring it over here,",
        "tokens": [
          50434,
          12842,
          309,
          670,
          510,
          11,
          50486
        ]
      },
      {
        "avg_logprob": -0.21164564049762227,
        "compression_ratio": 1.5573122529644268,
        "end": 702.36,
        "id": 252,
        "no_speech_prob": 0.000015689540305174887,
        "seek": 69688,
        "start": 699.32,
        "temperature": 0,
        "text": " and now we have a parachute shoot",
        "tokens": [
          50486,
          293,
          586,
          321,
          362,
          257,
          44665,
          3076,
          50638
        ]
      },
      {
        "avg_logprob": -0.21164564049762227,
        "compression_ratio": 1.5573122529644268,
        "end": 704.72,
        "id": 253,
        "no_speech_prob": 0.000015689540305174887,
        "seek": 69688,
        "start": 702.36,
        "temperature": 0,
        "text": " with a confidence of 49.29%.",
        "tokens": [
          50638,
          365,
          257,
          6687,
          295,
          16513,
          13,
          11871,
          6856,
          50756
        ]
      },
      {
        "avg_logprob": -0.21164564049762227,
        "compression_ratio": 1.5573122529644268,
        "end": 706.76,
        "id": 254,
        "no_speech_prob": 0.000015689540305174887,
        "seek": 69688,
        "start": 704.72,
        "temperature": 0,
        "text": " So, how does this work?",
        "tokens": [
          50756,
          407,
          11,
          577,
          775,
          341,
          589,
          30,
          50858
        ]
      },
      {
        "avg_logprob": -0.21164564049762227,
        "compression_ratio": 1.5573122529644268,
        "end": 709.34,
        "id": 255,
        "no_speech_prob": 0.000015689540305174887,
        "seek": 69688,
        "start": 706.76,
        "temperature": 0,
        "text": " Well, I will show you if you scroll down here,",
        "tokens": [
          50858,
          1042,
          11,
          286,
          486,
          855,
          291,
          498,
          291,
          11369,
          760,
          510,
          11,
          50987
        ]
      },
      {
        "avg_logprob": -0.21164564049762227,
        "compression_ratio": 1.5573122529644268,
        "end": 713.88,
        "id": 256,
        "no_speech_prob": 0.000015689540305174887,
        "seek": 69688,
        "start": 709.34,
        "temperature": 0,
        "text": " you will see here is the code for such a thing.",
        "tokens": [
          50987,
          291,
          486,
          536,
          510,
          307,
          264,
          3089,
          337,
          1270,
          257,
          551,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.21164564049762227,
        "compression_ratio": 1.5573122529644268,
        "end": 718.52,
        "id": 257,
        "no_speech_prob": 0.000015689540305174887,
        "seek": 69688,
        "start": 713.88,
        "temperature": 0,
        "text": " And so, the ml5 library is a machine learning library",
        "tokens": [
          51214,
          400,
          370,
          11,
          264,
          23271,
          20,
          6405,
          307,
          257,
          3479,
          2539,
          6405,
          51446
        ]
      },
      {
        "avg_logprob": -0.21164564049762227,
        "compression_ratio": 1.5573122529644268,
        "end": 721,
        "id": 258,
        "no_speech_prob": 0.000015689540305174887,
        "seek": 69688,
        "start": 718.52,
        "temperature": 0,
        "text": " built on top of TensorFlow.js.",
        "tokens": [
          51446,
          3094,
          322,
          1192,
          295,
          37624,
          13,
          25530,
          13,
          51570
        ]
      },
      {
        "avg_logprob": -0.21164564049762227,
        "compression_ratio": 1.5573122529644268,
        "end": 722.96,
        "id": 259,
        "no_speech_prob": 0.000015689540305174887,
        "seek": 69688,
        "start": 721,
        "temperature": 0,
        "text": " This library would not at all be possible",
        "tokens": [
          51570,
          639,
          6405,
          576,
          406,
          412,
          439,
          312,
          1944,
          51668
        ]
      },
      {
        "avg_logprob": -0.21164564049762227,
        "compression_ratio": 1.5573122529644268,
        "end": 726.04,
        "id": 260,
        "no_speech_prob": 0.000015689540305174887,
        "seek": 69688,
        "start": 722.96,
        "temperature": 0,
        "text": " without TensorFlow.js running behind the scenes",
        "tokens": [
          51668,
          1553,
          37624,
          13,
          25530,
          2614,
          2261,
          264,
          8026,
          51822
        ]
      },
      {
        "avg_logprob": -0.2991429913428522,
        "compression_ratio": 1.6414342629482073,
        "end": 729.24,
        "id": 261,
        "no_speech_prob": 0.00031503671198152006,
        "seek": 72604,
        "start": 726.04,
        "temperature": 0,
        "text": " to try to create some simple code examples",
        "tokens": [
          50364,
          281,
          853,
          281,
          1884,
          512,
          2199,
          3089,
          5110,
          50524
        ]
      },
      {
        "avg_logprob": -0.2991429913428522,
        "compression_ratio": 1.6414342629482073,
        "end": 730.5,
        "id": 262,
        "no_speech_prob": 0.00031503671198152006,
        "seek": 72604,
        "start": 729.24,
        "temperature": 0,
        "text": " to work with, at the moment,",
        "tokens": [
          50524,
          281,
          589,
          365,
          11,
          412,
          264,
          1623,
          11,
          50587
        ]
      },
      {
        "avg_logprob": -0.2991429913428522,
        "compression_ratio": 1.6414342629482073,
        "end": 732.9399999999999,
        "id": 263,
        "no_speech_prob": 0.00031503671198152006,
        "seek": 72604,
        "start": 730.5,
        "temperature": 0,
        "text": " mostly pre-trained models in the browser.",
        "tokens": [
          50587,
          5240,
          659,
          12,
          17227,
          2001,
          5245,
          294,
          264,
          11185,
          13,
          50709
        ]
      },
      {
        "avg_logprob": -0.2991429913428522,
        "compression_ratio": 1.6414342629482073,
        "end": 734.52,
        "id": 264,
        "no_speech_prob": 0.00031503671198152006,
        "seek": 72604,
        "start": 732.9399999999999,
        "temperature": 0,
        "text": " And there's lots more coming here,",
        "tokens": [
          50709,
          400,
          456,
          311,
          3195,
          544,
          1348,
          510,
          11,
          50788
        ]
      },
      {
        "avg_logprob": -0.2991429913428522,
        "compression_ratio": 1.6414342629482073,
        "end": 736.38,
        "id": 265,
        "no_speech_prob": 0.00031503671198152006,
        "seek": 72604,
        "start": 734.52,
        "temperature": 0,
        "text": " and I'm going to do a bunch of tutorials with this.",
        "tokens": [
          50788,
          293,
          286,
          478,
          516,
          281,
          360,
          257,
          3840,
          295,
          17616,
          365,
          341,
          13,
          50881
        ]
      },
      {
        "avg_logprob": -0.2991429913428522,
        "compression_ratio": 1.6414342629482073,
        "end": 737.5999999999999,
        "id": 266,
        "no_speech_prob": 0.00031503671198152006,
        "seek": 72604,
        "start": 736.38,
        "temperature": 0,
        "text": " But this project is,",
        "tokens": [
          50881,
          583,
          341,
          1716,
          307,
          11,
          50942
        ]
      },
      {
        "avg_logprob": -0.2991429913428522,
        "compression_ratio": 1.6414342629482073,
        "end": 739.78,
        "id": 267,
        "no_speech_prob": 0.00031503671198152006,
        "seek": 72604,
        "start": 737.5999999999999,
        "temperature": 0,
        "text": " I'm mentioning it now because Hannah Davis",
        "tokens": [
          50942,
          286,
          478,
          18315,
          309,
          586,
          570,
          21754,
          15658,
          51051
        ]
      },
      {
        "avg_logprob": -0.2991429913428522,
        "compression_ratio": 1.6414342629482073,
        "end": 741.9599999999999,
        "id": 268,
        "no_speech_prob": 0.00031503671198152006,
        "seek": 72604,
        "start": 739.78,
        "temperature": 0,
        "text": " at the I-O Festival,",
        "tokens": [
          51051,
          412,
          264,
          286,
          12,
          46,
          16512,
          11,
          51160
        ]
      },
      {
        "avg_logprob": -0.2991429913428522,
        "compression_ratio": 1.6414342629482073,
        "end": 743.86,
        "id": 269,
        "no_speech_prob": 0.00031503671198152006,
        "seek": 72604,
        "start": 741.9599999999999,
        "temperature": 0,
        "text": " totally not in the Slack channel here,",
        "tokens": [
          51160,
          3879,
          406,
          294,
          264,
          37211,
          2269,
          510,
          11,
          51255
        ]
      },
      {
        "avg_logprob": -0.2991429913428522,
        "compression_ratio": 1.6414342629482073,
        "end": 749.64,
        "id": 270,
        "no_speech_prob": 0.00031503671198152006,
        "seek": 72604,
        "start": 748.4,
        "temperature": 0,
        "text": " at the I-O Festival,",
        "tokens": [
          51482,
          412,
          264,
          286,
          12,
          46,
          16512,
          11,
          51544
        ]
      },
      {
        "avg_logprob": -0.2991429913428522,
        "compression_ratio": 1.6414342629482073,
        "end": 753.28,
        "id": 271,
        "no_speech_prob": 0.00031503671198152006,
        "seek": 72604,
        "start": 751.04,
        "temperature": 0,
        "text": " talked about ml5 in her presentation.",
        "tokens": [
          51614,
          2825,
          466,
          23271,
          20,
          294,
          720,
          5860,
          13,
          51726
        ]
      },
      {
        "avg_logprob": -0.2991429913428522,
        "compression_ratio": 1.6414342629482073,
        "end": 754.66,
        "id": 272,
        "no_speech_prob": 0.00031503671198152006,
        "seek": 72604,
        "start": 753.28,
        "temperature": 0,
        "text": " Hopefully, the I-O Festival,",
        "tokens": [
          51726,
          10429,
          11,
          264,
          286,
          12,
          46,
          16512,
          11,
          51795
        ]
      },
      {
        "avg_logprob": -0.22312962786751503,
        "compression_ratio": 1.6927710843373494,
        "end": 756.62,
        "id": 273,
        "no_speech_prob": 0.006095999386161566,
        "seek": 75466,
        "start": 755.3399999999999,
        "temperature": 0,
        "text": " just finished up in Minneapolis.",
        "tokens": [
          50398,
          445,
          4335,
          493,
          294,
          38713,
          13,
          50462
        ]
      },
      {
        "avg_logprob": -0.22312962786751503,
        "compression_ratio": 1.6927710843373494,
        "end": 759.38,
        "id": 274,
        "no_speech_prob": 0.006095999386161566,
        "seek": 75466,
        "start": 756.62,
        "temperature": 0,
        "text": " The videos, all the talks there are amazing.",
        "tokens": [
          50462,
          440,
          2145,
          11,
          439,
          264,
          6686,
          456,
          366,
          2243,
          13,
          50600
        ]
      },
      {
        "avg_logprob": -0.22312962786751503,
        "compression_ratio": 1.6927710843373494,
        "end": 761.1,
        "id": 275,
        "no_speech_prob": 0.006095999386161566,
        "seek": 75466,
        "start": 759.38,
        "temperature": 0,
        "text": " Go find their Vimeo channel.",
        "tokens": [
          50600,
          1037,
          915,
          641,
          691,
          1312,
          78,
          2269,
          13,
          50686
        ]
      },
      {
        "avg_logprob": -0.22312962786751503,
        "compression_ratio": 1.6927710843373494,
        "end": 762.5,
        "id": 276,
        "no_speech_prob": 0.006095999386161566,
        "seek": 75466,
        "start": 761.1,
        "temperature": 0,
        "text": " And all the ones from last year you can watch,",
        "tokens": [
          50686,
          400,
          439,
          264,
          2306,
          490,
          1036,
          1064,
          291,
          393,
          1159,
          11,
          50756
        ]
      },
      {
        "avg_logprob": -0.22312962786751503,
        "compression_ratio": 1.6927710843373494,
        "end": 764.66,
        "id": 277,
        "no_speech_prob": 0.006095999386161566,
        "seek": 75466,
        "start": 762.5,
        "temperature": 0,
        "text": " and then the ones from this year will be out soon.",
        "tokens": [
          50756,
          293,
          550,
          264,
          2306,
          490,
          341,
          1064,
          486,
          312,
          484,
          2321,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.22312962786751503,
        "compression_ratio": 1.6927710843373494,
        "end": 766.98,
        "id": 278,
        "no_speech_prob": 0.006095999386161566,
        "seek": 75466,
        "start": 764.66,
        "temperature": 0,
        "text": " And we're looking at trying to launch this",
        "tokens": [
          50864,
          400,
          321,
          434,
          1237,
          412,
          1382,
          281,
          4025,
          341,
          50980
        ]
      },
      {
        "avg_logprob": -0.22312962786751503,
        "compression_ratio": 1.6927710843373494,
        "end": 768.78,
        "id": 279,
        "no_speech_prob": 0.006095999386161566,
        "seek": 75466,
        "start": 766.98,
        "temperature": 0,
        "text": " more officially on June 15th.",
        "tokens": [
          50980,
          544,
          12053,
          322,
          6928,
          2119,
          392,
          13,
          51070
        ]
      },
      {
        "avg_logprob": -0.22312962786751503,
        "compression_ratio": 1.6927710843373494,
        "end": 770.5799999999999,
        "id": 280,
        "no_speech_prob": 0.006095999386161566,
        "seek": 75466,
        "start": 768.78,
        "temperature": 0,
        "text": " And I will mention that if you're interested",
        "tokens": [
          51070,
          400,
          286,
          486,
          2152,
          300,
          498,
          291,
          434,
          3102,
          51160
        ]
      },
      {
        "avg_logprob": -0.22312962786751503,
        "compression_ratio": 1.6927710843373494,
        "end": 772.1999999999999,
        "id": 281,
        "no_speech_prob": 0.006095999386161566,
        "seek": 75466,
        "start": 770.5799999999999,
        "temperature": 0,
        "text": " in kind of poking around,",
        "tokens": [
          51160,
          294,
          733,
          295,
          42684,
          926,
          11,
          51241
        ]
      },
      {
        "avg_logprob": -0.22312962786751503,
        "compression_ratio": 1.6927710843373494,
        "end": 773.98,
        "id": 282,
        "no_speech_prob": 0.006095999386161566,
        "seek": 75466,
        "start": 772.1999999999999,
        "temperature": 0,
        "text": " if you go to all of our GitHub repos,",
        "tokens": [
          51241,
          498,
          291,
          352,
          281,
          439,
          295,
          527,
          23331,
          1085,
          329,
          11,
          51330
        ]
      },
      {
        "avg_logprob": -0.22312962786751503,
        "compression_ratio": 1.6927710843373494,
        "end": 775.78,
        "id": 283,
        "no_speech_prob": 0.006095999386161566,
        "seek": 75466,
        "start": 773.98,
        "temperature": 0,
        "text": " first, let me just go over here.",
        "tokens": [
          51330,
          700,
          11,
          718,
          385,
          445,
          352,
          670,
          510,
          13,
          51420
        ]
      },
      {
        "avg_logprob": -0.22312962786751503,
        "compression_ratio": 1.6927710843373494,
        "end": 778.06,
        "id": 284,
        "no_speech_prob": 0.006095999386161566,
        "seek": 75466,
        "start": 775.78,
        "temperature": 0,
        "text": " We can see here's all sorts of wonderful people",
        "tokens": [
          51420,
          492,
          393,
          536,
          510,
          311,
          439,
          7527,
          295,
          3715,
          561,
          51534
        ]
      },
      {
        "avg_logprob": -0.22312962786751503,
        "compression_ratio": 1.6927710843373494,
        "end": 780.12,
        "id": 285,
        "no_speech_prob": 0.006095999386161566,
        "seek": 75466,
        "start": 778.06,
        "temperature": 0,
        "text": " who have been working on this project,",
        "tokens": [
          51534,
          567,
          362,
          668,
          1364,
          322,
          341,
          1716,
          11,
          51637
        ]
      },
      {
        "avg_logprob": -0.22312962786751503,
        "compression_ratio": 1.6927710843373494,
        "end": 782.02,
        "id": 286,
        "no_speech_prob": 0.006095999386161566,
        "seek": 75466,
        "start": 780.12,
        "temperature": 0,
        "text": " more than just these 10 people,",
        "tokens": [
          51637,
          544,
          813,
          445,
          613,
          1266,
          561,
          11,
          51732
        ]
      },
      {
        "avg_logprob": -0.22312962786751503,
        "compression_ratio": 1.6927710843373494,
        "end": 783.22,
        "id": 287,
        "no_speech_prob": 0.006095999386161566,
        "seek": 75466,
        "start": 782.02,
        "temperature": 0,
        "text": " but here are 10 people.",
        "tokens": [
          51732,
          457,
          510,
          366,
          1266,
          561,
          13,
          51792
        ]
      },
      {
        "avg_logprob": -0.28524216818153314,
        "compression_ratio": 1.6401673640167365,
        "end": 788.6600000000001,
        "id": 288,
        "no_speech_prob": 0.000012805433470930438,
        "seek": 78322,
        "start": 784.22,
        "temperature": 0,
        "text": " And what I want to show you here is under projects,",
        "tokens": [
          50414,
          400,
          437,
          286,
          528,
          281,
          855,
          291,
          510,
          307,
          833,
          4455,
          11,
          50636
        ]
      },
      {
        "avg_logprob": -0.28524216818153314,
        "compression_ratio": 1.6401673640167365,
        "end": 792.14,
        "id": 289,
        "no_speech_prob": 0.000012805433470930438,
        "seek": 78322,
        "start": 788.6600000000001,
        "temperature": 0,
        "text": " this is my first foray into using",
        "tokens": [
          50636,
          341,
          307,
          452,
          700,
          337,
          320,
          666,
          1228,
          50810
        ]
      },
      {
        "avg_logprob": -0.28524216818153314,
        "compression_ratio": 1.6401673640167365,
        "end": 796.34,
        "id": 290,
        "no_speech_prob": 0.000012805433470930438,
        "seek": 78322,
        "start": 792.14,
        "temperature": 0,
        "text": " the project management tool that's part of GitHub.",
        "tokens": [
          50810,
          264,
          1716,
          4592,
          2290,
          300,
          311,
          644,
          295,
          23331,
          13,
          51020
        ]
      },
      {
        "avg_logprob": -0.28524216818153314,
        "compression_ratio": 1.6401673640167365,
        "end": 799.86,
        "id": 291,
        "no_speech_prob": 0.000012805433470930438,
        "seek": 78322,
        "start": 796.34,
        "temperature": 0,
        "text": " Did you know that Microsoft bought GitHub?",
        "tokens": [
          51020,
          2589,
          291,
          458,
          300,
          8116,
          4243,
          23331,
          30,
          51196
        ]
      },
      {
        "avg_logprob": -0.28524216818153314,
        "compression_ratio": 1.6401673640167365,
        "end": 801.78,
        "id": 292,
        "no_speech_prob": 0.000012805433470930438,
        "seek": 78322,
        "start": 799.86,
        "temperature": 0,
        "text": " Some people think that's a problem.",
        "tokens": [
          51196,
          2188,
          561,
          519,
          300,
          311,
          257,
          1154,
          13,
          51292
        ]
      },
      {
        "avg_logprob": -0.28524216818153314,
        "compression_ratio": 1.6401673640167365,
        "end": 803.34,
        "id": 293,
        "no_speech_prob": 0.000012805433470930438,
        "seek": 78322,
        "start": 801.78,
        "temperature": 0,
        "text": " Some people think it's great.",
        "tokens": [
          51292,
          2188,
          561,
          519,
          309,
          311,
          869,
          13,
          51370
        ]
      },
      {
        "avg_logprob": -0.28524216818153314,
        "compression_ratio": 1.6401673640167365,
        "end": 804.1600000000001,
        "id": 294,
        "no_speech_prob": 0.000012805433470930438,
        "seek": 78322,
        "start": 803.34,
        "temperature": 0,
        "text": " I don't know.",
        "tokens": [
          51370,
          286,
          500,
          380,
          458,
          13,
          51411
        ]
      },
      {
        "avg_logprob": -0.28524216818153314,
        "compression_ratio": 1.6401673640167365,
        "end": 807.14,
        "id": 295,
        "no_speech_prob": 0.000012805433470930438,
        "seek": 78322,
        "start": 804.1600000000001,
        "temperature": 0,
        "text": " I'm going to just keep using it for a little while longer",
        "tokens": [
          51411,
          286,
          478,
          516,
          281,
          445,
          1066,
          1228,
          309,
          337,
          257,
          707,
          1339,
          2854,
          51560
        ]
      },
      {
        "avg_logprob": -0.28524216818153314,
        "compression_ratio": 1.6401673640167365,
        "end": 809.62,
        "id": 296,
        "no_speech_prob": 0.000012805433470930438,
        "seek": 78322,
        "start": 807.14,
        "temperature": 0,
        "text": " until somebody tells me not to.",
        "tokens": [
          51560,
          1826,
          2618,
          5112,
          385,
          406,
          281,
          13,
          51684
        ]
      },
      {
        "avg_logprob": -0.28524216818153314,
        "compression_ratio": 1.6401673640167365,
        "end": 812.9,
        "id": 297,
        "no_speech_prob": 0.000012805433470930438,
        "seek": 78322,
        "start": 809.62,
        "temperature": 0,
        "text": " Okay, so, but this project management tool",
        "tokens": [
          51684,
          1033,
          11,
          370,
          11,
          457,
          341,
          1716,
          4592,
          2290,
          51848
        ]
      },
      {
        "avg_logprob": -0.2613249009655368,
        "compression_ratio": 1.739864864864865,
        "end": 814.4599999999999,
        "id": 298,
        "no_speech_prob": 0.0008830276201479137,
        "seek": 81290,
        "start": 813.5799999999999,
        "temperature": 0,
        "text": " is the first time I've used it.",
        "tokens": [
          50398,
          307,
          264,
          700,
          565,
          286,
          600,
          1143,
          309,
          13,
          50442
        ]
      },
      {
        "avg_logprob": -0.2613249009655368,
        "compression_ratio": 1.739864864864865,
        "end": 816.5799999999999,
        "id": 299,
        "no_speech_prob": 0.0008830276201479137,
        "seek": 81290,
        "start": 814.4599999999999,
        "temperature": 0,
        "text": " If anyone wants to jump on in and get involved",
        "tokens": [
          50442,
          759,
          2878,
          2738,
          281,
          3012,
          322,
          294,
          293,
          483,
          3288,
          50548
        ]
      },
      {
        "avg_logprob": -0.2613249009655368,
        "compression_ratio": 1.739864864864865,
        "end": 818.3199999999999,
        "id": 300,
        "no_speech_prob": 0.0008830276201479137,
        "seek": 81290,
        "start": 816.5799999999999,
        "temperature": 0,
        "text": " and kind of have a little sprint here",
        "tokens": [
          50548,
          293,
          733,
          295,
          362,
          257,
          707,
          25075,
          510,
          50635
        ]
      },
      {
        "avg_logprob": -0.2613249009655368,
        "compression_ratio": 1.739864864864865,
        "end": 819.6999999999999,
        "id": 301,
        "no_speech_prob": 0.0008830276201479137,
        "seek": 81290,
        "start": 818.3199999999999,
        "temperature": 0,
        "text": " from now until June 15th,",
        "tokens": [
          50635,
          490,
          586,
          1826,
          6928,
          2119,
          392,
          11,
          50704
        ]
      },
      {
        "avg_logprob": -0.2613249009655368,
        "compression_ratio": 1.739864864864865,
        "end": 820.98,
        "id": 302,
        "no_speech_prob": 0.0008830276201479137,
        "seek": 81290,
        "start": 819.6999999999999,
        "temperature": 0,
        "text": " there's a lot, if you look at that website,",
        "tokens": [
          50704,
          456,
          311,
          257,
          688,
          11,
          498,
          291,
          574,
          412,
          300,
          3144,
          11,
          50768
        ]
      },
      {
        "avg_logprob": -0.2613249009655368,
        "compression_ratio": 1.739864864864865,
        "end": 822.22,
        "id": 303,
        "no_speech_prob": 0.0008830276201479137,
        "seek": 81290,
        "start": 820.98,
        "temperature": 0,
        "text": " there's a lot of stuff that's missing.",
        "tokens": [
          50768,
          456,
          311,
          257,
          688,
          295,
          1507,
          300,
          311,
          5361,
          13,
          50830
        ]
      },
      {
        "avg_logprob": -0.2613249009655368,
        "compression_ratio": 1.739864864864865,
        "end": 824.34,
        "id": 304,
        "no_speech_prob": 0.0008830276201479137,
        "seek": 81290,
        "start": 822.22,
        "temperature": 0,
        "text": " There's a lot of stuff that's broken.",
        "tokens": [
          50830,
          821,
          311,
          257,
          688,
          295,
          1507,
          300,
          311,
          5463,
          13,
          50936
        ]
      },
      {
        "avg_logprob": -0.2613249009655368,
        "compression_ratio": 1.739864864864865,
        "end": 827.1,
        "id": 305,
        "no_speech_prob": 0.0008830276201479137,
        "seek": 81290,
        "start": 824.34,
        "temperature": 0,
        "text": " And so, you know, reach out to me on Twitter,",
        "tokens": [
          50936,
          400,
          370,
          11,
          291,
          458,
          11,
          2524,
          484,
          281,
          385,
          322,
          5794,
          11,
          51074
        ]
      },
      {
        "avg_logprob": -0.2613249009655368,
        "compression_ratio": 1.739864864864865,
        "end": 828.04,
        "id": 306,
        "no_speech_prob": 0.0008830276201479137,
        "seek": 81290,
        "start": 827.1,
        "temperature": 0,
        "text": " at Schiffman.",
        "tokens": [
          51074,
          412,
          2065,
          3661,
          1601,
          13,
          51121
        ]
      },
      {
        "avg_logprob": -0.2613249009655368,
        "compression_ratio": 1.739864864864865,
        "end": 830.42,
        "id": 307,
        "no_speech_prob": 0.0008830276201479137,
        "seek": 81290,
        "start": 828.9399999999999,
        "temperature": 0,
        "text": " Type in a comment somewhere on GitHub",
        "tokens": [
          51166,
          15576,
          294,
          257,
          2871,
          4079,
          322,
          23331,
          51240
        ]
      },
      {
        "avg_logprob": -0.2613249009655368,
        "compression_ratio": 1.739864864864865,
        "end": 831.62,
        "id": 308,
        "no_speech_prob": 0.0008830276201479137,
        "seek": 81290,
        "start": 830.42,
        "temperature": 0,
        "text": " if you want to get involved and help us",
        "tokens": [
          51240,
          498,
          291,
          528,
          281,
          483,
          3288,
          293,
          854,
          505,
          51300
        ]
      },
      {
        "avg_logprob": -0.2613249009655368,
        "compression_ratio": 1.739864864864865,
        "end": 833.1,
        "id": 309,
        "no_speech_prob": 0.0008830276201479137,
        "seek": 81290,
        "start": 831.62,
        "temperature": 0,
        "text": " kind of push forward some of this code stuff",
        "tokens": [
          51300,
          733,
          295,
          2944,
          2128,
          512,
          295,
          341,
          3089,
          1507,
          51374
        ]
      },
      {
        "avg_logprob": -0.2613249009655368,
        "compression_ratio": 1.739864864864865,
        "end": 834.34,
        "id": 310,
        "no_speech_prob": 0.0008830276201479137,
        "seek": 81290,
        "start": 833.1,
        "temperature": 0,
        "text": " for the release.",
        "tokens": [
          51374,
          337,
          264,
          4374,
          13,
          51436
        ]
      },
      {
        "avg_logprob": -0.2613249009655368,
        "compression_ratio": 1.739864864864865,
        "end": 837.1,
        "id": 311,
        "no_speech_prob": 0.0008830276201479137,
        "seek": 81290,
        "start": 834.34,
        "temperature": 0,
        "text": " And okay, so that's what I wanted to mention there.",
        "tokens": [
          51436,
          400,
          1392,
          11,
          370,
          300,
          311,
          437,
          286,
          1415,
          281,
          2152,
          456,
          13,
          51574
        ]
      },
      {
        "avg_logprob": -0.22877848849577062,
        "compression_ratio": 1.7341269841269842,
        "end": 845.06,
        "id": 312,
        "no_speech_prob": 0.0004878528125118464,
        "seek": 84290,
        "start": 843.22,
        "temperature": 0,
        "text": " Do, do, do, do, looking in the chat,",
        "tokens": [
          50380,
          1144,
          11,
          360,
          11,
          360,
          11,
          360,
          11,
          1237,
          294,
          264,
          5081,
          11,
          50472
        ]
      },
      {
        "avg_logprob": -0.22877848849577062,
        "compression_ratio": 1.7341269841269842,
        "end": 846.5,
        "id": 313,
        "no_speech_prob": 0.0004878528125118464,
        "seek": 84290,
        "start": 845.06,
        "temperature": 0,
        "text": " looking in the chat, looking in the chat.",
        "tokens": [
          50472,
          1237,
          294,
          264,
          5081,
          11,
          1237,
          294,
          264,
          5081,
          13,
          50544
        ]
      },
      {
        "avg_logprob": -0.22877848849577062,
        "compression_ratio": 1.7341269841269842,
        "end": 848.98,
        "id": 314,
        "no_speech_prob": 0.0004878528125118464,
        "seek": 84290,
        "start": 846.5,
        "temperature": 0,
        "text": " Okay, so now, ah, coming back over here.",
        "tokens": [
          50544,
          1033,
          11,
          370,
          586,
          11,
          3716,
          11,
          1348,
          646,
          670,
          510,
          13,
          50668
        ]
      },
      {
        "avg_logprob": -0.22877848849577062,
        "compression_ratio": 1.7341269841269842,
        "end": 851.5,
        "id": 315,
        "no_speech_prob": 0.0004878528125118464,
        "seek": 84290,
        "start": 850.38,
        "temperature": 0,
        "text": " So this is what's coming.",
        "tokens": [
          50738,
          407,
          341,
          307,
          437,
          311,
          1348,
          13,
          50794
        ]
      },
      {
        "avg_logprob": -0.22877848849577062,
        "compression_ratio": 1.7341269841269842,
        "end": 853.24,
        "id": 316,
        "no_speech_prob": 0.0004878528125118464,
        "seek": 84290,
        "start": 851.5,
        "temperature": 0,
        "text": " This is what I hope to eventually have",
        "tokens": [
          50794,
          639,
          307,
          437,
          286,
          1454,
          281,
          4728,
          362,
          50881
        ]
      },
      {
        "avg_logprob": -0.22877848849577062,
        "compression_ratio": 1.7341269841269842,
        "end": 856.1999999999999,
        "id": 317,
        "no_speech_prob": 0.0004878528125118464,
        "seek": 84290,
        "start": 853.24,
        "temperature": 0,
        "text": " on this YouTube channel is a playlist",
        "tokens": [
          50881,
          322,
          341,
          3088,
          2269,
          307,
          257,
          16788,
          51029
        ]
      },
      {
        "avg_logprob": -0.22877848849577062,
        "compression_ratio": 1.7341269841269842,
        "end": 858.5,
        "id": 318,
        "no_speech_prob": 0.0004878528125118464,
        "seek": 84290,
        "start": 856.1999999999999,
        "temperature": 0,
        "text": " which is machine learning for beginners in the browser.",
        "tokens": [
          51029,
          597,
          307,
          3479,
          2539,
          337,
          26992,
          294,
          264,
          11185,
          13,
          51144
        ]
      },
      {
        "avg_logprob": -0.22877848849577062,
        "compression_ratio": 1.7341269841269842,
        "end": 860.02,
        "id": 319,
        "no_speech_prob": 0.0004878528125118464,
        "seek": 84290,
        "start": 858.5,
        "temperature": 0,
        "text": " I don't know what to call it exactly.",
        "tokens": [
          51144,
          286,
          500,
          380,
          458,
          437,
          281,
          818,
          309,
          2293,
          13,
          51220
        ]
      },
      {
        "avg_logprob": -0.22877848849577062,
        "compression_ratio": 1.7341269841269842,
        "end": 863.5799999999999,
        "id": 320,
        "no_speech_prob": 0.0004878528125118464,
        "seek": 84290,
        "start": 860.02,
        "temperature": 0,
        "text": " And I'm going to be using ml5 and p5.js for that together.",
        "tokens": [
          51220,
          400,
          286,
          478,
          516,
          281,
          312,
          1228,
          23271,
          20,
          293,
          280,
          20,
          13,
          25530,
          337,
          300,
          1214,
          13,
          51398
        ]
      },
      {
        "avg_logprob": -0.22877848849577062,
        "compression_ratio": 1.7341269841269842,
        "end": 867.18,
        "id": 321,
        "no_speech_prob": 0.0004878528125118464,
        "seek": 84290,
        "start": 863.5799999999999,
        "temperature": 0,
        "text": " By the way, the five in ml5 is an homage",
        "tokens": [
          51398,
          3146,
          264,
          636,
          11,
          264,
          1732,
          294,
          23271,
          20,
          307,
          364,
          44073,
          51578
        ]
      },
      {
        "avg_logprob": -0.22877848849577062,
        "compression_ratio": 1.7341269841269842,
        "end": 868.88,
        "id": 322,
        "no_speech_prob": 0.0004878528125118464,
        "seek": 84290,
        "start": 867.18,
        "temperature": 0,
        "text": " to p5 and processing",
        "tokens": [
          51578,
          281,
          280,
          20,
          293,
          9007,
          51663
        ]
      },
      {
        "avg_logprob": -0.23314125424339657,
        "compression_ratio": 1.5,
        "end": 874.88,
        "id": 323,
        "no_speech_prob": 0.000017778495021048002,
        "seek": 86888,
        "start": 869.88,
        "temperature": 0,
        "text": " because the ml5 library aspires to be kind of friendly",
        "tokens": [
          50414,
          570,
          264,
          23271,
          20,
          6405,
          16817,
          3145,
          281,
          312,
          733,
          295,
          9208,
          50664
        ]
      },
      {
        "avg_logprob": -0.23314125424339657,
        "compression_ratio": 1.5,
        "end": 877.8,
        "id": 324,
        "no_speech_prob": 0.000017778495021048002,
        "seek": 86888,
        "start": 875.4,
        "temperature": 0,
        "text": " and accessible in the same ways that processing",
        "tokens": [
          50690,
          293,
          9515,
          294,
          264,
          912,
          2098,
          300,
          9007,
          50810
        ]
      },
      {
        "avg_logprob": -0.23314125424339657,
        "compression_ratio": 1.5,
        "end": 879.96,
        "id": 325,
        "no_speech_prob": 0.000017778495021048002,
        "seek": 86888,
        "start": 877.8,
        "temperature": 0,
        "text": " and p5 have been over the years.",
        "tokens": [
          50810,
          293,
          280,
          20,
          362,
          668,
          670,
          264,
          924,
          13,
          50918
        ]
      },
      {
        "avg_logprob": -0.23314125424339657,
        "compression_ratio": 1.5,
        "end": 881.2,
        "id": 326,
        "no_speech_prob": 0.000017778495021048002,
        "seek": 86888,
        "start": 879.96,
        "temperature": 0,
        "text": " And there we go.",
        "tokens": [
          50918,
          400,
          456,
          321,
          352,
          13,
          50980
        ]
      },
      {
        "avg_logprob": -0.23314125424339657,
        "compression_ratio": 1.5,
        "end": 883.2,
        "id": 327,
        "no_speech_prob": 0.000017778495021048002,
        "seek": 86888,
        "start": 881.2,
        "temperature": 0,
        "text": " My camera's still shut off.",
        "tokens": [
          50980,
          1222,
          2799,
          311,
          920,
          5309,
          766,
          13,
          51080
        ]
      },
      {
        "avg_logprob": -0.23314125424339657,
        "compression_ratio": 1.5,
        "end": 885.2,
        "id": 328,
        "no_speech_prob": 0.000017778495021048002,
        "seek": 86888,
        "start": 883.2,
        "temperature": 0,
        "text": " Now, back to today.",
        "tokens": [
          51080,
          823,
          11,
          646,
          281,
          965,
          13,
          51180
        ]
      },
      {
        "avg_logprob": -0.23314125424339657,
        "compression_ratio": 1.5,
        "end": 886.46,
        "id": 329,
        "no_speech_prob": 0.000017778495021048002,
        "seek": 86888,
        "start": 885.2,
        "temperature": 0,
        "text": " It's one o'clock already.",
        "tokens": [
          51180,
          467,
          311,
          472,
          277,
          6,
          9023,
          1217,
          13,
          51243
        ]
      },
      {
        "avg_logprob": -0.23314125424339657,
        "compression_ratio": 1.5,
        "end": 893.04,
        "id": 330,
        "no_speech_prob": 0.000017778495021048002,
        "seek": 86888,
        "start": 888.96,
        "temperature": 0,
        "text": " So what, now, I have a pretty clear picture",
        "tokens": [
          51368,
          407,
          437,
          11,
          586,
          11,
          286,
          362,
          257,
          1238,
          1850,
          3036,
          51572
        ]
      },
      {
        "avg_logprob": -0.23314125424339657,
        "compression_ratio": 1.5,
        "end": 896.28,
        "id": 331,
        "no_speech_prob": 0.000017778495021048002,
        "seek": 86888,
        "start": 893.04,
        "temperature": 0,
        "text": " of what I want to do with my image classification examples",
        "tokens": [
          51572,
          295,
          437,
          286,
          528,
          281,
          360,
          365,
          452,
          3256,
          21538,
          5110,
          51734
        ]
      },
      {
        "avg_logprob": -0.23314125424339657,
        "compression_ratio": 1.5,
        "end": 897.48,
        "id": 332,
        "no_speech_prob": 0.000017778495021048002,
        "seek": 86888,
        "start": 896.28,
        "temperature": 0,
        "text": " that I'm going to build.",
        "tokens": [
          51734,
          300,
          286,
          478,
          516,
          281,
          1322,
          13,
          51794
        ]
      },
      {
        "avg_logprob": -0.2725045657852321,
        "compression_ratio": 1.748936170212766,
        "end": 902.76,
        "id": 333,
        "no_speech_prob": 0.000008801078365650028,
        "seek": 89888,
        "start": 899.12,
        "temperature": 0,
        "text": " I want to use the Quick Draw dataset.",
        "tokens": [
          50376,
          286,
          528,
          281,
          764,
          264,
          12101,
          20386,
          28872,
          13,
          50558
        ]
      },
      {
        "avg_logprob": -0.2725045657852321,
        "compression_ratio": 1.748936170212766,
        "end": 907.72,
        "id": 334,
        "no_speech_prob": 0.000008801078365650028,
        "seek": 89888,
        "start": 903.8,
        "temperature": 0,
        "text": " So one of my goals with making my machine learning tutorials",
        "tokens": [
          50610,
          407,
          472,
          295,
          452,
          5493,
          365,
          1455,
          452,
          3479,
          2539,
          17616,
          50806
        ]
      },
      {
        "avg_logprob": -0.2725045657852321,
        "compression_ratio": 1.748936170212766,
        "end": 910.86,
        "id": 335,
        "no_speech_prob": 0.000008801078365650028,
        "seek": 89888,
        "start": 907.72,
        "temperature": 0,
        "text": " is to use non-traditional datasets.",
        "tokens": [
          50806,
          307,
          281,
          764,
          2107,
          12,
          43831,
          2628,
          42856,
          13,
          50963
        ]
      },
      {
        "avg_logprob": -0.2725045657852321,
        "compression_ratio": 1.748936170212766,
        "end": 912.6,
        "id": 336,
        "no_speech_prob": 0.000008801078365650028,
        "seek": 89888,
        "start": 910.86,
        "temperature": 0,
        "text": " And maybe non-traditional is the wrong word,",
        "tokens": [
          50963,
          400,
          1310,
          2107,
          12,
          43831,
          2628,
          307,
          264,
          2085,
          1349,
          11,
          51050
        ]
      },
      {
        "avg_logprob": -0.2725045657852321,
        "compression_ratio": 1.748936170212766,
        "end": 916.6,
        "id": 337,
        "no_speech_prob": 0.000008801078365650028,
        "seek": 89888,
        "start": 912.6,
        "temperature": 0,
        "text": " but datasets that are outside of what you would typically",
        "tokens": [
          51050,
          457,
          42856,
          300,
          366,
          2380,
          295,
          437,
          291,
          576,
          5850,
          51250
        ]
      },
      {
        "avg_logprob": -0.2725045657852321,
        "compression_ratio": 1.748936170212766,
        "end": 920.4399999999999,
        "id": 338,
        "no_speech_prob": 0.000008801078365650028,
        "seek": 89888,
        "start": 916.6,
        "temperature": 0,
        "text": " find in machine learning and data science curriculum.",
        "tokens": [
          51250,
          915,
          294,
          3479,
          2539,
          293,
          1412,
          3497,
          14302,
          13,
          51442
        ]
      },
      {
        "avg_logprob": -0.2725045657852321,
        "compression_ratio": 1.748936170212766,
        "end": 922.48,
        "id": 339,
        "no_speech_prob": 0.000008801078365650028,
        "seek": 89888,
        "start": 920.4399999999999,
        "temperature": 0,
        "text": " I want them, I want to use different ones",
        "tokens": [
          51442,
          286,
          528,
          552,
          11,
          286,
          528,
          281,
          764,
          819,
          2306,
          51544
        ]
      },
      {
        "avg_logprob": -0.2725045657852321,
        "compression_ratio": 1.748936170212766,
        "end": 924.96,
        "id": 340,
        "no_speech_prob": 0.000008801078365650028,
        "seek": 89888,
        "start": 922.48,
        "temperature": 0,
        "text": " that are kind of in the creative space",
        "tokens": [
          51544,
          300,
          366,
          733,
          295,
          294,
          264,
          5880,
          1901,
          51668
        ]
      },
      {
        "avg_logprob": -0.2725045657852321,
        "compression_ratio": 1.748936170212766,
        "end": 926.76,
        "id": 341,
        "no_speech_prob": 0.000008801078365650028,
        "seek": 89888,
        "start": 924.96,
        "temperature": 0,
        "text": " to get people thinking more creatively",
        "tokens": [
          51668,
          281,
          483,
          561,
          1953,
          544,
          43750,
          51758
        ]
      },
      {
        "avg_logprob": -0.2447815395536877,
        "compression_ratio": 1.8097014925373134,
        "end": 929.24,
        "id": 342,
        "no_speech_prob": 0.00018522446043789387,
        "seek": 92676,
        "start": 926.76,
        "temperature": 0,
        "text": " about what kinds of data they encounter in their life",
        "tokens": [
          50364,
          466,
          437,
          3685,
          295,
          1412,
          436,
          8593,
          294,
          641,
          993,
          50488
        ]
      },
      {
        "avg_logprob": -0.2447815395536877,
        "compression_ratio": 1.8097014925373134,
        "end": 930.6,
        "id": 343,
        "no_speech_prob": 0.00018522446043789387,
        "seek": 92676,
        "start": 929.24,
        "temperature": 0,
        "text": " that they could maybe use.",
        "tokens": [
          50488,
          300,
          436,
          727,
          1310,
          764,
          13,
          50556
        ]
      },
      {
        "avg_logprob": -0.2447815395536877,
        "compression_ratio": 1.8097014925373134,
        "end": 934.28,
        "id": 344,
        "no_speech_prob": 0.00018522446043789387,
        "seek": 92676,
        "start": 931.92,
        "temperature": 0,
        "text": " I want to use datasets that are really simple",
        "tokens": [
          50622,
          286,
          528,
          281,
          764,
          42856,
          300,
          366,
          534,
          2199,
          50740
        ]
      },
      {
        "avg_logprob": -0.2447815395536877,
        "compression_ratio": 1.8097014925373134,
        "end": 936.4399999999999,
        "id": 345,
        "no_speech_prob": 0.00018522446043789387,
        "seek": 92676,
        "start": 934.28,
        "temperature": 0,
        "text": " and kind of like easy to understand and look at.",
        "tokens": [
          50740,
          293,
          733,
          295,
          411,
          1858,
          281,
          1223,
          293,
          574,
          412,
          13,
          50848
        ]
      },
      {
        "avg_logprob": -0.2447815395536877,
        "compression_ratio": 1.8097014925373134,
        "end": 939.24,
        "id": 346,
        "no_speech_prob": 0.00018522446043789387,
        "seek": 92676,
        "start": 936.4399999999999,
        "temperature": 0,
        "text": " And I also want to use datasets that are representative",
        "tokens": [
          50848,
          400,
          286,
          611,
          528,
          281,
          764,
          42856,
          300,
          366,
          12424,
          50988
        ]
      },
      {
        "avg_logprob": -0.2447815395536877,
        "compression_ratio": 1.8097014925373134,
        "end": 944.24,
        "id": 347,
        "no_speech_prob": 0.00018522446043789387,
        "seek": 92676,
        "start": 939.24,
        "temperature": 0,
        "text": " of the world that we live in and all of the cultures",
        "tokens": [
          50988,
          295,
          264,
          1002,
          300,
          321,
          1621,
          294,
          293,
          439,
          295,
          264,
          12951,
          51238
        ]
      },
      {
        "avg_logprob": -0.2447815395536877,
        "compression_ratio": 1.8097014925373134,
        "end": 947.4,
        "id": 348,
        "no_speech_prob": 0.00018522446043789387,
        "seek": 92676,
        "start": 944.4,
        "temperature": 0,
        "text": " and people that we share this great earth with.",
        "tokens": [
          51246,
          293,
          561,
          300,
          321,
          2073,
          341,
          869,
          4120,
          365,
          13,
          51396
        ]
      },
      {
        "avg_logprob": -0.2447815395536877,
        "compression_ratio": 1.8097014925373134,
        "end": 950.2,
        "id": 349,
        "no_speech_prob": 0.00018522446043789387,
        "seek": 92676,
        "start": 947.4,
        "temperature": 0,
        "text": " So, you know, things like, I'm trying to avoid things",
        "tokens": [
          51396,
          407,
          11,
          291,
          458,
          11,
          721,
          411,
          11,
          286,
          478,
          1382,
          281,
          5042,
          721,
          51536
        ]
      },
      {
        "avg_logprob": -0.2447815395536877,
        "compression_ratio": 1.8097014925373134,
        "end": 953.8,
        "id": 350,
        "no_speech_prob": 0.00018522446043789387,
        "seek": 92676,
        "start": 950.2,
        "temperature": 0,
        "text": " like MNIST, which is the sort of classic",
        "tokens": [
          51536,
          411,
          376,
          45,
          19756,
          11,
          597,
          307,
          264,
          1333,
          295,
          7230,
          51716
        ]
      },
      {
        "avg_logprob": -0.2447815395536877,
        "compression_ratio": 1.8097014925373134,
        "end": 956.68,
        "id": 351,
        "no_speech_prob": 0.00018522446043789387,
        "seek": 92676,
        "start": 953.8,
        "temperature": 0,
        "text": " handwritten digits dataset, things like the Iris dataset,",
        "tokens": [
          51716,
          1011,
          26859,
          27011,
          28872,
          11,
          721,
          411,
          264,
          40789,
          28872,
          11,
          51860
        ]
      },
      {
        "avg_logprob": -0.2631818000843983,
        "compression_ratio": 1.677115987460815,
        "end": 958.3599999999999,
        "id": 352,
        "no_speech_prob": 0.0001106110867112875,
        "seek": 95668,
        "start": 957.52,
        "temperature": 0,
        "text": " which is wonderful and I love flowers.",
        "tokens": [
          50406,
          597,
          307,
          3715,
          293,
          286,
          959,
          8085,
          13,
          50448
        ]
      },
      {
        "avg_logprob": -0.2631818000843983,
        "compression_ratio": 1.677115987460815,
        "end": 960.64,
        "id": 353,
        "no_speech_prob": 0.0001106110867112875,
        "seek": 95668,
        "start": 958.3599999999999,
        "temperature": 0,
        "text": " Nothing could possibly be wrong with a flowers dataset,",
        "tokens": [
          50448,
          6693,
          727,
          6264,
          312,
          2085,
          365,
          257,
          8085,
          28872,
          11,
          50562
        ]
      },
      {
        "avg_logprob": -0.2631818000843983,
        "compression_ratio": 1.677115987460815,
        "end": 963.56,
        "id": 354,
        "no_speech_prob": 0.0001106110867112875,
        "seek": 95668,
        "start": 960.64,
        "temperature": 0,
        "text": " but things that you wouldn't, that kind of made me feel",
        "tokens": [
          50562,
          457,
          721,
          300,
          291,
          2759,
          380,
          11,
          300,
          733,
          295,
          1027,
          385,
          841,
          50708
        ]
      },
      {
        "avg_logprob": -0.2631818000843983,
        "compression_ratio": 1.677115987460815,
        "end": 964.78,
        "id": 355,
        "no_speech_prob": 0.0001106110867112875,
        "seek": 95668,
        "start": 963.56,
        "temperature": 0,
        "text": " a bit more approachable.",
        "tokens": [
          50708,
          257,
          857,
          544,
          3109,
          712,
          13,
          50769
        ]
      },
      {
        "avg_logprob": -0.2631818000843983,
        "compression_ratio": 1.677115987460815,
        "end": 968.1999999999999,
        "id": 356,
        "no_speech_prob": 0.0001106110867112875,
        "seek": 95668,
        "start": 964.78,
        "temperature": 0,
        "text": " So I really, I asked this question a bunch of places",
        "tokens": [
          50769,
          407,
          286,
          534,
          11,
          286,
          2351,
          341,
          1168,
          257,
          3840,
          295,
          3190,
          50940
        ]
      },
      {
        "avg_logprob": -0.2631818000843983,
        "compression_ratio": 1.677115987460815,
        "end": 972.1999999999999,
        "id": 357,
        "no_speech_prob": 0.0001106110867112875,
        "seek": 95668,
        "start": 968.1999999999999,
        "temperature": 0,
        "text": " a bunch of times, I don't get any responses",
        "tokens": [
          50940,
          257,
          3840,
          295,
          1413,
          11,
          286,
          500,
          380,
          483,
          604,
          13019,
          51140
        ]
      },
      {
        "avg_logprob": -0.2631818000843983,
        "compression_ratio": 1.677115987460815,
        "end": 974.1999999999999,
        "id": 358,
        "no_speech_prob": 0.0001106110867112875,
        "seek": 95668,
        "start": 972.1999999999999,
        "temperature": 0,
        "text": " because I don't, I mean it's hard to find",
        "tokens": [
          51140,
          570,
          286,
          500,
          380,
          11,
          286,
          914,
          309,
          311,
          1152,
          281,
          915,
          51240
        ]
      },
      {
        "avg_logprob": -0.2631818000843983,
        "compression_ratio": 1.677115987460815,
        "end": 975.2399999999999,
        "id": 359,
        "no_speech_prob": 0.0001106110867112875,
        "seek": 95668,
        "start": 974.1999999999999,
        "temperature": 0,
        "text": " these kind of datasets.",
        "tokens": [
          51240,
          613,
          733,
          295,
          42856,
          13,
          51292
        ]
      },
      {
        "avg_logprob": -0.2631818000843983,
        "compression_ratio": 1.677115987460815,
        "end": 977.9599999999999,
        "id": 360,
        "no_speech_prob": 0.0001106110867112875,
        "seek": 95668,
        "start": 975.2399999999999,
        "temperature": 0,
        "text": " I feel like the Google Quick Draw dataset is a great one",
        "tokens": [
          51292,
          286,
          841,
          411,
          264,
          3329,
          12101,
          20386,
          28872,
          307,
          257,
          869,
          472,
          51428
        ]
      },
      {
        "avg_logprob": -0.2631818000843983,
        "compression_ratio": 1.677115987460815,
        "end": 979.9599999999999,
        "id": 361,
        "no_speech_prob": 0.0001106110867112875,
        "seek": 95668,
        "start": 977.9599999999999,
        "temperature": 0,
        "text": " for learning about image classification.",
        "tokens": [
          51428,
          337,
          2539,
          466,
          3256,
          21538,
          13,
          51528
        ]
      },
      {
        "avg_logprob": -0.2631818000843983,
        "compression_ratio": 1.677115987460815,
        "end": 983.28,
        "id": 362,
        "no_speech_prob": 0.0001106110867112875,
        "seek": 95668,
        "start": 980.92,
        "temperature": 0,
        "text": " And then what I'm thinking of doing,",
        "tokens": [
          51576,
          400,
          550,
          437,
          286,
          478,
          1953,
          295,
          884,
          11,
          51694
        ]
      },
      {
        "avg_logprob": -0.2631818000843983,
        "compression_ratio": 1.677115987460815,
        "end": 985.4799999999999,
        "id": 363,
        "no_speech_prob": 0.0001106110867112875,
        "seek": 95668,
        "start": 983.28,
        "temperature": 0,
        "text": " an XOR is like, it's not really a dataset,",
        "tokens": [
          51694,
          364,
          1783,
          2483,
          307,
          411,
          11,
          309,
          311,
          406,
          534,
          257,
          28872,
          11,
          51804
        ]
      },
      {
        "avg_logprob": -0.2631818000843983,
        "compression_ratio": 1.677115987460815,
        "end": 986.42,
        "id": 364,
        "no_speech_prob": 0.0001106110867112875,
        "seek": 95668,
        "start": 985.4799999999999,
        "temperature": 0,
        "text": " it's just made up.",
        "tokens": [
          51804,
          309,
          311,
          445,
          1027,
          493,
          13,
          51851
        ]
      },
      {
        "avg_logprob": -0.31075486682710196,
        "compression_ratio": 1.6203007518796992,
        "end": 988.66,
        "id": 365,
        "no_speech_prob": 0.000030241812055464834,
        "seek": 98642,
        "start": 987.16,
        "temperature": 0,
        "text": " Oh, I have something else I want to add in here.",
        "tokens": [
          50401,
          876,
          11,
          286,
          362,
          746,
          1646,
          286,
          528,
          281,
          909,
          294,
          510,
          13,
          50476
        ]
      },
      {
        "avg_logprob": -0.31075486682710196,
        "compression_ratio": 1.6203007518796992,
        "end": 989.5,
        "id": 366,
        "no_speech_prob": 0.000030241812055464834,
        "seek": 98642,
        "start": 988.66,
        "temperature": 0,
        "text": " Okay, hold on, hold on.",
        "tokens": [
          50476,
          1033,
          11,
          1797,
          322,
          11,
          1797,
          322,
          13,
          50518
        ]
      },
      {
        "avg_logprob": -0.31075486682710196,
        "compression_ratio": 1.6203007518796992,
        "end": 994.5,
        "id": 367,
        "no_speech_prob": 0.000030241812055464834,
        "seek": 98642,
        "start": 989.5,
        "temperature": 0,
        "text": " And then classification, what I'm, right now the only thing,",
        "tokens": [
          50518,
          400,
          550,
          21538,
          11,
          437,
          286,
          478,
          11,
          558,
          586,
          264,
          787,
          551,
          11,
          50768
        ]
      },
      {
        "avg_logprob": -0.31075486682710196,
        "compression_ratio": 1.6203007518796992,
        "end": 998.5799999999999,
        "id": 368,
        "no_speech_prob": 0.000030241812055464834,
        "seek": 98642,
        "start": 994.9399999999999,
        "temperature": 0,
        "text": " so TensorFlow.js, there's a node version of TensorFlow.js",
        "tokens": [
          50790,
          370,
          37624,
          13,
          25530,
          11,
          456,
          311,
          257,
          9984,
          3037,
          295,
          37624,
          13,
          25530,
          50972
        ]
      },
      {
        "avg_logprob": -0.31075486682710196,
        "compression_ratio": 1.6203007518796992,
        "end": 1002.4,
        "id": 369,
        "no_speech_prob": 0.000030241812055464834,
        "seek": 98642,
        "start": 998.5799999999999,
        "temperature": 0,
        "text": " that used this MLB, Major League Baseball dataset",
        "tokens": [
          50972,
          300,
          1143,
          341,
          21601,
          33,
          11,
          15581,
          11199,
          21054,
          3129,
          28872,
          51163
        ]
      },
      {
        "avg_logprob": -0.31075486682710196,
        "compression_ratio": 1.6203007518796992,
        "end": 1004.42,
        "id": 370,
        "no_speech_prob": 0.000030241812055464834,
        "seek": 98642,
        "start": 1002.4,
        "temperature": 0,
        "text": " to classify pitches and I love that.",
        "tokens": [
          51163,
          281,
          33872,
          43110,
          293,
          286,
          959,
          300,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.31075486682710196,
        "compression_ratio": 1.6203007518796992,
        "end": 1007.18,
        "id": 371,
        "no_speech_prob": 0.000030241812055464834,
        "seek": 98642,
        "start": 1004.42,
        "temperature": 0,
        "text": " First of all, I'm kind of a little bit of a baseball nerd.",
        "tokens": [
          51264,
          2386,
          295,
          439,
          11,
          286,
          478,
          733,
          295,
          257,
          707,
          857,
          295,
          257,
          14323,
          23229,
          13,
          51402
        ]
      },
      {
        "avg_logprob": -0.31075486682710196,
        "compression_ratio": 1.6203007518796992,
        "end": 1012.52,
        "id": 372,
        "no_speech_prob": 0.000030241812055464834,
        "seek": 98642,
        "start": 1009.0999999999999,
        "temperature": 0,
        "text": " You know, anywhere, so that's kind of interests me,",
        "tokens": [
          51498,
          509,
          458,
          11,
          4992,
          11,
          370,
          300,
          311,
          733,
          295,
          8847,
          385,
          11,
          51669
        ]
      },
      {
        "avg_logprob": -0.31075486682710196,
        "compression_ratio": 1.6203007518796992,
        "end": 1015.92,
        "id": 373,
        "no_speech_prob": 0.000030241812055464834,
        "seek": 98642,
        "start": 1012.52,
        "temperature": 0,
        "text": " but I don't know that baseball is perfect",
        "tokens": [
          51669,
          457,
          286,
          500,
          380,
          458,
          300,
          14323,
          307,
          2176,
          51839
        ]
      },
      {
        "avg_logprob": -0.32378666024459035,
        "compression_ratio": 1.7147766323024054,
        "end": 1018.16,
        "id": 374,
        "no_speech_prob": 0.000022125601390143856,
        "seek": 101592,
        "start": 1016.42,
        "temperature": 0,
        "text": " for what I want to do that's going to be,",
        "tokens": [
          50389,
          337,
          437,
          286,
          528,
          281,
          360,
          300,
          311,
          516,
          281,
          312,
          11,
          50476
        ]
      },
      {
        "avg_logprob": -0.32378666024459035,
        "compression_ratio": 1.7147766323024054,
        "end": 1023.9599999999999,
        "id": 375,
        "no_speech_prob": 0.000022125601390143856,
        "seek": 101592,
        "start": 1022.68,
        "temperature": 0,
        "text": " you know, a lot of people don't know about baseball",
        "tokens": [
          50702,
          291,
          458,
          11,
          257,
          688,
          295,
          561,
          500,
          380,
          458,
          466,
          14323,
          50766
        ]
      },
      {
        "avg_logprob": -0.32378666024459035,
        "compression_ratio": 1.7147766323024054,
        "end": 1024.8,
        "id": 376,
        "no_speech_prob": 0.000022125601390143856,
        "seek": 101592,
        "start": 1023.9599999999999,
        "temperature": 0,
        "text": " or are interested in baseball,",
        "tokens": [
          50766,
          420,
          366,
          3102,
          294,
          14323,
          11,
          50808
        ]
      },
      {
        "avg_logprob": -0.32378666024459035,
        "compression_ratio": 1.7147766323024054,
        "end": 1027.08,
        "id": 377,
        "no_speech_prob": 0.000022125601390143856,
        "seek": 101592,
        "start": 1024.8,
        "temperature": 0,
        "text": " it's maybe not reaching the more general audience",
        "tokens": [
          50808,
          309,
          311,
          1310,
          406,
          9906,
          264,
          544,
          2674,
          4034,
          50922
        ]
      },
      {
        "avg_logprob": -0.32378666024459035,
        "compression_ratio": 1.7147766323024054,
        "end": 1029.04,
        "id": 378,
        "no_speech_prob": 0.000022125601390143856,
        "seek": 101592,
        "start": 1027.08,
        "temperature": 0,
        "text": " that I'm imagining for this channel.",
        "tokens": [
          50922,
          300,
          286,
          478,
          27798,
          337,
          341,
          2269,
          13,
          51020
        ]
      },
      {
        "avg_logprob": -0.32378666024459035,
        "compression_ratio": 1.7147766323024054,
        "end": 1031.36,
        "id": 379,
        "no_speech_prob": 0.000022125601390143856,
        "seek": 101592,
        "start": 1029.04,
        "temperature": 0,
        "text": " So, but something like that that's really simple.",
        "tokens": [
          51020,
          407,
          11,
          457,
          746,
          411,
          300,
          300,
          311,
          534,
          2199,
          13,
          51136
        ]
      },
      {
        "avg_logprob": -0.32378666024459035,
        "compression_ratio": 1.7147766323024054,
        "end": 1033.3999999999999,
        "id": 380,
        "no_speech_prob": 0.000022125601390143856,
        "seek": 101592,
        "start": 1031.36,
        "temperature": 0,
        "text": " So all I can think of right now,",
        "tokens": [
          51136,
          407,
          439,
          286,
          393,
          519,
          295,
          558,
          586,
          11,
          51238
        ]
      },
      {
        "avg_logprob": -0.32378666024459035,
        "compression_ratio": 1.7147766323024054,
        "end": 1037.52,
        "id": 381,
        "no_speech_prob": 0.000022125601390143856,
        "seek": 101592,
        "start": 1033.3999999999999,
        "temperature": 0,
        "text": " because I, from Jabril, go check out S-E-F-D Science,",
        "tokens": [
          51238,
          570,
          286,
          11,
          490,
          40319,
          24216,
          11,
          352,
          1520,
          484,
          318,
          12,
          36,
          12,
          37,
          12,
          35,
          8976,
          11,
          51444
        ]
      },
      {
        "avg_logprob": -0.32378666024459035,
        "compression_ratio": 1.7147766323024054,
        "end": 1040.6599999999999,
        "id": 382,
        "no_speech_prob": 0.000022125601390143856,
        "seek": 101592,
        "start": 1037.52,
        "temperature": 0,
        "text": " S-E-F-D Science, I can never say his channel name.",
        "tokens": [
          51444,
          318,
          12,
          36,
          12,
          37,
          12,
          35,
          8976,
          11,
          286,
          393,
          1128,
          584,
          702,
          2269,
          1315,
          13,
          51601
        ]
      },
      {
        "avg_logprob": -0.32378666024459035,
        "compression_ratio": 1.7147766323024054,
        "end": 1043.54,
        "id": 383,
        "no_speech_prob": 0.000022125601390143856,
        "seek": 101592,
        "start": 1041.92,
        "temperature": 0,
        "text": " It's probably like, there's like a really easy way",
        "tokens": [
          51664,
          467,
          311,
          1391,
          411,
          11,
          456,
          311,
          411,
          257,
          534,
          1858,
          636,
          51745
        ]
      },
      {
        "avg_logprob": -0.32378666024459035,
        "compression_ratio": 1.7147766323024054,
        "end": 1045.12,
        "id": 384,
        "no_speech_prob": 0.000022125601390143856,
        "seek": 101592,
        "start": 1043.54,
        "temperature": 0,
        "text": " to say that channel name and I just can't do it,",
        "tokens": [
          51745,
          281,
          584,
          300,
          2269,
          1315,
          293,
          286,
          445,
          393,
          380,
          360,
          309,
          11,
          51824
        ]
      },
      {
        "avg_logprob": -0.2897880955746299,
        "compression_ratio": 1.6422764227642277,
        "end": 1047.9199999999998,
        "id": 385,
        "no_speech_prob": 0.00000718324690751615,
        "seek": 104512,
        "start": 1045.12,
        "temperature": 0,
        "text": " I don't know why, I'm almost falling over for no reason.",
        "tokens": [
          50364,
          286,
          500,
          380,
          458,
          983,
          11,
          286,
          478,
          1920,
          7440,
          670,
          337,
          572,
          1778,
          13,
          50504
        ]
      },
      {
        "avg_logprob": -0.2897880955746299,
        "compression_ratio": 1.6422764227642277,
        "end": 1050.54,
        "id": 386,
        "no_speech_prob": 0.00000718324690751615,
        "seek": 104512,
        "start": 1049.04,
        "temperature": 0,
        "text": " I was talking about something.",
        "tokens": [
          50560,
          286,
          390,
          1417,
          466,
          746,
          13,
          50635
        ]
      },
      {
        "avg_logprob": -0.2897880955746299,
        "compression_ratio": 1.6422764227642277,
        "end": 1053.6399999999999,
        "id": 387,
        "no_speech_prob": 0.00000718324690751615,
        "seek": 104512,
        "start": 1052.28,
        "temperature": 0,
        "text": " Ah, datasets.",
        "tokens": [
          50722,
          2438,
          11,
          42856,
          13,
          50790
        ]
      },
      {
        "avg_logprob": -0.2897880955746299,
        "compression_ratio": 1.6422764227642277,
        "end": 1056.6,
        "id": 388,
        "no_speech_prob": 0.00000718324690751615,
        "seek": 104512,
        "start": 1053.6399999999999,
        "temperature": 0,
        "text": " Jabril's had this demonstration of a color predictor.",
        "tokens": [
          50790,
          40319,
          24216,
          311,
          632,
          341,
          16520,
          295,
          257,
          2017,
          6069,
          284,
          13,
          50938
        ]
      },
      {
        "avg_logprob": -0.2897880955746299,
        "compression_ratio": 1.6422764227642277,
        "end": 1059.2399999999998,
        "id": 389,
        "no_speech_prob": 0.00000718324690751615,
        "seek": 104512,
        "start": 1056.6,
        "temperature": 0,
        "text": " One of my students actually, this semester,",
        "tokens": [
          50938,
          1485,
          295,
          452,
          1731,
          767,
          11,
          341,
          11894,
          11,
          51070
        ]
      },
      {
        "avg_logprob": -0.2897880955746299,
        "compression_ratio": 1.6422764227642277,
        "end": 1060.9199999999998,
        "id": 390,
        "no_speech_prob": 0.00000718324690751615,
        "seek": 104512,
        "start": 1059.2399999999998,
        "temperature": 0,
        "text": " created a variation on that,",
        "tokens": [
          51070,
          2942,
          257,
          12990,
          322,
          300,
          11,
          51154
        ]
      },
      {
        "avg_logprob": -0.2897880955746299,
        "compression_ratio": 1.6422764227642277,
        "end": 1063.2199999999998,
        "id": 391,
        "no_speech_prob": 0.00000718324690751615,
        "seek": 104512,
        "start": 1060.9199999999998,
        "temperature": 0,
        "text": " which was kind of predicting more about a color",
        "tokens": [
          51154,
          597,
          390,
          733,
          295,
          32884,
          544,
          466,
          257,
          2017,
          51269
        ]
      },
      {
        "avg_logprob": -0.2897880955746299,
        "compression_ratio": 1.6422764227642277,
        "end": 1067.26,
        "id": 392,
        "no_speech_prob": 0.00000718324690751615,
        "seek": 104512,
        "start": 1063.2199999999998,
        "temperature": 0,
        "text": " than just A or B, and so I was thinking of",
        "tokens": [
          51269,
          813,
          445,
          316,
          420,
          363,
          11,
          293,
          370,
          286,
          390,
          1953,
          295,
          51471
        ]
      },
      {
        "avg_logprob": -0.2897880955746299,
        "compression_ratio": 1.6422764227642277,
        "end": 1069.28,
        "id": 393,
        "no_speech_prob": 0.00000718324690751615,
        "seek": 104512,
        "start": 1067.26,
        "temperature": 0,
        "text": " kind of using that as an inspiration.",
        "tokens": [
          51471,
          733,
          295,
          1228,
          300,
          382,
          364,
          10249,
          13,
          51572
        ]
      },
      {
        "avg_logprob": -0.2897880955746299,
        "compression_ratio": 1.6422764227642277,
        "end": 1074.28,
        "id": 394,
        "no_speech_prob": 0.00000718324690751615,
        "seek": 104512,
        "start": 1069.28,
        "temperature": 0,
        "text": " And so like, what if I made a color classifier",
        "tokens": [
          51572,
          400,
          370,
          411,
          11,
          437,
          498,
          286,
          1027,
          257,
          2017,
          1508,
          9902,
          51822
        ]
      },
      {
        "avg_logprob": -0.2398322312148301,
        "compression_ratio": 1.6537102473498233,
        "end": 1079.4799999999998,
        "id": 395,
        "no_speech_prob": 0.000011125585842819419,
        "seek": 107512,
        "start": 1075.56,
        "temperature": 0,
        "text": " that classified colors into like, bluish, grayish,",
        "tokens": [
          50386,
          300,
          20627,
          4577,
          666,
          411,
          11,
          888,
          33786,
          11,
          10855,
          742,
          11,
          50582
        ]
      },
      {
        "avg_logprob": -0.2398322312148301,
        "compression_ratio": 1.6537102473498233,
        "end": 1081.4799999999998,
        "id": 396,
        "no_speech_prob": 0.000011125585842819419,
        "seek": 107512,
        "start": 1079.4799999999998,
        "temperature": 0,
        "text": " or aqua, like the sea, I don't know,",
        "tokens": [
          50582,
          420,
          2373,
          64,
          11,
          411,
          264,
          4158,
          11,
          286,
          500,
          380,
          458,
          11,
          50682
        ]
      },
      {
        "avg_logprob": -0.2398322312148301,
        "compression_ratio": 1.6537102473498233,
        "end": 1083.6399999999999,
        "id": 397,
        "no_speech_prob": 0.000011125585842819419,
        "seek": 107512,
        "start": 1081.4799999999998,
        "temperature": 0,
        "text": " some kind of set of arbitrary labels,",
        "tokens": [
          50682,
          512,
          733,
          295,
          992,
          295,
          23211,
          16949,
          11,
          50790
        ]
      },
      {
        "avg_logprob": -0.2398322312148301,
        "compression_ratio": 1.6537102473498233,
        "end": 1086.9599999999998,
        "id": 398,
        "no_speech_prob": 0.000011125585842819419,
        "seek": 107512,
        "start": 1083.6399999999999,
        "temperature": 0,
        "text": " like five to 10 labels that, but I need to,",
        "tokens": [
          50790,
          411,
          1732,
          281,
          1266,
          16949,
          300,
          11,
          457,
          286,
          643,
          281,
          11,
          50956
        ]
      },
      {
        "avg_logprob": -0.2398322312148301,
        "compression_ratio": 1.6537102473498233,
        "end": 1088.6399999999999,
        "id": 399,
        "no_speech_prob": 0.000011125585842819419,
        "seek": 107512,
        "start": 1086.9599999999998,
        "temperature": 0,
        "text": " so maybe I would crowdsource that dataset,",
        "tokens": [
          50956,
          370,
          1310,
          286,
          576,
          26070,
          2948,
          300,
          28872,
          11,
          51040
        ]
      },
      {
        "avg_logprob": -0.2398322312148301,
        "compression_ratio": 1.6537102473498233,
        "end": 1089.4799999999998,
        "id": 400,
        "no_speech_prob": 0.000011125585842819419,
        "seek": 107512,
        "start": 1088.6399999999999,
        "temperature": 0,
        "text": " I'm not sure yet.",
        "tokens": [
          51040,
          286,
          478,
          406,
          988,
          1939,
          13,
          51082
        ]
      },
      {
        "avg_logprob": -0.2398322312148301,
        "compression_ratio": 1.6537102473498233,
        "end": 1091.4399999999998,
        "id": 401,
        "no_speech_prob": 0.000011125585842819419,
        "seek": 107512,
        "start": 1089.4799999999998,
        "temperature": 0,
        "text": " So that's what I'm thinking about for classification.",
        "tokens": [
          51082,
          407,
          300,
          311,
          437,
          286,
          478,
          1953,
          466,
          337,
          21538,
          13,
          51180
        ]
      },
      {
        "avg_logprob": -0.2398322312148301,
        "compression_ratio": 1.6537102473498233,
        "end": 1092.84,
        "id": 402,
        "no_speech_prob": 0.000011125585842819419,
        "seek": 107512,
        "start": 1091.4399999999998,
        "temperature": 0,
        "text": " I kind of had hoped to do that today,",
        "tokens": [
          51180,
          286,
          733,
          295,
          632,
          19737,
          281,
          360,
          300,
          965,
          11,
          51250
        ]
      },
      {
        "avg_logprob": -0.2398322312148301,
        "compression_ratio": 1.6537102473498233,
        "end": 1096.36,
        "id": 403,
        "no_speech_prob": 0.000011125585842819419,
        "seek": 107512,
        "start": 1092.84,
        "temperature": 0,
        "text": " but I talk too much, and there's limited time.",
        "tokens": [
          51250,
          457,
          286,
          751,
          886,
          709,
          11,
          293,
          456,
          311,
          5567,
          565,
          13,
          51426
        ]
      },
      {
        "avg_logprob": -0.2398322312148301,
        "compression_ratio": 1.6537102473498233,
        "end": 1098.2399999999998,
        "id": 404,
        "no_speech_prob": 0.000011125585842819419,
        "seek": 107512,
        "start": 1096.36,
        "temperature": 0,
        "text": " But that's coming next week.",
        "tokens": [
          51426,
          583,
          300,
          311,
          1348,
          958,
          1243,
          13,
          51520
        ]
      },
      {
        "avg_logprob": -0.2398322312148301,
        "compression_ratio": 1.6537102473498233,
        "end": 1100.1999999999998,
        "id": 405,
        "no_speech_prob": 0.000011125585842819419,
        "seek": 107512,
        "start": 1098.2399999999998,
        "temperature": 0,
        "text": " Another thing I forgot in here.",
        "tokens": [
          51520,
          3996,
          551,
          286,
          5298,
          294,
          510,
          13,
          51618
        ]
      },
      {
        "avg_logprob": -0.2398322312148301,
        "compression_ratio": 1.6537102473498233,
        "end": 1102.4799999999998,
        "id": 406,
        "no_speech_prob": 0.000011125585842819419,
        "seek": 107512,
        "start": 1100.1999999999998,
        "temperature": 0,
        "text": " I wanted to make, like, make your own",
        "tokens": [
          51618,
          286,
          1415,
          281,
          652,
          11,
          411,
          11,
          652,
          428,
          1065,
          51732
        ]
      },
      {
        "avg_logprob": -0.36532617122568983,
        "compression_ratio": 1.4676616915422886,
        "end": 1106.6,
        "id": 407,
        "no_speech_prob": 0.00010554574691923335,
        "seek": 110248,
        "start": 1103.32,
        "temperature": 0,
        "text": " TF Playground.",
        "tokens": [
          50406,
          40964,
          5506,
          2921,
          13,
          50570
        ]
      },
      {
        "avg_logprob": -0.36532617122568983,
        "compression_ratio": 1.4676616915422886,
        "end": 1111.44,
        "id": 408,
        "no_speech_prob": 0.00010554574691923335,
        "seek": 110248,
        "start": 1109.28,
        "temperature": 0,
        "text": " So just briefly, one last thing that I'll mention",
        "tokens": [
          50704,
          407,
          445,
          10515,
          11,
          472,
          1036,
          551,
          300,
          286,
          603,
          2152,
          50812
        ]
      },
      {
        "avg_logprob": -0.36532617122568983,
        "compression_ratio": 1.4676616915422886,
        "end": 1113.24,
        "id": 409,
        "no_speech_prob": 0.00010554574691923335,
        "seek": 110248,
        "start": 1111.44,
        "temperature": 0,
        "text": " here on this to-do list.",
        "tokens": [
          50812,
          510,
          322,
          341,
          281,
          12,
          2595,
          1329,
          13,
          50902
        ]
      },
      {
        "avg_logprob": -0.36532617122568983,
        "compression_ratio": 1.4676616915422886,
        "end": 1118.24,
        "id": 410,
        "no_speech_prob": 0.00010554574691923335,
        "seek": 110248,
        "start": 1113.24,
        "temperature": 0,
        "text": " If you go to, I believe it's playground.tensorflow.js.",
        "tokens": [
          50902,
          759,
          291,
          352,
          281,
          11,
          286,
          1697,
          309,
          311,
          24646,
          13,
          83,
          23153,
          10565,
          13,
          25530,
          13,
          51152
        ]
      },
      {
        "avg_logprob": -0.36532617122568983,
        "compression_ratio": 1.4676616915422886,
        "end": 1120.56,
        "id": 411,
        "no_speech_prob": 0.00010554574691923335,
        "seek": 110248,
        "start": 1119.72,
        "temperature": 0,
        "text": " Is that?",
        "tokens": [
          51226,
          1119,
          300,
          30,
          51268
        ]
      },
      {
        "avg_logprob": -0.36532617122568983,
        "compression_ratio": 1.4676616915422886,
        "end": 1123.28,
        "id": 412,
        "no_speech_prob": 0.00010554574691923335,
        "seek": 110248,
        "start": 1121.72,
        "temperature": 0,
        "text": " Well, hold on.",
        "tokens": [
          51326,
          1042,
          11,
          1797,
          322,
          13,
          51404
        ]
      },
      {
        "avg_logprob": -0.36532617122568983,
        "compression_ratio": 1.4676616915422886,
        "end": 1125.66,
        "id": 413,
        "no_speech_prob": 0.00010554574691923335,
        "seek": 110248,
        "start": 1123.28,
        "temperature": 0,
        "text": " J, whatever, TensorFlow Playground.",
        "tokens": [
          51404,
          508,
          11,
          2035,
          11,
          37624,
          5506,
          2921,
          13,
          51523
        ]
      },
      {
        "avg_logprob": -0.36532617122568983,
        "compression_ratio": 1.4676616915422886,
        "end": 1130.2,
        "id": 414,
        "no_speech_prob": 0.00010554574691923335,
        "seek": 110248,
        "start": 1126.72,
        "temperature": 0,
        "text": " This is a project from the Big Picture group,",
        "tokens": [
          51576,
          639,
          307,
          257,
          1716,
          490,
          264,
          5429,
          35730,
          1594,
          11,
          51750
        ]
      },
      {
        "avg_logprob": -0.36532617122568983,
        "compression_ratio": 1.4676616915422886,
        "end": 1132.4,
        "id": 415,
        "no_speech_prob": 0.00010554574691923335,
        "seek": 110248,
        "start": 1130.2,
        "temperature": 0,
        "text": " the research group from Google that created,",
        "tokens": [
          51750,
          264,
          2132,
          1594,
          490,
          3329,
          300,
          2942,
          11,
          51860
        ]
      },
      {
        "avg_logprob": -0.2374866485595703,
        "compression_ratio": 1.8012820512820513,
        "end": 1134.64,
        "id": 416,
        "no_speech_prob": 0.0003920402377843857,
        "seek": 113240,
        "start": 1133.24,
        "temperature": 0,
        "text": " where TensorFlow.js itself came out of.",
        "tokens": [
          50406,
          689,
          37624,
          13,
          25530,
          2564,
          1361,
          484,
          295,
          13,
          50476
        ]
      },
      {
        "avg_logprob": -0.2374866485595703,
        "compression_ratio": 1.8012820512820513,
        "end": 1137.52,
        "id": 417,
        "no_speech_prob": 0.0003920402377843857,
        "seek": 113240,
        "start": 1134.64,
        "temperature": 0,
        "text": " And you can kind of create this little playground",
        "tokens": [
          50476,
          400,
          291,
          393,
          733,
          295,
          1884,
          341,
          707,
          24646,
          50620
        ]
      },
      {
        "avg_logprob": -0.2374866485595703,
        "compression_ratio": 1.8012820512820513,
        "end": 1139.8600000000001,
        "id": 418,
        "no_speech_prob": 0.0003920402377843857,
        "seek": 113240,
        "start": 1137.52,
        "temperature": 0,
        "text": " in the browser where you can configure a neural network,",
        "tokens": [
          50620,
          294,
          264,
          11185,
          689,
          291,
          393,
          22162,
          257,
          18161,
          3209,
          11,
          50737
        ]
      },
      {
        "avg_logprob": -0.2374866485595703,
        "compression_ratio": 1.8012820512820513,
        "end": 1142,
        "id": 419,
        "no_speech_prob": 0.0003920402377843857,
        "seek": 113240,
        "start": 1139.8600000000001,
        "temperature": 0,
        "text": " you can have this kind of 2D dataset,",
        "tokens": [
          50737,
          291,
          393,
          362,
          341,
          733,
          295,
          568,
          35,
          28872,
          11,
          50844
        ]
      },
      {
        "avg_logprob": -0.2374866485595703,
        "compression_ratio": 1.8012820512820513,
        "end": 1144.1200000000001,
        "id": 420,
        "no_speech_prob": 0.0003920402377843857,
        "seek": 113240,
        "start": 1142,
        "temperature": 0,
        "text": " you can actually, there's like a play button,",
        "tokens": [
          50844,
          291,
          393,
          767,
          11,
          456,
          311,
          411,
          257,
          862,
          2960,
          11,
          50950
        ]
      },
      {
        "avg_logprob": -0.2374866485595703,
        "compression_ratio": 1.8012820512820513,
        "end": 1146.26,
        "id": 421,
        "no_speech_prob": 0.0003920402377843857,
        "seek": 113240,
        "start": 1144.1200000000001,
        "temperature": 0,
        "text": " so you can run it, and you can watch it",
        "tokens": [
          50950,
          370,
          291,
          393,
          1190,
          309,
          11,
          293,
          291,
          393,
          1159,
          309,
          51057
        ]
      },
      {
        "avg_logprob": -0.2374866485595703,
        "compression_ratio": 1.8012820512820513,
        "end": 1148.5600000000002,
        "id": 422,
        "no_speech_prob": 0.0003920402377843857,
        "seek": 113240,
        "start": 1146.26,
        "temperature": 0,
        "text": " try to either classify, and there it goes,",
        "tokens": [
          51057,
          853,
          281,
          2139,
          33872,
          11,
          293,
          456,
          309,
          1709,
          11,
          51172
        ]
      },
      {
        "avg_logprob": -0.2374866485595703,
        "compression_ratio": 1.8012820512820513,
        "end": 1150.44,
        "id": 423,
        "no_speech_prob": 0.0003920402377843857,
        "seek": 113240,
        "start": 1148.5600000000002,
        "temperature": 0,
        "text": " sort of classify, or I don't know",
        "tokens": [
          51172,
          1333,
          295,
          33872,
          11,
          420,
          286,
          500,
          380,
          458,
          51266
        ]
      },
      {
        "avg_logprob": -0.2374866485595703,
        "compression_ratio": 1.8012820512820513,
        "end": 1151.68,
        "id": 424,
        "no_speech_prob": 0.0003920402377843857,
        "seek": 113240,
        "start": 1150.44,
        "temperature": 0,
        "text": " whether it's doing classification or regression.",
        "tokens": [
          51266,
          1968,
          309,
          311,
          884,
          21538,
          420,
          24590,
          13,
          51328
        ]
      },
      {
        "avg_logprob": -0.2374866485595703,
        "compression_ratio": 1.8012820512820513,
        "end": 1152.68,
        "id": 425,
        "no_speech_prob": 0.0003920402377843857,
        "seek": 113240,
        "start": 1151.68,
        "temperature": 0,
        "text": " It looks like classification to me,",
        "tokens": [
          51328,
          467,
          1542,
          411,
          21538,
          281,
          385,
          11,
          51378
        ]
      },
      {
        "avg_logprob": -0.2374866485595703,
        "compression_ratio": 1.8012820512820513,
        "end": 1153.92,
        "id": 426,
        "no_speech_prob": 0.0003920402377843857,
        "seek": 113240,
        "start": 1152.68,
        "temperature": 0,
        "text": " they're sort of blue and orange.",
        "tokens": [
          51378,
          436,
          434,
          1333,
          295,
          3344,
          293,
          7671,
          13,
          51440
        ]
      },
      {
        "avg_logprob": -0.2374866485595703,
        "compression_ratio": 1.8012820512820513,
        "end": 1157.7800000000002,
        "id": 427,
        "no_speech_prob": 0.0003920402377843857,
        "seek": 113240,
        "start": 1153.92,
        "temperature": 0,
        "text": " So I have no interest in building out something",
        "tokens": [
          51440,
          407,
          286,
          362,
          572,
          1179,
          294,
          2390,
          484,
          746,
          51633
        ]
      },
      {
        "avg_logprob": -0.2374866485595703,
        "compression_ratio": 1.8012820512820513,
        "end": 1161.48,
        "id": 428,
        "no_speech_prob": 0.0003920402377843857,
        "seek": 113240,
        "start": 1157.7800000000002,
        "temperature": 0,
        "text": " that has this level of sophistication in design,",
        "tokens": [
          51633,
          300,
          575,
          341,
          1496,
          295,
          15572,
          399,
          294,
          1715,
          11,
          51818
        ]
      },
      {
        "avg_logprob": -0.3261922960696013,
        "compression_ratio": 1.4570135746606334,
        "end": 1164.08,
        "id": 429,
        "no_speech_prob": 0.0000040929089664132334,
        "seek": 116148,
        "start": 1161.48,
        "temperature": 0,
        "text": " visual design, but I would like to show you,",
        "tokens": [
          50364,
          5056,
          1715,
          11,
          457,
          286,
          576,
          411,
          281,
          855,
          291,
          11,
          50494
        ]
      },
      {
        "avg_logprob": -0.3261922960696013,
        "compression_ratio": 1.4570135746606334,
        "end": 1167.16,
        "id": 430,
        "no_speech_prob": 0.0000040929089664132334,
        "seek": 116148,
        "start": 1164.08,
        "temperature": 0,
        "text": " well, could you, similarly to how I made",
        "tokens": [
          50494,
          731,
          11,
          727,
          291,
          11,
          14138,
          281,
          577,
          286,
          1027,
          50648
        ]
      },
      {
        "avg_logprob": -0.3261922960696013,
        "compression_ratio": 1.4570135746606334,
        "end": 1170.48,
        "id": 431,
        "no_speech_prob": 0.0000040929089664132334,
        "seek": 116148,
        "start": 1167.16,
        "temperature": 0,
        "text": " the linear regression, the polynomial regression examples,",
        "tokens": [
          50648,
          264,
          8213,
          24590,
          11,
          264,
          26110,
          24590,
          5110,
          11,
          50814
        ]
      },
      {
        "avg_logprob": -0.3261922960696013,
        "compression_ratio": 1.4570135746606334,
        "end": 1173.88,
        "id": 432,
        "no_speech_prob": 0.0000040929089664132334,
        "seek": 116148,
        "start": 1170.48,
        "temperature": 0,
        "text": " maybe I'll just do like a basic 2D classification problem",
        "tokens": [
          50814,
          1310,
          286,
          603,
          445,
          360,
          411,
          257,
          3875,
          568,
          35,
          21538,
          1154,
          50984
        ]
      },
      {
        "avg_logprob": -0.3261922960696013,
        "compression_ratio": 1.4570135746606334,
        "end": 1176.02,
        "id": 433,
        "no_speech_prob": 0.0000040929089664132334,
        "seek": 116148,
        "start": 1174.72,
        "temperature": 0,
        "text": " with drawing stuff.",
        "tokens": [
          51026,
          365,
          6316,
          1507,
          13,
          51091
        ]
      },
      {
        "avg_logprob": -0.3261922960696013,
        "compression_ratio": 1.4570135746606334,
        "end": 1178.58,
        "id": 434,
        "no_speech_prob": 0.0000040929089664132334,
        "seek": 116148,
        "start": 1177.28,
        "temperature": 0,
        "text": " Okay, so.",
        "tokens": [
          51154,
          1033,
          11,
          370,
          13,
          51219
        ]
      },
      {
        "avg_logprob": -0.3261922960696013,
        "compression_ratio": 1.4570135746606334,
        "end": 1182.24,
        "id": 435,
        "no_speech_prob": 0.0000040929089664132334,
        "seek": 116148,
        "start": 1179.96,
        "temperature": 0,
        "text": " That's my introductory talk.",
        "tokens": [
          51288,
          663,
          311,
          452,
          39048,
          751,
          13,
          51402
        ]
      },
      {
        "avg_logprob": -0.3261922960696013,
        "compression_ratio": 1.4570135746606334,
        "end": 1185.24,
        "id": 436,
        "no_speech_prob": 0.0000040929089664132334,
        "seek": 116148,
        "start": 1184.4,
        "temperature": 0,
        "text": " I love this.",
        "tokens": [
          51510,
          286,
          959,
          341,
          13,
          51552
        ]
      },
      {
        "avg_logprob": -0.3261922960696013,
        "compression_ratio": 1.4570135746606334,
        "end": 1190.16,
        "id": 437,
        "no_speech_prob": 0.0000040929089664132334,
        "seek": 116148,
        "start": 1186.96,
        "temperature": 0,
        "text": " Go, you little neurons, send that data, whoosh.",
        "tokens": [
          51638,
          1037,
          11,
          291,
          707,
          22027,
          11,
          2845,
          300,
          1412,
          11,
          567,
          3019,
          13,
          51798
        ]
      },
      {
        "avg_logprob": -0.26492650885331004,
        "compression_ratio": 1.5756302521008403,
        "end": 1193.02,
        "id": 438,
        "no_speech_prob": 0.00004908650953439064,
        "seek": 119148,
        "start": 1192.18,
        "temperature": 0,
        "text": " Whoosh.",
        "tokens": [
          50399,
          2102,
          3019,
          13,
          50441
        ]
      },
      {
        "avg_logprob": -0.26492650885331004,
        "compression_ratio": 1.5756302521008403,
        "end": 1195.2,
        "id": 439,
        "no_speech_prob": 0.00004908650953439064,
        "seek": 119148,
        "start": 1194.3600000000001,
        "temperature": 0,
        "text": " All right.",
        "tokens": [
          50508,
          1057,
          558,
          13,
          50550
        ]
      },
      {
        "avg_logprob": -0.26492650885331004,
        "compression_ratio": 1.5756302521008403,
        "end": 1199.6,
        "id": 440,
        "no_speech_prob": 0.00004908650953439064,
        "seek": 119148,
        "start": 1198.16,
        "temperature": 0,
        "text": " Oh, oh, I can break it.",
        "tokens": [
          50698,
          876,
          11,
          1954,
          11,
          286,
          393,
          1821,
          309,
          13,
          50770
        ]
      },
      {
        "avg_logprob": -0.26492650885331004,
        "compression_ratio": 1.5756302521008403,
        "end": 1201.06,
        "id": 441,
        "no_speech_prob": 0.00004908650953439064,
        "seek": 119148,
        "start": 1199.6,
        "temperature": 0,
        "text": " I'm very good at breaking things.",
        "tokens": [
          50770,
          286,
          478,
          588,
          665,
          412,
          7697,
          721,
          13,
          50843
        ]
      },
      {
        "avg_logprob": -0.26492650885331004,
        "compression_ratio": 1.5756302521008403,
        "end": 1202.44,
        "id": 442,
        "no_speech_prob": 0.00004908650953439064,
        "seek": 119148,
        "start": 1201.06,
        "temperature": 0,
        "text": " All right, so that's where I am.",
        "tokens": [
          50843,
          1057,
          558,
          11,
          370,
          300,
          311,
          689,
          286,
          669,
          13,
          50912
        ]
      },
      {
        "avg_logprob": -0.26492650885331004,
        "compression_ratio": 1.5756302521008403,
        "end": 1205.56,
        "id": 443,
        "no_speech_prob": 0.00004908650953439064,
        "seek": 119148,
        "start": 1202.44,
        "temperature": 0,
        "text": " So I think when all is said and done,",
        "tokens": [
          50912,
          407,
          286,
          519,
          562,
          439,
          307,
          848,
          293,
          1096,
          11,
          51068
        ]
      },
      {
        "avg_logprob": -0.26492650885331004,
        "compression_ratio": 1.5756302521008403,
        "end": 1208.96,
        "id": 444,
        "no_speech_prob": 0.00004908650953439064,
        "seek": 119148,
        "start": 1205.56,
        "temperature": 0,
        "text": " I think right now I'm just going to tackle today,",
        "tokens": [
          51068,
          286,
          519,
          558,
          586,
          286,
          478,
          445,
          516,
          281,
          14896,
          965,
          11,
          51238
        ]
      },
      {
        "avg_logprob": -0.26492650885331004,
        "compression_ratio": 1.5756302521008403,
        "end": 1212.6,
        "id": 445,
        "no_speech_prob": 0.00004908650953439064,
        "seek": 119148,
        "start": 1208.96,
        "temperature": 0,
        "text": " from now until about 2.30, which is an hour and a half,",
        "tokens": [
          51238,
          490,
          586,
          1826,
          466,
          568,
          13,
          3446,
          11,
          597,
          307,
          364,
          1773,
          293,
          257,
          1922,
          11,
          51420
        ]
      },
      {
        "avg_logprob": -0.26492650885331004,
        "compression_ratio": 1.5756302521008403,
        "end": 1216.3600000000001,
        "id": 446,
        "no_speech_prob": 0.00004908650953439064,
        "seek": 119148,
        "start": 1212.6,
        "temperature": 0,
        "text": " XOR, and I really am torn, like I don't want to do it,",
        "tokens": [
          51420,
          1783,
          2483,
          11,
          293,
          286,
          534,
          669,
          10885,
          11,
          411,
          286,
          500,
          380,
          528,
          281,
          360,
          309,
          11,
          51608
        ]
      },
      {
        "avg_logprob": -0.26492650885331004,
        "compression_ratio": 1.5756302521008403,
        "end": 1219.72,
        "id": 447,
        "no_speech_prob": 0.00004908650953439064,
        "seek": 119148,
        "start": 1216.3600000000001,
        "temperature": 0,
        "text": " because it's sort of, but it's good for me,",
        "tokens": [
          51608,
          570,
          309,
          311,
          1333,
          295,
          11,
          457,
          309,
          311,
          665,
          337,
          385,
          11,
          51776
        ]
      },
      {
        "avg_logprob": -0.26492650885331004,
        "compression_ratio": 1.5756302521008403,
        "end": 1220.82,
        "id": 448,
        "no_speech_prob": 0.00004908650953439064,
        "seek": 119148,
        "start": 1219.72,
        "temperature": 0,
        "text": " so I'm going to do it.",
        "tokens": [
          51776,
          370,
          286,
          478,
          516,
          281,
          360,
          309,
          13,
          51831
        ]
      },
      {
        "avg_logprob": -0.30799173990885415,
        "compression_ratio": 1.3964497041420119,
        "end": 1224.06,
        "id": 449,
        "no_speech_prob": 0.00001618740861886181,
        "seek": 122148,
        "start": 1222,
        "temperature": 0,
        "text": " All right, but before I do that,",
        "tokens": [
          50390,
          1057,
          558,
          11,
          457,
          949,
          286,
          360,
          300,
          11,
          50493
        ]
      },
      {
        "avg_logprob": -0.30799173990885415,
        "compression_ratio": 1.3964497041420119,
        "end": 1226.24,
        "id": 450,
        "no_speech_prob": 0.00001618740861886181,
        "seek": 122148,
        "start": 1224.06,
        "temperature": 0,
        "text": " let me see if I can get some questions",
        "tokens": [
          50493,
          718,
          385,
          536,
          498,
          286,
          393,
          483,
          512,
          1651,
          50602
        ]
      },
      {
        "avg_logprob": -0.30799173990885415,
        "compression_ratio": 1.3964497041420119,
        "end": 1228.6,
        "id": 451,
        "no_speech_prob": 0.00001618740861886181,
        "seek": 122148,
        "start": 1227.28,
        "temperature": 0,
        "text": " and get myself organized.",
        "tokens": [
          50654,
          293,
          483,
          2059,
          9983,
          13,
          50720
        ]
      },
      {
        "avg_logprob": -0.30799173990885415,
        "compression_ratio": 1.3964497041420119,
        "end": 1235.48,
        "id": 452,
        "no_speech_prob": 0.00001618740861886181,
        "seek": 122148,
        "start": 1231.44,
        "temperature": 0,
        "text": " Anybody have any questions about ML5, TensorFlow.js?",
        "tokens": [
          50862,
          19082,
          362,
          604,
          1651,
          466,
          21601,
          20,
          11,
          37624,
          13,
          25530,
          30,
          51064
        ]
      },
      {
        "avg_logprob": -0.30799173990885415,
        "compression_ratio": 1.3964497041420119,
        "end": 1241.14,
        "id": 453,
        "no_speech_prob": 0.00001618740861886181,
        "seek": 122148,
        "start": 1239.52,
        "temperature": 0,
        "text": " Life, the universe.",
        "tokens": [
          51266,
          7720,
          11,
          264,
          6445,
          13,
          51347
        ]
      },
      {
        "avg_logprob": -0.30799173990885415,
        "compression_ratio": 1.3964497041420119,
        "end": 1245.64,
        "id": 454,
        "no_speech_prob": 0.00001618740861886181,
        "seek": 122148,
        "start": 1244.4,
        "temperature": 0,
        "text": " How to play the ukulele.",
        "tokens": [
          51510,
          1012,
          281,
          862,
          264,
          26769,
          2271,
          306,
          13,
          51572
        ]
      },
      {
        "avg_logprob": -0.30799173990885415,
        "compression_ratio": 1.3964497041420119,
        "end": 1250.24,
        "id": 455,
        "no_speech_prob": 0.00001618740861886181,
        "seek": 122148,
        "start": 1248.24,
        "temperature": 0,
        "text": " All right, so what do I need to do here?",
        "tokens": [
          51702,
          1057,
          558,
          11,
          370,
          437,
          360,
          286,
          643,
          281,
          360,
          510,
          30,
          51802
        ]
      },
      {
        "avg_logprob": -0.359088659286499,
        "compression_ratio": 1.3806451612903226,
        "end": 1253.16,
        "id": 456,
        "no_speech_prob": 0.000022125241230241954,
        "seek": 125148,
        "start": 1252.1200000000001,
        "temperature": 0,
        "text": " There's a couple things that I need.",
        "tokens": [
          50396,
          821,
          311,
          257,
          1916,
          721,
          300,
          286,
          643,
          13,
          50448
        ]
      },
      {
        "avg_logprob": -0.359088659286499,
        "compression_ratio": 1.3806451612903226,
        "end": 1255.08,
        "id": 457,
        "no_speech_prob": 0.000022125241230241954,
        "seek": 125148,
        "start": 1253.16,
        "temperature": 0,
        "text": " Number one is...",
        "tokens": [
          50448,
          5118,
          472,
          307,
          485,
          50544
        ]
      },
      {
        "avg_logprob": -0.359088659286499,
        "compression_ratio": 1.3806451612903226,
        "end": 1267.6,
        "id": 458,
        "no_speech_prob": 0.000022125241230241954,
        "seek": 125148,
        "start": 1265.76,
        "temperature": 0,
        "text": " Where is websites?",
        "tokens": [
          51078,
          2305,
          307,
          12891,
          30,
          51170
        ]
      },
      {
        "avg_logprob": -0.359088659286499,
        "compression_ratio": 1.3806451612903226,
        "end": 1270.08,
        "id": 459,
        "no_speech_prob": 0.000022125241230241954,
        "seek": 125148,
        "start": 1268.6,
        "temperature": 0,
        "text": " Just looking at the...",
        "tokens": [
          51220,
          1449,
          1237,
          412,
          264,
          485,
          51294
        ]
      },
      {
        "avg_logprob": -0.359088659286499,
        "compression_ratio": 1.3806451612903226,
        "end": 1274.42,
        "id": 460,
        "no_speech_prob": 0.000022125241230241954,
        "seek": 125148,
        "start": 1270.08,
        "temperature": 0,
        "text": " If anyone who is a sponsor, a patron,",
        "tokens": [
          51294,
          759,
          2878,
          567,
          307,
          257,
          16198,
          11,
          257,
          21843,
          11,
          51511
        ]
      },
      {
        "avg_logprob": -0.359088659286499,
        "compression_ratio": 1.3806451612903226,
        "end": 1278.6,
        "id": 461,
        "no_speech_prob": 0.000022125241230241954,
        "seek": 125148,
        "start": 1275.96,
        "temperature": 0,
        "text": " there's an interesting question in the YouTube chat",
        "tokens": [
          51588,
          456,
          311,
          364,
          1880,
          1168,
          294,
          264,
          3088,
          5081,
          51720
        ]
      },
      {
        "avg_logprob": -0.359088659286499,
        "compression_ratio": 1.3806451612903226,
        "end": 1280.9,
        "id": 462,
        "no_speech_prob": 0.000022125241230241954,
        "seek": 125148,
        "start": 1278.6,
        "temperature": 0,
        "text": " that I might like to answer.",
        "tokens": [
          51720,
          300,
          286,
          1062,
          411,
          281,
          1867,
          13,
          51835
        ]
      },
      {
        "avg_logprob": -0.5805024319007749,
        "compression_ratio": 1.2136752136752136,
        "end": 1285.3400000000001,
        "id": 463,
        "no_speech_prob": 0.00011412069579819217,
        "seek": 128090,
        "start": 1281.3400000000001,
        "temperature": 0,
        "text": " You can paste it into the Slack channel.",
        "tokens": [
          50386,
          509,
          393,
          9163,
          309,
          666,
          264,
          37211,
          2269,
          13,
          50586
        ]
      },
      {
        "avg_logprob": -0.5805024319007749,
        "compression_ratio": 1.2136752136752136,
        "end": 1290.3000000000002,
        "id": 464,
        "no_speech_prob": 0.00011412069579819217,
        "seek": 128090,
        "start": 1288.8200000000002,
        "temperature": 0,
        "text": " This is not right.",
        "tokens": [
          50760,
          639,
          307,
          406,
          558,
          13,
          50834
        ]
      },
      {
        "avg_logprob": -0.5805024319007749,
        "compression_ratio": 1.2136752136752136,
        "end": 1291.14,
        "id": 465,
        "no_speech_prob": 0.00011412069579819217,
        "seek": 128090,
        "start": 1290.3000000000002,
        "temperature": 0,
        "text": " Where am I?",
        "tokens": [
          50834,
          2305,
          669,
          286,
          30,
          50876
        ]
      },
      {
        "avg_logprob": -0.5805024319007749,
        "compression_ratio": 1.2136752136752136,
        "end": 1291.96,
        "id": 466,
        "no_speech_prob": 0.00011412069579819217,
        "seek": 128090,
        "start": 1291.14,
        "temperature": 0,
        "text": " Nope, nope, nope.",
        "tokens": [
          50876,
          12172,
          11,
          23444,
          11,
          23444,
          13,
          50917
        ]
      },
      {
        "avg_logprob": -0.5805024319007749,
        "compression_ratio": 1.2136752136752136,
        "end": 1296.7800000000002,
        "id": 467,
        "no_speech_prob": 0.00011412069579819217,
        "seek": 128090,
        "start": 1295.94,
        "temperature": 0,
        "text": " Oh.",
        "tokens": [
          51116,
          876,
          13,
          51158
        ]
      },
      {
        "avg_logprob": -0.5805024319007749,
        "compression_ratio": 1.2136752136752136,
        "end": 1302.94,
        "id": 468,
        "no_speech_prob": 0.00011412069579819217,
        "seek": 128090,
        "start": 1298.9,
        "temperature": 0,
        "text": " Poodly, poppidly, dooby dooby, wah.",
        "tokens": [
          51264,
          430,
          1816,
          356,
          11,
          1665,
          79,
          327,
          356,
          11,
          360,
          13944,
          360,
          13944,
          11,
          31979,
          13,
          51466
        ]
      },
      {
        "avg_logprob": -0.5805024319007749,
        "compression_ratio": 1.2136752136752136,
        "end": 1303.7800000000002,
        "id": 469,
        "no_speech_prob": 0.00011412069579819217,
        "seek": 128090,
        "start": 1302.94,
        "temperature": 0,
        "text": " There we go.",
        "tokens": [
          51466,
          821,
          321,
          352,
          13,
          51508
        ]
      },
      {
        "avg_logprob": -0.4805241485140217,
        "compression_ratio": 1.2905405405405406,
        "end": 1311.72,
        "id": 470,
        "no_speech_prob": 0.000012029611752950586,
        "seek": 131090,
        "start": 1310.9,
        "temperature": 0,
        "text": " All right.",
        "tokens": [
          50364,
          1057,
          558,
          13,
          50405
        ]
      },
      {
        "avg_logprob": -0.4805241485140217,
        "compression_ratio": 1.2905405405405406,
        "end": 1321.7,
        "id": 471,
        "no_speech_prob": 0.000012029611752950586,
        "seek": 131090,
        "start": 1320.14,
        "temperature": 0,
        "text": " All right, there's two bits of code",
        "tokens": [
          50826,
          1057,
          558,
          11,
          456,
          311,
          732,
          9239,
          295,
          3089,
          50904
        ]
      },
      {
        "avg_logprob": -0.4805241485140217,
        "compression_ratio": 1.2905405405405406,
        "end": 1324.1000000000001,
        "id": 472,
        "no_speech_prob": 0.000012029611752950586,
        "seek": 131090,
        "start": 1321.7,
        "temperature": 0,
        "text": " that I need to get started with this.",
        "tokens": [
          50904,
          300,
          286,
          643,
          281,
          483,
          1409,
          365,
          341,
          13,
          51024
        ]
      },
      {
        "avg_logprob": -0.4805241485140217,
        "compression_ratio": 1.2905405405405406,
        "end": 1325.14,
        "id": 473,
        "no_speech_prob": 0.000012029611752950586,
        "seek": 131090,
        "start": 1324.1000000000001,
        "temperature": 0,
        "text": " One...",
        "tokens": [
          51024,
          1485,
          485,
          51076
        ]
      },
      {
        "avg_logprob": -0.4805241485140217,
        "compression_ratio": 1.2905405405405406,
        "end": 1331.22,
        "id": 474,
        "no_speech_prob": 0.000012029611752950586,
        "seek": 131090,
        "start": 1328.0600000000002,
        "temperature": 0,
        "text": " Is the actual previous XOR.",
        "tokens": [
          51222,
          1119,
          264,
          3539,
          3894,
          1783,
          2483,
          13,
          51380
        ]
      },
      {
        "avg_logprob": -0.4805241485140217,
        "compression_ratio": 1.2905405405405406,
        "end": 1336.3000000000002,
        "id": 475,
        "no_speech_prob": 0.000012029611752950586,
        "seek": 131090,
        "start": 1334.94,
        "temperature": 0,
        "text": " Oh, you gotta be kidding me.",
        "tokens": [
          51566,
          876,
          11,
          291,
          3428,
          312,
          9287,
          385,
          13,
          51634
        ]
      },
      {
        "avg_logprob": -0.4805241485140217,
        "compression_ratio": 1.2905405405405406,
        "end": 1337.14,
        "id": 476,
        "no_speech_prob": 0.000012029611752950586,
        "seek": 131090,
        "start": 1336.3000000000002,
        "temperature": 0,
        "text": " No, here.",
        "tokens": [
          51634,
          883,
          11,
          510,
          13,
          51676
        ]
      },
      {
        "avg_logprob": -0.4805241485140217,
        "compression_ratio": 1.2905405405405406,
        "end": 1340.26,
        "id": 477,
        "no_speech_prob": 0.000012029611752950586,
        "seek": 131090,
        "start": 1338.26,
        "temperature": 0,
        "text": " Here we go, coding challenge 92.",
        "tokens": [
          51732,
          1692,
          321,
          352,
          11,
          17720,
          3430,
          28225,
          13,
          51832
        ]
      },
      {
        "avg_logprob": -0.3610636591911316,
        "compression_ratio": 1.3426573426573427,
        "end": 1343.8200000000002,
        "id": 478,
        "no_speech_prob": 0.00004683875886257738,
        "seek": 134090,
        "start": 1341.5800000000002,
        "temperature": 0,
        "text": " And then I also want...",
        "tokens": [
          50398,
          400,
          550,
          286,
          611,
          528,
          485,
          50510
        ]
      },
      {
        "avg_logprob": -0.3610636591911316,
        "compression_ratio": 1.3426573426573427,
        "end": 1353.22,
        "id": 479,
        "no_speech_prob": 0.00004683875886257738,
        "seek": 134090,
        "start": 1349.5400000000002,
        "temperature": 0,
        "text": " To get under, maybe it's under courses,",
        "tokens": [
          50796,
          1407,
          483,
          833,
          11,
          1310,
          309,
          311,
          833,
          7712,
          11,
          50980
        ]
      },
      {
        "avg_logprob": -0.3610636591911316,
        "compression_ratio": 1.3426573426573427,
        "end": 1355.1200000000001,
        "id": 480,
        "no_speech_prob": 0.00004683875886257738,
        "seek": 134090,
        "start": 1353.22,
        "temperature": 0,
        "text": " intelligence and learning session.",
        "tokens": [
          50980,
          7599,
          293,
          2539,
          5481,
          13,
          51075
        ]
      },
      {
        "avg_logprob": -0.3610636591911316,
        "compression_ratio": 1.3426573426573427,
        "end": 1356.92,
        "id": 481,
        "no_speech_prob": 0.00004683875886257738,
        "seek": 134090,
        "start": 1356.0800000000002,
        "temperature": 0,
        "text": " Wait.",
        "tokens": [
          51123,
          3802,
          13,
          51165
        ]
      },
      {
        "avg_logprob": -0.3610636591911316,
        "compression_ratio": 1.3426573426573427,
        "end": 1361.44,
        "id": 482,
        "no_speech_prob": 0.00004683875886257738,
        "seek": 134090,
        "start": 1359.98,
        "temperature": 0,
        "text": " No, how come it's not there?",
        "tokens": [
          51318,
          883,
          11,
          577,
          808,
          309,
          311,
          406,
          456,
          30,
          51391
        ]
      },
      {
        "avg_logprob": -0.3610636591911316,
        "compression_ratio": 1.3426573426573427,
        "end": 1364.5,
        "id": 483,
        "no_speech_prob": 0.00004683875886257738,
        "seek": 134090,
        "start": 1362.3400000000001,
        "temperature": 0,
        "text": " Is this a different...",
        "tokens": [
          51436,
          1119,
          341,
          257,
          819,
          485,
          51544
        ]
      },
      {
        "avg_logprob": -0.3610636591911316,
        "compression_ratio": 1.3426573426573427,
        "end": 1366.44,
        "id": 484,
        "no_speech_prob": 0.00004683875886257738,
        "seek": 134090,
        "start": 1364.5,
        "temperature": 0,
        "text": " Oh, past, I'm in a different place.",
        "tokens": [
          51544,
          876,
          11,
          1791,
          11,
          286,
          478,
          294,
          257,
          819,
          1081,
          13,
          51641
        ]
      },
      {
        "avg_logprob": -0.41246648736902186,
        "compression_ratio": 1.394904458598726,
        "end": 1367.3600000000001,
        "id": 485,
        "no_speech_prob": 0.000014510445907944813,
        "seek": 136644,
        "start": 1366.52,
        "temperature": 0,
        "text": " Tsk.",
        "tokens": [
          50368,
          314,
          5161,
          13,
          50410
        ]
      },
      {
        "avg_logprob": -0.41246648736902186,
        "compression_ratio": 1.394904458598726,
        "end": 1373.3200000000002,
        "id": 486,
        "no_speech_prob": 0.000014510445907944813,
        "seek": 136644,
        "start": 1370.76,
        "temperature": 0,
        "text": " I have this in too many places.",
        "tokens": [
          50580,
          286,
          362,
          341,
          294,
          886,
          867,
          3190,
          13,
          50708
        ]
      },
      {
        "avg_logprob": -0.41246648736902186,
        "compression_ratio": 1.394904458598726,
        "end": 1377.24,
        "id": 487,
        "no_speech_prob": 0.000014510445907944813,
        "seek": 136644,
        "start": 1373.3200000000002,
        "temperature": 0,
        "text": " Courses, intelligence and learning session six.",
        "tokens": [
          50708,
          383,
          5067,
          279,
          11,
          7599,
          293,
          2539,
          5481,
          2309,
          13,
          50904
        ]
      },
      {
        "avg_logprob": -0.41246648736902186,
        "compression_ratio": 1.394904458598726,
        "end": 1378.88,
        "id": 488,
        "no_speech_prob": 0.000014510445907944813,
        "seek": 136644,
        "start": 1377.24,
        "temperature": 0,
        "text": " The layers API, I need that.",
        "tokens": [
          50904,
          440,
          7914,
          9362,
          11,
          286,
          643,
          300,
          13,
          50986
        ]
      },
      {
        "avg_logprob": -0.41246648736902186,
        "compression_ratio": 1.394904458598726,
        "end": 1384.0800000000002,
        "id": 489,
        "no_speech_prob": 0.000014510445907944813,
        "seek": 136644,
        "start": 1381.92,
        "temperature": 0,
        "text": " And then p5 TensorFlow.",
        "tokens": [
          51138,
          400,
          550,
          280,
          20,
          37624,
          13,
          51246
        ]
      },
      {
        "avg_logprob": -0.41246648736902186,
        "compression_ratio": 1.394904458598726,
        "end": 1387.16,
        "id": 490,
        "no_speech_prob": 0.000014510445907944813,
        "seek": 136644,
        "start": 1385.8,
        "temperature": 0,
        "text": " Let's put these in there.",
        "tokens": [
          51332,
          961,
          311,
          829,
          613,
          294,
          456,
          13,
          51400
        ]
      },
      {
        "avg_logprob": -0.41246648736902186,
        "compression_ratio": 1.394904458598726,
        "end": 1390.28,
        "id": 491,
        "no_speech_prob": 0.000014510445907944813,
        "seek": 136644,
        "start": 1388.72,
        "temperature": 0,
        "text": " And I don't need these anymore.",
        "tokens": [
          51478,
          400,
          286,
          500,
          380,
          643,
          613,
          3602,
          13,
          51556
        ]
      },
      {
        "avg_logprob": -0.41246648736902186,
        "compression_ratio": 1.394904458598726,
        "end": 1395,
        "id": 492,
        "no_speech_prob": 0.000014510445907944813,
        "seek": 136644,
        "start": 1391.2,
        "temperature": 0,
        "text": " And let's go over here.",
        "tokens": [
          51602,
          400,
          718,
          311,
          352,
          670,
          510,
          13,
          51792
        ]
      },
      {
        "avg_logprob": -0.3315457582473755,
        "compression_ratio": 1.5114942528735633,
        "end": 1401.44,
        "id": 493,
        "no_speech_prob": 0.0000359129517164547,
        "seek": 139644,
        "start": 1396.44,
        "temperature": 0,
        "text": " I don't know which would be better to start from.",
        "tokens": [
          50364,
          286,
          500,
          380,
          458,
          597,
          576,
          312,
          1101,
          281,
          722,
          490,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.3315457582473755,
        "compression_ratio": 1.5114942528735633,
        "end": 1404.3,
        "id": 494,
        "no_speech_prob": 0.0000359129517164547,
        "seek": 139644,
        "start": 1403.2,
        "temperature": 0,
        "text": " Let's start from this.",
        "tokens": [
          50702,
          961,
          311,
          722,
          490,
          341,
          13,
          50757
        ]
      },
      {
        "avg_logprob": -0.3315457582473755,
        "compression_ratio": 1.5114942528735633,
        "end": 1412.6000000000001,
        "id": 495,
        "no_speech_prob": 0.0000359129517164547,
        "seek": 139644,
        "start": 1410.2,
        "temperature": 0,
        "text": " This will be coding challenge what?",
        "tokens": [
          51052,
          639,
          486,
          312,
          17720,
          3430,
          437,
          30,
          51172
        ]
      },
      {
        "avg_logprob": -0.3315457582473755,
        "compression_ratio": 1.5114942528735633,
        "end": 1414.8400000000001,
        "id": 496,
        "no_speech_prob": 0.0000359129517164547,
        "seek": 139644,
        "start": 1412.6000000000001,
        "temperature": 0,
        "text": " What coding challenge number?",
        "tokens": [
          51172,
          708,
          17720,
          3430,
          1230,
          30,
          51284
        ]
      },
      {
        "avg_logprob": -0.3315457582473755,
        "compression_ratio": 1.5114942528735633,
        "end": 1417.72,
        "id": 497,
        "no_speech_prob": 0.0000359129517164547,
        "seek": 139644,
        "start": 1414.8400000000001,
        "temperature": 0,
        "text": " Isn't this the third time we do XOR?",
        "tokens": [
          51284,
          6998,
          380,
          341,
          264,
          2636,
          565,
          321,
          360,
          1783,
          2483,
          30,
          51428
        ]
      },
      {
        "avg_logprob": -0.3315457582473755,
        "compression_ratio": 1.5114942528735633,
        "end": 1418.76,
        "id": 498,
        "no_speech_prob": 0.0000359129517164547,
        "seek": 139644,
        "start": 1417.72,
        "temperature": 0,
        "text": " Is it really?",
        "tokens": [
          51428,
          1119,
          309,
          534,
          30,
          51480
        ]
      },
      {
        "avg_logprob": -0.3315457582473755,
        "compression_ratio": 1.5114942528735633,
        "end": 1423.52,
        "id": 499,
        "no_speech_prob": 0.0000359129517164547,
        "seek": 139644,
        "start": 1422.52,
        "temperature": 0,
        "text": " Oh, you're really torturing me",
        "tokens": [
          51668,
          876,
          11,
          291,
          434,
          534,
          10806,
          1345,
          385,
          51718
        ]
      },
      {
        "avg_logprob": -0.3315457582473755,
        "compression_ratio": 1.5114942528735633,
        "end": 1425.6000000000001,
        "id": 500,
        "no_speech_prob": 0.0000359129517164547,
        "seek": 139644,
        "start": 1423.52,
        "temperature": 0,
        "text": " because I really feel like I have a thing.",
        "tokens": [
          51718,
          570,
          286,
          534,
          841,
          411,
          286,
          362,
          257,
          551,
          13,
          51822
        ]
      },
      {
        "avg_logprob": -0.2899230888911656,
        "compression_ratio": 1.517391304347826,
        "end": 1428.72,
        "id": 501,
        "no_speech_prob": 0.000025867388103506528,
        "seek": 142644,
        "start": 1427.04,
        "temperature": 0,
        "text": " I have a little bit of a thing.",
        "tokens": [
          50394,
          286,
          362,
          257,
          707,
          857,
          295,
          257,
          551,
          13,
          50478
        ]
      },
      {
        "avg_logprob": -0.2899230888911656,
        "compression_ratio": 1.517391304347826,
        "end": 1430,
        "id": 502,
        "no_speech_prob": 0.000025867388103506528,
        "seek": 142644,
        "start": 1428.72,
        "temperature": 0,
        "text": " It's kind of a little...",
        "tokens": [
          50478,
          467,
          311,
          733,
          295,
          257,
          707,
          485,
          50542
        ]
      },
      {
        "avg_logprob": -0.2899230888911656,
        "compression_ratio": 1.517391304347826,
        "end": 1433.72,
        "id": 503,
        "no_speech_prob": 0.000025867388103506528,
        "seek": 142644,
        "start": 1431.6000000000001,
        "temperature": 0,
        "text": " If I'm listening to podcasts,",
        "tokens": [
          50622,
          759,
          286,
          478,
          4764,
          281,
          24045,
          11,
          50728
        ]
      },
      {
        "avg_logprob": -0.2899230888911656,
        "compression_ratio": 1.517391304347826,
        "end": 1436.52,
        "id": 504,
        "no_speech_prob": 0.000025867388103506528,
        "seek": 142644,
        "start": 1433.72,
        "temperature": 0,
        "text": " I have to listen to all of it every minute.",
        "tokens": [
          50728,
          286,
          362,
          281,
          2140,
          281,
          439,
          295,
          309,
          633,
          3456,
          13,
          50868
        ]
      },
      {
        "avg_logprob": -0.2899230888911656,
        "compression_ratio": 1.517391304347826,
        "end": 1439.14,
        "id": 505,
        "no_speech_prob": 0.000025867388103506528,
        "seek": 142644,
        "start": 1436.52,
        "temperature": 0,
        "text": " I can't not listen to one episode.",
        "tokens": [
          50868,
          286,
          393,
          380,
          406,
          2140,
          281,
          472,
          3500,
          13,
          50999
        ]
      },
      {
        "avg_logprob": -0.2899230888911656,
        "compression_ratio": 1.517391304347826,
        "end": 1444.52,
        "id": 506,
        "no_speech_prob": 0.000025867388103506528,
        "seek": 142644,
        "start": 1440.76,
        "temperature": 0,
        "text": " So somehow in my stuff, I just have to do the XOR now",
        "tokens": [
          51080,
          407,
          6063,
          294,
          452,
          1507,
          11,
          286,
          445,
          362,
          281,
          360,
          264,
          1783,
          2483,
          586,
          51268
        ]
      },
      {
        "avg_logprob": -0.2899230888911656,
        "compression_ratio": 1.517391304347826,
        "end": 1447.2,
        "id": 507,
        "no_speech_prob": 0.000025867388103506528,
        "seek": 142644,
        "start": 1444.52,
        "temperature": 0,
        "text": " with TensorFlow.js because I have to,",
        "tokens": [
          51268,
          365,
          37624,
          13,
          25530,
          570,
          286,
          362,
          281,
          11,
          51402
        ]
      },
      {
        "avg_logprob": -0.2899230888911656,
        "compression_ratio": 1.517391304347826,
        "end": 1448.56,
        "id": 508,
        "no_speech_prob": 0.000025867388103506528,
        "seek": 142644,
        "start": 1447.2,
        "temperature": 0,
        "text": " but maybe I should skip it.",
        "tokens": [
          51402,
          457,
          1310,
          286,
          820,
          10023,
          309,
          13,
          51470
        ]
      },
      {
        "avg_logprob": -0.2899230888911656,
        "compression_ratio": 1.517391304347826,
        "end": 1453.24,
        "id": 509,
        "no_speech_prob": 0.000025867388103506528,
        "seek": 142644,
        "start": 1451.48,
        "temperature": 0,
        "text": " What coding challenge number am I on?",
        "tokens": [
          51616,
          708,
          17720,
          3430,
          1230,
          669,
          286,
          322,
          30,
          51704
        ]
      },
      {
        "avg_logprob": -0.2899230888911656,
        "compression_ratio": 1.517391304347826,
        "end": 1454.3600000000001,
        "id": 510,
        "no_speech_prob": 0.000025867388103506528,
        "seek": 142644,
        "start": 1453.24,
        "temperature": 0,
        "text": " Did somebody tell me?",
        "tokens": [
          51704,
          2589,
          2618,
          980,
          385,
          30,
          51760
        ]
      },
      {
        "avg_logprob": -0.2899230888911656,
        "compression_ratio": 1.517391304347826,
        "end": 1456.3200000000002,
        "id": 511,
        "no_speech_prob": 0.000025867388103506528,
        "seek": 142644,
        "start": 1455.48,
        "temperature": 0,
        "text": " No.",
        "tokens": [
          51816,
          883,
          13,
          51858
        ]
      },
      {
        "avg_logprob": -0.4346897304058075,
        "compression_ratio": 1.2733333333333334,
        "end": 1458.76,
        "id": 512,
        "no_speech_prob": 0.00006205030513228849,
        "seek": 145644,
        "start": 1457.04,
        "temperature": 0,
        "text": " But I can find that out",
        "tokens": [
          50394,
          583,
          286,
          393,
          915,
          300,
          484,
          50480
        ]
      },
      {
        "avg_logprob": -0.4346897304058075,
        "compression_ratio": 1.2733333333333334,
        "end": 1464.96,
        "id": 513,
        "no_speech_prob": 0.00006205030513228849,
        "seek": 145644,
        "start": 1463.6000000000001,
        "temperature": 0,
        "text": " by going here.",
        "tokens": [
          50722,
          538,
          516,
          510,
          13,
          50790
        ]
      },
      {
        "avg_logprob": -0.4346897304058075,
        "compression_ratio": 1.2733333333333334,
        "end": 1471.24,
        "id": 514,
        "no_speech_prob": 0.00006205030513228849,
        "seek": 145644,
        "start": 1468.3200000000002,
        "temperature": 0,
        "text": " 105 was polynomial regression.",
        "tokens": [
          50958,
          33705,
          390,
          26110,
          24590,
          13,
          51104
        ]
      },
      {
        "avg_logprob": -0.4346897304058075,
        "compression_ratio": 1.2733333333333334,
        "end": 1475.48,
        "id": 515,
        "no_speech_prob": 0.00006205030513228849,
        "seek": 145644,
        "start": 1473.0800000000002,
        "temperature": 0,
        "text": " So this would be 106.",
        "tokens": [
          51196,
          407,
          341,
          576,
          312,
          1266,
          21,
          13,
          51316
        ]
      },
      {
        "avg_logprob": -0.4346897304058075,
        "compression_ratio": 1.2733333333333334,
        "end": 1479.88,
        "id": 516,
        "no_speech_prob": 0.00006205030513228849,
        "seek": 145644,
        "start": 1477.0800000000002,
        "temperature": 0,
        "text": " Okay, totally didn't do this right.",
        "tokens": [
          51396,
          1033,
          11,
          3879,
          994,
          380,
          360,
          341,
          558,
          13,
          51536
        ]
      },
      {
        "avg_logprob": -0.4346897304058075,
        "compression_ratio": 1.2733333333333334,
        "end": 1483.44,
        "id": 517,
        "no_speech_prob": 0.00006205030513228849,
        "seek": 145644,
        "start": 1481.8400000000001,
        "temperature": 0,
        "text": " Hey, how come there we go?",
        "tokens": [
          51634,
          1911,
          11,
          577,
          808,
          456,
          321,
          352,
          30,
          51714
        ]
      },
      {
        "avg_logprob": -0.4346897304058075,
        "compression_ratio": 1.2733333333333334,
        "end": 1486.24,
        "id": 518,
        "no_speech_prob": 0.00006205030513228849,
        "seek": 145644,
        "start": 1483.44,
        "temperature": 0,
        "text": " Now, do I have the atom editor open?",
        "tokens": [
          51714,
          823,
          11,
          360,
          286,
          362,
          264,
          12018,
          9839,
          1269,
          30,
          51854
        ]
      },
      {
        "avg_logprob": -0.3336542927941611,
        "compression_ratio": 1.176991150442478,
        "end": 1487.28,
        "id": 519,
        "no_speech_prob": 0.0003053475229535252,
        "seek": 148644,
        "start": 1486.44,
        "temperature": 0,
        "text": " No.",
        "tokens": [
          50364,
          883,
          13,
          50406
        ]
      },
      {
        "avg_logprob": -0.3336542927941611,
        "compression_ratio": 1.176991150442478,
        "end": 1506.6000000000001,
        "id": 520,
        "no_speech_prob": 0.0003053475229535252,
        "seek": 148644,
        "start": 1505.76,
        "temperature": 0,
        "text": " See, here's the thing.",
        "tokens": [
          51330,
          3008,
          11,
          510,
          311,
          264,
          551,
          13,
          51372
        ]
      },
      {
        "avg_logprob": -0.3336542927941611,
        "compression_ratio": 1.176991150442478,
        "end": 1508.48,
        "id": 521,
        "no_speech_prob": 0.0003053475229535252,
        "seek": 148644,
        "start": 1506.6000000000001,
        "temperature": 0,
        "text": " What's interesting about doing this YouTube channel",
        "tokens": [
          51372,
          708,
          311,
          1880,
          466,
          884,
          341,
          3088,
          2269,
          51466
        ]
      },
      {
        "avg_logprob": -0.3336542927941611,
        "compression_ratio": 1.176991150442478,
        "end": 1511.2,
        "id": 522,
        "no_speech_prob": 0.0003053475229535252,
        "seek": 148644,
        "start": 1508.48,
        "temperature": 0,
        "text": " is if I were teaching a course,",
        "tokens": [
          51466,
          307,
          498,
          286,
          645,
          4571,
          257,
          1164,
          11,
          51602
        ]
      },
      {
        "avg_logprob": -0.3336542927941611,
        "compression_ratio": 1.176991150442478,
        "end": 1513.4,
        "id": 523,
        "no_speech_prob": 0.0003053475229535252,
        "seek": 148644,
        "start": 1511.2,
        "temperature": 0,
        "text": " like I do, supposedly,",
        "tokens": [
          51602,
          411,
          286,
          360,
          11,
          20581,
          11,
          51712
        ]
      },
      {
        "avg_logprob": -0.28742018200102304,
        "compression_ratio": 1.4754098360655739,
        "end": 1516.76,
        "id": 524,
        "no_speech_prob": 0.000007411275873892009,
        "seek": 151340,
        "start": 1513.52,
        "temperature": 0,
        "text": " at NYU,",
        "tokens": [
          50370,
          412,
          42682,
          11,
          50532
        ]
      },
      {
        "avg_logprob": -0.28742018200102304,
        "compression_ratio": 1.4754098360655739,
        "end": 1520.1200000000001,
        "id": 525,
        "no_speech_prob": 0.000007411275873892009,
        "seek": 151340,
        "start": 1517.96,
        "temperature": 0,
        "text": " I just would not, I would just skip a lot of stuff",
        "tokens": [
          50592,
          286,
          445,
          576,
          406,
          11,
          286,
          576,
          445,
          10023,
          257,
          688,
          295,
          1507,
          50700
        ]
      },
      {
        "avg_logprob": -0.28742018200102304,
        "compression_ratio": 1.4754098360655739,
        "end": 1522.48,
        "id": 526,
        "no_speech_prob": 0.000007411275873892009,
        "seek": 151340,
        "start": 1520.1200000000001,
        "temperature": 0,
        "text": " because there's limited amounts of time.",
        "tokens": [
          50700,
          570,
          456,
          311,
          5567,
          11663,
          295,
          565,
          13,
          50818
        ]
      },
      {
        "avg_logprob": -0.28742018200102304,
        "compression_ratio": 1.4754098360655739,
        "end": 1523.8000000000002,
        "id": 527,
        "no_speech_prob": 0.000007411275873892009,
        "seek": 151340,
        "start": 1522.48,
        "temperature": 0,
        "text": " And I do, to some extent, do that here,",
        "tokens": [
          50818,
          400,
          286,
          360,
          11,
          281,
          512,
          8396,
          11,
          360,
          300,
          510,
          11,
          50884
        ]
      },
      {
        "avg_logprob": -0.28742018200102304,
        "compression_ratio": 1.4754098360655739,
        "end": 1526.0800000000002,
        "id": 528,
        "no_speech_prob": 0.000007411275873892009,
        "seek": 151340,
        "start": 1523.8000000000002,
        "temperature": 0,
        "text": " but I have this false,",
        "tokens": [
          50884,
          457,
          286,
          362,
          341,
          7908,
          11,
          50998
        ]
      },
      {
        "avg_logprob": -0.28742018200102304,
        "compression_ratio": 1.4754098360655739,
        "end": 1528.2800000000002,
        "id": 529,
        "no_speech_prob": 0.000007411275873892009,
        "seek": 151340,
        "start": 1526.0800000000002,
        "temperature": 0,
        "text": " it's like this false sense of infinite time",
        "tokens": [
          50998,
          309,
          311,
          411,
          341,
          7908,
          2020,
          295,
          13785,
          565,
          51108
        ]
      },
      {
        "avg_logprob": -0.28742018200102304,
        "compression_ratio": 1.4754098360655739,
        "end": 1529.92,
        "id": 530,
        "no_speech_prob": 0.000007411275873892009,
        "seek": 151340,
        "start": 1528.2800000000002,
        "temperature": 0,
        "text": " and I must do every single step",
        "tokens": [
          51108,
          293,
          286,
          1633,
          360,
          633,
          2167,
          1823,
          51190
        ]
      },
      {
        "avg_logprob": -0.28742018200102304,
        "compression_ratio": 1.4754098360655739,
        "end": 1531.9,
        "id": 531,
        "no_speech_prob": 0.000007411275873892009,
        "seek": 151340,
        "start": 1529.92,
        "temperature": 0,
        "text": " which I need to move away from.",
        "tokens": [
          51190,
          597,
          286,
          643,
          281,
          1286,
          1314,
          490,
          13,
          51289
        ]
      },
      {
        "avg_logprob": -0.3333185845678979,
        "compression_ratio": 1.5,
        "end": 1533.5800000000002,
        "id": 532,
        "no_speech_prob": 0.005384842399507761,
        "seek": 153190,
        "start": 1532.74,
        "temperature": 0,
        "text": " Um.",
        "tokens": [
          50406,
          3301,
          13,
          50448
        ]
      },
      {
        "avg_logprob": -0.3333185845678979,
        "compression_ratio": 1.5,
        "end": 1546.02,
        "id": 533,
        "no_speech_prob": 0.005384842399507761,
        "seek": 153190,
        "start": 1542.8200000000002,
        "temperature": 0,
        "text": " Kweekbunt writes, it's a good example, comma, but,",
        "tokens": [
          50910,
          591,
          23188,
          65,
          2760,
          13657,
          11,
          309,
          311,
          257,
          665,
          1365,
          11,
          22117,
          11,
          457,
          11,
          51070
        ]
      },
      {
        "avg_logprob": -0.3333185845678979,
        "compression_ratio": 1.5,
        "end": 1548.18,
        "id": 534,
        "no_speech_prob": 0.005384842399507761,
        "seek": 153190,
        "start": 1546.02,
        "temperature": 0,
        "text": " dot, dot, dot, and I get it.",
        "tokens": [
          51070,
          5893,
          11,
          5893,
          11,
          5893,
          11,
          293,
          286,
          483,
          309,
          13,
          51178
        ]
      },
      {
        "avg_logprob": -0.3333185845678979,
        "compression_ratio": 1.5,
        "end": 1550.74,
        "id": 535,
        "no_speech_prob": 0.005384842399507761,
        "seek": 153190,
        "start": 1548.18,
        "temperature": 0,
        "text": " I get it, but I'm waiting for what's coming next.",
        "tokens": [
          51178,
          286,
          483,
          309,
          11,
          457,
          286,
          478,
          3806,
          337,
          437,
          311,
          1348,
          958,
          13,
          51306
        ]
      },
      {
        "avg_logprob": -0.3333185845678979,
        "compression_ratio": 1.5,
        "end": 1553.18,
        "id": 536,
        "no_speech_prob": 0.005384842399507761,
        "seek": 153190,
        "start": 1550.74,
        "temperature": 0,
        "text": " I think I could fill it in, but.",
        "tokens": [
          51306,
          286,
          519,
          286,
          727,
          2836,
          309,
          294,
          11,
          457,
          13,
          51428
        ]
      },
      {
        "avg_logprob": -0.3333185845678979,
        "compression_ratio": 1.5,
        "end": 1554.02,
        "id": 537,
        "no_speech_prob": 0.005384842399507761,
        "seek": 153190,
        "start": 1553.18,
        "temperature": 0,
        "text": " But.",
        "tokens": [
          51428,
          583,
          13,
          51470
        ]
      },
      {
        "avg_logprob": -0.3333185845678979,
        "compression_ratio": 1.5,
        "end": 1559.3000000000002,
        "id": 538,
        "no_speech_prob": 0.005384842399507761,
        "seek": 153190,
        "start": 1556.38,
        "temperature": 0,
        "text": " But I think it's, ah.",
        "tokens": [
          51588,
          583,
          286,
          519,
          309,
          311,
          11,
          3716,
          13,
          51734
        ]
      },
      {
        "avg_logprob": -0.3333185845678979,
        "compression_ratio": 1.5,
        "end": 1561.3000000000002,
        "id": 539,
        "no_speech_prob": 0.005384842399507761,
        "seek": 153190,
        "start": 1559.3000000000002,
        "temperature": 0,
        "text": " Well, that's what I'm doing today.",
        "tokens": [
          51734,
          1042,
          11,
          300,
          311,
          437,
          286,
          478,
          884,
          965,
          13,
          51834
        ]
      },
      {
        "avg_logprob": -0.344044670226082,
        "compression_ratio": 1.3596491228070176,
        "end": 1562.28,
        "id": 540,
        "no_speech_prob": 0.00015597887977492064,
        "seek": 156130,
        "start": 1561.3,
        "temperature": 0,
        "text": " Unless.",
        "tokens": [
          50364,
          16581,
          13,
          50413
        ]
      },
      {
        "avg_logprob": -0.344044670226082,
        "compression_ratio": 1.3596491228070176,
        "end": 1567.1399999999999,
        "id": 541,
        "no_speech_prob": 0.00015597887977492064,
        "seek": 156130,
        "start": 1565.28,
        "temperature": 0,
        "text": " I mean, I'm going to do that, no, no, no.",
        "tokens": [
          50563,
          286,
          914,
          11,
          286,
          478,
          516,
          281,
          360,
          300,
          11,
          572,
          11,
          572,
          11,
          572,
          13,
          50656
        ]
      },
      {
        "avg_logprob": -0.344044670226082,
        "compression_ratio": 1.3596491228070176,
        "end": 1568.54,
        "id": 542,
        "no_speech_prob": 0.00015597887977492064,
        "seek": 156130,
        "start": 1567.1399999999999,
        "temperature": 0,
        "text": " Okay, that's what I'm doing.",
        "tokens": [
          50656,
          1033,
          11,
          300,
          311,
          437,
          286,
          478,
          884,
          13,
          50726
        ]
      },
      {
        "avg_logprob": -0.344044670226082,
        "compression_ratio": 1.3596491228070176,
        "end": 1572.1,
        "id": 543,
        "no_speech_prob": 0.00015597887977492064,
        "seek": 156130,
        "start": 1570.5,
        "temperature": 0,
        "text": " All right, all right, all right.",
        "tokens": [
          50824,
          1057,
          558,
          11,
          439,
          558,
          11,
          439,
          558,
          13,
          50904
        ]
      },
      {
        "avg_logprob": -0.344044670226082,
        "compression_ratio": 1.3596491228070176,
        "end": 1577.4199999999998,
        "id": 544,
        "no_speech_prob": 0.00015597887977492064,
        "seek": 156130,
        "start": 1576.58,
        "temperature": 0,
        "text": " So let's see.",
        "tokens": [
          51128,
          407,
          718,
          311,
          536,
          13,
          51170
        ]
      },
      {
        "avg_logprob": -0.344044670226082,
        "compression_ratio": 1.3596491228070176,
        "end": 1580.62,
        "id": 545,
        "no_speech_prob": 0.00015597887977492064,
        "seek": 156130,
        "start": 1578.34,
        "temperature": 0,
        "text": " Here we are, this is my list.",
        "tokens": [
          51216,
          1692,
          321,
          366,
          11,
          341,
          307,
          452,
          1329,
          13,
          51330
        ]
      },
      {
        "avg_logprob": -0.4416864612434484,
        "compression_ratio": 1.371069182389937,
        "end": 1592.1399999999999,
        "id": 546,
        "no_speech_prob": 0.0007208310998976231,
        "seek": 159130,
        "start": 1591.3,
        "temperature": 0,
        "text": " Um.",
        "tokens": [
          50364,
          3301,
          13,
          50406
        ]
      },
      {
        "avg_logprob": -0.4416864612434484,
        "compression_ratio": 1.371069182389937,
        "end": 1597.78,
        "id": 547,
        "no_speech_prob": 0.0007208310998976231,
        "seek": 159130,
        "start": 1594.54,
        "temperature": 0,
        "text": " Ah, pfft, thank you, thank you.",
        "tokens": [
          50526,
          2438,
          11,
          280,
          602,
          83,
          11,
          1309,
          291,
          11,
          1309,
          291,
          13,
          50688
        ]
      },
      {
        "avg_logprob": -0.4416864612434484,
        "compression_ratio": 1.371069182389937,
        "end": 1598.86,
        "id": 548,
        "no_speech_prob": 0.0007208310998976231,
        "seek": 159130,
        "start": 1597.78,
        "temperature": 0,
        "text": " Xor Shiffman.",
        "tokens": [
          50688,
          1783,
          284,
          1160,
          3661,
          1601,
          13,
          50742
        ]
      },
      {
        "avg_logprob": -0.4416864612434484,
        "compression_ratio": 1.371069182389937,
        "end": 1607.1,
        "id": 549,
        "no_speech_prob": 0.0007208310998976231,
        "seek": 159130,
        "start": 1605.8999999999999,
        "temperature": 0,
        "text": " See, I think I only actually made one,",
        "tokens": [
          51094,
          3008,
          11,
          286,
          519,
          286,
          787,
          767,
          1027,
          472,
          11,
          51154
        ]
      },
      {
        "avg_logprob": -0.4416864612434484,
        "compression_ratio": 1.371069182389937,
        "end": 1608.76,
        "id": 550,
        "no_speech_prob": 0.0007208310998976231,
        "seek": 159130,
        "start": 1607.1,
        "temperature": 0,
        "text": " even though it's like probably the third or fourth time",
        "tokens": [
          51154,
          754,
          1673,
          309,
          311,
          411,
          1391,
          264,
          2636,
          420,
          6409,
          565,
          51237
        ]
      },
      {
        "avg_logprob": -0.4416864612434484,
        "compression_ratio": 1.371069182389937,
        "end": 1609.94,
        "id": 551,
        "no_speech_prob": 0.0007208310998976231,
        "seek": 159130,
        "start": 1608.76,
        "temperature": 0,
        "text": " I'm doing it on this channel,",
        "tokens": [
          51237,
          286,
          478,
          884,
          309,
          322,
          341,
          2269,
          11,
          51296
        ]
      },
      {
        "avg_logprob": -0.4416864612434484,
        "compression_ratio": 1.371069182389937,
        "end": 1612.12,
        "id": 552,
        "no_speech_prob": 0.0007208310998976231,
        "seek": 159130,
        "start": 1609.94,
        "temperature": 0,
        "text": " I do only have one video, it appears.",
        "tokens": [
          51296,
          286,
          360,
          787,
          362,
          472,
          960,
          11,
          309,
          7038,
          13,
          51405
        ]
      },
      {
        "avg_logprob": -0.4416864612434484,
        "compression_ratio": 1.371069182389937,
        "end": 1617.34,
        "id": 553,
        "no_speech_prob": 0.0007208310998976231,
        "seek": 159130,
        "start": 1616.5,
        "temperature": 0,
        "text": " Yeah.",
        "tokens": [
          51624,
          865,
          13,
          51666
        ]
      },
      {
        "avg_logprob": -0.30584269762039185,
        "compression_ratio": 1.4396135265700483,
        "end": 1621.32,
        "id": 554,
        "no_speech_prob": 0.0000370529196516145,
        "seek": 161734,
        "start": 1618.34,
        "temperature": 0,
        "text": " Look, here's Simon talking about Xor.",
        "tokens": [
          50414,
          2053,
          11,
          510,
          311,
          13193,
          1417,
          466,
          1783,
          284,
          13,
          50563
        ]
      },
      {
        "avg_logprob": -0.30584269762039185,
        "compression_ratio": 1.4396135265700483,
        "end": 1623.86,
        "id": 555,
        "no_speech_prob": 0.0000370529196516145,
        "seek": 161734,
        "start": 1622.6599999999999,
        "temperature": 0,
        "text": " Some other videos, okay.",
        "tokens": [
          50630,
          2188,
          661,
          2145,
          11,
          1392,
          13,
          50690
        ]
      },
      {
        "avg_logprob": -0.30584269762039185,
        "compression_ratio": 1.4396135265700483,
        "end": 1627,
        "id": 556,
        "no_speech_prob": 0.0000370529196516145,
        "seek": 161734,
        "start": 1626.1,
        "temperature": 0,
        "text": " All right.",
        "tokens": [
          50802,
          1057,
          558,
          13,
          50847
        ]
      },
      {
        "avg_logprob": -0.30584269762039185,
        "compression_ratio": 1.4396135265700483,
        "end": 1634.34,
        "id": 557,
        "no_speech_prob": 0.0000370529196516145,
        "seek": 161734,
        "start": 1631.22,
        "temperature": 0,
        "text": " And now, did I run a server, yes.",
        "tokens": [
          51058,
          400,
          586,
          11,
          630,
          286,
          1190,
          257,
          7154,
          11,
          2086,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.30584269762039185,
        "compression_ratio": 1.4396135265700483,
        "end": 1635.62,
        "id": 558,
        "no_speech_prob": 0.0000370529196516145,
        "seek": 161734,
        "start": 1634.34,
        "temperature": 0,
        "text": " Let me open up the browser.",
        "tokens": [
          51214,
          961,
          385,
          1269,
          493,
          264,
          11185,
          13,
          51278
        ]
      },
      {
        "avg_logprob": -0.30584269762039185,
        "compression_ratio": 1.4396135265700483,
        "end": 1637.74,
        "id": 559,
        "no_speech_prob": 0.0000370529196516145,
        "seek": 161734,
        "start": 1635.62,
        "temperature": 0,
        "text": " I would love to do like some kind of little",
        "tokens": [
          51278,
          286,
          576,
          959,
          281,
          360,
          411,
          512,
          733,
          295,
          707,
          51384
        ]
      },
      {
        "avg_logprob": -0.30584269762039185,
        "compression_ratio": 1.4396135265700483,
        "end": 1640.26,
        "id": 560,
        "no_speech_prob": 0.0000370529196516145,
        "seek": 161734,
        "start": 1637.74,
        "temperature": 0,
        "text": " just fun algorithmic thing, the equivalent of like",
        "tokens": [
          51384,
          445,
          1019,
          9284,
          299,
          551,
          11,
          264,
          10344,
          295,
          411,
          51510
        ]
      },
      {
        "avg_logprob": -0.30584269762039185,
        "compression_ratio": 1.4396135265700483,
        "end": 1643.58,
        "id": 561,
        "no_speech_prob": 0.0000370529196516145,
        "seek": 161734,
        "start": 1640.26,
        "temperature": 0,
        "text": " phylotaxis today before I go if there's time,",
        "tokens": [
          51510,
          903,
          88,
          752,
          1328,
          39637,
          965,
          949,
          286,
          352,
          498,
          456,
          311,
          565,
          11,
          51676
        ]
      },
      {
        "avg_logprob": -0.30584269762039185,
        "compression_ratio": 1.4396135265700483,
        "end": 1644.6999999999998,
        "id": 562,
        "no_speech_prob": 0.0000370529196516145,
        "seek": 161734,
        "start": 1643.58,
        "temperature": 0,
        "text": " but I doubt there is.",
        "tokens": [
          51676,
          457,
          286,
          6385,
          456,
          307,
          13,
          51732
        ]
      },
      {
        "avg_logprob": -0.42132639001916955,
        "compression_ratio": 1.4086021505376345,
        "end": 1648.74,
        "id": 563,
        "no_speech_prob": 0.0001852239074651152,
        "seek": 164734,
        "start": 1647.8999999999999,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          50392,
          1033,
          13,
          50434
        ]
      },
      {
        "avg_logprob": -0.42132639001916955,
        "compression_ratio": 1.4086021505376345,
        "end": 1653.8999999999999,
        "id": 564,
        "no_speech_prob": 0.0001852239074651152,
        "seek": 164734,
        "start": 1652.4599999999998,
        "temperature": 0,
        "text": " All right.",
        "tokens": [
          50620,
          1057,
          558,
          13,
          50692
        ]
      },
      {
        "avg_logprob": -0.42132639001916955,
        "compression_ratio": 1.4086021505376345,
        "end": 1657.3799999999999,
        "id": 565,
        "no_speech_prob": 0.0001852239074651152,
        "seek": 164734,
        "start": 1653.8999999999999,
        "temperature": 0,
        "text": " Yeah, see, Guy writes, I miss the non-machine learning",
        "tokens": [
          50692,
          865,
          11,
          536,
          11,
          14690,
          13657,
          11,
          286,
          1713,
          264,
          2107,
          12,
          46061,
          2539,
          50866
        ]
      },
      {
        "avg_logprob": -0.42132639001916955,
        "compression_ratio": 1.4086021505376345,
        "end": 1658.6799999999998,
        "id": 566,
        "no_speech_prob": 0.0001852239074651152,
        "seek": 164734,
        "start": 1657.3799999999999,
        "temperature": 0,
        "text": " coding challenges.",
        "tokens": [
          50866,
          17720,
          4759,
          13,
          50931
        ]
      },
      {
        "avg_logprob": -0.42132639001916955,
        "compression_ratio": 1.4086021505376345,
        "end": 1661.3,
        "id": 567,
        "no_speech_prob": 0.0001852239074651152,
        "seek": 164734,
        "start": 1659.98,
        "temperature": 0,
        "text": " Totally agree.",
        "tokens": [
          50996,
          22837,
          3986,
          13,
          51062
        ]
      },
      {
        "avg_logprob": -0.42132639001916955,
        "compression_ratio": 1.4086021505376345,
        "end": 1663.9399999999998,
        "id": 568,
        "no_speech_prob": 0.0001852239074651152,
        "seek": 164734,
        "start": 1662.34,
        "temperature": 0,
        "text": " Yeah, I don't know.",
        "tokens": [
          51114,
          865,
          11,
          286,
          500,
          380,
          458,
          13,
          51194
        ]
      },
      {
        "avg_logprob": -0.42132639001916955,
        "compression_ratio": 1.4086021505376345,
        "end": 1668.5,
        "id": 569,
        "no_speech_prob": 0.0001852239074651152,
        "seek": 164734,
        "start": 1665.54,
        "temperature": 0,
        "text": " Burger Bob asks, could you please read the chat more often?",
        "tokens": [
          51274,
          28936,
          6085,
          8962,
          11,
          727,
          291,
          1767,
          1401,
          264,
          5081,
          544,
          2049,
          30,
          51422
        ]
      },
      {
        "avg_logprob": -0.42132639001916955,
        "compression_ratio": 1.4086021505376345,
        "end": 1673.26,
        "id": 570,
        "no_speech_prob": 0.0001852239074651152,
        "seek": 164734,
        "start": 1669.86,
        "temperature": 0,
        "text": " I totally get the sentiment, I appreciate the question.",
        "tokens": [
          51490,
          286,
          3879,
          483,
          264,
          16149,
          11,
          286,
          4449,
          264,
          1168,
          13,
          51660
        ]
      },
      {
        "avg_logprob": -0.42132639001916955,
        "compression_ratio": 1.4086021505376345,
        "end": 1675.58,
        "id": 571,
        "no_speech_prob": 0.0001852239074651152,
        "seek": 164734,
        "start": 1673.26,
        "temperature": 0,
        "text": " I can certainly try.",
        "tokens": [
          51660,
          286,
          393,
          3297,
          853,
          13,
          51776
        ]
      },
      {
        "avg_logprob": -0.2610360263438707,
        "compression_ratio": 1.601063829787234,
        "end": 1678.06,
        "id": 572,
        "no_speech_prob": 0.000037052654079161584,
        "seek": 167558,
        "start": 1675.58,
        "temperature": 0,
        "text": " It is very hard to follow the chat",
        "tokens": [
          50364,
          467,
          307,
          588,
          1152,
          281,
          1524,
          264,
          5081,
          50488
        ]
      },
      {
        "avg_logprob": -0.2610360263438707,
        "compression_ratio": 1.601063829787234,
        "end": 1681.3999999999999,
        "id": 573,
        "no_speech_prob": 0.000037052654079161584,
        "seek": 167558,
        "start": 1678.06,
        "temperature": 0,
        "text": " and do the live stream at the same time.",
        "tokens": [
          50488,
          293,
          360,
          264,
          1621,
          4309,
          412,
          264,
          912,
          565,
          13,
          50655
        ]
      },
      {
        "avg_logprob": -0.2610360263438707,
        "compression_ratio": 1.601063829787234,
        "end": 1686.62,
        "id": 574,
        "no_speech_prob": 0.000037052654079161584,
        "seek": 167558,
        "start": 1682.98,
        "temperature": 0,
        "text": " And maybe someday I'll have a better system for doing that.",
        "tokens": [
          50734,
          400,
          1310,
          19412,
          286,
          603,
          362,
          257,
          1101,
          1185,
          337,
          884,
          300,
          13,
          50916
        ]
      },
      {
        "avg_logprob": -0.2610360263438707,
        "compression_ratio": 1.601063829787234,
        "end": 1687.9399999999998,
        "id": 575,
        "no_speech_prob": 0.000037052654079161584,
        "seek": 167558,
        "start": 1686.62,
        "temperature": 0,
        "text": " I have some ideas for how to do that,",
        "tokens": [
          50916,
          286,
          362,
          512,
          3487,
          337,
          577,
          281,
          360,
          300,
          11,
          50982
        ]
      },
      {
        "avg_logprob": -0.2610360263438707,
        "compression_ratio": 1.601063829787234,
        "end": 1690.8799999999999,
        "id": 576,
        "no_speech_prob": 0.000037052654079161584,
        "seek": 167558,
        "start": 1687.9399999999998,
        "temperature": 0,
        "text": " but I need time to get some more screens",
        "tokens": [
          50982,
          457,
          286,
          643,
          565,
          281,
          483,
          512,
          544,
          11171,
          51129
        ]
      },
      {
        "avg_logprob": -0.2610360263438707,
        "compression_ratio": 1.601063829787234,
        "end": 1693.5,
        "id": 577,
        "no_speech_prob": 0.000037052654079161584,
        "seek": 167558,
        "start": 1690.8799999999999,
        "temperature": 0,
        "text": " and maybe have some help with that and that sort of thing.",
        "tokens": [
          51129,
          293,
          1310,
          362,
          512,
          854,
          365,
          300,
          293,
          300,
          1333,
          295,
          551,
          13,
          51260
        ]
      },
      {
        "avg_logprob": -0.2610360263438707,
        "compression_ratio": 1.601063829787234,
        "end": 1694.34,
        "id": 578,
        "no_speech_prob": 0.000037052654079161584,
        "seek": 167558,
        "start": 1693.5,
        "temperature": 0,
        "text": " All right.",
        "tokens": [
          51260,
          1057,
          558,
          13,
          51302
        ]
      },
      {
        "avg_logprob": -0.2610360263438707,
        "compression_ratio": 1.601063829787234,
        "end": 1703.6999999999998,
        "id": 579,
        "no_speech_prob": 0.000037052654079161584,
        "seek": 167558,
        "start": 1701.62,
        "temperature": 0,
        "text": " Ada, she writes,",
        "tokens": [
          51666,
          32276,
          11,
          750,
          13657,
          11,
          51770
        ]
      },
      {
        "avg_logprob": -0.3928178914388021,
        "compression_ratio": 1.2638888888888888,
        "end": 1705.82,
        "id": 580,
        "no_speech_prob": 0.00009761460387380794,
        "seek": 170370,
        "start": 1703.7,
        "temperature": 0,
        "text": " did he say filing taxes?",
        "tokens": [
          50364,
          630,
          415,
          584,
          26854,
          10041,
          30,
          50470
        ]
      },
      {
        "avg_logprob": -0.3928178914388021,
        "compression_ratio": 1.2638888888888888,
        "end": 1706.66,
        "id": 581,
        "no_speech_prob": 0.00009761460387380794,
        "seek": 170370,
        "start": 1705.82,
        "temperature": 0,
        "text": " Yes.",
        "tokens": [
          50470,
          1079,
          13,
          50512
        ]
      },
      {
        "avg_logprob": -0.3928178914388021,
        "compression_ratio": 1.2638888888888888,
        "end": 1711.06,
        "id": 582,
        "no_speech_prob": 0.00009761460387380794,
        "seek": 170370,
        "start": 1706.66,
        "temperature": 0,
        "text": " And now, coding challenge number 327.",
        "tokens": [
          50512,
          400,
          586,
          11,
          17720,
          3430,
          1230,
          8858,
          22,
          13,
          50732
        ]
      },
      {
        "avg_logprob": -0.3928178914388021,
        "compression_ratio": 1.2638888888888888,
        "end": 1712.6200000000001,
        "id": 583,
        "no_speech_prob": 0.00009761460387380794,
        "seek": 170370,
        "start": 1711.06,
        "temperature": 0,
        "text": " Filing your taxes.",
        "tokens": [
          50732,
          479,
          4883,
          428,
          10041,
          13,
          50810
        ]
      },
      {
        "avg_logprob": -0.3928178914388021,
        "compression_ratio": 1.2638888888888888,
        "end": 1714.42,
        "id": 584,
        "no_speech_prob": 0.00009761460387380794,
        "seek": 170370,
        "start": 1712.6200000000001,
        "temperature": 0,
        "text": " Let's go see.",
        "tokens": [
          50810,
          961,
          311,
          352,
          536,
          13,
          50900
        ]
      },
      {
        "avg_logprob": -0.3928178914388021,
        "compression_ratio": 1.2638888888888888,
        "end": 1717.88,
        "id": 585,
        "no_speech_prob": 0.00009761460387380794,
        "seek": 170370,
        "start": 1714.42,
        "temperature": 0,
        "text": " IRS tax filing API.",
        "tokens": [
          50900,
          33848,
          3366,
          26854,
          9362,
          13,
          51073
        ]
      },
      {
        "avg_logprob": -0.3928178914388021,
        "compression_ratio": 1.2638888888888888,
        "end": 1721.94,
        "id": 586,
        "no_speech_prob": 0.00009761460387380794,
        "seek": 170370,
        "start": 1720.74,
        "temperature": 0,
        "text": " Hmm.",
        "tokens": [
          51216,
          8239,
          13,
          51276
        ]
      },
      {
        "avg_logprob": -0.3928178914388021,
        "compression_ratio": 1.2638888888888888,
        "end": 1722.76,
        "id": 587,
        "no_speech_prob": 0.00009761460387380794,
        "seek": 170370,
        "start": 1721.94,
        "temperature": 0,
        "text": " Ooh.",
        "tokens": [
          51276,
          7951,
          13,
          51317
        ]
      },
      {
        "avg_logprob": -0.3928178914388021,
        "compression_ratio": 1.2638888888888888,
        "end": 1726.14,
        "id": 588,
        "no_speech_prob": 0.00009761460387380794,
        "seek": 170370,
        "start": 1722.76,
        "temperature": 0,
        "text": " IRS Gov eFileProvider Software Developer.",
        "tokens": [
          51317,
          33848,
          1037,
          85,
          308,
          37,
          794,
          12681,
          85,
          1438,
          27428,
          44915,
          13,
          51486
        ]
      },
      {
        "avg_logprob": -0.3928178914388021,
        "compression_ratio": 1.2638888888888888,
        "end": 1726.98,
        "id": 589,
        "no_speech_prob": 0.00009761460387380794,
        "seek": 170370,
        "start": 1726.14,
        "temperature": 0,
        "text": " Ooh.",
        "tokens": [
          51486,
          7951,
          13,
          51528
        ]
      },
      {
        "avg_logprob": -0.3928178914388021,
        "compression_ratio": 1.2638888888888888,
        "end": 1729.98,
        "id": 590,
        "no_speech_prob": 0.00009761460387380794,
        "seek": 170370,
        "start": 1729.14,
        "temperature": 0,
        "text": " Ooh.",
        "tokens": [
          51636,
          7951,
          13,
          51678
        ]
      },
      {
        "avg_logprob": -0.5615151492032138,
        "compression_ratio": 1.179245283018868,
        "end": 1734.54,
        "id": 591,
        "no_speech_prob": 0.00019716753740794957,
        "seek": 173370,
        "start": 1733.7,
        "temperature": 0,
        "text": " Ooh.",
        "tokens": [
          50364,
          7951,
          13,
          50406
        ]
      },
      {
        "avg_logprob": -0.5615151492032138,
        "compression_ratio": 1.179245283018868,
        "end": 1737.1200000000001,
        "id": 592,
        "no_speech_prob": 0.00019716753740794957,
        "seek": 173370,
        "start": 1736.28,
        "temperature": 0,
        "text": " Ooh.",
        "tokens": [
          50493,
          7951,
          13,
          50535
        ]
      },
      {
        "avg_logprob": -0.5615151492032138,
        "compression_ratio": 1.179245283018868,
        "end": 1739.38,
        "id": 593,
        "no_speech_prob": 0.00019716753740794957,
        "seek": 173370,
        "start": 1738.54,
        "temperature": 0,
        "text": " Ooh.",
        "tokens": [
          50606,
          7951,
          13,
          50648
        ]
      },
      {
        "avg_logprob": -0.5615151492032138,
        "compression_ratio": 1.179245283018868,
        "end": 1744.98,
        "id": 594,
        "no_speech_prob": 0.00019716753740794957,
        "seek": 173370,
        "start": 1744.14,
        "temperature": 0,
        "text": " Ooh.",
        "tokens": [
          50886,
          7951,
          13,
          50928
        ]
      },
      {
        "avg_logprob": -0.5615151492032138,
        "compression_ratio": 1.179245283018868,
        "end": 1756.3400000000001,
        "id": 595,
        "no_speech_prob": 0.00019716753740794957,
        "seek": 173370,
        "start": 1753.5800000000002,
        "temperature": 0,
        "text": " Okay, I guess XOR isn't so bad.",
        "tokens": [
          51358,
          1033,
          11,
          286,
          2041,
          1783,
          2483,
          1943,
          380,
          370,
          1578,
          13,
          51496
        ]
      },
      {
        "avg_logprob": -0.5615151492032138,
        "compression_ratio": 1.179245283018868,
        "end": 1758.1000000000001,
        "id": 596,
        "no_speech_prob": 0.00019716753740794957,
        "seek": 173370,
        "start": 1756.3400000000001,
        "temperature": 0,
        "text": " Filotaxis.",
        "tokens": [
          51496,
          7905,
          310,
          24633,
          13,
          51584
        ]
      },
      {
        "avg_logprob": -0.5615151492032138,
        "compression_ratio": 1.179245283018868,
        "end": 1761.18,
        "id": 597,
        "no_speech_prob": 0.00019716753740794957,
        "seek": 173370,
        "start": 1758.1000000000001,
        "temperature": 0,
        "text": " The spiral, beautiful Fibonacci spiral pattern",
        "tokens": [
          51584,
          440,
          25165,
          11,
          2238,
          479,
          897,
          266,
          43870,
          25165,
          5102,
          51738
        ]
      },
      {
        "avg_logprob": -0.5615151492032138,
        "compression_ratio": 1.179245283018868,
        "end": 1762.22,
        "id": 598,
        "no_speech_prob": 0.00019716753740794957,
        "seek": 173370,
        "start": 1761.18,
        "temperature": 0,
        "text": " of a sunflower.",
        "tokens": [
          51738,
          295,
          257,
          48215,
          13,
          51790
        ]
      },
      {
        "avg_logprob": -0.2753727458347784,
        "compression_ratio": 1.7102803738317758,
        "end": 1763.46,
        "id": 599,
        "no_speech_prob": 0.00007254325464600697,
        "seek": 176222,
        "start": 1762.22,
        "temperature": 0,
        "text": " That's what I was saying.",
        "tokens": [
          50364,
          663,
          311,
          437,
          286,
          390,
          1566,
          13,
          50426
        ]
      },
      {
        "avg_logprob": -0.2753727458347784,
        "compression_ratio": 1.7102803738317758,
        "end": 1768.6200000000001,
        "id": 600,
        "no_speech_prob": 0.00007254325464600697,
        "seek": 176222,
        "start": 1764.98,
        "temperature": 0,
        "text": " All right, see what happens.",
        "tokens": [
          50502,
          1057,
          558,
          11,
          536,
          437,
          2314,
          13,
          50684
        ]
      },
      {
        "avg_logprob": -0.2753727458347784,
        "compression_ratio": 1.7102803738317758,
        "end": 1773.54,
        "id": 601,
        "no_speech_prob": 0.00007254325464600697,
        "seek": 176222,
        "start": 1772.14,
        "temperature": 0,
        "text": " Burger Bob, that's exactly,",
        "tokens": [
          50860,
          28936,
          6085,
          11,
          300,
          311,
          2293,
          11,
          50930
        ]
      },
      {
        "avg_logprob": -0.2753727458347784,
        "compression_ratio": 1.7102803738317758,
        "end": 1775.46,
        "id": 602,
        "no_speech_prob": 0.00007254325464600697,
        "seek": 176222,
        "start": 1773.54,
        "temperature": 0,
        "text": " Burger Bob, I was worried about a giant screen",
        "tokens": [
          50930,
          28936,
          6085,
          11,
          286,
          390,
          5804,
          466,
          257,
          7410,
          2568,
          51026
        ]
      },
      {
        "avg_logprob": -0.2753727458347784,
        "compression_ratio": 1.7102803738317758,
        "end": 1777.1000000000001,
        "id": 603,
        "no_speech_prob": 0.00007254325464600697,
        "seek": 176222,
        "start": 1775.46,
        "temperature": 0,
        "text": " which shows the chat behind the camera.",
        "tokens": [
          51026,
          597,
          3110,
          264,
          5081,
          2261,
          264,
          2799,
          13,
          51108
        ]
      },
      {
        "avg_logprob": -0.2753727458347784,
        "compression_ratio": 1.7102803738317758,
        "end": 1778.78,
        "id": 604,
        "no_speech_prob": 0.00007254325464600697,
        "seek": 176222,
        "start": 1777.1000000000001,
        "temperature": 0,
        "text": " That is exactly what I would like.",
        "tokens": [
          51108,
          663,
          307,
          2293,
          437,
          286,
          576,
          411,
          13,
          51192
        ]
      },
      {
        "avg_logprob": -0.2753727458347784,
        "compression_ratio": 1.7102803738317758,
        "end": 1781.74,
        "id": 605,
        "no_speech_prob": 0.00007254325464600697,
        "seek": 176222,
        "start": 1779.8600000000001,
        "temperature": 0,
        "text": " And I will snap my fingers",
        "tokens": [
          51246,
          400,
          286,
          486,
          13650,
          452,
          7350,
          51340
        ]
      },
      {
        "avg_logprob": -0.2753727458347784,
        "compression_ratio": 1.7102803738317758,
        "end": 1785.02,
        "id": 606,
        "no_speech_prob": 0.00007254325464600697,
        "seek": 176222,
        "start": 1781.74,
        "temperature": 0,
        "text": " and giant screen will be mounted there behind the camera.",
        "tokens": [
          51340,
          293,
          7410,
          2568,
          486,
          312,
          19138,
          456,
          2261,
          264,
          2799,
          13,
          51504
        ]
      },
      {
        "avg_logprob": -0.2753727458347784,
        "compression_ratio": 1.7102803738317758,
        "end": 1786.38,
        "id": 607,
        "no_speech_prob": 0.00007254325464600697,
        "seek": 176222,
        "start": 1785.02,
        "temperature": 0,
        "text": " Somehow that didn't happen.",
        "tokens": [
          51504,
          28357,
          300,
          994,
          380,
          1051,
          13,
          51572
        ]
      },
      {
        "avg_logprob": -0.2753727458347784,
        "compression_ratio": 1.7102803738317758,
        "end": 1787.5,
        "id": 608,
        "no_speech_prob": 0.00007254325464600697,
        "seek": 176222,
        "start": 1786.38,
        "temperature": 0,
        "text": " I'm not sure why.",
        "tokens": [
          51572,
          286,
          478,
          406,
          988,
          983,
          13,
          51628
        ]
      },
      {
        "avg_logprob": -0.2753727458347784,
        "compression_ratio": 1.7102803738317758,
        "end": 1791.64,
        "id": 609,
        "no_speech_prob": 0.00007254325464600697,
        "seek": 176222,
        "start": 1787.5,
        "temperature": 0,
        "text": " So, I do like that suggestion.",
        "tokens": [
          51628,
          407,
          11,
          286,
          360,
          411,
          300,
          16541,
          13,
          51835
        ]
      },
      {
        "avg_logprob": -0.29192124954377763,
        "compression_ratio": 1.4708520179372198,
        "end": 1794.54,
        "id": 610,
        "no_speech_prob": 0.00013551890151575208,
        "seek": 179222,
        "start": 1793.22,
        "temperature": 0,
        "text": " Whoops.",
        "tokens": [
          50414,
          45263,
          13,
          50480
        ]
      },
      {
        "avg_logprob": -0.29192124954377763,
        "compression_ratio": 1.4708520179372198,
        "end": 1798.38,
        "id": 611,
        "no_speech_prob": 0.00013551890151575208,
        "seek": 179222,
        "start": 1796.22,
        "temperature": 0,
        "text": " Whoops, yes, Chris writes,",
        "tokens": [
          50564,
          45263,
          11,
          2086,
          11,
          6688,
          13657,
          11,
          50672
        ]
      },
      {
        "avg_logprob": -0.29192124954377763,
        "compression_ratio": 1.4708520179372198,
        "end": 1799.6200000000001,
        "id": 612,
        "no_speech_prob": 0.00013551890151575208,
        "seek": 179222,
        "start": 1798.38,
        "temperature": 0,
        "text": " it might be worth having a mod",
        "tokens": [
          50672,
          309,
          1062,
          312,
          3163,
          1419,
          257,
          1072,
          50734
        ]
      },
      {
        "avg_logprob": -0.29192124954377763,
        "compression_ratio": 1.4708520179372198,
        "end": 1801.9,
        "id": 613,
        "no_speech_prob": 0.00013551890151575208,
        "seek": 179222,
        "start": 1799.6200000000001,
        "temperature": 0,
        "text": " pull interesting questions out of both chats",
        "tokens": [
          50734,
          2235,
          1880,
          1651,
          484,
          295,
          1293,
          38057,
          50848
        ]
      },
      {
        "avg_logprob": -0.29192124954377763,
        "compression_ratio": 1.4708520179372198,
        "end": 1804.6200000000001,
        "id": 614,
        "no_speech_prob": 0.00013551890151575208,
        "seek": 179222,
        "start": 1801.9,
        "temperature": 0,
        "text": " and give them to Dan at Q&A breaks.",
        "tokens": [
          50848,
          293,
          976,
          552,
          281,
          3394,
          412,
          1249,
          5,
          32,
          9857,
          13,
          50984
        ]
      },
      {
        "avg_logprob": -0.29192124954377763,
        "compression_ratio": 1.4708520179372198,
        "end": 1806.66,
        "id": 615,
        "no_speech_prob": 0.00013551890151575208,
        "seek": 179222,
        "start": 1804.6200000000001,
        "temperature": 0,
        "text": " I'm absolutely game for trying that",
        "tokens": [
          50984,
          286,
          478,
          3122,
          1216,
          337,
          1382,
          300,
          51086
        ]
      },
      {
        "avg_logprob": -0.29192124954377763,
        "compression_ratio": 1.4708520179372198,
        "end": 1808.1000000000001,
        "id": 616,
        "no_speech_prob": 0.00013551890151575208,
        "seek": 179222,
        "start": 1806.66,
        "temperature": 0,
        "text": " and wants to sort of volunteer.",
        "tokens": [
          51086,
          293,
          2738,
          281,
          1333,
          295,
          13835,
          13,
          51158
        ]
      },
      {
        "avg_logprob": -0.29192124954377763,
        "compression_ratio": 1.4708520179372198,
        "end": 1810.2,
        "id": 617,
        "no_speech_prob": 0.00013551890151575208,
        "seek": 179222,
        "start": 1808.1000000000001,
        "temperature": 0,
        "text": " At this point, I think I would need a volunteer",
        "tokens": [
          51158,
          1711,
          341,
          935,
          11,
          286,
          519,
          286,
          576,
          643,
          257,
          13835,
          51263
        ]
      },
      {
        "avg_logprob": -0.29192124954377763,
        "compression_ratio": 1.4708520179372198,
        "end": 1812.18,
        "id": 618,
        "no_speech_prob": 0.00013551890151575208,
        "seek": 179222,
        "start": 1810.2,
        "temperature": 0,
        "text": " to help facilitate that.",
        "tokens": [
          51263,
          281,
          854,
          20207,
          300,
          13,
          51362
        ]
      },
      {
        "avg_logprob": -0.29192124954377763,
        "compression_ratio": 1.4708520179372198,
        "end": 1813.34,
        "id": 619,
        "no_speech_prob": 0.00013551890151575208,
        "seek": 179222,
        "start": 1812.18,
        "temperature": 0,
        "text": " That would be great.",
        "tokens": [
          51362,
          663,
          576,
          312,
          869,
          13,
          51420
        ]
      },
      {
        "avg_logprob": -0.29192124954377763,
        "compression_ratio": 1.4708520179372198,
        "end": 1815.06,
        "id": 620,
        "no_speech_prob": 0.00013551890151575208,
        "seek": 179222,
        "start": 1813.34,
        "temperature": 0,
        "text": " All right, let's...",
        "tokens": [
          51420,
          1057,
          558,
          11,
          718,
          311,
          485,
          51506
        ]
      },
      {
        "avg_logprob": -0.457815137960143,
        "compression_ratio": 1.4369747899159664,
        "end": 1815.8999999999999,
        "id": 621,
        "no_speech_prob": 0.0001559792144689709,
        "seek": 181506,
        "start": 1815.06,
        "temperature": 0,
        "text": " Let's see.",
        "tokens": [
          50364,
          961,
          311,
          536,
          13,
          50406
        ]
      },
      {
        "avg_logprob": -0.457815137960143,
        "compression_ratio": 1.4369747899159664,
        "end": 1824.06,
        "id": 622,
        "no_speech_prob": 0.0001559792144689709,
        "seek": 181506,
        "start": 1821.8999999999999,
        "temperature": 0,
        "text": " Let me get over all of my anxiety and hangups",
        "tokens": [
          50706,
          961,
          385,
          483,
          670,
          439,
          295,
          452,
          9119,
          293,
          3967,
          7528,
          50814
        ]
      },
      {
        "avg_logprob": -0.457815137960143,
        "compression_ratio": 1.4369747899159664,
        "end": 1828.3799999999999,
        "id": 623,
        "no_speech_prob": 0.0001559792144689709,
        "seek": 181506,
        "start": 1824.06,
        "temperature": 0,
        "text": " about doing XOR again and talk about them when I start.",
        "tokens": [
          50814,
          466,
          884,
          1783,
          2483,
          797,
          293,
          751,
          466,
          552,
          562,
          286,
          722,
          13,
          51030
        ]
      },
      {
        "avg_logprob": -0.457815137960143,
        "compression_ratio": 1.4369747899159664,
        "end": 1829.4199999999998,
        "id": 624,
        "no_speech_prob": 0.0001559792144689709,
        "seek": 181506,
        "start": 1828.3799999999999,
        "temperature": 0,
        "text": " And then...",
        "tokens": [
          51030,
          400,
          550,
          485,
          51082
        ]
      },
      {
        "avg_logprob": -0.457815137960143,
        "compression_ratio": 1.4369747899159664,
        "end": 1836.1,
        "id": 625,
        "no_speech_prob": 0.0001559792144689709,
        "seek": 181506,
        "start": 1835.26,
        "temperature": 0,
        "text": " And then...",
        "tokens": [
          51374,
          400,
          550,
          485,
          51416
        ]
      },
      {
        "avg_logprob": -0.457815137960143,
        "compression_ratio": 1.4369747899159664,
        "end": 1840.86,
        "id": 626,
        "no_speech_prob": 0.0001559792144689709,
        "seek": 181506,
        "start": 1839.74,
        "temperature": 0,
        "text": " And then...",
        "tokens": [
          51598,
          400,
          550,
          485,
          51654
        ]
      },
      {
        "avg_logprob": -0.457815137960143,
        "compression_ratio": 1.4369747899159664,
        "end": 1843.86,
        "id": 627,
        "no_speech_prob": 0.0001559792144689709,
        "seek": 181506,
        "start": 1842.4199999999998,
        "temperature": 0,
        "text": " And then I will begin.",
        "tokens": [
          51732,
          400,
          550,
          286,
          486,
          1841,
          13,
          51804
        ]
      },
      {
        "avg_logprob": -0.2789778468584774,
        "compression_ratio": 1.5133928571428572,
        "end": 1845.82,
        "id": 628,
        "no_speech_prob": 0.00015118104056455195,
        "seek": 184386,
        "start": 1843.86,
        "temperature": 0,
        "text": " I see all these people typing,",
        "tokens": [
          50364,
          286,
          536,
          439,
          613,
          561,
          18444,
          11,
          50462
        ]
      },
      {
        "avg_logprob": -0.2789778468584774,
        "compression_ratio": 1.5133928571428572,
        "end": 1849.34,
        "id": 629,
        "no_speech_prob": 0.00015118104056455195,
        "seek": 184386,
        "start": 1845.82,
        "temperature": 0,
        "text": " and Ada, and Kweekman, and Eric,",
        "tokens": [
          50462,
          293,
          32276,
          11,
          293,
          591,
          23188,
          1601,
          11,
          293,
          9336,
          11,
          50638
        ]
      },
      {
        "avg_logprob": -0.2789778468584774,
        "compression_ratio": 1.5133928571428572,
        "end": 1850.1799999999998,
        "id": 630,
        "no_speech_prob": 0.00015118104056455195,
        "seek": 184386,
        "start": 1849.34,
        "temperature": 0,
        "text": " but I got to move on.",
        "tokens": [
          50638,
          457,
          286,
          658,
          281,
          1286,
          322,
          13,
          50680
        ]
      },
      {
        "avg_logprob": -0.2789778468584774,
        "compression_ratio": 1.5133928571428572,
        "end": 1851.34,
        "id": 631,
        "no_speech_prob": 0.00015118104056455195,
        "seek": 184386,
        "start": 1850.1799999999998,
        "temperature": 0,
        "text": " I think I got to start.",
        "tokens": [
          50680,
          286,
          519,
          286,
          658,
          281,
          722,
          13,
          50738
        ]
      },
      {
        "avg_logprob": -0.2789778468584774,
        "compression_ratio": 1.5133928571428572,
        "end": 1853.4199999999998,
        "id": 632,
        "no_speech_prob": 0.00015118104056455195,
        "seek": 184386,
        "start": 1851.34,
        "temperature": 0,
        "text": " Because time is a wasting.",
        "tokens": [
          50738,
          1436,
          565,
          307,
          257,
          20457,
          13,
          50842
        ]
      },
      {
        "avg_logprob": -0.2789778468584774,
        "compression_ratio": 1.5133928571428572,
        "end": 1861.6599999999999,
        "id": 633,
        "no_speech_prob": 0.00015118104056455195,
        "seek": 184386,
        "start": 1860.06,
        "temperature": 0,
        "text": " Yes, thank you.",
        "tokens": [
          51174,
          1079,
          11,
          1309,
          291,
          13,
          51254
        ]
      },
      {
        "avg_logprob": -0.2789778468584774,
        "compression_ratio": 1.5133928571428572,
        "end": 1863.74,
        "id": 634,
        "no_speech_prob": 0.00015118104056455195,
        "seek": 184386,
        "start": 1861.6599999999999,
        "temperature": 0,
        "text": " Okay, Eric in the chat writes,",
        "tokens": [
          51254,
          1033,
          11,
          9336,
          294,
          264,
          5081,
          13657,
          11,
          51358
        ]
      },
      {
        "avg_logprob": -0.2789778468584774,
        "compression_ratio": 1.5133928571428572,
        "end": 1866.06,
        "id": 635,
        "no_speech_prob": 0.00015118104056455195,
        "seek": 184386,
        "start": 1863.74,
        "temperature": 0,
        "text": " sometimes it's important when learning something new",
        "tokens": [
          51358,
          2171,
          309,
          311,
          1021,
          562,
          2539,
          746,
          777,
          51474
        ]
      },
      {
        "avg_logprob": -0.2789778468584774,
        "compression_ratio": 1.5133928571428572,
        "end": 1868.12,
        "id": 636,
        "no_speech_prob": 0.00015118104056455195,
        "seek": 184386,
        "start": 1866.06,
        "temperature": 0,
        "text": " to base your exploration around an example",
        "tokens": [
          51474,
          281,
          3096,
          428,
          16197,
          926,
          364,
          1365,
          51577
        ]
      },
      {
        "avg_logprob": -0.2789778468584774,
        "compression_ratio": 1.5133928571428572,
        "end": 1872.58,
        "id": 637,
        "no_speech_prob": 0.00015118104056455195,
        "seek": 184386,
        "start": 1868.12,
        "temperature": 0,
        "text": " which is fairly trivial and you understand intimately well.",
        "tokens": [
          51577,
          597,
          307,
          6457,
          26703,
          293,
          291,
          1223,
          560,
          5401,
          731,
          13,
          51800
        ]
      },
      {
        "avg_logprob": -0.2708667193272317,
        "compression_ratio": 1.7209302325581395,
        "end": 1875.78,
        "id": 638,
        "no_speech_prob": 0.0002694766444619745,
        "seek": 187258,
        "start": 1872.58,
        "temperature": 0,
        "text": " True or were better, I could not have put it better myself.",
        "tokens": [
          50364,
          13587,
          420,
          645,
          1101,
          11,
          286,
          727,
          406,
          362,
          829,
          309,
          1101,
          2059,
          13,
          50524
        ]
      },
      {
        "avg_logprob": -0.2708667193272317,
        "compression_ratio": 1.7209302325581395,
        "end": 1877.1,
        "id": 639,
        "no_speech_prob": 0.0002694766444619745,
        "seek": 187258,
        "start": 1875.78,
        "temperature": 0,
        "text": " Thank you.",
        "tokens": [
          50524,
          1044,
          291,
          13,
          50590
        ]
      },
      {
        "avg_logprob": -0.2708667193272317,
        "compression_ratio": 1.7209302325581395,
        "end": 1879.98,
        "id": 640,
        "no_speech_prob": 0.0002694766444619745,
        "seek": 187258,
        "start": 1877.1,
        "temperature": 0,
        "text": " I'm going to read that sentence",
        "tokens": [
          50590,
          286,
          478,
          516,
          281,
          1401,
          300,
          8174,
          50734
        ]
      },
      {
        "avg_logprob": -0.2708667193272317,
        "compression_ratio": 1.7209302325581395,
        "end": 1881.34,
        "id": 641,
        "no_speech_prob": 0.0002694766444619745,
        "seek": 187258,
        "start": 1879.98,
        "temperature": 0,
        "text": " at the beginning of this coding challenge,",
        "tokens": [
          50734,
          412,
          264,
          2863,
          295,
          341,
          17720,
          3430,
          11,
          50802
        ]
      },
      {
        "avg_logprob": -0.2708667193272317,
        "compression_ratio": 1.7209302325581395,
        "end": 1882.28,
        "id": 642,
        "no_speech_prob": 0.0002694766444619745,
        "seek": 187258,
        "start": 1881.34,
        "temperature": 0,
        "text": " if you don't mind.",
        "tokens": [
          50802,
          498,
          291,
          500,
          380,
          1575,
          13,
          50849
        ]
      },
      {
        "avg_logprob": -0.2708667193272317,
        "compression_ratio": 1.7209302325581395,
        "end": 1886.26,
        "id": 643,
        "no_speech_prob": 0.0002694766444619745,
        "seek": 187258,
        "start": 1884.5,
        "temperature": 0,
        "text": " Hello, welcome to a coding challenge.",
        "tokens": [
          50960,
          2425,
          11,
          2928,
          281,
          257,
          17720,
          3430,
          13,
          51048
        ]
      },
      {
        "avg_logprob": -0.2708667193272317,
        "compression_ratio": 1.7209302325581395,
        "end": 1888.1399999999999,
        "id": 644,
        "no_speech_prob": 0.0002694766444619745,
        "seek": 187258,
        "start": 1886.26,
        "temperature": 0,
        "text": " Now, I know what you're thinking.",
        "tokens": [
          51048,
          823,
          11,
          286,
          458,
          437,
          291,
          434,
          1953,
          13,
          51142
        ]
      },
      {
        "avg_logprob": -0.2708667193272317,
        "compression_ratio": 1.7209302325581395,
        "end": 1888.98,
        "id": 645,
        "no_speech_prob": 0.0002694766444619745,
        "seek": 187258,
        "start": 1888.1399999999999,
        "temperature": 0,
        "text": " I mean, I don't know what you're thinking,",
        "tokens": [
          51142,
          286,
          914,
          11,
          286,
          500,
          380,
          458,
          437,
          291,
          434,
          1953,
          11,
          51184
        ]
      },
      {
        "avg_logprob": -0.2708667193272317,
        "compression_ratio": 1.7209302325581395,
        "end": 1890.78,
        "id": 646,
        "no_speech_prob": 0.0002694766444619745,
        "seek": 187258,
        "start": 1888.98,
        "temperature": 0,
        "text": " but I know what I'm thinking.",
        "tokens": [
          51184,
          457,
          286,
          458,
          437,
          286,
          478,
          1953,
          13,
          51274
        ]
      },
      {
        "avg_logprob": -0.2708667193272317,
        "compression_ratio": 1.7209302325581395,
        "end": 1894.6599999999999,
        "id": 647,
        "no_speech_prob": 0.0002694766444619745,
        "seek": 187258,
        "start": 1890.78,
        "temperature": 0,
        "text": " That looks like coding challenge number 92, XOR,",
        "tokens": [
          51274,
          663,
          1542,
          411,
          17720,
          3430,
          1230,
          28225,
          11,
          1783,
          2483,
          11,
          51468
        ]
      },
      {
        "avg_logprob": -0.2708667193272317,
        "compression_ratio": 1.7209302325581395,
        "end": 1898.02,
        "id": 648,
        "no_speech_prob": 0.0002694766444619745,
        "seek": 187258,
        "start": 1894.6599999999999,
        "temperature": 0,
        "text": " which is probably one of the less interesting,",
        "tokens": [
          51468,
          597,
          307,
          1391,
          472,
          295,
          264,
          1570,
          1880,
          11,
          51636
        ]
      },
      {
        "avg_logprob": -0.2708667193272317,
        "compression_ratio": 1.7209302325581395,
        "end": 1901.1799999999998,
        "id": 649,
        "no_speech_prob": 0.0002694766444619745,
        "seek": 187258,
        "start": 1898.02,
        "temperature": 0,
        "text": " creative, like, sort of just technical",
        "tokens": [
          51636,
          5880,
          11,
          411,
          11,
          1333,
          295,
          445,
          6191,
          51794
        ]
      },
      {
        "avg_logprob": -0.2562844125848067,
        "compression_ratio": 1.7210884353741496,
        "end": 1903.5800000000002,
        "id": 650,
        "no_speech_prob": 0.0008693560375832021,
        "seek": 190118,
        "start": 1901.18,
        "temperature": 0,
        "text": " coding challenge demonstrations that you've done.",
        "tokens": [
          50364,
          17720,
          3430,
          34714,
          300,
          291,
          600,
          1096,
          13,
          50484
        ]
      },
      {
        "avg_logprob": -0.2562844125848067,
        "compression_ratio": 1.7210884353741496,
        "end": 1907.02,
        "id": 651,
        "no_speech_prob": 0.0008693560375832021,
        "seek": 190118,
        "start": 1904.5,
        "temperature": 0,
        "text": " Why, why, why are you doing it again?",
        "tokens": [
          50530,
          1545,
          11,
          983,
          11,
          983,
          366,
          291,
          884,
          309,
          797,
          30,
          50656
        ]
      },
      {
        "avg_logprob": -0.2562844125848067,
        "compression_ratio": 1.7210884353741496,
        "end": 1911.1000000000001,
        "id": 652,
        "no_speech_prob": 0.0008693560375832021,
        "seek": 190118,
        "start": 1907.02,
        "temperature": 0,
        "text": " Well, Eric from the Coding Train community writes,",
        "tokens": [
          50656,
          1042,
          11,
          9336,
          490,
          264,
          383,
          8616,
          28029,
          1768,
          13657,
          11,
          50860
        ]
      },
      {
        "avg_logprob": -0.2562844125848067,
        "compression_ratio": 1.7210884353741496,
        "end": 1912.38,
        "id": 653,
        "no_speech_prob": 0.0008693560375832021,
        "seek": 190118,
        "start": 1911.1000000000001,
        "temperature": 0,
        "text": " nice explanation, because I was,",
        "tokens": [
          50860,
          1481,
          10835,
          11,
          570,
          286,
          390,
          11,
          50924
        ]
      },
      {
        "avg_logprob": -0.2562844125848067,
        "compression_ratio": 1.7210884353741496,
        "end": 1913.22,
        "id": 654,
        "no_speech_prob": 0.0008693560375832021,
        "seek": 190118,
        "start": 1912.38,
        "temperature": 0,
        "text": " just before I started this,",
        "tokens": [
          50924,
          445,
          949,
          286,
          1409,
          341,
          11,
          50966
        ]
      },
      {
        "avg_logprob": -0.2562844125848067,
        "compression_ratio": 1.7210884353741496,
        "end": 1914.7,
        "id": 655,
        "no_speech_prob": 0.0008693560375832021,
        "seek": 190118,
        "start": 1913.22,
        "temperature": 0,
        "text": " having a real hangup about this.",
        "tokens": [
          50966,
          1419,
          257,
          957,
          3967,
          1010,
          466,
          341,
          13,
          51040
        ]
      },
      {
        "avg_logprob": -0.2562844125848067,
        "compression_ratio": 1.7210884353741496,
        "end": 1917.42,
        "id": 656,
        "no_speech_prob": 0.0008693560375832021,
        "seek": 190118,
        "start": 1914.7,
        "temperature": 0,
        "text": " Sometimes it's important when learning something new",
        "tokens": [
          51040,
          4803,
          309,
          311,
          1021,
          562,
          2539,
          746,
          777,
          51176
        ]
      },
      {
        "avg_logprob": -0.2562844125848067,
        "compression_ratio": 1.7210884353741496,
        "end": 1919.96,
        "id": 657,
        "no_speech_prob": 0.0008693560375832021,
        "seek": 190118,
        "start": 1917.42,
        "temperature": 0,
        "text": " to base your exploration around an example",
        "tokens": [
          51176,
          281,
          3096,
          428,
          16197,
          926,
          364,
          1365,
          51303
        ]
      },
      {
        "avg_logprob": -0.2562844125848067,
        "compression_ratio": 1.7210884353741496,
        "end": 1923.26,
        "id": 658,
        "no_speech_prob": 0.0008693560375832021,
        "seek": 190118,
        "start": 1919.96,
        "temperature": 0,
        "text": " which is fairly trivial and you understand intimately well.",
        "tokens": [
          51303,
          597,
          307,
          6457,
          26703,
          293,
          291,
          1223,
          560,
          5401,
          731,
          13,
          51468
        ]
      },
      {
        "avg_logprob": -0.2562844125848067,
        "compression_ratio": 1.7210884353741496,
        "end": 1924.18,
        "id": 659,
        "no_speech_prob": 0.0008693560375832021,
        "seek": 190118,
        "start": 1923.26,
        "temperature": 0,
        "text": " So, here's the thing.",
        "tokens": [
          51468,
          407,
          11,
          510,
          311,
          264,
          551,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.2562844125848067,
        "compression_ratio": 1.7210884353741496,
        "end": 1926.8200000000002,
        "id": 660,
        "no_speech_prob": 0.0008693560375832021,
        "seek": 190118,
        "start": 1924.18,
        "temperature": 0,
        "text": " I am learning something new.",
        "tokens": [
          51514,
          286,
          669,
          2539,
          746,
          777,
          13,
          51646
        ]
      },
      {
        "avg_logprob": -0.2562844125848067,
        "compression_ratio": 1.7210884353741496,
        "end": 1927.8200000000002,
        "id": 661,
        "no_speech_prob": 0.0008693560375832021,
        "seek": 190118,
        "start": 1926.8200000000002,
        "temperature": 0,
        "text": " Oh, come back here.",
        "tokens": [
          51646,
          876,
          11,
          808,
          646,
          510,
          13,
          51696
        ]
      },
      {
        "avg_logprob": -0.2562844125848067,
        "compression_ratio": 1.7210884353741496,
        "end": 1929.9,
        "id": 662,
        "no_speech_prob": 0.0008693560375832021,
        "seek": 190118,
        "start": 1927.8200000000002,
        "temperature": 0,
        "text": " And the thing that I am learning something new",
        "tokens": [
          51696,
          400,
          264,
          551,
          300,
          286,
          669,
          2539,
          746,
          777,
          51800
        ]
      },
      {
        "avg_logprob": -0.24402933813340172,
        "compression_ratio": 1.685459940652819,
        "end": 1931.42,
        "id": 663,
        "no_speech_prob": 0.00011774362064898014,
        "seek": 192990,
        "start": 1929.9,
        "temperature": 0,
        "text": " is this TensorFlow.js thing.",
        "tokens": [
          50364,
          307,
          341,
          37624,
          13,
          25530,
          551,
          13,
          50440
        ]
      },
      {
        "avg_logprob": -0.24402933813340172,
        "compression_ratio": 1.685459940652819,
        "end": 1933.5400000000002,
        "id": 664,
        "no_speech_prob": 0.00011774362064898014,
        "seek": 192990,
        "start": 1931.42,
        "temperature": 0,
        "text": " And wouldn't it be fun to make,",
        "tokens": [
          50440,
          400,
          2759,
          380,
          309,
          312,
          1019,
          281,
          652,
          11,
          50546
        ]
      },
      {
        "avg_logprob": -0.24402933813340172,
        "compression_ratio": 1.685459940652819,
        "end": 1935.14,
        "id": 665,
        "no_speech_prob": 0.00011774362064898014,
        "seek": 192990,
        "start": 1933.5400000000002,
        "temperature": 0,
        "text": " like, play Pac-Man with it,",
        "tokens": [
          50546,
          411,
          11,
          862,
          10702,
          12,
          6652,
          365,
          309,
          11,
          50626
        ]
      },
      {
        "avg_logprob": -0.24402933813340172,
        "compression_ratio": 1.685459940652819,
        "end": 1937.3400000000001,
        "id": 666,
        "no_speech_prob": 0.00011774362064898014,
        "seek": 192990,
        "start": 1935.14,
        "temperature": 0,
        "text": " or the Emoji Scavenger Hunt project,",
        "tokens": [
          50626,
          420,
          264,
          462,
          3280,
          4013,
          47082,
          553,
          1321,
          31740,
          1716,
          11,
          50736
        ]
      },
      {
        "avg_logprob": -0.24402933813340172,
        "compression_ratio": 1.685459940652819,
        "end": 1939.48,
        "id": 667,
        "no_speech_prob": 0.00011774362064898014,
        "seek": 192990,
        "start": 1937.3400000000001,
        "temperature": 0,
        "text": " or Teachable Machine, or play a piano with it,",
        "tokens": [
          50736,
          420,
          26816,
          712,
          22155,
          11,
          420,
          862,
          257,
          9211,
          365,
          309,
          11,
          50843
        ]
      },
      {
        "avg_logprob": -0.24402933813340172,
        "compression_ratio": 1.685459940652819,
        "end": 1940.3200000000002,
        "id": 668,
        "no_speech_prob": 0.00011774362064898014,
        "seek": 192990,
        "start": 1939.48,
        "temperature": 0,
        "text": " all these things.",
        "tokens": [
          50843,
          439,
          613,
          721,
          13,
          50885
        ]
      },
      {
        "avg_logprob": -0.24402933813340172,
        "compression_ratio": 1.685459940652819,
        "end": 1941.5,
        "id": 669,
        "no_speech_prob": 0.00011774362064898014,
        "seek": 192990,
        "start": 1940.3200000000002,
        "temperature": 0,
        "text": " Oh, PoseNet, oh my god, we got it, we got it.",
        "tokens": [
          50885,
          876,
          11,
          40174,
          31890,
          11,
          1954,
          452,
          3044,
          11,
          321,
          658,
          309,
          11,
          321,
          658,
          309,
          13,
          50944
        ]
      },
      {
        "avg_logprob": -0.24402933813340172,
        "compression_ratio": 1.685459940652819,
        "end": 1942.3400000000001,
        "id": 670,
        "no_speech_prob": 0.00011774362064898014,
        "seek": 192990,
        "start": 1941.5,
        "temperature": 0,
        "text": " I want to get to that.",
        "tokens": [
          50944,
          286,
          528,
          281,
          483,
          281,
          300,
          13,
          50986
        ]
      },
      {
        "avg_logprob": -0.24402933813340172,
        "compression_ratio": 1.685459940652819,
        "end": 1944.14,
        "id": 671,
        "no_speech_prob": 0.00011774362064898014,
        "seek": 192990,
        "start": 1942.3400000000001,
        "temperature": 0,
        "text": " And I could just sort of go there right now.",
        "tokens": [
          50986,
          400,
          286,
          727,
          445,
          1333,
          295,
          352,
          456,
          558,
          586,
          13,
          51076
        ]
      },
      {
        "avg_logprob": -0.24402933813340172,
        "compression_ratio": 1.685459940652819,
        "end": 1945.7,
        "id": 672,
        "no_speech_prob": 0.00011774362064898014,
        "seek": 192990,
        "start": 1944.14,
        "temperature": 0,
        "text": " I will get there eventually.",
        "tokens": [
          51076,
          286,
          486,
          483,
          456,
          4728,
          13,
          51154
        ]
      },
      {
        "avg_logprob": -0.24402933813340172,
        "compression_ratio": 1.685459940652819,
        "end": 1947.3400000000001,
        "id": 673,
        "no_speech_prob": 0.00011774362064898014,
        "seek": 192990,
        "start": 1945.7,
        "temperature": 0,
        "text": " But I'm trying to learn the basics",
        "tokens": [
          51154,
          583,
          286,
          478,
          1382,
          281,
          1466,
          264,
          14688,
          51236
        ]
      },
      {
        "avg_logprob": -0.24402933813340172,
        "compression_ratio": 1.685459940652819,
        "end": 1949.7,
        "id": 674,
        "no_speech_prob": 0.00011774362064898014,
        "seek": 192990,
        "start": 1947.3400000000001,
        "temperature": 0,
        "text": " of how the library works.",
        "tokens": [
          51236,
          295,
          577,
          264,
          6405,
          1985,
          13,
          51354
        ]
      },
      {
        "avg_logprob": -0.24402933813340172,
        "compression_ratio": 1.685459940652819,
        "end": 1951.94,
        "id": 675,
        "no_speech_prob": 0.00011774362064898014,
        "seek": 192990,
        "start": 1949.7,
        "temperature": 0,
        "text": " And I'm trying to step through this slowly.",
        "tokens": [
          51354,
          400,
          286,
          478,
          1382,
          281,
          1823,
          807,
          341,
          5692,
          13,
          51466
        ]
      },
      {
        "avg_logprob": -0.24402933813340172,
        "compression_ratio": 1.685459940652819,
        "end": 1954.3400000000001,
        "id": 676,
        "no_speech_prob": 0.00011774362064898014,
        "seek": 192990,
        "start": 1951.94,
        "temperature": 0,
        "text": " So, I will say that if you're watching this video right now,",
        "tokens": [
          51466,
          407,
          11,
          286,
          486,
          584,
          300,
          498,
          291,
          434,
          1976,
          341,
          960,
          558,
          586,
          11,
          51586
        ]
      },
      {
        "avg_logprob": -0.24402933813340172,
        "compression_ratio": 1.685459940652819,
        "end": 1955.8200000000002,
        "id": 677,
        "no_speech_prob": 0.00011774362064898014,
        "seek": 192990,
        "start": 1954.3400000000001,
        "temperature": 0,
        "text": " where you are is not necessarily",
        "tokens": [
          51586,
          689,
          291,
          366,
          307,
          406,
          4725,
          51660
        ]
      },
      {
        "avg_logprob": -0.24402933813340172,
        "compression_ratio": 1.685459940652819,
        "end": 1958.22,
        "id": 678,
        "no_speech_prob": 0.00011774362064898014,
        "seek": 192990,
        "start": 1955.8200000000002,
        "temperature": 0,
        "text": " in the most beginner-friendly place",
        "tokens": [
          51660,
          294,
          264,
          881,
          22080,
          12,
          22864,
          1081,
          51780
        ]
      },
      {
        "avg_logprob": -0.2194822783111244,
        "compression_ratio": 1.7988826815642458,
        "end": 1961.3,
        "id": 679,
        "no_speech_prob": 0.00007484597153961658,
        "seek": 195822,
        "start": 1958.22,
        "temperature": 0,
        "text": " because I'm working with TensorFlow.js natively",
        "tokens": [
          50364,
          570,
          286,
          478,
          1364,
          365,
          37624,
          13,
          25530,
          8470,
          356,
          50518
        ]
      },
      {
        "avg_logprob": -0.2194822783111244,
        "compression_ratio": 1.7988826815642458,
        "end": 1963.8600000000001,
        "id": 680,
        "no_speech_prob": 0.00007484597153961658,
        "seek": 195822,
        "start": 1961.3,
        "temperature": 0,
        "text": " to implement basically, like, a weird math problem.",
        "tokens": [
          50518,
          281,
          4445,
          1936,
          11,
          411,
          11,
          257,
          3657,
          5221,
          1154,
          13,
          50646
        ]
      },
      {
        "avg_logprob": -0.2194822783111244,
        "compression_ratio": 1.7988826815642458,
        "end": 1965.06,
        "id": 681,
        "no_speech_prob": 0.00007484597153961658,
        "seek": 195822,
        "start": 1963.8600000000001,
        "temperature": 0,
        "text": " It's not that weird of a problem, actually,",
        "tokens": [
          50646,
          467,
          311,
          406,
          300,
          3657,
          295,
          257,
          1154,
          11,
          767,
          11,
          50706
        ]
      },
      {
        "avg_logprob": -0.2194822783111244,
        "compression_ratio": 1.7988826815642458,
        "end": 1967.18,
        "id": 682,
        "no_speech_prob": 0.00007484597153961658,
        "seek": 195822,
        "start": 1965.06,
        "temperature": 0,
        "text": " but a very basic, trivial math problem",
        "tokens": [
          50706,
          457,
          257,
          588,
          3875,
          11,
          26703,
          5221,
          1154,
          50812
        ]
      },
      {
        "avg_logprob": -0.2194822783111244,
        "compression_ratio": 1.7988826815642458,
        "end": 1969.58,
        "id": 683,
        "no_speech_prob": 0.00007484597153961658,
        "seek": 195822,
        "start": 1967.18,
        "temperature": 0,
        "text": " just to see how TensorFlow.js works.",
        "tokens": [
          50812,
          445,
          281,
          536,
          577,
          37624,
          13,
          25530,
          1985,
          13,
          50932
        ]
      },
      {
        "avg_logprob": -0.2194822783111244,
        "compression_ratio": 1.7988826815642458,
        "end": 1971.26,
        "id": 684,
        "no_speech_prob": 0.00007484597153961658,
        "seek": 195822,
        "start": 1969.58,
        "temperature": 0,
        "text": " That's what I'm trying to do in this coding challenge.",
        "tokens": [
          50932,
          663,
          311,
          437,
          286,
          478,
          1382,
          281,
          360,
          294,
          341,
          17720,
          3430,
          13,
          51016
        ]
      },
      {
        "avg_logprob": -0.2194822783111244,
        "compression_ratio": 1.7988826815642458,
        "end": 1974.22,
        "id": 685,
        "no_speech_prob": 0.00007484597153961658,
        "seek": 195822,
        "start": 1971.26,
        "temperature": 0,
        "text": " And in about 20 or 30 minutes, I'll be coding.",
        "tokens": [
          51016,
          400,
          294,
          466,
          945,
          420,
          2217,
          2077,
          11,
          286,
          603,
          312,
          17720,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.2194822783111244,
        "compression_ratio": 1.7988826815642458,
        "end": 1975.6200000000001,
        "id": 686,
        "no_speech_prob": 0.00007484597153961658,
        "seek": 195822,
        "start": 1974.22,
        "temperature": 0,
        "text": " This coding challenge is, just look,",
        "tokens": [
          51164,
          639,
          17720,
          3430,
          307,
          11,
          445,
          574,
          11,
          51234
        ]
      },
      {
        "avg_logprob": -0.2194822783111244,
        "compression_ratio": 1.7988826815642458,
        "end": 1977.46,
        "id": 687,
        "no_speech_prob": 0.00007484597153961658,
        "seek": 195822,
        "start": 1975.6200000000001,
        "temperature": 0,
        "text": " it's probably like four hours and 72 minutes long,",
        "tokens": [
          51234,
          309,
          311,
          1391,
          411,
          1451,
          2496,
          293,
          18731,
          2077,
          938,
          11,
          51326
        ]
      },
      {
        "avg_logprob": -0.2194822783111244,
        "compression_ratio": 1.7988826815642458,
        "end": 1978.82,
        "id": 688,
        "no_speech_prob": 0.00007484597153961658,
        "seek": 195822,
        "start": 1977.46,
        "temperature": 0,
        "text": " which is why I say 72 minutes",
        "tokens": [
          51326,
          597,
          307,
          983,
          286,
          584,
          18731,
          2077,
          51394
        ]
      },
      {
        "avg_logprob": -0.2194822783111244,
        "compression_ratio": 1.7988826815642458,
        "end": 1979.8600000000001,
        "id": 689,
        "no_speech_prob": 0.00007484597153961658,
        "seek": 195822,
        "start": 1978.82,
        "temperature": 0,
        "text": " because that's five hours and 12 minutes,",
        "tokens": [
          51394,
          570,
          300,
          311,
          1732,
          2496,
          293,
          2272,
          2077,
          11,
          51446
        ]
      },
      {
        "avg_logprob": -0.2194822783111244,
        "compression_ratio": 1.7988826815642458,
        "end": 1981.64,
        "id": 690,
        "no_speech_prob": 0.00007484597153961658,
        "seek": 195822,
        "start": 1979.8600000000001,
        "temperature": 0,
        "text": " but I don't know what's going on.",
        "tokens": [
          51446,
          457,
          286,
          500,
          380,
          458,
          437,
          311,
          516,
          322,
          13,
          51535
        ]
      },
      {
        "avg_logprob": -0.2194822783111244,
        "compression_ratio": 1.7988826815642458,
        "end": 1983.08,
        "id": 691,
        "no_speech_prob": 0.00007484597153961658,
        "seek": 195822,
        "start": 1981.64,
        "temperature": 0,
        "text": " But the trajectory that I'm on",
        "tokens": [
          51535,
          583,
          264,
          21512,
          300,
          286,
          478,
          322,
          51607
        ]
      },
      {
        "avg_logprob": -0.2194822783111244,
        "compression_ratio": 1.7988826815642458,
        "end": 1985.06,
        "id": 692,
        "no_speech_prob": 0.00007484597153961658,
        "seek": 195822,
        "start": 1983.08,
        "temperature": 0,
        "text": " is I'm going to start doing some stuff,",
        "tokens": [
          51607,
          307,
          286,
          478,
          516,
          281,
          722,
          884,
          512,
          1507,
          11,
          51706
        ]
      },
      {
        "avg_logprob": -0.2194822783111244,
        "compression_ratio": 1.7988826815642458,
        "end": 1986.02,
        "id": 693,
        "no_speech_prob": 0.00007484597153961658,
        "seek": 195822,
        "start": 1985.06,
        "temperature": 0,
        "text": " inching my way towards,",
        "tokens": [
          51706,
          7227,
          278,
          452,
          636,
          3030,
          11,
          51754
        ]
      },
      {
        "avg_logprob": -0.2194822783111244,
        "compression_ratio": 1.7988826815642458,
        "end": 1987.78,
        "id": 694,
        "no_speech_prob": 0.00007484597153961658,
        "seek": 195822,
        "start": 1986.02,
        "temperature": 0,
        "text": " oh, let's actually use some data.",
        "tokens": [
          51754,
          1954,
          11,
          718,
          311,
          767,
          764,
          512,
          1412,
          13,
          51842
        ]
      },
      {
        "avg_logprob": -0.21760525280916238,
        "compression_ratio": 1.7463556851311954,
        "end": 1989.82,
        "id": 695,
        "no_speech_prob": 0.00010391024989075959,
        "seek": 198778,
        "start": 1988.3,
        "temperature": 0,
        "text": " Let's use some more data, maybe some images.",
        "tokens": [
          50390,
          961,
          311,
          764,
          512,
          544,
          1412,
          11,
          1310,
          512,
          5267,
          13,
          50466
        ]
      },
      {
        "avg_logprob": -0.21760525280916238,
        "compression_ratio": 1.7463556851311954,
        "end": 1991.86,
        "id": 696,
        "no_speech_prob": 0.00010391024989075959,
        "seek": 198778,
        "start": 1989.82,
        "temperature": 0,
        "text": " And so, I've got a bunch of things that I'm stepping through",
        "tokens": [
          50466,
          400,
          370,
          11,
          286,
          600,
          658,
          257,
          3840,
          295,
          721,
          300,
          286,
          478,
          16821,
          807,
          50568
        ]
      },
      {
        "avg_logprob": -0.21760525280916238,
        "compression_ratio": 1.7463556851311954,
        "end": 1993.34,
        "id": 697,
        "no_speech_prob": 0.00010391024989075959,
        "seek": 198778,
        "start": 1991.86,
        "temperature": 0,
        "text": " and I'm trying to get to the point",
        "tokens": [
          50568,
          293,
          286,
          478,
          1382,
          281,
          483,
          281,
          264,
          935,
          50642
        ]
      },
      {
        "avg_logprob": -0.21760525280916238,
        "compression_ratio": 1.7463556851311954,
        "end": 1995.54,
        "id": 698,
        "no_speech_prob": 0.00010391024989075959,
        "seek": 198778,
        "start": 1993.34,
        "temperature": 0,
        "text": " where I'm going to use this other machine learning library",
        "tokens": [
          50642,
          689,
          286,
          478,
          516,
          281,
          764,
          341,
          661,
          3479,
          2539,
          6405,
          50752
        ]
      },
      {
        "avg_logprob": -0.21760525280916238,
        "compression_ratio": 1.7463556851311954,
        "end": 1997.94,
        "id": 699,
        "no_speech_prob": 0.00010391024989075959,
        "seek": 198778,
        "start": 1995.54,
        "temperature": 0,
        "text": " called ml5, which at the time of this recording",
        "tokens": [
          50752,
          1219,
          23271,
          20,
          11,
          597,
          412,
          264,
          565,
          295,
          341,
          6613,
          50872
        ]
      },
      {
        "avg_logprob": -0.21760525280916238,
        "compression_ratio": 1.7463556851311954,
        "end": 1999.86,
        "id": 700,
        "no_speech_prob": 0.00010391024989075959,
        "seek": 198778,
        "start": 1997.94,
        "temperature": 0,
        "text": " hasn't really officially been released yet,",
        "tokens": [
          50872,
          6132,
          380,
          534,
          12053,
          668,
          4736,
          1939,
          11,
          50968
        ]
      },
      {
        "avg_logprob": -0.21760525280916238,
        "compression_ratio": 1.7463556851311954,
        "end": 2002.22,
        "id": 701,
        "no_speech_prob": 0.00010391024989075959,
        "seek": 198778,
        "start": 1999.86,
        "temperature": 0,
        "text": " but builds on top of TensorFlow.js.",
        "tokens": [
          50968,
          457,
          15182,
          322,
          1192,
          295,
          37624,
          13,
          25530,
          13,
          51086
        ]
      },
      {
        "avg_logprob": -0.21760525280916238,
        "compression_ratio": 1.7463556851311954,
        "end": 2004.46,
        "id": 702,
        "no_speech_prob": 0.00010391024989075959,
        "seek": 198778,
        "start": 2002.22,
        "temperature": 0,
        "text": " Thank you, everyone who made TensorFlow.js,",
        "tokens": [
          51086,
          1044,
          291,
          11,
          1518,
          567,
          1027,
          37624,
          13,
          25530,
          11,
          51198
        ]
      },
      {
        "avg_logprob": -0.21760525280916238,
        "compression_ratio": 1.7463556851311954,
        "end": 2005.98,
        "id": 703,
        "no_speech_prob": 0.00010391024989075959,
        "seek": 198778,
        "start": 2004.46,
        "temperature": 0,
        "text": " wherever you are,",
        "tokens": [
          51198,
          8660,
          291,
          366,
          11,
          51274
        ]
      },
      {
        "avg_logprob": -0.21760525280916238,
        "compression_ratio": 1.7463556851311954,
        "end": 2008.54,
        "id": 704,
        "no_speech_prob": 0.00010391024989075959,
        "seek": 198778,
        "start": 2005.98,
        "temperature": 0,
        "text": " to try to create some more accessible interfaces",
        "tokens": [
          51274,
          281,
          853,
          281,
          1884,
          512,
          544,
          9515,
          28416,
          51402
        ]
      },
      {
        "avg_logprob": -0.21760525280916238,
        "compression_ratio": 1.7463556851311954,
        "end": 2011.16,
        "id": 705,
        "no_speech_prob": 0.00010391024989075959,
        "seek": 198778,
        "start": 2008.54,
        "temperature": 0,
        "text": " to some of the algorithms and models,",
        "tokens": [
          51402,
          281,
          512,
          295,
          264,
          14642,
          293,
          5245,
          11,
          51533
        ]
      },
      {
        "avg_logprob": -0.21760525280916238,
        "compression_ratio": 1.7463556851311954,
        "end": 2012.82,
        "id": 706,
        "no_speech_prob": 0.00010391024989075959,
        "seek": 198778,
        "start": 2011.16,
        "temperature": 0,
        "text": " things that you can do with TensorFlow.js",
        "tokens": [
          51533,
          721,
          300,
          291,
          393,
          360,
          365,
          37624,
          13,
          25530,
          51616
        ]
      },
      {
        "avg_logprob": -0.21760525280916238,
        "compression_ratio": 1.7463556851311954,
        "end": 2015.8999999999999,
        "id": 707,
        "no_speech_prob": 0.00010391024989075959,
        "seek": 198778,
        "start": 2012.82,
        "temperature": 0,
        "text": " without having to do the lower-level memory management",
        "tokens": [
          51616,
          1553,
          1419,
          281,
          360,
          264,
          3126,
          12,
          12418,
          4675,
          4592,
          51770
        ]
      },
      {
        "avg_logprob": -0.21760525280916238,
        "compression_ratio": 1.7463556851311954,
        "end": 2017.3799999999999,
        "id": 708,
        "no_speech_prob": 0.00010391024989075959,
        "seek": 198778,
        "start": 2015.8999999999999,
        "temperature": 0,
        "text": " and math operation stuff.",
        "tokens": [
          51770,
          293,
          5221,
          6916,
          1507,
          13,
          51844
        ]
      },
      {
        "avg_logprob": -0.32516396213585225,
        "compression_ratio": 1.7160493827160495,
        "end": 2019.8600000000001,
        "id": 709,
        "no_speech_prob": 0.000014285491488408297,
        "seek": 201738,
        "start": 2017.9,
        "temperature": 0,
        "text": " All of that is coming,",
        "tokens": [
          50390,
          1057,
          295,
          300,
          307,
          1348,
          11,
          50488
        ]
      },
      {
        "avg_logprob": -0.32516396213585225,
        "compression_ratio": 1.7160493827160495,
        "end": 2021.9,
        "id": 710,
        "no_speech_prob": 0.000014285491488408297,
        "seek": 201738,
        "start": 2019.8600000000001,
        "temperature": 0,
        "text": " and I just took a lot of time in this coding challenge",
        "tokens": [
          50488,
          293,
          286,
          445,
          1890,
          257,
          688,
          295,
          565,
          294,
          341,
          17720,
          3430,
          50590
        ]
      },
      {
        "avg_logprob": -0.32516396213585225,
        "compression_ratio": 1.7160493827160495,
        "end": 2022.8600000000001,
        "id": 711,
        "no_speech_prob": 0.000014285491488408297,
        "seek": 201738,
        "start": 2021.9,
        "temperature": 0,
        "text": " to say that to you.",
        "tokens": [
          50590,
          281,
          584,
          300,
          281,
          291,
          13,
          50638
        ]
      },
      {
        "avg_logprob": -0.32516396213585225,
        "compression_ratio": 1.7160493827160495,
        "end": 2026.9,
        "id": 712,
        "no_speech_prob": 0.000014285491488408297,
        "seek": 201738,
        "start": 2024.1000000000001,
        "temperature": 0,
        "text": " But as much as I kind of don't,",
        "tokens": [
          50700,
          583,
          382,
          709,
          382,
          286,
          733,
          295,
          500,
          380,
          11,
          50840
        ]
      },
      {
        "avg_logprob": -0.32516396213585225,
        "compression_ratio": 1.7160493827160495,
        "end": 2028.8600000000001,
        "id": 713,
        "no_speech_prob": 0.000014285491488408297,
        "seek": 201738,
        "start": 2026.9,
        "temperature": 0,
        "text": " I'm not so sure, but what I'm going to do,",
        "tokens": [
          50840,
          286,
          478,
          406,
          370,
          988,
          11,
          457,
          437,
          286,
          478,
          516,
          281,
          360,
          11,
          50938
        ]
      },
      {
        "avg_logprob": -0.32516396213585225,
        "compression_ratio": 1.7160493827160495,
        "end": 2029.8200000000002,
        "id": 714,
        "no_speech_prob": 0.000014285491488408297,
        "seek": 201738,
        "start": 2028.8600000000001,
        "temperature": 0,
        "text": " so y is x source.",
        "tokens": [
          50938,
          370,
          288,
          307,
          2031,
          4009,
          13,
          50986
        ]
      },
      {
        "avg_logprob": -0.32516396213585225,
        "compression_ratio": 1.7160493827160495,
        "end": 2030.66,
        "id": 715,
        "no_speech_prob": 0.000014285491488408297,
        "seek": 201738,
        "start": 2029.8200000000002,
        "temperature": 0,
        "text": " So here's the thing.",
        "tokens": [
          50986,
          407,
          510,
          311,
          264,
          551,
          13,
          51028
        ]
      },
      {
        "avg_logprob": -0.32516396213585225,
        "compression_ratio": 1.7160493827160495,
        "end": 2031.48,
        "id": 716,
        "no_speech_prob": 0.000014285491488408297,
        "seek": 201738,
        "start": 2030.66,
        "temperature": 0,
        "text": " This is y.",
        "tokens": [
          51028,
          639,
          307,
          288,
          13,
          51069
        ]
      },
      {
        "avg_logprob": -0.32516396213585225,
        "compression_ratio": 1.7160493827160495,
        "end": 2032.6200000000001,
        "id": 717,
        "no_speech_prob": 0.000014285491488408297,
        "seek": 201738,
        "start": 2031.48,
        "temperature": 0,
        "text": " I need an example.",
        "tokens": [
          51069,
          286,
          643,
          364,
          1365,
          13,
          51126
        ]
      },
      {
        "avg_logprob": -0.32516396213585225,
        "compression_ratio": 1.7160493827160495,
        "end": 2035.42,
        "id": 718,
        "no_speech_prob": 0.000014285491488408297,
        "seek": 201738,
        "start": 2032.6200000000001,
        "temperature": 0,
        "text": " This is the first time I'm going to ever,",
        "tokens": [
          51126,
          639,
          307,
          264,
          700,
          565,
          286,
          478,
          516,
          281,
          1562,
          11,
          51266
        ]
      },
      {
        "avg_logprob": -0.32516396213585225,
        "compression_ratio": 1.7160493827160495,
        "end": 2038.6200000000001,
        "id": 719,
        "no_speech_prob": 0.000014285491488408297,
        "seek": 201738,
        "start": 2035.42,
        "temperature": 0,
        "text": " in any of my videos except for the other one that I made,",
        "tokens": [
          51266,
          294,
          604,
          295,
          452,
          2145,
          3993,
          337,
          264,
          661,
          472,
          300,
          286,
          1027,
          11,
          51426
        ]
      },
      {
        "avg_logprob": -0.32516396213585225,
        "compression_ratio": 1.7160493827160495,
        "end": 2040.64,
        "id": 720,
        "no_speech_prob": 0.000014285491488408297,
        "seek": 201738,
        "start": 2038.6200000000001,
        "temperature": 0,
        "text": " but this is the first time that I'm actually going to use",
        "tokens": [
          51426,
          457,
          341,
          307,
          264,
          700,
          565,
          300,
          286,
          478,
          767,
          516,
          281,
          764,
          51527
        ]
      },
      {
        "avg_logprob": -0.32516396213585225,
        "compression_ratio": 1.7160493827160495,
        "end": 2044.3400000000001,
        "id": 721,
        "no_speech_prob": 0.000014285491488408297,
        "seek": 201738,
        "start": 2040.64,
        "temperature": 0,
        "text": " the tf.layers API",
        "tokens": [
          51527,
          264,
          256,
          69,
          13,
          8376,
          433,
          9362,
          51712
        ]
      },
      {
        "avg_logprob": -0.23191269044953633,
        "compression_ratio": 1.5772058823529411,
        "end": 2050.06,
        "id": 722,
        "no_speech_prob": 0.00006014134123688564,
        "seek": 204434,
        "start": 2045.22,
        "temperature": 0,
        "text": " to train a model with a dataset",
        "tokens": [
          50408,
          281,
          3847,
          257,
          2316,
          365,
          257,
          28872,
          50650
        ]
      },
      {
        "avg_logprob": -0.23191269044953633,
        "compression_ratio": 1.5772058823529411,
        "end": 2052.62,
        "id": 723,
        "no_speech_prob": 0.00006014134123688564,
        "seek": 204434,
        "start": 2050.06,
        "temperature": 0,
        "text": " to produce a certain output.",
        "tokens": [
          50650,
          281,
          5258,
          257,
          1629,
          5598,
          13,
          50778
        ]
      },
      {
        "avg_logprob": -0.23191269044953633,
        "compression_ratio": 1.5772058823529411,
        "end": 2056.2599999999998,
        "id": 724,
        "no_speech_prob": 0.00006014134123688564,
        "seek": 204434,
        "start": 2052.62,
        "temperature": 0,
        "text": " I did two tutorials about what the tf.layers API is.",
        "tokens": [
          50778,
          286,
          630,
          732,
          17616,
          466,
          437,
          264,
          256,
          69,
          13,
          8376,
          433,
          9362,
          307,
          13,
          50960
        ]
      },
      {
        "avg_logprob": -0.23191269044953633,
        "compression_ratio": 1.5772058823529411,
        "end": 2057.8199999999997,
        "id": 725,
        "no_speech_prob": 0.00006014134123688564,
        "seek": 204434,
        "start": 2056.2599999999998,
        "temperature": 0,
        "text": " You can pause now and go and watch those",
        "tokens": [
          50960,
          509,
          393,
          10465,
          586,
          293,
          352,
          293,
          1159,
          729,
          51038
        ]
      },
      {
        "avg_logprob": -0.23191269044953633,
        "compression_ratio": 1.5772058823529411,
        "end": 2059.22,
        "id": 726,
        "no_speech_prob": 0.00006014134123688564,
        "seek": 204434,
        "start": 2057.8199999999997,
        "temperature": 0,
        "text": " and then come back here,",
        "tokens": [
          51038,
          293,
          550,
          808,
          646,
          510,
          11,
          51108
        ]
      },
      {
        "avg_logprob": -0.23191269044953633,
        "compression_ratio": 1.5772058823529411,
        "end": 2060.16,
        "id": 727,
        "no_speech_prob": 0.00006014134123688564,
        "seek": 204434,
        "start": 2059.22,
        "temperature": 0,
        "text": " but in those videos,",
        "tokens": [
          51108,
          457,
          294,
          729,
          2145,
          11,
          51155
        ]
      },
      {
        "avg_logprob": -0.23191269044953633,
        "compression_ratio": 1.5772058823529411,
        "end": 2062.14,
        "id": 728,
        "no_speech_prob": 0.00006014134123688564,
        "seek": 204434,
        "start": 2060.16,
        "temperature": 0,
        "text": " I didn't actually do anything with tf.layers.",
        "tokens": [
          51155,
          286,
          994,
          380,
          767,
          360,
          1340,
          365,
          256,
          69,
          13,
          8376,
          433,
          13,
          51254
        ]
      },
      {
        "avg_logprob": -0.23191269044953633,
        "compression_ratio": 1.5772058823529411,
        "end": 2064.14,
        "id": 729,
        "no_speech_prob": 0.00006014134123688564,
        "seek": 204434,
        "start": 2062.14,
        "temperature": 0,
        "text": " I just sort of talked through and typed out some code.",
        "tokens": [
          51254,
          286,
          445,
          1333,
          295,
          2825,
          807,
          293,
          33941,
          484,
          512,
          3089,
          13,
          51354
        ]
      },
      {
        "avg_logprob": -0.23191269044953633,
        "compression_ratio": 1.5772058823529411,
        "end": 2065.9,
        "id": 730,
        "no_speech_prob": 0.00006014134123688564,
        "seek": 204434,
        "start": 2064.14,
        "temperature": 0,
        "text": " So the problem that I want to solve,",
        "tokens": [
          51354,
          407,
          264,
          1154,
          300,
          286,
          528,
          281,
          5039,
          11,
          51442
        ]
      },
      {
        "avg_logprob": -0.23191269044953633,
        "compression_ratio": 1.5772058823529411,
        "end": 2067.94,
        "id": 731,
        "no_speech_prob": 0.00006014134123688564,
        "seek": 204434,
        "start": 2065.9,
        "temperature": 0,
        "text": " and apologies for explaining this probably",
        "tokens": [
          51442,
          293,
          34929,
          337,
          13468,
          341,
          1391,
          51544
        ]
      },
      {
        "avg_logprob": -0.23191269044953633,
        "compression_ratio": 1.5772058823529411,
        "end": 2070.4,
        "id": 732,
        "no_speech_prob": 0.00006014134123688564,
        "seek": 204434,
        "start": 2067.94,
        "temperature": 0,
        "text": " for like the 15th time on this YouTube channel,",
        "tokens": [
          51544,
          337,
          411,
          264,
          2119,
          392,
          565,
          322,
          341,
          3088,
          2269,
          11,
          51667
        ]
      },
      {
        "avg_logprob": -0.22249808965944776,
        "compression_ratio": 1.5948275862068966,
        "end": 2074.92,
        "id": 733,
        "no_speech_prob": 0.000018925138647318818,
        "seek": 207040,
        "start": 2070.4,
        "temperature": 0,
        "text": " is very well known from machine learning, XOR,",
        "tokens": [
          50364,
          307,
          588,
          731,
          2570,
          490,
          3479,
          2539,
          11,
          1783,
          2483,
          11,
          50590
        ]
      },
      {
        "avg_logprob": -0.22249808965944776,
        "compression_ratio": 1.5948275862068966,
        "end": 2078.64,
        "id": 734,
        "no_speech_prob": 0.000018925138647318818,
        "seek": 207040,
        "start": 2074.92,
        "temperature": 0,
        "text": " because when the original perceptron was invented,",
        "tokens": [
          50590,
          570,
          562,
          264,
          3380,
          43276,
          2044,
          390,
          14479,
          11,
          50776
        ]
      },
      {
        "avg_logprob": -0.22249808965944776,
        "compression_ratio": 1.5948275862068966,
        "end": 2079.8,
        "id": 735,
        "no_speech_prob": 0.000018925138647318818,
        "seek": 207040,
        "start": 2078.64,
        "temperature": 0,
        "text": " the single perceptron,",
        "tokens": [
          50776,
          264,
          2167,
          43276,
          2044,
          11,
          50834
        ]
      },
      {
        "avg_logprob": -0.22249808965944776,
        "compression_ratio": 1.5948275862068966,
        "end": 2082.34,
        "id": 736,
        "no_speech_prob": 0.000018925138647318818,
        "seek": 207040,
        "start": 2079.8,
        "temperature": 0,
        "text": " the model of an individual neuron",
        "tokens": [
          50834,
          264,
          2316,
          295,
          364,
          2609,
          34090,
          50961
        ]
      },
      {
        "avg_logprob": -0.22249808965944776,
        "compression_ratio": 1.5948275862068966,
        "end": 2086.04,
        "id": 737,
        "no_speech_prob": 0.000018925138647318818,
        "seek": 207040,
        "start": 2082.34,
        "temperature": 0,
        "text": " that could receive inputs and generate an output,",
        "tokens": [
          50961,
          300,
          727,
          4774,
          15743,
          293,
          8460,
          364,
          5598,
          11,
          51146
        ]
      },
      {
        "avg_logprob": -0.22249808965944776,
        "compression_ratio": 1.5948275862068966,
        "end": 2088.64,
        "id": 738,
        "no_speech_prob": 0.000018925138647318818,
        "seek": 207040,
        "start": 2086.04,
        "temperature": 0,
        "text": " it could not solve XOR.",
        "tokens": [
          51146,
          309,
          727,
          406,
          5039,
          1783,
          2483,
          13,
          51276
        ]
      },
      {
        "avg_logprob": -0.22249808965944776,
        "compression_ratio": 1.5948275862068966,
        "end": 2090.8,
        "id": 739,
        "no_speech_prob": 0.000018925138647318818,
        "seek": 207040,
        "start": 2089.96,
        "temperature": 0,
        "text": " It just couldn't.",
        "tokens": [
          51342,
          467,
          445,
          2809,
          380,
          13,
          51384
        ]
      },
      {
        "avg_logprob": -0.22249808965944776,
        "compression_ratio": 1.5948275862068966,
        "end": 2092.4,
        "id": 740,
        "no_speech_prob": 0.000018925138647318818,
        "seek": 207040,
        "start": 2090.8,
        "temperature": 0,
        "text": " It's not a linearly separable problem,",
        "tokens": [
          51384,
          467,
          311,
          406,
          257,
          43586,
          3128,
          712,
          1154,
          11,
          51464
        ]
      },
      {
        "avg_logprob": -0.22249808965944776,
        "compression_ratio": 1.5948275862068966,
        "end": 2094.2200000000003,
        "id": 741,
        "no_speech_prob": 0.000018925138647318818,
        "seek": 207040,
        "start": 2092.4,
        "temperature": 0,
        "text": " and I've talked about that in other videos",
        "tokens": [
          51464,
          293,
          286,
          600,
          2825,
          466,
          300,
          294,
          661,
          2145,
          51555
        ]
      },
      {
        "avg_logprob": -0.22249808965944776,
        "compression_ratio": 1.5948275862068966,
        "end": 2096.8,
        "id": 742,
        "no_speech_prob": 0.000018925138647318818,
        "seek": 207040,
        "start": 2094.2200000000003,
        "temperature": 0,
        "text": " about why we need multilayer perceptrons.",
        "tokens": [
          51555,
          466,
          983,
          321,
          643,
          2120,
          388,
          11167,
          43276,
          13270,
          13,
          51684
        ]
      },
      {
        "avg_logprob": -0.31630011449886275,
        "compression_ratio": 1.5194805194805194,
        "end": 2100.28,
        "id": 743,
        "no_speech_prob": 0.000005255375526758144,
        "seek": 209680,
        "start": 2096.8,
        "temperature": 0,
        "text": " So the nice thing about XOR is I can diagram for you.",
        "tokens": [
          50364,
          407,
          264,
          1481,
          551,
          466,
          1783,
          2483,
          307,
          286,
          393,
          10686,
          337,
          291,
          13,
          50538
        ]
      },
      {
        "avg_logprob": -0.31630011449886275,
        "compression_ratio": 1.5194805194805194,
        "end": 2102.52,
        "id": 744,
        "no_speech_prob": 0.000005255375526758144,
        "seek": 209680,
        "start": 2101.6800000000003,
        "temperature": 0,
        "text": " Hold on a sec.",
        "tokens": [
          50608,
          6962,
          322,
          257,
          907,
          13,
          50650
        ]
      },
      {
        "avg_logprob": -0.31630011449886275,
        "compression_ratio": 1.5194805194805194,
        "end": 2103.34,
        "id": 745,
        "no_speech_prob": 0.000005255375526758144,
        "seek": 209680,
        "start": 2102.52,
        "temperature": 0,
        "text": " Ha.",
        "tokens": [
          50650,
          4064,
          13,
          50691
        ]
      },
      {
        "avg_logprob": -0.31630011449886275,
        "compression_ratio": 1.5194805194805194,
        "end": 2110.04,
        "id": 746,
        "no_speech_prob": 0.000005255375526758144,
        "seek": 209680,
        "start": 2108.54,
        "temperature": 0,
        "text": " I'm back.",
        "tokens": [
          50951,
          286,
          478,
          646,
          13,
          51026
        ]
      },
      {
        "avg_logprob": -0.31630011449886275,
        "compression_ratio": 1.5194805194805194,
        "end": 2113.9,
        "id": 747,
        "no_speech_prob": 0.000005255375526758144,
        "seek": 209680,
        "start": 2110.04,
        "temperature": 0,
        "text": " I can diagram for you the architecture",
        "tokens": [
          51026,
          286,
          393,
          10686,
          337,
          291,
          264,
          9482,
          51219
        ]
      },
      {
        "avg_logprob": -0.31630011449886275,
        "compression_ratio": 1.5194805194805194,
        "end": 2116.1200000000003,
        "id": 748,
        "no_speech_prob": 0.000005255375526758144,
        "seek": 209680,
        "start": 2113.9,
        "temperature": 0,
        "text": " of the model that we need to create.",
        "tokens": [
          51219,
          295,
          264,
          2316,
          300,
          321,
          643,
          281,
          1884,
          13,
          51330
        ]
      },
      {
        "avg_logprob": -0.31630011449886275,
        "compression_ratio": 1.5194805194805194,
        "end": 2118.84,
        "id": 749,
        "no_speech_prob": 0.000005255375526758144,
        "seek": 209680,
        "start": 2116.1200000000003,
        "temperature": 0,
        "text": " There are two inputs.",
        "tokens": [
          51330,
          821,
          366,
          732,
          15743,
          13,
          51466
        ]
      },
      {
        "avg_logprob": -0.31630011449886275,
        "compression_ratio": 1.5194805194805194,
        "end": 2121.36,
        "id": 750,
        "no_speech_prob": 0.000005255375526758144,
        "seek": 209680,
        "start": 2118.84,
        "temperature": 0,
        "text": " There is one output.",
        "tokens": [
          51466,
          821,
          307,
          472,
          5598,
          13,
          51592
        ]
      },
      {
        "avg_logprob": -0.31630011449886275,
        "compression_ratio": 1.5194805194805194,
        "end": 2124.76,
        "id": 751,
        "no_speech_prob": 0.000005255375526758144,
        "seek": 209680,
        "start": 2121.36,
        "temperature": 0,
        "text": " So the inputs to the XOR problem",
        "tokens": [
          51592,
          407,
          264,
          15743,
          281,
          264,
          1783,
          2483,
          1154,
          51762
        ]
      },
      {
        "avg_logprob": -0.2591020672820335,
        "compression_ratio": 1.794701986754967,
        "end": 2127.32,
        "id": 752,
        "no_speech_prob": 0.0007554047042503953,
        "seek": 212476,
        "start": 2124.76,
        "temperature": 0,
        "text": " are true and false values.",
        "tokens": [
          50364,
          366,
          2074,
          293,
          7908,
          4190,
          13,
          50492
        ]
      },
      {
        "avg_logprob": -0.2591020672820335,
        "compression_ratio": 1.794701986754967,
        "end": 2131.1600000000003,
        "id": 753,
        "no_speech_prob": 0.0007554047042503953,
        "seek": 212476,
        "start": 2127.32,
        "temperature": 0,
        "text": " So if I made a little truth table,",
        "tokens": [
          50492,
          407,
          498,
          286,
          1027,
          257,
          707,
          3494,
          3199,
          11,
          50684
        ]
      },
      {
        "avg_logprob": -0.2591020672820335,
        "compression_ratio": 1.794701986754967,
        "end": 2135.32,
        "id": 754,
        "no_speech_prob": 0.0007554047042503953,
        "seek": 212476,
        "start": 2131.1600000000003,
        "temperature": 0,
        "text": " and, or, XOR, right?",
        "tokens": [
          50684,
          293,
          11,
          420,
          11,
          1783,
          2483,
          11,
          558,
          30,
          50892
        ]
      },
      {
        "avg_logprob": -0.2591020672820335,
        "compression_ratio": 1.794701986754967,
        "end": 2139.44,
        "id": 755,
        "no_speech_prob": 0.0007554047042503953,
        "seek": 212476,
        "start": 2135.32,
        "temperature": 0,
        "text": " I could have true true, true false,",
        "tokens": [
          50892,
          286,
          727,
          362,
          2074,
          2074,
          11,
          2074,
          7908,
          11,
          51098
        ]
      },
      {
        "avg_logprob": -0.2591020672820335,
        "compression_ratio": 1.794701986754967,
        "end": 2142.32,
        "id": 756,
        "no_speech_prob": 0.0007554047042503953,
        "seek": 212476,
        "start": 2139.44,
        "temperature": 0,
        "text": " false true, false false.",
        "tokens": [
          51098,
          7908,
          2074,
          11,
          7908,
          7908,
          13,
          51242
        ]
      },
      {
        "avg_logprob": -0.2591020672820335,
        "compression_ratio": 1.794701986754967,
        "end": 2145.2000000000003,
        "id": 757,
        "no_speech_prob": 0.0007554047042503953,
        "seek": 212476,
        "start": 2142.32,
        "temperature": 0,
        "text": " An and operation would only ever give me true",
        "tokens": [
          51242,
          1107,
          293,
          6916,
          576,
          787,
          1562,
          976,
          385,
          2074,
          51386
        ]
      },
      {
        "avg_logprob": -0.2591020672820335,
        "compression_ratio": 1.794701986754967,
        "end": 2148.5200000000004,
        "id": 758,
        "no_speech_prob": 0.0007554047042503953,
        "seek": 212476,
        "start": 2145.2000000000003,
        "temperature": 0,
        "text": " when both are true, false, false, false.",
        "tokens": [
          51386,
          562,
          1293,
          366,
          2074,
          11,
          7908,
          11,
          7908,
          11,
          7908,
          13,
          51552
        ]
      },
      {
        "avg_logprob": -0.2591020672820335,
        "compression_ratio": 1.794701986754967,
        "end": 2153,
        "id": 759,
        "no_speech_prob": 0.0007554047042503953,
        "seek": 212476,
        "start": 2148.5200000000004,
        "temperature": 0,
        "text": " An or operation would only ever give me,",
        "tokens": [
          51552,
          1107,
          420,
          6916,
          576,
          787,
          1562,
          976,
          385,
          11,
          51776
        ]
      },
      {
        "avg_logprob": -0.2129037875940304,
        "compression_ratio": 1.6120218579234973,
        "end": 2155.6,
        "id": 760,
        "no_speech_prob": 0.00005144216265762225,
        "seek": 215300,
        "start": 2153,
        "temperature": 0,
        "text": " would give me true if just one of them is true.",
        "tokens": [
          50364,
          576,
          976,
          385,
          2074,
          498,
          445,
          472,
          295,
          552,
          307,
          2074,
          13,
          50494
        ]
      },
      {
        "avg_logprob": -0.2129037875940304,
        "compression_ratio": 1.6120218579234973,
        "end": 2162.96,
        "id": 761,
        "no_speech_prob": 0.00005144216265762225,
        "seek": 215300,
        "start": 2159.84,
        "temperature": 0,
        "text": " True, true, true, false.",
        "tokens": [
          50706,
          13587,
          11,
          2074,
          11,
          2074,
          11,
          7908,
          13,
          50862
        ]
      },
      {
        "avg_logprob": -0.2129037875940304,
        "compression_ratio": 1.6120218579234973,
        "end": 2163.8,
        "id": 762,
        "no_speech_prob": 0.00005144216265762225,
        "seek": 215300,
        "start": 2162.96,
        "temperature": 0,
        "text": " Can you even see that?",
        "tokens": [
          50862,
          1664,
          291,
          754,
          536,
          300,
          30,
          50904
        ]
      },
      {
        "avg_logprob": -0.2129037875940304,
        "compression_ratio": 1.6120218579234973,
        "end": 2165.68,
        "id": 763,
        "no_speech_prob": 0.00005144216265762225,
        "seek": 215300,
        "start": 2163.8,
        "temperature": 0,
        "text": " I can't see on my monitor, but hopefully you can.",
        "tokens": [
          50904,
          286,
          393,
          380,
          536,
          322,
          452,
          6002,
          11,
          457,
          4696,
          291,
          393,
          13,
          50998
        ]
      },
      {
        "avg_logprob": -0.2129037875940304,
        "compression_ratio": 1.6120218579234973,
        "end": 2169.08,
        "id": 764,
        "no_speech_prob": 0.00005144216265762225,
        "seek": 215300,
        "start": 2165.68,
        "temperature": 0,
        "text": " Now, XOR, the X for exclusive,",
        "tokens": [
          50998,
          823,
          11,
          1783,
          2483,
          11,
          264,
          1783,
          337,
          13005,
          11,
          51168
        ]
      },
      {
        "avg_logprob": -0.2129037875940304,
        "compression_ratio": 1.6120218579234973,
        "end": 2173.08,
        "id": 765,
        "no_speech_prob": 0.00005144216265762225,
        "seek": 215300,
        "start": 2169.96,
        "temperature": 0,
        "text": " gives me true only if one is true.",
        "tokens": [
          51212,
          2709,
          385,
          2074,
          787,
          498,
          472,
          307,
          2074,
          13,
          51368
        ]
      },
      {
        "avg_logprob": -0.2129037875940304,
        "compression_ratio": 1.6120218579234973,
        "end": 2174.76,
        "id": 766,
        "no_speech_prob": 0.00005144216265762225,
        "seek": 215300,
        "start": 2173.08,
        "temperature": 0,
        "text": " They can't both be true, only one.",
        "tokens": [
          51368,
          814,
          393,
          380,
          1293,
          312,
          2074,
          11,
          787,
          472,
          13,
          51452
        ]
      },
      {
        "avg_logprob": -0.2129037875940304,
        "compression_ratio": 1.6120218579234973,
        "end": 2179.76,
        "id": 767,
        "no_speech_prob": 0.00005144216265762225,
        "seek": 215300,
        "start": 2174.76,
        "temperature": 0,
        "text": " So in that case, I get false, true, true, false.",
        "tokens": [
          51452,
          407,
          294,
          300,
          1389,
          11,
          286,
          483,
          7908,
          11,
          2074,
          11,
          2074,
          11,
          7908,
          13,
          51702
        ]
      },
      {
        "avg_logprob": -0.20570020114674287,
        "compression_ratio": 1.9476439790575917,
        "end": 2183.8,
        "id": 768,
        "no_speech_prob": 0.00003219223071937449,
        "seek": 217976,
        "start": 2179.96,
        "temperature": 0,
        "text": " And the idea of linearly separable comes up here",
        "tokens": [
          50374,
          400,
          264,
          1558,
          295,
          43586,
          3128,
          712,
          1487,
          493,
          510,
          50566
        ]
      },
      {
        "avg_logprob": -0.20570020114674287,
        "compression_ratio": 1.9476439790575917,
        "end": 2187.2000000000003,
        "id": 769,
        "no_speech_prob": 0.00003219223071937449,
        "seek": 217976,
        "start": 2183.8,
        "temperature": 0,
        "text": " because I can draw a line here to separate true from false.",
        "tokens": [
          50566,
          570,
          286,
          393,
          2642,
          257,
          1622,
          510,
          281,
          4994,
          2074,
          490,
          7908,
          13,
          50736
        ]
      },
      {
        "avg_logprob": -0.20570020114674287,
        "compression_ratio": 1.9476439790575917,
        "end": 2189.8,
        "id": 770,
        "no_speech_prob": 0.00003219223071937449,
        "seek": 217976,
        "start": 2187.2000000000003,
        "temperature": 0,
        "text": " I can draw a line here to separate true from false.",
        "tokens": [
          50736,
          286,
          393,
          2642,
          257,
          1622,
          510,
          281,
          4994,
          2074,
          490,
          7908,
          13,
          50866
        ]
      },
      {
        "avg_logprob": -0.20570020114674287,
        "compression_ratio": 1.9476439790575917,
        "end": 2193.6400000000003,
        "id": 771,
        "no_speech_prob": 0.00003219223071937449,
        "seek": 217976,
        "start": 2189.8,
        "temperature": 0,
        "text": " But here, I can't draw a line, I could do this.",
        "tokens": [
          50866,
          583,
          510,
          11,
          286,
          393,
          380,
          2642,
          257,
          1622,
          11,
          286,
          727,
          360,
          341,
          13,
          51058
        ]
      },
      {
        "avg_logprob": -0.20570020114674287,
        "compression_ratio": 1.9476439790575917,
        "end": 2198.0400000000004,
        "id": 772,
        "no_speech_prob": 0.00003219223071937449,
        "seek": 217976,
        "start": 2195.1200000000003,
        "temperature": 0,
        "text": " But I can't draw a single line to separate true from false.",
        "tokens": [
          51132,
          583,
          286,
          393,
          380,
          2642,
          257,
          2167,
          1622,
          281,
          4994,
          2074,
          490,
          7908,
          13,
          51278
        ]
      },
      {
        "avg_logprob": -0.20570020114674287,
        "compression_ratio": 1.9476439790575917,
        "end": 2202.36,
        "id": 773,
        "no_speech_prob": 0.00003219223071937449,
        "seek": 217976,
        "start": 2198.0400000000004,
        "temperature": 0,
        "text": " We need a more sophisticated model with a hidden layer.",
        "tokens": [
          51278,
          492,
          643,
          257,
          544,
          16950,
          2316,
          365,
          257,
          7633,
          4583,
          13,
          51494
        ]
      },
      {
        "avg_logprob": -0.20570020114674287,
        "compression_ratio": 1.9476439790575917,
        "end": 2205.76,
        "id": 774,
        "no_speech_prob": 0.00003219223071937449,
        "seek": 217976,
        "start": 2202.36,
        "temperature": 0,
        "text": " So the inputs are things like a one and a zero.",
        "tokens": [
          51494,
          407,
          264,
          15743,
          366,
          721,
          411,
          257,
          472,
          293,
          257,
          4018,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.280819574991862,
        "compression_ratio": 1.6523178807947019,
        "end": 2213.44,
        "id": 775,
        "no_speech_prob": 0.00004264738890924491,
        "seek": 220976,
        "start": 2210.2400000000002,
        "temperature": 0,
        "text": " Feed forward into the hidden layer, activate,",
        "tokens": [
          50388,
          33720,
          2128,
          666,
          264,
          7633,
          4583,
          11,
          13615,
          11,
          50548
        ]
      },
      {
        "avg_logprob": -0.280819574991862,
        "compression_ratio": 1.6523178807947019,
        "end": 2217.6400000000003,
        "id": 776,
        "no_speech_prob": 0.00004264738890924491,
        "seek": 220976,
        "start": 2213.44,
        "temperature": 0,
        "text": " feed to the output, and the output should be a zero or a one.",
        "tokens": [
          50548,
          3154,
          281,
          264,
          5598,
          11,
          293,
          264,
          5598,
          820,
          312,
          257,
          4018,
          420,
          257,
          472,
          13,
          50758
        ]
      },
      {
        "avg_logprob": -0.280819574991862,
        "compression_ratio": 1.6523178807947019,
        "end": 2220.2000000000003,
        "id": 777,
        "no_speech_prob": 0.00004264738890924491,
        "seek": 220976,
        "start": 2217.6400000000003,
        "temperature": 0,
        "text": " It's really, in some ways, a classification problem,",
        "tokens": [
          50758,
          467,
          311,
          534,
          11,
          294,
          512,
          2098,
          11,
          257,
          21538,
          1154,
          11,
          50886
        ]
      },
      {
        "avg_logprob": -0.280819574991862,
        "compression_ratio": 1.6523178807947019,
        "end": 2222.6800000000003,
        "id": 778,
        "no_speech_prob": 0.00004264738890924491,
        "seek": 220976,
        "start": 2220.2000000000003,
        "temperature": 0,
        "text": " but I'm going to do this as a regression, essentially,",
        "tokens": [
          50886,
          457,
          286,
          478,
          516,
          281,
          360,
          341,
          382,
          257,
          24590,
          11,
          4476,
          11,
          51010
        ]
      },
      {
        "avg_logprob": -0.280819574991862,
        "compression_ratio": 1.6523178807947019,
        "end": 2225.0400000000004,
        "id": 779,
        "no_speech_prob": 0.00004264738890924491,
        "seek": 220976,
        "start": 2222.6800000000003,
        "temperature": 0,
        "text": " where I'm just going to get some number between zero and one.",
        "tokens": [
          51010,
          689,
          286,
          478,
          445,
          516,
          281,
          483,
          512,
          1230,
          1296,
          4018,
          293,
          472,
          13,
          51128
        ]
      },
      {
        "avg_logprob": -0.280819574991862,
        "compression_ratio": 1.6523178807947019,
        "end": 2226.76,
        "id": 780,
        "no_speech_prob": 0.00004264738890924491,
        "seek": 220976,
        "start": 2225.0400000000004,
        "temperature": 0,
        "text": " If you watched the previous coding challenge,",
        "tokens": [
          51128,
          759,
          291,
          6337,
          264,
          3894,
          17720,
          3430,
          11,
          51214
        ]
      },
      {
        "avg_logprob": -0.280819574991862,
        "compression_ratio": 1.6523178807947019,
        "end": 2228.8,
        "id": 781,
        "no_speech_prob": 0.00004264738890924491,
        "seek": 220976,
        "start": 2226.76,
        "temperature": 0,
        "text": " the reason why that is is because...",
        "tokens": [
          51214,
          264,
          1778,
          983,
          300,
          307,
          307,
          570,
          485,
          51316
        ]
      },
      {
        "avg_logprob": -0.280819574991862,
        "compression_ratio": 1.6523178807947019,
        "end": 2231.76,
        "id": 782,
        "no_speech_prob": 0.00004264738890924491,
        "seek": 220976,
        "start": 2228.8,
        "temperature": 0,
        "text": " Oh, thank you very much, good night.",
        "tokens": [
          51316,
          220,
          3756,
          11,
          1309,
          291,
          588,
          709,
          11,
          665,
          1818,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.280819574991862,
        "compression_ratio": 1.6523178807947019,
        "end": 2232.92,
        "id": 783,
        "no_speech_prob": 0.00004264738890924491,
        "seek": 220976,
        "start": 2231.76,
        "temperature": 0,
        "text": " This video is now over.",
        "tokens": [
          51464,
          639,
          960,
          307,
          586,
          670,
          13,
          51522
        ]
      },
      {
        "avg_logprob": -0.280819574991862,
        "compression_ratio": 1.6523178807947019,
        "end": 2236.8,
        "id": 784,
        "no_speech_prob": 0.00004264738890924491,
        "seek": 220976,
        "start": 2234.28,
        "temperature": 0,
        "text": " I hit my sound effect by accident.",
        "tokens": [
          51590,
          286,
          2045,
          452,
          1626,
          1802,
          538,
          6398,
          13,
          51716
        ]
      },
      {
        "avg_logprob": -0.280819574991862,
        "compression_ratio": 1.6523178807947019,
        "end": 2239.42,
        "id": 785,
        "no_speech_prob": 0.00004264738890924491,
        "seek": 220976,
        "start": 2236.8,
        "temperature": 0,
        "text": " Because what I'm trying to do is visualize",
        "tokens": [
          51716,
          1436,
          437,
          286,
          478,
          1382,
          281,
          360,
          307,
          23273,
          51847
        ]
      },
      {
        "avg_logprob": -0.44112688302993774,
        "compression_ratio": 1.1688311688311688,
        "end": 2241.6,
        "id": 786,
        "no_speech_prob": 0.00004908533810521476,
        "seek": 223942,
        "start": 2240.08,
        "temperature": 0,
        "text": " the true-false space.",
        "tokens": [
          50397,
          264,
          2074,
          12,
          36474,
          405,
          1901,
          13,
          50473
        ]
      },
      {
        "avg_logprob": -0.44112688302993774,
        "compression_ratio": 1.1688311688311688,
        "end": 2246.6,
        "id": 787,
        "no_speech_prob": 0.00004908533810521476,
        "seek": 223942,
        "start": 2243.58,
        "temperature": 0,
        "text": " All right, pause for a second.",
        "tokens": [
          50572,
          1057,
          558,
          11,
          10465,
          337,
          257,
          1150,
          13,
          50723
        ]
      },
      {
        "avg_logprob": -0.44112688302993774,
        "compression_ratio": 1.1688311688311688,
        "end": 2256.36,
        "id": 788,
        "no_speech_prob": 0.00004908533810521476,
        "seek": 223942,
        "start": 2254.46,
        "temperature": 0,
        "text": " I'm just taking a pause for a second.",
        "tokens": [
          51116,
          286,
          478,
          445,
          1940,
          257,
          10465,
          337,
          257,
          1150,
          13,
          51211
        ]
      },
      {
        "avg_logprob": -0.264961914582686,
        "compression_ratio": 1.4712041884816753,
        "end": 2271.26,
        "id": 789,
        "no_speech_prob": 0.00013551965821534395,
        "seek": 226942,
        "start": 2270.42,
        "temperature": 0,
        "text": " How long was that?",
        "tokens": [
          50414,
          1012,
          938,
          390,
          300,
          30,
          50456
        ]
      },
      {
        "avg_logprob": -0.264961914582686,
        "compression_ratio": 1.4712041884816753,
        "end": 2273.62,
        "id": 790,
        "no_speech_prob": 0.00013551965821534395,
        "seek": 226942,
        "start": 2271.26,
        "temperature": 0,
        "text": " It was like 10 minutes at least, right?",
        "tokens": [
          50456,
          467,
          390,
          411,
          1266,
          2077,
          412,
          1935,
          11,
          558,
          30,
          50574
        ]
      },
      {
        "avg_logprob": -0.264961914582686,
        "compression_ratio": 1.4712041884816753,
        "end": 2275.26,
        "id": 791,
        "no_speech_prob": 0.00013551965821534395,
        "seek": 226942,
        "start": 2273.62,
        "temperature": 0,
        "text": " But it's important.",
        "tokens": [
          50574,
          583,
          309,
          311,
          1021,
          13,
          50656
        ]
      },
      {
        "avg_logprob": -0.264961914582686,
        "compression_ratio": 1.4712041884816753,
        "end": 2277.96,
        "id": 792,
        "no_speech_prob": 0.00013551965821534395,
        "seek": 226942,
        "start": 2275.26,
        "temperature": 0,
        "text": " It's important for me to talk about what I'm doing.",
        "tokens": [
          50656,
          467,
          311,
          1021,
          337,
          385,
          281,
          751,
          466,
          437,
          286,
          478,
          884,
          13,
          50791
        ]
      },
      {
        "avg_logprob": -0.264961914582686,
        "compression_ratio": 1.4712041884816753,
        "end": 2280.9,
        "id": 793,
        "no_speech_prob": 0.00013551965821534395,
        "seek": 226942,
        "start": 2280.06,
        "temperature": 0,
        "text": " All right.",
        "tokens": [
          50896,
          1057,
          558,
          13,
          50938
        ]
      },
      {
        "avg_logprob": -0.264961914582686,
        "compression_ratio": 1.4712041884816753,
        "end": 2289.94,
        "id": 794,
        "no_speech_prob": 0.00013551965821534395,
        "seek": 226942,
        "start": 2285.26,
        "temperature": 0,
        "text": " So I'm just thinking here, where am I going next?",
        "tokens": [
          51156,
          407,
          286,
          478,
          445,
          1953,
          510,
          11,
          689,
          669,
          286,
          516,
          958,
          30,
          51390
        ]
      },
      {
        "avg_logprob": -0.264961914582686,
        "compression_ratio": 1.4712041884816753,
        "end": 2293.26,
        "id": 795,
        "no_speech_prob": 0.00013551965821534395,
        "seek": 226942,
        "start": 2289.94,
        "temperature": 0,
        "text": " Looking at the chat, no one's complaining too terribly.",
        "tokens": [
          51390,
          11053,
          412,
          264,
          5081,
          11,
          572,
          472,
          311,
          20740,
          886,
          22903,
          13,
          51556
        ]
      },
      {
        "avg_logprob": -0.264961914582686,
        "compression_ratio": 1.4712041884816753,
        "end": 2294.9,
        "id": 796,
        "no_speech_prob": 0.00013551965821534395,
        "seek": 226942,
        "start": 2293.26,
        "temperature": 0,
        "text": " And I think I'm going to move on.",
        "tokens": [
          51556,
          400,
          286,
          519,
          286,
          478,
          516,
          281,
          1286,
          322,
          13,
          51638
        ]
      },
      {
        "avg_logprob": -0.3245655197695077,
        "compression_ratio": 1.4240837696335078,
        "end": 2303.9,
        "id": 797,
        "no_speech_prob": 0.00000664339677314274,
        "seek": 229942,
        "start": 2300.26,
        "temperature": 0,
        "text": " I guess I could transition back over here,",
        "tokens": [
          50406,
          286,
          2041,
          286,
          727,
          6034,
          646,
          670,
          510,
          11,
          50588
        ]
      },
      {
        "avg_logprob": -0.3245655197695077,
        "compression_ratio": 1.4240837696335078,
        "end": 2305.14,
        "id": 798,
        "no_speech_prob": 0.00000664339677314274,
        "seek": 229942,
        "start": 2303.9,
        "temperature": 0,
        "text": " in case Matu, you want to edit out",
        "tokens": [
          50588,
          294,
          1389,
          6789,
          84,
          11,
          291,
          528,
          281,
          8129,
          484,
          50650
        ]
      },
      {
        "avg_logprob": -0.3245655197695077,
        "compression_ratio": 1.4240837696335078,
        "end": 2306.58,
        "id": 799,
        "no_speech_prob": 0.00000664339677314274,
        "seek": 229942,
        "start": 2305.14,
        "temperature": 0,
        "text": " the weird sound effect thing.",
        "tokens": [
          50650,
          264,
          3657,
          1626,
          1802,
          551,
          13,
          50722
        ]
      },
      {
        "avg_logprob": -0.3245655197695077,
        "compression_ratio": 1.4240837696335078,
        "end": 2318.1,
        "id": 800,
        "no_speech_prob": 0.00000664339677314274,
        "seek": 229942,
        "start": 2316.06,
        "temperature": 0,
        "text": " Oh, they're good sounding, okay, that's good.",
        "tokens": [
          51196,
          876,
          11,
          436,
          434,
          665,
          24931,
          11,
          1392,
          11,
          300,
          311,
          665,
          13,
          51298
        ]
      },
      {
        "avg_logprob": -0.3245655197695077,
        "compression_ratio": 1.4240837696335078,
        "end": 2322.84,
        "id": 801,
        "no_speech_prob": 0.00000664339677314274,
        "seek": 229942,
        "start": 2319.54,
        "temperature": 0,
        "text": " Hugo asks, will you ever do non-JavaScript videos?",
        "tokens": [
          51370,
          32504,
          8962,
          11,
          486,
          291,
          1562,
          360,
          2107,
          12,
          41,
          4061,
          14237,
          2145,
          30,
          51535
        ]
      },
      {
        "avg_logprob": -0.3245655197695077,
        "compression_ratio": 1.4240837696335078,
        "end": 2326.7000000000003,
        "id": 802,
        "no_speech_prob": 0.00000664339677314274,
        "seek": 229942,
        "start": 2322.84,
        "temperature": 0,
        "text": " Well, I do some processing in Java videos.",
        "tokens": [
          51535,
          1042,
          11,
          286,
          360,
          512,
          9007,
          294,
          10745,
          2145,
          13,
          51728
        ]
      },
      {
        "avg_logprob": -0.3245655197695077,
        "compression_ratio": 1.4240837696335078,
        "end": 2328.02,
        "id": 803,
        "no_speech_prob": 0.00000664339677314274,
        "seek": 229942,
        "start": 2326.7000000000003,
        "temperature": 0,
        "text": " Those aren't JavaScript.",
        "tokens": [
          51728,
          3950,
          3212,
          380,
          15778,
          13,
          51794
        ]
      },
      {
        "avg_logprob": -0.2933389138484347,
        "compression_ratio": 1.4876543209876543,
        "end": 2333.98,
        "id": 804,
        "no_speech_prob": 0.00000586280521019944,
        "seek": 232802,
        "start": 2328.98,
        "temperature": 0,
        "text": " But at this point, I'm kind of doing the JavaScript thing.",
        "tokens": [
          50412,
          583,
          412,
          341,
          935,
          11,
          286,
          478,
          733,
          295,
          884,
          264,
          15778,
          551,
          13,
          50662
        ]
      },
      {
        "avg_logprob": -0.2933389138484347,
        "compression_ratio": 1.4876543209876543,
        "end": 2344.86,
        "id": 805,
        "no_speech_prob": 0.00000586280521019944,
        "seek": 232802,
        "start": 2341.74,
        "temperature": 0,
        "text": " Okay, let me transition back, Matu.",
        "tokens": [
          51050,
          1033,
          11,
          718,
          385,
          6034,
          646,
          11,
          6789,
          84,
          13,
          51206
        ]
      },
      {
        "avg_logprob": -0.2933389138484347,
        "compression_ratio": 1.4876543209876543,
        "end": 2346.2599999999998,
        "id": 806,
        "no_speech_prob": 0.00000586280521019944,
        "seek": 232802,
        "start": 2344.86,
        "temperature": 0,
        "text": " Maybe the sound effect little thing",
        "tokens": [
          51206,
          2704,
          264,
          1626,
          1802,
          707,
          551,
          51276
        ]
      },
      {
        "avg_logprob": -0.2933389138484347,
        "compression_ratio": 1.4876543209876543,
        "end": 2347.94,
        "id": 807,
        "no_speech_prob": 0.00000586280521019944,
        "seek": 232802,
        "start": 2346.2599999999998,
        "temperature": 0,
        "text": " was a funny little bit.",
        "tokens": [
          51276,
          390,
          257,
          4074,
          707,
          857,
          13,
          51360
        ]
      },
      {
        "avg_logprob": -0.2933389138484347,
        "compression_ratio": 1.4876543209876543,
        "end": 2350.24,
        "id": 808,
        "no_speech_prob": 0.00000586280521019944,
        "seek": 232802,
        "start": 2347.94,
        "temperature": 0,
        "text": " But I think I'm going to just transition back.",
        "tokens": [
          51360,
          583,
          286,
          519,
          286,
          478,
          516,
          281,
          445,
          6034,
          646,
          13,
          51475
        ]
      },
      {
        "avg_logprob": -0.2933389138484347,
        "compression_ratio": 1.4876543209876543,
        "end": 2354.34,
        "id": 809,
        "no_speech_prob": 0.00000586280521019944,
        "seek": 232802,
        "start": 2352.3,
        "temperature": 0,
        "text": " Because ultimately what I'm going to do",
        "tokens": [
          51578,
          1436,
          6284,
          437,
          286,
          478,
          516,
          281,
          360,
          51680
        ]
      },
      {
        "avg_logprob": -0.25868417476785593,
        "compression_ratio": 1.8194444444444444,
        "end": 2358.94,
        "id": 810,
        "no_speech_prob": 0.00009461234003538266,
        "seek": 235434,
        "start": 2354.34,
        "temperature": 0,
        "text": " is visualize the output of the model.",
        "tokens": [
          50364,
          307,
          23273,
          264,
          5598,
          295,
          264,
          2316,
          13,
          50594
        ]
      },
      {
        "avg_logprob": -0.25868417476785593,
        "compression_ratio": 1.8194444444444444,
        "end": 2360.9,
        "id": 811,
        "no_speech_prob": 0.00009461234003538266,
        "seek": 235434,
        "start": 2358.94,
        "temperature": 0,
        "text": " And I'm going to send in numbers",
        "tokens": [
          50594,
          400,
          286,
          478,
          516,
          281,
          2845,
          294,
          3547,
          50692
        ]
      },
      {
        "avg_logprob": -0.25868417476785593,
        "compression_ratio": 1.8194444444444444,
        "end": 2362.98,
        "id": 812,
        "no_speech_prob": 0.00009461234003538266,
        "seek": 235434,
        "start": 2360.9,
        "temperature": 0,
        "text": " all the way between zero and one.",
        "tokens": [
          50692,
          439,
          264,
          636,
          1296,
          4018,
          293,
          472,
          13,
          50796
        ]
      },
      {
        "avg_logprob": -0.25868417476785593,
        "compression_ratio": 1.8194444444444444,
        "end": 2365.86,
        "id": 813,
        "no_speech_prob": 0.00009461234003538266,
        "seek": 235434,
        "start": 2364.3,
        "temperature": 0,
        "text": " I don't even know what I'm saying.",
        "tokens": [
          50862,
          286,
          500,
          380,
          754,
          458,
          437,
          286,
          478,
          1566,
          13,
          50940
        ]
      },
      {
        "avg_logprob": -0.25868417476785593,
        "compression_ratio": 1.8194444444444444,
        "end": 2369.1000000000004,
        "id": 814,
        "no_speech_prob": 0.00009461234003538266,
        "seek": 235434,
        "start": 2368.26,
        "temperature": 0,
        "text": " It's fine.",
        "tokens": [
          51060,
          467,
          311,
          2489,
          13,
          51102
        ]
      },
      {
        "avg_logprob": -0.25868417476785593,
        "compression_ratio": 1.8194444444444444,
        "end": 2374.34,
        "id": 815,
        "no_speech_prob": 0.00009461234003538266,
        "seek": 235434,
        "start": 2372.42,
        "temperature": 0,
        "text": " Because ultimately I'm going to visualize the output",
        "tokens": [
          51268,
          1436,
          6284,
          286,
          478,
          516,
          281,
          23273,
          264,
          5598,
          51364
        ]
      },
      {
        "avg_logprob": -0.25868417476785593,
        "compression_ratio": 1.8194444444444444,
        "end": 2375.42,
        "id": 816,
        "no_speech_prob": 0.00009461234003538266,
        "seek": 235434,
        "start": 2374.34,
        "temperature": 0,
        "text": " as grayscale values.",
        "tokens": [
          51364,
          382,
          677,
          3772,
          37088,
          4190,
          13,
          51418
        ]
      },
      {
        "avg_logprob": -0.25868417476785593,
        "compression_ratio": 1.8194444444444444,
        "end": 2377.42,
        "id": 817,
        "no_speech_prob": 0.00009461234003538266,
        "seek": 235434,
        "start": 2375.42,
        "temperature": 0,
        "text": " And I want to see grayscale values",
        "tokens": [
          51418,
          400,
          286,
          528,
          281,
          536,
          677,
          3772,
          37088,
          4190,
          51518
        ]
      },
      {
        "avg_logprob": -0.25868417476785593,
        "compression_ratio": 1.8194444444444444,
        "end": 2378.78,
        "id": 818,
        "no_speech_prob": 0.00009461234003538266,
        "seek": 235434,
        "start": 2377.42,
        "temperature": 0,
        "text": " all the way between zero and one.",
        "tokens": [
          51518,
          439,
          264,
          636,
          1296,
          4018,
          293,
          472,
          13,
          51586
        ]
      },
      {
        "avg_logprob": -0.25868417476785593,
        "compression_ratio": 1.8194444444444444,
        "end": 2380.58,
        "id": 819,
        "no_speech_prob": 0.00009461234003538266,
        "seek": 235434,
        "start": 2378.78,
        "temperature": 0,
        "text": " It's the same thing I did in the previous coding challenge,",
        "tokens": [
          51586,
          467,
          311,
          264,
          912,
          551,
          286,
          630,
          294,
          264,
          3894,
          17720,
          3430,
          11,
          51676
        ]
      },
      {
        "avg_logprob": -0.25868417476785593,
        "compression_ratio": 1.8194444444444444,
        "end": 2383.1400000000003,
        "id": 820,
        "no_speech_prob": 0.00009461234003538266,
        "seek": 235434,
        "start": 2380.58,
        "temperature": 0,
        "text": " if you happen to have watched that one.",
        "tokens": [
          51676,
          498,
          291,
          1051,
          281,
          362,
          6337,
          300,
          472,
          13,
          51804
        ]
      },
      {
        "avg_logprob": -0.231254791046356,
        "compression_ratio": 1.8045977011494252,
        "end": 2384.62,
        "id": 821,
        "no_speech_prob": 0.000004356870249466738,
        "seek": 238314,
        "start": 2383.14,
        "temperature": 0,
        "text": " All right, so now I actually,",
        "tokens": [
          50364,
          1057,
          558,
          11,
          370,
          586,
          286,
          767,
          11,
          50438
        ]
      },
      {
        "avg_logprob": -0.231254791046356,
        "compression_ratio": 1.8045977011494252,
        "end": 2388.72,
        "id": 822,
        "no_speech_prob": 0.000004356870249466738,
        "seek": 238314,
        "start": 2384.62,
        "temperature": 0,
        "text": " I'm going to also do something where I start from the code,",
        "tokens": [
          50438,
          286,
          478,
          516,
          281,
          611,
          360,
          746,
          689,
          286,
          722,
          490,
          264,
          3089,
          11,
          50643
        ]
      },
      {
        "avg_logprob": -0.231254791046356,
        "compression_ratio": 1.8045977011494252,
        "end": 2390.94,
        "id": 823,
        "no_speech_prob": 0.000004356870249466738,
        "seek": 238314,
        "start": 2388.72,
        "temperature": 0,
        "text": " from the previous coding challenge.",
        "tokens": [
          50643,
          490,
          264,
          3894,
          17720,
          3430,
          13,
          50754
        ]
      },
      {
        "avg_logprob": -0.231254791046356,
        "compression_ratio": 1.8045977011494252,
        "end": 2394.5,
        "id": 824,
        "no_speech_prob": 0.000004356870249466738,
        "seek": 238314,
        "start": 2390.94,
        "temperature": 0,
        "text": " And so we can see there's this idea of training data.",
        "tokens": [
          50754,
          400,
          370,
          321,
          393,
          536,
          456,
          311,
          341,
          1558,
          295,
          3097,
          1412,
          13,
          50932
        ]
      },
      {
        "avg_logprob": -0.231254791046356,
        "compression_ratio": 1.8045977011494252,
        "end": 2399.1,
        "id": 825,
        "no_speech_prob": 0.000004356870249466738,
        "seek": 238314,
        "start": 2394.5,
        "temperature": 0,
        "text": " The inputs to the XOR problem are zero, zero gives me a zero.",
        "tokens": [
          50932,
          440,
          15743,
          281,
          264,
          1783,
          2483,
          1154,
          366,
          4018,
          11,
          4018,
          2709,
          385,
          257,
          4018,
          13,
          51162
        ]
      },
      {
        "avg_logprob": -0.231254791046356,
        "compression_ratio": 1.8045977011494252,
        "end": 2400.74,
        "id": 826,
        "no_speech_prob": 0.000004356870249466738,
        "seek": 238314,
        "start": 2399.1,
        "temperature": 0,
        "text": " Zero, one gives me a one.",
        "tokens": [
          51162,
          17182,
          11,
          472,
          2709,
          385,
          257,
          472,
          13,
          51244
        ]
      },
      {
        "avg_logprob": -0.231254791046356,
        "compression_ratio": 1.8045977011494252,
        "end": 2401.7,
        "id": 827,
        "no_speech_prob": 0.000004356870249466738,
        "seek": 238314,
        "start": 2400.74,
        "temperature": 0,
        "text": " One, zero gives me a one.",
        "tokens": [
          51244,
          1485,
          11,
          4018,
          2709,
          385,
          257,
          472,
          13,
          51292
        ]
      },
      {
        "avg_logprob": -0.231254791046356,
        "compression_ratio": 1.8045977011494252,
        "end": 2402.74,
        "id": 828,
        "no_speech_prob": 0.000004356870249466738,
        "seek": 238314,
        "start": 2401.7,
        "temperature": 0,
        "text": " And one, one gives me a zero.",
        "tokens": [
          51292,
          400,
          472,
          11,
          472,
          2709,
          385,
          257,
          4018,
          13,
          51344
        ]
      },
      {
        "avg_logprob": -0.231254791046356,
        "compression_ratio": 1.8045977011494252,
        "end": 2404.18,
        "id": 829,
        "no_speech_prob": 0.000004356870249466738,
        "seek": 238314,
        "start": 2402.74,
        "temperature": 0,
        "text": " This is the training data.",
        "tokens": [
          51344,
          639,
          307,
          264,
          3097,
          1412,
          13,
          51416
        ]
      },
      {
        "avg_logprob": -0.231254791046356,
        "compression_ratio": 1.8045977011494252,
        "end": 2407.06,
        "id": 830,
        "no_speech_prob": 0.000004356870249466738,
        "seek": 238314,
        "start": 2404.18,
        "temperature": 0,
        "text": " And in my previous version of this,",
        "tokens": [
          51416,
          400,
          294,
          452,
          3894,
          3037,
          295,
          341,
          11,
          51560
        ]
      },
      {
        "avg_logprob": -0.231254791046356,
        "compression_ratio": 1.8045977011494252,
        "end": 2409.3599999999997,
        "id": 831,
        "no_speech_prob": 0.000004356870249466738,
        "seek": 238314,
        "start": 2407.06,
        "temperature": 0,
        "text": " I used my own neural network library.",
        "tokens": [
          51560,
          286,
          1143,
          452,
          1065,
          18161,
          3209,
          6405,
          13,
          51675
        ]
      },
      {
        "avg_logprob": -0.231254791046356,
        "compression_ratio": 1.8045977011494252,
        "end": 2410.94,
        "id": 832,
        "no_speech_prob": 0.000004356870249466738,
        "seek": 238314,
        "start": 2409.3599999999997,
        "temperature": 0,
        "text": " So in theory, I'm going to get rid of the idea",
        "tokens": [
          51675,
          407,
          294,
          5261,
          11,
          286,
          478,
          516,
          281,
          483,
          3973,
          295,
          264,
          1558,
          51754
        ]
      },
      {
        "avg_logprob": -0.25696428005511945,
        "compression_ratio": 1.6431924882629108,
        "end": 2413.06,
        "id": 833,
        "no_speech_prob": 0.0073457760736346245,
        "seek": 241094,
        "start": 2410.94,
        "temperature": 0,
        "text": " of a learning rate slider, just for,",
        "tokens": [
          50364,
          295,
          257,
          2539,
          3314,
          26046,
          11,
          445,
          337,
          11,
          50470
        ]
      },
      {
        "avg_logprob": -0.25696428005511945,
        "compression_ratio": 1.6431924882629108,
        "end": 2414.82,
        "id": 834,
        "no_speech_prob": 0.0073457760736346245,
        "seek": 241094,
        "start": 2413.06,
        "temperature": 0,
        "text": " we can add that back in later.",
        "tokens": [
          50470,
          321,
          393,
          909,
          300,
          646,
          294,
          1780,
          13,
          50558
        ]
      },
      {
        "avg_logprob": -0.25696428005511945,
        "compression_ratio": 1.6431924882629108,
        "end": 2419.58,
        "id": 835,
        "no_speech_prob": 0.0073457760736346245,
        "seek": 241094,
        "start": 2416.14,
        "temperature": 0,
        "text": " But let me get rid of the learning rate slider.",
        "tokens": [
          50624,
          583,
          718,
          385,
          483,
          3973,
          295,
          264,
          2539,
          3314,
          26046,
          13,
          50796
        ]
      },
      {
        "avg_logprob": -0.25696428005511945,
        "compression_ratio": 1.6431924882629108,
        "end": 2424.06,
        "id": 836,
        "no_speech_prob": 0.0073457760736346245,
        "seek": 241094,
        "start": 2419.58,
        "temperature": 0,
        "text": " Basically, I want to do exactly the same thing.",
        "tokens": [
          50796,
          8537,
          11,
          286,
          528,
          281,
          360,
          2293,
          264,
          912,
          551,
          13,
          51020
        ]
      },
      {
        "avg_logprob": -0.25696428005511945,
        "compression_ratio": 1.6431924882629108,
        "end": 2425.34,
        "id": 837,
        "no_speech_prob": 0.0073457760736346245,
        "seek": 241094,
        "start": 2424.06,
        "temperature": 0,
        "text": " The difference is I'm going to say",
        "tokens": [
          51020,
          440,
          2649,
          307,
          286,
          478,
          516,
          281,
          584,
          51084
        ]
      },
      {
        "avg_logprob": -0.25696428005511945,
        "compression_ratio": 1.6431924882629108,
        "end": 2430.34,
        "id": 838,
        "no_speech_prob": 0.0073457760736346245,
        "seek": 241094,
        "start": 2425.34,
        "temperature": 0,
        "text": " neural network equals tf.layers.sequential.",
        "tokens": [
          51084,
          18161,
          3209,
          6915,
          256,
          69,
          13,
          8376,
          433,
          13,
          11834,
          2549,
          13,
          51334
        ]
      },
      {
        "avg_logprob": -0.25696428005511945,
        "compression_ratio": 1.6431924882629108,
        "end": 2435.14,
        "id": 839,
        "no_speech_prob": 0.0073457760736346245,
        "seek": 241094,
        "start": 2431.9,
        "temperature": 0,
        "text": " And maybe I'll call this the model",
        "tokens": [
          51412,
          400,
          1310,
          286,
          603,
          818,
          341,
          264,
          2316,
          51574
        ]
      },
      {
        "avg_logprob": -0.25696428005511945,
        "compression_ratio": 1.6431924882629108,
        "end": 2436.46,
        "id": 840,
        "no_speech_prob": 0.0073457760736346245,
        "seek": 241094,
        "start": 2435.14,
        "temperature": 0,
        "text": " instead of neural network.",
        "tokens": [
          51574,
          2602,
          295,
          18161,
          3209,
          13,
          51640
        ]
      },
      {
        "avg_logprob": -0.25696428005511945,
        "compression_ratio": 1.6431924882629108,
        "end": 2438.06,
        "id": 841,
        "no_speech_prob": 0.0073457760736346245,
        "seek": 241094,
        "start": 2436.46,
        "temperature": 0,
        "text": " So the idea, oh, this is neural network here.",
        "tokens": [
          51640,
          407,
          264,
          1558,
          11,
          1954,
          11,
          341,
          307,
          18161,
          3209,
          510,
          13,
          51720
        ]
      },
      {
        "avg_logprob": -0.26728098209087664,
        "compression_ratio": 1.6363636363636365,
        "end": 2440.54,
        "id": 842,
        "no_speech_prob": 0.000011125598575745244,
        "seek": 243806,
        "start": 2438.06,
        "temperature": 0,
        "text": " So the idea here is that I want to",
        "tokens": [
          50364,
          407,
          264,
          1558,
          510,
          307,
          300,
          286,
          528,
          281,
          50488
        ]
      },
      {
        "avg_logprob": -0.26728098209087664,
        "compression_ratio": 1.6363636363636365,
        "end": 2448.38,
        "id": 843,
        "no_speech_prob": 0.000011125598575745244,
        "seek": 243806,
        "start": 2443.38,
        "temperature": 0,
        "text": " replace my neural network library with TensorFlow.js.",
        "tokens": [
          50630,
          7406,
          452,
          18161,
          3209,
          6405,
          365,
          37624,
          13,
          25530,
          13,
          50880
        ]
      },
      {
        "avg_logprob": -0.26728098209087664,
        "compression_ratio": 1.6363636363636365,
        "end": 2453.16,
        "id": 844,
        "no_speech_prob": 0.000011125598575745244,
        "seek": 243806,
        "start": 2449.9,
        "temperature": 0,
        "text": " And so this, for me, what the usefulness of this video",
        "tokens": [
          50956,
          400,
          370,
          341,
          11,
          337,
          385,
          11,
          437,
          264,
          4420,
          1287,
          295,
          341,
          960,
          51119
        ]
      },
      {
        "avg_logprob": -0.26728098209087664,
        "compression_ratio": 1.6363636363636365,
        "end": 2455.18,
        "id": 845,
        "no_speech_prob": 0.000011125598575745244,
        "seek": 243806,
        "start": 2453.16,
        "temperature": 0,
        "text": " is of me learning, I spent all this time",
        "tokens": [
          51119,
          307,
          295,
          385,
          2539,
          11,
          286,
          4418,
          439,
          341,
          565,
          51220
        ]
      },
      {
        "avg_logprob": -0.26728098209087664,
        "compression_ratio": 1.6363636363636365,
        "end": 2457.7799999999997,
        "id": 846,
        "no_speech_prob": 0.000011125598575745244,
        "seek": 243806,
        "start": 2455.18,
        "temperature": 0,
        "text": " trying to build my own rather sort of terrible",
        "tokens": [
          51220,
          1382,
          281,
          1322,
          452,
          1065,
          2831,
          1333,
          295,
          6237,
          51350
        ]
      },
      {
        "avg_logprob": -0.26728098209087664,
        "compression_ratio": 1.6363636363636365,
        "end": 2459.54,
        "id": 847,
        "no_speech_prob": 0.000011125598575745244,
        "seek": 243806,
        "start": 2457.7799999999997,
        "temperature": 0,
        "text": " neural network JavaScript library.",
        "tokens": [
          51350,
          18161,
          3209,
          15778,
          6405,
          13,
          51438
        ]
      },
      {
        "avg_logprob": -0.26728098209087664,
        "compression_ratio": 1.6363636363636365,
        "end": 2461.5,
        "id": 848,
        "no_speech_prob": 0.000011125598575745244,
        "seek": 243806,
        "start": 2459.54,
        "temperature": 0,
        "text": " And going through that was sort of helpful",
        "tokens": [
          51438,
          400,
          516,
          807,
          300,
          390,
          1333,
          295,
          4961,
          51536
        ]
      },
      {
        "avg_logprob": -0.26728098209087664,
        "compression_ratio": 1.6363636363636365,
        "end": 2463.22,
        "id": 849,
        "no_speech_prob": 0.000011125598575745244,
        "seek": 243806,
        "start": 2461.5,
        "temperature": 0,
        "text": " in thinking about how the stuff works.",
        "tokens": [
          51536,
          294,
          1953,
          466,
          577,
          264,
          1507,
          1985,
          13,
          51622
        ]
      },
      {
        "avg_logprob": -0.26728098209087664,
        "compression_ratio": 1.6363636363636365,
        "end": 2466.2999999999997,
        "id": 850,
        "no_speech_prob": 0.000011125598575745244,
        "seek": 243806,
        "start": 2463.22,
        "temperature": 0,
        "text": " Now if I can translate that into TensorFlow.js,",
        "tokens": [
          51622,
          823,
          498,
          286,
          393,
          13799,
          300,
          666,
          37624,
          13,
          25530,
          11,
          51776
        ]
      },
      {
        "avg_logprob": -0.2587221767125505,
        "compression_ratio": 1.5532994923857868,
        "end": 2468.54,
        "id": 851,
        "no_speech_prob": 0.0000015779609157107188,
        "seek": 246630,
        "start": 2467.1400000000003,
        "temperature": 0,
        "text": " things are going to hopefully start to sell",
        "tokens": [
          50406,
          721,
          366,
          516,
          281,
          4696,
          722,
          281,
          3607,
          50476
        ]
      },
      {
        "avg_logprob": -0.2587221767125505,
        "compression_ratio": 1.5532994923857868,
        "end": 2470.2400000000002,
        "id": 852,
        "no_speech_prob": 0.0000015779609157107188,
        "seek": 246630,
        "start": 2468.54,
        "temperature": 0,
        "text": " and make more sense into my brain.",
        "tokens": [
          50476,
          293,
          652,
          544,
          2020,
          666,
          452,
          3567,
          13,
          50561
        ]
      },
      {
        "avg_logprob": -0.2587221767125505,
        "compression_ratio": 1.5532994923857868,
        "end": 2478.7000000000003,
        "id": 853,
        "no_speech_prob": 0.0000015779609157107188,
        "seek": 246630,
        "start": 2477.02,
        "temperature": 0,
        "text": " Bruno is asking something in the chat",
        "tokens": [
          50900,
          23046,
          307,
          3365,
          746,
          294,
          264,
          5081,
          50984
        ]
      },
      {
        "avg_logprob": -0.2587221767125505,
        "compression_ratio": 1.5532994923857868,
        "end": 2480.0600000000004,
        "id": 854,
        "no_speech_prob": 0.0000015779609157107188,
        "seek": 246630,
        "start": 2478.7000000000003,
        "temperature": 0,
        "text": " about the true false table.",
        "tokens": [
          50984,
          466,
          264,
          2074,
          7908,
          3199,
          13,
          51052
        ]
      },
      {
        "avg_logprob": -0.2587221767125505,
        "compression_ratio": 1.5532994923857868,
        "end": 2482.02,
        "id": 855,
        "no_speech_prob": 0.0000015779609157107188,
        "seek": 246630,
        "start": 2480.0600000000004,
        "temperature": 0,
        "text": " Yeah, usually you draw it as a,",
        "tokens": [
          51052,
          865,
          11,
          2673,
          291,
          2642,
          309,
          382,
          257,
          11,
          51150
        ]
      },
      {
        "avg_logprob": -0.2587221767125505,
        "compression_ratio": 1.5532994923857868,
        "end": 2484.1800000000003,
        "id": 856,
        "no_speech_prob": 0.0000015779609157107188,
        "seek": 246630,
        "start": 2482.94,
        "temperature": 0,
        "text": " I might come back to this later.",
        "tokens": [
          51196,
          286,
          1062,
          808,
          646,
          281,
          341,
          1780,
          13,
          51258
        ]
      },
      {
        "avg_logprob": -0.2587221767125505,
        "compression_ratio": 1.5532994923857868,
        "end": 2487.84,
        "id": 857,
        "no_speech_prob": 0.0000015779609157107188,
        "seek": 246630,
        "start": 2484.1800000000003,
        "temperature": 0,
        "text": " Usually you draw it as a matrix.",
        "tokens": [
          51258,
          11419,
          291,
          2642,
          309,
          382,
          257,
          8141,
          13,
          51441
        ]
      },
      {
        "avg_logprob": -0.2587221767125505,
        "compression_ratio": 1.5532994923857868,
        "end": 2490.28,
        "id": 858,
        "no_speech_prob": 0.0000015779609157107188,
        "seek": 246630,
        "start": 2487.84,
        "temperature": 0,
        "text": " And I sort of did something weird there.",
        "tokens": [
          51441,
          400,
          286,
          1333,
          295,
          630,
          746,
          3657,
          456,
          13,
          51563
        ]
      },
      {
        "avg_logprob": -0.2587221767125505,
        "compression_ratio": 1.5532994923857868,
        "end": 2491.38,
        "id": 859,
        "no_speech_prob": 0.0000015779609157107188,
        "seek": 246630,
        "start": 2490.28,
        "temperature": 0,
        "text": " But I think it's fine.",
        "tokens": [
          51563,
          583,
          286,
          519,
          309,
          311,
          2489,
          13,
          51618
        ]
      },
      {
        "avg_logprob": -0.3836048620718497,
        "compression_ratio": 1.2990654205607477,
        "end": 2498.1400000000003,
        "id": 860,
        "no_speech_prob": 0.00008750237611820921,
        "seek": 249630,
        "start": 2497.3,
        "temperature": 0,
        "text": " I'm sorry, I'm looking at,",
        "tokens": [
          50414,
          286,
          478,
          2597,
          11,
          286,
          478,
          1237,
          412,
          11,
          50456
        ]
      },
      {
        "avg_logprob": -0.3836048620718497,
        "compression_ratio": 1.2990654205607477,
        "end": 2499.7400000000002,
        "id": 861,
        "no_speech_prob": 0.00008750237611820921,
        "seek": 249630,
        "start": 2498.1400000000003,
        "temperature": 0,
        "text": " see, this is what happens when I look at the chat too much.",
        "tokens": [
          50456,
          536,
          11,
          341,
          307,
          437,
          2314,
          562,
          286,
          574,
          412,
          264,
          5081,
          886,
          709,
          13,
          50536
        ]
      },
      {
        "avg_logprob": -0.3836048620718497,
        "compression_ratio": 1.2990654205607477,
        "end": 2500.5800000000004,
        "id": 862,
        "no_speech_prob": 0.00008750237611820921,
        "seek": 249630,
        "start": 2499.7400000000002,
        "temperature": 0,
        "text": " All right.",
        "tokens": [
          50536,
          1057,
          558,
          13,
          50578
        ]
      },
      {
        "avg_logprob": -0.3836048620718497,
        "compression_ratio": 1.2990654205607477,
        "end": 2508.42,
        "id": 863,
        "no_speech_prob": 0.00008750237611820921,
        "seek": 249630,
        "start": 2507.5800000000004,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          50928,
          1033,
          13,
          50970
        ]
      },
      {
        "avg_logprob": -0.3836048620718497,
        "compression_ratio": 1.2990654205607477,
        "end": 2519.1400000000003,
        "id": 864,
        "no_speech_prob": 0.00008750237611820921,
        "seek": 249630,
        "start": 2518.3,
        "temperature": 0,
        "text": " All right.",
        "tokens": [
          51464,
          1057,
          558,
          13,
          51506
        ]
      },
      {
        "avg_logprob": -0.3836048620718497,
        "compression_ratio": 1.2990654205607477,
        "end": 2523.6600000000003,
        "id": 865,
        "no_speech_prob": 0.00008750237611820921,
        "seek": 249630,
        "start": 2520.76,
        "temperature": 0,
        "text": " Okay, so now we need to,",
        "tokens": [
          51587,
          1033,
          11,
          370,
          586,
          321,
          643,
          281,
          11,
          51732
        ]
      },
      {
        "avg_logprob": -0.2392216750553676,
        "compression_ratio": 1.665158371040724,
        "end": 2526.3399999999997,
        "id": 866,
        "no_speech_prob": 0.00014653078687842935,
        "seek": 252366,
        "start": 2524.3799999999997,
        "temperature": 0,
        "text": " what this constructor here said,",
        "tokens": [
          50400,
          437,
          341,
          47479,
          510,
          848,
          11,
          50498
        ]
      },
      {
        "avg_logprob": -0.2392216750553676,
        "compression_ratio": 1.665158371040724,
        "end": 2528.14,
        "id": 867,
        "no_speech_prob": 0.00014653078687842935,
        "seek": 252366,
        "start": 2526.3399999999997,
        "temperature": 0,
        "text": " and let's just put this back to this.",
        "tokens": [
          50498,
          293,
          718,
          311,
          445,
          829,
          341,
          646,
          281,
          341,
          13,
          50588
        ]
      },
      {
        "avg_logprob": -0.2392216750553676,
        "compression_ratio": 1.665158371040724,
        "end": 2529.7999999999997,
        "id": 868,
        "no_speech_prob": 0.00014653078687842935,
        "seek": 252366,
        "start": 2528.14,
        "temperature": 0,
        "text": " This constructor here said,",
        "tokens": [
          50588,
          639,
          47479,
          510,
          848,
          11,
          50671
        ]
      },
      {
        "avg_logprob": -0.2392216750553676,
        "compression_ratio": 1.665158371040724,
        "end": 2533.8199999999997,
        "id": 869,
        "no_speech_prob": 0.00014653078687842935,
        "seek": 252366,
        "start": 2530.8599999999997,
        "temperature": 0,
        "text": " make a neural network with two inputs,",
        "tokens": [
          50724,
          652,
          257,
          18161,
          3209,
          365,
          732,
          15743,
          11,
          50872
        ]
      },
      {
        "avg_logprob": -0.2392216750553676,
        "compression_ratio": 1.665158371040724,
        "end": 2535.56,
        "id": 870,
        "no_speech_prob": 0.00014653078687842935,
        "seek": 252366,
        "start": 2533.8199999999997,
        "temperature": 0,
        "text": " two hidden nodes, and one output.",
        "tokens": [
          50872,
          732,
          7633,
          13891,
          11,
          293,
          472,
          5598,
          13,
          50959
        ]
      },
      {
        "avg_logprob": -0.2392216750553676,
        "compression_ratio": 1.665158371040724,
        "end": 2538.3799999999997,
        "id": 871,
        "no_speech_prob": 0.00014653078687842935,
        "seek": 252366,
        "start": 2535.56,
        "temperature": 0,
        "text": " So I need to duplicate that idea here with tf.layers.",
        "tokens": [
          50959,
          407,
          286,
          643,
          281,
          23976,
          300,
          1558,
          510,
          365,
          256,
          69,
          13,
          8376,
          433,
          13,
          51100
        ]
      },
      {
        "avg_logprob": -0.2392216750553676,
        "compression_ratio": 1.665158371040724,
        "end": 2543.3799999999997,
        "id": 872,
        "no_speech_prob": 0.00014653078687842935,
        "seek": 252366,
        "start": 2538.3799999999997,
        "temperature": 0,
        "text": " So let's go to the TensorFlow.js API reference.",
        "tokens": [
          51100,
          407,
          718,
          311,
          352,
          281,
          264,
          37624,
          13,
          25530,
          9362,
          6408,
          13,
          51350
        ]
      },
      {
        "avg_logprob": -0.2392216750553676,
        "compression_ratio": 1.665158371040724,
        "end": 2548.24,
        "id": 873,
        "no_speech_prob": 0.00014653078687842935,
        "seek": 252366,
        "start": 2544.2799999999997,
        "temperature": 0,
        "text": " And we're going to go all, scroll down to tf.layers.",
        "tokens": [
          51395,
          400,
          321,
          434,
          516,
          281,
          352,
          439,
          11,
          11369,
          760,
          281,
          256,
          69,
          13,
          8376,
          433,
          13,
          51593
        ]
      },
      {
        "avg_logprob": -0.2392216750553676,
        "compression_ratio": 1.665158371040724,
        "end": 2553.22,
        "id": 874,
        "no_speech_prob": 0.00014653078687842935,
        "seek": 252366,
        "start": 2550.08,
        "temperature": 0,
        "text": " And what I want to make is a dense layer.",
        "tokens": [
          51685,
          400,
          437,
          286,
          528,
          281,
          652,
          307,
          257,
          18011,
          4583,
          13,
          51842
        ]
      },
      {
        "avg_logprob": -0.2020997507818814,
        "compression_ratio": 1.733009708737864,
        "end": 2554.8199999999997,
        "id": 875,
        "no_speech_prob": 0.00001670140409260057,
        "seek": 255322,
        "start": 2553.74,
        "temperature": 0,
        "text": " tf.layers.dense.",
        "tokens": [
          50390,
          256,
          69,
          13,
          8376,
          433,
          13,
          67,
          1288,
          13,
          50444
        ]
      },
      {
        "avg_logprob": -0.2020997507818814,
        "compression_ratio": 1.733009708737864,
        "end": 2557.64,
        "id": 876,
        "no_speech_prob": 0.00001670140409260057,
        "seek": 255322,
        "start": 2554.8199999999997,
        "temperature": 0,
        "text": " A dense layer is a fully connected layer.",
        "tokens": [
          50444,
          316,
          18011,
          4583,
          307,
          257,
          4498,
          4582,
          4583,
          13,
          50585
        ]
      },
      {
        "avg_logprob": -0.2020997507818814,
        "compression_ratio": 1.733009708737864,
        "end": 2562.14,
        "id": 877,
        "no_speech_prob": 0.00001670140409260057,
        "seek": 255322,
        "start": 2557.64,
        "temperature": 0,
        "text": " So what I'm going to do is I am going to say,",
        "tokens": [
          50585,
          407,
          437,
          286,
          478,
          516,
          281,
          360,
          307,
          286,
          669,
          516,
          281,
          584,
          11,
          50810
        ]
      },
      {
        "avg_logprob": -0.2020997507818814,
        "compression_ratio": 1.733009708737864,
        "end": 2567.14,
        "id": 878,
        "no_speech_prob": 0.00001670140409260057,
        "seek": 255322,
        "start": 2562.14,
        "temperature": 0,
        "text": " let hidden equal tf.layers.dense.",
        "tokens": [
          50810,
          718,
          7633,
          2681,
          256,
          69,
          13,
          8376,
          433,
          13,
          67,
          1288,
          13,
          51060
        ]
      },
      {
        "avg_logprob": -0.2020997507818814,
        "compression_ratio": 1.733009708737864,
        "end": 2573.2799999999997,
        "id": 879,
        "no_speech_prob": 0.00001670140409260057,
        "seek": 255322,
        "start": 2569.06,
        "temperature": 0,
        "text": " And then I can put inside there an object",
        "tokens": [
          51156,
          400,
          550,
          286,
          393,
          829,
          1854,
          456,
          364,
          2657,
          51367
        ]
      },
      {
        "avg_logprob": -0.2020997507818814,
        "compression_ratio": 1.733009708737864,
        "end": 2575.7799999999997,
        "id": 880,
        "no_speech_prob": 0.00001670140409260057,
        "seek": 255322,
        "start": 2573.2799999999997,
        "temperature": 0,
        "text": " that has the parameters of how I want to configure",
        "tokens": [
          51367,
          300,
          575,
          264,
          9834,
          295,
          577,
          286,
          528,
          281,
          22162,
          51492
        ]
      },
      {
        "avg_logprob": -0.2020997507818814,
        "compression_ratio": 1.733009708737864,
        "end": 2576.62,
        "id": 881,
        "no_speech_prob": 0.00001670140409260057,
        "seek": 255322,
        "start": 2575.7799999999997,
        "temperature": 0,
        "text": " that layer.",
        "tokens": [
          51492,
          300,
          4583,
          13,
          51534
        ]
      },
      {
        "avg_logprob": -0.2020997507818814,
        "compression_ratio": 1.733009708737864,
        "end": 2578.7799999999997,
        "id": 882,
        "no_speech_prob": 0.00001670140409260057,
        "seek": 255322,
        "start": 2576.62,
        "temperature": 0,
        "text": " And so how do I want to configure it?",
        "tokens": [
          51534,
          400,
          370,
          577,
          360,
          286,
          528,
          281,
          22162,
          309,
          30,
          51642
        ]
      },
      {
        "avg_logprob": -0.2020997507818814,
        "compression_ratio": 1.733009708737864,
        "end": 2581.2599999999998,
        "id": 883,
        "no_speech_prob": 0.00001670140409260057,
        "seek": 255322,
        "start": 2578.7799999999997,
        "temperature": 0,
        "text": " The two things that I really need to do",
        "tokens": [
          51642,
          440,
          732,
          721,
          300,
          286,
          534,
          643,
          281,
          360,
          51766
        ]
      },
      {
        "avg_logprob": -0.2020997507818814,
        "compression_ratio": 1.733009708737864,
        "end": 2583.16,
        "id": 884,
        "no_speech_prob": 0.00001670140409260057,
        "seek": 255322,
        "start": 2581.2599999999998,
        "temperature": 0,
        "text": " is this is the hidden layer, right?",
        "tokens": [
          51766,
          307,
          341,
          307,
          264,
          7633,
          4583,
          11,
          558,
          30,
          51861
        ]
      },
      {
        "avg_logprob": -0.2342298573461072,
        "compression_ratio": 1.7934782608695652,
        "end": 2586.7599999999998,
        "id": 885,
        "no_speech_prob": 0.0000011544608469193918,
        "seek": 258316,
        "start": 2584,
        "temperature": 0,
        "text": " I need to give it an input shape, right?",
        "tokens": [
          50406,
          286,
          643,
          281,
          976,
          309,
          364,
          4846,
          3909,
          11,
          558,
          30,
          50544
        ]
      },
      {
        "avg_logprob": -0.2342298573461072,
        "compression_ratio": 1.7934782608695652,
        "end": 2588.68,
        "id": 886,
        "no_speech_prob": 0.0000011544608469193918,
        "seek": 258316,
        "start": 2586.7599999999998,
        "temperature": 0,
        "text": " I need to say what's coming in.",
        "tokens": [
          50544,
          286,
          643,
          281,
          584,
          437,
          311,
          1348,
          294,
          13,
          50640
        ]
      },
      {
        "avg_logprob": -0.2342298573461072,
        "compression_ratio": 1.7934782608695652,
        "end": 2590.6,
        "id": 887,
        "no_speech_prob": 0.0000011544608469193918,
        "seek": 258316,
        "start": 2588.68,
        "temperature": 0,
        "text": " What's coming in, that's what this is here.",
        "tokens": [
          50640,
          708,
          311,
          1348,
          294,
          11,
          300,
          311,
          437,
          341,
          307,
          510,
          13,
          50736
        ]
      },
      {
        "avg_logprob": -0.2342298573461072,
        "compression_ratio": 1.7934782608695652,
        "end": 2592.7999999999997,
        "id": 888,
        "no_speech_prob": 0.0000011544608469193918,
        "seek": 258316,
        "start": 2590.6,
        "temperature": 0,
        "text": " I need to say how many nodes it has.",
        "tokens": [
          50736,
          286,
          643,
          281,
          584,
          577,
          867,
          13891,
          309,
          575,
          13,
          50846
        ]
      },
      {
        "avg_logprob": -0.2342298573461072,
        "compression_ratio": 1.7934782608695652,
        "end": 2594.2,
        "id": 889,
        "no_speech_prob": 0.0000011544608469193918,
        "seek": 258316,
        "start": 2592.7999999999997,
        "temperature": 0,
        "text": " That's the number of units.",
        "tokens": [
          50846,
          663,
          311,
          264,
          1230,
          295,
          6815,
          13,
          50916
        ]
      },
      {
        "avg_logprob": -0.2342298573461072,
        "compression_ratio": 1.7934782608695652,
        "end": 2596.5,
        "id": 890,
        "no_speech_prob": 0.0000011544608469193918,
        "seek": 258316,
        "start": 2594.2,
        "temperature": 0,
        "text": " And then it probably has a default one,",
        "tokens": [
          50916,
          400,
          550,
          309,
          1391,
          575,
          257,
          7576,
          472,
          11,
          51031
        ]
      },
      {
        "avg_logprob": -0.2342298573461072,
        "compression_ratio": 1.7934782608695652,
        "end": 2598.6,
        "id": 891,
        "no_speech_prob": 0.0000011544608469193918,
        "seek": 258316,
        "start": 2596.5,
        "temperature": 0,
        "text": " but I can specify an activation function.",
        "tokens": [
          51031,
          457,
          286,
          393,
          16500,
          364,
          24433,
          2445,
          13,
          51136
        ]
      },
      {
        "avg_logprob": -0.2342298573461072,
        "compression_ratio": 1.7934782608695652,
        "end": 2600.62,
        "id": 892,
        "no_speech_prob": 0.0000011544608469193918,
        "seek": 258316,
        "start": 2598.6,
        "temperature": 0,
        "text": " And again, I'm just going to use sigmoid",
        "tokens": [
          51136,
          400,
          797,
          11,
          286,
          478,
          445,
          516,
          281,
          764,
          4556,
          3280,
          327,
          51237
        ]
      },
      {
        "avg_logprob": -0.2342298573461072,
        "compression_ratio": 1.7934782608695652,
        "end": 2603.24,
        "id": 893,
        "no_speech_prob": 0.0000011544608469193918,
        "seek": 258316,
        "start": 2600.62,
        "temperature": 0,
        "text": " as this historical activation function",
        "tokens": [
          51237,
          382,
          341,
          8584,
          24433,
          2445,
          51368
        ]
      },
      {
        "avg_logprob": -0.2342298573461072,
        "compression_ratio": 1.7934782608695652,
        "end": 2605.8599999999997,
        "id": 894,
        "no_speech_prob": 0.0000011544608469193918,
        "seek": 258316,
        "start": 2603.24,
        "temperature": 0,
        "text": " that I've been using in all my videos to date.",
        "tokens": [
          51368,
          300,
          286,
          600,
          668,
          1228,
          294,
          439,
          452,
          2145,
          281,
          4002,
          13,
          51499
        ]
      },
      {
        "avg_logprob": -0.2342298573461072,
        "compression_ratio": 1.7934782608695652,
        "end": 2608.7599999999998,
        "id": 895,
        "no_speech_prob": 0.0000011544608469193918,
        "seek": 258316,
        "start": 2605.8599999999997,
        "temperature": 0,
        "text": " I'm going to soon talk about softmax, what that is,",
        "tokens": [
          51499,
          286,
          478,
          516,
          281,
          2321,
          751,
          466,
          2787,
          41167,
          11,
          437,
          300,
          307,
          11,
          51644
        ]
      },
      {
        "avg_logprob": -0.2342298573461072,
        "compression_ratio": 1.7934782608695652,
        "end": 2612.08,
        "id": 896,
        "no_speech_prob": 0.0000011544608469193918,
        "seek": 258316,
        "start": 2608.7599999999998,
        "temperature": 0,
        "text": " as well as some other activation functions like rel,",
        "tokens": [
          51644,
          382,
          731,
          382,
          512,
          661,
          24433,
          6828,
          411,
          1039,
          11,
          51810
        ]
      },
      {
        "avg_logprob": -0.25771509035669193,
        "compression_ratio": 1.5215311004784688,
        "end": 2614.7599999999998,
        "id": 897,
        "no_speech_prob": 0.000013419999959296547,
        "seek": 261208,
        "start": 2612.08,
        "temperature": 0,
        "text": " which is maybe more commonly used.",
        "tokens": [
          50364,
          597,
          307,
          1310,
          544,
          12719,
          1143,
          13,
          50498
        ]
      },
      {
        "avg_logprob": -0.25771509035669193,
        "compression_ratio": 1.5215311004784688,
        "end": 2618.12,
        "id": 898,
        "no_speech_prob": 0.000013419999959296547,
        "seek": 261208,
        "start": 2616.2799999999997,
        "temperature": 0,
        "text": " By the way, nobody pronounces it that way but me,",
        "tokens": [
          50574,
          3146,
          264,
          636,
          11,
          5079,
          14144,
          887,
          309,
          300,
          636,
          457,
          385,
          11,
          50666
        ]
      },
      {
        "avg_logprob": -0.25771509035669193,
        "compression_ratio": 1.5215311004784688,
        "end": 2620.16,
        "id": 899,
        "no_speech_prob": 0.000013419999959296547,
        "seek": 261208,
        "start": 2618.12,
        "temperature": 0,
        "text": " so don't get confused.",
        "tokens": [
          50666,
          370,
          500,
          380,
          483,
          9019,
          13,
          50768
        ]
      },
      {
        "avg_logprob": -0.25771509035669193,
        "compression_ratio": 1.5215311004784688,
        "end": 2624.12,
        "id": 900,
        "no_speech_prob": 0.000013419999959296547,
        "seek": 261208,
        "start": 2620.16,
        "temperature": 0,
        "text": " All right, so I want to say input shape,",
        "tokens": [
          50768,
          1057,
          558,
          11,
          370,
          286,
          528,
          281,
          584,
          4846,
          3909,
          11,
          50966
        ]
      },
      {
        "avg_logprob": -0.25771509035669193,
        "compression_ratio": 1.5215311004784688,
        "end": 2627.68,
        "id": 901,
        "no_speech_prob": 0.000013419999959296547,
        "seek": 261208,
        "start": 2624.12,
        "temperature": 0,
        "text": " I believe is just, there's just two inputs.",
        "tokens": [
          50966,
          286,
          1697,
          307,
          445,
          11,
          456,
          311,
          445,
          732,
          15743,
          13,
          51144
        ]
      },
      {
        "avg_logprob": -0.25771509035669193,
        "compression_ratio": 1.5215311004784688,
        "end": 2632.68,
        "id": 902,
        "no_speech_prob": 0.000013419999959296547,
        "seek": 261208,
        "start": 2627.68,
        "temperature": 0,
        "text": " I also want to have two units, two nodes,",
        "tokens": [
          51144,
          286,
          611,
          528,
          281,
          362,
          732,
          6815,
          11,
          732,
          13891,
          11,
          51394
        ]
      },
      {
        "avg_logprob": -0.25771509035669193,
        "compression_ratio": 1.5215311004784688,
        "end": 2636.7999999999997,
        "id": 903,
        "no_speech_prob": 0.000013419999959296547,
        "seek": 261208,
        "start": 2633.52,
        "temperature": 0,
        "text": " and activation is going to be sigmoid.",
        "tokens": [
          51436,
          293,
          24433,
          307,
          516,
          281,
          312,
          4556,
          3280,
          327,
          13,
          51600
        ]
      },
      {
        "avg_logprob": -0.25771509035669193,
        "compression_ratio": 1.5215311004784688,
        "end": 2640.46,
        "id": 904,
        "no_speech_prob": 0.000013419999959296547,
        "seek": 261208,
        "start": 2637.7599999999998,
        "temperature": 0,
        "text": " So now I have created the hidden layer.",
        "tokens": [
          51648,
          407,
          586,
          286,
          362,
          2942,
          264,
          7633,
          4583,
          13,
          51783
        ]
      },
      {
        "avg_logprob": -0.25771509035669193,
        "compression_ratio": 1.5215311004784688,
        "end": 2641.2999999999997,
        "id": 905,
        "no_speech_prob": 0.000013419999959296547,
        "seek": 261208,
        "start": 2640.46,
        "temperature": 0,
        "text": " Yay!",
        "tokens": [
          51783,
          13268,
          0,
          51825
        ]
      },
      {
        "avg_logprob": -0.23220420837402345,
        "compression_ratio": 1.8461538461538463,
        "end": 2646.6,
        "id": 906,
        "no_speech_prob": 0.00000409290714742383,
        "seek": 264208,
        "start": 2642.4,
        "temperature": 0,
        "text": " The other layer that I need to create is the output layer.",
        "tokens": [
          50380,
          440,
          661,
          4583,
          300,
          286,
          643,
          281,
          1884,
          307,
          264,
          5598,
          4583,
          13,
          50590
        ]
      },
      {
        "avg_logprob": -0.23220420837402345,
        "compression_ratio": 1.8461538461538463,
        "end": 2648.16,
        "id": 907,
        "no_speech_prob": 0.00000409290714742383,
        "seek": 264208,
        "start": 2646.6,
        "temperature": 0,
        "text": " And so what am I going to do with the output layer?",
        "tokens": [
          50590,
          400,
          370,
          437,
          669,
          286,
          516,
          281,
          360,
          365,
          264,
          5598,
          4583,
          30,
          50668
        ]
      },
      {
        "avg_logprob": -0.23220420837402345,
        "compression_ratio": 1.8461538461538463,
        "end": 2650.56,
        "id": 908,
        "no_speech_prob": 0.00000409290714742383,
        "seek": 264208,
        "start": 2648.16,
        "temperature": 0,
        "text": " I don't need to provide an input shape",
        "tokens": [
          50668,
          286,
          500,
          380,
          643,
          281,
          2893,
          364,
          4846,
          3909,
          50788
        ]
      },
      {
        "avg_logprob": -0.23220420837402345,
        "compression_ratio": 1.8461538461538463,
        "end": 2652.7999999999997,
        "id": 909,
        "no_speech_prob": 0.00000409290714742383,
        "seek": 264208,
        "start": 2650.56,
        "temperature": 0,
        "text": " because the input shape can be inferred",
        "tokens": [
          50788,
          570,
          264,
          4846,
          3909,
          393,
          312,
          13596,
          986,
          50900
        ]
      },
      {
        "avg_logprob": -0.23220420837402345,
        "compression_ratio": 1.8461538461538463,
        "end": 2655.08,
        "id": 910,
        "no_speech_prob": 0.00000409290714742383,
        "seek": 264208,
        "start": 2652.7999999999997,
        "temperature": 0,
        "text": " if I add them sequentially.",
        "tokens": [
          50900,
          498,
          286,
          909,
          552,
          5123,
          3137,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.23220420837402345,
        "compression_ratio": 1.8461538461538463,
        "end": 2657.56,
        "id": 911,
        "no_speech_prob": 0.00000409290714742383,
        "seek": 264208,
        "start": 2655.08,
        "temperature": 0,
        "text": " The inputs are not a layer, so for this first layer,",
        "tokens": [
          51014,
          440,
          15743,
          366,
          406,
          257,
          4583,
          11,
          370,
          337,
          341,
          700,
          4583,
          11,
          51138
        ]
      },
      {
        "avg_logprob": -0.23220420837402345,
        "compression_ratio": 1.8461538461538463,
        "end": 2659.7999999999997,
        "id": 912,
        "no_speech_prob": 0.00000409290714742383,
        "seek": 264208,
        "start": 2657.56,
        "temperature": 0,
        "text": " the hidden layer, I've got to say how many there are.",
        "tokens": [
          51138,
          264,
          7633,
          4583,
          11,
          286,
          600,
          658,
          281,
          584,
          577,
          867,
          456,
          366,
          13,
          51250
        ]
      },
      {
        "avg_logprob": -0.23220420837402345,
        "compression_ratio": 1.8461538461538463,
        "end": 2661.6,
        "id": 913,
        "no_speech_prob": 0.00000409290714742383,
        "seek": 264208,
        "start": 2659.7999999999997,
        "temperature": 0,
        "text": " But now once I'm creating this next layer,",
        "tokens": [
          51250,
          583,
          586,
          1564,
          286,
          478,
          4084,
          341,
          958,
          4583,
          11,
          51340
        ]
      },
      {
        "avg_logprob": -0.23220420837402345,
        "compression_ratio": 1.8461538461538463,
        "end": 2663.64,
        "id": 914,
        "no_speech_prob": 0.00000409290714742383,
        "seek": 264208,
        "start": 2661.6,
        "temperature": 0,
        "text": " it can just, the input shape is going to be defined",
        "tokens": [
          51340,
          309,
          393,
          445,
          11,
          264,
          4846,
          3909,
          307,
          516,
          281,
          312,
          7642,
          51442
        ]
      },
      {
        "avg_logprob": -0.23220420837402345,
        "compression_ratio": 1.8461538461538463,
        "end": 2664.7999999999997,
        "id": 915,
        "no_speech_prob": 0.00000409290714742383,
        "seek": 264208,
        "start": 2663.64,
        "temperature": 0,
        "text": " by what was before it.",
        "tokens": [
          51442,
          538,
          437,
          390,
          949,
          309,
          13,
          51500
        ]
      },
      {
        "avg_logprob": -0.23220420837402345,
        "compression_ratio": 1.8461538461538463,
        "end": 2667.52,
        "id": 916,
        "no_speech_prob": 0.00000409290714742383,
        "seek": 264208,
        "start": 2665.7,
        "temperature": 0,
        "text": " So now I'm going to say,",
        "tokens": [
          51545,
          407,
          586,
          286,
          478,
          516,
          281,
          584,
          11,
          51636
        ]
      },
      {
        "avg_logprob": -0.23220420837402345,
        "compression_ratio": 1.8461538461538463,
        "end": 2671.14,
        "id": 917,
        "no_speech_prob": 0.00000409290714742383,
        "seek": 264208,
        "start": 2667.52,
        "temperature": 0,
        "text": " I really have to stop hitting the sound effects by accident.",
        "tokens": [
          51636,
          286,
          534,
          362,
          281,
          1590,
          8850,
          264,
          1626,
          5065,
          538,
          6398,
          13,
          51817
        ]
      },
      {
        "avg_logprob": -0.2942391563864315,
        "compression_ratio": 1.5060975609756098,
        "end": 2677.52,
        "id": 918,
        "no_speech_prob": 0.0000013497011650542845,
        "seek": 267208,
        "start": 2672.52,
        "temperature": 0,
        "text": " And now I'm going to say let output equal tf.layers.dense.",
        "tokens": [
          50386,
          400,
          586,
          286,
          478,
          516,
          281,
          584,
          718,
          5598,
          2681,
          256,
          69,
          13,
          8376,
          433,
          13,
          67,
          1288,
          13,
          50636
        ]
      },
      {
        "avg_logprob": -0.2942391563864315,
        "compression_ratio": 1.5060975609756098,
        "end": 2684.52,
        "id": 919,
        "no_speech_prob": 0.0000013497011650542845,
        "seek": 267208,
        "start": 2679.52,
        "temperature": 0,
        "text": " And all I need to say is units one activation sigmoid.",
        "tokens": [
          50736,
          400,
          439,
          286,
          643,
          281,
          584,
          307,
          6815,
          472,
          24433,
          4556,
          3280,
          327,
          13,
          50986
        ]
      },
      {
        "avg_logprob": -0.2942391563864315,
        "compression_ratio": 1.5060975609756098,
        "end": 2691.7999999999997,
        "id": 920,
        "no_speech_prob": 0.0000013497011650542845,
        "seek": 267208,
        "start": 2686.7999999999997,
        "temperature": 0,
        "text": " Then all I have to do is say model.addHidden,",
        "tokens": [
          51100,
          1396,
          439,
          286,
          362,
          281,
          360,
          307,
          584,
          2316,
          13,
          25224,
          39,
          6171,
          11,
          51350
        ]
      },
      {
        "avg_logprob": -0.2942391563864315,
        "compression_ratio": 1.5060975609756098,
        "end": 2695.36,
        "id": 921,
        "no_speech_prob": 0.0000013497011650542845,
        "seek": 267208,
        "start": 2691.84,
        "temperature": 0,
        "text": " model.addOutput.",
        "tokens": [
          51352,
          2316,
          13,
          25224,
          28353,
          2582,
          13,
          51528
        ]
      },
      {
        "avg_logprob": -0.2942391563864315,
        "compression_ratio": 1.5060975609756098,
        "end": 2697.2,
        "id": 922,
        "no_speech_prob": 0.0000013497011650542845,
        "seek": 267208,
        "start": 2695.36,
        "temperature": 0,
        "text": " So this is the model.",
        "tokens": [
          51528,
          407,
          341,
          307,
          264,
          2316,
          13,
          51620
        ]
      },
      {
        "avg_logprob": -0.2942391563864315,
        "compression_ratio": 1.5060975609756098,
        "end": 2701.6,
        "id": 923,
        "no_speech_prob": 0.0000013497011650542845,
        "seek": 267208,
        "start": 2697.2,
        "temperature": 0,
        "text": " Now, one thing I need to do is I definitely need",
        "tokens": [
          51620,
          823,
          11,
          472,
          551,
          286,
          643,
          281,
          360,
          307,
          286,
          2138,
          643,
          51840
        ]
      },
      {
        "avg_logprob": -0.2437407852064633,
        "compression_ratio": 1.5993150684931507,
        "end": 2705.12,
        "id": 924,
        "no_speech_prob": 0.0005274756695143878,
        "seek": 270160,
        "start": 2702.16,
        "temperature": 0,
        "text": " to import the TensorFlow.js library,",
        "tokens": [
          50392,
          281,
          974,
          264,
          37624,
          13,
          25530,
          6405,
          11,
          50540
        ]
      },
      {
        "avg_logprob": -0.2437407852064633,
        "compression_ratio": 1.5993150684931507,
        "end": 2707.64,
        "id": 925,
        "no_speech_prob": 0.0005274756695143878,
        "seek": 270160,
        "start": 2705.12,
        "temperature": 0,
        "text": " which I happen to have from one of my previous examples.",
        "tokens": [
          50540,
          597,
          286,
          1051,
          281,
          362,
          490,
          472,
          295,
          452,
          3894,
          5110,
          13,
          50666
        ]
      },
      {
        "avg_logprob": -0.2437407852064633,
        "compression_ratio": 1.5993150684931507,
        "end": 2709.48,
        "id": 926,
        "no_speech_prob": 0.0005274756695143878,
        "seek": 270160,
        "start": 2707.64,
        "temperature": 0,
        "text": " So I'm going, right now I only have,",
        "tokens": [
          50666,
          407,
          286,
          478,
          516,
          11,
          558,
          586,
          286,
          787,
          362,
          11,
          50758
        ]
      },
      {
        "avg_logprob": -0.2437407852064633,
        "compression_ratio": 1.5993150684931507,
        "end": 2712.2,
        "id": 927,
        "no_speech_prob": 0.0005274756695143878,
        "seek": 270160,
        "start": 2709.48,
        "temperature": 0,
        "text": " I have the p5 libraries in my index.html",
        "tokens": [
          50758,
          286,
          362,
          264,
          280,
          20,
          15148,
          294,
          452,
          8186,
          13,
          357,
          15480,
          50894
        ]
      },
      {
        "avg_logprob": -0.2437407852064633,
        "compression_ratio": 1.5993150684931507,
        "end": 2714.56,
        "id": 928,
        "no_speech_prob": 0.0005274756695143878,
        "seek": 270160,
        "start": 2712.2,
        "temperature": 0,
        "text": " plus my crazy neural network thing",
        "tokens": [
          50894,
          1804,
          452,
          3219,
          18161,
          3209,
          551,
          51012
        ]
      },
      {
        "avg_logprob": -0.2437407852064633,
        "compression_ratio": 1.5993150684931507,
        "end": 2717.12,
        "id": 929,
        "no_speech_prob": 0.0005274756695143878,
        "seek": 270160,
        "start": 2714.56,
        "temperature": 0,
        "text": " and my actual code in Sketch.js.",
        "tokens": [
          51012,
          293,
          452,
          3539,
          3089,
          294,
          49245,
          13,
          25530,
          13,
          51140
        ]
      },
      {
        "avg_logprob": -0.2437407852064633,
        "compression_ratio": 1.5993150684931507,
        "end": 2721,
        "id": 930,
        "no_speech_prob": 0.0005274756695143878,
        "seek": 270160,
        "start": 2717.96,
        "temperature": 0,
        "text": " Someday maybe I'll use the fancy new import syntax stuff.",
        "tokens": [
          51182,
          12297,
          16826,
          1310,
          286,
          603,
          764,
          264,
          10247,
          777,
          974,
          28431,
          1507,
          13,
          51334
        ]
      },
      {
        "avg_logprob": -0.2437407852064633,
        "compression_ratio": 1.5993150684931507,
        "end": 2723.2799999999997,
        "id": 931,
        "no_speech_prob": 0.0005274756695143878,
        "seek": 270160,
        "start": 2721,
        "temperature": 0,
        "text": " Let me just have everything kind of line up.",
        "tokens": [
          51334,
          961,
          385,
          445,
          362,
          1203,
          733,
          295,
          1622,
          493,
          13,
          51448
        ]
      },
      {
        "avg_logprob": -0.2437407852064633,
        "compression_ratio": 1.5993150684931507,
        "end": 2724.3199999999997,
        "id": 932,
        "no_speech_prob": 0.0005274756695143878,
        "seek": 270160,
        "start": 2723.2799999999997,
        "temperature": 0,
        "text": " Let me add this in here.",
        "tokens": [
          51448,
          961,
          385,
          909,
          341,
          294,
          510,
          13,
          51500
        ]
      },
      {
        "avg_logprob": -0.2437407852064633,
        "compression_ratio": 1.5993150684931507,
        "end": 2726.2799999999997,
        "id": 933,
        "no_speech_prob": 0.0005274756695143878,
        "seek": 270160,
        "start": 2724.3199999999997,
        "temperature": 0,
        "text": " So now tf.js should be there.",
        "tokens": [
          51500,
          407,
          586,
          256,
          69,
          13,
          25530,
          820,
          312,
          456,
          13,
          51598
        ]
      },
      {
        "avg_logprob": -0.2437407852064633,
        "compression_ratio": 1.5993150684931507,
        "end": 2728.48,
        "id": 934,
        "no_speech_prob": 0.0005274756695143878,
        "seek": 270160,
        "start": 2726.2799999999997,
        "temperature": 0,
        "text": " I should be able to go back and run this",
        "tokens": [
          51598,
          286,
          820,
          312,
          1075,
          281,
          352,
          646,
          293,
          1190,
          341,
          51708
        ]
      },
      {
        "avg_logprob": -0.2437407852064633,
        "compression_ratio": 1.5993150684931507,
        "end": 2730.36,
        "id": 935,
        "no_speech_prob": 0.0005274756695143878,
        "seek": 270160,
        "start": 2728.48,
        "temperature": 0,
        "text": " and not see any errors, aha!",
        "tokens": [
          51708,
          293,
          406,
          536,
          604,
          13603,
          11,
          47340,
          0,
          51802
        ]
      },
      {
        "avg_logprob": -0.25987719107365265,
        "compression_ratio": 1.401360544217687,
        "end": 2737.6,
        "id": 936,
        "no_speech_prob": 0.00007967284182086587,
        "seek": 273160,
        "start": 2732.6,
        "temperature": 0,
        "text": " Tf.layers.sequential is not a function.",
        "tokens": [
          50414,
          314,
          69,
          13,
          8376,
          433,
          13,
          11834,
          2549,
          307,
          406,
          257,
          2445,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.25987719107365265,
        "compression_ratio": 1.401360544217687,
        "end": 2742.36,
        "id": 937,
        "no_speech_prob": 0.00007967284182086587,
        "seek": 273160,
        "start": 2740.52,
        "temperature": 0,
        "text": " Sorry, I'm seeing things in the chat.",
        "tokens": [
          50810,
          4919,
          11,
          286,
          478,
          2577,
          721,
          294,
          264,
          5081,
          13,
          50902
        ]
      },
      {
        "avg_logprob": -0.25987719107365265,
        "compression_ratio": 1.401360544217687,
        "end": 2745.72,
        "id": 938,
        "no_speech_prob": 0.00007967284182086587,
        "seek": 273160,
        "start": 2743.3199999999997,
        "temperature": 0,
        "text": " Chat's really off the rails with this XOR thing.",
        "tokens": [
          50950,
          27503,
          311,
          534,
          766,
          264,
          27649,
          365,
          341,
          1783,
          2483,
          551,
          13,
          51070
        ]
      },
      {
        "avg_logprob": -0.25987719107365265,
        "compression_ratio": 1.401360544217687,
        "end": 2758.24,
        "id": 939,
        "no_speech_prob": 0.00007967284182086587,
        "seek": 273160,
        "start": 2753.72,
        "temperature": 0,
        "text": " All right, so I probably just didn't name",
        "tokens": [
          51470,
          1057,
          558,
          11,
          370,
          286,
          1391,
          445,
          994,
          380,
          1315,
          51696
        ]
      },
      {
        "avg_logprob": -0.25987719107365265,
        "compression_ratio": 1.401360544217687,
        "end": 2761.2799999999997,
        "id": 940,
        "no_speech_prob": 0.00007967284182086587,
        "seek": 273160,
        "start": 2758.24,
        "temperature": 0,
        "text": " tf.layers.sequential the right thing.",
        "tokens": [
          51696,
          256,
          69,
          13,
          8376,
          433,
          13,
          11834,
          2549,
          264,
          558,
          551,
          13,
          51848
        ]
      },
      {
        "avg_logprob": -0.2333300076998197,
        "compression_ratio": 1.705607476635514,
        "end": 2764.52,
        "id": 941,
        "no_speech_prob": 0.000044001095375278965,
        "seek": 276128,
        "start": 2761.96,
        "temperature": 0,
        "text": " I could go look, by the way, I made an example.",
        "tokens": [
          50398,
          286,
          727,
          352,
          574,
          11,
          538,
          264,
          636,
          11,
          286,
          1027,
          364,
          1365,
          13,
          50526
        ]
      },
      {
        "avg_logprob": -0.2333300076998197,
        "compression_ratio": 1.705607476635514,
        "end": 2766.2000000000003,
        "id": 942,
        "no_speech_prob": 0.000044001095375278965,
        "seek": 276128,
        "start": 2764.52,
        "temperature": 0,
        "text": " Oh, it's just tf.sequential.",
        "tokens": [
          50526,
          876,
          11,
          309,
          311,
          445,
          256,
          69,
          13,
          11834,
          2549,
          13,
          50610
        ]
      },
      {
        "avg_logprob": -0.2333300076998197,
        "compression_ratio": 1.705607476635514,
        "end": 2769.6000000000004,
        "id": 943,
        "no_speech_prob": 0.000044001095375278965,
        "seek": 276128,
        "start": 2766.2000000000003,
        "temperature": 0,
        "text": " Okay, so all I want to say is I just got that wrong.",
        "tokens": [
          50610,
          1033,
          11,
          370,
          439,
          286,
          528,
          281,
          584,
          307,
          286,
          445,
          658,
          300,
          2085,
          13,
          50780
        ]
      },
      {
        "avg_logprob": -0.2333300076998197,
        "compression_ratio": 1.705607476635514,
        "end": 2771.88,
        "id": 944,
        "no_speech_prob": 0.000044001095375278965,
        "seek": 276128,
        "start": 2769.6000000000004,
        "temperature": 0,
        "text": " It's tf.sequential.",
        "tokens": [
          50780,
          467,
          311,
          256,
          69,
          13,
          11834,
          2549,
          13,
          50894
        ]
      },
      {
        "avg_logprob": -0.2333300076998197,
        "compression_ratio": 1.705607476635514,
        "end": 2776.44,
        "id": 945,
        "no_speech_prob": 0.000044001095375278965,
        "seek": 276128,
        "start": 2771.88,
        "temperature": 0,
        "text": " So I could go, hopefully I would find this here,",
        "tokens": [
          50894,
          407,
          286,
          727,
          352,
          11,
          4696,
          286,
          576,
          915,
          341,
          510,
          11,
          51122
        ]
      },
      {
        "avg_logprob": -0.2333300076998197,
        "compression_ratio": 1.705607476635514,
        "end": 2779.52,
        "id": 946,
        "no_speech_prob": 0.000044001095375278965,
        "seek": 276128,
        "start": 2776.44,
        "temperature": 0,
        "text": " tf.sequential, yeah, models creation.",
        "tokens": [
          51122,
          256,
          69,
          13,
          11834,
          2549,
          11,
          1338,
          11,
          5245,
          8016,
          13,
          51276
        ]
      },
      {
        "avg_logprob": -0.2333300076998197,
        "compression_ratio": 1.705607476635514,
        "end": 2780.76,
        "id": 947,
        "no_speech_prob": 0.000044001095375278965,
        "seek": 276128,
        "start": 2779.52,
        "temperature": 0,
        "text": " There it is, tf.sequential.",
        "tokens": [
          51276,
          821,
          309,
          307,
          11,
          256,
          69,
          13,
          11834,
          2549,
          13,
          51338
        ]
      },
      {
        "avg_logprob": -0.2333300076998197,
        "compression_ratio": 1.705607476635514,
        "end": 2782.4,
        "id": 948,
        "no_speech_prob": 0.000044001095375278965,
        "seek": 276128,
        "start": 2780.76,
        "temperature": 0,
        "text": " So I just had that wrong.",
        "tokens": [
          51338,
          407,
          286,
          445,
          632,
          300,
          2085,
          13,
          51420
        ]
      },
      {
        "avg_logprob": -0.2333300076998197,
        "compression_ratio": 1.705607476635514,
        "end": 2785.44,
        "id": 949,
        "no_speech_prob": 0.000044001095375278965,
        "seek": 276128,
        "start": 2782.4,
        "temperature": 0,
        "text": " Okay, let's try refreshing this yet again.",
        "tokens": [
          51420,
          1033,
          11,
          718,
          311,
          853,
          19772,
          341,
          1939,
          797,
          13,
          51572
        ]
      },
      {
        "avg_logprob": -0.2333300076998197,
        "compression_ratio": 1.705607476635514,
        "end": 2788.6800000000003,
        "id": 950,
        "no_speech_prob": 0.000044001095375278965,
        "seek": 276128,
        "start": 2786.84,
        "temperature": 0,
        "text": " Slider is not defined.",
        "tokens": [
          51642,
          6187,
          1438,
          307,
          406,
          7642,
          13,
          51734
        ]
      },
      {
        "avg_logprob": -0.2333300076998197,
        "compression_ratio": 1.705607476635514,
        "end": 2790.4,
        "id": 951,
        "no_speech_prob": 0.000044001095375278965,
        "seek": 276128,
        "start": 2789.5600000000004,
        "temperature": 0,
        "text": " Hold on.",
        "tokens": [
          51778,
          6962,
          322,
          13,
          51820
        ]
      },
      {
        "avg_logprob": -0.4042437692706505,
        "compression_ratio": 1.4545454545454546,
        "end": 2792.52,
        "id": 952,
        "no_speech_prob": 0.000014738926438440103,
        "seek": 279128,
        "start": 2791.52,
        "temperature": 0,
        "text": " Sorry, Matzia.",
        "tokens": [
          50376,
          4919,
          11,
          6789,
          40395,
          13,
          50426
        ]
      },
      {
        "avg_logprob": -0.4042437692706505,
        "compression_ratio": 1.4545454545454546,
        "end": 2795.76,
        "id": 953,
        "no_speech_prob": 0.000014738926438440103,
        "seek": 279128,
        "start": 2793.84,
        "temperature": 0,
        "text": " I have to turn the notifications off on my watch.",
        "tokens": [
          50492,
          286,
          362,
          281,
          1261,
          264,
          13426,
          766,
          322,
          452,
          1159,
          13,
          50588
        ]
      },
      {
        "avg_logprob": -0.4042437692706505,
        "compression_ratio": 1.4545454545454546,
        "end": 2798.2400000000002,
        "id": 954,
        "no_speech_prob": 0.000014738926438440103,
        "seek": 279128,
        "start": 2795.76,
        "temperature": 0,
        "text": " I'm getting phone calls and buzzing things.",
        "tokens": [
          50588,
          286,
          478,
          1242,
          2593,
          5498,
          293,
          29659,
          721,
          13,
          50712
        ]
      },
      {
        "avg_logprob": -0.4042437692706505,
        "compression_ratio": 1.4545454545454546,
        "end": 2801.5600000000004,
        "id": 955,
        "no_speech_prob": 0.000014738926438440103,
        "seek": 279128,
        "start": 2800.6800000000003,
        "temperature": 0,
        "text": " Take a minute here.",
        "tokens": [
          50834,
          3664,
          257,
          3456,
          510,
          13,
          50878
        ]
      },
      {
        "avg_logprob": -0.4042437692706505,
        "compression_ratio": 1.4545454545454546,
        "end": 2804.92,
        "id": 956,
        "no_speech_prob": 0.000014738926438440103,
        "seek": 279128,
        "start": 2801.5600000000004,
        "temperature": 0,
        "text": " Somebody said that I'm good at drinking drinks in profile,",
        "tokens": [
          50878,
          13463,
          848,
          300,
          286,
          478,
          665,
          412,
          1224,
          12408,
          12142,
          294,
          7964,
          11,
          51046
        ]
      },
      {
        "avg_logprob": -0.4042437692706505,
        "compression_ratio": 1.4545454545454546,
        "end": 2808.32,
        "id": 957,
        "no_speech_prob": 0.000014738926438440103,
        "seek": 279128,
        "start": 2804.92,
        "temperature": 0,
        "text": " that I could be like a coding train brought to you,",
        "tokens": [
          51046,
          300,
          286,
          727,
          312,
          411,
          257,
          17720,
          3847,
          3038,
          281,
          291,
          11,
          51216
        ]
      },
      {
        "avg_logprob": -0.4042437692706505,
        "compression_ratio": 1.4545454545454546,
        "end": 2810.4,
        "id": 958,
        "no_speech_prob": 0.000014738926438440103,
        "seek": 279128,
        "start": 2808.32,
        "temperature": 0,
        "text": " I'm Buzz marketing clean canteen.",
        "tokens": [
          51216,
          286,
          478,
          29209,
          6370,
          2541,
          393,
          9791,
          13,
          51320
        ]
      },
      {
        "avg_logprob": -0.4042437692706505,
        "compression_ratio": 1.4545454545454546,
        "end": 2813.1200000000003,
        "id": 959,
        "no_speech_prob": 0.000014738926438440103,
        "seek": 279128,
        "start": 2811.28,
        "temperature": 0,
        "text": " Not an official sponsor.",
        "tokens": [
          51364,
          1726,
          364,
          4783,
          16198,
          13,
          51456
        ]
      },
      {
        "avg_logprob": -0.4042437692706505,
        "compression_ratio": 1.4545454545454546,
        "end": 2820.2000000000003,
        "id": 960,
        "no_speech_prob": 0.000014738926438440103,
        "seek": 279128,
        "start": 2819.36,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          51768,
          1033,
          13,
          51810
        ]
      },
      {
        "avg_logprob": -0.5117753179449784,
        "compression_ratio": 1.3522727272727273,
        "end": 2823.1600000000003,
        "id": 961,
        "no_speech_prob": 0.000006339208539429819,
        "seek": 282128,
        "start": 2822.1600000000003,
        "temperature": 0,
        "text": " Where was I?",
        "tokens": [
          50408,
          2305,
          390,
          286,
          30,
          50458
        ]
      },
      {
        "avg_logprob": -0.5117753179449784,
        "compression_ratio": 1.3522727272727273,
        "end": 2829,
        "id": 962,
        "no_speech_prob": 0.000006339208539429819,
        "seek": 282128,
        "start": 2828.1600000000003,
        "temperature": 0,
        "text": " Right.",
        "tokens": [
          50708,
          1779,
          13,
          50750
        ]
      },
      {
        "avg_logprob": -0.5117753179449784,
        "compression_ratio": 1.3522727272727273,
        "end": 2835.32,
        "id": 963,
        "no_speech_prob": 0.000006339208539429819,
        "seek": 282128,
        "start": 2830.88,
        "temperature": 0,
        "text": " All right, let me fix this learning rate issue, 0.1.",
        "tokens": [
          50844,
          1057,
          558,
          11,
          718,
          385,
          3191,
          341,
          2539,
          3314,
          2734,
          11,
          1958,
          13,
          16,
          13,
          51066
        ]
      },
      {
        "avg_logprob": -0.5117753179449784,
        "compression_ratio": 1.3522727272727273,
        "end": 2837.32,
        "id": 964,
        "no_speech_prob": 0.000006339208539429819,
        "seek": 282128,
        "start": 2835.32,
        "temperature": 0,
        "text": " I just want the thing to run.",
        "tokens": [
          51066,
          286,
          445,
          528,
          264,
          551,
          281,
          1190,
          13,
          51166
        ]
      },
      {
        "avg_logprob": -0.5117753179449784,
        "compression_ratio": 1.3522727272727273,
        "end": 2840.6800000000003,
        "id": 965,
        "no_speech_prob": 0.000006339208539429819,
        "seek": 282128,
        "start": 2837.32,
        "temperature": 0,
        "text": " Okay, so it's going, it's still working with",
        "tokens": [
          51166,
          1033,
          11,
          370,
          309,
          311,
          516,
          11,
          309,
          311,
          920,
          1364,
          365,
          51334
        ]
      },
      {
        "avg_logprob": -0.5117753179449784,
        "compression_ratio": 1.3522727272727273,
        "end": 2848.2000000000003,
        "id": 966,
        "no_speech_prob": 0.000006339208539429819,
        "seek": 282128,
        "start": 2843.2000000000003,
        "temperature": 0,
        "text": " my neural network library, not the new TensorFlow.js one.",
        "tokens": [
          51460,
          452,
          18161,
          3209,
          6405,
          11,
          406,
          264,
          777,
          37624,
          13,
          25530,
          472,
          13,
          51710
        ]
      },
      {
        "avg_logprob": -0.5117753179449784,
        "compression_ratio": 1.3522727272727273,
        "end": 2850.0400000000004,
        "id": 967,
        "no_speech_prob": 0.000006339208539429819,
        "seek": 282128,
        "start": 2848.36,
        "temperature": 0,
        "text": " But let's keep stepping through.",
        "tokens": [
          51718,
          583,
          718,
          311,
          1066,
          16821,
          807,
          13,
          51802
        ]
      },
      {
        "avg_logprob": -0.1678034464518229,
        "compression_ratio": 1.7906976744186047,
        "end": 2854.2000000000003,
        "id": 968,
        "no_speech_prob": 0.000009223462257068604,
        "seek": 285128,
        "start": 2851.92,
        "temperature": 0,
        "text": " So, ah, so what am I missing here?",
        "tokens": [
          50396,
          407,
          11,
          3716,
          11,
          370,
          437,
          669,
          286,
          5361,
          510,
          30,
          50510
        ]
      },
      {
        "avg_logprob": -0.1678034464518229,
        "compression_ratio": 1.7906976744186047,
        "end": 2856.6000000000004,
        "id": 969,
        "no_speech_prob": 0.000009223462257068604,
        "seek": 285128,
        "start": 2854.2000000000003,
        "temperature": 0,
        "text": " So when I make a model, this is,",
        "tokens": [
          50510,
          407,
          562,
          286,
          652,
          257,
          2316,
          11,
          341,
          307,
          11,
          50630
        ]
      },
      {
        "avg_logprob": -0.1678034464518229,
        "compression_ratio": 1.7906976744186047,
        "end": 2858.32,
        "id": 970,
        "no_speech_prob": 0.000009223462257068604,
        "seek": 285128,
        "start": 2856.6000000000004,
        "temperature": 0,
        "text": " now I've architected the model.",
        "tokens": [
          50630,
          586,
          286,
          600,
          6331,
          292,
          264,
          2316,
          13,
          50716
        ]
      },
      {
        "avg_logprob": -0.1678034464518229,
        "compression_ratio": 1.7906976744186047,
        "end": 2861.1600000000003,
        "id": 971,
        "no_speech_prob": 0.000009223462257068604,
        "seek": 285128,
        "start": 2858.32,
        "temperature": 0,
        "text": " I've architected this particular architecture,",
        "tokens": [
          50716,
          286,
          600,
          6331,
          292,
          341,
          1729,
          9482,
          11,
          50858
        ]
      },
      {
        "avg_logprob": -0.1678034464518229,
        "compression_ratio": 1.7906976744186047,
        "end": 2863.5600000000004,
        "id": 972,
        "no_speech_prob": 0.000009223462257068604,
        "seek": 285128,
        "start": 2861.1600000000003,
        "temperature": 0,
        "text": " but I need to do another step.",
        "tokens": [
          50858,
          457,
          286,
          643,
          281,
          360,
          1071,
          1823,
          13,
          50978
        ]
      },
      {
        "avg_logprob": -0.1678034464518229,
        "compression_ratio": 1.7906976744186047,
        "end": 2866.1600000000003,
        "id": 973,
        "no_speech_prob": 0.000009223462257068604,
        "seek": 285128,
        "start": 2863.5600000000004,
        "temperature": 0,
        "text": " I need to compile the model,",
        "tokens": [
          50978,
          286,
          643,
          281,
          31413,
          264,
          2316,
          11,
          51108
        ]
      },
      {
        "avg_logprob": -0.1678034464518229,
        "compression_ratio": 1.7906976744186047,
        "end": 2871.1600000000003,
        "id": 974,
        "no_speech_prob": 0.000009223462257068604,
        "seek": 285128,
        "start": 2866.1600000000003,
        "temperature": 0,
        "text": " and I need to define the loss function and the optimizer.",
        "tokens": [
          51108,
          293,
          286,
          643,
          281,
          6964,
          264,
          4470,
          2445,
          293,
          264,
          5028,
          6545,
          13,
          51358
        ]
      },
      {
        "avg_logprob": -0.1678034464518229,
        "compression_ratio": 1.7906976744186047,
        "end": 2875,
        "id": 975,
        "no_speech_prob": 0.000009223462257068604,
        "seek": 285128,
        "start": 2873.6000000000004,
        "temperature": 0,
        "text": " Basically, I need to say like,",
        "tokens": [
          51480,
          8537,
          11,
          286,
          643,
          281,
          584,
          411,
          11,
          51550
        ]
      },
      {
        "avg_logprob": -0.1678034464518229,
        "compression_ratio": 1.7906976744186047,
        "end": 2877.32,
        "id": 976,
        "no_speech_prob": 0.000009223462257068604,
        "seek": 285128,
        "start": 2875,
        "temperature": 0,
        "text": " okay, well, this is how I'm going to determine",
        "tokens": [
          51550,
          1392,
          11,
          731,
          11,
          341,
          307,
          577,
          286,
          478,
          516,
          281,
          6997,
          51666
        ]
      },
      {
        "avg_logprob": -0.1678034464518229,
        "compression_ratio": 1.7906976744186047,
        "end": 2881,
        "id": 977,
        "no_speech_prob": 0.000009223462257068604,
        "seek": 285128,
        "start": 2877.32,
        "temperature": 0,
        "text": " how well the model is currently performing",
        "tokens": [
          51666,
          577,
          731,
          264,
          2316,
          307,
          4362,
          10205,
          51850
        ]
      },
      {
        "avg_logprob": -0.227614423353895,
        "compression_ratio": 1.8741007194244603,
        "end": 2884.6,
        "id": 978,
        "no_speech_prob": 0.000002260323753944249,
        "seek": 288100,
        "start": 2881.68,
        "temperature": 0,
        "text": " with the training data and testing data potentially.",
        "tokens": [
          50398,
          365,
          264,
          3097,
          1412,
          293,
          4997,
          1412,
          7263,
          13,
          50544
        ]
      },
      {
        "avg_logprob": -0.227614423353895,
        "compression_ratio": 1.8741007194244603,
        "end": 2886.68,
        "id": 979,
        "no_speech_prob": 0.000002260323753944249,
        "seek": 288100,
        "start": 2884.6,
        "temperature": 0,
        "text": " But I'm not getting, testing data will come",
        "tokens": [
          50544,
          583,
          286,
          478,
          406,
          1242,
          11,
          4997,
          1412,
          486,
          808,
          50648
        ]
      },
      {
        "avg_logprob": -0.227614423353895,
        "compression_ratio": 1.8741007194244603,
        "end": 2888.8,
        "id": 980,
        "no_speech_prob": 0.000002260323753944249,
        "seek": 288100,
        "start": 2886.68,
        "temperature": 0,
        "text": " in my next video about classification.",
        "tokens": [
          50648,
          294,
          452,
          958,
          960,
          466,
          21538,
          13,
          50754
        ]
      },
      {
        "avg_logprob": -0.227614423353895,
        "compression_ratio": 1.8741007194244603,
        "end": 2890.56,
        "id": 981,
        "no_speech_prob": 0.000002260323753944249,
        "seek": 288100,
        "start": 2888.8,
        "temperature": 0,
        "text": " But here, I'm not making a distinction",
        "tokens": [
          50754,
          583,
          510,
          11,
          286,
          478,
          406,
          1455,
          257,
          16844,
          50842
        ]
      },
      {
        "avg_logprob": -0.227614423353895,
        "compression_ratio": 1.8741007194244603,
        "end": 2891.8,
        "id": 982,
        "no_speech_prob": 0.000002260323753944249,
        "seek": 288100,
        "start": 2890.56,
        "temperature": 0,
        "text": " between training and testing data.",
        "tokens": [
          50842,
          1296,
          3097,
          293,
          4997,
          1412,
          13,
          50904
        ]
      },
      {
        "avg_logprob": -0.227614423353895,
        "compression_ratio": 1.8741007194244603,
        "end": 2893.2,
        "id": 983,
        "no_speech_prob": 0.000002260323753944249,
        "seek": 288100,
        "start": 2891.8,
        "temperature": 0,
        "text": " I'm conflating those two concepts,",
        "tokens": [
          50904,
          286,
          478,
          1497,
          75,
          990,
          729,
          732,
          10392,
          11,
          50974
        ]
      },
      {
        "avg_logprob": -0.227614423353895,
        "compression_ratio": 1.8741007194244603,
        "end": 2895.16,
        "id": 984,
        "no_speech_prob": 0.000002260323753944249,
        "seek": 288100,
        "start": 2893.2,
        "temperature": 0,
        "text": " which is a big mistake and a problem,",
        "tokens": [
          50974,
          597,
          307,
          257,
          955,
          6146,
          293,
          257,
          1154,
          11,
          51072
        ]
      },
      {
        "avg_logprob": -0.227614423353895,
        "compression_ratio": 1.8741007194244603,
        "end": 2897.44,
        "id": 985,
        "no_speech_prob": 0.000002260323753944249,
        "seek": 288100,
        "start": 2895.16,
        "temperature": 0,
        "text": " but we're stepping through this stuff little by little,",
        "tokens": [
          51072,
          457,
          321,
          434,
          16821,
          807,
          341,
          1507,
          707,
          538,
          707,
          11,
          51186
        ]
      },
      {
        "avg_logprob": -0.227614423353895,
        "compression_ratio": 1.8741007194244603,
        "end": 2900.28,
        "id": 986,
        "no_speech_prob": 0.000002260323753944249,
        "seek": 288100,
        "start": 2897.44,
        "temperature": 0,
        "text": " little by little, like a butterfly flapping its wings.",
        "tokens": [
          51186,
          707,
          538,
          707,
          11,
          411,
          257,
          22140,
          283,
          15639,
          1080,
          11405,
          13,
          51328
        ]
      },
      {
        "avg_logprob": -0.227614423353895,
        "compression_ratio": 1.8741007194244603,
        "end": 2902.36,
        "id": 987,
        "no_speech_prob": 0.000002260323753944249,
        "seek": 288100,
        "start": 2901.36,
        "temperature": 0,
        "text": " It's not at all like a butterfly,",
        "tokens": [
          51382,
          467,
          311,
          406,
          412,
          439,
          411,
          257,
          22140,
          11,
          51432
        ]
      },
      {
        "avg_logprob": -0.227614423353895,
        "compression_ratio": 1.8741007194244603,
        "end": 2904.36,
        "id": 988,
        "no_speech_prob": 0.000002260323753944249,
        "seek": 288100,
        "start": 2902.36,
        "temperature": 0,
        "text": " but I felt like I was being like a butterfly.",
        "tokens": [
          51432,
          457,
          286,
          2762,
          411,
          286,
          390,
          885,
          411,
          257,
          22140,
          13,
          51532
        ]
      },
      {
        "avg_logprob": -0.227614423353895,
        "compression_ratio": 1.8741007194244603,
        "end": 2909.36,
        "id": 989,
        "no_speech_prob": 0.000002260323753944249,
        "seek": 288100,
        "start": 2904.36,
        "temperature": 0,
        "text": " And then an optimizer is what sort of function,",
        "tokens": [
          51532,
          400,
          550,
          364,
          5028,
          6545,
          307,
          437,
          1333,
          295,
          2445,
          11,
          51782
        ]
      },
      {
        "avg_logprob": -0.2542154154646287,
        "compression_ratio": 1.6497695852534562,
        "end": 2913.2400000000002,
        "id": 990,
        "no_speech_prob": 0.000269478652626276,
        "seek": 290936,
        "start": 2909.7200000000003,
        "temperature": 0,
        "text": " what sort of algorithm am I using to adjust",
        "tokens": [
          50382,
          437,
          1333,
          295,
          9284,
          669,
          286,
          1228,
          281,
          4369,
          50558
        ]
      },
      {
        "avg_logprob": -0.2542154154646287,
        "compression_ratio": 1.6497695852534562,
        "end": 2915.44,
        "id": 991,
        "no_speech_prob": 0.000269478652626276,
        "seek": 290936,
        "start": 2913.2400000000002,
        "temperature": 0,
        "text": " all of the weights of all these connections",
        "tokens": [
          50558,
          439,
          295,
          264,
          17443,
          295,
          439,
          613,
          9271,
          50668
        ]
      },
      {
        "avg_logprob": -0.2542154154646287,
        "compression_ratio": 1.6497695852534562,
        "end": 2918.32,
        "id": 992,
        "no_speech_prob": 0.000269478652626276,
        "seek": 290936,
        "start": 2915.44,
        "temperature": 0,
        "text": " according to the loss function itself.",
        "tokens": [
          50668,
          4650,
          281,
          264,
          4470,
          2445,
          2564,
          13,
          50812
        ]
      },
      {
        "avg_logprob": -0.2542154154646287,
        "compression_ratio": 1.6497695852534562,
        "end": 2920.08,
        "id": 993,
        "no_speech_prob": 0.000269478652626276,
        "seek": 290936,
        "start": 2918.32,
        "temperature": 0,
        "text": " So I need to define those things.",
        "tokens": [
          50812,
          407,
          286,
          643,
          281,
          6964,
          729,
          721,
          13,
          50900
        ]
      },
      {
        "avg_logprob": -0.2542154154646287,
        "compression_ratio": 1.6497695852534562,
        "end": 2921.2200000000003,
        "id": 994,
        "no_speech_prob": 0.000269478652626276,
        "seek": 290936,
        "start": 2920.08,
        "temperature": 0,
        "text": " I forgot how.",
        "tokens": [
          50900,
          286,
          5298,
          577,
          13,
          50957
        ]
      },
      {
        "avg_logprob": -0.2542154154646287,
        "compression_ratio": 1.6497695852534562,
        "end": 2924.48,
        "id": 995,
        "no_speech_prob": 0.000269478652626276,
        "seek": 290936,
        "start": 2922.48,
        "temperature": 0,
        "text": " I know it's in the thing I made last week,",
        "tokens": [
          51020,
          286,
          458,
          309,
          311,
          294,
          264,
          551,
          286,
          1027,
          1036,
          1243,
          11,
          51120
        ]
      },
      {
        "avg_logprob": -0.2542154154646287,
        "compression_ratio": 1.6497695852534562,
        "end": 2925.6,
        "id": 996,
        "no_speech_prob": 0.000269478652626276,
        "seek": 290936,
        "start": 2924.48,
        "temperature": 0,
        "text": " but this stuff just isn't.",
        "tokens": [
          51120,
          457,
          341,
          1507,
          445,
          1943,
          380,
          13,
          51176
        ]
      },
      {
        "avg_logprob": -0.2542154154646287,
        "compression_ratio": 1.6497695852534562,
        "end": 2928.4,
        "id": 997,
        "no_speech_prob": 0.000269478652626276,
        "seek": 290936,
        "start": 2925.6,
        "temperature": 0,
        "text": " So let me try to type it out how I think it is,",
        "tokens": [
          51176,
          407,
          718,
          385,
          853,
          281,
          2010,
          309,
          484,
          577,
          286,
          519,
          309,
          307,
          11,
          51316
        ]
      },
      {
        "avg_logprob": -0.2542154154646287,
        "compression_ratio": 1.6497695852534562,
        "end": 2929.6,
        "id": 998,
        "no_speech_prob": 0.000269478652626276,
        "seek": 290936,
        "start": 2928.4,
        "temperature": 0,
        "text": " and then we'll go check.",
        "tokens": [
          51316,
          293,
          550,
          321,
          603,
          352,
          1520,
          13,
          51376
        ]
      },
      {
        "avg_logprob": -0.2542154154646287,
        "compression_ratio": 1.6497695852534562,
        "end": 2934.6400000000003,
        "id": 999,
        "no_speech_prob": 0.000269478652626276,
        "seek": 290936,
        "start": 2930.52,
        "temperature": 0,
        "text": " So I know I need to create an optimizer.",
        "tokens": [
          51422,
          407,
          286,
          458,
          286,
          643,
          281,
          1884,
          364,
          5028,
          6545,
          13,
          51628
        ]
      },
      {
        "avg_logprob": -0.2952042715890067,
        "compression_ratio": 1.6761904761904762,
        "end": 2940.64,
        "id": 1000,
        "no_speech_prob": 0.0002571412769611925,
        "seek": 293464,
        "start": 2935.64,
        "temperature": 0,
        "text": " TF optimizer, like this, and with a learning rate.",
        "tokens": [
          50414,
          40964,
          5028,
          6545,
          11,
          411,
          341,
          11,
          293,
          365,
          257,
          2539,
          3314,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.2952042715890067,
        "compression_ratio": 1.6761904761904762,
        "end": 2942.24,
        "id": 1001,
        "no_speech_prob": 0.0002571412769611925,
        "seek": 293464,
        "start": 2941.24,
        "temperature": 0,
        "text": " Something like this.",
        "tokens": [
          50694,
          6595,
          411,
          341,
          13,
          50744
        ]
      },
      {
        "avg_logprob": -0.2952042715890067,
        "compression_ratio": 1.6761904761904762,
        "end": 2946.3199999999997,
        "id": 1002,
        "no_speech_prob": 0.0002571412769611925,
        "seek": 293464,
        "start": 2942.24,
        "temperature": 0,
        "text": " Like I want to have, use stochastic gradient descent",
        "tokens": [
          50744,
          1743,
          286,
          528,
          281,
          362,
          11,
          764,
          342,
          8997,
          2750,
          16235,
          23475,
          50948
        ]
      },
      {
        "avg_logprob": -0.2952042715890067,
        "compression_ratio": 1.6761904761904762,
        "end": 2947.16,
        "id": 1003,
        "no_speech_prob": 0.0002571412769611925,
        "seek": 293464,
        "start": 2946.3199999999997,
        "temperature": 0,
        "text": " with some learning rate.",
        "tokens": [
          50948,
          365,
          512,
          2539,
          3314,
          13,
          50990
        ]
      },
      {
        "avg_logprob": -0.2952042715890067,
        "compression_ratio": 1.6761904761904762,
        "end": 2948.1,
        "id": 1004,
        "no_speech_prob": 0.0002571412769611925,
        "seek": 293464,
        "start": 2947.16,
        "temperature": 0,
        "text": " That's not correct.",
        "tokens": [
          50990,
          663,
          311,
          406,
          3006,
          13,
          51037
        ]
      },
      {
        "avg_logprob": -0.2952042715890067,
        "compression_ratio": 1.6761904761904762,
        "end": 2952.4,
        "id": 1005,
        "no_speech_prob": 0.0002571412769611925,
        "seek": 293464,
        "start": 2948.1,
        "temperature": 0,
        "text": " This is me like trying to remember what the code is.",
        "tokens": [
          51037,
          639,
          307,
          385,
          411,
          1382,
          281,
          1604,
          437,
          264,
          3089,
          307,
          13,
          51252
        ]
      },
      {
        "avg_logprob": -0.2952042715890067,
        "compression_ratio": 1.6761904761904762,
        "end": 2956.48,
        "id": 1006,
        "no_speech_prob": 0.0002571412769611925,
        "seek": 293464,
        "start": 2952.4,
        "temperature": 0,
        "text": " And then I need to say like model.compile.",
        "tokens": [
          51252,
          400,
          550,
          286,
          643,
          281,
          584,
          411,
          2316,
          13,
          21541,
          794,
          13,
          51456
        ]
      },
      {
        "avg_logprob": -0.2952042715890067,
        "compression_ratio": 1.6761904761904762,
        "end": 2958.24,
        "id": 1007,
        "no_speech_prob": 0.0002571412769611925,
        "seek": 293464,
        "start": 2956.48,
        "temperature": 0,
        "text": " And then I think when I compile it,",
        "tokens": [
          51456,
          400,
          550,
          286,
          519,
          562,
          286,
          31413,
          309,
          11,
          51544
        ]
      },
      {
        "avg_logprob": -0.2952042715890067,
        "compression_ratio": 1.6761904761904762,
        "end": 2961.2999999999997,
        "id": 1008,
        "no_speech_prob": 0.0002571412769611925,
        "seek": 293464,
        "start": 2958.24,
        "temperature": 0,
        "text": " I'll say things like this, I'm going to compile it",
        "tokens": [
          51544,
          286,
          603,
          584,
          721,
          411,
          341,
          11,
          286,
          478,
          516,
          281,
          31413,
          309,
          51697
        ]
      },
      {
        "avg_logprob": -0.2265566059800445,
        "compression_ratio": 1.6693877551020408,
        "end": 2964.3,
        "id": 1009,
        "no_speech_prob": 0.000014285506949818227,
        "seek": 296130,
        "start": 2961.3,
        "temperature": 0,
        "text": " with this optimizer and this loss function",
        "tokens": [
          50364,
          365,
          341,
          5028,
          6545,
          293,
          341,
          4470,
          2445,
          50514
        ]
      },
      {
        "avg_logprob": -0.2265566059800445,
        "compression_ratio": 1.6693877551020408,
        "end": 2969.3,
        "id": 1010,
        "no_speech_prob": 0.000014285506949818227,
        "seek": 296130,
        "start": 2964.3,
        "temperature": 0,
        "text": " like root mean squared or something like that.",
        "tokens": [
          50514,
          411,
          5593,
          914,
          8889,
          420,
          746,
          411,
          300,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.2265566059800445,
        "compression_ratio": 1.6693877551020408,
        "end": 2972.94,
        "id": 1011,
        "no_speech_prob": 0.000014285506949818227,
        "seek": 296130,
        "start": 2970.46,
        "temperature": 0,
        "text": " So this is what I'm remembering from when I looked at this",
        "tokens": [
          50822,
          407,
          341,
          307,
          437,
          286,
          478,
          20719,
          490,
          562,
          286,
          2956,
          412,
          341,
          50946
        ]
      },
      {
        "avg_logprob": -0.2265566059800445,
        "compression_ratio": 1.6693877551020408,
        "end": 2974.42,
        "id": 1012,
        "no_speech_prob": 0.000014285506949818227,
        "seek": 296130,
        "start": 2972.94,
        "temperature": 0,
        "text": " at one time, and I probably got this wrong.",
        "tokens": [
          50946,
          412,
          472,
          565,
          11,
          293,
          286,
          1391,
          658,
          341,
          2085,
          13,
          51020
        ]
      },
      {
        "avg_logprob": -0.2265566059800445,
        "compression_ratio": 1.6693877551020408,
        "end": 2976.9,
        "id": 1013,
        "no_speech_prob": 0.000014285506949818227,
        "seek": 296130,
        "start": 2974.42,
        "temperature": 0,
        "text": " So let's actually go look at the API docs.",
        "tokens": [
          51020,
          407,
          718,
          311,
          767,
          352,
          574,
          412,
          264,
          9362,
          45623,
          13,
          51144
        ]
      },
      {
        "avg_logprob": -0.2265566059800445,
        "compression_ratio": 1.6693877551020408,
        "end": 2978.6600000000003,
        "id": 1014,
        "no_speech_prob": 0.000014285506949818227,
        "seek": 296130,
        "start": 2976.9,
        "temperature": 0,
        "text": " Well, first, what's the chance that any of this",
        "tokens": [
          51144,
          1042,
          11,
          700,
          11,
          437,
          311,
          264,
          2931,
          300,
          604,
          295,
          341,
          51232
        ]
      },
      {
        "avg_logprob": -0.2265566059800445,
        "compression_ratio": 1.6693877551020408,
        "end": 2979.7400000000002,
        "id": 1015,
        "no_speech_prob": 0.000014285506949818227,
        "seek": 296130,
        "start": 2978.6600000000003,
        "temperature": 0,
        "text": " actually makes sense?",
        "tokens": [
          51232,
          767,
          1669,
          2020,
          30,
          51286
        ]
      },
      {
        "avg_logprob": -0.2265566059800445,
        "compression_ratio": 1.6693877551020408,
        "end": 2981.5,
        "id": 1016,
        "no_speech_prob": 0.000014285506949818227,
        "seek": 296130,
        "start": 2979.7400000000002,
        "temperature": 0,
        "text": " Okay, TF optimizer is not a function.",
        "tokens": [
          51286,
          1033,
          11,
          40964,
          5028,
          6545,
          307,
          406,
          257,
          2445,
          13,
          51374
        ]
      },
      {
        "avg_logprob": -0.2265566059800445,
        "compression_ratio": 1.6693877551020408,
        "end": 2984.26,
        "id": 1017,
        "no_speech_prob": 0.000014285506949818227,
        "seek": 296130,
        "start": 2981.5,
        "temperature": 0,
        "text": " So let's see, how do we create the optimizer?",
        "tokens": [
          51374,
          407,
          718,
          311,
          536,
          11,
          577,
          360,
          321,
          1884,
          264,
          5028,
          6545,
          30,
          51512
        ]
      },
      {
        "avg_logprob": -0.2265566059800445,
        "compression_ratio": 1.6693877551020408,
        "end": 2985.94,
        "id": 1018,
        "no_speech_prob": 0.000014285506949818227,
        "seek": 296130,
        "start": 2984.26,
        "temperature": 0,
        "text": " Optimizer.",
        "tokens": [
          51512,
          35013,
          6545,
          13,
          51596
        ]
      },
      {
        "avg_logprob": -0.2265566059800445,
        "compression_ratio": 1.6693877551020408,
        "end": 2990.1800000000003,
        "id": 1019,
        "no_speech_prob": 0.000014285506949818227,
        "seek": 296130,
        "start": 2989.34,
        "temperature": 0,
        "text": " Ah, yes.",
        "tokens": [
          51766,
          2438,
          11,
          2086,
          13,
          51808
        ]
      },
      {
        "avg_logprob": -0.21363018899068345,
        "compression_ratio": 1.6743119266055047,
        "end": 2992.06,
        "id": 1020,
        "no_speech_prob": 0.000021112415197421797,
        "seek": 299018,
        "start": 2990.18,
        "temperature": 0,
        "text": " So this is what I want.",
        "tokens": [
          50364,
          407,
          341,
          307,
          437,
          286,
          528,
          13,
          50458
        ]
      },
      {
        "avg_logprob": -0.21363018899068345,
        "compression_ratio": 1.6743119266055047,
        "end": 2995.1,
        "id": 1021,
        "no_speech_prob": 0.000021112415197421797,
        "seek": 299018,
        "start": 2992.06,
        "temperature": 0,
        "text": " I want a tf.train.sgd.",
        "tokens": [
          50458,
          286,
          528,
          257,
          256,
          69,
          13,
          83,
          7146,
          13,
          82,
          70,
          67,
          13,
          50610
        ]
      },
      {
        "avg_logprob": -0.21363018899068345,
        "compression_ratio": 1.6743119266055047,
        "end": 2996.22,
        "id": 1022,
        "no_speech_prob": 0.000021112415197421797,
        "seek": 299018,
        "start": 2995.1,
        "temperature": 0,
        "text": " This is how I create the other.",
        "tokens": [
          50610,
          639,
          307,
          577,
          286,
          1884,
          264,
          661,
          13,
          50666
        ]
      },
      {
        "avg_logprob": -0.21363018899068345,
        "compression_ratio": 1.6743119266055047,
        "end": 2999.1,
        "id": 1023,
        "no_speech_prob": 0.000021112415197421797,
        "seek": 299018,
        "start": 2996.22,
        "temperature": 0,
        "text": " Optimizer is not a key word in the API.",
        "tokens": [
          50666,
          35013,
          6545,
          307,
          406,
          257,
          2141,
          1349,
          294,
          264,
          9362,
          13,
          50810
        ]
      },
      {
        "avg_logprob": -0.21363018899068345,
        "compression_ratio": 1.6743119266055047,
        "end": 3001.04,
        "id": 1024,
        "no_speech_prob": 0.000021112415197421797,
        "seek": 299018,
        "start": 2999.1,
        "temperature": 0,
        "text": " I just, I imagined that for myself.",
        "tokens": [
          50810,
          286,
          445,
          11,
          286,
          16590,
          300,
          337,
          2059,
          13,
          50907
        ]
      },
      {
        "avg_logprob": -0.21363018899068345,
        "compression_ratio": 1.6743119266055047,
        "end": 3003.62,
        "id": 1025,
        "no_speech_prob": 0.000021112415197421797,
        "seek": 299018,
        "start": 3001.04,
        "temperature": 0,
        "text": " So I need to say tf.train.sgd",
        "tokens": [
          50907,
          407,
          286,
          643,
          281,
          584,
          256,
          69,
          13,
          83,
          7146,
          13,
          82,
          70,
          67,
          51036
        ]
      },
      {
        "avg_logprob": -0.21363018899068345,
        "compression_ratio": 1.6743119266055047,
        "end": 3005.46,
        "id": 1026,
        "no_speech_prob": 0.000021112415197421797,
        "seek": 299018,
        "start": 3003.62,
        "temperature": 0,
        "text": " and then give it a learning rate.",
        "tokens": [
          51036,
          293,
          550,
          976,
          309,
          257,
          2539,
          3314,
          13,
          51128
        ]
      },
      {
        "avg_logprob": -0.21363018899068345,
        "compression_ratio": 1.6743119266055047,
        "end": 3008.22,
        "id": 1027,
        "no_speech_prob": 0.000021112415197421797,
        "seek": 299018,
        "start": 3005.46,
        "temperature": 0,
        "text": " So tf.train.sgd.",
        "tokens": [
          51128,
          407,
          256,
          69,
          13,
          83,
          7146,
          13,
          82,
          70,
          67,
          13,
          51266
        ]
      },
      {
        "avg_logprob": -0.21363018899068345,
        "compression_ratio": 1.6743119266055047,
        "end": 3010.54,
        "id": 1028,
        "no_speech_prob": 0.000021112415197421797,
        "seek": 299018,
        "start": 3008.22,
        "temperature": 0,
        "text": " And there are other kinds of optimizers",
        "tokens": [
          51266,
          400,
          456,
          366,
          661,
          3685,
          295,
          5028,
          22525,
          51382
        ]
      },
      {
        "avg_logprob": -0.21363018899068345,
        "compression_ratio": 1.6743119266055047,
        "end": 3013.62,
        "id": 1029,
        "no_speech_prob": 0.000021112415197421797,
        "seek": 299018,
        "start": 3010.54,
        "temperature": 0,
        "text": " that I think I've even shown you and we'll use more",
        "tokens": [
          51382,
          300,
          286,
          519,
          286,
          600,
          754,
          4898,
          291,
          293,
          321,
          603,
          764,
          544,
          51536
        ]
      },
      {
        "avg_logprob": -0.21363018899068345,
        "compression_ratio": 1.6743119266055047,
        "end": 3016.22,
        "id": 1030,
        "no_speech_prob": 0.000021112415197421797,
        "seek": 299018,
        "start": 3013.62,
        "temperature": 0,
        "text": " and give it a learning rate like 0.1.",
        "tokens": [
          51536,
          293,
          976,
          309,
          257,
          2539,
          3314,
          411,
          1958,
          13,
          16,
          13,
          51666
        ]
      },
      {
        "avg_logprob": -0.23567733479969538,
        "compression_ratio": 1.689922480620155,
        "end": 3020.8199999999997,
        "id": 1031,
        "no_speech_prob": 0.000001191107685372117,
        "seek": 301622,
        "start": 3016.22,
        "temperature": 0,
        "text": " Then I want to look at model.compile.",
        "tokens": [
          50364,
          1396,
          286,
          528,
          281,
          574,
          412,
          2316,
          13,
          21541,
          794,
          13,
          50594
        ]
      },
      {
        "avg_logprob": -0.23567733479969538,
        "compression_ratio": 1.689922480620155,
        "end": 3025.8199999999997,
        "id": 1032,
        "no_speech_prob": 0.000001191107685372117,
        "seek": 301622,
        "start": 3022.3799999999997,
        "temperature": 0,
        "text": " So let's look for compile.",
        "tokens": [
          50672,
          407,
          718,
          311,
          574,
          337,
          31413,
          13,
          50844
        ]
      },
      {
        "avg_logprob": -0.23567733479969538,
        "compression_ratio": 1.689922480620155,
        "end": 3027.3999999999996,
        "id": 1033,
        "no_speech_prob": 0.000001191107685372117,
        "seek": 301622,
        "start": 3025.8199999999997,
        "temperature": 0,
        "text": " Well, we can see in some examples here.",
        "tokens": [
          50844,
          1042,
          11,
          321,
          393,
          536,
          294,
          512,
          5110,
          510,
          13,
          50923
        ]
      },
      {
        "avg_logprob": -0.23567733479969538,
        "compression_ratio": 1.689922480620155,
        "end": 3031.5,
        "id": 1034,
        "no_speech_prob": 0.000001191107685372117,
        "seek": 301622,
        "start": 3027.3999999999996,
        "temperature": 0,
        "text": " What I'm looking for is where the actual compile,",
        "tokens": [
          50923,
          708,
          286,
          478,
          1237,
          337,
          307,
          689,
          264,
          3539,
          31413,
          11,
          51128
        ]
      },
      {
        "avg_logprob": -0.23567733479969538,
        "compression_ratio": 1.689922480620155,
        "end": 3032.62,
        "id": 1035,
        "no_speech_prob": 0.000001191107685372117,
        "seek": 301622,
        "start": 3031.5,
        "temperature": 0,
        "text": " there it is, compile.",
        "tokens": [
          51128,
          456,
          309,
          307,
          11,
          31413,
          13,
          51184
        ]
      },
      {
        "avg_logprob": -0.23567733479969538,
        "compression_ratio": 1.689922480620155,
        "end": 3035.3799999999997,
        "id": 1036,
        "no_speech_prob": 0.000001191107685372117,
        "seek": 301622,
        "start": 3033.7,
        "temperature": 0,
        "text": " So the compile function compiles it",
        "tokens": [
          51238,
          407,
          264,
          31413,
          2445,
          715,
          4680,
          309,
          51322
        ]
      },
      {
        "avg_logprob": -0.23567733479969538,
        "compression_ratio": 1.689922480620155,
        "end": 3037.14,
        "id": 1037,
        "no_speech_prob": 0.000001191107685372117,
        "seek": 301622,
        "start": 3035.3799999999997,
        "temperature": 0,
        "text": " and give an optimizer a loss.",
        "tokens": [
          51322,
          293,
          976,
          364,
          5028,
          6545,
          257,
          4470,
          13,
          51410
        ]
      },
      {
        "avg_logprob": -0.23567733479969538,
        "compression_ratio": 1.689922480620155,
        "end": 3038.8199999999997,
        "id": 1038,
        "no_speech_prob": 0.000001191107685372117,
        "seek": 301622,
        "start": 3037.14,
        "temperature": 0,
        "text": " And I can also do some metric stuff.",
        "tokens": [
          51410,
          400,
          286,
          393,
          611,
          360,
          512,
          20678,
          1507,
          13,
          51494
        ]
      },
      {
        "avg_logprob": -0.23567733479969538,
        "compression_ratio": 1.689922480620155,
        "end": 3040.3999999999996,
        "id": 1039,
        "no_speech_prob": 0.000001191107685372117,
        "seek": 301622,
        "start": 3038.8199999999997,
        "temperature": 0,
        "text": " I'm not going to worry about the metrics too much,",
        "tokens": [
          51494,
          286,
          478,
          406,
          516,
          281,
          3292,
          466,
          264,
          16367,
          886,
          709,
          11,
          51573
        ]
      },
      {
        "avg_logprob": -0.23567733479969538,
        "compression_ratio": 1.689922480620155,
        "end": 3041.8999999999996,
        "id": 1040,
        "no_speech_prob": 0.000001191107685372117,
        "seek": 301622,
        "start": 3040.3999999999996,
        "temperature": 0,
        "text": " although maybe I'll try to come back",
        "tokens": [
          51573,
          4878,
          1310,
          286,
          603,
          853,
          281,
          808,
          646,
          51648
        ]
      },
      {
        "avg_logprob": -0.23567733479969538,
        "compression_ratio": 1.689922480620155,
        "end": 3042.8599999999997,
        "id": 1041,
        "no_speech_prob": 0.000001191107685372117,
        "seek": 301622,
        "start": 3041.8999999999996,
        "temperature": 0,
        "text": " towards the end of this video.",
        "tokens": [
          51648,
          3030,
          264,
          917,
          295,
          341,
          960,
          13,
          51696
        ]
      },
      {
        "avg_logprob": -0.23567733479969538,
        "compression_ratio": 1.689922480620155,
        "end": 3045.54,
        "id": 1042,
        "no_speech_prob": 0.000001191107685372117,
        "seek": 301622,
        "start": 3042.8599999999997,
        "temperature": 0,
        "text": " Okay, model.compile, optimizer, loss.",
        "tokens": [
          51696,
          1033,
          11,
          2316,
          13,
          21541,
          794,
          11,
          5028,
          6545,
          11,
          4470,
          13,
          51830
        ]
      },
      {
        "avg_logprob": -0.41925062073601616,
        "compression_ratio": 1.4,
        "end": 3047.06,
        "id": 1043,
        "no_speech_prob": 0.00012731085007544607,
        "seek": 304554,
        "start": 3045.54,
        "temperature": 0,
        "text": " I think this might actually be fine.",
        "tokens": [
          50364,
          286,
          519,
          341,
          1062,
          767,
          312,
          2489,
          13,
          50440
        ]
      },
      {
        "avg_logprob": -0.41925062073601616,
        "compression_ratio": 1.4,
        "end": 3048.46,
        "id": 1044,
        "no_speech_prob": 0.00012731085007544607,
        "seek": 304554,
        "start": 3047.06,
        "temperature": 0,
        "text": " Is it root mean squared?",
        "tokens": [
          50440,
          1119,
          309,
          5593,
          914,
          8889,
          30,
          50510
        ]
      },
      {
        "avg_logprob": -0.41925062073601616,
        "compression_ratio": 1.4,
        "end": 3050.4,
        "id": 1045,
        "no_speech_prob": 0.00012731085007544607,
        "seek": 304554,
        "start": 3048.46,
        "temperature": 0,
        "text": " So let's look for the loss functions.",
        "tokens": [
          50510,
          407,
          718,
          311,
          574,
          337,
          264,
          4470,
          6828,
          13,
          50607
        ]
      },
      {
        "avg_logprob": -0.41925062073601616,
        "compression_ratio": 1.4,
        "end": 3057.9,
        "id": 1046,
        "no_speech_prob": 0.00012731085007544607,
        "seek": 304554,
        "start": 3052.9,
        "temperature": 0,
        "text": " Loss, root mean, mean squared.",
        "tokens": [
          50732,
          441,
          772,
          11,
          5593,
          914,
          11,
          914,
          8889,
          13,
          50982
        ]
      },
      {
        "avg_logprob": -0.41925062073601616,
        "compression_ratio": 1.4,
        "end": 3062.38,
        "id": 1047,
        "no_speech_prob": 0.00012731085007544607,
        "seek": 304554,
        "start": 3060.02,
        "temperature": 0,
        "text": " Oh, why did I, I keep saying root.",
        "tokens": [
          51088,
          876,
          11,
          983,
          630,
          286,
          11,
          286,
          1066,
          1566,
          5593,
          13,
          51206
        ]
      },
      {
        "avg_logprob": -0.41925062073601616,
        "compression_ratio": 1.4,
        "end": 3070.22,
        "id": 1048,
        "no_speech_prob": 0.00012731085007544607,
        "seek": 304554,
        "start": 3068.22,
        "temperature": 0,
        "text": " I'm on the floor lying down.",
        "tokens": [
          51498,
          286,
          478,
          322,
          264,
          4123,
          8493,
          760,
          13,
          51598
        ]
      },
      {
        "avg_logprob": -0.41925062073601616,
        "compression_ratio": 1.4,
        "end": 3072.86,
        "id": 1049,
        "no_speech_prob": 0.00012731085007544607,
        "seek": 304554,
        "start": 3071.14,
        "temperature": 0,
        "text": " Is that so sad?",
        "tokens": [
          51644,
          1119,
          300,
          370,
          4227,
          30,
          51730
        ]
      },
      {
        "avg_logprob": -0.2831185184307952,
        "compression_ratio": 1.7121771217712176,
        "end": 3075.7400000000002,
        "id": 1050,
        "no_speech_prob": 0.00009461245645070449,
        "seek": 307286,
        "start": 3072.86,
        "temperature": 0,
        "text": " I said root because I have it in my head",
        "tokens": [
          50364,
          286,
          848,
          5593,
          570,
          286,
          362,
          309,
          294,
          452,
          1378,
          50508
        ]
      },
      {
        "avg_logprob": -0.2831185184307952,
        "compression_ratio": 1.7121771217712176,
        "end": 3078.7000000000003,
        "id": 1051,
        "no_speech_prob": 0.00009461245645070449,
        "seek": 307286,
        "start": 3075.7400000000002,
        "temperature": 0,
        "text": " from something that I did a very long time ago",
        "tokens": [
          50508,
          490,
          746,
          300,
          286,
          630,
          257,
          588,
          938,
          565,
          2057,
          50656
        ]
      },
      {
        "avg_logprob": -0.2831185184307952,
        "compression_ratio": 1.7121771217712176,
        "end": 3081.6600000000003,
        "id": 1052,
        "no_speech_prob": 0.00009461245645070449,
        "seek": 307286,
        "start": 3078.7000000000003,
        "temperature": 0,
        "text": " where I was always taking the square root",
        "tokens": [
          50656,
          689,
          286,
          390,
          1009,
          1940,
          264,
          3732,
          5593,
          50804
        ]
      },
      {
        "avg_logprob": -0.2831185184307952,
        "compression_ratio": 1.7121771217712176,
        "end": 3082.9,
        "id": 1053,
        "no_speech_prob": 0.00009461245645070449,
        "seek": 307286,
        "start": 3081.6600000000003,
        "temperature": 0,
        "text": " of the mean squared error.",
        "tokens": [
          50804,
          295,
          264,
          914,
          8889,
          6713,
          13,
          50866
        ]
      },
      {
        "avg_logprob": -0.2831185184307952,
        "compression_ratio": 1.7121771217712176,
        "end": 3084.34,
        "id": 1054,
        "no_speech_prob": 0.00009461245645070449,
        "seek": 307286,
        "start": 3082.9,
        "temperature": 0,
        "text": " So I always say root mean squared.",
        "tokens": [
          50866,
          407,
          286,
          1009,
          584,
          5593,
          914,
          8889,
          13,
          50938
        ]
      },
      {
        "avg_logprob": -0.2831185184307952,
        "compression_ratio": 1.7121771217712176,
        "end": 3085.94,
        "id": 1055,
        "no_speech_prob": 0.00009461245645070449,
        "seek": 307286,
        "start": 3084.34,
        "temperature": 0,
        "text": " There's no root here involved.",
        "tokens": [
          50938,
          821,
          311,
          572,
          5593,
          510,
          3288,
          13,
          51018
        ]
      },
      {
        "avg_logprob": -0.2831185184307952,
        "compression_ratio": 1.7121771217712176,
        "end": 3092.1,
        "id": 1056,
        "no_speech_prob": 0.00009461245645070449,
        "seek": 307286,
        "start": 3089.3,
        "temperature": 0,
        "text": " I guess I have to get back up and continue this tutorial.",
        "tokens": [
          51186,
          286,
          2041,
          286,
          362,
          281,
          483,
          646,
          493,
          293,
          2354,
          341,
          7073,
          13,
          51326
        ]
      },
      {
        "avg_logprob": -0.2831185184307952,
        "compression_ratio": 1.7121771217712176,
        "end": 3095.42,
        "id": 1057,
        "no_speech_prob": 0.00009461245645070449,
        "seek": 307286,
        "start": 3093.4,
        "temperature": 0,
        "text": " How long was I saying root for?",
        "tokens": [
          51391,
          1012,
          938,
          390,
          286,
          1566,
          5593,
          337,
          30,
          51492
        ]
      },
      {
        "avg_logprob": -0.2831185184307952,
        "compression_ratio": 1.7121771217712176,
        "end": 3096.7400000000002,
        "id": 1058,
        "no_speech_prob": 0.00009461245645070449,
        "seek": 307286,
        "start": 3095.42,
        "temperature": 0,
        "text": " How annoying will that be for the people",
        "tokens": [
          51492,
          1012,
          11304,
          486,
          300,
          312,
          337,
          264,
          561,
          51558
        ]
      },
      {
        "avg_logprob": -0.2831185184307952,
        "compression_ratio": 1.7121771217712176,
        "end": 3097.9,
        "id": 1059,
        "no_speech_prob": 0.00009461245645070449,
        "seek": 307286,
        "start": 3096.7400000000002,
        "temperature": 0,
        "text": " who watch this later?",
        "tokens": [
          51558,
          567,
          1159,
          341,
          1780,
          30,
          51616
        ]
      },
      {
        "avg_logprob": -0.2831185184307952,
        "compression_ratio": 1.7121771217712176,
        "end": 3100.78,
        "id": 1060,
        "no_speech_prob": 0.00009461245645070449,
        "seek": 307286,
        "start": 3098.78,
        "temperature": 0,
        "text": " Okay, whoop, don't, you know, I have to get up slowly",
        "tokens": [
          51660,
          1033,
          11,
          567,
          404,
          11,
          500,
          380,
          11,
          291,
          458,
          11,
          286,
          362,
          281,
          483,
          493,
          5692,
          51760
        ]
      },
      {
        "avg_logprob": -0.2831185184307952,
        "compression_ratio": 1.7121771217712176,
        "end": 3102.48,
        "id": 1061,
        "no_speech_prob": 0.00009461245645070449,
        "seek": 307286,
        "start": 3100.78,
        "temperature": 0,
        "text": " or else I get kind of lightheaded.",
        "tokens": [
          51760,
          420,
          1646,
          286,
          483,
          733,
          295,
          1442,
          28409,
          13,
          51845
        ]
      },
      {
        "avg_logprob": -0.21658869656649501,
        "compression_ratio": 1.6419213973799127,
        "end": 3105.3,
        "id": 1062,
        "no_speech_prob": 0.000022827982320450246,
        "seek": 310286,
        "start": 3103.86,
        "temperature": 0,
        "text": " All right, apologies.",
        "tokens": [
          50414,
          1057,
          558,
          11,
          34929,
          13,
          50486
        ]
      },
      {
        "avg_logprob": -0.21658869656649501,
        "compression_ratio": 1.6419213973799127,
        "end": 3108.2200000000003,
        "id": 1063,
        "no_speech_prob": 0.000022827982320450246,
        "seek": 310286,
        "start": 3105.3,
        "temperature": 0,
        "text": " I've been saying root mean squared error",
        "tokens": [
          50486,
          286,
          600,
          668,
          1566,
          5593,
          914,
          8889,
          6713,
          50632
        ]
      },
      {
        "avg_logprob": -0.21658869656649501,
        "compression_ratio": 1.6419213973799127,
        "end": 3110.46,
        "id": 1064,
        "no_speech_prob": 0.000022827982320450246,
        "seek": 310286,
        "start": 3108.2200000000003,
        "temperature": 0,
        "text": " because I'm stuck in this world",
        "tokens": [
          50632,
          570,
          286,
          478,
          5541,
          294,
          341,
          1002,
          50744
        ]
      },
      {
        "avg_logprob": -0.21658869656649501,
        "compression_ratio": 1.6419213973799127,
        "end": 3111.5,
        "id": 1065,
        "no_speech_prob": 0.000022827982320450246,
        "seek": 310286,
        "start": 3110.46,
        "temperature": 0,
        "text": " where you have to take the square root",
        "tokens": [
          50744,
          689,
          291,
          362,
          281,
          747,
          264,
          3732,
          5593,
          50796
        ]
      },
      {
        "avg_logprob": -0.21658869656649501,
        "compression_ratio": 1.6419213973799127,
        "end": 3112.6600000000003,
        "id": 1066,
        "no_speech_prob": 0.000022827982320450246,
        "seek": 310286,
        "start": 3111.5,
        "temperature": 0,
        "text": " which you don't need to do here.",
        "tokens": [
          50796,
          597,
          291,
          500,
          380,
          643,
          281,
          360,
          510,
          13,
          50854
        ]
      },
      {
        "avg_logprob": -0.21658869656649501,
        "compression_ratio": 1.6419213973799127,
        "end": 3115.1800000000003,
        "id": 1067,
        "no_speech_prob": 0.000022827982320450246,
        "seek": 310286,
        "start": 3112.6600000000003,
        "temperature": 0,
        "text": " So just mean squared error, that's all I need.",
        "tokens": [
          50854,
          407,
          445,
          914,
          8889,
          6713,
          11,
          300,
          311,
          439,
          286,
          643,
          13,
          50980
        ]
      },
      {
        "avg_logprob": -0.21658869656649501,
        "compression_ratio": 1.6419213973799127,
        "end": 3120.1800000000003,
        "id": 1068,
        "no_speech_prob": 0.000022827982320450246,
        "seek": 310286,
        "start": 3115.1800000000003,
        "temperature": 0,
        "text": " This is my loss function, mean squared error.",
        "tokens": [
          50980,
          639,
          307,
          452,
          4470,
          2445,
          11,
          914,
          8889,
          6713,
          13,
          51230
        ]
      },
      {
        "avg_logprob": -0.21658869656649501,
        "compression_ratio": 1.6419213973799127,
        "end": 3126.1400000000003,
        "id": 1069,
        "no_speech_prob": 0.000022827982320450246,
        "seek": 310286,
        "start": 3121.1400000000003,
        "temperature": 0,
        "text": " Now, let us now go back here, hit refresh.",
        "tokens": [
          51278,
          823,
          11,
          718,
          505,
          586,
          352,
          646,
          510,
          11,
          2045,
          15134,
          13,
          51528
        ]
      },
      {
        "avg_logprob": -0.21658869656649501,
        "compression_ratio": 1.6419213973799127,
        "end": 3129.88,
        "id": 1070,
        "no_speech_prob": 0.000022827982320450246,
        "seek": 310286,
        "start": 3127.8,
        "temperature": 0,
        "text": " All right, things are happening, things are going.",
        "tokens": [
          51611,
          1057,
          558,
          11,
          721,
          366,
          2737,
          11,
          721,
          366,
          516,
          13,
          51715
        ]
      },
      {
        "avg_logprob": -0.21658869656649501,
        "compression_ratio": 1.6419213973799127,
        "end": 3132.54,
        "id": 1071,
        "no_speech_prob": 0.000022827982320450246,
        "seek": 310286,
        "start": 3129.88,
        "temperature": 0,
        "text": " So the model is built.",
        "tokens": [
          51715,
          407,
          264,
          2316,
          307,
          3094,
          13,
          51848
        ]
      },
      {
        "avg_logprob": -0.33942871762995136,
        "compression_ratio": 1.35,
        "end": 3135.98,
        "id": 1072,
        "no_speech_prob": 0.00000813968654256314,
        "seek": 313254,
        "start": 3133.22,
        "temperature": 0,
        "text": " The model is compiled and the next thing",
        "tokens": [
          50398,
          440,
          2316,
          307,
          36548,
          293,
          264,
          958,
          551,
          50536
        ]
      },
      {
        "avg_logprob": -0.33942871762995136,
        "compression_ratio": 1.35,
        "end": 3138.46,
        "id": 1073,
        "no_speech_prob": 0.00000813968654256314,
        "seek": 313254,
        "start": 3135.98,
        "temperature": 0,
        "text": " that I am ready to do is now actually",
        "tokens": [
          50536,
          300,
          286,
          669,
          1919,
          281,
          360,
          307,
          586,
          767,
          50660
        ]
      },
      {
        "avg_logprob": -0.33942871762995136,
        "compression_ratio": 1.35,
        "end": 3140.74,
        "id": 1074,
        "no_speech_prob": 0.00000813968654256314,
        "seek": 313254,
        "start": 3138.46,
        "temperature": 0,
        "text": " start putting data in the model.",
        "tokens": [
          50660,
          722,
          3372,
          1412,
          294,
          264,
          2316,
          13,
          50774
        ]
      },
      {
        "avg_logprob": -0.33942871762995136,
        "compression_ratio": 1.35,
        "end": 3145.14,
        "id": 1075,
        "no_speech_prob": 0.00000813968654256314,
        "seek": 313254,
        "start": 3143.08,
        "temperature": 0,
        "text": " Time out for a second, why did I lose?",
        "tokens": [
          50891,
          6161,
          484,
          337,
          257,
          1150,
          11,
          983,
          630,
          286,
          3624,
          30,
          50994
        ]
      },
      {
        "avg_logprob": -0.33942871762995136,
        "compression_ratio": 1.35,
        "end": 3157.5,
        "id": 1076,
        "no_speech_prob": 0.00000813968654256314,
        "seek": 313254,
        "start": 3155.38,
        "temperature": 0,
        "text": " All right, just give me a second here.",
        "tokens": [
          51506,
          1057,
          558,
          11,
          445,
          976,
          385,
          257,
          1150,
          510,
          13,
          51612
        ]
      },
      {
        "avg_logprob": -0.3217923033471201,
        "compression_ratio": 1.731958762886598,
        "end": 3162.66,
        "id": 1077,
        "no_speech_prob": 0.00004400109173730016,
        "seek": 315750,
        "start": 3157.66,
        "temperature": 0,
        "text": " I really have to watch the time.",
        "tokens": [
          50372,
          286,
          534,
          362,
          281,
          1159,
          264,
          565,
          13,
          50622
        ]
      },
      {
        "avg_logprob": -0.3217923033471201,
        "compression_ratio": 1.731958762886598,
        "end": 3165.22,
        "id": 1078,
        "no_speech_prob": 0.00004400109173730016,
        "seek": 315750,
        "start": 3163.74,
        "temperature": 0,
        "text": " I've got an hour.",
        "tokens": [
          50676,
          286,
          600,
          658,
          364,
          1773,
          13,
          50750
        ]
      },
      {
        "avg_logprob": -0.3217923033471201,
        "compression_ratio": 1.731958762886598,
        "end": 3168.02,
        "id": 1079,
        "no_speech_prob": 0.00004400109173730016,
        "seek": 315750,
        "start": 3165.22,
        "temperature": 0,
        "text": " I have to be at Little League practice.",
        "tokens": [
          50750,
          286,
          362,
          281,
          312,
          412,
          8022,
          11199,
          3124,
          13,
          50890
        ]
      },
      {
        "avg_logprob": -0.3217923033471201,
        "compression_ratio": 1.731958762886598,
        "end": 3171.66,
        "id": 1080,
        "no_speech_prob": 0.00004400109173730016,
        "seek": 315750,
        "start": 3168.02,
        "temperature": 0,
        "text": " I am not a strange 44 year old person",
        "tokens": [
          50890,
          286,
          669,
          406,
          257,
          5861,
          16408,
          1064,
          1331,
          954,
          51072
        ]
      },
      {
        "avg_logprob": -0.3217923033471201,
        "compression_ratio": 1.731958762886598,
        "end": 3173.62,
        "id": 1081,
        "no_speech_prob": 0.00004400109173730016,
        "seek": 315750,
        "start": 3171.66,
        "temperature": 0,
        "text": " who plays in Little League but my son",
        "tokens": [
          51072,
          567,
          5749,
          294,
          8022,
          11199,
          457,
          452,
          1872,
          51170
        ]
      },
      {
        "avg_logprob": -0.3217923033471201,
        "compression_ratio": 1.731958762886598,
        "end": 3175.7,
        "id": 1082,
        "no_speech_prob": 0.00004400109173730016,
        "seek": 315750,
        "start": 3173.62,
        "temperature": 0,
        "text": " is playing Little League for the first time this year.",
        "tokens": [
          51170,
          307,
          2433,
          8022,
          11199,
          337,
          264,
          700,
          565,
          341,
          1064,
          13,
          51274
        ]
      },
      {
        "avg_logprob": -0.3217923033471201,
        "compression_ratio": 1.731958762886598,
        "end": 3178,
        "id": 1083,
        "no_speech_prob": 0.00004400109173730016,
        "seek": 315750,
        "start": 3175.7,
        "temperature": 0,
        "text": " I have to be at the practice, cannot be late.",
        "tokens": [
          51274,
          286,
          362,
          281,
          312,
          412,
          264,
          3124,
          11,
          2644,
          312,
          3469,
          13,
          51389
        ]
      },
      {
        "avg_logprob": -0.3217923033471201,
        "compression_ratio": 1.731958762886598,
        "end": 3181.4,
        "id": 1084,
        "no_speech_prob": 0.00004400109173730016,
        "seek": 315750,
        "start": 3179.1,
        "temperature": 0,
        "text": " So I have another hour though, okay.",
        "tokens": [
          51444,
          407,
          286,
          362,
          1071,
          1773,
          1673,
          11,
          1392,
          13,
          51559
        ]
      },
      {
        "avg_logprob": -0.3217923033471201,
        "compression_ratio": 1.731958762886598,
        "end": 3185.38,
        "id": 1085,
        "no_speech_prob": 0.00004400109173730016,
        "seek": 315750,
        "start": 3183.7,
        "temperature": 0,
        "text": " I'm not the coach, don't worry.",
        "tokens": [
          51674,
          286,
          478,
          406,
          264,
          6560,
          11,
          500,
          380,
          3292,
          13,
          51758
        ]
      },
      {
        "avg_logprob": -0.2887842758842137,
        "compression_ratio": 1.6224489795918366,
        "end": 3189.1800000000003,
        "id": 1086,
        "no_speech_prob": 0.0005442112451419234,
        "seek": 318538,
        "start": 3185.46,
        "temperature": 0,
        "text": " I'm just, stand by the side, you cheer.",
        "tokens": [
          50368,
          286,
          478,
          445,
          11,
          1463,
          538,
          264,
          1252,
          11,
          291,
          12581,
          13,
          50554
        ]
      },
      {
        "avg_logprob": -0.2887842758842137,
        "compression_ratio": 1.6224489795918366,
        "end": 3191.94,
        "id": 1087,
        "no_speech_prob": 0.0005442112451419234,
        "seek": 318538,
        "start": 3189.1800000000003,
        "temperature": 0,
        "text": " Do my little, hold my little signs, that's it.",
        "tokens": [
          50554,
          1144,
          452,
          707,
          11,
          1797,
          452,
          707,
          7880,
          11,
          300,
          311,
          309,
          13,
          50692
        ]
      },
      {
        "avg_logprob": -0.2887842758842137,
        "compression_ratio": 1.6224489795918366,
        "end": 3193.9,
        "id": 1088,
        "no_speech_prob": 0.0005442112451419234,
        "seek": 318538,
        "start": 3191.94,
        "temperature": 0,
        "text": " I don't have any signs, should have signs.",
        "tokens": [
          50692,
          286,
          500,
          380,
          362,
          604,
          7880,
          11,
          820,
          362,
          7880,
          13,
          50790
        ]
      },
      {
        "avg_logprob": -0.2887842758842137,
        "compression_ratio": 1.6224489795918366,
        "end": 3195.78,
        "id": 1089,
        "no_speech_prob": 0.0005442112451419234,
        "seek": 318538,
        "start": 3193.9,
        "temperature": 0,
        "text": " I was actually thinking of sponsoring a Little League team",
        "tokens": [
          50790,
          286,
          390,
          767,
          1953,
          295,
          30311,
          257,
          8022,
          11199,
          1469,
          50884
        ]
      },
      {
        "avg_logprob": -0.2887842758842137,
        "compression_ratio": 1.6224489795918366,
        "end": 3197.7000000000003,
        "id": 1090,
        "no_speech_prob": 0.0005442112451419234,
        "seek": 318538,
        "start": 3195.78,
        "temperature": 0,
        "text": " like the Coding Train sponsored Little League team",
        "tokens": [
          50884,
          411,
          264,
          383,
          8616,
          28029,
          16621,
          8022,
          11199,
          1469,
          50980
        ]
      },
      {
        "avg_logprob": -0.2887842758842137,
        "compression_ratio": 1.6224489795918366,
        "end": 3200.3,
        "id": 1091,
        "no_speech_prob": 0.0005442112451419234,
        "seek": 318538,
        "start": 3197.7000000000003,
        "temperature": 0,
        "text": " but I didn't get it together this year, maybe next year.",
        "tokens": [
          50980,
          457,
          286,
          994,
          380,
          483,
          309,
          1214,
          341,
          1064,
          11,
          1310,
          958,
          1064,
          13,
          51110
        ]
      },
      {
        "avg_logprob": -0.2887842758842137,
        "compression_ratio": 1.6224489795918366,
        "end": 3201.1400000000003,
        "id": 1092,
        "no_speech_prob": 0.0005442112451419234,
        "seek": 318538,
        "start": 3200.3,
        "temperature": 0,
        "text": " All right.",
        "tokens": [
          51110,
          1057,
          558,
          13,
          51152
        ]
      },
      {
        "avg_logprob": -0.2887842758842137,
        "compression_ratio": 1.6224489795918366,
        "end": 3209.7200000000003,
        "id": 1093,
        "no_speech_prob": 0.0005442112451419234,
        "seek": 318538,
        "start": 3208.9,
        "temperature": 0,
        "text": " All right.",
        "tokens": [
          51540,
          1057,
          558,
          13,
          51581
        ]
      },
      {
        "avg_logprob": -0.3705404192902321,
        "compression_ratio": 1.4263157894736842,
        "end": 3219.54,
        "id": 1094,
        "no_speech_prob": 0.00004611269832821563,
        "seek": 321538,
        "start": 3216.38,
        "temperature": 0,
        "text": " There are two next steps.",
        "tokens": [
          50414,
          821,
          366,
          732,
          958,
          4439,
          13,
          50572
        ]
      },
      {
        "avg_logprob": -0.3705404192902321,
        "compression_ratio": 1.4263157894736842,
        "end": 3220.38,
        "id": 1095,
        "no_speech_prob": 0.00004611269832821563,
        "seek": 321538,
        "start": 3219.54,
        "temperature": 0,
        "text": " Oops.",
        "tokens": [
          50572,
          21726,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.3705404192902321,
        "compression_ratio": 1.4263157894736842,
        "end": 3229.46,
        "id": 1096,
        "no_speech_prob": 0.00004611269832821563,
        "seek": 321538,
        "start": 3224.46,
        "temperature": 0,
        "text": " Oh, why is this completely died?",
        "tokens": [
          50818,
          876,
          11,
          983,
          307,
          341,
          2584,
          4539,
          30,
          51068
        ]
      },
      {
        "avg_logprob": -0.3705404192902321,
        "compression_ratio": 1.4263157894736842,
        "end": 3236.58,
        "id": 1097,
        "no_speech_prob": 0.00004611269832821563,
        "seek": 321538,
        "start": 3234.62,
        "temperature": 0,
        "text": " I just, I know that I'm saying 44 a lot",
        "tokens": [
          51326,
          286,
          445,
          11,
          286,
          458,
          300,
          286,
          478,
          1566,
          16408,
          257,
          688,
          51424
        ]
      },
      {
        "avg_logprob": -0.3705404192902321,
        "compression_ratio": 1.4263157894736842,
        "end": 3238.7000000000003,
        "id": 1098,
        "no_speech_prob": 0.00004611269832821563,
        "seek": 321538,
        "start": 3236.58,
        "temperature": 0,
        "text": " because it's about to be 45 so I feel like",
        "tokens": [
          51424,
          570,
          309,
          311,
          466,
          281,
          312,
          6905,
          370,
          286,
          841,
          411,
          51530
        ]
      },
      {
        "avg_logprob": -0.3705404192902321,
        "compression_ratio": 1.4263157894736842,
        "end": 3239.94,
        "id": 1099,
        "no_speech_prob": 0.00004611269832821563,
        "seek": 321538,
        "start": 3238.7000000000003,
        "temperature": 0,
        "text": " I might as well say 44.",
        "tokens": [
          51530,
          286,
          1062,
          382,
          731,
          584,
          16408,
          13,
          51592
        ]
      },
      {
        "avg_logprob": -0.3705404192902321,
        "compression_ratio": 1.4263157894736842,
        "end": 3242.6600000000003,
        "id": 1100,
        "no_speech_prob": 0.00004611269832821563,
        "seek": 321538,
        "start": 3239.94,
        "temperature": 0,
        "text": " I like number 44 much better than number 45",
        "tokens": [
          51592,
          286,
          411,
          1230,
          16408,
          709,
          1101,
          813,
          1230,
          6905,
          51728
        ]
      },
      {
        "avg_logprob": -0.3705404192902321,
        "compression_ratio": 1.4263157894736842,
        "end": 3245.2200000000003,
        "id": 1101,
        "no_speech_prob": 0.00004611269832821563,
        "seek": 321538,
        "start": 3242.6600000000003,
        "temperature": 0,
        "text": " for a variety of reasons I will not get into right now.",
        "tokens": [
          51728,
          337,
          257,
          5673,
          295,
          4112,
          286,
          486,
          406,
          483,
          666,
          558,
          586,
          13,
          51856
        ]
      },
      {
        "avg_logprob": -0.23608323299523556,
        "compression_ratio": 1.6923076923076923,
        "end": 3247.4199999999996,
        "id": 1102,
        "no_speech_prob": 0.000038229089113883674,
        "seek": 324522,
        "start": 3246.06,
        "temperature": 0,
        "text": " If anyone can figure out what I'm talking about.",
        "tokens": [
          50406,
          759,
          2878,
          393,
          2573,
          484,
          437,
          286,
          478,
          1417,
          466,
          13,
          50474
        ]
      },
      {
        "avg_logprob": -0.23608323299523556,
        "compression_ratio": 1.6923076923076923,
        "end": 3250.54,
        "id": 1103,
        "no_speech_prob": 0.000038229089113883674,
        "seek": 324522,
        "start": 3247.4199999999996,
        "temperature": 0,
        "text": " All right, it's pretty obvious probably.",
        "tokens": [
          50474,
          1057,
          558,
          11,
          309,
          311,
          1238,
          6322,
          1391,
          13,
          50630
        ]
      },
      {
        "avg_logprob": -0.23608323299523556,
        "compression_ratio": 1.6923076923076923,
        "end": 3254.74,
        "id": 1104,
        "no_speech_prob": 0.000038229089113883674,
        "seek": 324522,
        "start": 3250.54,
        "temperature": 0,
        "text": " All right so, the two things that we need to do now.",
        "tokens": [
          50630,
          1057,
          558,
          370,
          11,
          264,
          732,
          721,
          300,
          321,
          643,
          281,
          360,
          586,
          13,
          50840
        ]
      },
      {
        "avg_logprob": -0.23608323299523556,
        "compression_ratio": 1.6923076923076923,
        "end": 3256.14,
        "id": 1105,
        "no_speech_prob": 0.000038229089113883674,
        "seek": 324522,
        "start": 3254.74,
        "temperature": 0,
        "text": " What are the two main steps?",
        "tokens": [
          50840,
          708,
          366,
          264,
          732,
          2135,
          4439,
          30,
          50910
        ]
      },
      {
        "avg_logprob": -0.23608323299523556,
        "compression_ratio": 1.6923076923076923,
        "end": 3259.8999999999996,
        "id": 1106,
        "no_speech_prob": 0.000038229089113883674,
        "seek": 324522,
        "start": 3256.14,
        "temperature": 0,
        "text": " I don't know why I came over here but since I'm over here.",
        "tokens": [
          50910,
          286,
          500,
          380,
          458,
          983,
          286,
          1361,
          670,
          510,
          457,
          1670,
          286,
          478,
          670,
          510,
          13,
          51098
        ]
      },
      {
        "avg_logprob": -0.23608323299523556,
        "compression_ratio": 1.6923076923076923,
        "end": 3261.62,
        "id": 1107,
        "no_speech_prob": 0.000038229089113883674,
        "seek": 324522,
        "start": 3259.8999999999996,
        "temperature": 0,
        "text": " So first of all, I drew this truth table thing",
        "tokens": [
          51098,
          407,
          700,
          295,
          439,
          11,
          286,
          12804,
          341,
          3494,
          3199,
          551,
          51184
        ]
      },
      {
        "avg_logprob": -0.23608323299523556,
        "compression_ratio": 1.6923076923076923,
        "end": 3264.62,
        "id": 1108,
        "no_speech_prob": 0.000038229089113883674,
        "seek": 324522,
        "start": 3261.62,
        "temperature": 0,
        "text": " a little bit weirdly and so you might recall,",
        "tokens": [
          51184,
          257,
          707,
          857,
          48931,
          293,
          370,
          291,
          1062,
          9901,
          11,
          51334
        ]
      },
      {
        "avg_logprob": -0.23608323299523556,
        "compression_ratio": 1.6923076923076923,
        "end": 3266.22,
        "id": 1109,
        "no_speech_prob": 0.000038229089113883674,
        "seek": 324522,
        "start": 3264.62,
        "temperature": 0,
        "text": " just to be clear about what's going on,",
        "tokens": [
          51334,
          445,
          281,
          312,
          1850,
          466,
          437,
          311,
          516,
          322,
          11,
          51414
        ]
      },
      {
        "avg_logprob": -0.23608323299523556,
        "compression_ratio": 1.6923076923076923,
        "end": 3268.8999999999996,
        "id": 1110,
        "no_speech_prob": 0.000038229089113883674,
        "seek": 324522,
        "start": 3266.22,
        "temperature": 0,
        "text": " this is my little drawing of the canvas right now",
        "tokens": [
          51414,
          341,
          307,
          452,
          707,
          6316,
          295,
          264,
          16267,
          558,
          586,
          51548
        ]
      },
      {
        "avg_logprob": -0.23608323299523556,
        "compression_ratio": 1.6923076923076923,
        "end": 3272.22,
        "id": 1111,
        "no_speech_prob": 0.000038229089113883674,
        "seek": 324522,
        "start": 3268.8999999999996,
        "temperature": 0,
        "text": " and the idea of the canvas is that I want to see",
        "tokens": [
          51548,
          293,
          264,
          1558,
          295,
          264,
          16267,
          307,
          300,
          286,
          528,
          281,
          536,
          51714
        ]
      },
      {
        "avg_logprob": -0.22599525774939586,
        "compression_ratio": 1.8904109589041096,
        "end": 3276.58,
        "id": 1112,
        "no_speech_prob": 0.0005193040706217289,
        "seek": 327222,
        "start": 3272.2599999999998,
        "temperature": 0,
        "text": " what the neural network thinks false false is at zero zero.",
        "tokens": [
          50366,
          437,
          264,
          18161,
          3209,
          7309,
          7908,
          7908,
          307,
          412,
          4018,
          4018,
          13,
          50582
        ]
      },
      {
        "avg_logprob": -0.22599525774939586,
        "compression_ratio": 1.8904109589041096,
        "end": 3279.7799999999997,
        "id": 1113,
        "no_speech_prob": 0.0005193040706217289,
        "seek": 327222,
        "start": 3276.58,
        "temperature": 0,
        "text": " I want to see what it thinks true false is",
        "tokens": [
          50582,
          286,
          528,
          281,
          536,
          437,
          309,
          7309,
          2074,
          7908,
          307,
          50742
        ]
      },
      {
        "avg_logprob": -0.22599525774939586,
        "compression_ratio": 1.8904109589041096,
        "end": 3282.62,
        "id": 1114,
        "no_speech_prob": 0.0005193040706217289,
        "seek": 327222,
        "start": 3279.7799999999997,
        "temperature": 0,
        "text": " at this right hand, top right hand side.",
        "tokens": [
          50742,
          412,
          341,
          558,
          1011,
          11,
          1192,
          558,
          1011,
          1252,
          13,
          50884
        ]
      },
      {
        "avg_logprob": -0.22599525774939586,
        "compression_ratio": 1.8904109589041096,
        "end": 3286.02,
        "id": 1115,
        "no_speech_prob": 0.0005193040706217289,
        "seek": 327222,
        "start": 3282.62,
        "temperature": 0,
        "text": " The bottom left hand side I want to see it zero one",
        "tokens": [
          50884,
          440,
          2767,
          1411,
          1011,
          1252,
          286,
          528,
          281,
          536,
          309,
          4018,
          472,
          51054
        ]
      },
      {
        "avg_logprob": -0.22599525774939586,
        "compression_ratio": 1.8904109589041096,
        "end": 3288.2599999999998,
        "id": 1116,
        "no_speech_prob": 0.0005193040706217289,
        "seek": 327222,
        "start": 3286.02,
        "temperature": 0,
        "text": " and then I want to see here one one.",
        "tokens": [
          51054,
          293,
          550,
          286,
          528,
          281,
          536,
          510,
          472,
          472,
          13,
          51166
        ]
      },
      {
        "avg_logprob": -0.22599525774939586,
        "compression_ratio": 1.8904109589041096,
        "end": 3293.2599999999998,
        "id": 1117,
        "no_speech_prob": 0.0005193040706217289,
        "seek": 327222,
        "start": 3288.2599999999998,
        "temperature": 0,
        "text": " So false is black for zero and true is white for one.",
        "tokens": [
          51166,
          407,
          7908,
          307,
          2211,
          337,
          4018,
          293,
          2074,
          307,
          2418,
          337,
          472,
          13,
          51416
        ]
      },
      {
        "avg_logprob": -0.22599525774939586,
        "compression_ratio": 1.8904109589041096,
        "end": 3296.2799999999997,
        "id": 1118,
        "no_speech_prob": 0.0005193040706217289,
        "seek": 327222,
        "start": 3294.54,
        "temperature": 0,
        "text": " That's the way I'm going to map the color.",
        "tokens": [
          51480,
          663,
          311,
          264,
          636,
          286,
          478,
          516,
          281,
          4471,
          264,
          2017,
          13,
          51567
        ]
      },
      {
        "avg_logprob": -0.22599525774939586,
        "compression_ratio": 1.8904109589041096,
        "end": 3299.8599999999997,
        "id": 1119,
        "no_speech_prob": 0.0005193040706217289,
        "seek": 327222,
        "start": 3296.2799999999997,
        "temperature": 0,
        "text": " So I should see some kind of bands of like,",
        "tokens": [
          51567,
          407,
          286,
          820,
          536,
          512,
          733,
          295,
          13543,
          295,
          411,
          11,
          51746
        ]
      },
      {
        "avg_logprob": -0.22599525774939586,
        "compression_ratio": 1.8904109589041096,
        "end": 3302.14,
        "id": 1120,
        "no_speech_prob": 0.0005193040706217289,
        "seek": 327222,
        "start": 3299.8599999999997,
        "temperature": 0,
        "text": " I should be getting something like this.",
        "tokens": [
          51746,
          286,
          820,
          312,
          1242,
          746,
          411,
          341,
          13,
          51860
        ]
      },
      {
        "avg_logprob": -0.21529423489290125,
        "compression_ratio": 1.8408163265306123,
        "end": 3304.66,
        "id": 1121,
        "no_speech_prob": 8.059442393459904e-7,
        "seek": 330214,
        "start": 3302.98,
        "temperature": 0,
        "text": " So darker here and like this.",
        "tokens": [
          50406,
          407,
          12741,
          510,
          293,
          411,
          341,
          13,
          50490
        ]
      },
      {
        "avg_logprob": -0.21529423489290125,
        "compression_ratio": 1.8408163265306123,
        "end": 3307.14,
        "id": 1122,
        "no_speech_prob": 8.059442393459904e-7,
        "seek": 330214,
        "start": 3304.66,
        "temperature": 0,
        "text": " So let's go look, does that match?",
        "tokens": [
          50490,
          407,
          718,
          311,
          352,
          574,
          11,
          775,
          300,
          2995,
          30,
          50614
        ]
      },
      {
        "avg_logprob": -0.21529423489290125,
        "compression_ratio": 1.8408163265306123,
        "end": 3309.1,
        "id": 1123,
        "no_speech_prob": 8.059442393459904e-7,
        "seek": 330214,
        "start": 3307.14,
        "temperature": 0,
        "text": " Yeah, that's exactly what I'm seeing here.",
        "tokens": [
          50614,
          865,
          11,
          300,
          311,
          2293,
          437,
          286,
          478,
          2577,
          510,
          13,
          50712
        ]
      },
      {
        "avg_logprob": -0.21529423489290125,
        "compression_ratio": 1.8408163265306123,
        "end": 3313.1,
        "id": 1124,
        "no_speech_prob": 8.059442393459904e-7,
        "seek": 330214,
        "start": 3309.1,
        "temperature": 0,
        "text": " So, the reason why I came over here is what I need,",
        "tokens": [
          50712,
          407,
          11,
          264,
          1778,
          983,
          286,
          1361,
          670,
          510,
          307,
          437,
          286,
          643,
          11,
          50912
        ]
      },
      {
        "avg_logprob": -0.21529423489290125,
        "compression_ratio": 1.8408163265306123,
        "end": 3315.02,
        "id": 1125,
        "no_speech_prob": 8.059442393459904e-7,
        "seek": 330214,
        "start": 3313.1,
        "temperature": 0,
        "text": " what I think, there's two things that I need to do.",
        "tokens": [
          50912,
          437,
          286,
          519,
          11,
          456,
          311,
          732,
          721,
          300,
          286,
          643,
          281,
          360,
          13,
          51008
        ]
      },
      {
        "avg_logprob": -0.21529423489290125,
        "compression_ratio": 1.8408163265306123,
        "end": 3317.22,
        "id": 1126,
        "no_speech_prob": 8.059442393459904e-7,
        "seek": 330214,
        "start": 3315.02,
        "temperature": 0,
        "text": " Number one is I need to train the model",
        "tokens": [
          51008,
          5118,
          472,
          307,
          286,
          643,
          281,
          3847,
          264,
          2316,
          51118
        ]
      },
      {
        "avg_logprob": -0.21529423489290125,
        "compression_ratio": 1.8408163265306123,
        "end": 3319.8199999999997,
        "id": 1127,
        "no_speech_prob": 8.059442393459904e-7,
        "seek": 330214,
        "start": 3317.22,
        "temperature": 0,
        "text": " to produce this output, my desired output",
        "tokens": [
          51118,
          281,
          5258,
          341,
          5598,
          11,
          452,
          14721,
          5598,
          51248
        ]
      },
      {
        "avg_logprob": -0.21529423489290125,
        "compression_ratio": 1.8408163265306123,
        "end": 3322.1,
        "id": 1128,
        "no_speech_prob": 8.059442393459904e-7,
        "seek": 330214,
        "start": 3319.8199999999997,
        "temperature": 0,
        "text": " that I think it should do and then I also need",
        "tokens": [
          51248,
          300,
          286,
          519,
          309,
          820,
          360,
          293,
          550,
          286,
          611,
          643,
          51362
        ]
      },
      {
        "avg_logprob": -0.21529423489290125,
        "compression_ratio": 1.8408163265306123,
        "end": 3325.8599999999997,
        "id": 1129,
        "no_speech_prob": 8.059442393459904e-7,
        "seek": 330214,
        "start": 3322.1,
        "temperature": 0,
        "text": " to ask the model to predict so I can draw",
        "tokens": [
          51362,
          281,
          1029,
          264,
          2316,
          281,
          6069,
          370,
          286,
          393,
          2642,
          51550
        ]
      },
      {
        "avg_logprob": -0.21529423489290125,
        "compression_ratio": 1.8408163265306123,
        "end": 3328.3799999999997,
        "id": 1130,
        "no_speech_prob": 8.059442393459904e-7,
        "seek": 330214,
        "start": 3325.8599999999997,
        "temperature": 0,
        "text": " what it thinks its output is.",
        "tokens": [
          51550,
          437,
          309,
          7309,
          1080,
          5598,
          307,
          13,
          51676
        ]
      },
      {
        "avg_logprob": -0.21529423489290125,
        "compression_ratio": 1.8408163265306123,
        "end": 3331.5,
        "id": 1131,
        "no_speech_prob": 8.059442393459904e-7,
        "seek": 330214,
        "start": 3328.3799999999997,
        "temperature": 0,
        "text": " So the two, and so the two steps here,",
        "tokens": [
          51676,
          407,
          264,
          732,
          11,
          293,
          370,
          264,
          732,
          4439,
          510,
          11,
          51832
        ]
      },
      {
        "avg_logprob": -0.26543354002897407,
        "compression_ratio": 1.7480314960629921,
        "end": 3335.78,
        "id": 1132,
        "no_speech_prob": 0.00008481097029289231,
        "seek": 333150,
        "start": 3331.9,
        "temperature": 0,
        "text": " I'm running out of space, but in the TensorFlow.js library,",
        "tokens": [
          50384,
          286,
          478,
          2614,
          484,
          295,
          1901,
          11,
          457,
          294,
          264,
          37624,
          13,
          25530,
          6405,
          11,
          50578
        ]
      },
      {
        "avg_logprob": -0.26543354002897407,
        "compression_ratio": 1.7480314960629921,
        "end": 3340.32,
        "id": 1133,
        "no_speech_prob": 0.00008481097029289231,
        "seek": 333150,
        "start": 3335.78,
        "temperature": 0,
        "text": " I need to look at the predict function and the fit function.",
        "tokens": [
          50578,
          286,
          643,
          281,
          574,
          412,
          264,
          6069,
          2445,
          293,
          264,
          3318,
          2445,
          13,
          50805
        ]
      },
      {
        "avg_logprob": -0.26543354002897407,
        "compression_ratio": 1.7480314960629921,
        "end": 3343.86,
        "id": 1134,
        "no_speech_prob": 0.00008481097029289231,
        "seek": 333150,
        "start": 3341.3,
        "temperature": 0,
        "text": " Predict for just saying here's the inputs,",
        "tokens": [
          50854,
          430,
          24945,
          337,
          445,
          1566,
          510,
          311,
          264,
          15743,
          11,
          50982
        ]
      },
      {
        "avg_logprob": -0.26543354002897407,
        "compression_ratio": 1.7480314960629921,
        "end": 3345.22,
        "id": 1135,
        "no_speech_prob": 0.00008481097029289231,
        "seek": 333150,
        "start": 3343.86,
        "temperature": 0,
        "text": " what is your output?",
        "tokens": [
          50982,
          437,
          307,
          428,
          5598,
          30,
          51050
        ]
      },
      {
        "avg_logprob": -0.26543354002897407,
        "compression_ratio": 1.7480314960629921,
        "end": 3348.72,
        "id": 1136,
        "no_speech_prob": 0.00008481097029289231,
        "seek": 333150,
        "start": 3345.22,
        "temperature": 0,
        "text": " The fit function for saying here's labeled inputs,",
        "tokens": [
          51050,
          440,
          3318,
          2445,
          337,
          1566,
          510,
          311,
          21335,
          15743,
          11,
          51225
        ]
      },
      {
        "avg_logprob": -0.26543354002897407,
        "compression_ratio": 1.7480314960629921,
        "end": 3351.02,
        "id": 1137,
        "no_speech_prob": 0.00008481097029289231,
        "seek": 333150,
        "start": 3348.72,
        "temperature": 0,
        "text": " inputs with known outputs, adjust,",
        "tokens": [
          51225,
          15743,
          365,
          2570,
          23930,
          11,
          4369,
          11,
          51340
        ]
      },
      {
        "avg_logprob": -0.26543354002897407,
        "compression_ratio": 1.7480314960629921,
        "end": 3352.94,
        "id": 1138,
        "no_speech_prob": 0.00008481097029289231,
        "seek": 333150,
        "start": 3351.02,
        "temperature": 0,
        "text": " optimize yourself according to that.",
        "tokens": [
          51340,
          19719,
          1803,
          4650,
          281,
          300,
          13,
          51436
        ]
      },
      {
        "avg_logprob": -0.26543354002897407,
        "compression_ratio": 1.7480314960629921,
        "end": 3354.86,
        "id": 1139,
        "no_speech_prob": 0.00008481097029289231,
        "seek": 333150,
        "start": 3352.94,
        "temperature": 0,
        "text": " So I'm going to do things backwards.",
        "tokens": [
          51436,
          407,
          286,
          478,
          516,
          281,
          360,
          721,
          12204,
          13,
          51532
        ]
      },
      {
        "avg_logprob": -0.26543354002897407,
        "compression_ratio": 1.7480314960629921,
        "end": 3357.18,
        "id": 1140,
        "no_speech_prob": 0.00008481097029289231,
        "seek": 333150,
        "start": 3354.86,
        "temperature": 0,
        "text": " I'm going to do just the predict step first.",
        "tokens": [
          51532,
          286,
          478,
          516,
          281,
          360,
          445,
          264,
          6069,
          1823,
          700,
          13,
          51648
        ]
      },
      {
        "avg_logprob": -0.26543354002897407,
        "compression_ratio": 1.7480314960629921,
        "end": 3360.22,
        "id": 1141,
        "no_speech_prob": 0.00008481097029289231,
        "seek": 333150,
        "start": 3357.18,
        "temperature": 0,
        "text": " I just want to see when it starts up with no training,",
        "tokens": [
          51648,
          286,
          445,
          528,
          281,
          536,
          562,
          309,
          3719,
          493,
          365,
          572,
          3097,
          11,
          51800
        ]
      },
      {
        "avg_logprob": -0.2638570964336395,
        "compression_ratio": 1.3909774436090225,
        "end": 3362.08,
        "id": 1142,
        "no_speech_prob": 0.00004133534457650967,
        "seek": 336022,
        "start": 3360.22,
        "temperature": 0,
        "text": " what visual output do we get?",
        "tokens": [
          50364,
          437,
          5056,
          5598,
          360,
          321,
          483,
          30,
          50457
        ]
      },
      {
        "avg_logprob": -0.2638570964336395,
        "compression_ratio": 1.3909774436090225,
        "end": 3368.74,
        "id": 1143,
        "no_speech_prob": 0.00004133534457650967,
        "seek": 336022,
        "start": 3365.2599999999998,
        "temperature": 0,
        "text": " So coming back to the code, let's look here.",
        "tokens": [
          50616,
          407,
          1348,
          646,
          281,
          264,
          3089,
          11,
          718,
          311,
          574,
          510,
          13,
          50790
        ]
      },
      {
        "avg_logprob": -0.2638570964336395,
        "compression_ratio": 1.3909774436090225,
        "end": 3371.98,
        "id": 1144,
        "no_speech_prob": 0.00004133534457650967,
        "seek": 336022,
        "start": 3368.74,
        "temperature": 0,
        "text": " So this, this is what I need to replace.",
        "tokens": [
          50790,
          407,
          341,
          11,
          341,
          307,
          437,
          286,
          643,
          281,
          7406,
          13,
          50952
        ]
      },
      {
        "avg_logprob": -0.2638570964336395,
        "compression_ratio": 1.3909774436090225,
        "end": 3375.8999999999996,
        "id": 1145,
        "no_speech_prob": 0.00004133534457650967,
        "seek": 336022,
        "start": 3371.98,
        "temperature": 0,
        "text": " I need to say, now I need to say,",
        "tokens": [
          50952,
          286,
          643,
          281,
          584,
          11,
          586,
          286,
          643,
          281,
          584,
          11,
          51148
        ]
      },
      {
        "avg_logprob": -0.2638570964336395,
        "compression_ratio": 1.3909774436090225,
        "end": 3382.3799999999997,
        "id": 1146,
        "no_speech_prob": 0.00004133534457650967,
        "seek": 336022,
        "start": 3377.3799999999997,
        "temperature": 0,
        "text": " let, whoops, y equal model.predict.",
        "tokens": [
          51222,
          718,
          11,
          567,
          3370,
          11,
          288,
          2681,
          2316,
          13,
          79,
          24945,
          13,
          51472
        ]
      },
      {
        "avg_logprob": -0.31540928388896744,
        "compression_ratio": 1.7372262773722629,
        "end": 3395.22,
        "id": 1147,
        "no_speech_prob": 0.000026274738047504798,
        "seek": 339022,
        "start": 3390.22,
        "temperature": 0,
        "text": " Model.predict, now let's go look at the documentation.",
        "tokens": [
          50364,
          17105,
          13,
          79,
          24945,
          11,
          586,
          718,
          311,
          352,
          574,
          412,
          264,
          14333,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.31540928388896744,
        "compression_ratio": 1.7372262773722629,
        "end": 3402.06,
        "id": 1148,
        "no_speech_prob": 0.000026274738047504798,
        "seek": 339022,
        "start": 3399.7799999999997,
        "temperature": 0,
        "text": " I need to send in the inputs.",
        "tokens": [
          50842,
          286,
          643,
          281,
          2845,
          294,
          264,
          15743,
          13,
          50956
        ]
      },
      {
        "avg_logprob": -0.31540928388896744,
        "compression_ratio": 1.7372262773722629,
        "end": 3407.8599999999997,
        "id": 1149,
        "no_speech_prob": 0.000026274738047504798,
        "seek": 339022,
        "start": 3403.3799999999997,
        "temperature": 0,
        "text": " So let's go back to the documentation, model.predict.",
        "tokens": [
          51022,
          407,
          718,
          311,
          352,
          646,
          281,
          264,
          14333,
          11,
          2316,
          13,
          79,
          24945,
          13,
          51246
        ]
      },
      {
        "avg_logprob": -0.31540928388896744,
        "compression_ratio": 1.7372262773722629,
        "end": 3412.8999999999996,
        "id": 1150,
        "no_speech_prob": 0.000026274738047504798,
        "seek": 339022,
        "start": 3410.5,
        "temperature": 0,
        "text": " I need a better way of browsing this documentation.",
        "tokens": [
          51378,
          286,
          643,
          257,
          1101,
          636,
          295,
          38602,
          341,
          14333,
          13,
          51498
        ]
      },
      {
        "avg_logprob": -0.31540928388896744,
        "compression_ratio": 1.7372262773722629,
        "end": 3413.74,
        "id": 1151,
        "no_speech_prob": 0.000026274738047504798,
        "seek": 339022,
        "start": 3412.8999999999996,
        "temperature": 0,
        "text": " Here it is.",
        "tokens": [
          51498,
          1692,
          309,
          307,
          13,
          51540
        ]
      },
      {
        "avg_logprob": -0.31540928388896744,
        "compression_ratio": 1.7372262773722629,
        "end": 3419.18,
        "id": 1152,
        "no_speech_prob": 0.000026274738047504798,
        "seek": 339022,
        "start": 3416.14,
        "temperature": 0,
        "text": " So I need to, sorry, model.predict,",
        "tokens": [
          51660,
          407,
          286,
          643,
          281,
          11,
          2597,
          11,
          2316,
          13,
          79,
          24945,
          11,
          51812
        ]
      },
      {
        "avg_logprob": -0.26614101260316136,
        "compression_ratio": 1.5561797752808988,
        "end": 3421.3399999999997,
        "id": 1153,
        "no_speech_prob": 0.00004832557897316292,
        "seek": 341918,
        "start": 3419.18,
        "temperature": 0,
        "text": " I need to give it the x's.",
        "tokens": [
          50364,
          286,
          643,
          281,
          976,
          309,
          264,
          2031,
          311,
          13,
          50472
        ]
      },
      {
        "avg_logprob": -0.26614101260316136,
        "compression_ratio": 1.5561797752808988,
        "end": 3423.02,
        "id": 1154,
        "no_speech_prob": 0.00004832557897316292,
        "seek": 341918,
        "start": 3421.3399999999997,
        "temperature": 0,
        "text": " What are the x's?",
        "tokens": [
          50472,
          708,
          366,
          264,
          2031,
          311,
          30,
          50556
        ]
      },
      {
        "avg_logprob": -0.26614101260316136,
        "compression_ratio": 1.5561797752808988,
        "end": 3426.3399999999997,
        "id": 1155,
        "no_speech_prob": 0.00004832557897316292,
        "seek": 341918,
        "start": 3423.02,
        "temperature": 0,
        "text": " This are the x's, but remember,",
        "tokens": [
          50556,
          639,
          366,
          264,
          2031,
          311,
          11,
          457,
          1604,
          11,
          50722
        ]
      },
      {
        "avg_logprob": -0.26614101260316136,
        "compression_ratio": 1.5561797752808988,
        "end": 3429.58,
        "id": 1156,
        "no_speech_prob": 0.00004832557897316292,
        "seek": 341918,
        "start": 3426.3399999999997,
        "temperature": 0,
        "text": " I'm using tensorflow.js now.",
        "tokens": [
          50722,
          286,
          478,
          1228,
          40863,
          10565,
          13,
          25530,
          586,
          13,
          50884
        ]
      },
      {
        "avg_logprob": -0.26614101260316136,
        "compression_ratio": 1.5561797752808988,
        "end": 3434.1,
        "id": 1157,
        "no_speech_prob": 0.00004832557897316292,
        "seek": 341918,
        "start": 3429.58,
        "temperature": 0,
        "text": " Tensorflow.js, oy, oy, oy, vague vault.",
        "tokens": [
          50884,
          34306,
          10565,
          13,
          25530,
          11,
          15376,
          11,
          15376,
          11,
          15376,
          11,
          24247,
          27134,
          13,
          51110
        ]
      },
      {
        "avg_logprob": -0.26614101260316136,
        "compression_ratio": 1.5561797752808988,
        "end": 3436.98,
        "id": 1158,
        "no_speech_prob": 0.00004832557897316292,
        "seek": 341918,
        "start": 3434.1,
        "temperature": 0,
        "text": " I have to make them a tensor, I can't use regular arrays.",
        "tokens": [
          51110,
          286,
          362,
          281,
          652,
          552,
          257,
          40863,
          11,
          286,
          393,
          380,
          764,
          3890,
          41011,
          13,
          51254
        ]
      },
      {
        "avg_logprob": -0.26614101260316136,
        "compression_ratio": 1.5561797752808988,
        "end": 3441.98,
        "id": 1159,
        "no_speech_prob": 0.00004832557897316292,
        "seek": 341918,
        "start": 3436.98,
        "temperature": 0,
        "text": " So I could say, let x's equal tensor one d,",
        "tokens": [
          51254,
          407,
          286,
          727,
          584,
          11,
          718,
          2031,
          311,
          2681,
          40863,
          472,
          274,
          11,
          51504
        ]
      },
      {
        "avg_logprob": -0.26614101260316136,
        "compression_ratio": 1.5561797752808988,
        "end": 3448.46,
        "id": 1160,
        "no_speech_prob": 0.00004832557897316292,
        "seek": 341918,
        "start": 3447.06,
        "temperature": 0,
        "text": " oh no, sorry, I got confused.",
        "tokens": [
          51758,
          1954,
          572,
          11,
          2597,
          11,
          286,
          658,
          9019,
          13,
          51828
        ]
      },
      {
        "avg_logprob": -0.28392429675086067,
        "compression_ratio": 1.592741935483871,
        "end": 3453.46,
        "id": 1161,
        "no_speech_prob": 0.000025867417207336985,
        "seek": 344846,
        "start": 3448.46,
        "temperature": 0,
        "text": " tf.tensor one d inputs, and then model x's.",
        "tokens": [
          50364,
          256,
          69,
          13,
          83,
          23153,
          472,
          274,
          15743,
          11,
          293,
          550,
          2316,
          2031,
          311,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.28392429675086067,
        "compression_ratio": 1.592741935483871,
        "end": 3458.26,
        "id": 1162,
        "no_speech_prob": 0.000025867417207336985,
        "seek": 344846,
        "start": 3455.94,
        "temperature": 0,
        "text": " Now here's the thing, so this is the,",
        "tokens": [
          50738,
          823,
          510,
          311,
          264,
          551,
          11,
          370,
          341,
          307,
          264,
          11,
          50854
        ]
      },
      {
        "avg_logprob": -0.28392429675086067,
        "compression_ratio": 1.592741935483871,
        "end": 3461.06,
        "id": 1163,
        "no_speech_prob": 0.000025867417207336985,
        "seek": 344846,
        "start": 3458.26,
        "temperature": 0,
        "text": " there's many problems what I've done so far, okay?",
        "tokens": [
          50854,
          456,
          311,
          867,
          2740,
          437,
          286,
          600,
          1096,
          370,
          1400,
          11,
          1392,
          30,
          50994
        ]
      },
      {
        "avg_logprob": -0.28392429675086067,
        "compression_ratio": 1.592741935483871,
        "end": 3463.26,
        "id": 1164,
        "no_speech_prob": 0.000025867417207336985,
        "seek": 344846,
        "start": 3461.06,
        "temperature": 0,
        "text": " Many problems, which I will solve slowly,",
        "tokens": [
          50994,
          5126,
          2740,
          11,
          597,
          286,
          486,
          5039,
          5692,
          11,
          51104
        ]
      },
      {
        "avg_logprob": -0.28392429675086067,
        "compression_ratio": 1.592741935483871,
        "end": 3465.98,
        "id": 1165,
        "no_speech_prob": 0.000025867417207336985,
        "seek": 344846,
        "start": 3463.26,
        "temperature": 0,
        "text": " this could be a very long video, I apologize in advance.",
        "tokens": [
          51104,
          341,
          727,
          312,
          257,
          588,
          938,
          960,
          11,
          286,
          12328,
          294,
          7295,
          13,
          51240
        ]
      },
      {
        "avg_logprob": -0.28392429675086067,
        "compression_ratio": 1.592741935483871,
        "end": 3467.38,
        "id": 1166,
        "no_speech_prob": 0.000025867417207336985,
        "seek": 344846,
        "start": 3465.98,
        "temperature": 0,
        "text": " You can take a break now, pause, take a break,",
        "tokens": [
          51240,
          509,
          393,
          747,
          257,
          1821,
          586,
          11,
          10465,
          11,
          747,
          257,
          1821,
          11,
          51310
        ]
      },
      {
        "avg_logprob": -0.28392429675086067,
        "compression_ratio": 1.592741935483871,
        "end": 3468.98,
        "id": 1167,
        "no_speech_prob": 0.000025867417207336985,
        "seek": 344846,
        "start": 3467.38,
        "temperature": 0,
        "text": " go do something else, come back.",
        "tokens": [
          51310,
          352,
          360,
          746,
          1646,
          11,
          808,
          646,
          13,
          51390
        ]
      },
      {
        "avg_logprob": -0.28392429675086067,
        "compression_ratio": 1.592741935483871,
        "end": 3472.84,
        "id": 1168,
        "no_speech_prob": 0.000025867417207336985,
        "seek": 344846,
        "start": 3470.06,
        "temperature": 0,
        "text": " So what's problem number one?",
        "tokens": [
          51444,
          407,
          437,
          311,
          1154,
          1230,
          472,
          30,
          51583
        ]
      },
      {
        "avg_logprob": -0.28392429675086067,
        "compression_ratio": 1.592741935483871,
        "end": 3476.46,
        "id": 1169,
        "no_speech_prob": 0.000025867417207336985,
        "seek": 344846,
        "start": 3472.84,
        "temperature": 0,
        "text": " Problem number one is predict happens asynchronously.",
        "tokens": [
          51583,
          11676,
          1230,
          472,
          307,
          6069,
          2314,
          42642,
          5098,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.25691913573209907,
        "compression_ratio": 1.596774193548387,
        "end": 3481.38,
        "id": 1170,
        "no_speech_prob": 0.0002066293527605012,
        "seek": 347646,
        "start": 3477.42,
        "temperature": 0,
        "text": " Oh boy, pause for a second here.",
        "tokens": [
          50412,
          876,
          3237,
          11,
          10465,
          337,
          257,
          1150,
          510,
          13,
          50610
        ]
      },
      {
        "avg_logprob": -0.25691913573209907,
        "compression_ratio": 1.596774193548387,
        "end": 3486.82,
        "id": 1171,
        "no_speech_prob": 0.0002066293527605012,
        "seek": 347646,
        "start": 3482.34,
        "temperature": 0,
        "text": " How did I do this in, so I made an example,",
        "tokens": [
          50658,
          1012,
          630,
          286,
          360,
          341,
          294,
          11,
          370,
          286,
          1027,
          364,
          1365,
          11,
          50882
        ]
      },
      {
        "avg_logprob": -0.25691913573209907,
        "compression_ratio": 1.596774193548387,
        "end": 3489.78,
        "id": 1172,
        "no_speech_prob": 0.0002066293527605012,
        "seek": 347646,
        "start": 3486.82,
        "temperature": 0,
        "text": " I just need to think about this for a second.",
        "tokens": [
          50882,
          286,
          445,
          643,
          281,
          519,
          466,
          341,
          337,
          257,
          1150,
          13,
          51030
        ]
      },
      {
        "avg_logprob": -0.25691913573209907,
        "compression_ratio": 1.596774193548387,
        "end": 3491.42,
        "id": 1173,
        "no_speech_prob": 0.0002066293527605012,
        "seek": 347646,
        "start": 3489.78,
        "temperature": 0,
        "text": " Wait, my glasses are steaming up,",
        "tokens": [
          51030,
          3802,
          11,
          452,
          10812,
          366,
          2126,
          5184,
          493,
          11,
          51112
        ]
      },
      {
        "avg_logprob": -0.25691913573209907,
        "compression_ratio": 1.596774193548387,
        "end": 3493.7400000000002,
        "id": 1174,
        "no_speech_prob": 0.0002066293527605012,
        "seek": 347646,
        "start": 3491.42,
        "temperature": 0,
        "text": " why is it getting all warm in here?",
        "tokens": [
          51112,
          983,
          307,
          309,
          1242,
          439,
          4561,
          294,
          510,
          30,
          51228
        ]
      },
      {
        "avg_logprob": -0.25691913573209907,
        "compression_ratio": 1.596774193548387,
        "end": 3497.9,
        "id": 1175,
        "no_speech_prob": 0.0002066293527605012,
        "seek": 347646,
        "start": 3493.7400000000002,
        "temperature": 0,
        "text": " Hold on, oh and Eric, thank you for that pull request.",
        "tokens": [
          51228,
          6962,
          322,
          11,
          1954,
          293,
          9336,
          11,
          1309,
          291,
          337,
          300,
          2235,
          5308,
          13,
          51436
        ]
      },
      {
        "avg_logprob": -0.25691913573209907,
        "compression_ratio": 1.596774193548387,
        "end": 3499.7,
        "id": 1176,
        "no_speech_prob": 0.0002066293527605012,
        "seek": 347646,
        "start": 3497.9,
        "temperature": 0,
        "text": " I probably should merge that and then look at,",
        "tokens": [
          51436,
          286,
          1391,
          820,
          22183,
          300,
          293,
          550,
          574,
          412,
          11,
          51526
        ]
      },
      {
        "avg_logprob": -0.25691913573209907,
        "compression_ratio": 1.596774193548387,
        "end": 3501.26,
        "id": 1177,
        "no_speech_prob": 0.0002066293527605012,
        "seek": 347646,
        "start": 3499.7,
        "temperature": 0,
        "text": " because he probably fixed a bunch of things,",
        "tokens": [
          51526,
          570,
          415,
          1391,
          6806,
          257,
          3840,
          295,
          721,
          11,
          51604
        ]
      },
      {
        "avg_logprob": -0.25691913573209907,
        "compression_ratio": 1.596774193548387,
        "end": 3502.7,
        "id": 1178,
        "no_speech_prob": 0.0002066293527605012,
        "seek": 347646,
        "start": 3501.26,
        "temperature": 0,
        "text": " I just want to see something.",
        "tokens": [
          51604,
          286,
          445,
          528,
          281,
          536,
          746,
          13,
          51676
        ]
      },
      {
        "avg_logprob": -0.25691913573209907,
        "compression_ratio": 1.596774193548387,
        "end": 3504.38,
        "id": 1179,
        "no_speech_prob": 0.0002066293527605012,
        "seek": 347646,
        "start": 3502.7,
        "temperature": 0,
        "text": " Can we do this as a batch?",
        "tokens": [
          51676,
          1664,
          321,
          360,
          341,
          382,
          257,
          15245,
          30,
          51760
        ]
      },
      {
        "avg_logprob": -0.2795287752614438,
        "compression_ratio": 1.678391959798995,
        "end": 3507.78,
        "id": 1180,
        "no_speech_prob": 0.00001834287468227558,
        "seek": 350438,
        "start": 3504.38,
        "temperature": 0,
        "text": " Oh, no, predict happens synchronously.",
        "tokens": [
          50364,
          876,
          11,
          572,
          11,
          6069,
          2314,
          19331,
          5098,
          13,
          50534
        ]
      },
      {
        "avg_logprob": -0.2795287752614438,
        "compression_ratio": 1.678391959798995,
        "end": 3510.98,
        "id": 1181,
        "no_speech_prob": 0.00001834287468227558,
        "seek": 350438,
        "start": 3508.86,
        "temperature": 0,
        "text": " It's fit that's asynchronous, oh good,",
        "tokens": [
          50588,
          467,
          311,
          3318,
          300,
          311,
          49174,
          11,
          1954,
          665,
          11,
          50694
        ]
      },
      {
        "avg_logprob": -0.2795287752614438,
        "compression_ratio": 1.678391959798995,
        "end": 3512.28,
        "id": 1182,
        "no_speech_prob": 0.00001834287468227558,
        "seek": 350438,
        "start": 3510.98,
        "temperature": 0,
        "text": " that's why I'm doing this.",
        "tokens": [
          50694,
          300,
          311,
          983,
          286,
          478,
          884,
          341,
          13,
          50759
        ]
      },
      {
        "avg_logprob": -0.2795287752614438,
        "compression_ratio": 1.678391959798995,
        "end": 3514.7400000000002,
        "id": 1183,
        "no_speech_prob": 0.00001834287468227558,
        "seek": 350438,
        "start": 3513.9,
        "temperature": 0,
        "text": " Right?",
        "tokens": [
          50840,
          1779,
          30,
          50882
        ]
      },
      {
        "avg_logprob": -0.2795287752614438,
        "compression_ratio": 1.678391959798995,
        "end": 3518.6800000000003,
        "id": 1184,
        "no_speech_prob": 0.00001834287468227558,
        "seek": 350438,
        "start": 3515.82,
        "temperature": 0,
        "text": " Predict happens, can happen synchronously.",
        "tokens": [
          50936,
          430,
          24945,
          2314,
          11,
          393,
          1051,
          19331,
          5098,
          13,
          51079
        ]
      },
      {
        "avg_logprob": -0.2795287752614438,
        "compression_ratio": 1.678391959798995,
        "end": 3522.46,
        "id": 1185,
        "no_speech_prob": 0.00001834287468227558,
        "seek": 350438,
        "start": 3520.38,
        "temperature": 0,
        "text": " Let me look at, actually I should show you",
        "tokens": [
          51164,
          961,
          385,
          574,
          412,
          11,
          767,
          286,
          820,
          855,
          291,
          51268
        ]
      },
      {
        "avg_logprob": -0.2795287752614438,
        "compression_ratio": 1.678391959798995,
        "end": 3524.26,
        "id": 1186,
        "no_speech_prob": 0.00001834287468227558,
        "seek": 350438,
        "start": 3522.46,
        "temperature": 0,
        "text": " what I'm looking at.",
        "tokens": [
          51268,
          437,
          286,
          478,
          1237,
          412,
          13,
          51358
        ]
      },
      {
        "avg_logprob": -0.2795287752614438,
        "compression_ratio": 1.678391959798995,
        "end": 3526.62,
        "id": 1187,
        "no_speech_prob": 0.00001834287468227558,
        "seek": 350438,
        "start": 3524.26,
        "temperature": 0,
        "text": " I know why I'm looking at it on this other computer.",
        "tokens": [
          51358,
          286,
          458,
          983,
          286,
          478,
          1237,
          412,
          309,
          322,
          341,
          661,
          3820,
          13,
          51476
        ]
      },
      {
        "avg_logprob": -0.2795287752614438,
        "compression_ratio": 1.678391959798995,
        "end": 3531.86,
        "id": 1188,
        "no_speech_prob": 0.00001834287468227558,
        "seek": 350438,
        "start": 3529.38,
        "temperature": 0,
        "text": " Oops, I'm just looking up some stuff",
        "tokens": [
          51614,
          21726,
          11,
          286,
          478,
          445,
          1237,
          493,
          512,
          1507,
          51738
        ]
      },
      {
        "avg_logprob": -0.2795287752614438,
        "compression_ratio": 1.678391959798995,
        "end": 3533.1400000000003,
        "id": 1189,
        "no_speech_prob": 0.00001834287468227558,
        "seek": 350438,
        "start": 3531.86,
        "temperature": 0,
        "text": " for how this stuff works.",
        "tokens": [
          51738,
          337,
          577,
          341,
          1507,
          1985,
          13,
          51802
        ]
      },
      {
        "avg_logprob": -0.4295339864843032,
        "compression_ratio": 1.5948275862068966,
        "end": 3535.2000000000003,
        "id": 1190,
        "no_speech_prob": 0.00031999743077903986,
        "seek": 353438,
        "start": 3534.38,
        "temperature": 0.2,
        "text": " Okay.",
        "tokens": [
          50364,
          1033,
          13,
          50405
        ]
      },
      {
        "avg_logprob": -0.4295339864843032,
        "compression_ratio": 1.5948275862068966,
        "end": 3546.28,
        "id": 1191,
        "no_speech_prob": 0.00031999743077903986,
        "seek": 353438,
        "start": 3543.82,
        "temperature": 0.2,
        "text": " Oh wait, wait, wait, wait, wait, wait, wait, wait.",
        "tokens": [
          50836,
          876,
          1699,
          11,
          1699,
          11,
          1699,
          11,
          1699,
          11,
          1699,
          11,
          1699,
          11,
          1699,
          11,
          1699,
          13,
          50959
        ]
      },
      {
        "avg_logprob": -0.4295339864843032,
        "compression_ratio": 1.5948275862068966,
        "end": 3553.7000000000003,
        "id": 1192,
        "no_speech_prob": 0.00031999743077903986,
        "seek": 353438,
        "start": 3551.06,
        "temperature": 0.2,
        "text": " No, hold on, hold on, let me show you what I'm looking at.",
        "tokens": [
          51198,
          883,
          11,
          1797,
          322,
          11,
          1797,
          322,
          11,
          718,
          385,
          855,
          291,
          437,
          286,
          478,
          1237,
          412,
          13,
          51330
        ]
      },
      {
        "avg_logprob": -0.4295339864843032,
        "compression_ratio": 1.5948275862068966,
        "end": 3554.98,
        "id": 1193,
        "no_speech_prob": 0.00031999743077903986,
        "seek": 353438,
        "start": 3553.7000000000003,
        "temperature": 0.2,
        "text": " Because I don't know why I'm looking at this.",
        "tokens": [
          51330,
          1436,
          286,
          500,
          380,
          458,
          983,
          286,
          478,
          1237,
          412,
          341,
          13,
          51394
        ]
      },
      {
        "avg_logprob": -0.4295339864843032,
        "compression_ratio": 1.5948275862068966,
        "end": 3556.34,
        "id": 1194,
        "no_speech_prob": 0.00031999743077903986,
        "seek": 353438,
        "start": 3554.98,
        "temperature": 0.2,
        "text": " So I have a repo",
        "tokens": [
          51394,
          407,
          286,
          362,
          257,
          49040,
          51462
        ]
      },
      {
        "avg_logprob": -0.4295339864843032,
        "compression_ratio": 1.5948275862068966,
        "end": 3563.1800000000003,
        "id": 1195,
        "no_speech_prob": 0.00031999743077903986,
        "seek": 353438,
        "start": 3562.1400000000003,
        "temperature": 0.2,
        "text": " called",
        "tokens": [
          51752,
          1219,
          51804
        ]
      },
      {
        "avg_logprob": -0.3623963180853396,
        "compression_ratio": 1.3473684210526315,
        "end": 3567.3,
        "id": 1196,
        "no_speech_prob": 0.00036829698365181684,
        "seek": 356438,
        "start": 3564.94,
        "temperature": 0,
        "text": " 145, it's not called 145, that's the time.",
        "tokens": [
          50392,
          3499,
          20,
          11,
          309,
          311,
          406,
          1219,
          3499,
          20,
          11,
          300,
          311,
          264,
          565,
          13,
          50510
        ]
      },
      {
        "avg_logprob": -0.3623963180853396,
        "compression_ratio": 1.3473684210526315,
        "end": 3570.7400000000002,
        "id": 1197,
        "no_speech_prob": 0.00036829698365181684,
        "seek": 356438,
        "start": 3567.3,
        "temperature": 0,
        "text": " TensorFlow.js examples, xor",
        "tokens": [
          50510,
          37624,
          13,
          25530,
          5110,
          11,
          2031,
          284,
          50682
        ]
      },
      {
        "avg_logprob": -0.3623963180853396,
        "compression_ratio": 1.3473684210526315,
        "end": 3573.7000000000003,
        "id": 1198,
        "no_speech_prob": 0.00036829698365181684,
        "seek": 356438,
        "start": 3572.7000000000003,
        "temperature": 0,
        "text": " sketch,",
        "tokens": [
          50780,
          12325,
          11,
          50830
        ]
      },
      {
        "avg_logprob": -0.3623963180853396,
        "compression_ratio": 1.3473684210526315,
        "end": 3576.34,
        "id": 1199,
        "no_speech_prob": 0.00036829698365181684,
        "seek": 356438,
        "start": 3575.5,
        "temperature": 0,
        "text": " right?",
        "tokens": [
          50920,
          558,
          30,
          50962
        ]
      },
      {
        "avg_logprob": -0.3623963180853396,
        "compression_ratio": 1.3473684210526315,
        "end": 3581.46,
        "id": 1200,
        "no_speech_prob": 0.00036829698365181684,
        "seek": 356438,
        "start": 3578.9,
        "temperature": 0,
        "text": " So I know I have to do it as a batch.",
        "tokens": [
          51090,
          407,
          286,
          458,
          286,
          362,
          281,
          360,
          309,
          382,
          257,
          15245,
          13,
          51218
        ]
      },
      {
        "avg_logprob": -0.3623963180853396,
        "compression_ratio": 1.3473684210526315,
        "end": 3583.7000000000003,
        "id": 1201,
        "no_speech_prob": 0.00036829698365181684,
        "seek": 356438,
        "start": 3581.46,
        "temperature": 0,
        "text": " Neural network predicts.",
        "tokens": [
          51218,
          1734,
          1807,
          3209,
          6069,
          82,
          13,
          51330
        ]
      },
      {
        "avg_logprob": -0.3623963180853396,
        "compression_ratio": 1.3473684210526315,
        "end": 3586.5,
        "id": 1202,
        "no_speech_prob": 0.00036829698365181684,
        "seek": 356438,
        "start": 3583.7000000000003,
        "temperature": 0,
        "text": " Oh, or did I do it, and so I was putting it in a class,",
        "tokens": [
          51330,
          876,
          11,
          420,
          630,
          286,
          360,
          309,
          11,
          293,
          370,
          286,
          390,
          3372,
          309,
          294,
          257,
          1508,
          11,
          51470
        ]
      },
      {
        "avg_logprob": -0.3623963180853396,
        "compression_ratio": 1.3473684210526315,
        "end": 3588.06,
        "id": 1203,
        "no_speech_prob": 0.00036829698365181684,
        "seek": 356438,
        "start": 3586.5,
        "temperature": 0,
        "text": " which I'm not going to do here.",
        "tokens": [
          51470,
          597,
          286,
          478,
          406,
          516,
          281,
          360,
          510,
          13,
          51548
        ]
      },
      {
        "avg_logprob": -0.3623963180853396,
        "compression_ratio": 1.3473684210526315,
        "end": 3592.06,
        "id": 1204,
        "no_speech_prob": 0.00036829698365181684,
        "seek": 356438,
        "start": 3589.1800000000003,
        "temperature": 0,
        "text": " Tidy return, oh, I,",
        "tokens": [
          51604,
          314,
          38836,
          2736,
          11,
          1954,
          11,
          286,
          11,
          51748
        ]
      },
      {
        "avg_logprob": -0.2640227293356871,
        "compression_ratio": 1.5060240963855422,
        "end": 3596.78,
        "id": 1205,
        "no_speech_prob": 0.000019525865354808047,
        "seek": 359438,
        "start": 3594.7400000000002,
        "temperature": 0,
        "text": " no, predict happens",
        "tokens": [
          50382,
          572,
          11,
          6069,
          2314,
          50484
        ]
      },
      {
        "avg_logprob": -0.2640227293356871,
        "compression_ratio": 1.5060240963855422,
        "end": 3601.7400000000002,
        "id": 1206,
        "no_speech_prob": 0.000019525865354808047,
        "seek": 359438,
        "start": 3598.9,
        "temperature": 0,
        "text": " synchronously, but then pulling the data off",
        "tokens": [
          50590,
          19331,
          5098,
          11,
          457,
          550,
          8407,
          264,
          1412,
          766,
          50732
        ]
      },
      {
        "avg_logprob": -0.2640227293356871,
        "compression_ratio": 1.5060240963855422,
        "end": 3604.9,
        "id": 1207,
        "no_speech_prob": 0.000019525865354808047,
        "seek": 359438,
        "start": 3601.7400000000002,
        "temperature": 0,
        "text": " happens asynchronously, but I can use data sync",
        "tokens": [
          50732,
          2314,
          42642,
          5098,
          11,
          457,
          286,
          393,
          764,
          1412,
          20271,
          50890
        ]
      },
      {
        "avg_logprob": -0.2640227293356871,
        "compression_ratio": 1.5060240963855422,
        "end": 3609.6600000000003,
        "id": 1208,
        "no_speech_prob": 0.000019525865354808047,
        "seek": 359438,
        "start": 3604.9,
        "temperature": 0,
        "text": " even though I probably should be using tf.nextframe.",
        "tokens": [
          50890,
          754,
          1673,
          286,
          1391,
          820,
          312,
          1228,
          256,
          69,
          13,
          716,
          734,
          17265,
          13,
          51128
        ]
      },
      {
        "avg_logprob": -0.2640227293356871,
        "compression_ratio": 1.5060240963855422,
        "end": 3611.38,
        "id": 1209,
        "no_speech_prob": 0.000019525865354808047,
        "seek": 359438,
        "start": 3609.6600000000003,
        "temperature": 0,
        "text": " I don't know how to use that yet.",
        "tokens": [
          51128,
          286,
          500,
          380,
          458,
          577,
          281,
          764,
          300,
          1939,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.2640227293356871,
        "compression_ratio": 1.5060240963855422,
        "end": 3616.7000000000003,
        "id": 1210,
        "no_speech_prob": 0.000019525865354808047,
        "seek": 359438,
        "start": 3613.94,
        "temperature": 0,
        "text": " So I will deal with that later.",
        "tokens": [
          51342,
          407,
          286,
          486,
          2028,
          365,
          300,
          1780,
          13,
          51480
        ]
      },
      {
        "avg_logprob": -0.2640227293356871,
        "compression_ratio": 1.5060240963855422,
        "end": 3617.6,
        "id": 1211,
        "no_speech_prob": 0.000019525865354808047,
        "seek": 359438,
        "start": 3616.7000000000003,
        "temperature": 0,
        "text": " Okay, sorry.",
        "tokens": [
          51480,
          1033,
          11,
          2597,
          13,
          51525
        ]
      },
      {
        "avg_logprob": -0.2640227293356871,
        "compression_ratio": 1.5060240963855422,
        "end": 3622.86,
        "id": 1212,
        "no_speech_prob": 0.000019525865354808047,
        "seek": 359438,
        "start": 3622.02,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          51746,
          1033,
          13,
          51788
        ]
      },
      {
        "avg_logprob": -0.4358165447528546,
        "compression_ratio": 1.180327868852459,
        "end": 3626.1400000000003,
        "id": 1213,
        "no_speech_prob": 0.000015689287465647794,
        "seek": 362438,
        "start": 3625.3,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          50410,
          1033,
          13,
          50452
        ]
      },
      {
        "avg_logprob": -0.4358165447528546,
        "compression_ratio": 1.180327868852459,
        "end": 3631.82,
        "id": 1214,
        "no_speech_prob": 0.000015689287465647794,
        "seek": 362438,
        "start": 3630.02,
        "temperature": 0,
        "text": " Okay, here I am back.",
        "tokens": [
          50646,
          1033,
          11,
          510,
          286,
          669,
          646,
          13,
          50736
        ]
      },
      {
        "avg_logprob": -0.4358165447528546,
        "compression_ratio": 1.180327868852459,
        "end": 3634.06,
        "id": 1215,
        "no_speech_prob": 0.000015689287465647794,
        "seek": 362438,
        "start": 3633.2200000000003,
        "temperature": 0,
        "text": " All right, sorry.",
        "tokens": [
          50806,
          1057,
          558,
          11,
          2597,
          13,
          50848
        ]
      },
      {
        "avg_logprob": -0.4358165447528546,
        "compression_ratio": 1.180327868852459,
        "end": 3636.9,
        "id": 1216,
        "no_speech_prob": 0.000015689287465647794,
        "seek": 362438,
        "start": 3635.1400000000003,
        "temperature": 0,
        "text": " I'm gonna just back up a bit.",
        "tokens": [
          50902,
          286,
          478,
          799,
          445,
          646,
          493,
          257,
          857,
          13,
          50990
        ]
      },
      {
        "avg_logprob": -0.4358165447528546,
        "compression_ratio": 1.180327868852459,
        "end": 3643.38,
        "id": 1217,
        "no_speech_prob": 0.000015689287465647794,
        "seek": 362438,
        "start": 3638.98,
        "temperature": 0,
        "text": " Mathieu, you can splice things however you feel so inclined.",
        "tokens": [
          51094,
          15776,
          19347,
          11,
          291,
          393,
          4732,
          573,
          721,
          4461,
          291,
          841,
          370,
          28173,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.4358165447528546,
        "compression_ratio": 1.180327868852459,
        "end": 3648.94,
        "id": 1218,
        "no_speech_prob": 0.000015689287465647794,
        "seek": 362438,
        "start": 3648.1,
        "temperature": 0,
        "text": " Whoops.",
        "tokens": [
          51550,
          45263,
          13,
          51592
        ]
      },
      {
        "avg_logprob": -0.292485093417233,
        "compression_ratio": 1.5276073619631902,
        "end": 3655.2200000000003,
        "id": 1219,
        "no_speech_prob": 0.00017130801279563457,
        "seek": 365438,
        "start": 3654.38,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          50364,
          1033,
          13,
          50406
        ]
      },
      {
        "avg_logprob": -0.292485093417233,
        "compression_ratio": 1.5276073619631902,
        "end": 3669.58,
        "id": 1220,
        "no_speech_prob": 0.00017130801279563457,
        "seek": 365438,
        "start": 3665.1,
        "temperature": 0,
        "text": " So I need to, now I need to ask the TensorFlow layer,",
        "tokens": [
          50900,
          407,
          286,
          643,
          281,
          11,
          586,
          286,
          643,
          281,
          1029,
          264,
          37624,
          4583,
          11,
          51124
        ]
      },
      {
        "avg_logprob": -0.292485093417233,
        "compression_ratio": 1.5276073619631902,
        "end": 3673.1400000000003,
        "id": 1221,
        "no_speech_prob": 0.00017130801279563457,
        "seek": 365438,
        "start": 3669.58,
        "temperature": 0,
        "text": " sequential model thingy to give me the why.",
        "tokens": [
          51124,
          42881,
          2316,
          551,
          88,
          281,
          976,
          385,
          264,
          983,
          13,
          51302
        ]
      },
      {
        "avg_logprob": -0.292485093417233,
        "compression_ratio": 1.5276073619631902,
        "end": 3678.1400000000003,
        "id": 1222,
        "no_speech_prob": 0.00017130801279563457,
        "seek": 365438,
        "start": 3673.1400000000003,
        "temperature": 0,
        "text": " Neural model.predict, but what does it expect?",
        "tokens": [
          51302,
          1734,
          1807,
          2316,
          13,
          79,
          24945,
          11,
          457,
          437,
          775,
          309,
          2066,
          30,
          51552
        ]
      },
      {
        "avg_logprob": -0.292485093417233,
        "compression_ratio": 1.5276073619631902,
        "end": 3680.9,
        "id": 1223,
        "no_speech_prob": 0.00017130801279563457,
        "seek": 365438,
        "start": 3678.62,
        "temperature": 0,
        "text": " Its predict function, unlike my predict function,",
        "tokens": [
          51576,
          6953,
          6069,
          2445,
          11,
          8343,
          452,
          6069,
          2445,
          11,
          51690
        ]
      },
      {
        "avg_logprob": -0.292485093417233,
        "compression_ratio": 1.5276073619631902,
        "end": 3684.3,
        "id": 1224,
        "no_speech_prob": 0.00017130801279563457,
        "seek": 365438,
        "start": 3680.9,
        "temperature": 0,
        "text": " cannot get a regular array, it expects a tensor.",
        "tokens": [
          51690,
          2644,
          483,
          257,
          3890,
          10225,
          11,
          309,
          33280,
          257,
          40863,
          13,
          51860
        ]
      },
      {
        "avg_logprob": -0.27764813653353987,
        "compression_ratio": 1.6517857142857142,
        "end": 3690.1800000000003,
        "id": 1225,
        "no_speech_prob": 0.000005507602054422023,
        "seek": 368430,
        "start": 3685.1800000000003,
        "temperature": 0,
        "text": " So I need to make the x's into tf.tensor1d",
        "tokens": [
          50408,
          407,
          286,
          643,
          281,
          652,
          264,
          2031,
          311,
          666,
          256,
          69,
          13,
          83,
          23153,
          16,
          67,
          50658
        ]
      },
      {
        "avg_logprob": -0.27764813653353987,
        "compression_ratio": 1.6517857142857142,
        "end": 3696.1400000000003,
        "id": 1226,
        "no_speech_prob": 0.000005507602054422023,
        "seek": 368430,
        "start": 3691.2200000000003,
        "temperature": 0,
        "text": " with those inputs and pass those through predict.",
        "tokens": [
          50710,
          365,
          729,
          15743,
          293,
          1320,
          729,
          807,
          6069,
          13,
          50956
        ]
      },
      {
        "avg_logprob": -0.27764813653353987,
        "compression_ratio": 1.6517857142857142,
        "end": 3698.0600000000004,
        "id": 1227,
        "no_speech_prob": 0.000005507602054422023,
        "seek": 368430,
        "start": 3696.1400000000003,
        "temperature": 0,
        "text": " Now here's the thing.",
        "tokens": [
          50956,
          823,
          510,
          311,
          264,
          551,
          13,
          51052
        ]
      },
      {
        "avg_logprob": -0.27764813653353987,
        "compression_ratio": 1.6517857142857142,
        "end": 3699.7400000000002,
        "id": 1228,
        "no_speech_prob": 0.000005507602054422023,
        "seek": 368430,
        "start": 3698.0600000000004,
        "temperature": 0,
        "text": " There's a lot of issues with this",
        "tokens": [
          51052,
          821,
          311,
          257,
          688,
          295,
          2663,
          365,
          341,
          51136
        ]
      },
      {
        "avg_logprob": -0.27764813653353987,
        "compression_ratio": 1.6517857142857142,
        "end": 3703.42,
        "id": 1229,
        "no_speech_prob": 0.000005507602054422023,
        "seek": 368430,
        "start": 3701.3,
        "temperature": 0,
        "text": " that I need to resolve, and this is gonna run really slow,",
        "tokens": [
          51214,
          300,
          286,
          643,
          281,
          14151,
          11,
          293,
          341,
          307,
          799,
          1190,
          534,
          2964,
          11,
          51320
        ]
      },
      {
        "avg_logprob": -0.27764813653353987,
        "compression_ratio": 1.6517857142857142,
        "end": 3705.0600000000004,
        "id": 1230,
        "no_speech_prob": 0.000005507602054422023,
        "seek": 368430,
        "start": 3703.42,
        "temperature": 0,
        "text": " and I need to actually do this as a batch process.",
        "tokens": [
          51320,
          293,
          286,
          643,
          281,
          767,
          360,
          341,
          382,
          257,
          15245,
          1399,
          13,
          51402
        ]
      },
      {
        "avg_logprob": -0.27764813653353987,
        "compression_ratio": 1.6517857142857142,
        "end": 3706.54,
        "id": 1231,
        "no_speech_prob": 0.000005507602054422023,
        "seek": 368430,
        "start": 3705.0600000000004,
        "temperature": 0,
        "text": " I'm gonna get to all that, but just looking",
        "tokens": [
          51402,
          286,
          478,
          799,
          483,
          281,
          439,
          300,
          11,
          457,
          445,
          1237,
          51476
        ]
      },
      {
        "avg_logprob": -0.27764813653353987,
        "compression_ratio": 1.6517857142857142,
        "end": 3710.5800000000004,
        "id": 1232,
        "no_speech_prob": 0.000005507602054422023,
        "seek": 368430,
        "start": 3706.54,
        "temperature": 0,
        "text": " at what I've got so far, model.predict,",
        "tokens": [
          51476,
          412,
          437,
          286,
          600,
          658,
          370,
          1400,
          11,
          2316,
          13,
          79,
          24945,
          11,
          51678
        ]
      },
      {
        "avg_logprob": -0.27764813653353987,
        "compression_ratio": 1.6517857142857142,
        "end": 3712.1000000000004,
        "id": 1233,
        "no_speech_prob": 0.000005507602054422023,
        "seek": 368430,
        "start": 3710.5800000000004,
        "temperature": 0,
        "text": " there's a question of like,",
        "tokens": [
          51678,
          456,
          311,
          257,
          1168,
          295,
          411,
          11,
          51754
        ]
      },
      {
        "avg_logprob": -0.2201637330094004,
        "compression_ratio": 1.8666666666666667,
        "end": 3714.54,
        "id": 1234,
        "no_speech_prob": 0.00007843781349947676,
        "seek": 371210,
        "start": 3712.1,
        "temperature": 0,
        "text": " is this happening synchronously or asynchronously?",
        "tokens": [
          50364,
          307,
          341,
          2737,
          19331,
          5098,
          420,
          42642,
          5098,
          30,
          50486
        ]
      },
      {
        "avg_logprob": -0.2201637330094004,
        "compression_ratio": 1.8666666666666667,
        "end": 3717.62,
        "id": 1235,
        "no_speech_prob": 0.00007843781349947676,
        "seek": 371210,
        "start": 3714.54,
        "temperature": 0,
        "text": " This actually is happening synchronously,",
        "tokens": [
          50486,
          639,
          767,
          307,
          2737,
          19331,
          5098,
          11,
          50640
        ]
      },
      {
        "avg_logprob": -0.2201637330094004,
        "compression_ratio": 1.8666666666666667,
        "end": 3722.62,
        "id": 1236,
        "no_speech_prob": 0.00007843781349947676,
        "seek": 371210,
        "start": 3717.62,
        "temperature": 0,
        "text": " but the problem is I need to say fill with the result,",
        "tokens": [
          50640,
          457,
          264,
          1154,
          307,
          286,
          643,
          281,
          584,
          2836,
          365,
          264,
          1874,
          11,
          50890
        ]
      },
      {
        "avg_logprob": -0.2201637330094004,
        "compression_ratio": 1.8666666666666667,
        "end": 3725.02,
        "id": 1237,
        "no_speech_prob": 0.00007843781349947676,
        "seek": 371210,
        "start": 3722.9,
        "temperature": 0,
        "text": " like I need to get that number out,",
        "tokens": [
          50904,
          411,
          286,
          643,
          281,
          483,
          300,
          1230,
          484,
          11,
          51010
        ]
      },
      {
        "avg_logprob": -0.2201637330094004,
        "compression_ratio": 1.8666666666666667,
        "end": 3729.38,
        "id": 1238,
        "no_speech_prob": 0.00007843781349947676,
        "seek": 371210,
        "start": 3725.02,
        "temperature": 0,
        "text": " and to get the number out, I actually wanna call.data,",
        "tokens": [
          51010,
          293,
          281,
          483,
          264,
          1230,
          484,
          11,
          286,
          767,
          1948,
          818,
          2411,
          67,
          3274,
          11,
          51228
        ]
      },
      {
        "avg_logprob": -0.2201637330094004,
        "compression_ratio": 1.8666666666666667,
        "end": 3731.6,
        "id": 1239,
        "no_speech_prob": 0.00007843781349947676,
        "seek": 371210,
        "start": 3729.38,
        "temperature": 0,
        "text": " and that happens asynchronously.",
        "tokens": [
          51228,
          293,
          300,
          2314,
          42642,
          5098,
          13,
          51339
        ]
      },
      {
        "avg_logprob": -0.2201637330094004,
        "compression_ratio": 1.8666666666666667,
        "end": 3733.86,
        "id": 1240,
        "no_speech_prob": 0.00007843781349947676,
        "seek": 371210,
        "start": 3731.6,
        "temperature": 0,
        "text": " So because I'm working with such teeny bits",
        "tokens": [
          51339,
          407,
          570,
          286,
          478,
          1364,
          365,
          1270,
          48232,
          9239,
          51452
        ]
      },
      {
        "avg_logprob": -0.2201637330094004,
        "compression_ratio": 1.8666666666666667,
        "end": 3737.38,
        "id": 1241,
        "no_speech_prob": 0.00007843781349947676,
        "seek": 371210,
        "start": 3733.86,
        "temperature": 0,
        "text": " of data right now, I think I'm gonna use data sync,",
        "tokens": [
          51452,
          295,
          1412,
          558,
          586,
          11,
          286,
          519,
          286,
          478,
          799,
          764,
          1412,
          20271,
          11,
          51628
        ]
      },
      {
        "avg_logprob": -0.2201637330094004,
        "compression_ratio": 1.8666666666666667,
        "end": 3738.8199999999997,
        "id": 1242,
        "no_speech_prob": 0.00007843781349947676,
        "seek": 371210,
        "start": 3737.38,
        "temperature": 0,
        "text": " and there could be issues with that,",
        "tokens": [
          51628,
          293,
          456,
          727,
          312,
          2663,
          365,
          300,
          11,
          51700
        ]
      },
      {
        "avg_logprob": -0.2201637330094004,
        "compression_ratio": 1.8666666666666667,
        "end": 3740.98,
        "id": 1243,
        "no_speech_prob": 0.00007843781349947676,
        "seek": 371210,
        "start": 3738.8199999999997,
        "temperature": 0,
        "text": " and as I move more forward, we're gonna see",
        "tokens": [
          51700,
          293,
          382,
          286,
          1286,
          544,
          2128,
          11,
          321,
          434,
          799,
          536,
          51808
        ]
      },
      {
        "avg_logprob": -0.2556984791388878,
        "compression_ratio": 1.6,
        "end": 3742.66,
        "id": 1244,
        "no_speech_prob": 0.00007602470577694476,
        "seek": 374098,
        "start": 3740.98,
        "temperature": 0,
        "text": " when I really need to be more thoughtful",
        "tokens": [
          50364,
          562,
          286,
          534,
          643,
          281,
          312,
          544,
          21566,
          50448
        ]
      },
      {
        "avg_logprob": -0.2556984791388878,
        "compression_ratio": 1.6,
        "end": 3744.96,
        "id": 1245,
        "no_speech_prob": 0.00007602470577694476,
        "seek": 374098,
        "start": 3742.66,
        "temperature": 0,
        "text": " about callbacks and promises,",
        "tokens": [
          50448,
          466,
          818,
          17758,
          293,
          16403,
          11,
          50563
        ]
      },
      {
        "avg_logprob": -0.2556984791388878,
        "compression_ratio": 1.6,
        "end": 3746.9,
        "id": 1246,
        "no_speech_prob": 0.00007602470577694476,
        "seek": 374098,
        "start": 3744.96,
        "temperature": 0,
        "text": " but I'm gonna use data sync right now.",
        "tokens": [
          50563,
          457,
          286,
          478,
          799,
          764,
          1412,
          20271,
          558,
          586,
          13,
          50660
        ]
      },
      {
        "avg_logprob": -0.2556984791388878,
        "compression_ratio": 1.6,
        "end": 3750.9,
        "id": 1247,
        "no_speech_prob": 0.00007602470577694476,
        "seek": 374098,
        "start": 3746.9,
        "temperature": 0,
        "text": " So I should be able to predict the output with this input,",
        "tokens": [
          50660,
          407,
          286,
          820,
          312,
          1075,
          281,
          6069,
          264,
          5598,
          365,
          341,
          4846,
          11,
          50860
        ]
      },
      {
        "avg_logprob": -0.2556984791388878,
        "compression_ratio": 1.6,
        "end": 3755.9,
        "id": 1248,
        "no_speech_prob": 0.00007602470577694476,
        "seek": 374098,
        "start": 3750.9,
        "temperature": 0,
        "text": " get that data, and then, let me just say console.log y,",
        "tokens": [
          50860,
          483,
          300,
          1412,
          11,
          293,
          550,
          11,
          718,
          385,
          445,
          584,
          11076,
          13,
          4987,
          288,
          11,
          51110
        ]
      },
      {
        "avg_logprob": -0.2556984791388878,
        "compression_ratio": 1.6,
        "end": 3760.78,
        "id": 1249,
        "no_speech_prob": 0.00007602470577694476,
        "seek": 374098,
        "start": 3758.54,
        "temperature": 0,
        "text": " and I'm gonna make the resolution here",
        "tokens": [
          51242,
          293,
          286,
          478,
          799,
          652,
          264,
          8669,
          510,
          51354
        ]
      },
      {
        "avg_logprob": -0.2556984791388878,
        "compression_ratio": 1.6,
        "end": 3767.3,
        "id": 1250,
        "no_speech_prob": 0.00007602470577694476,
        "seek": 374098,
        "start": 3762.3,
        "temperature": 0,
        "text": " of the, oh yeah, the resolution really big, like 50,",
        "tokens": [
          51430,
          295,
          264,
          11,
          1954,
          1338,
          11,
          264,
          8669,
          534,
          955,
          11,
          411,
          2625,
          11,
          51680
        ]
      },
      {
        "avg_logprob": -0.2556984791388878,
        "compression_ratio": 1.6,
        "end": 3770.82,
        "id": 1251,
        "no_speech_prob": 0.00007602470577694476,
        "seek": 374098,
        "start": 3768.16,
        "temperature": 0,
        "text": " because I just wanna look at very, very little data",
        "tokens": [
          51723,
          570,
          286,
          445,
          1948,
          574,
          412,
          588,
          11,
          588,
          707,
          1412,
          51856
        ]
      },
      {
        "avg_logprob": -0.2502168443467882,
        "compression_ratio": 1.6766917293233083,
        "end": 3773.5,
        "id": 1252,
        "no_speech_prob": 0.0002098827390000224,
        "seek": 377082,
        "start": 3771.6200000000003,
        "temperature": 0,
        "text": " to start with, and let's look,",
        "tokens": [
          50404,
          281,
          722,
          365,
          11,
          293,
          718,
          311,
          574,
          11,
          50498
        ]
      },
      {
        "avg_logprob": -0.2502168443467882,
        "compression_ratio": 1.6766917293233083,
        "end": 3774.42,
        "id": 1253,
        "no_speech_prob": 0.0002098827390000224,
        "seek": 377082,
        "start": 3773.5,
        "temperature": 0,
        "text": " I'm not gonna draw anything,",
        "tokens": [
          50498,
          286,
          478,
          406,
          799,
          2642,
          1340,
          11,
          50544
        ]
      },
      {
        "avg_logprob": -0.2502168443467882,
        "compression_ratio": 1.6766917293233083,
        "end": 3776.1400000000003,
        "id": 1254,
        "no_speech_prob": 0.0002098827390000224,
        "seek": 377082,
        "start": 3774.42,
        "temperature": 0,
        "text": " let's just look and see what's coming out.",
        "tokens": [
          50544,
          718,
          311,
          445,
          574,
          293,
          536,
          437,
          311,
          1348,
          484,
          13,
          50630
        ]
      },
      {
        "avg_logprob": -0.2502168443467882,
        "compression_ratio": 1.6766917293233083,
        "end": 3779.3,
        "id": 1255,
        "no_speech_prob": 0.0002098827390000224,
        "seek": 377082,
        "start": 3776.1400000000003,
        "temperature": 0,
        "text": " What's coming out here, y, and then let me just say no loop.",
        "tokens": [
          50630,
          708,
          311,
          1348,
          484,
          510,
          11,
          288,
          11,
          293,
          550,
          718,
          385,
          445,
          584,
          572,
          6367,
          13,
          50788
        ]
      },
      {
        "avg_logprob": -0.2502168443467882,
        "compression_ratio": 1.6766917293233083,
        "end": 3782.1000000000004,
        "id": 1256,
        "no_speech_prob": 0.0002098827390000224,
        "seek": 377082,
        "start": 3779.3,
        "temperature": 0,
        "text": " So let's look in the console and see if we get anything.",
        "tokens": [
          50788,
          407,
          718,
          311,
          574,
          294,
          264,
          11076,
          293,
          536,
          498,
          321,
          483,
          1340,
          13,
          50928
        ]
      },
      {
        "avg_logprob": -0.2502168443467882,
        "compression_ratio": 1.6766917293233083,
        "end": 3785.04,
        "id": 1257,
        "no_speech_prob": 0.0002098827390000224,
        "seek": 377082,
        "start": 3783.46,
        "temperature": 0,
        "text": " Error.",
        "tokens": [
          50996,
          3300,
          2874,
          13,
          51075
        ]
      },
      {
        "avg_logprob": -0.2502168443467882,
        "compression_ratio": 1.6766917293233083,
        "end": 3788.3,
        "id": 1258,
        "no_speech_prob": 0.0002098827390000224,
        "seek": 377082,
        "start": 3785.04,
        "temperature": 0,
        "text": " Expected when checking dense one input",
        "tokens": [
          51075,
          2111,
          10729,
          562,
          8568,
          18011,
          472,
          4846,
          51238
        ]
      },
      {
        "avg_logprob": -0.2502168443467882,
        "compression_ratio": 1.6766917293233083,
        "end": 3790.5,
        "id": 1259,
        "no_speech_prob": 0.0002098827390000224,
        "seek": 377082,
        "start": 3788.3,
        "temperature": 0,
        "text": " to have two dimensions, but it got array with shape two.",
        "tokens": [
          51238,
          281,
          362,
          732,
          12819,
          11,
          457,
          309,
          658,
          10225,
          365,
          3909,
          732,
          13,
          51348
        ]
      },
      {
        "avg_logprob": -0.2502168443467882,
        "compression_ratio": 1.6766917293233083,
        "end": 3793.42,
        "id": 1260,
        "no_speech_prob": 0.0002098827390000224,
        "seek": 377082,
        "start": 3790.5,
        "temperature": 0,
        "text": " Oh, once again, I have the same problem I've had",
        "tokens": [
          51348,
          876,
          11,
          1564,
          797,
          11,
          286,
          362,
          264,
          912,
          1154,
          286,
          600,
          632,
          51494
        ]
      },
      {
        "avg_logprob": -0.2502168443467882,
        "compression_ratio": 1.6766917293233083,
        "end": 3796.36,
        "id": 1261,
        "no_speech_prob": 0.0002098827390000224,
        "seek": 377082,
        "start": 3793.42,
        "temperature": 0,
        "text": " every single time I've done this with TensorFlow.js.",
        "tokens": [
          51494,
          633,
          2167,
          565,
          286,
          600,
          1096,
          341,
          365,
          37624,
          13,
          25530,
          13,
          51641
        ]
      },
      {
        "avg_logprob": -0.2502168443467882,
        "compression_ratio": 1.6766917293233083,
        "end": 3798.78,
        "id": 1262,
        "no_speech_prob": 0.0002098827390000224,
        "seek": 377082,
        "start": 3796.36,
        "temperature": 0,
        "text": " So the good news is,",
        "tokens": [
          51641,
          407,
          264,
          665,
          2583,
          307,
          11,
          51762
        ]
      },
      {
        "avg_logprob": -0.23157521544909868,
        "compression_ratio": 1.6135458167330676,
        "end": 3805.94,
        "id": 1263,
        "no_speech_prob": 0.000015446299585164525,
        "seek": 380082,
        "start": 3801.02,
        "temperature": 0,
        "text": " I don't want to just give this 1D tensor.",
        "tokens": [
          50374,
          286,
          500,
          380,
          528,
          281,
          445,
          976,
          341,
          502,
          35,
          40863,
          13,
          50620
        ]
      },
      {
        "avg_logprob": -0.23157521544909868,
        "compression_ratio": 1.6135458167330676,
        "end": 3808.6200000000003,
        "id": 1264,
        "no_speech_prob": 0.000015446299585164525,
        "seek": 380082,
        "start": 3805.94,
        "temperature": 0,
        "text": " Even though my data is just two values,",
        "tokens": [
          50620,
          2754,
          1673,
          452,
          1412,
          307,
          445,
          732,
          4190,
          11,
          50754
        ]
      },
      {
        "avg_logprob": -0.23157521544909868,
        "compression_ratio": 1.6135458167330676,
        "end": 3810.46,
        "id": 1265,
        "no_speech_prob": 0.000015446299585164525,
        "seek": 380082,
        "start": 3808.6200000000003,
        "temperature": 0,
        "text": " zero, one, one, zero, one, one,",
        "tokens": [
          50754,
          4018,
          11,
          472,
          11,
          472,
          11,
          4018,
          11,
          472,
          11,
          472,
          11,
          50846
        ]
      },
      {
        "avg_logprob": -0.23157521544909868,
        "compression_ratio": 1.6135458167330676,
        "end": 3813.94,
        "id": 1266,
        "no_speech_prob": 0.000015446299585164525,
        "seek": 380082,
        "start": 3810.46,
        "temperature": 0,
        "text": " and it's a one-dimensional array with two numbers in it,",
        "tokens": [
          50846,
          293,
          309,
          311,
          257,
          472,
          12,
          18759,
          10225,
          365,
          732,
          3547,
          294,
          309,
          11,
          51020
        ]
      },
      {
        "avg_logprob": -0.23157521544909868,
        "compression_ratio": 1.6135458167330676,
        "end": 3815.54,
        "id": 1267,
        "no_speech_prob": 0.000015446299585164525,
        "seek": 380082,
        "start": 3813.94,
        "temperature": 0,
        "text": " I actually wanna be able to do something like,",
        "tokens": [
          51020,
          286,
          767,
          1948,
          312,
          1075,
          281,
          360,
          746,
          411,
          11,
          51100
        ]
      },
      {
        "avg_logprob": -0.23157521544909868,
        "compression_ratio": 1.6135458167330676,
        "end": 3817.94,
        "id": 1268,
        "no_speech_prob": 0.000015446299585164525,
        "seek": 380082,
        "start": 3815.54,
        "temperature": 0,
        "text": " hey, take these 15 data points",
        "tokens": [
          51100,
          4177,
          11,
          747,
          613,
          2119,
          1412,
          2793,
          51220
        ]
      },
      {
        "avg_logprob": -0.23157521544909868,
        "compression_ratio": 1.6135458167330676,
        "end": 3821.1000000000004,
        "id": 1269,
        "no_speech_prob": 0.000015446299585164525,
        "seek": 380082,
        "start": 3819.5,
        "temperature": 0,
        "text": " and give me the results, the predictions",
        "tokens": [
          51298,
          293,
          976,
          385,
          264,
          3542,
          11,
          264,
          21264,
          51378
        ]
      },
      {
        "avg_logprob": -0.23157521544909868,
        "compression_ratio": 1.6135458167330676,
        "end": 3822.3,
        "id": 1270,
        "no_speech_prob": 0.000015446299585164525,
        "seek": 380082,
        "start": 3821.1000000000004,
        "temperature": 0,
        "text": " for all 15 of those.",
        "tokens": [
          51378,
          337,
          439,
          2119,
          295,
          729,
          13,
          51438
        ]
      },
      {
        "avg_logprob": -0.23157521544909868,
        "compression_ratio": 1.6135458167330676,
        "end": 3824.54,
        "id": 1271,
        "no_speech_prob": 0.000015446299585164525,
        "seek": 380082,
        "start": 3822.3,
        "temperature": 0,
        "text": " And so what I really wanna be doing",
        "tokens": [
          51438,
          400,
          370,
          437,
          286,
          534,
          1948,
          312,
          884,
          51550
        ]
      },
      {
        "avg_logprob": -0.23157521544909868,
        "compression_ratio": 1.6135458167330676,
        "end": 3828.26,
        "id": 1272,
        "no_speech_prob": 0.000015446299585164525,
        "seek": 380082,
        "start": 3824.54,
        "temperature": 0,
        "text": " is I always need to send in kind of like one order higher,",
        "tokens": [
          51550,
          307,
          286,
          1009,
          643,
          281,
          2845,
          294,
          733,
          295,
          411,
          472,
          1668,
          2946,
          11,
          51736
        ]
      },
      {
        "avg_logprob": -0.2641792297363281,
        "compression_ratio": 1.5866141732283465,
        "end": 3831.46,
        "id": 1273,
        "no_speech_prob": 0.00009761553519638255,
        "seek": 382826,
        "start": 3828.26,
        "temperature": 0,
        "text": " one degree, one rank higher.",
        "tokens": [
          50364,
          472,
          4314,
          11,
          472,
          6181,
          2946,
          13,
          50524
        ]
      },
      {
        "avg_logprob": -0.2641792297363281,
        "compression_ratio": 1.5866141732283465,
        "end": 3837.0600000000004,
        "id": 1274,
        "no_speech_prob": 0.00009761553519638255,
        "seek": 382826,
        "start": 3832.42,
        "temperature": 0,
        "text": " So this actually, I'm just sending in one piece of data",
        "tokens": [
          50572,
          407,
          341,
          767,
          11,
          286,
          478,
          445,
          7750,
          294,
          472,
          2522,
          295,
          1412,
          50804
        ]
      },
      {
        "avg_logprob": -0.2641792297363281,
        "compression_ratio": 1.5866141732283465,
        "end": 3840.0600000000004,
        "id": 1275,
        "no_speech_prob": 0.00009761553519638255,
        "seek": 382826,
        "start": 3837.0600000000004,
        "temperature": 0,
        "text": " in point, in point input.",
        "tokens": [
          50804,
          294,
          935,
          11,
          294,
          935,
          4846,
          13,
          50954
        ]
      },
      {
        "avg_logprob": -0.2641792297363281,
        "compression_ratio": 1.5866141732283465,
        "end": 3842.0200000000004,
        "id": 1276,
        "no_speech_prob": 0.00009761553519638255,
        "seek": 382826,
        "start": 3840.0600000000004,
        "temperature": 0,
        "text": " Brain stopped working in the middle of this video.",
        "tokens": [
          50954,
          29783,
          5936,
          1364,
          294,
          264,
          2808,
          295,
          341,
          960,
          13,
          51052
        ]
      },
      {
        "avg_logprob": -0.2641792297363281,
        "compression_ratio": 1.5866141732283465,
        "end": 3843.6200000000003,
        "id": 1277,
        "no_speech_prob": 0.00009761553519638255,
        "seek": 382826,
        "start": 3842.0200000000004,
        "temperature": 0,
        "text": " That's 17 hours long.",
        "tokens": [
          51052,
          663,
          311,
          3282,
          2496,
          938,
          13,
          51132
        ]
      },
      {
        "avg_logprob": -0.2641792297363281,
        "compression_ratio": 1.5866141732283465,
        "end": 3849.1800000000003,
        "id": 1278,
        "no_speech_prob": 0.00009761553519638255,
        "seek": 382826,
        "start": 3846.1000000000004,
        "temperature": 0,
        "text": " Ah, and this now, I also have to say tensor 2D now",
        "tokens": [
          51256,
          2438,
          11,
          293,
          341,
          586,
          11,
          286,
          611,
          362,
          281,
          584,
          40863,
          568,
          35,
          586,
          51410
        ]
      },
      {
        "avg_logprob": -0.2641792297363281,
        "compression_ratio": 1.5866141732283465,
        "end": 3850.9,
        "id": 1279,
        "no_speech_prob": 0.00009761553519638255,
        "seek": 382826,
        "start": 3849.1800000000003,
        "temperature": 0,
        "text": " because it's a 2D tensor.",
        "tokens": [
          51410,
          570,
          309,
          311,
          257,
          568,
          35,
          40863,
          13,
          51496
        ]
      },
      {
        "avg_logprob": -0.2641792297363281,
        "compression_ratio": 1.5866141732283465,
        "end": 3852.8,
        "id": 1280,
        "no_speech_prob": 0.00009761553519638255,
        "seek": 382826,
        "start": 3851.96,
        "temperature": 0,
        "text": " There we go.",
        "tokens": [
          51549,
          821,
          321,
          352,
          13,
          51591
        ]
      },
      {
        "avg_logprob": -0.2641792297363281,
        "compression_ratio": 1.5866141732283465,
        "end": 3854.38,
        "id": 1281,
        "no_speech_prob": 0.00009761553519638255,
        "seek": 382826,
        "start": 3852.8,
        "temperature": 0,
        "text": " Ah, so we can see, look at this.",
        "tokens": [
          51591,
          2438,
          11,
          370,
          321,
          393,
          536,
          11,
          574,
          412,
          341,
          13,
          51670
        ]
      },
      {
        "avg_logprob": -0.2641792297363281,
        "compression_ratio": 1.5866141732283465,
        "end": 3856.5400000000004,
        "id": 1282,
        "no_speech_prob": 0.00009761553519638255,
        "seek": 382826,
        "start": 3854.38,
        "temperature": 0,
        "text": " The results came out for all those little spots.",
        "tokens": [
          51670,
          440,
          3542,
          1361,
          484,
          337,
          439,
          729,
          707,
          10681,
          13,
          51778
        ]
      },
      {
        "avg_logprob": -0.2641792297363281,
        "compression_ratio": 1.5866141732283465,
        "end": 3858.1400000000003,
        "id": 1283,
        "no_speech_prob": 0.00009761553519638255,
        "seek": 382826,
        "start": 3856.5400000000004,
        "temperature": 0,
        "text": " You can see little numbers between zero and one",
        "tokens": [
          51778,
          509,
          393,
          536,
          707,
          3547,
          1296,
          4018,
          293,
          472,
          51858
        ]
      },
      {
        "avg_logprob": -0.3352965530084104,
        "compression_ratio": 1.5333333333333334,
        "end": 3859.8599999999997,
        "id": 1284,
        "no_speech_prob": 0.0000848109120852314,
        "seek": 385814,
        "start": 3859.02,
        "temperature": 0,
        "text": " in an array.",
        "tokens": [
          50408,
          294,
          364,
          10225,
          13,
          50450
        ]
      },
      {
        "avg_logprob": -0.3352965530084104,
        "compression_ratio": 1.5333333333333334,
        "end": 3862.94,
        "id": 1285,
        "no_speech_prob": 0.0000848109120852314,
        "seek": 385814,
        "start": 3859.8599999999997,
        "temperature": 0,
        "text": " So now I can, instead of console logging y,",
        "tokens": [
          50450,
          407,
          586,
          286,
          393,
          11,
          2602,
          295,
          11076,
          27991,
          288,
          11,
          50604
        ]
      },
      {
        "avg_logprob": -0.3352965530084104,
        "compression_ratio": 1.5333333333333334,
        "end": 3867.2599999999998,
        "id": 1286,
        "no_speech_prob": 0.0000848109120852314,
        "seek": 385814,
        "start": 3864.22,
        "temperature": 0,
        "text": " and I just want that, it comes back in an array,",
        "tokens": [
          50668,
          293,
          286,
          445,
          528,
          300,
          11,
          309,
          1487,
          646,
          294,
          364,
          10225,
          11,
          50820
        ]
      },
      {
        "avg_logprob": -0.3352965530084104,
        "compression_ratio": 1.5333333333333334,
        "end": 3869.2999999999997,
        "id": 1287,
        "no_speech_prob": 0.0000848109120852314,
        "seek": 385814,
        "start": 3867.2599999999998,
        "temperature": 0,
        "text": " but there's only one number I care about.",
        "tokens": [
          50820,
          457,
          456,
          311,
          787,
          472,
          1230,
          286,
          1127,
          466,
          13,
          50922
        ]
      },
      {
        "avg_logprob": -0.3352965530084104,
        "compression_ratio": 1.5333333333333334,
        "end": 3873.2999999999997,
        "id": 1288,
        "no_speech_prob": 0.0000848109120852314,
        "seek": 385814,
        "start": 3871.2599999999998,
        "temperature": 0,
        "text": " I can put this back in here.",
        "tokens": [
          51020,
          286,
          393,
          829,
          341,
          646,
          294,
          510,
          13,
          51122
        ]
      },
      {
        "avg_logprob": -0.3352965530084104,
        "compression_ratio": 1.5333333333333334,
        "end": 3877.42,
        "id": 1289,
        "no_speech_prob": 0.0000848109120852314,
        "seek": 385814,
        "start": 3873.2999999999997,
        "temperature": 0,
        "text": " I can take out no loop, and I can run it.",
        "tokens": [
          51122,
          286,
          393,
          747,
          484,
          572,
          6367,
          11,
          293,
          286,
          393,
          1190,
          309,
          13,
          51328
        ]
      },
      {
        "avg_logprob": -0.3352965530084104,
        "compression_ratio": 1.5333333333333334,
        "end": 3882.42,
        "id": 1290,
        "no_speech_prob": 0.0000848109120852314,
        "seek": 385814,
        "start": 3877.42,
        "temperature": 0,
        "text": " We can see, look, there is my current visualization of XOR.",
        "tokens": [
          51328,
          492,
          393,
          536,
          11,
          574,
          11,
          456,
          307,
          452,
          2190,
          25801,
          295,
          1783,
          2483,
          13,
          51578
        ]
      },
      {
        "avg_logprob": -0.3352965530084104,
        "compression_ratio": 1.5333333333333334,
        "end": 3887.02,
        "id": 1291,
        "no_speech_prob": 0.0000848109120852314,
        "seek": 385814,
        "start": 3886.18,
        "temperature": 0,
        "text": " I'm not really done.",
        "tokens": [
          51766,
          286,
          478,
          406,
          534,
          1096,
          13,
          51808
        ]
      },
      {
        "avg_logprob": -0.26397794995989116,
        "compression_ratio": 1.7692307692307692,
        "end": 3888.9,
        "id": 1292,
        "no_speech_prob": 0.0008558982517570257,
        "seek": 388702,
        "start": 3887.02,
        "temperature": 0,
        "text": " I have so much left to do in this video",
        "tokens": [
          50364,
          286,
          362,
          370,
          709,
          1411,
          281,
          360,
          294,
          341,
          960,
          50458
        ]
      },
      {
        "avg_logprob": -0.26397794995989116,
        "compression_ratio": 1.7692307692307692,
        "end": 3892.14,
        "id": 1293,
        "no_speech_prob": 0.0008558982517570257,
        "seek": 388702,
        "start": 3888.9,
        "temperature": 0,
        "text": " that is, been recording for the last three or four days.",
        "tokens": [
          50458,
          300,
          307,
          11,
          668,
          6613,
          337,
          264,
          1036,
          1045,
          420,
          1451,
          1708,
          13,
          50620
        ]
      },
      {
        "avg_logprob": -0.26397794995989116,
        "compression_ratio": 1.7692307692307692,
        "end": 3895.2599999999998,
        "id": 1294,
        "no_speech_prob": 0.0008558982517570257,
        "seek": 388702,
        "start": 3893.9,
        "temperature": 0,
        "text": " All right, one thing I want to do",
        "tokens": [
          50708,
          1057,
          558,
          11,
          472,
          551,
          286,
          528,
          281,
          360,
          50776
        ]
      },
      {
        "avg_logprob": -0.26397794995989116,
        "compression_ratio": 1.7692307692307692,
        "end": 3898.98,
        "id": 1295,
        "no_speech_prob": 0.0008558982517570257,
        "seek": 388702,
        "start": 3895.2599999999998,
        "temperature": 0,
        "text": " is I just want to say stroke 255.",
        "tokens": [
          50776,
          307,
          286,
          445,
          528,
          281,
          584,
          12403,
          3552,
          20,
          13,
          50962
        ]
      },
      {
        "avg_logprob": -0.26397794995989116,
        "compression_ratio": 1.7692307692307692,
        "end": 3901.14,
        "id": 1296,
        "no_speech_prob": 0.0008558982517570257,
        "seek": 388702,
        "start": 3898.98,
        "temperature": 0,
        "text": " So I just want to sort of see a little bit more.",
        "tokens": [
          50962,
          407,
          286,
          445,
          528,
          281,
          1333,
          295,
          536,
          257,
          707,
          857,
          544,
          13,
          51070
        ]
      },
      {
        "avg_logprob": -0.26397794995989116,
        "compression_ratio": 1.7692307692307692,
        "end": 3903.42,
        "id": 1297,
        "no_speech_prob": 0.0008558982517570257,
        "seek": 388702,
        "start": 3901.14,
        "temperature": 0,
        "text": " Okay, that's actually what I'm looking at here.",
        "tokens": [
          51070,
          1033,
          11,
          300,
          311,
          767,
          437,
          286,
          478,
          1237,
          412,
          510,
          13,
          51184
        ]
      },
      {
        "avg_logprob": -0.26397794995989116,
        "compression_ratio": 1.7692307692307692,
        "end": 3904.82,
        "id": 1298,
        "no_speech_prob": 0.0008558982517570257,
        "seek": 388702,
        "start": 3903.42,
        "temperature": 0,
        "text": " I actually want to make the resolution,",
        "tokens": [
          51184,
          286,
          767,
          528,
          281,
          652,
          264,
          8669,
          11,
          51254
        ]
      },
      {
        "avg_logprob": -0.26397794995989116,
        "compression_ratio": 1.7692307692307692,
        "end": 3908.66,
        "id": 1299,
        "no_speech_prob": 0.0008558982517570257,
        "seek": 388702,
        "start": 3904.82,
        "temperature": 0,
        "text": " for debugging wise, I also want to make the resolution",
        "tokens": [
          51254,
          337,
          45592,
          10829,
          11,
          286,
          611,
          528,
          281,
          652,
          264,
          8669,
          51446
        ]
      },
      {
        "avg_logprob": -0.26397794995989116,
        "compression_ratio": 1.7692307692307692,
        "end": 3909.66,
        "id": 1300,
        "no_speech_prob": 0.0008558982517570257,
        "seek": 388702,
        "start": 3908.66,
        "temperature": 0,
        "text": " a little bit bigger.",
        "tokens": [
          51446,
          257,
          707,
          857,
          3801,
          13,
          51496
        ]
      },
      {
        "avg_logprob": -0.26397794995989116,
        "compression_ratio": 1.7692307692307692,
        "end": 3912.16,
        "id": 1301,
        "no_speech_prob": 0.0008558982517570257,
        "seek": 388702,
        "start": 3911.32,
        "temperature": 0,
        "text": " So let's see.",
        "tokens": [
          51579,
          407,
          718,
          311,
          536,
          13,
          51621
        ]
      },
      {
        "avg_logprob": -0.26397794995989116,
        "compression_ratio": 1.7692307692307692,
        "end": 3912.98,
        "id": 1302,
        "no_speech_prob": 0.0008558982517570257,
        "seek": 388702,
        "start": 3912.16,
        "temperature": 0,
        "text": " Now, one thing I'm curious about,",
        "tokens": [
          51621,
          823,
          11,
          472,
          551,
          286,
          478,
          6369,
          466,
          11,
          51662
        ]
      },
      {
        "avg_logprob": -0.26397794995989116,
        "compression_ratio": 1.7692307692307692,
        "end": 3914.62,
        "id": 1303,
        "no_speech_prob": 0.0008558982517570257,
        "seek": 388702,
        "start": 3912.98,
        "temperature": 0,
        "text": " let's look at the frame rate here.",
        "tokens": [
          51662,
          718,
          311,
          574,
          412,
          264,
          3920,
          3314,
          510,
          13,
          51744
        ]
      },
      {
        "avg_logprob": -0.2846022711859809,
        "compression_ratio": 1.7652173913043478,
        "end": 3919.18,
        "id": 1304,
        "no_speech_prob": 0.000007183253728726413,
        "seek": 391462,
        "start": 3915.62,
        "temperature": 0,
        "text": " That's running at 30 frames per second, so that's fine.",
        "tokens": [
          50414,
          663,
          311,
          2614,
          412,
          2217,
          12083,
          680,
          1150,
          11,
          370,
          300,
          311,
          2489,
          13,
          50592
        ]
      },
      {
        "avg_logprob": -0.2846022711859809,
        "compression_ratio": 1.7652173913043478,
        "end": 3922.46,
        "id": 1305,
        "no_speech_prob": 0.000007183253728726413,
        "seek": 391462,
        "start": 3919.18,
        "temperature": 0,
        "text": " Let me now actually make the resolution much, much higher,",
        "tokens": [
          50592,
          961,
          385,
          586,
          767,
          652,
          264,
          8669,
          709,
          11,
          709,
          2946,
          11,
          50756
        ]
      },
      {
        "avg_logprob": -0.2846022711859809,
        "compression_ratio": 1.7652173913043478,
        "end": 3925.46,
        "id": 1306,
        "no_speech_prob": 0.000007183253728726413,
        "seek": 391462,
        "start": 3924.54,
        "temperature": 0,
        "text": " like this.",
        "tokens": [
          50860,
          411,
          341,
          13,
          50906
        ]
      },
      {
        "avg_logprob": -0.2846022711859809,
        "compression_ratio": 1.7652173913043478,
        "end": 3929.1,
        "id": 1307,
        "no_speech_prob": 0.000007183253728726413,
        "seek": 391462,
        "start": 3928.2599999999998,
        "temperature": 0,
        "text": " Oh my goodness.",
        "tokens": [
          51046,
          876,
          452,
          8387,
          13,
          51088
        ]
      },
      {
        "avg_logprob": -0.2846022711859809,
        "compression_ratio": 1.7652173913043478,
        "end": 3930.8199999999997,
        "id": 1308,
        "no_speech_prob": 0.000007183253728726413,
        "seek": 391462,
        "start": 3929.1,
        "temperature": 0,
        "text": " Oh, it's not even getting to the first frame.",
        "tokens": [
          51088,
          876,
          11,
          309,
          311,
          406,
          754,
          1242,
          281,
          264,
          700,
          3920,
          13,
          51174
        ]
      },
      {
        "avg_logprob": -0.2846022711859809,
        "compression_ratio": 1.7652173913043478,
        "end": 3932.9,
        "id": 1309,
        "no_speech_prob": 0.000007183253728726413,
        "seek": 391462,
        "start": 3930.8199999999997,
        "temperature": 0,
        "text": " Oh, boom, oh, oh, oh, there we go.",
        "tokens": [
          51174,
          876,
          11,
          9351,
          11,
          1954,
          11,
          1954,
          11,
          1954,
          11,
          456,
          321,
          352,
          13,
          51278
        ]
      },
      {
        "avg_logprob": -0.2846022711859809,
        "compression_ratio": 1.7652173913043478,
        "end": 3935.02,
        "id": 1310,
        "no_speech_prob": 0.000007183253728726413,
        "seek": 391462,
        "start": 3934.18,
        "temperature": 0,
        "text": " Look at the frame rate.",
        "tokens": [
          51342,
          2053,
          412,
          264,
          3920,
          3314,
          13,
          51384
        ]
      },
      {
        "avg_logprob": -0.2846022711859809,
        "compression_ratio": 1.7652173913043478,
        "end": 3936.12,
        "id": 1311,
        "no_speech_prob": 0.000007183253728726413,
        "seek": 391462,
        "start": 3935.02,
        "temperature": 0,
        "text": " Oh, it can't even give me a frame rate.",
        "tokens": [
          51384,
          876,
          11,
          309,
          393,
          380,
          754,
          976,
          385,
          257,
          3920,
          3314,
          13,
          51439
        ]
      },
      {
        "avg_logprob": -0.2846022711859809,
        "compression_ratio": 1.7652173913043478,
        "end": 3937.18,
        "id": 1312,
        "no_speech_prob": 0.000007183253728726413,
        "seek": 391462,
        "start": 3936.12,
        "temperature": 0,
        "text": " It's so stuck.",
        "tokens": [
          51439,
          467,
          311,
          370,
          5541,
          13,
          51492
        ]
      },
      {
        "avg_logprob": -0.2846022711859809,
        "compression_ratio": 1.7652173913043478,
        "end": 3939.06,
        "id": 1313,
        "no_speech_prob": 0.000007183253728726413,
        "seek": 391462,
        "start": 3937.18,
        "temperature": 0,
        "text": " It can't even get one frame per second.",
        "tokens": [
          51492,
          467,
          393,
          380,
          754,
          483,
          472,
          3920,
          680,
          1150,
          13,
          51586
        ]
      },
      {
        "avg_logprob": -0.2846022711859809,
        "compression_ratio": 1.7652173913043478,
        "end": 3940.46,
        "id": 1314,
        "no_speech_prob": 0.000007183253728726413,
        "seek": 391462,
        "start": 3939.06,
        "temperature": 0,
        "text": " So here's the thing.",
        "tokens": [
          51586,
          407,
          510,
          311,
          264,
          551,
          13,
          51656
        ]
      },
      {
        "avg_logprob": -0.2846022711859809,
        "compression_ratio": 1.7652173913043478,
        "end": 3942.8599999999997,
        "id": 1315,
        "no_speech_prob": 0.000007183253728726413,
        "seek": 391462,
        "start": 3940.46,
        "temperature": 0,
        "text": " I have done something very, very, very bad.",
        "tokens": [
          51656,
          286,
          362,
          1096,
          746,
          588,
          11,
          588,
          11,
          588,
          1578,
          13,
          51776
        ]
      },
      {
        "avg_logprob": -0.2742246086917706,
        "compression_ratio": 1.6640316205533596,
        "end": 3944.06,
        "id": 1316,
        "no_speech_prob": 0.000025867413569358177,
        "seek": 394286,
        "start": 3943.2200000000003,
        "temperature": 0,
        "text": " Ha, ha, ha.",
        "tokens": [
          50382,
          4064,
          11,
          324,
          11,
          324,
          13,
          50424
        ]
      },
      {
        "avg_logprob": -0.2742246086917706,
        "compression_ratio": 1.6640316205533596,
        "end": 3947.6600000000003,
        "id": 1317,
        "no_speech_prob": 0.000025867413569358177,
        "seek": 394286,
        "start": 3945.26,
        "temperature": 0,
        "text": " And I need it to stop.",
        "tokens": [
          50484,
          400,
          286,
          643,
          309,
          281,
          1590,
          13,
          50604
        ]
      },
      {
        "avg_logprob": -0.2742246086917706,
        "compression_ratio": 1.6640316205533596,
        "end": 3949.46,
        "id": 1318,
        "no_speech_prob": 0.000025867413569358177,
        "seek": 394286,
        "start": 3947.6600000000003,
        "temperature": 0,
        "text": " No loop, stop.",
        "tokens": [
          50604,
          883,
          6367,
          11,
          1590,
          13,
          50694
        ]
      },
      {
        "avg_logprob": -0.2742246086917706,
        "compression_ratio": 1.6640316205533596,
        "end": 3951.54,
        "id": 1319,
        "no_speech_prob": 0.000025867413569358177,
        "seek": 394286,
        "start": 3949.46,
        "temperature": 0,
        "text": " You don't have to do any more work.",
        "tokens": [
          50694,
          509,
          500,
          380,
          362,
          281,
          360,
          604,
          544,
          589,
          13,
          50798
        ]
      },
      {
        "avg_logprob": -0.2742246086917706,
        "compression_ratio": 1.6640316205533596,
        "end": 3953.58,
        "id": 1320,
        "no_speech_prob": 0.000025867413569358177,
        "seek": 394286,
        "start": 3951.54,
        "temperature": 0,
        "text": " And let's put the resolution back at 100,",
        "tokens": [
          50798,
          400,
          718,
          311,
          829,
          264,
          8669,
          646,
          412,
          2319,
          11,
          50900
        ]
      },
      {
        "avg_logprob": -0.2742246086917706,
        "compression_ratio": 1.6640316205533596,
        "end": 3954.7400000000002,
        "id": 1321,
        "no_speech_prob": 0.000025867413569358177,
        "seek": 394286,
        "start": 3953.58,
        "temperature": 0,
        "text": " and let's think about this.",
        "tokens": [
          50900,
          293,
          718,
          311,
          519,
          466,
          341,
          13,
          50958
        ]
      },
      {
        "avg_logprob": -0.2742246086917706,
        "compression_ratio": 1.6640316205533596,
        "end": 3956.3,
        "id": 1322,
        "no_speech_prob": 0.000025867413569358177,
        "seek": 394286,
        "start": 3954.7400000000002,
        "temperature": 0,
        "text": " What's going on here?",
        "tokens": [
          50958,
          708,
          311,
          516,
          322,
          510,
          30,
          51036
        ]
      },
      {
        "avg_logprob": -0.2742246086917706,
        "compression_ratio": 1.6640316205533596,
        "end": 3957.1600000000003,
        "id": 1323,
        "no_speech_prob": 0.000025867413569358177,
        "seek": 394286,
        "start": 3956.3,
        "temperature": 0,
        "text": " Look at this.",
        "tokens": [
          51036,
          2053,
          412,
          341,
          13,
          51079
        ]
      },
      {
        "avg_logprob": -0.2742246086917706,
        "compression_ratio": 1.6640316205533596,
        "end": 3958.38,
        "id": 1324,
        "no_speech_prob": 0.000025867413569358177,
        "seek": 394286,
        "start": 3957.1600000000003,
        "temperature": 0,
        "text": " Look at this predict function,",
        "tokens": [
          51079,
          2053,
          412,
          341,
          6069,
          2445,
          11,
          51140
        ]
      },
      {
        "avg_logprob": -0.2742246086917706,
        "compression_ratio": 1.6640316205533596,
        "end": 3960.04,
        "id": 1325,
        "no_speech_prob": 0.000025867413569358177,
        "seek": 394286,
        "start": 3958.38,
        "temperature": 0,
        "text": " and look at this data sync function.",
        "tokens": [
          51140,
          293,
          574,
          412,
          341,
          1412,
          20271,
          2445,
          13,
          51223
        ]
      },
      {
        "avg_logprob": -0.2742246086917706,
        "compression_ratio": 1.6640316205533596,
        "end": 3961.1400000000003,
        "id": 1326,
        "no_speech_prob": 0.000025867413569358177,
        "seek": 394286,
        "start": 3960.04,
        "temperature": 0,
        "text": " What am I doing?",
        "tokens": [
          51223,
          708,
          669,
          286,
          884,
          30,
          51278
        ]
      },
      {
        "avg_logprob": -0.2742246086917706,
        "compression_ratio": 1.6640316205533596,
        "end": 3965.6200000000003,
        "id": 1327,
        "no_speech_prob": 0.000025867413569358177,
        "seek": 394286,
        "start": 3961.1400000000003,
        "temperature": 0,
        "text": " I am calling that function multiple times,",
        "tokens": [
          51278,
          286,
          669,
          5141,
          300,
          2445,
          3866,
          1413,
          11,
          51502
        ]
      },
      {
        "avg_logprob": -0.2742246086917706,
        "compression_ratio": 1.6640316205533596,
        "end": 3968.58,
        "id": 1328,
        "no_speech_prob": 0.000025867413569358177,
        "seek": 394286,
        "start": 3965.6200000000003,
        "temperature": 0,
        "text": " every single, for every single spot on that grid.",
        "tokens": [
          51502,
          633,
          2167,
          11,
          337,
          633,
          2167,
          4008,
          322,
          300,
          10748,
          13,
          51650
        ]
      },
      {
        "avg_logprob": -0.2742246086917706,
        "compression_ratio": 1.6640316205533596,
        "end": 3972.3,
        "id": 1329,
        "no_speech_prob": 0.000025867413569358177,
        "seek": 394286,
        "start": 3969.48,
        "temperature": 0,
        "text": " When I'm working with something like TensorFlow.js,",
        "tokens": [
          51695,
          1133,
          286,
          478,
          1364,
          365,
          746,
          411,
          37624,
          13,
          25530,
          11,
          51836
        ]
      },
      {
        "avg_logprob": -0.21535625302694678,
        "compression_ratio": 1.6150943396226416,
        "end": 3976.34,
        "id": 1330,
        "no_speech_prob": 0.000004289332082407782,
        "seek": 397230,
        "start": 3972.7400000000002,
        "temperature": 0,
        "text": " whenever I create a tensor or feed data into a model,",
        "tokens": [
          50386,
          5699,
          286,
          1884,
          257,
          40863,
          420,
          3154,
          1412,
          666,
          257,
          2316,
          11,
          50566
        ]
      },
      {
        "avg_logprob": -0.21535625302694678,
        "compression_ratio": 1.6150943396226416,
        "end": 3981.34,
        "id": 1331,
        "no_speech_prob": 0.000004289332082407782,
        "seek": 397230,
        "start": 3976.34,
        "temperature": 0,
        "text": " the data has to go from my code onto the GPU.",
        "tokens": [
          50566,
          264,
          1412,
          575,
          281,
          352,
          490,
          452,
          3089,
          3911,
          264,
          18407,
          13,
          50816
        ]
      },
      {
        "avg_logprob": -0.21535625302694678,
        "compression_ratio": 1.6150943396226416,
        "end": 3983.1400000000003,
        "id": 1332,
        "no_speech_prob": 0.000004289332082407782,
        "seek": 397230,
        "start": 3981.6200000000003,
        "temperature": 0,
        "text": " And then when it's done,",
        "tokens": [
          50830,
          400,
          550,
          562,
          309,
          311,
          1096,
          11,
          50906
        ]
      },
      {
        "avg_logprob": -0.21535625302694678,
        "compression_ratio": 1.6150943396226416,
        "end": 3985.6200000000003,
        "id": 1333,
        "no_speech_prob": 0.000004289332082407782,
        "seek": 397230,
        "start": 3983.1400000000003,
        "temperature": 0,
        "text": " that data sync is pulling it off of the GPU",
        "tokens": [
          50906,
          300,
          1412,
          20271,
          307,
          8407,
          309,
          766,
          295,
          264,
          18407,
          51030
        ]
      },
      {
        "avg_logprob": -0.21535625302694678,
        "compression_ratio": 1.6150943396226416,
        "end": 3987.0600000000004,
        "id": 1334,
        "no_speech_prob": 0.000004289332082407782,
        "seek": 397230,
        "start": 3985.6200000000003,
        "temperature": 0,
        "text": " so I can use it again in my code,",
        "tokens": [
          51030,
          370,
          286,
          393,
          764,
          309,
          797,
          294,
          452,
          3089,
          11,
          51102
        ]
      },
      {
        "avg_logprob": -0.21535625302694678,
        "compression_ratio": 1.6150943396226416,
        "end": 3988.7000000000003,
        "id": 1335,
        "no_speech_prob": 0.000004289332082407782,
        "seek": 397230,
        "start": 3987.0600000000004,
        "temperature": 0,
        "text": " that graphics processing unit",
        "tokens": [
          51102,
          300,
          11837,
          9007,
          4985,
          51184
        ]
      },
      {
        "avg_logprob": -0.21535625302694678,
        "compression_ratio": 1.6150943396226416,
        "end": 3990.7000000000003,
        "id": 1336,
        "no_speech_prob": 0.000004289332082407782,
        "seek": 397230,
        "start": 3988.7000000000003,
        "temperature": 0,
        "text": " where all the math is happening behind the scenes.",
        "tokens": [
          51184,
          689,
          439,
          264,
          5221,
          307,
          2737,
          2261,
          264,
          8026,
          13,
          51284
        ]
      },
      {
        "avg_logprob": -0.21535625302694678,
        "compression_ratio": 1.6150943396226416,
        "end": 3994.26,
        "id": 1337,
        "no_speech_prob": 0.000004289332082407782,
        "seek": 397230,
        "start": 3990.7000000000003,
        "temperature": 0,
        "text": " I want to do that as few times as possible.",
        "tokens": [
          51284,
          286,
          528,
          281,
          360,
          300,
          382,
          1326,
          1413,
          382,
          1944,
          13,
          51462
        ]
      },
      {
        "avg_logprob": -0.21535625302694678,
        "compression_ratio": 1.6150943396226416,
        "end": 3998.6200000000003,
        "id": 1338,
        "no_speech_prob": 0.000004289332082407782,
        "seek": 397230,
        "start": 3995.7000000000003,
        "temperature": 0,
        "text": " Look how this is, I'm creating this two-dimensional array",
        "tokens": [
          51534,
          2053,
          577,
          341,
          307,
          11,
          286,
          478,
          4084,
          341,
          732,
          12,
          18759,
          10225,
          51680
        ]
      },
      {
        "avg_logprob": -0.21535625302694678,
        "compression_ratio": 1.6150943396226416,
        "end": 4002.1800000000003,
        "id": 1339,
        "no_speech_prob": 0.000004289332082407782,
        "seek": 397230,
        "start": 3998.6200000000003,
        "temperature": 0,
        "text": " with one thing in it, you know, 100 times.",
        "tokens": [
          51680,
          365,
          472,
          551,
          294,
          309,
          11,
          291,
          458,
          11,
          2319,
          1413,
          13,
          51858
        ]
      },
      {
        "avg_logprob": -0.22626267227472044,
        "compression_ratio": 1.5980861244019138,
        "end": 4006.54,
        "id": 1340,
        "no_speech_prob": 0.0000031381450753542595,
        "seek": 400218,
        "start": 4003.02,
        "temperature": 0,
        "text": " I could just create one array with 100 things in it",
        "tokens": [
          50406,
          286,
          727,
          445,
          1884,
          472,
          10225,
          365,
          2319,
          721,
          294,
          309,
          50582
        ]
      },
      {
        "avg_logprob": -0.22626267227472044,
        "compression_ratio": 1.5980861244019138,
        "end": 4007.66,
        "id": 1341,
        "no_speech_prob": 0.0000031381450753542595,
        "seek": 400218,
        "start": 4006.54,
        "temperature": 0,
        "text": " and call predict once.",
        "tokens": [
          50582,
          293,
          818,
          6069,
          1564,
          13,
          50638
        ]
      },
      {
        "avg_logprob": -0.22626267227472044,
        "compression_ratio": 1.5980861244019138,
        "end": 4009.22,
        "id": 1342,
        "no_speech_prob": 0.0000031381450753542595,
        "seek": 400218,
        "start": 4007.66,
        "temperature": 0,
        "text": " That's what I want to do.",
        "tokens": [
          50638,
          663,
          311,
          437,
          286,
          528,
          281,
          360,
          13,
          50716
        ]
      },
      {
        "avg_logprob": -0.22626267227472044,
        "compression_ratio": 1.5980861244019138,
        "end": 4012.8999999999996,
        "id": 1343,
        "no_speech_prob": 0.0000031381450753542595,
        "seek": 400218,
        "start": 4009.22,
        "temperature": 0,
        "text": " So what I need is for this nested loop to happen twice.",
        "tokens": [
          50716,
          407,
          437,
          286,
          643,
          307,
          337,
          341,
          15646,
          292,
          6367,
          281,
          1051,
          6091,
          13,
          50900
        ]
      },
      {
        "avg_logprob": -0.22626267227472044,
        "compression_ratio": 1.5980861244019138,
        "end": 4017.62,
        "id": 1344,
        "no_speech_prob": 0.0000031381450753542595,
        "seek": 400218,
        "start": 4013.7799999999997,
        "temperature": 0,
        "text": " Once to set up the data,",
        "tokens": [
          50944,
          3443,
          281,
          992,
          493,
          264,
          1412,
          11,
          51136
        ]
      },
      {
        "avg_logprob": -0.22626267227472044,
        "compression_ratio": 1.5980861244019138,
        "end": 4019.3999999999996,
        "id": 1345,
        "no_speech_prob": 0.0000031381450753542595,
        "seek": 400218,
        "start": 4017.62,
        "temperature": 0,
        "text": " and another to draw all the results.",
        "tokens": [
          51136,
          293,
          1071,
          281,
          2642,
          439,
          264,
          3542,
          13,
          51225
        ]
      },
      {
        "avg_logprob": -0.22626267227472044,
        "compression_ratio": 1.5980861244019138,
        "end": 4021.4199999999996,
        "id": 1346,
        "no_speech_prob": 0.0000031381450753542595,
        "seek": 400218,
        "start": 4019.3999999999996,
        "temperature": 0,
        "text": " So I'm going to copy paste this,",
        "tokens": [
          51225,
          407,
          286,
          478,
          516,
          281,
          5055,
          9163,
          341,
          11,
          51326
        ]
      },
      {
        "avg_logprob": -0.22626267227472044,
        "compression_ratio": 1.5980861244019138,
        "end": 4023.02,
        "id": 1347,
        "no_speech_prob": 0.0000031381450753542595,
        "seek": 400218,
        "start": 4021.4199999999996,
        "temperature": 0,
        "text": " just put it right below.",
        "tokens": [
          51326,
          445,
          829,
          309,
          558,
          2507,
          13,
          51406
        ]
      },
      {
        "avg_logprob": -0.22626267227472044,
        "compression_ratio": 1.5980861244019138,
        "end": 4028.02,
        "id": 1348,
        "no_speech_prob": 0.0000031381450753542595,
        "seek": 400218,
        "start": 4023.02,
        "temperature": 0,
        "text": " So this, now what we need to do is create the input data.",
        "tokens": [
          51406,
          407,
          341,
          11,
          586,
          437,
          321,
          643,
          281,
          360,
          307,
          1884,
          264,
          4846,
          1412,
          13,
          51656
        ]
      },
      {
        "avg_logprob": -0.18712918301846118,
        "compression_ratio": 1.7018633540372672,
        "end": 4037.46,
        "id": 1349,
        "no_speech_prob": 0.000011125590390292928,
        "seek": 403218,
        "start": 4032.46,
        "temperature": 0,
        "text": " So I'm going to say let inputs be a blank array.",
        "tokens": [
          50378,
          407,
          286,
          478,
          516,
          281,
          584,
          718,
          15743,
          312,
          257,
          8247,
          10225,
          13,
          50628
        ]
      },
      {
        "avg_logprob": -0.18712918301846118,
        "compression_ratio": 1.7018633540372672,
        "end": 4043.3799999999997,
        "id": 1350,
        "no_speech_prob": 0.000011125590390292928,
        "seek": 403218,
        "start": 4038.8199999999997,
        "temperature": 0,
        "text": " Then I'm going to say inputs.push.",
        "tokens": [
          50696,
          1396,
          286,
          478,
          516,
          281,
          584,
          15743,
          13,
          79,
          1498,
          13,
          50924
        ]
      },
      {
        "avg_logprob": -0.18712918301846118,
        "compression_ratio": 1.7018633540372672,
        "end": 4051.4199999999996,
        "id": 1351,
        "no_speech_prob": 0.000011125590390292928,
        "seek": 403218,
        "start": 4047.06,
        "temperature": 0,
        "text": " And I'm going to just push in x1, x2.",
        "tokens": [
          51108,
          400,
          286,
          478,
          516,
          281,
          445,
          2944,
          294,
          2031,
          16,
          11,
          2031,
          17,
          13,
          51326
        ]
      },
      {
        "avg_logprob": -0.18712918301846118,
        "compression_ratio": 1.7018633540372672,
        "end": 4056.4199999999996,
        "id": 1352,
        "no_speech_prob": 0.000011125590390292928,
        "seek": 403218,
        "start": 4051.4199999999996,
        "temperature": 0,
        "text": " So I'm going to put every single x1, x2 all the way along.",
        "tokens": [
          51326,
          407,
          286,
          478,
          516,
          281,
          829,
          633,
          2167,
          2031,
          16,
          11,
          2031,
          17,
          439,
          264,
          636,
          2051,
          13,
          51576
        ]
      },
      {
        "avg_logprob": -0.18712918301846118,
        "compression_ratio": 1.7018633540372672,
        "end": 4059.56,
        "id": 1353,
        "no_speech_prob": 0.000011125590390292928,
        "seek": 403218,
        "start": 4056.8999999999996,
        "temperature": 0,
        "text": " I don't want to create the tensor or do this here.",
        "tokens": [
          51600,
          286,
          500,
          380,
          528,
          281,
          1884,
          264,
          40863,
          420,
          360,
          341,
          510,
          13,
          51733
        ]
      },
      {
        "avg_logprob": -0.18712918301846118,
        "compression_ratio": 1.7018633540372672,
        "end": 4061.3799999999997,
        "id": 1354,
        "no_speech_prob": 0.000011125590390292928,
        "seek": 403218,
        "start": 4059.56,
        "temperature": 0,
        "text": " I don't want to do the drawing stuff here.",
        "tokens": [
          51733,
          286,
          500,
          380,
          528,
          281,
          360,
          264,
          6316,
          1507,
          510,
          13,
          51824
        ]
      },
      {
        "avg_logprob": -0.20611048889160155,
        "compression_ratio": 1.755868544600939,
        "end": 4063.1800000000003,
        "id": 1355,
        "no_speech_prob": 0.000007646533049410209,
        "seek": 406138,
        "start": 4061.38,
        "temperature": 0,
        "text": " I just want to create, I just want to have a loop",
        "tokens": [
          50364,
          286,
          445,
          528,
          281,
          1884,
          11,
          286,
          445,
          528,
          281,
          362,
          257,
          6367,
          50454
        ]
      },
      {
        "avg_logprob": -0.20611048889160155,
        "compression_ratio": 1.755868544600939,
        "end": 4064.62,
        "id": 1356,
        "no_speech_prob": 0.000007646533049410209,
        "seek": 406138,
        "start": 4063.1800000000003,
        "temperature": 0,
        "text": " that creates all the data.",
        "tokens": [
          50454,
          300,
          7829,
          439,
          264,
          1412,
          13,
          50526
        ]
      },
      {
        "avg_logprob": -0.20611048889160155,
        "compression_ratio": 1.755868544600939,
        "end": 4069.62,
        "id": 1357,
        "no_speech_prob": 0.000007646533049410209,
        "seek": 406138,
        "start": 4064.62,
        "temperature": 0,
        "text": " Now, I can get the x's is all of those inputs",
        "tokens": [
          50526,
          823,
          11,
          286,
          393,
          483,
          264,
          2031,
          311,
          307,
          439,
          295,
          729,
          15743,
          50776
        ]
      },
      {
        "avg_logprob": -0.20611048889160155,
        "compression_ratio": 1.755868544600939,
        "end": 4075.2200000000003,
        "id": 1358,
        "no_speech_prob": 0.000007646533049410209,
        "seek": 406138,
        "start": 4070.2200000000003,
        "temperature": 0,
        "text": " into a 2D tensor and the y's, this is now the y's,",
        "tokens": [
          50806,
          666,
          257,
          568,
          35,
          40863,
          293,
          264,
          288,
          311,
          11,
          341,
          307,
          586,
          264,
          288,
          311,
          11,
          51056
        ]
      },
      {
        "avg_logprob": -0.20611048889160155,
        "compression_ratio": 1.755868544600939,
        "end": 4079.1800000000003,
        "id": 1359,
        "no_speech_prob": 0.000007646533049410209,
        "seek": 406138,
        "start": 4075.2200000000003,
        "temperature": 0,
        "text": " is, and now here's the thing, I don't just,",
        "tokens": [
          51056,
          307,
          11,
          293,
          586,
          510,
          311,
          264,
          551,
          11,
          286,
          500,
          380,
          445,
          11,
          51254
        ]
      },
      {
        "avg_logprob": -0.20611048889160155,
        "compression_ratio": 1.755868544600939,
        "end": 4080.7000000000003,
        "id": 1360,
        "no_speech_prob": 0.000007646533049410209,
        "seek": 406138,
        "start": 4079.1800000000003,
        "temperature": 0,
        "text": " let's so, hold on, I got to look at what",
        "tokens": [
          51254,
          718,
          311,
          370,
          11,
          1797,
          322,
          11,
          286,
          658,
          281,
          574,
          412,
          437,
          51330
        ]
      },
      {
        "avg_logprob": -0.20611048889160155,
        "compression_ratio": 1.755868544600939,
        "end": 4082.02,
        "id": 1361,
        "no_speech_prob": 0.000007646533049410209,
        "seek": 406138,
        "start": 4080.7000000000003,
        "temperature": 0,
        "text": " that's going to look like.",
        "tokens": [
          51330,
          300,
          311,
          516,
          281,
          574,
          411,
          13,
          51396
        ]
      },
      {
        "avg_logprob": -0.20611048889160155,
        "compression_ratio": 1.755868544600939,
        "end": 4083.82,
        "id": 1362,
        "no_speech_prob": 0.000007646533049410209,
        "seek": 406138,
        "start": 4082.02,
        "temperature": 0,
        "text": " Let's comment this out for a second.",
        "tokens": [
          51396,
          961,
          311,
          2871,
          341,
          484,
          337,
          257,
          1150,
          13,
          51486
        ]
      },
      {
        "avg_logprob": -0.20611048889160155,
        "compression_ratio": 1.755868544600939,
        "end": 4090.26,
        "id": 1363,
        "no_speech_prob": 0.000007646533049410209,
        "seek": 406138,
        "start": 4085.26,
        "temperature": 0,
        "text": " Let's look at the y's and see what that looks like.",
        "tokens": [
          51558,
          961,
          311,
          574,
          412,
          264,
          288,
          311,
          293,
          536,
          437,
          300,
          1542,
          411,
          13,
          51808
        ]
      },
      {
        "avg_logprob": -0.2626004417737325,
        "compression_ratio": 1.4576271186440677,
        "end": 4096.9800000000005,
        "id": 1364,
        "no_speech_prob": 0.00004133536640438251,
        "seek": 409138,
        "start": 4091.98,
        "temperature": 0,
        "text": " Oh, okay, sketch.78 error.",
        "tokens": [
          50394,
          876,
          11,
          1392,
          11,
          12325,
          13,
          30693,
          6713,
          13,
          50644
        ]
      },
      {
        "avg_logprob": -0.2626004417737325,
        "compression_ratio": 1.4576271186440677,
        "end": 4102.18,
        "id": 1365,
        "no_speech_prob": 0.00004133536640438251,
        "seek": 409138,
        "start": 4097.18,
        "temperature": 0,
        "text": " Oh, no let there, just inputs.push.",
        "tokens": [
          50654,
          876,
          11,
          572,
          718,
          456,
          11,
          445,
          15743,
          13,
          79,
          1498,
          13,
          50904
        ]
      },
      {
        "avg_logprob": -0.2626004417737325,
        "compression_ratio": 1.4576271186440677,
        "end": 4106.86,
        "id": 1366,
        "no_speech_prob": 0.00004133536640438251,
        "seek": 409138,
        "start": 4104.7,
        "temperature": 0,
        "text": " Okay, oh, I want to say no loop.",
        "tokens": [
          51030,
          1033,
          11,
          1954,
          11,
          286,
          528,
          281,
          584,
          572,
          6367,
          13,
          51138
        ]
      },
      {
        "avg_logprob": -0.2626004417737325,
        "compression_ratio": 1.4576271186440677,
        "end": 4109.9800000000005,
        "id": 1367,
        "no_speech_prob": 0.00004133536640438251,
        "seek": 409138,
        "start": 4106.86,
        "temperature": 0,
        "text": " Let me leave that no loop in, put it back.",
        "tokens": [
          51138,
          961,
          385,
          1856,
          300,
          572,
          6367,
          294,
          11,
          829,
          309,
          646,
          13,
          51294
        ]
      },
      {
        "avg_logprob": -0.2626004417737325,
        "compression_ratio": 1.4576271186440677,
        "end": 4112,
        "id": 1368,
        "no_speech_prob": 0.00004133536640438251,
        "seek": 409138,
        "start": 4109.9800000000005,
        "temperature": 0,
        "text": " I just want to look at it once.",
        "tokens": [
          51294,
          286,
          445,
          528,
          281,
          574,
          412,
          309,
          1564,
          13,
          51395
        ]
      },
      {
        "avg_logprob": -0.2626004417737325,
        "compression_ratio": 1.4576271186440677,
        "end": 4113.78,
        "id": 1369,
        "no_speech_prob": 0.00004133536640438251,
        "seek": 409138,
        "start": 4112,
        "temperature": 0,
        "text": " So you can see, what did I get?",
        "tokens": [
          51395,
          407,
          291,
          393,
          536,
          11,
          437,
          630,
          286,
          483,
          30,
          51484
        ]
      },
      {
        "avg_logprob": -0.2626004417737325,
        "compression_ratio": 1.4576271186440677,
        "end": 4115.68,
        "id": 1370,
        "no_speech_prob": 0.00004133536640438251,
        "seek": 409138,
        "start": 4113.78,
        "temperature": 0,
        "text": " I got a big array of 16 numbers.",
        "tokens": [
          51484,
          286,
          658,
          257,
          955,
          10225,
          295,
          3165,
          3547,
          13,
          51579
        ]
      },
      {
        "avg_logprob": -0.2626004417737325,
        "compression_ratio": 1.4576271186440677,
        "end": 4117.26,
        "id": 1371,
        "no_speech_prob": 0.00004133536640438251,
        "seek": 409138,
        "start": 4115.68,
        "temperature": 0,
        "text": " I got all the results.",
        "tokens": [
          51579,
          286,
          658,
          439,
          264,
          3542,
          13,
          51658
        ]
      },
      {
        "avg_logprob": -0.28128209678075644,
        "compression_ratio": 1.5621621621621622,
        "end": 4122.780000000001,
        "id": 1372,
        "no_speech_prob": 0.000017231568563147448,
        "seek": 411726,
        "start": 4118.26,
        "temperature": 0,
        "text": " So now what I want to do is, back here,",
        "tokens": [
          50414,
          407,
          586,
          437,
          286,
          528,
          281,
          360,
          307,
          11,
          646,
          510,
          11,
          50640
        ]
      },
      {
        "avg_logprob": -0.28128209678075644,
        "compression_ratio": 1.5621621621621622,
        "end": 4126.08,
        "id": 1373,
        "no_speech_prob": 0.000017231568563147448,
        "seek": 411726,
        "start": 4124.38,
        "temperature": 0,
        "text": " now I just need to do the drawing.",
        "tokens": [
          50720,
          586,
          286,
          445,
          643,
          281,
          360,
          264,
          6316,
          13,
          50805
        ]
      },
      {
        "avg_logprob": -0.28128209678075644,
        "compression_ratio": 1.5621621621621622,
        "end": 4130.3,
        "id": 1374,
        "no_speech_prob": 0.000017231568563147448,
        "seek": 411726,
        "start": 4127.62,
        "temperature": 0,
        "text": " And I don't need the input data, I don't need the model,",
        "tokens": [
          50882,
          400,
          286,
          500,
          380,
          643,
          264,
          4846,
          1412,
          11,
          286,
          500,
          380,
          643,
          264,
          2316,
          11,
          51016
        ]
      },
      {
        "avg_logprob": -0.28128209678075644,
        "compression_ratio": 1.5621621621621622,
        "end": 4133.22,
        "id": 1375,
        "no_speech_prob": 0.000017231568563147448,
        "seek": 411726,
        "start": 4130.3,
        "temperature": 0,
        "text": " all I need to do is draw and I need to say fill,",
        "tokens": [
          51016,
          439,
          286,
          643,
          281,
          360,
          307,
          2642,
          293,
          286,
          643,
          281,
          584,
          2836,
          11,
          51162
        ]
      },
      {
        "avg_logprob": -0.28128209678075644,
        "compression_ratio": 1.5621621621621622,
        "end": 4136.1,
        "id": 1376,
        "no_speech_prob": 0.000017231568563147448,
        "seek": 411726,
        "start": 4133.22,
        "temperature": 0,
        "text": " y's, index, what?",
        "tokens": [
          51162,
          288,
          311,
          11,
          8186,
          11,
          437,
          30,
          51306
        ]
      },
      {
        "avg_logprob": -0.28128209678075644,
        "compression_ratio": 1.5621621621621622,
        "end": 4140.280000000001,
        "id": 1377,
        "no_speech_prob": 0.000017231568563147448,
        "seek": 411726,
        "start": 4136.1,
        "temperature": 0,
        "text": " I plus j times the number of columns maybe?",
        "tokens": [
          51306,
          286,
          1804,
          361,
          1413,
          264,
          1230,
          295,
          13766,
          1310,
          30,
          51515
        ]
      },
      {
        "avg_logprob": -0.28128209678075644,
        "compression_ratio": 1.5621621621621622,
        "end": 4143.26,
        "id": 1378,
        "no_speech_prob": 0.000017231568563147448,
        "seek": 411726,
        "start": 4140.280000000001,
        "temperature": 0,
        "text": " Right, because this is a one dimensional array",
        "tokens": [
          51515,
          1779,
          11,
          570,
          341,
          307,
          257,
          472,
          18795,
          10225,
          51664
        ]
      },
      {
        "avg_logprob": -0.28499949875698294,
        "compression_ratio": 1.5170731707317073,
        "end": 4147.66,
        "id": 1379,
        "no_speech_prob": 0.00004757641727337614,
        "seek": 414326,
        "start": 4143.26,
        "temperature": 0,
        "text": " to describe each spot in that grid.",
        "tokens": [
          50364,
          281,
          6786,
          1184,
          4008,
          294,
          300,
          10748,
          13,
          50584
        ]
      },
      {
        "avg_logprob": -0.28499949875698294,
        "compression_ratio": 1.5170731707317073,
        "end": 4149.46,
        "id": 1380,
        "no_speech_prob": 0.00004757641727337614,
        "seek": 414326,
        "start": 4147.66,
        "temperature": 0,
        "text": " I could do something like, maybe I'll just do this,",
        "tokens": [
          50584,
          286,
          727,
          360,
          746,
          411,
          11,
          1310,
          286,
          603,
          445,
          360,
          341,
          11,
          50674
        ]
      },
      {
        "avg_logprob": -0.28499949875698294,
        "compression_ratio": 1.5170731707317073,
        "end": 4152.5,
        "id": 1381,
        "no_speech_prob": 0.00004757641727337614,
        "seek": 414326,
        "start": 4149.46,
        "temperature": 0,
        "text": " let index equal zero, and I'm going to say fill",
        "tokens": [
          50674,
          718,
          8186,
          2681,
          4018,
          11,
          293,
          286,
          478,
          516,
          281,
          584,
          2836,
          50826
        ]
      },
      {
        "avg_logprob": -0.28499949875698294,
        "compression_ratio": 1.5170731707317073,
        "end": 4154.22,
        "id": 1382,
        "no_speech_prob": 0.00004757641727337614,
        "seek": 414326,
        "start": 4152.5,
        "temperature": 0,
        "text": " based on this particular one.",
        "tokens": [
          50826,
          2361,
          322,
          341,
          1729,
          472,
          13,
          50912
        ]
      },
      {
        "avg_logprob": -0.28499949875698294,
        "compression_ratio": 1.5170731707317073,
        "end": 4157.18,
        "id": 1383,
        "no_speech_prob": 0.00004757641727337614,
        "seek": 414326,
        "start": 4155.38,
        "temperature": 0,
        "text": " And I don't need this even, sorry.",
        "tokens": [
          50970,
          400,
          286,
          500,
          380,
          643,
          341,
          754,
          11,
          2597,
          13,
          51060
        ]
      },
      {
        "avg_logprob": -0.28499949875698294,
        "compression_ratio": 1.5170731707317073,
        "end": 4162.1,
        "id": 1384,
        "no_speech_prob": 0.00004757641727337614,
        "seek": 414326,
        "start": 4158.54,
        "temperature": 0,
        "text": " And I just need to say then index plus plus.",
        "tokens": [
          51128,
          400,
          286,
          445,
          643,
          281,
          584,
          550,
          8186,
          1804,
          1804,
          13,
          51306
        ]
      },
      {
        "avg_logprob": -0.28499949875698294,
        "compression_ratio": 1.5170731707317073,
        "end": 4163.3,
        "id": 1385,
        "no_speech_prob": 0.00004757641727337614,
        "seek": 414326,
        "start": 4162.1,
        "temperature": 0,
        "text": " So what are the steps here?",
        "tokens": [
          51306,
          407,
          437,
          366,
          264,
          4439,
          510,
          30,
          51366
        ]
      },
      {
        "avg_logprob": -0.28499949875698294,
        "compression_ratio": 1.5170731707317073,
        "end": 4167.4400000000005,
        "id": 1386,
        "no_speech_prob": 0.00004757641727337614,
        "seek": 414326,
        "start": 4163.3,
        "temperature": 0,
        "text": " Create the data, get the predictions,",
        "tokens": [
          51366,
          20248,
          264,
          1412,
          11,
          483,
          264,
          21264,
          11,
          51573
        ]
      },
      {
        "avg_logprob": -0.28060402408722906,
        "compression_ratio": 1.4864864864864864,
        "end": 4172.44,
        "id": 1387,
        "no_speech_prob": 0.000029311495381989516,
        "seek": 416744,
        "start": 4167.44,
        "temperature": 0,
        "text": " draw the results, okay?",
        "tokens": [
          50364,
          2642,
          264,
          3542,
          11,
          1392,
          30,
          50614
        ]
      },
      {
        "avg_logprob": -0.28060402408722906,
        "compression_ratio": 1.4864864864864864,
        "end": 4179.48,
        "id": 1388,
        "no_speech_prob": 0.000029311495381989516,
        "seek": 416744,
        "start": 4178.5199999999995,
        "temperature": 0,
        "text": " There we go.",
        "tokens": [
          50918,
          821,
          321,
          352,
          13,
          50966
        ]
      },
      {
        "avg_logprob": -0.28060402408722906,
        "compression_ratio": 1.4864864864864864,
        "end": 4181.759999999999,
        "id": 1389,
        "no_speech_prob": 0.000029311495381989516,
        "seek": 416744,
        "start": 4179.48,
        "temperature": 0,
        "text": " So now we can see this is working.",
        "tokens": [
          50966,
          407,
          586,
          321,
          393,
          536,
          341,
          307,
          1364,
          13,
          51080
        ]
      },
      {
        "avg_logprob": -0.28060402408722906,
        "compression_ratio": 1.4864864864864864,
        "end": 4182.719999999999,
        "id": 1390,
        "no_speech_prob": 0.000029311495381989516,
        "seek": 416744,
        "start": 4181.759999999999,
        "temperature": 0,
        "text": " I mean, it's not doing anything,",
        "tokens": [
          51080,
          286,
          914,
          11,
          309,
          311,
          406,
          884,
          1340,
          11,
          51128
        ]
      },
      {
        "avg_logprob": -0.28060402408722906,
        "compression_ratio": 1.4864864864864864,
        "end": 4185.04,
        "id": 1391,
        "no_speech_prob": 0.000029311495381989516,
        "seek": 416744,
        "start": 4182.719999999999,
        "temperature": 0,
        "text": " but now let's check this frame rate question.",
        "tokens": [
          51128,
          457,
          586,
          718,
          311,
          1520,
          341,
          3920,
          3314,
          1168,
          13,
          51244
        ]
      },
      {
        "avg_logprob": -0.28060402408722906,
        "compression_ratio": 1.4864864864864864,
        "end": 4187.24,
        "id": 1392,
        "no_speech_prob": 0.000029311495381989516,
        "seek": 416744,
        "start": 4185.04,
        "temperature": 0,
        "text": " We don't need to console log the y's.",
        "tokens": [
          51244,
          492,
          500,
          380,
          643,
          281,
          11076,
          3565,
          264,
          288,
          311,
          13,
          51354
        ]
      },
      {
        "avg_logprob": -0.28060402408722906,
        "compression_ratio": 1.4864864864864864,
        "end": 4189.2,
        "id": 1393,
        "no_speech_prob": 0.000029311495381989516,
        "seek": 416744,
        "start": 4187.24,
        "temperature": 0,
        "text": " I'm going to get rid of the no loop.",
        "tokens": [
          51354,
          286,
          478,
          516,
          281,
          483,
          3973,
          295,
          264,
          572,
          6367,
          13,
          51452
        ]
      },
      {
        "avg_logprob": -0.28060402408722906,
        "compression_ratio": 1.4864864864864864,
        "end": 4193.24,
        "id": 1394,
        "no_speech_prob": 0.000029311495381989516,
        "seek": 416744,
        "start": 4191,
        "temperature": 0,
        "text": " Let's refresh this.",
        "tokens": [
          51542,
          961,
          311,
          15134,
          341,
          13,
          51654
        ]
      },
      {
        "avg_logprob": -0.28060402408722906,
        "compression_ratio": 1.4864864864864864,
        "end": 4196.719999999999,
        "id": 1395,
        "no_speech_prob": 0.000029311495381989516,
        "seek": 416744,
        "start": 4194.719999999999,
        "temperature": 0,
        "text": " Let's look at the frame rate.",
        "tokens": [
          51728,
          961,
          311,
          574,
          412,
          264,
          3920,
          3314,
          13,
          51828
        ]
      },
      {
        "avg_logprob": -0.21965241865678267,
        "compression_ratio": 1.5799086757990868,
        "end": 4198,
        "id": 1396,
        "no_speech_prob": 0.000017502912669442594,
        "seek": 419672,
        "start": 4196.72,
        "temperature": 0,
        "text": " 30 frames per second.",
        "tokens": [
          50364,
          2217,
          12083,
          680,
          1150,
          13,
          50428
        ]
      },
      {
        "avg_logprob": -0.21965241865678267,
        "compression_ratio": 1.5799086757990868,
        "end": 4201.04,
        "id": 1397,
        "no_speech_prob": 0.000017502912669442594,
        "seek": 419672,
        "start": 4198,
        "temperature": 0,
        "text": " Let's pump it up a little.",
        "tokens": [
          50428,
          961,
          311,
          5889,
          309,
          493,
          257,
          707,
          13,
          50580
        ]
      },
      {
        "avg_logprob": -0.21965241865678267,
        "compression_ratio": 1.5799086757990868,
        "end": 4204.1,
        "id": 1398,
        "no_speech_prob": 0.000017502912669442594,
        "seek": 419672,
        "start": 4201.04,
        "temperature": 0,
        "text": " Let's pump you up a little.",
        "tokens": [
          50580,
          961,
          311,
          5889,
          291,
          493,
          257,
          707,
          13,
          50733
        ]
      },
      {
        "avg_logprob": -0.21965241865678267,
        "compression_ratio": 1.5799086757990868,
        "end": 4207.96,
        "id": 1399,
        "no_speech_prob": 0.000017502912669442594,
        "seek": 419672,
        "start": 4205.12,
        "temperature": 0,
        "text": " And where was the resolution there?",
        "tokens": [
          50784,
          400,
          689,
          390,
          264,
          8669,
          456,
          30,
          50926
        ]
      },
      {
        "avg_logprob": -0.21965241865678267,
        "compression_ratio": 1.5799086757990868,
        "end": 4209.4400000000005,
        "id": 1400,
        "no_speech_prob": 0.000017502912669442594,
        "seek": 419672,
        "start": 4207.96,
        "temperature": 0,
        "text": " Let's make this 20.",
        "tokens": [
          50926,
          961,
          311,
          652,
          341,
          945,
          13,
          51000
        ]
      },
      {
        "avg_logprob": -0.21965241865678267,
        "compression_ratio": 1.5799086757990868,
        "end": 4210.6,
        "id": 1401,
        "no_speech_prob": 0.000017502912669442594,
        "seek": 419672,
        "start": 4209.4400000000005,
        "temperature": 0,
        "text": " Don't want to go crazy.",
        "tokens": [
          51000,
          1468,
          380,
          528,
          281,
          352,
          3219,
          13,
          51058
        ]
      },
      {
        "avg_logprob": -0.21965241865678267,
        "compression_ratio": 1.5799086757990868,
        "end": 4213.34,
        "id": 1402,
        "no_speech_prob": 0.000017502912669442594,
        "seek": 419672,
        "start": 4212.4400000000005,
        "temperature": 0,
        "text": " And look at the frame rate.",
        "tokens": [
          51150,
          400,
          574,
          412,
          264,
          3920,
          3314,
          13,
          51195
        ]
      },
      {
        "avg_logprob": -0.21965241865678267,
        "compression_ratio": 1.5799086757990868,
        "end": 4215.7,
        "id": 1403,
        "no_speech_prob": 0.000017502912669442594,
        "seek": 419672,
        "start": 4213.34,
        "temperature": 0,
        "text": " There we go, 30 frames per second, no problem,",
        "tokens": [
          51195,
          821,
          321,
          352,
          11,
          2217,
          12083,
          680,
          1150,
          11,
          572,
          1154,
          11,
          51313
        ]
      },
      {
        "avg_logprob": -0.21965241865678267,
        "compression_ratio": 1.5799086757990868,
        "end": 4218.400000000001,
        "id": 1404,
        "no_speech_prob": 0.000017502912669442594,
        "seek": 419672,
        "start": 4215.7,
        "temperature": 0,
        "text": " because I'm only one time through draw",
        "tokens": [
          51313,
          570,
          286,
          478,
          787,
          472,
          565,
          807,
          2642,
          51448
        ]
      },
      {
        "avg_logprob": -0.21965241865678267,
        "compression_ratio": 1.5799086757990868,
        "end": 4222.12,
        "id": 1405,
        "no_speech_prob": 0.000017502912669442594,
        "seek": 419672,
        "start": 4218.400000000001,
        "temperature": 0,
        "text": " trying to copy data onto the GPU and get it.",
        "tokens": [
          51448,
          1382,
          281,
          5055,
          1412,
          3911,
          264,
          18407,
          293,
          483,
          309,
          13,
          51634
        ]
      },
      {
        "avg_logprob": -0.21965241865678267,
        "compression_ratio": 1.5799086757990868,
        "end": 4224.240000000001,
        "id": 1406,
        "no_speech_prob": 0.000017502912669442594,
        "seek": 419672,
        "start": 4222.12,
        "temperature": 0,
        "text": " I'm only calling predict once.",
        "tokens": [
          51634,
          286,
          478,
          787,
          5141,
          6069,
          1564,
          13,
          51740
        ]
      },
      {
        "avg_logprob": -0.24895439773309427,
        "compression_ratio": 1.5769230769230769,
        "end": 4226.92,
        "id": 1407,
        "no_speech_prob": 0.0000018738749076874228,
        "seek": 422424,
        "start": 4224.24,
        "temperature": 0,
        "text": " And we can, just to check, we can go to 10.",
        "tokens": [
          50364,
          400,
          321,
          393,
          11,
          445,
          281,
          1520,
          11,
          321,
          393,
          352,
          281,
          1266,
          13,
          50498
        ]
      },
      {
        "avg_logprob": -0.24895439773309427,
        "compression_ratio": 1.5769230769230769,
        "end": 4231.5599999999995,
        "id": 1408,
        "no_speech_prob": 0.0000018738749076874228,
        "seek": 422424,
        "start": 4229.44,
        "temperature": 0,
        "text": " And we can look at the frame rate.",
        "tokens": [
          50624,
          400,
          321,
          393,
          574,
          412,
          264,
          3920,
          3314,
          13,
          50730
        ]
      },
      {
        "avg_logprob": -0.24895439773309427,
        "compression_ratio": 1.5769230769230769,
        "end": 4233.08,
        "id": 1409,
        "no_speech_prob": 0.0000018738749076874228,
        "seek": 422424,
        "start": 4231.5599999999995,
        "temperature": 0,
        "text": " And you can see it's like kind of running",
        "tokens": [
          50730,
          400,
          291,
          393,
          536,
          309,
          311,
          411,
          733,
          295,
          2614,
          50806
        ]
      },
      {
        "avg_logprob": -0.24895439773309427,
        "compression_ratio": 1.5769230769230769,
        "end": 4234.76,
        "id": 1410,
        "no_speech_prob": 0.0000018738749076874228,
        "seek": 422424,
        "start": 4233.08,
        "temperature": 0,
        "text": " a little bit slow, but this is because",
        "tokens": [
          50806,
          257,
          707,
          857,
          2964,
          11,
          457,
          341,
          307,
          570,
          50890
        ]
      },
      {
        "avg_logprob": -0.24895439773309427,
        "compression_ratio": 1.5769230769230769,
        "end": 4236.32,
        "id": 1411,
        "no_speech_prob": 0.0000018738749076874228,
        "seek": 422424,
        "start": 4234.76,
        "temperature": 0,
        "text": " I'm not being too thoughtful about",
        "tokens": [
          50890,
          286,
          478,
          406,
          885,
          886,
          21566,
          466,
          50968
        ]
      },
      {
        "avg_logprob": -0.24895439773309427,
        "compression_ratio": 1.5769230769230769,
        "end": 4237.98,
        "id": 1412,
        "no_speech_prob": 0.0000018738749076874228,
        "seek": 422424,
        "start": 4236.32,
        "temperature": 0,
        "text": " the asynchronous nature of this stuff.",
        "tokens": [
          50968,
          264,
          49174,
          3687,
          295,
          341,
          1507,
          13,
          51051
        ]
      },
      {
        "avg_logprob": -0.24895439773309427,
        "compression_ratio": 1.5769230769230769,
        "end": 4239.599999999999,
        "id": 1413,
        "no_speech_prob": 0.0000018738749076874228,
        "seek": 422424,
        "start": 4237.98,
        "temperature": 0,
        "text": " I could do other things to optimize it,",
        "tokens": [
          51051,
          286,
          727,
          360,
          661,
          721,
          281,
          19719,
          309,
          11,
          51132
        ]
      },
      {
        "avg_logprob": -0.24895439773309427,
        "compression_ratio": 1.5769230769230769,
        "end": 4242.5199999999995,
        "id": 1414,
        "no_speech_prob": 0.0000018738749076874228,
        "seek": 422424,
        "start": 4239.599999999999,
        "temperature": 0,
        "text": " but I'm just going to ignore that and leave it at,",
        "tokens": [
          51132,
          457,
          286,
          478,
          445,
          516,
          281,
          11200,
          300,
          293,
          1856,
          309,
          412,
          11,
          51278
        ]
      },
      {
        "avg_logprob": -0.24895439773309427,
        "compression_ratio": 1.5769230769230769,
        "end": 4243.719999999999,
        "id": 1415,
        "no_speech_prob": 0.0000018738749076874228,
        "seek": 422424,
        "start": 4242.5199999999995,
        "temperature": 0,
        "text": " let me make it 25.",
        "tokens": [
          51278,
          718,
          385,
          652,
          309,
          3552,
          13,
          51338
        ]
      },
      {
        "avg_logprob": -0.24895439773309427,
        "compression_ratio": 1.5769230769230769,
        "end": 4247.76,
        "id": 1416,
        "no_speech_prob": 0.0000018738749076874228,
        "seek": 422424,
        "start": 4246.36,
        "temperature": 0,
        "text": " Hey, time out for a sec.",
        "tokens": [
          51470,
          1911,
          11,
          565,
          484,
          337,
          257,
          907,
          13,
          51540
        ]
      },
      {
        "avg_logprob": -0.24895439773309427,
        "compression_ratio": 1.5769230769230769,
        "end": 4252.599999999999,
        "id": 1417,
        "no_speech_prob": 0.0000018738749076874228,
        "seek": 422424,
        "start": 4250.5599999999995,
        "temperature": 0,
        "text": " This should definitely be multiple parts.",
        "tokens": [
          51680,
          639,
          820,
          2138,
          312,
          3866,
          3166,
          13,
          51782
        ]
      },
      {
        "avg_logprob": -0.2597436820511269,
        "compression_ratio": 1.5990338164251208,
        "end": 4257.08,
        "id": 1418,
        "no_speech_prob": 0.00000402944533561822,
        "seek": 425424,
        "start": 4254.76,
        "temperature": 0,
        "text": " Oh yeah, create inputs at the start, they are constant.",
        "tokens": [
          50390,
          876,
          1338,
          11,
          1884,
          15743,
          412,
          264,
          722,
          11,
          436,
          366,
          5754,
          13,
          50506
        ]
      },
      {
        "avg_logprob": -0.2597436820511269,
        "compression_ratio": 1.5990338164251208,
        "end": 4258.5199999999995,
        "id": 1419,
        "no_speech_prob": 0.00000402944533561822,
        "seek": 425424,
        "start": 4257.08,
        "temperature": 0,
        "text": " Oh, that's such a good point.",
        "tokens": [
          50506,
          876,
          11,
          300,
          311,
          1270,
          257,
          665,
          935,
          13,
          50578
        ]
      },
      {
        "avg_logprob": -0.2597436820511269,
        "compression_ratio": 1.5990338164251208,
        "end": 4260.8,
        "id": 1420,
        "no_speech_prob": 0.00000402944533561822,
        "seek": 425424,
        "start": 4259.44,
        "temperature": 0,
        "text": " Okay, I'm going to do that right now.",
        "tokens": [
          50624,
          1033,
          11,
          286,
          478,
          516,
          281,
          360,
          300,
          558,
          586,
          13,
          50692
        ]
      },
      {
        "avg_logprob": -0.2597436820511269,
        "compression_ratio": 1.5990338164251208,
        "end": 4262.16,
        "id": 1421,
        "no_speech_prob": 0.00000402944533561822,
        "seek": 425424,
        "start": 4260.8,
        "temperature": 0,
        "text": " That's a very good point.",
        "tokens": [
          50692,
          663,
          311,
          257,
          588,
          665,
          935,
          13,
          50760
        ]
      },
      {
        "avg_logprob": -0.2597436820511269,
        "compression_ratio": 1.5990338164251208,
        "end": 4264,
        "id": 1422,
        "no_speech_prob": 0.00000402944533561822,
        "seek": 425424,
        "start": 4262.16,
        "temperature": 0,
        "text": " Who said that in the chat?",
        "tokens": [
          50760,
          2102,
          848,
          300,
          294,
          264,
          5081,
          30,
          50852
        ]
      },
      {
        "avg_logprob": -0.2597436820511269,
        "compression_ratio": 1.5990338164251208,
        "end": 4265.44,
        "id": 1423,
        "no_speech_prob": 0.00000402944533561822,
        "seek": 425424,
        "start": 4264,
        "temperature": 0,
        "text": " Probably lots of people have.",
        "tokens": [
          50852,
          9210,
          3195,
          295,
          561,
          362,
          13,
          50924
        ]
      },
      {
        "avg_logprob": -0.2597436820511269,
        "compression_ratio": 1.5990338164251208,
        "end": 4269.4,
        "id": 1424,
        "no_speech_prob": 0.00000402944533561822,
        "seek": 425424,
        "start": 4267.719999999999,
        "temperature": 0,
        "text": " Pre-calculate them, set up error.",
        "tokens": [
          51038,
          6001,
          12,
          9895,
          2444,
          473,
          552,
          11,
          992,
          493,
          6713,
          13,
          51122
        ]
      },
      {
        "avg_logprob": -0.2597436820511269,
        "compression_ratio": 1.5990338164251208,
        "end": 4270.44,
        "id": 1425,
        "no_speech_prob": 0.00000402944533561822,
        "seek": 425424,
        "start": 4269.4,
        "temperature": 0,
        "text": " Bunch of people have.",
        "tokens": [
          51122,
          363,
          1680,
          295,
          561,
          362,
          13,
          51174
        ]
      },
      {
        "avg_logprob": -0.2597436820511269,
        "compression_ratio": 1.5990338164251208,
        "end": 4272.98,
        "id": 1426,
        "no_speech_prob": 0.00000402944533561822,
        "seek": 425424,
        "start": 4272.16,
        "temperature": 0,
        "text": " Yeah, okay.",
        "tokens": [
          51260,
          865,
          11,
          1392,
          13,
          51301
        ]
      },
      {
        "avg_logprob": -0.2597436820511269,
        "compression_ratio": 1.5990338164251208,
        "end": 4278,
        "id": 1427,
        "no_speech_prob": 0.00000402944533561822,
        "seek": 425424,
        "start": 4276.96,
        "temperature": 0,
        "text": " Oh, this.",
        "tokens": [
          51500,
          876,
          11,
          341,
          13,
          51552
        ]
      },
      {
        "avg_logprob": -0.2597436820511269,
        "compression_ratio": 1.5990338164251208,
        "end": 4283.5599999999995,
        "id": 1428,
        "no_speech_prob": 0.00000402944533561822,
        "seek": 425424,
        "start": 4281.76,
        "temperature": 0,
        "text": " All right, all right, everybody's saying that.",
        "tokens": [
          51740,
          1057,
          558,
          11,
          439,
          558,
          11,
          2201,
          311,
          1566,
          300,
          13,
          51830
        ]
      },
      {
        "avg_logprob": -0.25123806794484455,
        "compression_ratio": 1.5980861244019138,
        "end": 4284.38,
        "id": 1429,
        "no_speech_prob": 0.000018058459318126552,
        "seek": 428356,
        "start": 4283.56,
        "temperature": 0,
        "text": " All right.",
        "tokens": [
          50364,
          1057,
          558,
          13,
          50405
        ]
      },
      {
        "avg_logprob": -0.25123806794484455,
        "compression_ratio": 1.5980861244019138,
        "end": 4293.96,
        "id": 1430,
        "no_speech_prob": 0.000018058459318126552,
        "seek": 428356,
        "start": 4291.080000000001,
        "temperature": 0,
        "text": " The chat is giving me some even further optimization,",
        "tokens": [
          50740,
          440,
          5081,
          307,
          2902,
          385,
          512,
          754,
          3052,
          19618,
          11,
          50884
        ]
      },
      {
        "avg_logprob": -0.25123806794484455,
        "compression_ratio": 1.5980861244019138,
        "end": 4298.6,
        "id": 1431,
        "no_speech_prob": 0.000018058459318126552,
        "seek": 428356,
        "start": 4293.96,
        "temperature": 0,
        "text": " which is why am I bothering to do this in draw?",
        "tokens": [
          50884,
          597,
          307,
          983,
          669,
          286,
          31432,
          281,
          360,
          341,
          294,
          2642,
          30,
          51116
        ]
      },
      {
        "avg_logprob": -0.25123806794484455,
        "compression_ratio": 1.5980861244019138,
        "end": 4302.240000000001,
        "id": 1432,
        "no_speech_prob": 0.000018058459318126552,
        "seek": 428356,
        "start": 4298.6,
        "temperature": 0,
        "text": " This is something that, these inputs never change.",
        "tokens": [
          51116,
          639,
          307,
          746,
          300,
          11,
          613,
          15743,
          1128,
          1319,
          13,
          51298
        ]
      },
      {
        "avg_logprob": -0.25123806794484455,
        "compression_ratio": 1.5980861244019138,
        "end": 4305.04,
        "id": 1433,
        "no_speech_prob": 0.000018058459318126552,
        "seek": 428356,
        "start": 4302.240000000001,
        "temperature": 0,
        "text": " I can just do them once at the beginning,",
        "tokens": [
          51298,
          286,
          393,
          445,
          360,
          552,
          1564,
          412,
          264,
          2863,
          11,
          51438
        ]
      },
      {
        "avg_logprob": -0.25123806794484455,
        "compression_ratio": 1.5980861244019138,
        "end": 4309.200000000001,
        "id": 1434,
        "no_speech_prob": 0.000018058459318126552,
        "seek": 428356,
        "start": 4305.04,
        "temperature": 0,
        "text": " because, and I can ask for them many times in draw.",
        "tokens": [
          51438,
          570,
          11,
          293,
          286,
          393,
          1029,
          337,
          552,
          867,
          1413,
          294,
          2642,
          13,
          51646
        ]
      },
      {
        "avg_logprob": -0.25123806794484455,
        "compression_ratio": 1.5980861244019138,
        "end": 4310.68,
        "id": 1435,
        "no_speech_prob": 0.000018058459318126552,
        "seek": 428356,
        "start": 4309.200000000001,
        "temperature": 0,
        "text": " So let's actually fix that.",
        "tokens": [
          51646,
          407,
          718,
          311,
          767,
          3191,
          300,
          13,
          51720
        ]
      },
      {
        "avg_logprob": -0.25123806794484455,
        "compression_ratio": 1.5980861244019138,
        "end": 4312.56,
        "id": 1436,
        "no_speech_prob": 0.000018058459318126552,
        "seek": 428356,
        "start": 4310.68,
        "temperature": 0,
        "text": " So I'm actually going to, I'm going to take this",
        "tokens": [
          51720,
          407,
          286,
          478,
          767,
          516,
          281,
          11,
          286,
          478,
          516,
          281,
          747,
          341,
          51814
        ]
      },
      {
        "avg_logprob": -0.3791938928457407,
        "compression_ratio": 1.5532994923857868,
        "end": 4316.240000000001,
        "id": 1437,
        "no_speech_prob": 0.00008349594281753525,
        "seek": 431256,
        "start": 4312.56,
        "temperature": 0,
        "text": " and say, I'm going to make these global variables.",
        "tokens": [
          50364,
          293,
          584,
          11,
          286,
          478,
          516,
          281,
          652,
          613,
          4338,
          9102,
          13,
          50548
        ]
      },
      {
        "avg_logprob": -0.3791938928457407,
        "compression_ratio": 1.5532994923857868,
        "end": 4319.4800000000005,
        "id": 1438,
        "no_speech_prob": 0.00008349594281753525,
        "seek": 431256,
        "start": 4317.84,
        "temperature": 0,
        "text": " I don't know if you guys can hear the music.",
        "tokens": [
          50628,
          286,
          500,
          380,
          458,
          498,
          291,
          1074,
          393,
          1568,
          264,
          1318,
          13,
          50710
        ]
      },
      {
        "avg_logprob": -0.3791938928457407,
        "compression_ratio": 1.5532994923857868,
        "end": 4322.120000000001,
        "id": 1439,
        "no_speech_prob": 0.00008349594281753525,
        "seek": 431256,
        "start": 4319.4800000000005,
        "temperature": 0,
        "text": " It's coming from the room next to me, but it's there.",
        "tokens": [
          50710,
          467,
          311,
          1348,
          490,
          264,
          1808,
          958,
          281,
          385,
          11,
          457,
          309,
          311,
          456,
          13,
          50842
        ]
      },
      {
        "avg_logprob": -0.3791938928457407,
        "compression_ratio": 1.5532994923857868,
        "end": 4325.56,
        "id": 1440,
        "no_speech_prob": 0.00008349594281753525,
        "seek": 431256,
        "start": 4323.360000000001,
        "temperature": 0,
        "text": " Beh, wah, wah, wah, wah.",
        "tokens": [
          50904,
          220,
          6524,
          71,
          11,
          31979,
          11,
          31979,
          11,
          31979,
          11,
          31979,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.3791938928457407,
        "compression_ratio": 1.5532994923857868,
        "end": 4327.3,
        "id": 1441,
        "no_speech_prob": 0.00008349594281753525,
        "seek": 431256,
        "start": 4325.56,
        "temperature": 0,
        "text": " All right, then, ooh.",
        "tokens": [
          51014,
          1057,
          558,
          11,
          550,
          11,
          17024,
          13,
          51101
        ]
      },
      {
        "avg_logprob": -0.3791938928457407,
        "compression_ratio": 1.5532994923857868,
        "end": 4330.240000000001,
        "id": 1442,
        "no_speech_prob": 0.00008349594281753525,
        "seek": 431256,
        "start": 4328.160000000001,
        "temperature": 0,
        "text": " Oh, but the width and height does not exist",
        "tokens": [
          51144,
          876,
          11,
          457,
          264,
          11402,
          293,
          6681,
          775,
          406,
          2514,
          51248
        ]
      },
      {
        "avg_logprob": -0.3791938928457407,
        "compression_ratio": 1.5532994923857868,
        "end": 4332.580000000001,
        "id": 1443,
        "no_speech_prob": 0.00008349594281753525,
        "seek": 431256,
        "start": 4330.240000000001,
        "temperature": 0,
        "text": " until after create canvas.",
        "tokens": [
          51248,
          1826,
          934,
          1884,
          16267,
          13,
          51365
        ]
      },
      {
        "avg_logprob": -0.3791938928457407,
        "compression_ratio": 1.5532994923857868,
        "end": 4336.8,
        "id": 1444,
        "no_speech_prob": 0.00008349594281753525,
        "seek": 431256,
        "start": 4335.280000000001,
        "temperature": 0,
        "text": " So let me do this.",
        "tokens": [
          51500,
          407,
          718,
          385,
          360,
          341,
          13,
          51576
        ]
      },
      {
        "avg_logprob": -0.3791938928457407,
        "compression_ratio": 1.5532994923857868,
        "end": 4341.240000000001,
        "id": 1445,
        "no_speech_prob": 0.00008349594281753525,
        "seek": 431256,
        "start": 4340.320000000001,
        "temperature": 0,
        "text": " And let me do this.",
        "tokens": [
          51752,
          400,
          718,
          385,
          360,
          341,
          13,
          51798
        ]
      },
      {
        "avg_logprob": -0.25772751151741324,
        "compression_ratio": 1.4746835443037976,
        "end": 4345.240000000001,
        "id": 1446,
        "no_speech_prob": 0.000014510455912386533,
        "seek": 434256,
        "start": 4343.400000000001,
        "temperature": 0,
        "text": " Okay, so now that's there.",
        "tokens": [
          50406,
          1033,
          11,
          370,
          586,
          300,
          311,
          456,
          13,
          50498
        ]
      },
      {
        "avg_logprob": -0.25772751151741324,
        "compression_ratio": 1.4746835443037976,
        "end": 4349.96,
        "id": 1447,
        "no_speech_prob": 0.000014510455912386533,
        "seek": 434256,
        "start": 4345.240000000001,
        "temperature": 0,
        "text": " Now I should be able to take this,",
        "tokens": [
          50498,
          823,
          286,
          820,
          312,
          1075,
          281,
          747,
          341,
          11,
          50734
        ]
      },
      {
        "avg_logprob": -0.25772751151741324,
        "compression_ratio": 1.4746835443037976,
        "end": 4354.96,
        "id": 1448,
        "no_speech_prob": 0.000014510455912386533,
        "seek": 434256,
        "start": 4349.96,
        "temperature": 0,
        "text": " the input data, and put this right here in the beginning.",
        "tokens": [
          50734,
          264,
          4846,
          1412,
          11,
          293,
          829,
          341,
          558,
          510,
          294,
          264,
          2863,
          13,
          50984
        ]
      },
      {
        "avg_logprob": -0.25772751151741324,
        "compression_ratio": 1.4746835443037976,
        "end": 4359.8,
        "id": 1449,
        "no_speech_prob": 0.000014510455912386533,
        "seek": 434256,
        "start": 4356.04,
        "temperature": 0,
        "text": " And then I'm going to make a variable called xs.",
        "tokens": [
          51038,
          400,
          550,
          286,
          478,
          516,
          281,
          652,
          257,
          7006,
          1219,
          2031,
          82,
          13,
          51226
        ]
      },
      {
        "avg_logprob": -0.25772751151741324,
        "compression_ratio": 1.4746835443037976,
        "end": 4366.160000000001,
        "id": 1450,
        "no_speech_prob": 0.000014510455912386533,
        "seek": 434256,
        "start": 4362.160000000001,
        "temperature": 0,
        "text": " And xs, and where did I do that?",
        "tokens": [
          51344,
          400,
          2031,
          82,
          11,
          293,
          689,
          630,
          286,
          360,
          300,
          30,
          51544
        ]
      },
      {
        "avg_logprob": -0.25772751151741324,
        "compression_ratio": 1.4746835443037976,
        "end": 4371.42,
        "id": 1451,
        "no_speech_prob": 0.000014510455912386533,
        "seek": 434256,
        "start": 4368.52,
        "temperature": 0,
        "text": " Here, and then create those xs.",
        "tokens": [
          51662,
          1692,
          11,
          293,
          550,
          1884,
          729,
          2031,
          82,
          13,
          51807
        ]
      },
      {
        "avg_logprob": -0.2218603117276082,
        "compression_ratio": 1.5991735537190082,
        "end": 4373.4400000000005,
        "id": 1452,
        "no_speech_prob": 5.285512543196091e-7,
        "seek": 437142,
        "start": 4371.42,
        "temperature": 0,
        "text": " So I'm now doing this in setup.",
        "tokens": [
          50364,
          407,
          286,
          478,
          586,
          884,
          341,
          294,
          8657,
          13,
          50465
        ]
      },
      {
        "avg_logprob": -0.2218603117276082,
        "compression_ratio": 1.5991735537190082,
        "end": 4378.38,
        "id": 1453,
        "no_speech_prob": 5.285512543196091e-7,
        "seek": 437142,
        "start": 4375.22,
        "temperature": 0,
        "text": " And then in draw, the only thing I need to do in draw",
        "tokens": [
          50554,
          400,
          550,
          294,
          2642,
          11,
          264,
          787,
          551,
          286,
          643,
          281,
          360,
          294,
          2642,
          50712
        ]
      },
      {
        "avg_logprob": -0.2218603117276082,
        "compression_ratio": 1.5991735537190082,
        "end": 4379.7,
        "id": 1454,
        "no_speech_prob": 5.285512543196091e-7,
        "seek": 437142,
        "start": 4378.38,
        "temperature": 0,
        "text": " is run the predict.",
        "tokens": [
          50712,
          307,
          1190,
          264,
          6069,
          13,
          50778
        ]
      },
      {
        "avg_logprob": -0.2218603117276082,
        "compression_ratio": 1.5991735537190082,
        "end": 4381.74,
        "id": 1455,
        "no_speech_prob": 5.285512543196091e-7,
        "seek": 437142,
        "start": 4379.7,
        "temperature": 0,
        "text": " This is going to make things run a lot faster.",
        "tokens": [
          50778,
          639,
          307,
          516,
          281,
          652,
          721,
          1190,
          257,
          688,
          4663,
          13,
          50880
        ]
      },
      {
        "avg_logprob": -0.2218603117276082,
        "compression_ratio": 1.5991735537190082,
        "end": 4383.26,
        "id": 1456,
        "no_speech_prob": 5.285512543196091e-7,
        "seek": 437142,
        "start": 4381.74,
        "temperature": 0,
        "text": " Let's make sure it still works.",
        "tokens": [
          50880,
          961,
          311,
          652,
          988,
          309,
          920,
          1985,
          13,
          50956
        ]
      },
      {
        "avg_logprob": -0.2218603117276082,
        "compression_ratio": 1.5991735537190082,
        "end": 4388.9400000000005,
        "id": 1457,
        "no_speech_prob": 5.285512543196091e-7,
        "seek": 437142,
        "start": 4388.1,
        "temperature": 0,
        "text": " Here we go.",
        "tokens": [
          51198,
          1692,
          321,
          352,
          13,
          51240
        ]
      },
      {
        "avg_logprob": -0.2218603117276082,
        "compression_ratio": 1.5991735537190082,
        "end": 4392.14,
        "id": 1458,
        "no_speech_prob": 5.285512543196091e-7,
        "seek": 437142,
        "start": 4390.46,
        "temperature": 0,
        "text": " Okay, so you notice we get like a different color",
        "tokens": [
          51316,
          1033,
          11,
          370,
          291,
          3449,
          321,
          483,
          411,
          257,
          819,
          2017,
          51400
        ]
      },
      {
        "avg_logprob": -0.2218603117276082,
        "compression_ratio": 1.5991735537190082,
        "end": 4394.9400000000005,
        "id": 1459,
        "no_speech_prob": 5.285512543196091e-7,
        "seek": 437142,
        "start": 4392.14,
        "temperature": 0,
        "text": " each time I refresh, because the neural network model,",
        "tokens": [
          51400,
          1184,
          565,
          286,
          15134,
          11,
          570,
          264,
          18161,
          3209,
          2316,
          11,
          51540
        ]
      },
      {
        "avg_logprob": -0.2218603117276082,
        "compression_ratio": 1.5991735537190082,
        "end": 4397.26,
        "id": 1460,
        "no_speech_prob": 5.285512543196091e-7,
        "seek": 437142,
        "start": 4394.9400000000005,
        "temperature": 0,
        "text": " the sequential model, is initializing everything randomly.",
        "tokens": [
          51540,
          264,
          42881,
          2316,
          11,
          307,
          5883,
          3319,
          1203,
          16979,
          13,
          51656
        ]
      },
      {
        "avg_logprob": -0.2218603117276082,
        "compression_ratio": 1.5991735537190082,
        "end": 4399.42,
        "id": 1461,
        "no_speech_prob": 5.285512543196091e-7,
        "seek": 437142,
        "start": 4397.26,
        "temperature": 0,
        "text": " But now I get to train it.",
        "tokens": [
          51656,
          583,
          586,
          286,
          483,
          281,
          3847,
          309,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.2671277576022678,
        "compression_ratio": 1.4065934065934067,
        "end": 4401.14,
        "id": 1462,
        "no_speech_prob": 0.000310155184706673,
        "seek": 439942,
        "start": 4400.3,
        "temperature": 0,
        "text": " Yes!",
        "tokens": [
          50408,
          1079,
          0,
          50450
        ]
      },
      {
        "avg_logprob": -0.2671277576022678,
        "compression_ratio": 1.4065934065934067,
        "end": 4403.54,
        "id": 1463,
        "no_speech_prob": 0.000310155184706673,
        "seek": 439942,
        "start": 4401.9800000000005,
        "temperature": 0,
        "text": " Now I think we're ready to train it.",
        "tokens": [
          50492,
          823,
          286,
          519,
          321,
          434,
          1919,
          281,
          3847,
          309,
          13,
          50570
        ]
      },
      {
        "avg_logprob": -0.2671277576022678,
        "compression_ratio": 1.4065934065934067,
        "end": 4406.58,
        "id": 1464,
        "no_speech_prob": 0.000310155184706673,
        "seek": 439942,
        "start": 4403.54,
        "temperature": 0,
        "text": " So here is what I did",
        "tokens": [
          50570,
          407,
          510,
          307,
          437,
          286,
          630,
          50722
        ]
      },
      {
        "avg_logprob": -0.2671277576022678,
        "compression_ratio": 1.4065934065934067,
        "end": 4410.72,
        "id": 1465,
        "no_speech_prob": 0.000310155184706673,
        "seek": 439942,
        "start": 4409.16,
        "temperature": 0,
        "text": " when I had my previous,",
        "tokens": [
          50851,
          562,
          286,
          632,
          452,
          3894,
          11,
          50929
        ]
      },
      {
        "avg_logprob": -0.2671277576022678,
        "compression_ratio": 1.4065934065934067,
        "end": 4412.88,
        "id": 1466,
        "no_speech_prob": 0.000310155184706673,
        "seek": 439942,
        "start": 4410.72,
        "temperature": 0,
        "text": " my own JavaScript neural network library.",
        "tokens": [
          50929,
          452,
          1065,
          15778,
          18161,
          3209,
          6405,
          13,
          51037
        ]
      },
      {
        "avg_logprob": -0.2671277576022678,
        "compression_ratio": 1.4065934065934067,
        "end": 4415.06,
        "id": 1467,
        "no_speech_prob": 0.000310155184706673,
        "seek": 439942,
        "start": 4412.88,
        "temperature": 0,
        "text": " I called neural network.train,",
        "tokens": [
          51037,
          286,
          1219,
          18161,
          3209,
          13,
          83,
          7146,
          11,
          51146
        ]
      },
      {
        "avg_logprob": -0.2671277576022678,
        "compression_ratio": 1.4065934065934067,
        "end": 4417.62,
        "id": 1468,
        "no_speech_prob": 0.000310155184706673,
        "seek": 439942,
        "start": 4415.06,
        "temperature": 0,
        "text": " data.inputs, data.outputs.",
        "tokens": [
          51146,
          1412,
          13,
          259,
          2582,
          82,
          11,
          1412,
          13,
          346,
          2582,
          82,
          13,
          51274
        ]
      },
      {
        "avg_logprob": -0.2671277576022678,
        "compression_ratio": 1.4065934065934067,
        "end": 4423.38,
        "id": 1469,
        "no_speech_prob": 0.000310155184706673,
        "seek": 439942,
        "start": 4421.9800000000005,
        "temperature": 0,
        "text": " Sorry, I'm reading the chat.",
        "tokens": [
          51492,
          4919,
          11,
          286,
          478,
          3760,
          264,
          5081,
          13,
          51562
        ]
      },
      {
        "avg_logprob": -0.2671277576022678,
        "compression_ratio": 1.4065934065934067,
        "end": 4426.66,
        "id": 1470,
        "no_speech_prob": 0.000310155184706673,
        "seek": 439942,
        "start": 4425.3,
        "temperature": 0,
        "text": " You guys couldn't hear the music?",
        "tokens": [
          51658,
          509,
          1074,
          2809,
          380,
          1568,
          264,
          1318,
          30,
          51726
        ]
      },
      {
        "avg_logprob": -0.2671277576022678,
        "compression_ratio": 1.4065934065934067,
        "end": 4427.5,
        "id": 1471,
        "no_speech_prob": 0.000310155184706673,
        "seek": 439942,
        "start": 4426.66,
        "temperature": 0,
        "text": " Well.",
        "tokens": [
          51726,
          1042,
          13,
          51768
        ]
      },
      {
        "avg_logprob": -0.23885613728344926,
        "compression_ratio": 1.6916666666666667,
        "end": 4435.26,
        "id": 1472,
        "no_speech_prob": 0.000019833349142572843,
        "seek": 442942,
        "start": 4430.26,
        "temperature": 0,
        "text": " All right, so if only I could remember exactly what I wrote",
        "tokens": [
          50406,
          1057,
          558,
          11,
          370,
          498,
          787,
          286,
          727,
          1604,
          2293,
          437,
          286,
          4114,
          50656
        ]
      },
      {
        "avg_logprob": -0.23885613728344926,
        "compression_ratio": 1.6916666666666667,
        "end": 4438.46,
        "id": 1473,
        "no_speech_prob": 0.000019833349142572843,
        "seek": 442942,
        "start": 4436.22,
        "temperature": 0,
        "text": " when I made that tf.layers tutorial.",
        "tokens": [
          50704,
          562,
          286,
          1027,
          300,
          256,
          69,
          13,
          8376,
          433,
          7073,
          13,
          50816
        ]
      },
      {
        "avg_logprob": -0.23885613728344926,
        "compression_ratio": 1.6916666666666667,
        "end": 4441.3,
        "id": 1474,
        "no_speech_prob": 0.000019833349142572843,
        "seek": 442942,
        "start": 4438.46,
        "temperature": 0,
        "text": " But I know that what I need to do here",
        "tokens": [
          50816,
          583,
          286,
          458,
          300,
          437,
          286,
          643,
          281,
          360,
          510,
          50958
        ]
      },
      {
        "avg_logprob": -0.23885613728344926,
        "compression_ratio": 1.6916666666666667,
        "end": 4443.9400000000005,
        "id": 1475,
        "no_speech_prob": 0.000019833349142572843,
        "seek": 442942,
        "start": 4441.3,
        "temperature": 0,
        "text": " is I need to do something like this.",
        "tokens": [
          50958,
          307,
          286,
          643,
          281,
          360,
          746,
          411,
          341,
          13,
          51090
        ]
      },
      {
        "avg_logprob": -0.23885613728344926,
        "compression_ratio": 1.6916666666666667,
        "end": 4448.3,
        "id": 1476,
        "no_speech_prob": 0.000019833349142572843,
        "seek": 442942,
        "start": 4443.9400000000005,
        "temperature": 0,
        "text": " Model.fit some xs and some ys.",
        "tokens": [
          51090,
          17105,
          13,
          6845,
          512,
          2031,
          82,
          293,
          512,
          288,
          82,
          13,
          51308
        ]
      },
      {
        "avg_logprob": -0.23885613728344926,
        "compression_ratio": 1.6916666666666667,
        "end": 4450.1,
        "id": 1477,
        "no_speech_prob": 0.000019833349142572843,
        "seek": 442942,
        "start": 4448.3,
        "temperature": 0,
        "text": " That's the training, that's the equivalent.",
        "tokens": [
          51308,
          663,
          311,
          264,
          3097,
          11,
          300,
          311,
          264,
          10344,
          13,
          51398
        ]
      },
      {
        "avg_logprob": -0.23885613728344926,
        "compression_ratio": 1.6916666666666667,
        "end": 4451.9,
        "id": 1478,
        "no_speech_prob": 0.000019833349142572843,
        "seek": 442942,
        "start": 4450.1,
        "temperature": 0,
        "text": " And the learning rate is irrelevant.",
        "tokens": [
          51398,
          400,
          264,
          2539,
          3314,
          307,
          28682,
          13,
          51488
        ]
      },
      {
        "avg_logprob": -0.23885613728344926,
        "compression_ratio": 1.6916666666666667,
        "end": 4454.9400000000005,
        "id": 1479,
        "no_speech_prob": 0.000019833349142572843,
        "seek": 442942,
        "start": 4453.26,
        "temperature": 0,
        "text": " And I don't necessarily need to do it.",
        "tokens": [
          51556,
          400,
          286,
          500,
          380,
          4725,
          643,
          281,
          360,
          309,
          13,
          51640
        ]
      },
      {
        "avg_logprob": -0.23885613728344926,
        "compression_ratio": 1.6916666666666667,
        "end": 4456.18,
        "id": 1480,
        "no_speech_prob": 0.000019833349142572843,
        "seek": 442942,
        "start": 4454.9400000000005,
        "temperature": 0,
        "text": " This is basically what I want to do.",
        "tokens": [
          51640,
          639,
          307,
          1936,
          437,
          286,
          528,
          281,
          360,
          13,
          51702
        ]
      },
      {
        "avg_logprob": -0.23885613728344926,
        "compression_ratio": 1.6916666666666667,
        "end": 4459.02,
        "id": 1481,
        "no_speech_prob": 0.000019833349142572843,
        "seek": 442942,
        "start": 4456.18,
        "temperature": 0,
        "text": " Every time through draw, I want to try to fit",
        "tokens": [
          51702,
          2048,
          565,
          807,
          2642,
          11,
          286,
          528,
          281,
          853,
          281,
          3318,
          51844
        ]
      },
      {
        "avg_logprob": -0.22657897824146708,
        "compression_ratio": 1.8064516129032258,
        "end": 4460.580000000001,
        "id": 1482,
        "no_speech_prob": 0.000006643429514952004,
        "seek": 445902,
        "start": 4459.580000000001,
        "temperature": 0,
        "text": " the model with some training data.",
        "tokens": [
          50392,
          264,
          2316,
          365,
          512,
          3097,
          1412,
          13,
          50442
        ]
      },
      {
        "avg_logprob": -0.22657897824146708,
        "compression_ratio": 1.8064516129032258,
        "end": 4462.580000000001,
        "id": 1483,
        "no_speech_prob": 0.000006643429514952004,
        "seek": 445902,
        "start": 4460.580000000001,
        "temperature": 0,
        "text": " So let's first make the training data.",
        "tokens": [
          50442,
          407,
          718,
          311,
          700,
          652,
          264,
          3097,
          1412,
          13,
          50542
        ]
      },
      {
        "avg_logprob": -0.22657897824146708,
        "compression_ratio": 1.8064516129032258,
        "end": 4463.900000000001,
        "id": 1484,
        "no_speech_prob": 0.000006643429514952004,
        "seek": 445902,
        "start": 4462.580000000001,
        "temperature": 0,
        "text": " This is not exactly right.",
        "tokens": [
          50542,
          639,
          307,
          406,
          2293,
          558,
          13,
          50608
        ]
      },
      {
        "avg_logprob": -0.22657897824146708,
        "compression_ratio": 1.8064516129032258,
        "end": 4465.540000000001,
        "id": 1485,
        "no_speech_prob": 0.000006643429514952004,
        "seek": 445902,
        "start": 4463.900000000001,
        "temperature": 0,
        "text": " I need to figure it out and I need to use a weight.",
        "tokens": [
          50608,
          286,
          643,
          281,
          2573,
          309,
          484,
          293,
          286,
          643,
          281,
          764,
          257,
          3364,
          13,
          50690
        ]
      },
      {
        "avg_logprob": -0.22657897824146708,
        "compression_ratio": 1.8064516129032258,
        "end": 4466.820000000001,
        "id": 1486,
        "no_speech_prob": 0.000006643429514952004,
        "seek": 445902,
        "start": 4465.540000000001,
        "temperature": 0,
        "text": " I need to think asynchronously.",
        "tokens": [
          50690,
          286,
          643,
          281,
          519,
          42642,
          5098,
          13,
          50754
        ]
      },
      {
        "avg_logprob": -0.22657897824146708,
        "compression_ratio": 1.8064516129032258,
        "end": 4468.040000000001,
        "id": 1487,
        "no_speech_prob": 0.000006643429514952004,
        "seek": 445902,
        "start": 4466.820000000001,
        "temperature": 0,
        "text": " But this is the idea.",
        "tokens": [
          50754,
          583,
          341,
          307,
          264,
          1558,
          13,
          50815
        ]
      },
      {
        "avg_logprob": -0.22657897824146708,
        "compression_ratio": 1.8064516129032258,
        "end": 4470.900000000001,
        "id": 1488,
        "no_speech_prob": 0.000006643429514952004,
        "seek": 445902,
        "start": 4469.46,
        "temperature": 0,
        "text": " So if I go back to the top here,",
        "tokens": [
          50886,
          407,
          498,
          286,
          352,
          646,
          281,
          264,
          1192,
          510,
          11,
          50958
        ]
      },
      {
        "avg_logprob": -0.22657897824146708,
        "compression_ratio": 1.8064516129032258,
        "end": 4472.46,
        "id": 1489,
        "no_speech_prob": 0.000006643429514952004,
        "seek": 445902,
        "start": 4470.900000000001,
        "temperature": 0,
        "text": " this is my training data.",
        "tokens": [
          50958,
          341,
          307,
          452,
          3097,
          1412,
          13,
          51036
        ]
      },
      {
        "avg_logprob": -0.22657897824146708,
        "compression_ratio": 1.8064516129032258,
        "end": 4476.42,
        "id": 1490,
        "no_speech_prob": 0.000006643429514952004,
        "seek": 445902,
        "start": 4472.46,
        "temperature": 0,
        "text": " Now one thing I definitely need to change",
        "tokens": [
          51036,
          823,
          472,
          551,
          286,
          2138,
          643,
          281,
          1319,
          51234
        ]
      },
      {
        "avg_logprob": -0.22657897824146708,
        "compression_ratio": 1.8064516129032258,
        "end": 4484.52,
        "id": 1491,
        "no_speech_prob": 0.000006643429514952004,
        "seek": 445902,
        "start": 4479.52,
        "temperature": 0,
        "text": " is I'm going to keep the xs and ys separate in training.",
        "tokens": [
          51389,
          307,
          286,
          478,
          516,
          281,
          1066,
          264,
          2031,
          82,
          293,
          288,
          82,
          4994,
          294,
          3097,
          13,
          51639
        ]
      },
      {
        "avg_logprob": -0.22657897824146708,
        "compression_ratio": 1.8064516129032258,
        "end": 4488.1,
        "id": 1492,
        "no_speech_prob": 0.000006643429514952004,
        "seek": 445902,
        "start": 4484.580000000001,
        "temperature": 0,
        "text": " So I'm going to do this is,",
        "tokens": [
          51642,
          407,
          286,
          478,
          516,
          281,
          360,
          341,
          307,
          11,
          51818
        ]
      },
      {
        "avg_logprob": -0.26450383385946585,
        "compression_ratio": 1.463855421686747,
        "end": 4490.780000000001,
        "id": 1493,
        "no_speech_prob": 0.000009666105142969172,
        "seek": 448810,
        "start": 4488.1,
        "temperature": 0,
        "text": " I'm just going to do this kind of manually",
        "tokens": [
          50364,
          286,
          478,
          445,
          516,
          281,
          360,
          341,
          733,
          295,
          16945,
          50498
        ]
      },
      {
        "avg_logprob": -0.26450383385946585,
        "compression_ratio": 1.463855421686747,
        "end": 4492.46,
        "id": 1494,
        "no_speech_prob": 0.000009666105142969172,
        "seek": 448810,
        "start": 4490.780000000001,
        "temperature": 0,
        "text": " because what's the big deal?",
        "tokens": [
          50498,
          570,
          437,
          311,
          264,
          955,
          2028,
          30,
          50582
        ]
      },
      {
        "avg_logprob": -0.26450383385946585,
        "compression_ratio": 1.463855421686747,
        "end": 4496.22,
        "id": 1495,
        "no_speech_prob": 0.000009666105142969172,
        "seek": 448810,
        "start": 4493.860000000001,
        "temperature": 0,
        "text": " So let me make the training set.",
        "tokens": [
          50652,
          407,
          718,
          385,
          652,
          264,
          3097,
          992,
          13,
          50770
        ]
      },
      {
        "avg_logprob": -0.26450383385946585,
        "compression_ratio": 1.463855421686747,
        "end": 4500.38,
        "id": 1496,
        "no_speech_prob": 0.000009666105142969172,
        "seek": 448810,
        "start": 4498.56,
        "temperature": 0,
        "text": " And then one, one.",
        "tokens": [
          50887,
          400,
          550,
          472,
          11,
          472,
          13,
          50978
        ]
      },
      {
        "avg_logprob": -0.26450383385946585,
        "compression_ratio": 1.463855421686747,
        "end": 4503.360000000001,
        "id": 1497,
        "no_speech_prob": 0.000009666105142969172,
        "seek": 448810,
        "start": 4501.700000000001,
        "temperature": 0,
        "text": " Those are the xs.",
        "tokens": [
          51044,
          3950,
          366,
          264,
          2031,
          82,
          13,
          51127
        ]
      },
      {
        "avg_logprob": -0.26450383385946585,
        "compression_ratio": 1.463855421686747,
        "end": 4507.22,
        "id": 1498,
        "no_speech_prob": 0.000009666105142969172,
        "seek": 448810,
        "start": 4504.240000000001,
        "temperature": 0,
        "text": " Now let me look at the ys.",
        "tokens": [
          51171,
          823,
          718,
          385,
          574,
          412,
          264,
          288,
          82,
          13,
          51320
        ]
      },
      {
        "avg_logprob": -0.26450383385946585,
        "compression_ratio": 1.463855421686747,
        "end": 4512.22,
        "id": 1499,
        "no_speech_prob": 0.000009666105142969172,
        "seek": 448810,
        "start": 4507.22,
        "temperature": 0,
        "text": " And the ys would be zero, one, one, zero.",
        "tokens": [
          51320,
          400,
          264,
          288,
          82,
          576,
          312,
          4018,
          11,
          472,
          11,
          472,
          11,
          4018,
          13,
          51570
        ]
      },
      {
        "avg_logprob": -0.26450383385946585,
        "compression_ratio": 1.463855421686747,
        "end": 4517.54,
        "id": 1500,
        "no_speech_prob": 0.000009666105142969172,
        "seek": 448810,
        "start": 4515.06,
        "temperature": 0,
        "text": " Then I need those to be tensors.",
        "tokens": [
          51712,
          1396,
          286,
          643,
          729,
          281,
          312,
          10688,
          830,
          13,
          51836
        ]
      },
      {
        "avg_logprob": -0.3994543579803116,
        "compression_ratio": 1.4464285714285714,
        "end": 4523.54,
        "id": 1501,
        "no_speech_prob": 0.00015356203948613256,
        "seek": 451810,
        "start": 4518.54,
        "temperature": 0,
        "text": " So I need to say const tf xs.",
        "tokens": [
          50386,
          407,
          286,
          643,
          281,
          584,
          1817,
          256,
          69,
          2031,
          82,
          13,
          50636
        ]
      },
      {
        "avg_logprob": -0.3994543579803116,
        "compression_ratio": 1.4464285714285714,
        "end": 4533.02,
        "id": 1502,
        "no_speech_prob": 0.00015356203948613256,
        "seek": 451810,
        "start": 4531.58,
        "temperature": 0,
        "text": " So I'm trying to think of good naming for this.",
        "tokens": [
          51038,
          407,
          286,
          478,
          1382,
          281,
          519,
          295,
          665,
          25290,
          337,
          341,
          13,
          51110
        ]
      },
      {
        "avg_logprob": -0.3994543579803116,
        "compression_ratio": 1.4464285714285714,
        "end": 4534.5,
        "id": 1503,
        "no_speech_prob": 0.00015356203948613256,
        "seek": 451810,
        "start": 4533.02,
        "temperature": 0,
        "text": " I kind of want them to be called.",
        "tokens": [
          51110,
          286,
          733,
          295,
          528,
          552,
          281,
          312,
          1219,
          13,
          51184
        ]
      },
      {
        "avg_logprob": -0.3994543579803116,
        "compression_ratio": 1.4464285714285714,
        "end": 4535.34,
        "id": 1504,
        "no_speech_prob": 0.00015356203948613256,
        "seek": 451810,
        "start": 4534.5,
        "temperature": 0,
        "text": " Actually, you know what?",
        "tokens": [
          51184,
          5135,
          11,
          291,
          458,
          437,
          30,
          51226
        ]
      },
      {
        "avg_logprob": -0.3994543579803116,
        "compression_ratio": 1.4464285714285714,
        "end": 4537.9400000000005,
        "id": 1505,
        "no_speech_prob": 0.00015356203948613256,
        "seek": 451810,
        "start": 4535.34,
        "temperature": 0,
        "text": " I'm just going to call it, do I have a global x?",
        "tokens": [
          51226,
          286,
          478,
          445,
          516,
          281,
          818,
          309,
          11,
          360,
          286,
          362,
          257,
          4338,
          2031,
          30,
          51356
        ]
      },
      {
        "avg_logprob": -0.3994543579803116,
        "compression_ratio": 1.4464285714285714,
        "end": 4539.860000000001,
        "id": 1506,
        "no_speech_prob": 0.00015356203948613256,
        "seek": 451810,
        "start": 4537.9400000000005,
        "temperature": 0,
        "text": " Yeah, I have a global xs already.",
        "tokens": [
          51356,
          865,
          11,
          286,
          362,
          257,
          4338,
          2031,
          82,
          1217,
          13,
          51452
        ]
      },
      {
        "avg_logprob": -0.3994543579803116,
        "compression_ratio": 1.4464285714285714,
        "end": 4547.42,
        "id": 1507,
        "no_speech_prob": 0.00015356203948613256,
        "seek": 451810,
        "start": 4542.42,
        "temperature": 0,
        "text": " tf xs equals tensor 2d.",
        "tokens": [
          51580,
          256,
          69,
          2031,
          82,
          6915,
          40863,
          568,
          67,
          13,
          51830
        ]
      },
      {
        "avg_logprob": -0.23953606100643382,
        "compression_ratio": 1.7991266375545851,
        "end": 4553.02,
        "id": 1508,
        "no_speech_prob": 0.0001233944931300357,
        "seek": 454810,
        "start": 4548.38,
        "temperature": 0,
        "text": " Oh, tf tensor 2d.",
        "tokens": [
          50378,
          876,
          11,
          256,
          69,
          40863,
          568,
          67,
          13,
          50610
        ]
      },
      {
        "avg_logprob": -0.23953606100643382,
        "compression_ratio": 1.7991266375545851,
        "end": 4554.22,
        "id": 1509,
        "no_speech_prob": 0.0001233944931300357,
        "seek": 454810,
        "start": 4553.02,
        "temperature": 0,
        "text": " You know what I'm going to do?",
        "tokens": [
          50610,
          509,
          458,
          437,
          286,
          478,
          516,
          281,
          360,
          30,
          50670
        ]
      },
      {
        "avg_logprob": -0.23953606100643382,
        "compression_ratio": 1.7991266375545851,
        "end": 4555.3,
        "id": 1510,
        "no_speech_prob": 0.0001233944931300357,
        "seek": 454810,
        "start": 4554.22,
        "temperature": 0,
        "text": " I don't need these.",
        "tokens": [
          50670,
          286,
          500,
          380,
          643,
          613,
          13,
          50724
        ]
      },
      {
        "avg_logprob": -0.23953606100643382,
        "compression_ratio": 1.7991266375545851,
        "end": 4557.34,
        "id": 1511,
        "no_speech_prob": 0.0001233944931300357,
        "seek": 454810,
        "start": 4555.3,
        "temperature": 0,
        "text": " I don't need two separate sets of variables.",
        "tokens": [
          50724,
          286,
          500,
          380,
          643,
          732,
          4994,
          6352,
          295,
          9102,
          13,
          50826
        ]
      },
      {
        "avg_logprob": -0.23953606100643382,
        "compression_ratio": 1.7991266375545851,
        "end": 4558.58,
        "id": 1512,
        "no_speech_prob": 0.0001233944931300357,
        "seek": 454810,
        "start": 4557.34,
        "temperature": 0,
        "text": " I'm just going to create it.",
        "tokens": [
          50826,
          286,
          478,
          445,
          516,
          281,
          1884,
          309,
          13,
          50888
        ]
      },
      {
        "avg_logprob": -0.23953606100643382,
        "compression_ratio": 1.7991266375545851,
        "end": 4560.780000000001,
        "id": 1513,
        "no_speech_prob": 0.0001233944931300357,
        "seek": 454810,
        "start": 4558.58,
        "temperature": 0,
        "text": " I'm going to call this, ah,",
        "tokens": [
          50888,
          286,
          478,
          516,
          281,
          818,
          341,
          11,
          3716,
          11,
          50998
        ]
      },
      {
        "avg_logprob": -0.23953606100643382,
        "compression_ratio": 1.7991266375545851,
        "end": 4563.22,
        "id": 1514,
        "no_speech_prob": 0.0001233944931300357,
        "seek": 454810,
        "start": 4560.780000000001,
        "temperature": 0,
        "text": " everything is so much more complicated than I make it.",
        "tokens": [
          50998,
          1203,
          307,
          370,
          709,
          544,
          6179,
          813,
          286,
          652,
          309,
          13,
          51120
        ]
      },
      {
        "avg_logprob": -0.23953606100643382,
        "compression_ratio": 1.7991266375545851,
        "end": 4564.620000000001,
        "id": 1515,
        "no_speech_prob": 0.0001233944931300357,
        "seek": 454810,
        "start": 4563.22,
        "temperature": 0,
        "text": " So much more simple than I make it.",
        "tokens": [
          51120,
          407,
          709,
          544,
          2199,
          813,
          286,
          652,
          309,
          13,
          51190
        ]
      },
      {
        "avg_logprob": -0.23953606100643382,
        "compression_ratio": 1.7991266375545851,
        "end": 4566.5,
        "id": 1516,
        "no_speech_prob": 0.0001233944931300357,
        "seek": 454810,
        "start": 4564.620000000001,
        "temperature": 0,
        "text": " I'm just going to make these tensors directly",
        "tokens": [
          51190,
          286,
          478,
          445,
          516,
          281,
          652,
          613,
          10688,
          830,
          3838,
          51284
        ]
      },
      {
        "avg_logprob": -0.23953606100643382,
        "compression_ratio": 1.7991266375545851,
        "end": 4567.5,
        "id": 1517,
        "no_speech_prob": 0.0001233944931300357,
        "seek": 454810,
        "start": 4566.5,
        "temperature": 0,
        "text": " by saying tf.tensor2d.",
        "tokens": [
          51284,
          538,
          1566,
          256,
          69,
          13,
          83,
          23153,
          17,
          67,
          13,
          51334
        ]
      },
      {
        "avg_logprob": -0.23953606100643382,
        "compression_ratio": 1.7991266375545851,
        "end": 4575.1,
        "id": 1518,
        "no_speech_prob": 0.0001233944931300357,
        "seek": 454810,
        "start": 4572.54,
        "temperature": 0,
        "text": " And then I'll put the parentheses around this.",
        "tokens": [
          51586,
          400,
          550,
          286,
          603,
          829,
          264,
          34153,
          926,
          341,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.23953606100643382,
        "compression_ratio": 1.7991266375545851,
        "end": 4577.3,
        "id": 1519,
        "no_speech_prob": 0.0001233944931300357,
        "seek": 454810,
        "start": 4575.1,
        "temperature": 0,
        "text": " And there, now I made it a tensor.",
        "tokens": [
          51714,
          400,
          456,
          11,
          586,
          286,
          1027,
          309,
          257,
          40863,
          13,
          51824
        ]
      },
      {
        "avg_logprob": -0.3022292361539953,
        "compression_ratio": 1.6049382716049383,
        "end": 4580.900000000001,
        "id": 1520,
        "no_speech_prob": 0.000012805450751329772,
        "seek": 457730,
        "start": 4577.3,
        "temperature": 0,
        "text": " Then I'll say tf.tensor2d.",
        "tokens": [
          50364,
          1396,
          286,
          603,
          584,
          256,
          69,
          13,
          83,
          23153,
          17,
          67,
          13,
          50544
        ]
      },
      {
        "avg_logprob": -0.3022292361539953,
        "compression_ratio": 1.6049382716049383,
        "end": 4582.26,
        "id": 1521,
        "no_speech_prob": 0.000012805450751329772,
        "seek": 457730,
        "start": 4580.900000000001,
        "temperature": 0,
        "text": " And now I made this a tensor.",
        "tokens": [
          50544,
          400,
          586,
          286,
          1027,
          341,
          257,
          40863,
          13,
          50612
        ]
      },
      {
        "avg_logprob": -0.3022292361539953,
        "compression_ratio": 1.6049382716049383,
        "end": 4583.1,
        "id": 1522,
        "no_speech_prob": 0.000012805450751329772,
        "seek": 457730,
        "start": 4582.26,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          50612,
          1033,
          13,
          50654
        ]
      },
      {
        "avg_logprob": -0.3022292361539953,
        "compression_ratio": 1.6049382716049383,
        "end": 4586.42,
        "id": 1523,
        "no_speech_prob": 0.000012805450751329772,
        "seek": 457730,
        "start": 4584.14,
        "temperature": 0,
        "text": " Now I've got the training data.",
        "tokens": [
          50706,
          823,
          286,
          600,
          658,
          264,
          3097,
          1412,
          13,
          50820
        ]
      },
      {
        "avg_logprob": -0.3022292361539953,
        "compression_ratio": 1.6049382716049383,
        "end": 4587.820000000001,
        "id": 1524,
        "no_speech_prob": 0.000012805450751329772,
        "seek": 457730,
        "start": 4586.42,
        "temperature": 0,
        "text": " And I'm going to get rid of this.",
        "tokens": [
          50820,
          400,
          286,
          478,
          516,
          281,
          483,
          3973,
          295,
          341,
          13,
          50890
        ]
      },
      {
        "avg_logprob": -0.3022292361539953,
        "compression_ratio": 1.6049382716049383,
        "end": 4589.78,
        "id": 1525,
        "no_speech_prob": 0.000012805450751329772,
        "seek": 457730,
        "start": 4587.820000000001,
        "temperature": 0,
        "text": " This is the old way that I had the training data,",
        "tokens": [
          50890,
          639,
          307,
          264,
          1331,
          636,
          300,
          286,
          632,
          264,
          3097,
          1412,
          11,
          50988
        ]
      },
      {
        "avg_logprob": -0.3022292361539953,
        "compression_ratio": 1.6049382716049383,
        "end": 4591.56,
        "id": 1526,
        "no_speech_prob": 0.000012805450751329772,
        "seek": 457730,
        "start": 4589.78,
        "temperature": 0,
        "text": " which is totally unnecessary.",
        "tokens": [
          50988,
          597,
          307,
          3879,
          19350,
          13,
          51077
        ]
      },
      {
        "avg_logprob": -0.3022292361539953,
        "compression_ratio": 1.6049382716049383,
        "end": 4593.820000000001,
        "id": 1527,
        "no_speech_prob": 0.000012805450751329772,
        "seek": 457730,
        "start": 4591.56,
        "temperature": 0,
        "text": " So the training xs and the training ys.",
        "tokens": [
          51077,
          407,
          264,
          3097,
          2031,
          82,
          293,
          264,
          3097,
          288,
          82,
          13,
          51190
        ]
      },
      {
        "avg_logprob": -0.3022292361539953,
        "compression_ratio": 1.6049382716049383,
        "end": 4595.02,
        "id": 1528,
        "no_speech_prob": 0.000012805450751329772,
        "seek": 457730,
        "start": 4593.820000000001,
        "temperature": 0,
        "text": " You with me?",
        "tokens": [
          51190,
          509,
          365,
          385,
          30,
          51250
        ]
      },
      {
        "avg_logprob": -0.3022292361539953,
        "compression_ratio": 1.6049382716049383,
        "end": 4596.14,
        "id": 1529,
        "no_speech_prob": 0.000012805450751329772,
        "seek": 457730,
        "start": 4595.02,
        "temperature": 0,
        "text": " How long have you been watching?",
        "tokens": [
          51250,
          1012,
          938,
          362,
          291,
          668,
          1976,
          30,
          51306
        ]
      },
      {
        "avg_logprob": -0.3022292361539953,
        "compression_ratio": 1.6049382716049383,
        "end": 4598.78,
        "id": 1530,
        "no_speech_prob": 0.000012805450751329772,
        "seek": 457730,
        "start": 4596.14,
        "temperature": 0,
        "text": " If you're still watching, I don't know.",
        "tokens": [
          51306,
          759,
          291,
          434,
          920,
          1976,
          11,
          286,
          500,
          380,
          458,
          13,
          51438
        ]
      },
      {
        "avg_logprob": -0.3022292361539953,
        "compression_ratio": 1.6049382716049383,
        "end": 4600.9400000000005,
        "id": 1531,
        "no_speech_prob": 0.000012805450751329772,
        "seek": 457730,
        "start": 4598.78,
        "temperature": 0,
        "text": " Do it, get up and do it, some jumping jacks.",
        "tokens": [
          51438,
          1144,
          309,
          11,
          483,
          493,
          293,
          360,
          309,
          11,
          512,
          11233,
          7109,
          82,
          13,
          51546
        ]
      },
      {
        "avg_logprob": -0.3022292361539953,
        "compression_ratio": 1.6049382716049383,
        "end": 4605.22,
        "id": 1532,
        "no_speech_prob": 0.000012805450751329772,
        "seek": 457730,
        "start": 4603.9800000000005,
        "temperature": 0,
        "text": " Let's see.",
        "tokens": [
          51698,
          961,
          311,
          536,
          13,
          51760
        ]
      },
      {
        "avg_logprob": -0.23384544896144493,
        "compression_ratio": 1.5068493150684932,
        "end": 4608.14,
        "id": 1533,
        "no_speech_prob": 0.000006854311777715338,
        "seek": 460522,
        "start": 4605.22,
        "temperature": 0,
        "text": " Now, I need to do model.fit.",
        "tokens": [
          50364,
          823,
          11,
          286,
          643,
          281,
          360,
          2316,
          13,
          6845,
          13,
          50510
        ]
      },
      {
        "avg_logprob": -0.23384544896144493,
        "compression_ratio": 1.5068493150684932,
        "end": 4612.740000000001,
        "id": 1534,
        "no_speech_prob": 0.000006854311777715338,
        "seek": 460522,
        "start": 4608.14,
        "temperature": 0,
        "text": " Now, model.fit happens asynchronously.",
        "tokens": [
          50510,
          823,
          11,
          2316,
          13,
          6845,
          2314,
          42642,
          5098,
          13,
          50740
        ]
      },
      {
        "avg_logprob": -0.23384544896144493,
        "compression_ratio": 1.5068493150684932,
        "end": 4616.06,
        "id": 1535,
        "no_speech_prob": 0.000006854311777715338,
        "seek": 460522,
        "start": 4612.740000000001,
        "temperature": 0,
        "text": " So let's put it in its own async function",
        "tokens": [
          50740,
          407,
          718,
          311,
          829,
          309,
          294,
          1080,
          1065,
          382,
          34015,
          2445,
          50906
        ]
      },
      {
        "avg_logprob": -0.23384544896144493,
        "compression_ratio": 1.5068493150684932,
        "end": 4619.06,
        "id": 1536,
        "no_speech_prob": 0.000006854311777715338,
        "seek": 460522,
        "start": 4617.740000000001,
        "temperature": 0,
        "text": " called trainModel.",
        "tokens": [
          50990,
          1219,
          3847,
          44,
          41147,
          13,
          51056
        ]
      },
      {
        "avg_logprob": -0.23384544896144493,
        "compression_ratio": 1.5068493150684932,
        "end": 4624.06,
        "id": 1537,
        "no_speech_prob": 0.000006854311777715338,
        "seek": 460522,
        "start": 4621.780000000001,
        "temperature": 0,
        "text": " Now, if you don't know what it means",
        "tokens": [
          51192,
          823,
          11,
          498,
          291,
          500,
          380,
          458,
          437,
          309,
          1355,
          51306
        ]
      },
      {
        "avg_logprob": -0.23384544896144493,
        "compression_ratio": 1.5068493150684932,
        "end": 4628.9800000000005,
        "id": 1538,
        "no_speech_prob": 0.000006854311777715338,
        "seek": 460522,
        "start": 4624.06,
        "temperature": 0,
        "text": " to write a function that is tagged with the keyword async,",
        "tokens": [
          51306,
          281,
          2464,
          257,
          2445,
          300,
          307,
          40239,
          365,
          264,
          20428,
          382,
          34015,
          11,
          51552
        ]
      },
      {
        "avg_logprob": -0.23384544896144493,
        "compression_ratio": 1.5068493150684932,
        "end": 4632.820000000001,
        "id": 1539,
        "no_speech_prob": 0.000006854311777715338,
        "seek": 460522,
        "start": 4628.9800000000005,
        "temperature": 0,
        "text": " this is part of ES8, a very newish version of JavaScript.",
        "tokens": [
          51552,
          341,
          307,
          644,
          295,
          12564,
          23,
          11,
          257,
          588,
          777,
          742,
          3037,
          295,
          15778,
          13,
          51744
        ]
      },
      {
        "avg_logprob": -0.23384544896144493,
        "compression_ratio": 1.5068493150684932,
        "end": 4634.860000000001,
        "id": 1540,
        "no_speech_prob": 0.000006854311777715338,
        "seek": 460522,
        "start": 4632.820000000001,
        "temperature": 0,
        "text": " And I made a bunch of videos about what that is",
        "tokens": [
          51744,
          400,
          286,
          1027,
          257,
          3840,
          295,
          2145,
          466,
          437,
          300,
          307,
          51846
        ]
      },
      {
        "avg_logprob": -0.2583272232968583,
        "compression_ratio": 1.6027397260273972,
        "end": 4636.339999999999,
        "id": 1541,
        "no_speech_prob": 0.00005829116707900539,
        "seek": 463486,
        "start": 4635.5,
        "temperature": 0,
        "text": " that you can go back and watch.",
        "tokens": [
          50396,
          300,
          291,
          393,
          352,
          646,
          293,
          1159,
          13,
          50438
        ]
      },
      {
        "avg_logprob": -0.2583272232968583,
        "compression_ratio": 1.6027397260273972,
        "end": 4639.86,
        "id": 1542,
        "no_speech_prob": 0.00005829116707900539,
        "seek": 463486,
        "start": 4636.339999999999,
        "temperature": 0,
        "text": " But this is basically a way for me to now say,",
        "tokens": [
          50438,
          583,
          341,
          307,
          1936,
          257,
          636,
          337,
          385,
          281,
          586,
          584,
          11,
          50614
        ]
      },
      {
        "avg_logprob": -0.2583272232968583,
        "compression_ratio": 1.6027397260273972,
        "end": 4642.46,
        "id": 1543,
        "no_speech_prob": 0.00005829116707900539,
        "seek": 463486,
        "start": 4639.86,
        "temperature": 0,
        "text": " wait, model.fit.",
        "tokens": [
          50614,
          1699,
          11,
          2316,
          13,
          6845,
          13,
          50744
        ]
      },
      {
        "avg_logprob": -0.2583272232968583,
        "compression_ratio": 1.6027397260273972,
        "end": 4645.98,
        "id": 1544,
        "no_speech_prob": 0.00005829116707900539,
        "seek": 463486,
        "start": 4644.38,
        "temperature": 0,
        "text": " And then let's look at actually,",
        "tokens": [
          50840,
          400,
          550,
          718,
          311,
          574,
          412,
          767,
          11,
          50920
        ]
      },
      {
        "avg_logprob": -0.2583272232968583,
        "compression_ratio": 1.6027397260273972,
        "end": 4648.0199999999995,
        "id": 1545,
        "no_speech_prob": 0.00005829116707900539,
        "seek": 463486,
        "start": 4645.98,
        "temperature": 0,
        "text": " let's look at the fit function.",
        "tokens": [
          50920,
          718,
          311,
          574,
          412,
          264,
          3318,
          2445,
          13,
          51022
        ]
      },
      {
        "avg_logprob": -0.2583272232968583,
        "compression_ratio": 1.6027397260273972,
        "end": 4653.0199999999995,
        "id": 1546,
        "no_speech_prob": 0.00005829116707900539,
        "seek": 463486,
        "start": 4648.0199999999995,
        "temperature": 0,
        "text": " Model.evaluate, compile, predict, fit.",
        "tokens": [
          51022,
          17105,
          13,
          68,
          3337,
          10107,
          11,
          31413,
          11,
          6069,
          11,
          3318,
          13,
          51272
        ]
      },
      {
        "avg_logprob": -0.2583272232968583,
        "compression_ratio": 1.6027397260273972,
        "end": 4659.339999999999,
        "id": 1547,
        "no_speech_prob": 0.00005829116707900539,
        "seek": 463486,
        "start": 4654.74,
        "temperature": 0,
        "text": " So what I need is to give it the xs and the ys.",
        "tokens": [
          51358,
          407,
          437,
          286,
          643,
          307,
          281,
          976,
          309,
          264,
          2031,
          82,
          293,
          264,
          288,
          82,
          13,
          51588
        ]
      },
      {
        "avg_logprob": -0.2583272232968583,
        "compression_ratio": 1.6027397260273972,
        "end": 4661.339999999999,
        "id": 1548,
        "no_speech_prob": 0.00005829116707900539,
        "seek": 463486,
        "start": 4659.339999999999,
        "temperature": 0,
        "text": " There's batch size I'm not going to worry about.",
        "tokens": [
          51588,
          821,
          311,
          15245,
          2744,
          286,
          478,
          406,
          516,
          281,
          3292,
          466,
          13,
          51688
        ]
      },
      {
        "avg_logprob": -0.2583272232968583,
        "compression_ratio": 1.6027397260273972,
        "end": 4664.099999999999,
        "id": 1549,
        "no_speech_prob": 0.00005829116707900539,
        "seek": 463486,
        "start": 4661.339999999999,
        "temperature": 0,
        "text": " There's epochs I'm not going to worry about, or epics.",
        "tokens": [
          51688,
          821,
          311,
          30992,
          28346,
          286,
          478,
          406,
          516,
          281,
          3292,
          466,
          11,
          420,
          2388,
          1167,
          13,
          51826
        ]
      },
      {
        "avg_logprob": -0.281050371836467,
        "compression_ratio": 1.4337349397590362,
        "end": 4669.179999999999,
        "id": 1550,
        "no_speech_prob": 0.000019525859897839837,
        "seek": 466486,
        "start": 4665.66,
        "temperature": 0,
        "text": " And so h will give me back the history.",
        "tokens": [
          50404,
          400,
          370,
          276,
          486,
          976,
          385,
          646,
          264,
          2503,
          13,
          50580
        ]
      },
      {
        "avg_logprob": -0.281050371836467,
        "compression_ratio": 1.4337349397590362,
        "end": 4670.9,
        "id": 1551,
        "no_speech_prob": 0.000019525859897839837,
        "seek": 466486,
        "start": 4669.179999999999,
        "temperature": 0,
        "text": " So let's just see here.",
        "tokens": [
          50580,
          407,
          718,
          311,
          445,
          536,
          510,
          13,
          50666
        ]
      },
      {
        "avg_logprob": -0.281050371836467,
        "compression_ratio": 1.4337349397590362,
        "end": 4675.0599999999995,
        "id": 1552,
        "no_speech_prob": 0.000019525859897839837,
        "seek": 466486,
        "start": 4670.9,
        "temperature": 0,
        "text": " I'm now going to say trainModel.then,",
        "tokens": [
          50666,
          286,
          478,
          586,
          516,
          281,
          584,
          3847,
          44,
          41147,
          13,
          19096,
          11,
          50874
        ]
      },
      {
        "avg_logprob": -0.281050371836467,
        "compression_ratio": 1.4337349397590362,
        "end": 4682.74,
        "id": 1553,
        "no_speech_prob": 0.000019525859897839837,
        "seek": 466486,
        "start": 4677.74,
        "temperature": 0,
        "text": " h console.log, h.loss, index zero.",
        "tokens": [
          51008,
          276,
          11076,
          13,
          4987,
          11,
          276,
          13,
          75,
          772,
          11,
          8186,
          4018,
          13,
          51258
        ]
      },
      {
        "avg_logprob": -0.281050371836467,
        "compression_ratio": 1.4337349397590362,
        "end": 4685.66,
        "id": 1554,
        "no_speech_prob": 0.000019525859897839837,
        "seek": 466486,
        "start": 4684.179999999999,
        "temperature": 0,
        "text": " Let's say no loop again.",
        "tokens": [
          51330,
          961,
          311,
          584,
          572,
          6367,
          797,
          13,
          51404
        ]
      },
      {
        "avg_logprob": -0.281050371836467,
        "compression_ratio": 1.4337349397590362,
        "end": 4689.339999999999,
        "id": 1555,
        "no_speech_prob": 0.000019525859897839837,
        "seek": 466486,
        "start": 4686.58,
        "temperature": 0,
        "text": " So basically what I'm doing here is",
        "tokens": [
          51450,
          407,
          1936,
          437,
          286,
          478,
          884,
          510,
          307,
          51588
        ]
      },
      {
        "avg_logprob": -0.281050371836467,
        "compression_ratio": 1.4337349397590362,
        "end": 4693.74,
        "id": 1556,
        "no_speech_prob": 0.000019525859897839837,
        "seek": 466486,
        "start": 4691.339999999999,
        "temperature": 0,
        "text": " I want to call this function trainModel.",
        "tokens": [
          51688,
          286,
          528,
          281,
          818,
          341,
          2445,
          3847,
          44,
          41147,
          13,
          51808
        ]
      },
      {
        "avg_logprob": -0.20491678818412448,
        "compression_ratio": 1.8024193548387097,
        "end": 4695.9,
        "id": 1557,
        "no_speech_prob": 0.00007602461118949577,
        "seek": 469374,
        "start": 4693.74,
        "temperature": 0,
        "text": " And I'm using this idea of promises.",
        "tokens": [
          50364,
          400,
          286,
          478,
          1228,
          341,
          1558,
          295,
          16403,
          13,
          50472
        ]
      },
      {
        "avg_logprob": -0.20491678818412448,
        "compression_ratio": 1.8024193548387097,
        "end": 4699.0199999999995,
        "id": 1558,
        "no_speech_prob": 0.00007602461118949577,
        "seek": 469374,
        "start": 4695.9,
        "temperature": 0,
        "text": " It's going to await the model, oh and I need to return.",
        "tokens": [
          50472,
          467,
          311,
          516,
          281,
          19670,
          264,
          2316,
          11,
          1954,
          293,
          286,
          643,
          281,
          2736,
          13,
          50628
        ]
      },
      {
        "avg_logprob": -0.20491678818412448,
        "compression_ratio": 1.8024193548387097,
        "end": 4703.62,
        "id": 1559,
        "no_speech_prob": 0.00007602461118949577,
        "seek": 469374,
        "start": 4700.82,
        "temperature": 0,
        "text": " Do I say await return or return await?",
        "tokens": [
          50718,
          1144,
          286,
          584,
          19670,
          2736,
          420,
          2736,
          19670,
          30,
          50858
        ]
      },
      {
        "avg_logprob": -0.20491678818412448,
        "compression_ratio": 1.8024193548387097,
        "end": 4704.82,
        "id": 1560,
        "no_speech_prob": 0.00007602461118949577,
        "seek": 469374,
        "start": 4703.62,
        "temperature": 0,
        "text": " No.",
        "tokens": [
          50858,
          883,
          13,
          50918
        ]
      },
      {
        "avg_logprob": -0.20491678818412448,
        "compression_ratio": 1.8024193548387097,
        "end": 4706.5,
        "id": 1561,
        "no_speech_prob": 0.00007602461118949577,
        "seek": 469374,
        "start": 4704.82,
        "temperature": 0,
        "text": " I must say return await.",
        "tokens": [
          50918,
          286,
          1633,
          584,
          2736,
          19670,
          13,
          51002
        ]
      },
      {
        "avg_logprob": -0.20491678818412448,
        "compression_ratio": 1.8024193548387097,
        "end": 4708.82,
        "id": 1562,
        "no_speech_prob": 0.00007602461118949577,
        "seek": 469374,
        "start": 4706.5,
        "temperature": 0,
        "text": " Return await model.fit.",
        "tokens": [
          51002,
          24350,
          19670,
          2316,
          13,
          6845,
          13,
          51118
        ]
      },
      {
        "avg_logprob": -0.20491678818412448,
        "compression_ratio": 1.8024193548387097,
        "end": 4711.34,
        "id": 1563,
        "no_speech_prob": 0.00007602461118949577,
        "seek": 469374,
        "start": 4708.82,
        "temperature": 0,
        "text": " So I'm going to return a promise",
        "tokens": [
          51118,
          407,
          286,
          478,
          516,
          281,
          2736,
          257,
          6228,
          51244
        ]
      },
      {
        "avg_logprob": -0.20491678818412448,
        "compression_ratio": 1.8024193548387097,
        "end": 4714.219999999999,
        "id": 1564,
        "no_speech_prob": 0.00007602461118949577,
        "seek": 469374,
        "start": 4711.34,
        "temperature": 0,
        "text": " which will have the result of the fit function.",
        "tokens": [
          51244,
          597,
          486,
          362,
          264,
          1874,
          295,
          264,
          3318,
          2445,
          13,
          51388
        ]
      },
      {
        "avg_logprob": -0.20491678818412448,
        "compression_ratio": 1.8024193548387097,
        "end": 4715.38,
        "id": 1565,
        "no_speech_prob": 0.00007602461118949577,
        "seek": 469374,
        "start": 4714.219999999999,
        "temperature": 0,
        "text": " And I don't know if this is right.",
        "tokens": [
          51388,
          400,
          286,
          500,
          380,
          458,
          498,
          341,
          307,
          558,
          13,
          51446
        ]
      },
      {
        "avg_logprob": -0.20491678818412448,
        "compression_ratio": 1.8024193548387097,
        "end": 4717.7,
        "id": 1566,
        "no_speech_prob": 0.00007602461118949577,
        "seek": 469374,
        "start": 4715.38,
        "temperature": 0,
        "text": " I want to just look, I want to do that.",
        "tokens": [
          51446,
          286,
          528,
          281,
          445,
          574,
          11,
          286,
          528,
          281,
          360,
          300,
          13,
          51562
        ]
      },
      {
        "avg_logprob": -0.20491678818412448,
        "compression_ratio": 1.8024193548387097,
        "end": 4719.78,
        "id": 1567,
        "no_speech_prob": 0.00007602461118949577,
        "seek": 469374,
        "start": 4717.7,
        "temperature": 0,
        "text": " I want to call to trainModel every time in draw.",
        "tokens": [
          51562,
          286,
          528,
          281,
          818,
          281,
          3847,
          44,
          41147,
          633,
          565,
          294,
          2642,
          13,
          51666
        ]
      },
      {
        "avg_logprob": -0.20491678818412448,
        "compression_ratio": 1.8024193548387097,
        "end": 4722.219999999999,
        "id": 1568,
        "no_speech_prob": 0.00007602461118949577,
        "seek": 469374,
        "start": 4719.78,
        "temperature": 0,
        "text": " I might need to do this somewhere else just for right now",
        "tokens": [
          51666,
          286,
          1062,
          643,
          281,
          360,
          341,
          4079,
          1646,
          445,
          337,
          558,
          586,
          51788
        ]
      },
      {
        "avg_logprob": -0.2947911201639378,
        "compression_ratio": 1.5802469135802468,
        "end": 4723.780000000001,
        "id": 1569,
        "no_speech_prob": 0.000009223466804542113,
        "seek": 472222,
        "start": 4722.22,
        "temperature": 0,
        "text": " and then see what the loss is.",
        "tokens": [
          50364,
          293,
          550,
          536,
          437,
          264,
          4470,
          307,
          13,
          50442
        ]
      },
      {
        "avg_logprob": -0.2947911201639378,
        "compression_ratio": 1.5802469135802468,
        "end": 4733.860000000001,
        "id": 1570,
        "no_speech_prob": 0.000009223466804542113,
        "seek": 472222,
        "start": 4729.42,
        "temperature": 0,
        "text": " On x73, async function.",
        "tokens": [
          50724,
          1282,
          2031,
          33396,
          11,
          382,
          34015,
          2445,
          13,
          50946
        ]
      },
      {
        "avg_logprob": -0.2947911201639378,
        "compression_ratio": 1.5802469135802468,
        "end": 4736.22,
        "id": 1571,
        "no_speech_prob": 0.000009223466804542113,
        "seek": 472222,
        "start": 4733.860000000001,
        "temperature": 0,
        "text": " Async function, I've got to say function.",
        "tokens": [
          50946,
          1018,
          34015,
          2445,
          11,
          286,
          600,
          658,
          281,
          584,
          2445,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.2947911201639378,
        "compression_ratio": 1.5802469135802468,
        "end": 4738.7,
        "id": 1572,
        "no_speech_prob": 0.000009223466804542113,
        "seek": 472222,
        "start": 4736.22,
        "temperature": 0,
        "text": " Function, it's an async function, not an async.",
        "tokens": [
          51064,
          11166,
          882,
          11,
          309,
          311,
          364,
          382,
          34015,
          2445,
          11,
          406,
          364,
          382,
          34015,
          13,
          51188
        ]
      },
      {
        "avg_logprob": -0.2947911201639378,
        "compression_ratio": 1.5802469135802468,
        "end": 4739.54,
        "id": 1573,
        "no_speech_prob": 0.000009223466804542113,
        "seek": 472222,
        "start": 4738.7,
        "temperature": 0,
        "text": " There we go.",
        "tokens": [
          51188,
          821,
          321,
          352,
          13,
          51230
        ]
      },
      {
        "avg_logprob": -0.2947911201639378,
        "compression_ratio": 1.5802469135802468,
        "end": 4745.06,
        "id": 1574,
        "no_speech_prob": 0.000009223466804542113,
        "seek": 472222,
        "start": 4741.66,
        "temperature": 0,
        "text": " Ys is not defined where in trainModel.",
        "tokens": [
          51336,
          398,
          82,
          307,
          406,
          7642,
          689,
          294,
          3847,
          44,
          41147,
          13,
          51506
        ]
      },
      {
        "avg_logprob": -0.2947911201639378,
        "compression_ratio": 1.5802469135802468,
        "end": 4747.3,
        "id": 1575,
        "no_speech_prob": 0.000009223466804542113,
        "seek": 472222,
        "start": 4745.06,
        "temperature": 0,
        "text": " Oh right, this is, I forgot to call it",
        "tokens": [
          51506,
          876,
          558,
          11,
          341,
          307,
          11,
          286,
          5298,
          281,
          818,
          309,
          51618
        ]
      },
      {
        "avg_logprob": -0.2947911201639378,
        "compression_ratio": 1.5802469135802468,
        "end": 4749.820000000001,
        "id": 1576,
        "no_speech_prob": 0.000009223466804542113,
        "seek": 472222,
        "start": 4747.3,
        "temperature": 0,
        "text": " trainXs and trainYs.",
        "tokens": [
          51618,
          3847,
          55,
          82,
          293,
          3847,
          56,
          82,
          13,
          51744
        ]
      },
      {
        "avg_logprob": -0.30674733434404644,
        "compression_ratio": 1.5661157024793388,
        "end": 4753.5,
        "id": 1577,
        "no_speech_prob": 0.00002885709545807913,
        "seek": 474982,
        "start": 4749.82,
        "temperature": 0,
        "text": " So my training data, trainXs and trainYs.",
        "tokens": [
          50364,
          407,
          452,
          3097,
          1412,
          11,
          3847,
          55,
          82,
          293,
          3847,
          56,
          82,
          13,
          50548
        ]
      },
      {
        "avg_logprob": -0.30674733434404644,
        "compression_ratio": 1.5661157024793388,
        "end": 4756.98,
        "id": 1578,
        "no_speech_prob": 0.00002885709545807913,
        "seek": 474982,
        "start": 4754.38,
        "temperature": 0,
        "text": " Isn't it nice how the word train just appears everywhere",
        "tokens": [
          50592,
          6998,
          380,
          309,
          1481,
          577,
          264,
          1349,
          3847,
          445,
          7038,
          5315,
          50722
        ]
      },
      {
        "avg_logprob": -0.30674733434404644,
        "compression_ratio": 1.5661157024793388,
        "end": 4758.78,
        "id": 1579,
        "no_speech_prob": 0.00002885709545807913,
        "seek": 474982,
        "start": 4756.98,
        "temperature": 0,
        "text": " when you're doing machine learning?",
        "tokens": [
          50722,
          562,
          291,
          434,
          884,
          3479,
          2539,
          30,
          50812
        ]
      },
      {
        "avg_logprob": -0.30674733434404644,
        "compression_ratio": 1.5661157024793388,
        "end": 4762.62,
        "id": 1580,
        "no_speech_prob": 0.00002885709545807913,
        "seek": 474982,
        "start": 4760.78,
        "temperature": 0,
        "text": " Drink your glass of milk or whatever it is you're having",
        "tokens": [
          50912,
          24529,
          428,
          4276,
          295,
          5392,
          420,
          2035,
          309,
          307,
          291,
          434,
          1419,
          51004
        ]
      },
      {
        "avg_logprob": -0.30674733434404644,
        "compression_ratio": 1.5661157024793388,
        "end": 4765.259999999999,
        "id": 1581,
        "no_speech_prob": 0.00002885709545807913,
        "seek": 474982,
        "start": 4762.62,
        "temperature": 0,
        "text": " while you're watching this coding train stuff.",
        "tokens": [
          51004,
          1339,
          291,
          434,
          1976,
          341,
          17720,
          3847,
          1507,
          13,
          51136
        ]
      },
      {
        "avg_logprob": -0.30674733434404644,
        "compression_ratio": 1.5661157024793388,
        "end": 4769.66,
        "id": 1582,
        "no_speech_prob": 0.00002885709545807913,
        "seek": 474982,
        "start": 4766.7,
        "temperature": 0,
        "text": " Cannot read property zero of undefined",
        "tokens": [
          51208,
          29866,
          310,
          1401,
          4707,
          4018,
          295,
          674,
          5666,
          2001,
          51356
        ]
      },
      {
        "avg_logprob": -0.30674733434404644,
        "compression_ratio": 1.5661157024793388,
        "end": 4771.259999999999,
        "id": 1583,
        "no_speech_prob": 0.00002885709545807913,
        "seek": 474982,
        "start": 4769.66,
        "temperature": 0,
        "text": " at trainModel then h.",
        "tokens": [
          51356,
          412,
          3847,
          44,
          41147,
          550,
          276,
          13,
          51436
        ]
      },
      {
        "avg_logprob": -0.30674733434404644,
        "compression_ratio": 1.5661157024793388,
        "end": 4772.259999999999,
        "id": 1584,
        "no_speech_prob": 0.00002885709545807913,
        "seek": 474982,
        "start": 4771.259999999999,
        "temperature": 0,
        "text": " All right.",
        "tokens": [
          51436,
          1057,
          558,
          13,
          51486
        ]
      },
      {
        "avg_logprob": -0.30674733434404644,
        "compression_ratio": 1.5661157024793388,
        "end": 4776.139999999999,
        "id": 1585,
        "no_speech_prob": 0.00002885709545807913,
        "seek": 474982,
        "start": 4772.259999999999,
        "temperature": 0,
        "text": " Let's just console log h.",
        "tokens": [
          51486,
          961,
          311,
          445,
          11076,
          3565,
          276,
          13,
          51680
        ]
      },
      {
        "avg_logprob": -0.30674733434404644,
        "compression_ratio": 1.5661157024793388,
        "end": 4778.219999999999,
        "id": 1586,
        "no_speech_prob": 0.00002885709545807913,
        "seek": 474982,
        "start": 4776.139999999999,
        "temperature": 0,
        "text": " I don't know what that is, what I've done.",
        "tokens": [
          51680,
          286,
          500,
          380,
          458,
          437,
          300,
          307,
          11,
          437,
          286,
          600,
          1096,
          13,
          51784
        ]
      },
      {
        "avg_logprob": -0.277388150875385,
        "compression_ratio": 1.5208333333333333,
        "end": 4781.46,
        "id": 1587,
        "no_speech_prob": 0.000011659521078399848,
        "seek": 477982,
        "start": 4780.62,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          50404,
          1033,
          13,
          50446
        ]
      },
      {
        "avg_logprob": -0.277388150875385,
        "compression_ratio": 1.5208333333333333,
        "end": 4785.0199999999995,
        "id": 1588,
        "no_speech_prob": 0.000011659521078399848,
        "seek": 477982,
        "start": 4782.7,
        "temperature": 0,
        "text": " History, loss, zero.",
        "tokens": [
          50508,
          12486,
          11,
          4470,
          11,
          4018,
          13,
          50624
        ]
      },
      {
        "avg_logprob": -0.277388150875385,
        "compression_ratio": 1.5208333333333333,
        "end": 4786.219999999999,
        "id": 1589,
        "no_speech_prob": 0.000011659521078399848,
        "seek": 477982,
        "start": 4785.0199999999995,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          50624,
          1033,
          13,
          50684
        ]
      },
      {
        "avg_logprob": -0.277388150875385,
        "compression_ratio": 1.5208333333333333,
        "end": 4788.78,
        "id": 1590,
        "no_speech_prob": 0.000011659521078399848,
        "seek": 477982,
        "start": 4786.219999999999,
        "temperature": 0,
        "text": " Oh no, by the way, I didn't give it any testing data.",
        "tokens": [
          50684,
          876,
          572,
          11,
          538,
          264,
          636,
          11,
          286,
          994,
          380,
          976,
          309,
          604,
          4997,
          1412,
          13,
          50812
        ]
      },
      {
        "avg_logprob": -0.277388150875385,
        "compression_ratio": 1.5208333333333333,
        "end": 4790.62,
        "id": 1591,
        "no_speech_prob": 0.000011659521078399848,
        "seek": 477982,
        "start": 4788.78,
        "temperature": 0,
        "text": " So what's it computing the loss from?",
        "tokens": [
          50812,
          407,
          437,
          311,
          309,
          15866,
          264,
          4470,
          490,
          30,
          50904
        ]
      },
      {
        "avg_logprob": -0.277388150875385,
        "compression_ratio": 1.5208333333333333,
        "end": 4795.42,
        "id": 1592,
        "no_speech_prob": 0.000011659521078399848,
        "seek": 477982,
        "start": 4792.099999999999,
        "temperature": 0,
        "text": " History, so this is, I'm going to call this result.",
        "tokens": [
          50978,
          12486,
          11,
          370,
          341,
          307,
          11,
          286,
          478,
          516,
          281,
          818,
          341,
          1874,
          13,
          51144
        ]
      },
      {
        "avg_logprob": -0.277388150875385,
        "compression_ratio": 1.5208333333333333,
        "end": 4800.78,
        "id": 1593,
        "no_speech_prob": 0.000011659521078399848,
        "seek": 477982,
        "start": 4796.66,
        "temperature": 0,
        "text": " Result, history.loss, index zero.",
        "tokens": [
          51206,
          5015,
          723,
          11,
          2503,
          13,
          75,
          772,
          11,
          8186,
          4018,
          13,
          51412
        ]
      },
      {
        "avg_logprob": -0.277388150875385,
        "compression_ratio": 1.5208333333333333,
        "end": 4802.94,
        "id": 1594,
        "no_speech_prob": 0.000011659521078399848,
        "seek": 477982,
        "start": 4801.66,
        "temperature": 0,
        "text": " All right, there we go.",
        "tokens": [
          51456,
          1057,
          558,
          11,
          456,
          321,
          352,
          13,
          51520
        ]
      },
      {
        "avg_logprob": -0.277388150875385,
        "compression_ratio": 1.5208333333333333,
        "end": 4805.38,
        "id": 1595,
        "no_speech_prob": 0.000011659521078399848,
        "seek": 477982,
        "start": 4804.139999999999,
        "temperature": 0,
        "text": " There we go.",
        "tokens": [
          51580,
          821,
          321,
          352,
          13,
          51642
        ]
      },
      {
        "avg_logprob": -0.277388150875385,
        "compression_ratio": 1.5208333333333333,
        "end": 4809.54,
        "id": 1596,
        "no_speech_prob": 0.000011659521078399848,
        "seek": 477982,
        "start": 4805.38,
        "temperature": 0,
        "text": " Now let's let it do that over and over again",
        "tokens": [
          51642,
          823,
          718,
          311,
          718,
          309,
          360,
          300,
          670,
          293,
          670,
          797,
          51850
        ]
      },
      {
        "avg_logprob": -0.4155578035296816,
        "compression_ratio": 1.5688073394495412,
        "end": 4811.14,
        "id": 1597,
        "no_speech_prob": 0.000011478721717139706,
        "seek": 480954,
        "start": 4810.3,
        "temperature": 0,
        "text": " in draw.",
        "tokens": [
          50402,
          294,
          2642,
          13,
          50444
        ]
      },
      {
        "avg_logprob": -0.4155578035296816,
        "compression_ratio": 1.5688073394495412,
        "end": 4818.54,
        "id": 1598,
        "no_speech_prob": 0.000011478721717139706,
        "seek": 480954,
        "start": 4813.54,
        "temperature": 0,
        "text": " Do do do do do do do do do do do do do do do do do do do.",
        "tokens": [
          50564,
          1144,
          360,
          360,
          360,
          360,
          360,
          360,
          360,
          360,
          360,
          360,
          360,
          360,
          360,
          360,
          360,
          360,
          360,
          360,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.4155578035296816,
        "compression_ratio": 1.5688073394495412,
        "end": 4823.9,
        "id": 1599,
        "no_speech_prob": 0.000011478721717139706,
        "seek": 480954,
        "start": 4823.06,
        "temperature": 0,
        "text": " All right.",
        "tokens": [
          51040,
          1057,
          558,
          13,
          51082
        ]
      },
      {
        "avg_logprob": -0.4155578035296816,
        "compression_ratio": 1.5688073394495412,
        "end": 4827.98,
        "id": 1600,
        "no_speech_prob": 0.000011478721717139706,
        "seek": 480954,
        "start": 4825.78,
        "temperature": 0,
        "text": " So this is a bit of a fail here.",
        "tokens": [
          51176,
          407,
          341,
          307,
          257,
          857,
          295,
          257,
          3061,
          510,
          13,
          51286
        ]
      },
      {
        "avg_logprob": -0.4155578035296816,
        "compression_ratio": 1.5688073394495412,
        "end": 4831.62,
        "id": 1601,
        "no_speech_prob": 0.000011478721717139706,
        "seek": 480954,
        "start": 4830.3,
        "temperature": 0,
        "text": " Oh.",
        "tokens": [
          51402,
          876,
          13,
          51468
        ]
      },
      {
        "avg_logprob": -0.4155578035296816,
        "compression_ratio": 1.5688073394495412,
        "end": 4834.34,
        "id": 1602,
        "no_speech_prob": 0.000011478721717139706,
        "seek": 480954,
        "start": 4831.62,
        "temperature": 0,
        "text": " No, if we're returning the promise, that's a good point.",
        "tokens": [
          51468,
          883,
          11,
          498,
          321,
          434,
          12678,
          264,
          6228,
          11,
          300,
          311,
          257,
          665,
          935,
          13,
          51604
        ]
      },
      {
        "avg_logprob": -0.23699824015299478,
        "compression_ratio": 1.574468085106383,
        "end": 4840.62,
        "id": 1603,
        "no_speech_prob": 0.000026688483558245935,
        "seek": 483954,
        "start": 4839.62,
        "temperature": 0,
        "text": " There we go.",
        "tokens": [
          50368,
          821,
          321,
          352,
          13,
          50418
        ]
      },
      {
        "avg_logprob": -0.23699824015299478,
        "compression_ratio": 1.574468085106383,
        "end": 4842.42,
        "id": 1604,
        "no_speech_prob": 0.000026688483558245935,
        "seek": 483954,
        "start": 4841.58,
        "temperature": 0,
        "text": " All right.",
        "tokens": [
          50466,
          1057,
          558,
          13,
          50508
        ]
      },
      {
        "avg_logprob": -0.23699824015299478,
        "compression_ratio": 1.574468085106383,
        "end": 4851.9,
        "id": 1605,
        "no_speech_prob": 0.000026688483558245935,
        "seek": 483954,
        "start": 4850.7,
        "temperature": 0,
        "text": " So I let this run a little bit",
        "tokens": [
          50922,
          407,
          286,
          718,
          341,
          1190,
          257,
          707,
          857,
          50982
        ]
      },
      {
        "avg_logprob": -0.23699824015299478,
        "compression_ratio": 1.574468085106383,
        "end": 4854.14,
        "id": 1606,
        "no_speech_prob": 0.000026688483558245935,
        "seek": 483954,
        "start": 4851.9,
        "temperature": 0,
        "text": " and unfortunately you can see it's getting nowhere.",
        "tokens": [
          50982,
          293,
          7015,
          291,
          393,
          536,
          309,
          311,
          1242,
          11159,
          13,
          51094
        ]
      },
      {
        "avg_logprob": -0.23699824015299478,
        "compression_ratio": 1.574468085106383,
        "end": 4856.94,
        "id": 1607,
        "no_speech_prob": 0.000026688483558245935,
        "seek": 483954,
        "start": 4854.14,
        "temperature": 0,
        "text": " This loss, which I'm not sure exactly how it's calculating",
        "tokens": [
          51094,
          639,
          4470,
          11,
          597,
          286,
          478,
          406,
          988,
          2293,
          577,
          309,
          311,
          28258,
          51234
        ]
      },
      {
        "avg_logprob": -0.23699824015299478,
        "compression_ratio": 1.574468085106383,
        "end": 4859.7,
        "id": 1608,
        "no_speech_prob": 0.000026688483558245935,
        "seek": 483954,
        "start": 4856.94,
        "temperature": 0,
        "text": " that, I'll think about that and come back to it,",
        "tokens": [
          51234,
          300,
          11,
          286,
          603,
          519,
          466,
          300,
          293,
          808,
          646,
          281,
          309,
          11,
          51372
        ]
      },
      {
        "avg_logprob": -0.23699824015299478,
        "compression_ratio": 1.574468085106383,
        "end": 4861.94,
        "id": 1609,
        "no_speech_prob": 0.000026688483558245935,
        "seek": 483954,
        "start": 4859.7,
        "temperature": 0,
        "text": " is not going down anymore.",
        "tokens": [
          51372,
          307,
          406,
          516,
          760,
          3602,
          13,
          51484
        ]
      },
      {
        "avg_logprob": -0.23699824015299478,
        "compression_ratio": 1.574468085106383,
        "end": 4863.46,
        "id": 1610,
        "no_speech_prob": 0.000026688483558245935,
        "seek": 483954,
        "start": 4861.94,
        "temperature": 0,
        "text": " So what could be some problems here?",
        "tokens": [
          51484,
          407,
          437,
          727,
          312,
          512,
          2740,
          510,
          30,
          51560
        ]
      },
      {
        "avg_logprob": -0.23699824015299478,
        "compression_ratio": 1.574468085106383,
        "end": 4866.9,
        "id": 1611,
        "no_speech_prob": 0.000026688483558245935,
        "seek": 483954,
        "start": 4863.46,
        "temperature": 0,
        "text": " Number one is maybe my learning rate is no good.",
        "tokens": [
          51560,
          5118,
          472,
          307,
          1310,
          452,
          2539,
          3314,
          307,
          572,
          665,
          13,
          51732
        ]
      },
      {
        "avg_logprob": -0.23699824015299478,
        "compression_ratio": 1.574468085106383,
        "end": 4869.14,
        "id": 1612,
        "no_speech_prob": 0.000026688483558245935,
        "seek": 483954,
        "start": 4866.9,
        "temperature": 0,
        "text": " Not that it's no good, maybe it's too low.",
        "tokens": [
          51732,
          1726,
          300,
          309,
          311,
          572,
          665,
          11,
          1310,
          309,
          311,
          886,
          2295,
          13,
          51844
        ]
      },
      {
        "avg_logprob": -0.24279346938960808,
        "compression_ratio": 1.65,
        "end": 4872.18,
        "id": 1613,
        "no_speech_prob": 0.000006240923994482728,
        "seek": 486914,
        "start": 4869.700000000001,
        "temperature": 0,
        "text": " So where did I set up that learning rate again?",
        "tokens": [
          50392,
          407,
          689,
          630,
          286,
          992,
          493,
          300,
          2539,
          3314,
          797,
          30,
          50516
        ]
      },
      {
        "avg_logprob": -0.24279346938960808,
        "compression_ratio": 1.65,
        "end": 4874.900000000001,
        "id": 1614,
        "no_speech_prob": 0.000006240923994482728,
        "seek": 486914,
        "start": 4872.18,
        "temperature": 0,
        "text": " Let me get rid of, by the way, I just want to now delete.",
        "tokens": [
          50516,
          961,
          385,
          483,
          3973,
          295,
          11,
          538,
          264,
          636,
          11,
          286,
          445,
          528,
          281,
          586,
          12097,
          13,
          50652
        ]
      },
      {
        "avg_logprob": -0.24279346938960808,
        "compression_ratio": 1.65,
        "end": 4877.1,
        "id": 1615,
        "no_speech_prob": 0.000006240923994482728,
        "seek": 486914,
        "start": 4874.900000000001,
        "temperature": 0,
        "text": " I want to make sure I'm not using",
        "tokens": [
          50652,
          286,
          528,
          281,
          652,
          988,
          286,
          478,
          406,
          1228,
          50762
        ]
      },
      {
        "avg_logprob": -0.24279346938960808,
        "compression_ratio": 1.65,
        "end": 4879.820000000001,
        "id": 1616,
        "no_speech_prob": 0.000006240923994482728,
        "seek": 486914,
        "start": 4877.1,
        "temperature": 0,
        "text": " any of my old neural network code.",
        "tokens": [
          50762,
          604,
          295,
          452,
          1331,
          18161,
          3209,
          3089,
          13,
          50898
        ]
      },
      {
        "avg_logprob": -0.24279346938960808,
        "compression_ratio": 1.65,
        "end": 4882.26,
        "id": 1617,
        "no_speech_prob": 0.000006240923994482728,
        "seek": 486914,
        "start": 4879.820000000001,
        "temperature": 0,
        "text": " So I'm deleting all references to that.",
        "tokens": [
          50898,
          407,
          286,
          478,
          48946,
          439,
          15400,
          281,
          300,
          13,
          51020
        ]
      },
      {
        "avg_logprob": -0.24279346938960808,
        "compression_ratio": 1.65,
        "end": 4888.820000000001,
        "id": 1618,
        "no_speech_prob": 0.000006240923994482728,
        "seek": 486914,
        "start": 4884.700000000001,
        "temperature": 0,
        "text": " So this is now purely TensorFlow.js and let me refresh",
        "tokens": [
          51142,
          407,
          341,
          307,
          586,
          17491,
          37624,
          13,
          25530,
          293,
          718,
          385,
          15134,
          51348
        ]
      },
      {
        "avg_logprob": -0.24279346938960808,
        "compression_ratio": 1.65,
        "end": 4889.9400000000005,
        "id": 1619,
        "no_speech_prob": 0.000006240923994482728,
        "seek": 486914,
        "start": 4888.820000000001,
        "temperature": 0,
        "text": " and run this again.",
        "tokens": [
          51348,
          293,
          1190,
          341,
          797,
          13,
          51404
        ]
      },
      {
        "avg_logprob": -0.24279346938960808,
        "compression_ratio": 1.65,
        "end": 4894.660000000001,
        "id": 1620,
        "no_speech_prob": 0.000006240923994482728,
        "seek": 486914,
        "start": 4891.34,
        "temperature": 0,
        "text": " And let me look into Sketch.js and find",
        "tokens": [
          51474,
          400,
          718,
          385,
          574,
          666,
          49245,
          13,
          25530,
          293,
          915,
          51640
        ]
      },
      {
        "avg_logprob": -0.24279346938960808,
        "compression_ratio": 1.65,
        "end": 4896.740000000001,
        "id": 1621,
        "no_speech_prob": 0.000006240923994482728,
        "seek": 486914,
        "start": 4894.660000000001,
        "temperature": 0,
        "text": " where did I set the learning rate right here.",
        "tokens": [
          51640,
          689,
          630,
          286,
          992,
          264,
          2539,
          3314,
          558,
          510,
          13,
          51744
        ]
      },
      {
        "avg_logprob": -0.24279346938960808,
        "compression_ratio": 1.65,
        "end": 4898.34,
        "id": 1622,
        "no_speech_prob": 0.000006240923994482728,
        "seek": 486914,
        "start": 4896.740000000001,
        "temperature": 0,
        "text": " Let's set it to 0.5.",
        "tokens": [
          51744,
          961,
          311,
          992,
          309,
          281,
          1958,
          13,
          20,
          13,
          51824
        ]
      },
      {
        "avg_logprob": -0.27305265426635744,
        "compression_ratio": 1.5637254901960784,
        "end": 4901.660000000001,
        "id": 1623,
        "no_speech_prob": 0.000004860423359787092,
        "seek": 489914,
        "start": 4900.14,
        "temperature": 0,
        "text": " And see what we get.",
        "tokens": [
          50414,
          400,
          536,
          437,
          321,
          483,
          13,
          50490
        ]
      },
      {
        "avg_logprob": -0.27305265426635744,
        "compression_ratio": 1.5637254901960784,
        "end": 4905.780000000001,
        "id": 1624,
        "no_speech_prob": 0.000004860423359787092,
        "seek": 489914,
        "start": 4903.62,
        "temperature": 0,
        "text": " It's getting better.",
        "tokens": [
          50588,
          467,
          311,
          1242,
          1101,
          13,
          50696
        ]
      },
      {
        "avg_logprob": -0.27305265426635744,
        "compression_ratio": 1.5637254901960784,
        "end": 4908.14,
        "id": 1625,
        "no_speech_prob": 0.000004860423359787092,
        "seek": 489914,
        "start": 4905.780000000001,
        "temperature": 0,
        "text": " I'm going to let this run for a little bit and I'll be back.",
        "tokens": [
          50696,
          286,
          478,
          516,
          281,
          718,
          341,
          1190,
          337,
          257,
          707,
          857,
          293,
          286,
          603,
          312,
          646,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.27305265426635744,
        "compression_ratio": 1.5637254901960784,
        "end": 4913.9800000000005,
        "id": 1626,
        "no_speech_prob": 0.000004860423359787092,
        "seek": 489914,
        "start": 4911.900000000001,
        "temperature": 0,
        "text": " Let me look at...",
        "tokens": [
          51002,
          961,
          385,
          574,
          412,
          485,
          51106
        ]
      },
      {
        "avg_logprob": -0.27305265426635744,
        "compression_ratio": 1.5637254901960784,
        "end": 4919.780000000001,
        "id": 1627,
        "no_speech_prob": 0.000004860423359787092,
        "seek": 489914,
        "start": 4917.38,
        "temperature": 0,
        "text": " So one thing I want to do also is I want to write,",
        "tokens": [
          51276,
          407,
          472,
          551,
          286,
          528,
          281,
          360,
          611,
          307,
          286,
          528,
          281,
          2464,
          11,
          51396
        ]
      },
      {
        "avg_logprob": -0.27305265426635744,
        "compression_ratio": 1.5637254901960784,
        "end": 4922.62,
        "id": 1628,
        "no_speech_prob": 0.000004860423359787092,
        "seek": 489914,
        "start": 4919.780000000001,
        "temperature": 0,
        "text": " it looks nice if I write in the numbers actually",
        "tokens": [
          51396,
          309,
          1542,
          1481,
          498,
          286,
          2464,
          294,
          264,
          3547,
          767,
          51538
        ]
      },
      {
        "avg_logprob": -0.27305265426635744,
        "compression_ratio": 1.5637254901960784,
        "end": 4925.46,
        "id": 1629,
        "no_speech_prob": 0.000004860423359787092,
        "seek": 489914,
        "start": 4922.62,
        "temperature": 0,
        "text": " of what the output is, where it is.",
        "tokens": [
          51538,
          295,
          437,
          264,
          5598,
          307,
          11,
          689,
          309,
          307,
          13,
          51680
        ]
      },
      {
        "avg_logprob": -0.27305265426635744,
        "compression_ratio": 1.5637254901960784,
        "end": 4927.02,
        "id": 1630,
        "no_speech_prob": 0.000004860423359787092,
        "seek": 489914,
        "start": 4925.46,
        "temperature": 0,
        "text": " You can see that it's actually getting there",
        "tokens": [
          51680,
          509,
          393,
          536,
          300,
          309,
          311,
          767,
          1242,
          456,
          51758
        ]
      },
      {
        "avg_logprob": -0.27305265426635744,
        "compression_ratio": 1.5637254901960784,
        "end": 4928.22,
        "id": 1631,
        "no_speech_prob": 0.000004860423359787092,
        "seek": 489914,
        "start": 4927.02,
        "temperature": 0,
        "text": " just very slowly.",
        "tokens": [
          51758,
          445,
          588,
          5692,
          13,
          51818
        ]
      },
      {
        "avg_logprob": -0.21115550127896396,
        "compression_ratio": 1.5466666666666666,
        "end": 4933.22,
        "id": 1632,
        "no_speech_prob": 0.0000028573131203302182,
        "seek": 492822,
        "start": 4929.1,
        "temperature": 0,
        "text": " Just want to see what settings I used in my other example.",
        "tokens": [
          50408,
          1449,
          528,
          281,
          536,
          437,
          6257,
          286,
          1143,
          294,
          452,
          661,
          1365,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.21115550127896396,
        "compression_ratio": 1.5466666666666666,
        "end": 4938.14,
        "id": 1633,
        "no_speech_prob": 0.0000028573131203302182,
        "seek": 492822,
        "start": 4936.22,
        "temperature": 0,
        "text": " Try different optimizers and activation functions.",
        "tokens": [
          50764,
          6526,
          819,
          5028,
          22525,
          293,
          24433,
          6828,
          13,
          50860
        ]
      },
      {
        "avg_logprob": -0.21115550127896396,
        "compression_ratio": 1.5466666666666666,
        "end": 4939.780000000001,
        "id": 1634,
        "no_speech_prob": 0.0000028573131203302182,
        "seek": 492822,
        "start": 4938.14,
        "temperature": 0,
        "text": " Yeah, I'm going to do that in a second.",
        "tokens": [
          50860,
          865,
          11,
          286,
          478,
          516,
          281,
          360,
          300,
          294,
          257,
          1150,
          13,
          50942
        ]
      },
      {
        "avg_logprob": -0.21115550127896396,
        "compression_ratio": 1.5466666666666666,
        "end": 4942.5,
        "id": 1635,
        "no_speech_prob": 0.0000028573131203302182,
        "seek": 492822,
        "start": 4939.780000000001,
        "temperature": 0,
        "text": " I want to get it to work with this first.",
        "tokens": [
          50942,
          286,
          528,
          281,
          483,
          309,
          281,
          589,
          365,
          341,
          700,
          13,
          51078
        ]
      },
      {
        "avg_logprob": -0.21115550127896396,
        "compression_ratio": 1.5466666666666666,
        "end": 4944.780000000001,
        "id": 1636,
        "no_speech_prob": 0.0000028573131203302182,
        "seek": 492822,
        "start": 4942.5,
        "temperature": 0,
        "text": " I just want to see what settings I used.",
        "tokens": [
          51078,
          286,
          445,
          528,
          281,
          536,
          437,
          6257,
          286,
          1143,
          13,
          51192
        ]
      },
      {
        "avg_logprob": -0.2958851093199195,
        "compression_ratio": 1.4610389610389611,
        "end": 4946.46,
        "id": 1637,
        "no_speech_prob": 0.000004356877525424352,
        "seek": 494478,
        "start": 4945.62,
        "temperature": 0,
        "text": " Um...",
        "tokens": [
          50406,
          3301,
          485,
          50448
        ]
      },
      {
        "avg_logprob": -0.2958851093199195,
        "compression_ratio": 1.4610389610389611,
        "end": 4952.54,
        "id": 1638,
        "no_speech_prob": 0.000004356877525424352,
        "seek": 494478,
        "start": 4951.7,
        "temperature": 0,
        "text": " Um...",
        "tokens": [
          50710,
          3301,
          485,
          50752
        ]
      },
      {
        "avg_logprob": -0.2958851093199195,
        "compression_ratio": 1.4610389610389611,
        "end": 4954.46,
        "id": 1639,
        "no_speech_prob": 0.000004356877525424352,
        "seek": 494478,
        "start": 4953.62,
        "temperature": 0,
        "text": " Um...",
        "tokens": [
          50806,
          3301,
          485,
          50848
        ]
      },
      {
        "avg_logprob": -0.2958851093199195,
        "compression_ratio": 1.4610389610389611,
        "end": 4959.94,
        "id": 1640,
        "no_speech_prob": 0.000004356877525424352,
        "seek": 494478,
        "start": 4957.58,
        "temperature": 0,
        "text": " Oh, did I forget to put shuffle in?",
        "tokens": [
          51004,
          876,
          11,
          630,
          286,
          2870,
          281,
          829,
          39426,
          294,
          30,
          51122
        ]
      },
      {
        "avg_logprob": -0.2958851093199195,
        "compression_ratio": 1.4610389610389611,
        "end": 4961.5,
        "id": 1641,
        "no_speech_prob": 0.000004356877525424352,
        "seek": 494478,
        "start": 4959.94,
        "temperature": 0,
        "text": " It should shuffle it by default.",
        "tokens": [
          51122,
          467,
          820,
          39426,
          309,
          538,
          7576,
          13,
          51200
        ]
      },
      {
        "avg_logprob": -0.2958851093199195,
        "compression_ratio": 1.4610389610389611,
        "end": 4962.82,
        "id": 1642,
        "no_speech_prob": 0.000004356877525424352,
        "seek": 494478,
        "start": 4961.5,
        "temperature": 0,
        "text": " I wonder if I...",
        "tokens": [
          51200,
          286,
          2441,
          498,
          286,
          485,
          51266
        ]
      },
      {
        "avg_logprob": -0.2958851093199195,
        "compression_ratio": 1.4610389610389611,
        "end": 4964.82,
        "id": 1643,
        "no_speech_prob": 0.000004356877525424352,
        "seek": 494478,
        "start": 4962.82,
        "temperature": 0,
        "text": " Ah, you know what?",
        "tokens": [
          51266,
          2438,
          11,
          291,
          458,
          437,
          30,
          51366
        ]
      },
      {
        "avg_logprob": -0.2958851093199195,
        "compression_ratio": 1.4610389610389611,
        "end": 4966.5,
        "id": 1644,
        "no_speech_prob": 0.000004356877525424352,
        "seek": 494478,
        "start": 4964.82,
        "temperature": 0,
        "text": " I forgot to put shuffle in.",
        "tokens": [
          51366,
          286,
          5298,
          281,
          829,
          39426,
          294,
          13,
          51450
        ]
      },
      {
        "avg_logprob": -0.2958851093199195,
        "compression_ratio": 1.4610389610389611,
        "end": 4968.42,
        "id": 1645,
        "no_speech_prob": 0.000004356877525424352,
        "seek": 494478,
        "start": 4967.34,
        "temperature": 0,
        "text": " It's actually working.",
        "tokens": [
          51492,
          467,
          311,
          767,
          1364,
          13,
          51546
        ]
      },
      {
        "avg_logprob": -0.2958851093199195,
        "compression_ratio": 1.4610389610389611,
        "end": 4973.3,
        "id": 1646,
        "no_speech_prob": 0.000004356877525424352,
        "seek": 494478,
        "start": 4971.139999999999,
        "temperature": 0,
        "text": " All right, I'm back and you can see the loss is now",
        "tokens": [
          51682,
          1057,
          558,
          11,
          286,
          478,
          646,
          293,
          291,
          393,
          536,
          264,
          4470,
          307,
          586,
          51790
        ]
      },
      {
        "avg_logprob": -0.20627057374413335,
        "compression_ratio": 1.7857142857142858,
        "end": 4975.14,
        "id": 1647,
        "no_speech_prob": 0.0003514366690069437,
        "seek": 497330,
        "start": 4973.34,
        "temperature": 0,
        "text": " kind of much lower and you can start to see",
        "tokens": [
          50366,
          733,
          295,
          709,
          3126,
          293,
          291,
          393,
          722,
          281,
          536,
          50456
        ]
      },
      {
        "avg_logprob": -0.20627057374413335,
        "compression_ratio": 1.7857142857142858,
        "end": 4976.66,
        "id": 1648,
        "no_speech_prob": 0.0003514366690069437,
        "seek": 497330,
        "start": 4975.14,
        "temperature": 0,
        "text": " the visual that I'm expecting,",
        "tokens": [
          50456,
          264,
          5056,
          300,
          286,
          478,
          9650,
          11,
          50532
        ]
      },
      {
        "avg_logprob": -0.20627057374413335,
        "compression_ratio": 1.7857142857142858,
        "end": 4978.22,
        "id": 1649,
        "no_speech_prob": 0.0003514366690069437,
        "seek": 497330,
        "start": 4976.66,
        "temperature": 0,
        "text": " which has a true value in this corner,",
        "tokens": [
          50532,
          597,
          575,
          257,
          2074,
          2158,
          294,
          341,
          4538,
          11,
          50610
        ]
      },
      {
        "avg_logprob": -0.20627057374413335,
        "compression_ratio": 1.7857142857142858,
        "end": 4979.22,
        "id": 1650,
        "no_speech_prob": 0.0003514366690069437,
        "seek": 497330,
        "start": 4978.22,
        "temperature": 0,
        "text": " true value in the top corner,",
        "tokens": [
          50610,
          2074,
          2158,
          294,
          264,
          1192,
          4538,
          11,
          50660
        ]
      },
      {
        "avg_logprob": -0.20627057374413335,
        "compression_ratio": 1.7857142857142858,
        "end": 4981.54,
        "id": 1651,
        "no_speech_prob": 0.0003514366690069437,
        "seek": 497330,
        "start": 4979.22,
        "temperature": 0,
        "text": " and sort of darker false values in those corners.",
        "tokens": [
          50660,
          293,
          1333,
          295,
          12741,
          7908,
          4190,
          294,
          729,
          12413,
          13,
          50776
        ]
      },
      {
        "avg_logprob": -0.20627057374413335,
        "compression_ratio": 1.7857142857142858,
        "end": 4984.18,
        "id": 1652,
        "no_speech_prob": 0.0003514366690069437,
        "seek": 497330,
        "start": 4981.54,
        "temperature": 0,
        "text": " But it's still kind of performing rather poorly.",
        "tokens": [
          50776,
          583,
          309,
          311,
          920,
          733,
          295,
          10205,
          2831,
          22271,
          13,
          50908
        ]
      },
      {
        "avg_logprob": -0.20627057374413335,
        "compression_ratio": 1.7857142857142858,
        "end": 4987.42,
        "id": 1653,
        "no_speech_prob": 0.0003514366690069437,
        "seek": 497330,
        "start": 4984.18,
        "temperature": 0,
        "text": " One thing that I forgot to do is when I call",
        "tokens": [
          50908,
          1485,
          551,
          300,
          286,
          5298,
          281,
          360,
          307,
          562,
          286,
          818,
          51070
        ]
      },
      {
        "avg_logprob": -0.20627057374413335,
        "compression_ratio": 1.7857142857142858,
        "end": 4988.9800000000005,
        "id": 1654,
        "no_speech_prob": 0.0003514366690069437,
        "seek": 497330,
        "start": 4987.42,
        "temperature": 0,
        "text": " the fit function,",
        "tokens": [
          51070,
          264,
          3318,
          2445,
          11,
          51148
        ]
      },
      {
        "avg_logprob": -0.20627057374413335,
        "compression_ratio": 1.7857142857142858,
        "end": 4996.3,
        "id": 1655,
        "no_speech_prob": 0.0003514366690069437,
        "seek": 497330,
        "start": 4991.3,
        "temperature": 0,
        "text": " there are a set of options that I can pass in",
        "tokens": [
          51264,
          456,
          366,
          257,
          992,
          295,
          3956,
          300,
          286,
          393,
          1320,
          294,
          51514
        ]
      },
      {
        "avg_logprob": -0.20627057374413335,
        "compression_ratio": 1.7857142857142858,
        "end": 4998.38,
        "id": 1656,
        "no_speech_prob": 0.0003514366690069437,
        "seek": 497330,
        "start": 4996.38,
        "temperature": 0,
        "text": " for the number of epochs and all sorts of things.",
        "tokens": [
          51518,
          337,
          264,
          1230,
          295,
          30992,
          28346,
          293,
          439,
          7527,
          295,
          721,
          13,
          51618
        ]
      },
      {
        "avg_logprob": -0.20627057374413335,
        "compression_ratio": 1.7857142857142858,
        "end": 5000.54,
        "id": 1657,
        "no_speech_prob": 0.0003514366690069437,
        "seek": 497330,
        "start": 4998.38,
        "temperature": 0,
        "text": " But one of the ones that I really want to pass in here",
        "tokens": [
          51618,
          583,
          472,
          295,
          264,
          2306,
          300,
          286,
          534,
          528,
          281,
          1320,
          294,
          510,
          51726
        ]
      },
      {
        "avg_logprob": -0.20627057374413335,
        "compression_ratio": 1.7857142857142858,
        "end": 5002.06,
        "id": 1658,
        "no_speech_prob": 0.0003514366690069437,
        "seek": 497330,
        "start": 5000.54,
        "temperature": 0,
        "text": " is called shuffle.",
        "tokens": [
          51726,
          307,
          1219,
          39426,
          13,
          51802
        ]
      },
      {
        "avg_logprob": -0.22446372509002685,
        "compression_ratio": 1.5411764705882354,
        "end": 5004.5,
        "id": 1659,
        "no_speech_prob": 0.000012805460755771492,
        "seek": 500206,
        "start": 5002.06,
        "temperature": 0,
        "text": " Shuffle takes the training data",
        "tokens": [
          50364,
          1160,
          21665,
          2516,
          264,
          3097,
          1412,
          50486
        ]
      },
      {
        "avg_logprob": -0.22446372509002685,
        "compression_ratio": 1.5411764705882354,
        "end": 5006.740000000001,
        "id": 1660,
        "no_speech_prob": 0.000012805460755771492,
        "seek": 500206,
        "start": 5004.5,
        "temperature": 0,
        "text": " and it shuffles the order of it each time.",
        "tokens": [
          50486,
          293,
          309,
          402,
          1245,
          904,
          264,
          1668,
          295,
          309,
          1184,
          565,
          13,
          50598
        ]
      },
      {
        "avg_logprob": -0.22446372509002685,
        "compression_ratio": 1.5411764705882354,
        "end": 5009.860000000001,
        "id": 1661,
        "no_speech_prob": 0.000012805460755771492,
        "seek": 500206,
        "start": 5006.740000000001,
        "temperature": 0,
        "text": " Right now I'm training it with the same four data points",
        "tokens": [
          50598,
          1779,
          586,
          286,
          478,
          3097,
          309,
          365,
          264,
          912,
          1451,
          1412,
          2793,
          50754
        ]
      },
      {
        "avg_logprob": -0.22446372509002685,
        "compression_ratio": 1.5411764705882354,
        "end": 5011.18,
        "id": 1662,
        "no_speech_prob": 0.000012805460755771492,
        "seek": 500206,
        "start": 5009.860000000001,
        "temperature": 0,
        "text": " in the same order every time,",
        "tokens": [
          50754,
          294,
          264,
          912,
          1668,
          633,
          565,
          11,
          50820
        ]
      },
      {
        "avg_logprob": -0.22446372509002685,
        "compression_ratio": 1.5411764705882354,
        "end": 5012.9400000000005,
        "id": 1663,
        "no_speech_prob": 0.000012805460755771492,
        "seek": 500206,
        "start": 5011.18,
        "temperature": 0,
        "text": " which could be a bit of a problem.",
        "tokens": [
          50820,
          597,
          727,
          312,
          257,
          857,
          295,
          257,
          1154,
          13,
          50908
        ]
      },
      {
        "avg_logprob": -0.22446372509002685,
        "compression_ratio": 1.5411764705882354,
        "end": 5016.26,
        "id": 1664,
        "no_speech_prob": 0.000012805460755771492,
        "seek": 500206,
        "start": 5012.9400000000005,
        "temperature": 0,
        "text": " And, okay, so let me now,",
        "tokens": [
          50908,
          400,
          11,
          1392,
          11,
          370,
          718,
          385,
          586,
          11,
          51074
        ]
      },
      {
        "avg_logprob": -0.22446372509002685,
        "compression_ratio": 1.5411764705882354,
        "end": 5018.3,
        "id": 1665,
        "no_speech_prob": 0.000012805460755771492,
        "seek": 500206,
        "start": 5016.26,
        "temperature": 0,
        "text": " let me refresh here and run this again.",
        "tokens": [
          51074,
          718,
          385,
          15134,
          510,
          293,
          1190,
          341,
          797,
          13,
          51176
        ]
      },
      {
        "avg_logprob": -0.3693245854871026,
        "compression_ratio": 1.2333333333333334,
        "end": 5019.14,
        "id": 1666,
        "no_speech_prob": 0.0008040801621973515,
        "seek": 501830,
        "start": 5018.3,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          50364,
          1033,
          13,
          50406
        ]
      },
      {
        "avg_logprob": -0.3693245854871026,
        "compression_ratio": 1.2333333333333334,
        "end": 5032.54,
        "id": 1667,
        "no_speech_prob": 0.0008040801621973515,
        "seek": 501830,
        "start": 5030.38,
        "temperature": 0,
        "text": " Whoops, I can't see the frame rate because.",
        "tokens": [
          50968,
          45263,
          11,
          286,
          393,
          380,
          536,
          264,
          3920,
          3314,
          570,
          13,
          51076
        ]
      },
      {
        "avg_logprob": -0.3693245854871026,
        "compression_ratio": 1.2333333333333334,
        "end": 5036.3,
        "id": 1668,
        "no_speech_prob": 0.0008040801621973515,
        "seek": 501830,
        "start": 5035.46,
        "temperature": 0,
        "text": " Timeout a sec.",
        "tokens": [
          51222,
          6161,
          346,
          257,
          907,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.3693245854871026,
        "compression_ratio": 1.2333333333333334,
        "end": 5043.06,
        "id": 1669,
        "no_speech_prob": 0.0008040801621973515,
        "seek": 501830,
        "start": 5039.860000000001,
        "temperature": 0,
        "text": " Point five, optimizer, oh!",
        "tokens": [
          51442,
          12387,
          1732,
          11,
          5028,
          6545,
          11,
          1954,
          0,
          51602
        ]
      },
      {
        "avg_logprob": -0.3693245854871026,
        "compression_ratio": 1.2333333333333334,
        "end": 5045.820000000001,
        "id": 1670,
        "no_speech_prob": 0.0008040801621973515,
        "seek": 501830,
        "start": 5043.06,
        "temperature": 0,
        "text": " Optimizer, yeah, this is all the same.",
        "tokens": [
          51602,
          35013,
          6545,
          11,
          1338,
          11,
          341,
          307,
          439,
          264,
          912,
          13,
          51740
        ]
      },
      {
        "avg_logprob": -0.3693245854871026,
        "compression_ratio": 1.2333333333333334,
        "end": 5047.42,
        "id": 1671,
        "no_speech_prob": 0.0008040801621973515,
        "seek": 501830,
        "start": 5045.820000000001,
        "temperature": 0,
        "text": " Sigmoid, sigmoid.",
        "tokens": [
          51740,
          37763,
          3280,
          327,
          11,
          4556,
          3280,
          327,
          13,
          51820
        ]
      },
      {
        "avg_logprob": -0.30461859324621776,
        "compression_ratio": 1.2816901408450705,
        "end": 5050.7,
        "id": 1672,
        "no_speech_prob": 0.000003844930233753985,
        "seek": 504830,
        "start": 5049.3,
        "temperature": 0,
        "text": " Data.",
        "tokens": [
          50414,
          11888,
          13,
          50484
        ]
      },
      {
        "avg_logprob": -0.30461859324621776,
        "compression_ratio": 1.2816901408450705,
        "end": 5054.5,
        "id": 1673,
        "no_speech_prob": 0.000003844930233753985,
        "seek": 504830,
        "start": 5053.3,
        "temperature": 0,
        "text": " Train.",
        "tokens": [
          50614,
          28029,
          13,
          50674
        ]
      },
      {
        "avg_logprob": -0.30461859324621776,
        "compression_ratio": 1.2816901408450705,
        "end": 5057.3,
        "id": 1674,
        "no_speech_prob": 0.000003844930233753985,
        "seek": 504830,
        "start": 5054.5,
        "temperature": 0,
        "text": " Did I, am I giving it, oh, you know what I probably did.",
        "tokens": [
          50674,
          2589,
          286,
          11,
          669,
          286,
          2902,
          309,
          11,
          1954,
          11,
          291,
          458,
          437,
          286,
          1391,
          630,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.30461859324621776,
        "compression_ratio": 1.2816901408450705,
        "end": 5071.34,
        "id": 1675,
        "no_speech_prob": 0.000003844930233753985,
        "seek": 504830,
        "start": 5069.46,
        "temperature": 0,
        "text": " No, I thought maybe I was giving it more epochs",
        "tokens": [
          51422,
          883,
          11,
          286,
          1194,
          1310,
          286,
          390,
          2902,
          309,
          544,
          30992,
          28346,
          51516
        ]
      },
      {
        "avg_logprob": -0.30461859324621776,
        "compression_ratio": 1.2816901408450705,
        "end": 5072.860000000001,
        "id": 1676,
        "no_speech_prob": 0.000003844930233753985,
        "seek": 504830,
        "start": 5071.34,
        "temperature": 0,
        "text": " or something.",
        "tokens": [
          51516,
          420,
          746,
          13,
          51592
        ]
      },
      {
        "avg_logprob": -0.30461859324621776,
        "compression_ratio": 1.2816901408450705,
        "end": 5075.38,
        "id": 1677,
        "no_speech_prob": 0.000003844930233753985,
        "seek": 504830,
        "start": 5072.860000000001,
        "temperature": 0,
        "text": " Shuffle for XOR is not a big help, apparently not.",
        "tokens": [
          51592,
          1160,
          21665,
          337,
          1783,
          2483,
          307,
          406,
          257,
          955,
          854,
          11,
          7970,
          406,
          13,
          51718
        ]
      },
      {
        "avg_logprob": -0.49201785496303013,
        "compression_ratio": 1.1734693877551021,
        "end": 5083.3,
        "id": 1678,
        "no_speech_prob": 0.0000074112349466304295,
        "seek": 507830,
        "start": 5078.3,
        "temperature": 0,
        "text": " I don't think I'm curious I could do.",
        "tokens": [
          50364,
          286,
          500,
          380,
          519,
          286,
          478,
          6369,
          286,
          727,
          360,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.49201785496303013,
        "compression_ratio": 1.1734693877551021,
        "end": 5089.34,
        "id": 1679,
        "no_speech_prob": 0.0000074112349466304295,
        "seek": 507830,
        "start": 5088.1,
        "temperature": 0,
        "text": " Just out of curiosity.",
        "tokens": [
          50854,
          1449,
          484,
          295,
          18769,
          13,
          50916
        ]
      },
      {
        "avg_logprob": -0.49201785496303013,
        "compression_ratio": 1.1734693877551021,
        "end": 5102.54,
        "id": 1680,
        "no_speech_prob": 0.0000074112349466304295,
        "seek": 507830,
        "start": 5098.78,
        "temperature": 0,
        "text": " Because if I go to that thing I was showing everybody.",
        "tokens": [
          51388,
          1436,
          498,
          286,
          352,
          281,
          300,
          551,
          286,
          390,
          4099,
          2201,
          13,
          51576
        ]
      },
      {
        "avg_logprob": -0.5939906161764393,
        "compression_ratio": 0.921875,
        "end": 5109.14,
        "id": 1681,
        "no_speech_prob": 0.0005192823009565473,
        "seek": 510830,
        "start": 5108.3,
        "temperature": 0,
        "text": " Oh.",
        "tokens": [
          50364,
          876,
          13,
          50406
        ]
      },
      {
        "avg_logprob": -0.5939906161764393,
        "compression_ratio": 0.921875,
        "end": 5119.78,
        "id": 1682,
        "no_speech_prob": 0.0005192823009565473,
        "seek": 510830,
        "start": 5118.14,
        "temperature": 0,
        "text": " Where, this is.",
        "tokens": [
          50856,
          2305,
          11,
          341,
          307,
          13,
          50938
        ]
      },
      {
        "avg_logprob": -0.5939906161764393,
        "compression_ratio": 0.921875,
        "end": 5126.54,
        "id": 1683,
        "no_speech_prob": 0.0005192823009565473,
        "seek": 510830,
        "start": 5123.9800000000005,
        "temperature": 0,
        "text": " This should be hosted via GitHub Pages.",
        "tokens": [
          51148,
          639,
          820,
          312,
          19204,
          5766,
          23331,
          430,
          1660,
          13,
          51276
        ]
      },
      {
        "avg_logprob": -0.4262885093688965,
        "compression_ratio": 1.4518072289156627,
        "end": 5139.820000000001,
        "id": 1684,
        "no_speech_prob": 0.0002234152052551508,
        "seek": 513830,
        "start": 5138.820000000001,
        "temperature": 0,
        "text": " I'm not sure.",
        "tokens": [
          50390,
          286,
          478,
          406,
          988,
          13,
          50440
        ]
      },
      {
        "avg_logprob": -0.4262885093688965,
        "compression_ratio": 1.4518072289156627,
        "end": 5146.14,
        "id": 1685,
        "no_speech_prob": 0.0002234152052551508,
        "seek": 513830,
        "start": 5143.38,
        "temperature": 0,
        "text": " For loop and epochs will really help, yeah.",
        "tokens": [
          50618,
          1171,
          6367,
          293,
          30992,
          28346,
          486,
          534,
          854,
          11,
          1338,
          13,
          50756
        ]
      },
      {
        "avg_logprob": -0.4262885093688965,
        "compression_ratio": 1.4518072289156627,
        "end": 5149.26,
        "id": 1686,
        "no_speech_prob": 0.0002234152052551508,
        "seek": 513830,
        "start": 5146.14,
        "temperature": 0,
        "text": " I just wanted to see, I'm pretty sure,",
        "tokens": [
          50756,
          286,
          445,
          1415,
          281,
          536,
          11,
          286,
          478,
          1238,
          988,
          11,
          50912
        ]
      },
      {
        "avg_logprob": -0.4262885093688965,
        "compression_ratio": 1.4518072289156627,
        "end": 5151.06,
        "id": 1687,
        "no_speech_prob": 0.0002234152052551508,
        "seek": 513830,
        "start": 5149.26,
        "temperature": 0,
        "text": " I don't know why this isn't loading.",
        "tokens": [
          50912,
          286,
          500,
          380,
          458,
          983,
          341,
          1943,
          380,
          15114,
          13,
          51002
        ]
      },
      {
        "avg_logprob": -0.4262885093688965,
        "compression_ratio": 1.4518072289156627,
        "end": 5161.66,
        "id": 1688,
        "no_speech_prob": 0.0002234152052551508,
        "seek": 513830,
        "start": 5160.58,
        "temperature": 0,
        "text": " I mean, the other thing is,",
        "tokens": [
          51478,
          286,
          914,
          11,
          264,
          661,
          551,
          307,
          11,
          51532
        ]
      },
      {
        "avg_logprob": -0.4262885093688965,
        "compression_ratio": 1.4518072289156627,
        "end": 5163.5,
        "id": 1689,
        "no_speech_prob": 0.0002234152052551508,
        "seek": 513830,
        "start": 5161.66,
        "temperature": 0,
        "text": " I probably should create a separate,",
        "tokens": [
          51532,
          286,
          1391,
          820,
          1884,
          257,
          4994,
          11,
          51624
        ]
      },
      {
        "avg_logprob": -0.4262885093688965,
        "compression_ratio": 1.4518072289156627,
        "end": 5165.54,
        "id": 1690,
        "no_speech_prob": 0.0002234152052551508,
        "seek": 513830,
        "start": 5163.5,
        "temperature": 0,
        "text": " I mean, there's no such thing as a thread,",
        "tokens": [
          51624,
          286,
          914,
          11,
          456,
          311,
          572,
          1270,
          551,
          382,
          257,
          7207,
          11,
          51726
        ]
      },
      {
        "avg_logprob": -0.29578333634596604,
        "compression_ratio": 1.5732484076433122,
        "end": 5167.78,
        "id": 1691,
        "no_speech_prob": 0.0000066434276959626,
        "seek": 516554,
        "start": 5165.54,
        "temperature": 0,
        "text": " but I probably should have,",
        "tokens": [
          50364,
          457,
          286,
          1391,
          820,
          362,
          11,
          50476
        ]
      },
      {
        "avg_logprob": -0.29578333634596604,
        "compression_ratio": 1.5732484076433122,
        "end": 5172.0199999999995,
        "id": 1692,
        "no_speech_prob": 0.0000066434276959626,
        "seek": 516554,
        "start": 5170.18,
        "temperature": 0,
        "text": " I should just run the training,",
        "tokens": [
          50596,
          286,
          820,
          445,
          1190,
          264,
          3097,
          11,
          50688
        ]
      },
      {
        "avg_logprob": -0.29578333634596604,
        "compression_ratio": 1.5732484076433122,
        "end": 5175.38,
        "id": 1693,
        "no_speech_prob": 0.0000066434276959626,
        "seek": 516554,
        "start": 5172.0199999999995,
        "temperature": 0,
        "text": " like this async function I should just.",
        "tokens": [
          50688,
          411,
          341,
          382,
          34015,
          2445,
          286,
          820,
          445,
          13,
          50856
        ]
      },
      {
        "avg_logprob": -0.29578333634596604,
        "compression_ratio": 1.5732484076433122,
        "end": 5180.98,
        "id": 1694,
        "no_speech_prob": 0.0000066434276959626,
        "seek": 516554,
        "start": 5179.62,
        "temperature": 0,
        "text": " Like I don't need to,",
        "tokens": [
          51068,
          1743,
          286,
          500,
          380,
          643,
          281,
          11,
          51136
        ]
      },
      {
        "avg_logprob": -0.29578333634596604,
        "compression_ratio": 1.5732484076433122,
        "end": 5186.74,
        "id": 1695,
        "no_speech_prob": 0.0000066434276959626,
        "seek": 516554,
        "start": 5184.1,
        "temperature": 0,
        "text": " like I shouldn't be calling this in draw,",
        "tokens": [
          51292,
          411,
          286,
          4659,
          380,
          312,
          5141,
          341,
          294,
          2642,
          11,
          51424
        ]
      },
      {
        "avg_logprob": -0.29578333634596604,
        "compression_ratio": 1.5732484076433122,
        "end": 5188.42,
        "id": 1696,
        "no_speech_prob": 0.0000066434276959626,
        "seek": 516554,
        "start": 5186.74,
        "temperature": 0,
        "text": " but I just wanted to start doing that.",
        "tokens": [
          51424,
          457,
          286,
          445,
          1415,
          281,
          722,
          884,
          300,
          13,
          51508
        ]
      },
      {
        "avg_logprob": -0.29578333634596604,
        "compression_ratio": 1.5732484076433122,
        "end": 5190.06,
        "id": 1697,
        "no_speech_prob": 0.0000066434276959626,
        "seek": 516554,
        "start": 5188.42,
        "temperature": 0,
        "text": " I was gonna fix that later.",
        "tokens": [
          51508,
          286,
          390,
          799,
          3191,
          300,
          1780,
          13,
          51590
        ]
      },
      {
        "avg_logprob": -0.29578333634596604,
        "compression_ratio": 1.5732484076433122,
        "end": 5195.0199999999995,
        "id": 1698,
        "no_speech_prob": 0.0000066434276959626,
        "seek": 516554,
        "start": 5193.66,
        "temperature": 0,
        "text": " What time is it?",
        "tokens": [
          51770,
          708,
          565,
          307,
          309,
          30,
          51838
        ]
      },
      {
        "avg_logprob": -0.3657638468640916,
        "compression_ratio": 1.2522522522522523,
        "end": 5196.5,
        "id": 1699,
        "no_speech_prob": 0.00006605205999221653,
        "seek": 519502,
        "start": 5195.42,
        "temperature": 0,
        "text": " I have a half an hour.",
        "tokens": [
          50384,
          286,
          362,
          257,
          1922,
          364,
          1773,
          13,
          50438
        ]
      },
      {
        "avg_logprob": -0.3657638468640916,
        "compression_ratio": 1.2522522522522523,
        "end": 5198.820000000001,
        "id": 1700,
        "no_speech_prob": 0.00006605205999221653,
        "seek": 519502,
        "start": 5197.780000000001,
        "temperature": 0,
        "text": " And get through this.",
        "tokens": [
          50502,
          400,
          483,
          807,
          341,
          13,
          50554
        ]
      },
      {
        "avg_logprob": -0.3657638468640916,
        "compression_ratio": 1.2522522522522523,
        "end": 5208.780000000001,
        "id": 1701,
        "no_speech_prob": 0.00006605205999221653,
        "seek": 519502,
        "start": 5207.34,
        "temperature": 0,
        "text": " Whoops.",
        "tokens": [
          50980,
          45263,
          13,
          51052
        ]
      },
      {
        "avg_logprob": -0.3657638468640916,
        "compression_ratio": 1.2522522522522523,
        "end": 5210.02,
        "id": 1702,
        "no_speech_prob": 0.00006605205999221653,
        "seek": 519502,
        "start": 5208.780000000001,
        "temperature": 0,
        "text": " Why is this not loading?",
        "tokens": [
          51052,
          1545,
          307,
          341,
          406,
          15114,
          30,
          51114
        ]
      },
      {
        "avg_logprob": -0.3657638468640916,
        "compression_ratio": 1.2522522522522523,
        "end": 5214.820000000001,
        "id": 1703,
        "no_speech_prob": 0.00006605205999221653,
        "seek": 519502,
        "start": 5212.02,
        "temperature": 0,
        "text": " Oh, is it because, oh, it's probably because this is running.",
        "tokens": [
          51214,
          876,
          11,
          307,
          309,
          570,
          11,
          1954,
          11,
          309,
          311,
          1391,
          570,
          341,
          307,
          2614,
          13,
          51354
        ]
      },
      {
        "avg_logprob": -0.4063498780534074,
        "compression_ratio": 1.2058823529411764,
        "end": 5230.02,
        "id": 1704,
        "no_speech_prob": 0.00008349559357156977,
        "seek": 522502,
        "start": 5225.02,
        "temperature": 0,
        "text": " I don't know why my example,",
        "tokens": [
          50364,
          286,
          500,
          380,
          458,
          983,
          452,
          1365,
          11,
          50614
        ]
      },
      {
        "avg_logprob": -0.4063498780534074,
        "compression_ratio": 1.2058823529411764,
        "end": 5237.5,
        "id": 1705,
        "no_speech_prob": 0.00008349559357156977,
        "seek": 522502,
        "start": 5235.38,
        "temperature": 0,
        "text": " I wanted to just see the performance of my example.",
        "tokens": [
          50882,
          286,
          1415,
          281,
          445,
          536,
          264,
          3389,
          295,
          452,
          1365,
          13,
          50988
        ]
      },
      {
        "avg_logprob": -0.4063498780534074,
        "compression_ratio": 1.2058823529411764,
        "end": 5239.540000000001,
        "id": 1706,
        "no_speech_prob": 0.00008349559357156977,
        "seek": 522502,
        "start": 5237.5,
        "temperature": 0,
        "text": " Hold on, I think I need to restart Chrome.",
        "tokens": [
          50988,
          6962,
          322,
          11,
          286,
          519,
          286,
          643,
          281,
          21022,
          15327,
          13,
          51090
        ]
      },
      {
        "avg_logprob": -0.2426161580271535,
        "compression_ratio": 1.5063291139240507,
        "end": 5256.5,
        "id": 1707,
        "no_speech_prob": 0.000010129987458640244,
        "seek": 525502,
        "start": 5255.660000000001,
        "temperature": 0,
        "text": " Whoops.",
        "tokens": [
          50396,
          45263,
          13,
          50438
        ]
      },
      {
        "avg_logprob": -0.2426161580271535,
        "compression_ratio": 1.5063291139240507,
        "end": 5262.9400000000005,
        "id": 1708,
        "no_speech_prob": 0.000010129987458640244,
        "seek": 525502,
        "start": 5261.42,
        "temperature": 0,
        "text": " Why is this not working?",
        "tokens": [
          50684,
          1545,
          307,
          341,
          406,
          1364,
          30,
          50760
        ]
      },
      {
        "avg_logprob": -0.2426161580271535,
        "compression_ratio": 1.5063291139240507,
        "end": 5266.34,
        "id": 1709,
        "no_speech_prob": 0.000010129987458640244,
        "seek": 525502,
        "start": 5265.5,
        "temperature": 0,
        "text": " Here we go.",
        "tokens": [
          50888,
          1692,
          321,
          352,
          13,
          50930
        ]
      },
      {
        "avg_logprob": -0.2426161580271535,
        "compression_ratio": 1.5063291139240507,
        "end": 5272.42,
        "id": 1710,
        "no_speech_prob": 0.000010129987458640244,
        "seek": 525502,
        "start": 5270.900000000001,
        "temperature": 0,
        "text": " Yeah, I know I should do,",
        "tokens": [
          51158,
          865,
          11,
          286,
          458,
          286,
          820,
          360,
          11,
          51234
        ]
      },
      {
        "avg_logprob": -0.2426161580271535,
        "compression_ratio": 1.5063291139240507,
        "end": 5274.46,
        "id": 1711,
        "no_speech_prob": 0.000010129987458640244,
        "seek": 525502,
        "start": 5272.42,
        "temperature": 0,
        "text": " I was gonna do the set interval thing,",
        "tokens": [
          51234,
          286,
          390,
          799,
          360,
          264,
          992,
          15035,
          551,
          11,
          51336
        ]
      },
      {
        "avg_logprob": -0.2426161580271535,
        "compression_ratio": 1.5063291139240507,
        "end": 5277.3,
        "id": 1712,
        "no_speech_prob": 0.000010129987458640244,
        "seek": 525502,
        "start": 5275.38,
        "temperature": 0,
        "text": " but I actually wasn't gonna do set interval.",
        "tokens": [
          51382,
          457,
          286,
          767,
          2067,
          380,
          799,
          360,
          992,
          15035,
          13,
          51478
        ]
      },
      {
        "avg_logprob": -0.2426161580271535,
        "compression_ratio": 1.5063291139240507,
        "end": 5278.580000000001,
        "id": 1713,
        "no_speech_prob": 0.000010129987458640244,
        "seek": 525502,
        "start": 5277.3,
        "temperature": 0,
        "text": " I was gonna do set timeout",
        "tokens": [
          51478,
          286,
          390,
          799,
          360,
          992,
          565,
          346,
          51542
        ]
      },
      {
        "avg_logprob": -0.2426161580271535,
        "compression_ratio": 1.5063291139240507,
        "end": 5281.42,
        "id": 1714,
        "no_speech_prob": 0.000010129987458640244,
        "seek": 525502,
        "start": 5278.580000000001,
        "temperature": 0,
        "text": " and then have it recursively call itself when it's done.",
        "tokens": [
          51542,
          293,
          550,
          362,
          309,
          20560,
          3413,
          818,
          2564,
          562,
          309,
          311,
          1096,
          13,
          51684
        ]
      },
      {
        "avg_logprob": -0.2763033018007383,
        "compression_ratio": 1.4846938775510203,
        "end": 5285.74,
        "id": 1715,
        "no_speech_prob": 0.000007646534868399613,
        "seek": 528142,
        "start": 5282.42,
        "temperature": 0,
        "text": " I'm just, I got lost and this is not important.",
        "tokens": [
          50414,
          286,
          478,
          445,
          11,
          286,
          658,
          2731,
          293,
          341,
          307,
          406,
          1021,
          13,
          50580
        ]
      },
      {
        "avg_logprob": -0.2763033018007383,
        "compression_ratio": 1.4846938775510203,
        "end": 5287.58,
        "id": 1716,
        "no_speech_prob": 0.000007646534868399613,
        "seek": 528142,
        "start": 5285.74,
        "temperature": 0,
        "text": " I just thought I could run the thing that I made before",
        "tokens": [
          50580,
          286,
          445,
          1194,
          286,
          727,
          1190,
          264,
          551,
          300,
          286,
          1027,
          949,
          50672
        ]
      },
      {
        "avg_logprob": -0.2763033018007383,
        "compression_ratio": 1.4846938775510203,
        "end": 5289.02,
        "id": 1717,
        "no_speech_prob": 0.000007646534868399613,
        "seek": 528142,
        "start": 5287.58,
        "temperature": 0,
        "text": " just to see how it performed,",
        "tokens": [
          50672,
          445,
          281,
          536,
          577,
          309,
          10332,
          11,
          50744
        ]
      },
      {
        "avg_logprob": -0.2763033018007383,
        "compression_ratio": 1.4846938775510203,
        "end": 5292.02,
        "id": 1718,
        "no_speech_prob": 0.000007646534868399613,
        "seek": 528142,
        "start": 5290.02,
        "temperature": 0,
        "text": " but I don't know what it's stuck.",
        "tokens": [
          50794,
          457,
          286,
          500,
          380,
          458,
          437,
          309,
          311,
          5541,
          13,
          50894
        ]
      },
      {
        "avg_logprob": -0.2763033018007383,
        "compression_ratio": 1.4846938775510203,
        "end": 5294.82,
        "id": 1719,
        "no_speech_prob": 0.000007646534868399613,
        "seek": 528142,
        "start": 5292.02,
        "temperature": 0,
        "text": " Is anybody else, anybody else try running this example?",
        "tokens": [
          50894,
          1119,
          4472,
          1646,
          11,
          4472,
          1646,
          853,
          2614,
          341,
          1365,
          30,
          51034
        ]
      },
      {
        "avg_logprob": -0.2763033018007383,
        "compression_ratio": 1.4846938775510203,
        "end": 5299.1,
        "id": 1720,
        "no_speech_prob": 0.000007646534868399613,
        "seek": 528142,
        "start": 5296.66,
        "temperature": 0,
        "text": " Maybe I'll merge Eric's pull request.",
        "tokens": [
          51126,
          2704,
          286,
          603,
          22183,
          9336,
          311,
          2235,
          5308,
          13,
          51248
        ]
      },
      {
        "avg_logprob": -0.2763033018007383,
        "compression_ratio": 1.4846938775510203,
        "end": 5300.02,
        "id": 1721,
        "no_speech_prob": 0.000007646534868399613,
        "seek": 528142,
        "start": 5299.1,
        "temperature": 0,
        "text": " It's like stuck.",
        "tokens": [
          51248,
          467,
          311,
          411,
          5541,
          13,
          51294
        ]
      },
      {
        "avg_logprob": -0.2763033018007383,
        "compression_ratio": 1.4846938775510203,
        "end": 5302.82,
        "id": 1722,
        "no_speech_prob": 0.000007646534868399613,
        "seek": 528142,
        "start": 5301.62,
        "temperature": 0,
        "text": " Weird.",
        "tokens": [
          51374,
          32033,
          13,
          51434
        ]
      },
      {
        "avg_logprob": -0.2763033018007383,
        "compression_ratio": 1.4846938775510203,
        "end": 5303.66,
        "id": 1723,
        "no_speech_prob": 0.000007646534868399613,
        "seek": 528142,
        "start": 5302.82,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          51434,
          1033,
          13,
          51476
        ]
      },
      {
        "avg_logprob": -0.3917915170842951,
        "compression_ratio": 1.3409090909090908,
        "end": 5304.5,
        "id": 1724,
        "no_speech_prob": 0.000005014731414121343,
        "seek": 530366,
        "start": 5303.66,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          50364,
          1033,
          13,
          50406
        ]
      },
      {
        "avg_logprob": -0.3917915170842951,
        "compression_ratio": 1.3409090909090908,
        "end": 5312.22,
        "id": 1725,
        "no_speech_prob": 0.000005014731414121343,
        "seek": 530366,
        "start": 5308.38,
        "temperature": 0,
        "text": " Yeah, that's what I wanted to do next frame.",
        "tokens": [
          50600,
          865,
          11,
          300,
          311,
          437,
          286,
          1415,
          281,
          360,
          958,
          3920,
          13,
          50792
        ]
      },
      {
        "avg_logprob": -0.3917915170842951,
        "compression_ratio": 1.3409090909090908,
        "end": 5318.82,
        "id": 1726,
        "no_speech_prob": 0.000005014731414121343,
        "seek": 530366,
        "start": 5314.0199999999995,
        "temperature": 0,
        "text": " So, me, I am, so me, let me come back to that.",
        "tokens": [
          50882,
          407,
          11,
          385,
          11,
          286,
          669,
          11,
          370,
          385,
          11,
          718,
          385,
          808,
          646,
          281,
          300,
          13,
          51122
        ]
      },
      {
        "avg_logprob": -0.3917915170842951,
        "compression_ratio": 1.3409090909090908,
        "end": 5322.26,
        "id": 1727,
        "no_speech_prob": 0.000005014731414121343,
        "seek": 530366,
        "start": 5318.82,
        "temperature": 0,
        "text": " I didn't wanna do that first, but yeah,",
        "tokens": [
          51122,
          286,
          994,
          380,
          1948,
          360,
          300,
          700,
          11,
          457,
          1338,
          11,
          51294
        ]
      },
      {
        "avg_logprob": -0.3917915170842951,
        "compression_ratio": 1.3409090909090908,
        "end": 5328.7,
        "id": 1728,
        "no_speech_prob": 0.000005014731414121343,
        "seek": 530366,
        "start": 5327.46,
        "temperature": 0,
        "text": " but thank you for that.",
        "tokens": [
          51554,
          457,
          1309,
          291,
          337,
          300,
          13,
          51616
        ]
      },
      {
        "avg_logprob": -0.3917915170842951,
        "compression_ratio": 1.3409090909090908,
        "end": 5330.0599999999995,
        "id": 1729,
        "no_speech_prob": 0.000005014731414121343,
        "seek": 530366,
        "start": 5328.7,
        "temperature": 0,
        "text": " Oh my goodness.",
        "tokens": [
          51616,
          876,
          452,
          8387,
          13,
          51684
        ]
      },
      {
        "avg_logprob": -0.5094319449530708,
        "compression_ratio": 1.2903225806451613,
        "end": 5332.54,
        "id": 1730,
        "no_speech_prob": 0.00006302755355136469,
        "seek": 533006,
        "start": 5330.38,
        "temperature": 0,
        "text": " I forgot to tidy everything.",
        "tokens": [
          50380,
          286,
          5298,
          281,
          34646,
          1203,
          13,
          50488
        ]
      },
      {
        "avg_logprob": -0.5094319449530708,
        "compression_ratio": 1.2903225806451613,
        "end": 5336.54,
        "id": 1731,
        "no_speech_prob": 0.00006302755355136469,
        "seek": 533006,
        "start": 5332.54,
        "temperature": 0,
        "text": " Oh, well, but yeah, the why's I need to dispose",
        "tokens": [
          50488,
          876,
          11,
          731,
          11,
          457,
          1338,
          11,
          264,
          983,
          311,
          286,
          643,
          281,
          42537,
          50688
        ]
      },
      {
        "avg_logprob": -0.5094319449530708,
        "compression_ratio": 1.2903225806451613,
        "end": 5341.18,
        "id": 1732,
        "no_speech_prob": 0.00006302755355136469,
        "seek": 533006,
        "start": 5337.9400000000005,
        "temperature": 0,
        "text": " and I also need to tidy this.",
        "tokens": [
          50758,
          293,
          286,
          611,
          643,
          281,
          34646,
          341,
          13,
          50920
        ]
      },
      {
        "avg_logprob": -0.5094319449530708,
        "compression_ratio": 1.2903225806451613,
        "end": 5342.02,
        "id": 1733,
        "no_speech_prob": 0.00006302755355136469,
        "seek": 533006,
        "start": 5341.18,
        "temperature": 0,
        "text": " Oh yeah.",
        "tokens": [
          50920,
          876,
          1338,
          13,
          50962
        ]
      },
      {
        "avg_logprob": -0.5094319449530708,
        "compression_ratio": 1.2903225806451613,
        "end": 5346.06,
        "id": 1734,
        "no_speech_prob": 0.00006302755355136469,
        "seek": 533006,
        "start": 5343.860000000001,
        "temperature": 0,
        "text": " Let me at least just go back to where I was.",
        "tokens": [
          51054,
          961,
          385,
          412,
          1935,
          445,
          352,
          646,
          281,
          689,
          286,
          390,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.5356672286987305,
        "compression_ratio": 1.2416666666666667,
        "end": 5363.06,
        "id": 1735,
        "no_speech_prob": 0.000005771912583441008,
        "seek": 536006,
        "start": 5360.06,
        "temperature": 0,
        "text": " I'm gonna let this go for a little bit.",
        "tokens": [
          50364,
          286,
          478,
          799,
          718,
          341,
          352,
          337,
          257,
          707,
          857,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.5356672286987305,
        "compression_ratio": 1.2416666666666667,
        "end": 5363.900000000001,
        "id": 1736,
        "no_speech_prob": 0.000005771912583441008,
        "seek": 536006,
        "start": 5363.06,
        "temperature": 0,
        "text": " Just wanna,",
        "tokens": [
          50514,
          1449,
          1948,
          11,
          50556
        ]
      },
      {
        "avg_logprob": -0.5356672286987305,
        "compression_ratio": 1.2416666666666667,
        "end": 5374.3,
        "id": 1737,
        "no_speech_prob": 0.000005771912583441008,
        "seek": 536006,
        "start": 5373.06,
        "temperature": 0,
        "text": " did anybody see what that was?",
        "tokens": [
          51014,
          630,
          4472,
          536,
          437,
          300,
          390,
          30,
          51076
        ]
      },
      {
        "avg_logprob": -0.5356672286987305,
        "compression_ratio": 1.2416666666666667,
        "end": 5378.14,
        "id": 1738,
        "no_speech_prob": 0.000005771912583441008,
        "seek": 536006,
        "start": 5377.3,
        "temperature": 0,
        "text": " There it is.",
        "tokens": [
          51226,
          821,
          309,
          307,
          13,
          51268
        ]
      },
      {
        "avg_logprob": -0.5356672286987305,
        "compression_ratio": 1.2416666666666667,
        "end": 5378.9800000000005,
        "id": 1739,
        "no_speech_prob": 0.000005771912583441008,
        "seek": 536006,
        "start": 5378.14,
        "temperature": 0,
        "text": " Where is it?",
        "tokens": [
          51268,
          2305,
          307,
          309,
          30,
          51310
        ]
      },
      {
        "avg_logprob": -0.5356672286987305,
        "compression_ratio": 1.2416666666666667,
        "end": 5382.700000000001,
        "id": 1740,
        "no_speech_prob": 0.000005771912583441008,
        "seek": 536006,
        "start": 5381.860000000001,
        "temperature": 0,
        "text": " Yeah, look at that.",
        "tokens": [
          51454,
          865,
          11,
          574,
          412,
          300,
          13,
          51496
        ]
      },
      {
        "avg_logprob": -0.5356672286987305,
        "compression_ratio": 1.2416666666666667,
        "end": 5383.54,
        "id": 1741,
        "no_speech_prob": 0.000005771912583441008,
        "seek": 536006,
        "start": 5382.700000000001,
        "temperature": 0,
        "text": " That's a mess.",
        "tokens": [
          51496,
          663,
          311,
          257,
          2082,
          13,
          51538
        ]
      },
      {
        "avg_logprob": -0.5356672286987305,
        "compression_ratio": 1.2416666666666667,
        "end": 5384.38,
        "id": 1742,
        "no_speech_prob": 0.000005771912583441008,
        "seek": 536006,
        "start": 5383.54,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          51538,
          1033,
          13,
          51580
        ]
      },
      {
        "avg_logprob": -2.1862370225249745,
        "compression_ratio": 1.7248677248677249,
        "end": 5385.900000000001,
        "id": 1743,
        "no_speech_prob": 0.000041335351852467284,
        "seek": 538438,
        "start": 5385.06,
        "temperature": 1,
        "text": " Okay.",
        "tokens": [
          50398,
          1033,
          13,
          50440
        ]
      },
      {
        "avg_logprob": -2.1862370225249745,
        "compression_ratio": 1.7248677248677249,
        "end": 5394.2,
        "id": 1744,
        "no_speech_prob": 0.000041335351852467284,
        "seek": 538438,
        "start": 5391.900000000001,
        "temperature": 1,
        "text": " All right, so things are still working,",
        "tokens": [
          50740,
          1057,
          558,
          11,
          370,
          721,
          366,
          920,
          1364,
          11,
          50855
        ]
      },
      {
        "avg_logprob": -2.1862370225249745,
        "compression_ratio": 1.7248677248677249,
        "end": 5395.3,
        "id": 1745,
        "no_speech_prob": 0.000041335351852467284,
        "seek": 538438,
        "start": 5394.2,
        "temperature": 1,
        "text": " but it's still running kind of slow.",
        "tokens": [
          50855,
          758,
          83,
          309,
          311,
          920,
          2614,
          733,
          295,
          2964,
          13,
          50910
        ]
      },
      {
        "avg_logprob": -2.1862370225249745,
        "compression_ratio": 1.7248677248677249,
        "end": 5397.78,
        "id": 1746,
        "no_speech_prob": 0.000041335351852467284,
        "seek": 538438,
        "start": 5395.3,
        "temperature": 1,
        "text": " We can see I'm getting the loss down.",
        "tokens": [
          50910,
          492,
          393,
          536,
          286,
          478,
          1242,
          264,
          4470,
          760,
          13,
          51034
        ]
      },
      {
        "avg_logprob": -2.1862370225249745,
        "compression_ratio": 1.7248677248677249,
        "end": 5399.4400000000005,
        "id": 1747,
        "no_speech_prob": 0.000041335351852467284,
        "seek": 538438,
        "start": 5397.78,
        "temperature": 1,
        "text": " Hold on.",
        "tokens": [
          51034,
          6962,
          322,
          13,
          51117
        ]
      },
      {
        "avg_logprob": -2.1862370225249745,
        "compression_ratio": 1.7248677248677249,
        "end": 5401,
        "id": 1748,
        "no_speech_prob": 0.000041335351852467284,
        "seek": 538438,
        "start": 5399.4400000000005,
        "temperature": 1,
        "text": " Let me see.",
        "tokens": [
          51117,
          961,
          385,
          536,
          13,
          51195
        ]
      },
      {
        "avg_logprob": -2.1862370225249745,
        "compression_ratio": 1.7248677248677249,
        "end": 5402.9800000000005,
        "id": 1749,
        "no_speech_prob": 0.000041335351852467284,
        "seek": 538438,
        "start": 5401,
        "temperature": 1,
        "text": " Okay, things are still lose.",
        "tokens": [
          51195,
          3477,
          320,
          11,
          721,
          366,
          920,
          1750,
          68,
          13,
          51294
        ]
      },
      {
        "avg_logprob": -2.1862370225249745,
        "compression_ratio": 1.7248677248677249,
        "end": 5406.66,
        "id": 1750,
        "no_speech_prob": 0.000041335351852467284,
        "seek": 538438,
        "start": 5404.58,
        "temperature": 1,
        "text": " Okay, this is not working.",
        "tokens": [
          51374,
          1033,
          11,
          341,
          307,
          406,
          1364,
          13,
          51478
        ]
      },
      {
        "avg_logprob": -2.1862370225249745,
        "compression_ratio": 1.7248677248677249,
        "end": 5408.02,
        "id": 1751,
        "no_speech_prob": 0.000041335351852467284,
        "seek": 538438,
        "start": 5406.66,
        "temperature": 1,
        "text": " This can be happening.",
        "tokens": [
          51478,
          639,
          393,
          312,
          2737,
          13,
          51546
        ]
      },
      {
        "avg_logprob": -2.1862370225249745,
        "compression_ratio": 1.7248677248677249,
        "end": 5408.04,
        "id": 1752,
        "no_speech_prob": 0.000041335351852467284,
        "seek": 538438,
        "start": 5408.02,
        "temperature": 1,
        "text": " It's not working.",
        "tokens": [
          51546,
          467,
          311,
          572,
          83,
          1364,
          13,
          51547
        ]
      },
      {
        "avg_logprob": -2.1862370225249745,
        "compression_ratio": 1.7248677248677249,
        "end": 5409.68,
        "id": 1753,
        "no_speech_prob": 0.000041335351852467284,
        "seek": 538438,
        "start": 5408.62,
        "temperature": 1,
        "text": " This can be happening.",
        "tokens": [
          51576,
          639,
          393,
          312,
          2737,
          13,
          51629
        ]
      },
      {
        "avg_logprob": -2.1862370225249745,
        "compression_ratio": 1.7248677248677249,
        "end": 5411.72,
        "id": 1754,
        "no_speech_prob": 0.000041335351852467284,
        "seek": 538438,
        "start": 5409.68,
        "temperature": 1,
        "text": " And I can appraiseWhitesail.",
        "tokens": [
          51629,
          400,
          286,
          393,
          724,
          424,
          908,
          2471,
          3324,
          864,
          13,
          51731
        ]
      },
      {
        "avg_logprob": -2.1862370225249745,
        "compression_ratio": 1.7248677248677249,
        "end": 5414,
        "id": 1755,
        "no_speech_prob": 0.000041335351852467284,
        "seek": 538438,
        "start": 5411.72,
        "temperature": 1,
        "text": " I'm a referee, I get no red rattle.",
        "tokens": [
          51731,
          286,
          478,
          257,
          1895,
          323,
          68,
          11,
          286,
          483,
          572,
          2182,
          367,
          3327,
          13,
          51845
        ]
      },
      {
        "avg_logprob": -0.270973629421658,
        "compression_ratio": 1.704968944099379,
        "end": 5414.86,
        "id": 1756,
        "no_speech_prob": 0.00030534807592630386,
        "seek": 541400,
        "start": 5414,
        "temperature": 0,
        "text": " Okay, things are working.",
        "tokens": [
          50364,
          1033,
          11,
          721,
          366,
          1364,
          13,
          50407
        ]
      },
      {
        "avg_logprob": -0.270973629421658,
        "compression_ratio": 1.704968944099379,
        "end": 5417.14,
        "id": 1757,
        "no_speech_prob": 0.00030534807592630386,
        "seek": 541400,
        "start": 5414.86,
        "temperature": 0,
        "text": " It's kind of getting close to the right result.",
        "tokens": [
          50407,
          467,
          311,
          733,
          295,
          1242,
          1998,
          281,
          264,
          558,
          1874,
          13,
          50521
        ]
      },
      {
        "avg_logprob": -0.270973629421658,
        "compression_ratio": 1.704968944099379,
        "end": 5418.74,
        "id": 1758,
        "no_speech_prob": 0.00030534807592630386,
        "seek": 541400,
        "start": 5417.14,
        "temperature": 0,
        "text": " You can see the loss is going down.",
        "tokens": [
          50521,
          509,
          393,
          536,
          264,
          4470,
          307,
          516,
          760,
          13,
          50601
        ]
      },
      {
        "avg_logprob": -0.270973629421658,
        "compression_ratio": 1.704968944099379,
        "end": 5420.94,
        "id": 1759,
        "no_speech_prob": 0.00030534807592630386,
        "seek": 541400,
        "start": 5418.74,
        "temperature": 0,
        "text": " I've realized, thanks to the chat, of course,",
        "tokens": [
          50601,
          286,
          600,
          5334,
          11,
          3231,
          281,
          264,
          5081,
          11,
          295,
          1164,
          11,
          50711
        ]
      },
      {
        "avg_logprob": -0.270973629421658,
        "compression_ratio": 1.704968944099379,
        "end": 5423.18,
        "id": 1760,
        "no_speech_prob": 0.00030534807592630386,
        "seek": 541400,
        "start": 5420.94,
        "temperature": 0,
        "text": " that I forgot something really important.",
        "tokens": [
          50711,
          300,
          286,
          5298,
          746,
          534,
          1021,
          13,
          50823
        ]
      },
      {
        "avg_logprob": -0.270973629421658,
        "compression_ratio": 1.704968944099379,
        "end": 5424.92,
        "id": 1761,
        "no_speech_prob": 0.00030534807592630386,
        "seek": 541400,
        "start": 5423.18,
        "temperature": 0,
        "text": " I want to try to make it learn faster,",
        "tokens": [
          50823,
          286,
          528,
          281,
          853,
          281,
          652,
          309,
          1466,
          4663,
          11,
          50910
        ]
      },
      {
        "avg_logprob": -0.270973629421658,
        "compression_ratio": 1.704968944099379,
        "end": 5426.26,
        "id": 1762,
        "no_speech_prob": 0.00030534807592630386,
        "seek": 541400,
        "start": 5424.92,
        "temperature": 0,
        "text": " which I will kind of get to,",
        "tokens": [
          50910,
          597,
          286,
          486,
          733,
          295,
          483,
          281,
          11,
          50977
        ]
      },
      {
        "avg_logprob": -0.270973629421658,
        "compression_ratio": 1.704968944099379,
        "end": 5428.56,
        "id": 1763,
        "no_speech_prob": 0.00030534807592630386,
        "seek": 541400,
        "start": 5426.26,
        "temperature": 0,
        "text": " and I want to think about the sort of asynchronous nature",
        "tokens": [
          50977,
          293,
          286,
          528,
          281,
          519,
          466,
          264,
          1333,
          295,
          49174,
          3687,
          51092
        ]
      },
      {
        "avg_logprob": -0.270973629421658,
        "compression_ratio": 1.704968944099379,
        "end": 5430.18,
        "id": 1764,
        "no_speech_prob": 0.00030534807592630386,
        "seek": 541400,
        "start": 5428.56,
        "temperature": 0,
        "text": " of using p5's draw loop",
        "tokens": [
          51092,
          295,
          1228,
          280,
          20,
          311,
          2642,
          6367,
          51173
        ]
      },
      {
        "avg_logprob": -0.270973629421658,
        "compression_ratio": 1.704968944099379,
        "end": 5433.26,
        "id": 1765,
        "no_speech_prob": 0.00030534807592630386,
        "seek": 541400,
        "start": 5430.18,
        "temperature": 0,
        "text": " and using the model.fit at the same time.",
        "tokens": [
          51173,
          293,
          1228,
          264,
          2316,
          13,
          6845,
          412,
          264,
          912,
          565,
          13,
          51327
        ]
      },
      {
        "avg_logprob": -0.270973629421658,
        "compression_ratio": 1.704968944099379,
        "end": 5434.74,
        "id": 1766,
        "no_speech_prob": 0.00030534807592630386,
        "seek": 541400,
        "start": 5433.26,
        "temperature": 0,
        "text": " But before I do any of that,",
        "tokens": [
          51327,
          583,
          949,
          286,
          360,
          604,
          295,
          300,
          11,
          51401
        ]
      },
      {
        "avg_logprob": -0.270973629421658,
        "compression_ratio": 1.704968944099379,
        "end": 5436.16,
        "id": 1767,
        "no_speech_prob": 0.00030534807592630386,
        "seek": 541400,
        "start": 5434.74,
        "temperature": 0,
        "text": " I just realized I haven't thought",
        "tokens": [
          51401,
          286,
          445,
          5334,
          286,
          2378,
          380,
          1194,
          51472
        ]
      },
      {
        "avg_logprob": -0.270973629421658,
        "compression_ratio": 1.704968944099379,
        "end": 5438.22,
        "id": 1768,
        "no_speech_prob": 0.00030534807592630386,
        "seek": 541400,
        "start": 5436.16,
        "temperature": 0,
        "text": " about memory management at all.",
        "tokens": [
          51472,
          466,
          4675,
          4592,
          412,
          439,
          13,
          51575
        ]
      },
      {
        "avg_logprob": -0.270973629421658,
        "compression_ratio": 1.704968944099379,
        "end": 5439.38,
        "id": 1769,
        "no_speech_prob": 0.00030534807592630386,
        "seek": 541400,
        "start": 5438.22,
        "temperature": 0,
        "text": " And there's a big problem.",
        "tokens": [
          51575,
          400,
          456,
          311,
          257,
          955,
          1154,
          13,
          51633
        ]
      },
      {
        "avg_logprob": -0.270973629421658,
        "compression_ratio": 1.704968944099379,
        "end": 5441.98,
        "id": 1770,
        "no_speech_prob": 0.00030534807592630386,
        "seek": 541400,
        "start": 5439.38,
        "temperature": 0,
        "text": " If I just take out for a second this,",
        "tokens": [
          51633,
          759,
          286,
          445,
          747,
          484,
          337,
          257,
          1150,
          341,
          11,
          51763
        ]
      },
      {
        "avg_logprob": -0.3047475108393916,
        "compression_ratio": 1.50253807106599,
        "end": 5445,
        "id": 1771,
        "no_speech_prob": 0.000024682847652002238,
        "seek": 544198,
        "start": 5442.799999999999,
        "temperature": 0,
        "text": " and let me do this here.",
        "tokens": [
          50405,
          293,
          718,
          385,
          360,
          341,
          510,
          13,
          50515
        ]
      },
      {
        "avg_logprob": -0.3047475108393916,
        "compression_ratio": 1.50253807106599,
        "end": 5449.48,
        "id": 1772,
        "no_speech_prob": 0.000024682847652002238,
        "seek": 544198,
        "start": 5447.32,
        "temperature": 0,
        "text": " Take out this console.log,",
        "tokens": [
          50631,
          3664,
          484,
          341,
          11076,
          13,
          4987,
          11,
          50739
        ]
      },
      {
        "avg_logprob": -0.3047475108393916,
        "compression_ratio": 1.50253807106599,
        "end": 5452.879999999999,
        "id": 1773,
        "no_speech_prob": 0.000024682847652002238,
        "seek": 544198,
        "start": 5450.799999999999,
        "temperature": 0,
        "text": " and I run this again,",
        "tokens": [
          50805,
          293,
          286,
          1190,
          341,
          797,
          11,
          50909
        ]
      },
      {
        "avg_logprob": -0.3047475108393916,
        "compression_ratio": 1.50253807106599,
        "end": 5456.759999999999,
        "id": 1774,
        "no_speech_prob": 0.000024682847652002238,
        "seek": 544198,
        "start": 5452.879999999999,
        "temperature": 0,
        "text": " and I look at, say, if I say in the, oops.",
        "tokens": [
          50909,
          293,
          286,
          574,
          412,
          11,
          584,
          11,
          498,
          286,
          584,
          294,
          264,
          11,
          34166,
          13,
          51103
        ]
      },
      {
        "avg_logprob": -0.3047475108393916,
        "compression_ratio": 1.50253807106599,
        "end": 5458.36,
        "id": 1775,
        "no_speech_prob": 0.000024682847652002238,
        "seek": 544198,
        "start": 5456.759999999999,
        "temperature": 0,
        "text": " Yeah, I'm like killing my computer.",
        "tokens": [
          51103,
          865,
          11,
          286,
          478,
          411,
          8011,
          452,
          3820,
          13,
          51183
        ]
      },
      {
        "avg_logprob": -0.3047475108393916,
        "compression_ratio": 1.50253807106599,
        "end": 5459.839999999999,
        "id": 1776,
        "no_speech_prob": 0.000024682847652002238,
        "seek": 544198,
        "start": 5458.36,
        "temperature": 0,
        "text": " It can barely run it again,",
        "tokens": [
          51183,
          467,
          393,
          10268,
          1190,
          309,
          797,
          11,
          51257
        ]
      },
      {
        "avg_logprob": -0.3047475108393916,
        "compression_ratio": 1.50253807106599,
        "end": 5464.839999999999,
        "id": 1777,
        "no_speech_prob": 0.000024682847652002238,
        "seek": 544198,
        "start": 5459.839999999999,
        "temperature": 0,
        "text": " because watch what tf memory num tensors.",
        "tokens": [
          51257,
          570,
          1159,
          437,
          256,
          69,
          4675,
          1031,
          10688,
          830,
          13,
          51507
        ]
      },
      {
        "avg_logprob": -0.3047475108393916,
        "compression_ratio": 1.50253807106599,
        "end": 5469,
        "id": 1778,
        "no_speech_prob": 0.000024682847652002238,
        "seek": 544198,
        "start": 5465.919999999999,
        "temperature": 0,
        "text": " 3,455, 4,479.",
        "tokens": [
          51561,
          805,
          11,
          8465,
          20,
          11,
          1017,
          11,
          14060,
          24,
          13,
          51715
        ]
      },
      {
        "avg_logprob": -0.3047475108393916,
        "compression_ratio": 1.50253807106599,
        "end": 5470.16,
        "id": 1779,
        "no_speech_prob": 0.000024682847652002238,
        "seek": 544198,
        "start": 5469,
        "temperature": 0,
        "text": " I'm just generating tensors.",
        "tokens": [
          51715,
          286,
          478,
          445,
          17746,
          10688,
          830,
          13,
          51773
        ]
      },
      {
        "avg_logprob": -0.3047475108393916,
        "compression_ratio": 1.50253807106599,
        "end": 5471.48,
        "id": 1780,
        "no_speech_prob": 0.000024682847652002238,
        "seek": 544198,
        "start": 5470.16,
        "temperature": 0,
        "text": " I'm filling up all the memory.",
        "tokens": [
          51773,
          286,
          478,
          10623,
          493,
          439,
          264,
          4675,
          13,
          51839
        ]
      },
      {
        "avg_logprob": -0.2302490504442063,
        "compression_ratio": 1.5570175438596492,
        "end": 5473.959999999999,
        "id": 1781,
        "no_speech_prob": 0.000022474085199064575,
        "seek": 547148,
        "start": 5471.98,
        "temperature": 0,
        "text": " Performance on this is going to be a disaster.",
        "tokens": [
          50389,
          25047,
          322,
          341,
          307,
          516,
          281,
          312,
          257,
          11293,
          13,
          50488
        ]
      },
      {
        "avg_logprob": -0.2302490504442063,
        "compression_ratio": 1.5570175438596492,
        "end": 5476.74,
        "id": 1782,
        "no_speech_prob": 0.000022474085199064575,
        "seek": 547148,
        "start": 5473.959999999999,
        "temperature": 0,
        "text": " So let me stop it before it gets too bad,",
        "tokens": [
          50488,
          407,
          718,
          385,
          1590,
          309,
          949,
          309,
          2170,
          886,
          1578,
          11,
          50627
        ]
      },
      {
        "avg_logprob": -0.2302490504442063,
        "compression_ratio": 1.5570175438596492,
        "end": 5479.339999999999,
        "id": 1783,
        "no_speech_prob": 0.000022474085199064575,
        "seek": 547148,
        "start": 5476.74,
        "temperature": 0,
        "text": " and let's see, where do I need to do some cleanup?",
        "tokens": [
          50627,
          293,
          718,
          311,
          536,
          11,
          689,
          360,
          286,
          643,
          281,
          360,
          512,
          40991,
          30,
          50757
        ]
      },
      {
        "avg_logprob": -0.2302490504442063,
        "compression_ratio": 1.5570175438596492,
        "end": 5482.9,
        "id": 1784,
        "no_speech_prob": 0.000022474085199064575,
        "seek": 547148,
        "start": 5479.339999999999,
        "temperature": 0,
        "text": " So these x's, these training tensors,",
        "tokens": [
          50757,
          407,
          613,
          2031,
          311,
          11,
          613,
          3097,
          10688,
          830,
          11,
          50935
        ]
      },
      {
        "avg_logprob": -0.2302490504442063,
        "compression_ratio": 1.5570175438596492,
        "end": 5484.82,
        "id": 1785,
        "no_speech_prob": 0.000022474085199064575,
        "seek": 547148,
        "start": 5482.9,
        "temperature": 0,
        "text": " I never need to clean those up.",
        "tokens": [
          50935,
          286,
          1128,
          643,
          281,
          2541,
          729,
          493,
          13,
          51031
        ]
      },
      {
        "avg_logprob": -0.2302490504442063,
        "compression_ratio": 1.5570175438596492,
        "end": 5487.139999999999,
        "id": 1786,
        "no_speech_prob": 0.000022474085199064575,
        "seek": 547148,
        "start": 5484.82,
        "temperature": 0,
        "text": " Those I can keep forever.",
        "tokens": [
          51031,
          3950,
          286,
          393,
          1066,
          5680,
          13,
          51147
        ]
      },
      {
        "avg_logprob": -0.2302490504442063,
        "compression_ratio": 1.5570175438596492,
        "end": 5491.48,
        "id": 1787,
        "no_speech_prob": 0.000022474085199064575,
        "seek": 547148,
        "start": 5488.66,
        "temperature": 0,
        "text": " But in train model,",
        "tokens": [
          51223,
          583,
          294,
          3847,
          2316,
          11,
          51364
        ]
      },
      {
        "avg_logprob": -0.2302490504442063,
        "compression_ratio": 1.5570175438596492,
        "end": 5496.36,
        "id": 1788,
        "no_speech_prob": 0.000022474085199064575,
        "seek": 547148,
        "start": 5491.48,
        "temperature": 0,
        "text": " I should probably tf.tidy this whole thing.",
        "tokens": [
          51364,
          286,
          820,
          1391,
          256,
          69,
          13,
          83,
          38836,
          341,
          1379,
          551,
          13,
          51608
        ]
      },
      {
        "avg_logprob": -0.2302490504442063,
        "compression_ratio": 1.5570175438596492,
        "end": 5497.2,
        "id": 1789,
        "no_speech_prob": 0.000022474085199064575,
        "seek": 547148,
        "start": 5496.36,
        "temperature": 0,
        "text": " Let me think about that.",
        "tokens": [
          51608,
          961,
          385,
          519,
          466,
          300,
          13,
          51650
        ]
      },
      {
        "avg_logprob": -0.2302490504442063,
        "compression_ratio": 1.5570175438596492,
        "end": 5499.9,
        "id": 1790,
        "no_speech_prob": 0.000022474085199064575,
        "seek": 547148,
        "start": 5497.2,
        "temperature": 0,
        "text": " Let's first actually, the y's,",
        "tokens": [
          51650,
          961,
          311,
          700,
          767,
          11,
          264,
          288,
          311,
          11,
          51785
        ]
      },
      {
        "avg_logprob": -0.2482874007452102,
        "compression_ratio": 1.5577889447236182,
        "end": 5502,
        "id": 1791,
        "no_speech_prob": 0.00013765456969849765,
        "seek": 549990,
        "start": 5499.9,
        "temperature": 0,
        "text": " after I do this, I can just dispose those.",
        "tokens": [
          50364,
          934,
          286,
          360,
          341,
          11,
          286,
          393,
          445,
          42537,
          729,
          13,
          50469
        ]
      },
      {
        "avg_logprob": -0.2482874007452102,
        "compression_ratio": 1.5577889447236182,
        "end": 5506.259999999999,
        "id": 1792,
        "no_speech_prob": 0.00013765456969849765,
        "seek": 549990,
        "start": 5503.4,
        "temperature": 0,
        "text": " So the y's, I definitely need to dispose.",
        "tokens": [
          50539,
          407,
          264,
          288,
          311,
          11,
          286,
          2138,
          643,
          281,
          42537,
          13,
          50682
        ]
      },
      {
        "avg_logprob": -0.2482874007452102,
        "compression_ratio": 1.5577889447236182,
        "end": 5507.759999999999,
        "id": 1793,
        "no_speech_prob": 0.00013765456969849765,
        "seek": 549990,
        "start": 5506.259999999999,
        "temperature": 0,
        "text": " Let's at least just do that first,",
        "tokens": [
          50682,
          961,
          311,
          412,
          1935,
          445,
          360,
          300,
          700,
          11,
          50757
        ]
      },
      {
        "avg_logprob": -0.2482874007452102,
        "compression_ratio": 1.5577889447236182,
        "end": 5511.0599999999995,
        "id": 1794,
        "no_speech_prob": 0.00013765456969849765,
        "seek": 549990,
        "start": 5507.759999999999,
        "temperature": 0,
        "text": " and let's see where that gets, oh.",
        "tokens": [
          50757,
          293,
          718,
          311,
          536,
          689,
          300,
          2170,
          11,
          1954,
          13,
          50922
        ]
      },
      {
        "avg_logprob": -0.2482874007452102,
        "compression_ratio": 1.5577889447236182,
        "end": 5515.5199999999995,
        "id": 1795,
        "no_speech_prob": 0.00013765456969849765,
        "seek": 549990,
        "start": 5513.799999999999,
        "temperature": 0,
        "text": " Oh, look at this.",
        "tokens": [
          51059,
          876,
          11,
          574,
          412,
          341,
          13,
          51145
        ]
      },
      {
        "avg_logprob": -0.2482874007452102,
        "compression_ratio": 1.5577889447236182,
        "end": 5518.46,
        "id": 1796,
        "no_speech_prob": 0.00013765456969849765,
        "seek": 549990,
        "start": 5515.5199999999995,
        "temperature": 0,
        "text": " Ah, because I used data sync, I could use tf.tidy,",
        "tokens": [
          51145,
          2438,
          11,
          570,
          286,
          1143,
          1412,
          20271,
          11,
          286,
          727,
          764,
          256,
          69,
          13,
          83,
          38836,
          11,
          51292
        ]
      },
      {
        "avg_logprob": -0.2482874007452102,
        "compression_ratio": 1.5577889447236182,
        "end": 5521.639999999999,
        "id": 1797,
        "no_speech_prob": 0.00013765456969849765,
        "seek": 549990,
        "start": 5518.46,
        "temperature": 0,
        "text": " but what I'm going to do now is y's,",
        "tokens": [
          51292,
          457,
          437,
          286,
          478,
          516,
          281,
          360,
          586,
          307,
          288,
          311,
          11,
          51451
        ]
      },
      {
        "avg_logprob": -0.2482874007452102,
        "compression_ratio": 1.5577889447236182,
        "end": 5525.96,
        "id": 1798,
        "no_speech_prob": 0.00013765456969849765,
        "seek": 549990,
        "start": 5521.639999999999,
        "temperature": 0,
        "text": " and then I'm going to say let y underscore values",
        "tokens": [
          51451,
          293,
          550,
          286,
          478,
          516,
          281,
          584,
          718,
          288,
          37556,
          4190,
          51667
        ]
      },
      {
        "avg_logprob": -0.25384516655644285,
        "compression_ratio": 1.3866666666666667,
        "end": 5530.5,
        "id": 1799,
        "no_speech_prob": 0.00034062896156683564,
        "seek": 552596,
        "start": 5525.9800000000005,
        "temperature": 0,
        "text": " equals y's dot data sync.",
        "tokens": [
          50365,
          6915,
          288,
          311,
          5893,
          1412,
          20271,
          13,
          50591
        ]
      },
      {
        "avg_logprob": -0.25384516655644285,
        "compression_ratio": 1.3866666666666667,
        "end": 5533.02,
        "id": 1800,
        "no_speech_prob": 0.00034062896156683564,
        "seek": 552596,
        "start": 5530.5,
        "temperature": 0,
        "text": " I can't clean it up once it's also been data synced,",
        "tokens": [
          50591,
          286,
          393,
          380,
          2541,
          309,
          493,
          1564,
          309,
          311,
          611,
          668,
          1412,
          5451,
          1232,
          11,
          50717
        ]
      },
      {
        "avg_logprob": -0.25384516655644285,
        "compression_ratio": 1.3866666666666667,
        "end": 5535.04,
        "id": 1801,
        "no_speech_prob": 0.00034062896156683564,
        "seek": 552596,
        "start": 5533.02,
        "temperature": 0,
        "text": " so now I do the y's dot dispose.",
        "tokens": [
          50717,
          370,
          586,
          286,
          360,
          264,
          288,
          311,
          5893,
          42537,
          13,
          50818
        ]
      },
      {
        "avg_logprob": -0.25384516655644285,
        "compression_ratio": 1.3866666666666667,
        "end": 5540.9800000000005,
        "id": 1802,
        "no_speech_prob": 0.00034062896156683564,
        "seek": 552596,
        "start": 5539.26,
        "temperature": 0,
        "text": " Whoops, do I have no loop on?",
        "tokens": [
          51029,
          45263,
          11,
          360,
          286,
          362,
          572,
          6367,
          322,
          30,
          51115
        ]
      },
      {
        "avg_logprob": -0.25384516655644285,
        "compression_ratio": 1.3866666666666667,
        "end": 5541.82,
        "id": 1803,
        "no_speech_prob": 0.00034062896156683564,
        "seek": 552596,
        "start": 5540.9800000000005,
        "temperature": 0,
        "text": " No.",
        "tokens": [
          51115,
          883,
          13,
          51157
        ]
      },
      {
        "avg_logprob": -0.25384516655644285,
        "compression_ratio": 1.3866666666666667,
        "end": 5548.9800000000005,
        "id": 1804,
        "no_speech_prob": 0.00034062896156683564,
        "seek": 552596,
        "start": 5544.54,
        "temperature": 0,
        "text": " And still going up.",
        "tokens": [
          51293,
          400,
          920,
          516,
          493,
          13,
          51515
        ]
      },
      {
        "avg_logprob": -0.25384516655644285,
        "compression_ratio": 1.3866666666666667,
        "end": 5552.54,
        "id": 1805,
        "no_speech_prob": 0.00034062896156683564,
        "seek": 552596,
        "start": 5551.54,
        "temperature": 0,
        "text": " That's weird.",
        "tokens": [
          51643,
          663,
          311,
          3657,
          13,
          51693
        ]
      },
      {
        "avg_logprob": -0.25384516655644285,
        "compression_ratio": 1.3866666666666667,
        "end": 5555.5,
        "id": 1806,
        "no_speech_prob": 0.00034062896156683564,
        "seek": 552596,
        "start": 5552.54,
        "temperature": 0,
        "text": " Oh, this has to be y values.",
        "tokens": [
          51693,
          876,
          11,
          341,
          575,
          281,
          312,
          288,
          4190,
          13,
          51841
        ]
      },
      {
        "avg_logprob": -0.26345161263269323,
        "compression_ratio": 1.6666666666666667,
        "end": 5558.56,
        "id": 1807,
        "no_speech_prob": 0.000004860446551901987,
        "seek": 555550,
        "start": 5556,
        "temperature": 0,
        "text": " Also, I have to change that to y values, so that helped.",
        "tokens": [
          50389,
          2743,
          11,
          286,
          362,
          281,
          1319,
          300,
          281,
          288,
          4190,
          11,
          370,
          300,
          4254,
          13,
          50517
        ]
      },
      {
        "avg_logprob": -0.26345161263269323,
        "compression_ratio": 1.6666666666666667,
        "end": 5562.4,
        "id": 1808,
        "no_speech_prob": 0.000004860446551901987,
        "seek": 555550,
        "start": 5560,
        "temperature": 0,
        "text": " This video is so long.",
        "tokens": [
          50589,
          639,
          960,
          307,
          370,
          938,
          13,
          50709
        ]
      },
      {
        "avg_logprob": -0.26345161263269323,
        "compression_ratio": 1.6666666666666667,
        "end": 5565.36,
        "id": 1809,
        "no_speech_prob": 0.000004860446551901987,
        "seek": 555550,
        "start": 5562.4,
        "temperature": 0,
        "text": " Now, what I want to do is I need to,",
        "tokens": [
          50709,
          823,
          11,
          437,
          286,
          528,
          281,
          360,
          307,
          286,
          643,
          281,
          11,
          50857
        ]
      },
      {
        "avg_logprob": -0.26345161263269323,
        "compression_ratio": 1.6666666666666667,
        "end": 5568.08,
        "id": 1810,
        "no_speech_prob": 0.000004860446551901987,
        "seek": 555550,
        "start": 5565.36,
        "temperature": 0,
        "text": " ah, let's just do this, tf.tidy.",
        "tokens": [
          50857,
          3716,
          11,
          718,
          311,
          445,
          360,
          341,
          11,
          256,
          69,
          13,
          83,
          38836,
          13,
          50993
        ]
      },
      {
        "avg_logprob": -0.26345161263269323,
        "compression_ratio": 1.6666666666666667,
        "end": 5569.88,
        "id": 1811,
        "no_speech_prob": 0.000004860446551901987,
        "seek": 555550,
        "start": 5568.08,
        "temperature": 0,
        "text": " Let's just put the tf.tidy here.",
        "tokens": [
          50993,
          961,
          311,
          445,
          829,
          264,
          256,
          69,
          13,
          83,
          38836,
          510,
          13,
          51083
        ]
      },
      {
        "avg_logprob": -0.26345161263269323,
        "compression_ratio": 1.6666666666666667,
        "end": 5573.86,
        "id": 1812,
        "no_speech_prob": 0.000004860446551901987,
        "seek": 555550,
        "start": 5571.36,
        "temperature": 0,
        "text": " So like whatever happens in this function,",
        "tokens": [
          51157,
          407,
          411,
          2035,
          2314,
          294,
          341,
          2445,
          11,
          51282
        ]
      },
      {
        "avg_logprob": -0.26345161263269323,
        "compression_ratio": 1.6666666666666667,
        "end": 5577.96,
        "id": 1813,
        "no_speech_prob": 0.000004860446551901987,
        "seek": 555550,
        "start": 5575.8,
        "temperature": 0,
        "text": " just tidy it all up.",
        "tokens": [
          51379,
          445,
          34646,
          309,
          439,
          493,
          13,
          51487
        ]
      },
      {
        "avg_logprob": -0.26345161263269323,
        "compression_ratio": 1.6666666666666667,
        "end": 5579.12,
        "id": 1814,
        "no_speech_prob": 0.000004860446551901987,
        "seek": 555550,
        "start": 5577.96,
        "temperature": 0,
        "text": " I could put it probably up here.",
        "tokens": [
          51487,
          286,
          727,
          829,
          309,
          1391,
          493,
          510,
          13,
          51545
        ]
      },
      {
        "avg_logprob": -0.26345161263269323,
        "compression_ratio": 1.6666666666666667,
        "end": 5580.72,
        "id": 1815,
        "no_speech_prob": 0.000004860446551901987,
        "seek": 555550,
        "start": 5579.12,
        "temperature": 0,
        "text": " It's the model.fit that I need to tidy,",
        "tokens": [
          51545,
          467,
          311,
          264,
          2316,
          13,
          6845,
          300,
          286,
          643,
          281,
          34646,
          11,
          51625
        ]
      },
      {
        "avg_logprob": -0.26345161263269323,
        "compression_ratio": 1.6666666666666667,
        "end": 5582,
        "id": 1816,
        "no_speech_prob": 0.000004860446551901987,
        "seek": 555550,
        "start": 5580.72,
        "temperature": 0,
        "text": " but I'm just going to do this.",
        "tokens": [
          51625,
          457,
          286,
          478,
          445,
          516,
          281,
          360,
          341,
          13,
          51689
        ]
      },
      {
        "avg_logprob": -0.26345161263269323,
        "compression_ratio": 1.6666666666666667,
        "end": 5583.04,
        "id": 1817,
        "no_speech_prob": 0.000004860446551901987,
        "seek": 555550,
        "start": 5582,
        "temperature": 0,
        "text": " Let's do this.",
        "tokens": [
          51689,
          961,
          311,
          360,
          341,
          13,
          51741
        ]
      },
      {
        "avg_logprob": -0.2751743316650391,
        "compression_ratio": 1.1313131313131313,
        "end": 5588.34,
        "id": 1818,
        "no_speech_prob": 0.00008888073352864012,
        "seek": 558304,
        "start": 5583.98,
        "temperature": 0,
        "text": " 540, 900, ooh, I'm still missing something.",
        "tokens": [
          50411,
          1025,
          5254,
          11,
          22016,
          11,
          17024,
          11,
          286,
          478,
          920,
          5361,
          746,
          13,
          50629
        ]
      },
      {
        "avg_logprob": -0.2751743316650391,
        "compression_ratio": 1.1313131313131313,
        "end": 5590.14,
        "id": 1819,
        "no_speech_prob": 0.00008888073352864012,
        "seek": 558304,
        "start": 5588.34,
        "temperature": 0,
        "text": " What tensor is being created over and over again",
        "tokens": [
          50629,
          708,
          40863,
          307,
          885,
          2942,
          670,
          293,
          670,
          797,
          50719
        ]
      },
      {
        "avg_logprob": -0.2751743316650391,
        "compression_ratio": 1.1313131313131313,
        "end": 5591.22,
        "id": 1820,
        "no_speech_prob": 0.00008888073352864012,
        "seek": 558304,
        "start": 5590.14,
        "temperature": 0,
        "text": " that I didn't tidy?",
        "tokens": [
          50719,
          300,
          286,
          994,
          380,
          34646,
          30,
          50773
        ]
      },
      {
        "avg_logprob": -0.4829081271557098,
        "compression_ratio": 1.180952380952381,
        "end": 5615.12,
        "id": 1821,
        "no_speech_prob": 0.0017274068668484688,
        "seek": 561304,
        "start": 5614.04,
        "temperature": 0,
        "text": " Oh, it's 220.",
        "tokens": [
          50414,
          876,
          11,
          309,
          311,
          29387,
          13,
          50468
        ]
      },
      {
        "avg_logprob": -0.4829081271557098,
        "compression_ratio": 1.180952380952381,
        "end": 5618.28,
        "id": 1822,
        "no_speech_prob": 0.0017274068668484688,
        "seek": 561304,
        "start": 5615.12,
        "temperature": 0,
        "text": " Oh, this is turning into a disaster.",
        "tokens": [
          50468,
          876,
          11,
          341,
          307,
          6246,
          666,
          257,
          11293,
          13,
          50626
        ]
      },
      {
        "avg_logprob": -0.4829081271557098,
        "compression_ratio": 1.180952380952381,
        "end": 5620.32,
        "id": 1823,
        "no_speech_prob": 0.0017274068668484688,
        "seek": 561304,
        "start": 5618.28,
        "temperature": 0,
        "text": " Hmm, what did I not tidy?",
        "tokens": [
          50626,
          8239,
          11,
          437,
          630,
          286,
          406,
          34646,
          30,
          50728
        ]
      },
      {
        "avg_logprob": -0.4829081271557098,
        "compression_ratio": 1.180952380952381,
        "end": 5624.24,
        "id": 1824,
        "no_speech_prob": 0.0017274068668484688,
        "seek": 561304,
        "start": 5622.04,
        "temperature": 0,
        "text": " I guess maybe I need to put tidy in here.",
        "tokens": [
          50814,
          286,
          2041,
          1310,
          286,
          643,
          281,
          829,
          34646,
          294,
          510,
          13,
          50924
        ]
      },
      {
        "avg_logprob": -0.4829081271557098,
        "compression_ratio": 1.180952380952381,
        "end": 5627.24,
        "id": 1825,
        "no_speech_prob": 0.0017274068668484688,
        "seek": 561304,
        "start": 5626.4,
        "temperature": 0,
        "text": " Like.",
        "tokens": [
          51032,
          1743,
          13,
          51074
        ]
      },
      {
        "avg_logprob": -0.5288329946583715,
        "compression_ratio": 0.8852459016393442,
        "end": 5643.88,
        "id": 1826,
        "no_speech_prob": 0.0005112566868774593,
        "seek": 564304,
        "start": 5643.04,
        "temperature": 0,
        "text": " Hmm.",
        "tokens": [
          50364,
          8239,
          13,
          50406
        ]
      },
      {
        "avg_logprob": -0.5288329946583715,
        "compression_ratio": 0.8852459016393442,
        "end": 5648.44,
        "id": 1827,
        "no_speech_prob": 0.0005112566868774593,
        "seek": 564304,
        "start": 5646.92,
        "temperature": 0,
        "text": " Or I can just say,",
        "tokens": [
          50558,
          1610,
          286,
          393,
          445,
          584,
          11,
          50634
        ]
      },
      {
        "avg_logprob": -0.5288329946583715,
        "compression_ratio": 0.8852459016393442,
        "end": 5653.6,
        "id": 1828,
        "no_speech_prob": 0.0005112566868774593,
        "seek": 564304,
        "start": 5652.56,
        "temperature": 0,
        "text": " like this, right?",
        "tokens": [
          50840,
          411,
          341,
          11,
          558,
          30,
          50892
        ]
      },
      {
        "avg_logprob": -0.5288329946583715,
        "compression_ratio": 0.8852459016393442,
        "end": 5661.76,
        "id": 1829,
        "no_speech_prob": 0.0005112566868774593,
        "seek": 564304,
        "start": 5660.92,
        "temperature": 0,
        "text": " Hold on.",
        "tokens": [
          51258,
          6962,
          322,
          13,
          51300
        ]
      },
      {
        "avg_logprob": -0.5288329946583715,
        "compression_ratio": 0.8852459016393442,
        "end": 5666.64,
        "id": 1830,
        "no_speech_prob": 0.0005112566868774593,
        "seek": 564304,
        "start": 5665.8,
        "temperature": 0,
        "text": " Oh.",
        "tokens": [
          51502,
          876,
          13,
          51544
        ]
      },
      {
        "avg_logprob": -0.3406284423101516,
        "compression_ratio": 0.8181818181818182,
        "end": 5674.88,
        "id": 1831,
        "no_speech_prob": 0.00012339289241936058,
        "seek": 567304,
        "start": 5674.04,
        "temperature": 0,
        "text": " Hmm.",
        "tokens": [
          50414,
          8239,
          13,
          50456
        ]
      },
      {
        "avg_logprob": -0.3406284423101516,
        "compression_ratio": 0.8181818181818182,
        "end": 5691.08,
        "id": 1832,
        "no_speech_prob": 0.00012339289241936058,
        "seek": 567304,
        "start": 5689.8,
        "temperature": 0,
        "text": " I'm so confused.",
        "tokens": [
          51202,
          286,
          478,
          370,
          9019,
          13,
          51266
        ]
      },
      {
        "avg_logprob": -0.3406284423101516,
        "compression_ratio": 0.8181818181818182,
        "end": 5694.12,
        "id": 1833,
        "no_speech_prob": 0.00012339289241936058,
        "seek": 567304,
        "start": 5693.28,
        "temperature": 0,
        "text": " Like this?",
        "tokens": [
          51376,
          1743,
          341,
          30,
          51418
        ]
      },
      {
        "avg_logprob": -0.3406284423101516,
        "compression_ratio": 0.8181818181818182,
        "end": 5696.28,
        "id": 1834,
        "no_speech_prob": 0.00012339289241936058,
        "seek": 567304,
        "start": 5695.44,
        "temperature": 0,
        "text": " No.",
        "tokens": [
          51484,
          883,
          13,
          51526
        ]
      },
      {
        "avg_logprob": -0.2854957142095456,
        "compression_ratio": 1.4352941176470588,
        "end": 5704.8,
        "id": 1835,
        "no_speech_prob": 0.00005649785089190118,
        "seek": 570304,
        "start": 5703.96,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          50410,
          1033,
          13,
          50452
        ]
      },
      {
        "avg_logprob": -0.2854957142095456,
        "compression_ratio": 1.4352941176470588,
        "end": 5710.12,
        "id": 1836,
        "no_speech_prob": 0.00005649785089190118,
        "seek": 570304,
        "start": 5708.68,
        "temperature": 0,
        "text": " I'm so confused, hold on.",
        "tokens": [
          50646,
          286,
          478,
          370,
          9019,
          11,
          1797,
          322,
          13,
          50718
        ]
      },
      {
        "avg_logprob": -0.2854957142095456,
        "compression_ratio": 1.4352941176470588,
        "end": 5714.76,
        "id": 1837,
        "no_speech_prob": 0.00005649785089190118,
        "seek": 570304,
        "start": 5712.56,
        "temperature": 0,
        "text": " I have to make the arrow function async?",
        "tokens": [
          50840,
          286,
          362,
          281,
          652,
          264,
          11610,
          2445,
          382,
          34015,
          30,
          50950
        ]
      },
      {
        "avg_logprob": -0.2854957142095456,
        "compression_ratio": 1.4352941176470588,
        "end": 5717.5199999999995,
        "id": 1838,
        "no_speech_prob": 0.00005649785089190118,
        "seek": 570304,
        "start": 5714.76,
        "temperature": 0,
        "text": " Yeah, this is like, I'm like lost here.",
        "tokens": [
          50950,
          865,
          11,
          341,
          307,
          411,
          11,
          286,
          478,
          411,
          2731,
          510,
          13,
          51088
        ]
      },
      {
        "avg_logprob": -0.2854957142095456,
        "compression_ratio": 1.4352941176470588,
        "end": 5719.12,
        "id": 1839,
        "no_speech_prob": 0.00005649785089190118,
        "seek": 570304,
        "start": 5717.5199999999995,
        "temperature": 0,
        "text": " Let me back up for a second.",
        "tokens": [
          51088,
          961,
          385,
          646,
          493,
          337,
          257,
          1150,
          13,
          51168
        ]
      },
      {
        "avg_logprob": -0.2854957142095456,
        "compression_ratio": 1.4352941176470588,
        "end": 5722.48,
        "id": 1840,
        "no_speech_prob": 0.00005649785089190118,
        "seek": 570304,
        "start": 5720.2,
        "temperature": 0,
        "text": " This is why I wanted to tidy outside of it.",
        "tokens": [
          51222,
          639,
          307,
          983,
          286,
          1415,
          281,
          34646,
          2380,
          295,
          309,
          13,
          51336
        ]
      },
      {
        "avg_logprob": -0.2854957142095456,
        "compression_ratio": 1.4352941176470588,
        "end": 5725.16,
        "id": 1841,
        "no_speech_prob": 0.00005649785089190118,
        "seek": 570304,
        "start": 5723.56,
        "temperature": 0,
        "text": " Get rid of tf.tidy for a second.",
        "tokens": [
          51390,
          3240,
          3973,
          295,
          256,
          69,
          13,
          83,
          38836,
          337,
          257,
          1150,
          13,
          51470
        ]
      },
      {
        "avg_logprob": -0.2854957142095456,
        "compression_ratio": 1.4352941176470588,
        "end": 5726.4,
        "id": 1842,
        "no_speech_prob": 0.00005649785089190118,
        "seek": 570304,
        "start": 5725.16,
        "temperature": 0,
        "text": " What did I have to start?",
        "tokens": [
          51470,
          708,
          630,
          286,
          362,
          281,
          722,
          30,
          51532
        ]
      },
      {
        "avg_logprob": -0.30695347075766705,
        "compression_ratio": 1.1442307692307692,
        "end": 5734.8,
        "id": 1843,
        "no_speech_prob": 0.000044693970266962424,
        "seek": 573304,
        "start": 5733.96,
        "temperature": 0,
        "text": " Hmm.",
        "tokens": [
          50410,
          8239,
          13,
          50452
        ]
      },
      {
        "avg_logprob": -0.30695347075766705,
        "compression_ratio": 1.1442307692307692,
        "end": 5737.8,
        "id": 1844,
        "no_speech_prob": 0.000044693970266962424,
        "seek": 573304,
        "start": 5736.2,
        "temperature": 0,
        "text": " Can I just put this here?",
        "tokens": [
          50522,
          1664,
          286,
          445,
          829,
          341,
          510,
          30,
          50602
        ]
      },
      {
        "avg_logprob": -0.30695347075766705,
        "compression_ratio": 1.1442307692307692,
        "end": 5746.26,
        "id": 1845,
        "no_speech_prob": 0.000044693970266962424,
        "seek": 573304,
        "start": 5745.36,
        "temperature": 0,
        "text": " What am I missing?",
        "tokens": [
          50980,
          708,
          669,
          286,
          5361,
          30,
          51025
        ]
      },
      {
        "avg_logprob": -0.30695347075766705,
        "compression_ratio": 1.1442307692307692,
        "end": 5755.72,
        "id": 1846,
        "no_speech_prob": 0.000044693970266962424,
        "seek": 573304,
        "start": 5753.32,
        "temperature": 0,
        "text": " I can't use promises in a tidy.",
        "tokens": [
          51378,
          286,
          393,
          380,
          764,
          16403,
          294,
          257,
          34646,
          13,
          51498
        ]
      },
      {
        "avg_logprob": -0.30695347075766705,
        "compression_ratio": 1.1442307692307692,
        "end": 5757.92,
        "id": 1847,
        "no_speech_prob": 0.000044693970266962424,
        "seek": 573304,
        "start": 5755.72,
        "temperature": 0,
        "text": " Oh, right.",
        "tokens": [
          51498,
          876,
          11,
          558,
          13,
          51608
        ]
      },
      {
        "avg_logprob": -0.30695347075766705,
        "compression_ratio": 1.1442307692307692,
        "end": 5759.4,
        "id": 1848,
        "no_speech_prob": 0.000044693970266962424,
        "seek": 573304,
        "start": 5757.92,
        "temperature": 0,
        "text": " So I was doing this right.",
        "tokens": [
          51608,
          407,
          286,
          390,
          884,
          341,
          558,
          13,
          51682
        ]
      },
      {
        "avg_logprob": -0.4403551518917084,
        "compression_ratio": 1.1857142857142857,
        "end": 5764.88,
        "id": 1849,
        "no_speech_prob": 0.00003591275526559912,
        "seek": 576304,
        "start": 5764.04,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          50414,
          1033,
          13,
          50456
        ]
      },
      {
        "avg_logprob": -0.4403551518917084,
        "compression_ratio": 1.1857142857142857,
        "end": 5773.6,
        "id": 1850,
        "no_speech_prob": 0.00003591275526559912,
        "seek": 576304,
        "start": 5772.04,
        "temperature": 0,
        "text": " Hold on a sec.",
        "tokens": [
          50814,
          6962,
          322,
          257,
          907,
          13,
          50892
        ]
      },
      {
        "avg_logprob": -0.4403551518917084,
        "compression_ratio": 1.1857142857142857,
        "end": 5775.88,
        "id": 1851,
        "no_speech_prob": 0.00003591275526559912,
        "seek": 576304,
        "start": 5773.6,
        "temperature": 0,
        "text": " What was wrong with what I had here?",
        "tokens": [
          50892,
          708,
          390,
          2085,
          365,
          437,
          286,
          632,
          510,
          30,
          51006
        ]
      },
      {
        "avg_logprob": -0.4403551518917084,
        "compression_ratio": 1.1857142857142857,
        "end": 5783.48,
        "id": 1852,
        "no_speech_prob": 0.00003591275526559912,
        "seek": 576304,
        "start": 5782.24,
        "temperature": 0,
        "text": " What was wrong with this?",
        "tokens": [
          51324,
          708,
          390,
          2085,
          365,
          341,
          30,
          51386
        ]
      },
      {
        "avg_logprob": -0.5717335480910081,
        "compression_ratio": 0.9452054794520548,
        "end": 5784.32,
        "id": 1853,
        "no_speech_prob": 0.00014202289457898587,
        "seek": 578348,
        "start": 5783.48,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          50364,
          1033,
          13,
          50406
        ]
      },
      {
        "avg_logprob": -0.5717335480910081,
        "compression_ratio": 0.9452054794520548,
        "end": 5794.799999999999,
        "id": 1854,
        "no_speech_prob": 0.00014202289457898587,
        "seek": 578348,
        "start": 5792.4,
        "temperature": 0,
        "text": " Like why is this, this should be fine, right?",
        "tokens": [
          50810,
          1743,
          983,
          307,
          341,
          11,
          341,
          820,
          312,
          2489,
          11,
          558,
          30,
          50930
        ]
      },
      {
        "avg_logprob": -0.5717335480910081,
        "compression_ratio": 0.9452054794520548,
        "end": 5805.5199999999995,
        "id": 1855,
        "no_speech_prob": 0.00014202289457898587,
        "seek": 578348,
        "start": 5804.5199999999995,
        "temperature": 0,
        "text": " Which version of?",
        "tokens": [
          51416,
          3013,
          3037,
          295,
          30,
          51466
        ]
      },
      {
        "avg_logprob": -0.4543509292602539,
        "compression_ratio": 1.1531531531531531,
        "end": 5806.360000000001,
        "id": 1856,
        "no_speech_prob": 0.00020662944007199258,
        "seek": 580552,
        "start": 5805.52,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          50364,
          1033,
          13,
          50406
        ]
      },
      {
        "avg_logprob": -0.4543509292602539,
        "compression_ratio": 1.1531531531531531,
        "end": 5814.240000000001,
        "id": 1857,
        "no_speech_prob": 0.00020662944007199258,
        "seek": 580552,
        "start": 5812.240000000001,
        "temperature": 0,
        "text": " Well, let me also go back to",
        "tokens": [
          50700,
          1042,
          11,
          718,
          385,
          611,
          352,
          646,
          281,
          50800
        ]
      },
      {
        "avg_logprob": -0.4543509292602539,
        "compression_ratio": 1.1531531531531531,
        "end": 5821.6,
        "id": 1858,
        "no_speech_prob": 0.00020662944007199258,
        "seek": 580552,
        "start": 5819.320000000001,
        "temperature": 0,
        "text": " making the resolution much bigger.",
        "tokens": [
          51054,
          1455,
          264,
          8669,
          709,
          3801,
          13,
          51168
        ]
      },
      {
        "avg_logprob": -0.4543509292602539,
        "compression_ratio": 1.1531531531531531,
        "end": 5828.76,
        "id": 1859,
        "no_speech_prob": 0.00020662944007199258,
        "seek": 580552,
        "start": 5827.92,
        "temperature": 0,
        "text": " Oh.",
        "tokens": [
          51484,
          876,
          13,
          51526
        ]
      },
      {
        "avg_logprob": -0.4543509292602539,
        "compression_ratio": 1.1531531531531531,
        "end": 5830.400000000001,
        "id": 1860,
        "no_speech_prob": 0.00020662944007199258,
        "seek": 580552,
        "start": 5828.76,
        "temperature": 0,
        "text": " Oh, I had it right before.",
        "tokens": [
          51526,
          876,
          11,
          286,
          632,
          309,
          558,
          949,
          13,
          51608
        ]
      },
      {
        "avg_logprob": -0.4543509292602539,
        "compression_ratio": 1.1531531531531531,
        "end": 5831.84,
        "id": 1861,
        "no_speech_prob": 0.00020662944007199258,
        "seek": 580552,
        "start": 5830.400000000001,
        "temperature": 0,
        "text": " I just didn't hit save.",
        "tokens": [
          51608,
          286,
          445,
          994,
          380,
          2045,
          3155,
          13,
          51680
        ]
      },
      {
        "avg_logprob": -0.4543509292602539,
        "compression_ratio": 1.1531531531531531,
        "end": 5832.68,
        "id": 1862,
        "no_speech_prob": 0.00020662944007199258,
        "seek": 580552,
        "start": 5831.84,
        "temperature": 0,
        "text": " Ah!",
        "tokens": [
          51680,
          2438,
          0,
          51722
        ]
      },
      {
        "avg_logprob": -0.37941118188806483,
        "compression_ratio": 1.380281690140845,
        "end": 5836.360000000001,
        "id": 1863,
        "no_speech_prob": 0.00007484614616259933,
        "seek": 583552,
        "start": 5835.52,
        "temperature": 0,
        "text": " Ah!",
        "tokens": [
          50364,
          2438,
          0,
          50406
        ]
      },
      {
        "avg_logprob": -0.37941118188806483,
        "compression_ratio": 1.380281690140845,
        "end": 5841.400000000001,
        "id": 1864,
        "no_speech_prob": 0.00007484614616259933,
        "seek": 583552,
        "start": 5840.400000000001,
        "temperature": 0,
        "text": " I'm gonna do a back flip, ready?",
        "tokens": [
          50608,
          286,
          478,
          799,
          360,
          257,
          646,
          7929,
          11,
          1919,
          30,
          50658
        ]
      },
      {
        "avg_logprob": -0.37941118188806483,
        "compression_ratio": 1.380281690140845,
        "end": 5843.6,
        "id": 1865,
        "no_speech_prob": 0.00007484614616259933,
        "seek": 583552,
        "start": 5841.400000000001,
        "temperature": 0,
        "text": " One, two, no, no, no, I'm not doing a back flip.",
        "tokens": [
          50658,
          1485,
          11,
          732,
          11,
          572,
          11,
          572,
          11,
          572,
          11,
          286,
          478,
          406,
          884,
          257,
          646,
          7929,
          13,
          50768
        ]
      },
      {
        "avg_logprob": -0.37941118188806483,
        "compression_ratio": 1.380281690140845,
        "end": 5847.56,
        "id": 1866,
        "no_speech_prob": 0.00007484614616259933,
        "seek": 583552,
        "start": 5846,
        "temperature": 0,
        "text": " I had it right the whole time.",
        "tokens": [
          50888,
          286,
          632,
          309,
          558,
          264,
          1379,
          565,
          13,
          50966
        ]
      },
      {
        "avg_logprob": -0.37941118188806483,
        "compression_ratio": 1.380281690140845,
        "end": 5856.64,
        "id": 1867,
        "no_speech_prob": 0.00007484614616259933,
        "seek": 583552,
        "start": 5855.120000000001,
        "temperature": 0,
        "text": " No.",
        "tokens": [
          51344,
          883,
          13,
          51420
        ]
      },
      {
        "avg_logprob": -0.37941118188806483,
        "compression_ratio": 1.380281690140845,
        "end": 5857.84,
        "id": 1868,
        "no_speech_prob": 0.00007484614616259933,
        "seek": 583552,
        "start": 5856.64,
        "temperature": 0,
        "text": " Well, that's so weird.",
        "tokens": [
          51420,
          1042,
          11,
          300,
          311,
          370,
          3657,
          13,
          51480
        ]
      },
      {
        "avg_logprob": -0.37941118188806483,
        "compression_ratio": 1.380281690140845,
        "end": 5862.56,
        "id": 1869,
        "no_speech_prob": 0.00007484614616259933,
        "seek": 583552,
        "start": 5859.120000000001,
        "temperature": 0,
        "text": " When the resolution is higher, I have a memory leak?",
        "tokens": [
          51544,
          1133,
          264,
          8669,
          307,
          2946,
          11,
          286,
          362,
          257,
          4675,
          17143,
          30,
          51716
        ]
      },
      {
        "avg_logprob": -0.43209221783806295,
        "compression_ratio": 1.077922077922078,
        "end": 5866.360000000001,
        "id": 1870,
        "no_speech_prob": 0.0004238829424139112,
        "seek": 586552,
        "start": 5865.52,
        "temperature": 0,
        "text": " Hmm.",
        "tokens": [
          50364,
          8239,
          13,
          50406
        ]
      },
      {
        "avg_logprob": -0.43209221783806295,
        "compression_ratio": 1.077922077922078,
        "end": 5880.400000000001,
        "id": 1871,
        "no_speech_prob": 0.0004238829424139112,
        "seek": 586552,
        "start": 5878.96,
        "temperature": 0,
        "text": " That's weird.",
        "tokens": [
          51036,
          663,
          311,
          3657,
          13,
          51108
        ]
      },
      {
        "avg_logprob": -0.43209221783806295,
        "compression_ratio": 1.077922077922078,
        "end": 5883.160000000001,
        "id": 1872,
        "no_speech_prob": 0.0004238829424139112,
        "seek": 586552,
        "start": 5881.72,
        "temperature": 0,
        "text": " What am I missing?",
        "tokens": [
          51174,
          708,
          669,
          286,
          5361,
          30,
          51246
        ]
      },
      {
        "avg_logprob": -0.43209221783806295,
        "compression_ratio": 1.077922077922078,
        "end": 5889.320000000001,
        "id": 1873,
        "no_speech_prob": 0.0004238829424139112,
        "seek": 586552,
        "start": 5888.120000000001,
        "temperature": 0,
        "text": " Why do I have three in there?",
        "tokens": [
          51494,
          1545,
          360,
          286,
          362,
          1045,
          294,
          456,
          30,
          51554
        ]
      },
      {
        "avg_logprob": -0.43209221783806295,
        "compression_ratio": 1.077922077922078,
        "end": 5890.320000000001,
        "id": 1874,
        "no_speech_prob": 0.0004238829424139112,
        "seek": 586552,
        "start": 5889.320000000001,
        "temperature": 0,
        "text": " That was weird.",
        "tokens": [
          51554,
          663,
          390,
          3657,
          13,
          51604
        ]
      },
      {
        "avg_logprob": -0.5298192501068115,
        "compression_ratio": 0.8181818181818182,
        "end": 5896.360000000001,
        "id": 1875,
        "no_speech_prob": 0.0012065537739545107,
        "seek": 589552,
        "start": 5895.52,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          50364,
          1033,
          13,
          50406
        ]
      },
      {
        "avg_logprob": -0.5298192501068115,
        "compression_ratio": 0.8181818181818182,
        "end": 5919.4800000000005,
        "id": 1876,
        "no_speech_prob": 0.0012065537739545107,
        "seek": 589552,
        "start": 5917.52,
        "temperature": 0,
        "text": " I'm going out of my mind here.",
        "tokens": [
          51464,
          286,
          478,
          516,
          484,
          295,
          452,
          1575,
          510,
          13,
          51562
        ]
      },
      {
        "avg_logprob": -0.37319678229254644,
        "compression_ratio": 1.011764705882353,
        "end": 5927.120000000001,
        "id": 1877,
        "no_speech_prob": 0.000511242775246501,
        "seek": 592552,
        "start": 5925.92,
        "temperature": 0,
        "text": " What is it?",
        "tokens": [
          50384,
          708,
          307,
          309,
          30,
          50444
        ]
      },
      {
        "avg_logprob": -0.37319678229254644,
        "compression_ratio": 1.011764705882353,
        "end": 5933.040000000001,
        "id": 1878,
        "no_speech_prob": 0.000511242775246501,
        "seek": 592552,
        "start": 5931.040000000001,
        "temperature": 0,
        "text": " What, I have some like weird bug here",
        "tokens": [
          50640,
          708,
          11,
          286,
          362,
          512,
          411,
          3657,
          7426,
          510,
          50740
        ]
      },
      {
        "avg_logprob": -0.37319678229254644,
        "compression_ratio": 1.011764705882353,
        "end": 5934.280000000001,
        "id": 1879,
        "no_speech_prob": 0.000511242775246501,
        "seek": 592552,
        "start": 5933.040000000001,
        "temperature": 0,
        "text": " that I'm not thinking of.",
        "tokens": [
          50740,
          300,
          286,
          478,
          406,
          1953,
          295,
          13,
          50802
        ]
      },
      {
        "avg_logprob": -0.37319678229254644,
        "compression_ratio": 1.011764705882353,
        "end": 5936.4800000000005,
        "id": 1880,
        "no_speech_prob": 0.000511242775246501,
        "seek": 592552,
        "start": 5935.56,
        "temperature": 0,
        "text": " Xs?",
        "tokens": [
          50866,
          1783,
          82,
          30,
          50912
        ]
      },
      {
        "avg_logprob": -0.37319678229254644,
        "compression_ratio": 1.011764705882353,
        "end": 5943.64,
        "id": 1881,
        "no_speech_prob": 0.000511242775246501,
        "seek": 592552,
        "start": 5942.8,
        "temperature": 0,
        "text": " Let's.",
        "tokens": [
          51228,
          961,
          311,
          13,
          51270
        ]
      },
      {
        "avg_logprob": -0.35688912868499756,
        "compression_ratio": 1.1214953271028036,
        "end": 5958.080000000001,
        "id": 1882,
        "no_speech_prob": 0.00013765416224487126,
        "seek": 595552,
        "start": 5956.280000000001,
        "temperature": 0,
        "text": " Let me tf.tidy this whole thing.",
        "tokens": [
          50402,
          961,
          385,
          256,
          69,
          13,
          83,
          38836,
          341,
          1379,
          551,
          13,
          50492
        ]
      },
      {
        "avg_logprob": -0.35688912868499756,
        "compression_ratio": 1.1214953271028036,
        "end": 5965.52,
        "id": 1883,
        "no_speech_prob": 0.00013765416224487126,
        "seek": 595552,
        "start": 5964.280000000001,
        "temperature": 0,
        "text": " Hmm.",
        "tokens": [
          50802,
          8239,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.35688912868499756,
        "compression_ratio": 1.1214953271028036,
        "end": 5967.080000000001,
        "id": 1884,
        "no_speech_prob": 0.00013765416224487126,
        "seek": 595552,
        "start": 5965.52,
        "temperature": 0,
        "text": " Ah!",
        "tokens": [
          50864,
          2438,
          0,
          50942
        ]
      },
      {
        "avg_logprob": -0.35688912868499756,
        "compression_ratio": 1.1214953271028036,
        "end": 5971.84,
        "id": 1885,
        "no_speech_prob": 0.00013765416224487126,
        "seek": 595552,
        "start": 5967.080000000001,
        "temperature": 0,
        "text": " So why with a different resolution?",
        "tokens": [
          50942,
          407,
          983,
          365,
          257,
          819,
          8669,
          30,
          51180
        ]
      },
      {
        "avg_logprob": -0.35688912868499756,
        "compression_ratio": 1.1214953271028036,
        "end": 5978.68,
        "id": 1886,
        "no_speech_prob": 0.00013765416224487126,
        "seek": 595552,
        "start": 5976.92,
        "temperature": 0,
        "text": " That's so weird.",
        "tokens": [
          51434,
          663,
          311,
          370,
          3657,
          13,
          51522
        ]
      },
      {
        "avg_logprob": -0.35688912868499756,
        "compression_ratio": 1.1214953271028036,
        "end": 5983.080000000001,
        "id": 1887,
        "no_speech_prob": 0.00013765416224487126,
        "seek": 595552,
        "start": 5981.120000000001,
        "temperature": 0,
        "text": " I feel like that's a bug.",
        "tokens": [
          51644,
          286,
          841,
          411,
          300,
          311,
          257,
          7426,
          13,
          51742
        ]
      },
      {
        "avg_logprob": -0.2398868136935764,
        "compression_ratio": 1.5416666666666667,
        "end": 5989.080000000001,
        "id": 1888,
        "no_speech_prob": 0.0000670920853735879,
        "seek": 598552,
        "start": 5986.52,
        "temperature": 0,
        "text": " Yeah, the slower the resolution, the less early.",
        "tokens": [
          50414,
          865,
          11,
          264,
          14009,
          264,
          8669,
          11,
          264,
          1570,
          2440,
          13,
          50542
        ]
      },
      {
        "avg_logprob": -0.2398868136935764,
        "compression_ratio": 1.5416666666666667,
        "end": 5995.200000000001,
        "id": 1889,
        "no_speech_prob": 0.0000670920853735879,
        "seek": 598552,
        "start": 5991.4800000000005,
        "temperature": 0,
        "text": " I sort of feel like there's some bug that's not my code.",
        "tokens": [
          50662,
          286,
          1333,
          295,
          841,
          411,
          456,
          311,
          512,
          7426,
          300,
          311,
          406,
          452,
          3089,
          13,
          50848
        ]
      },
      {
        "avg_logprob": -0.2398868136935764,
        "compression_ratio": 1.5416666666666667,
        "end": 5998.040000000001,
        "id": 1890,
        "no_speech_prob": 0.0000670920853735879,
        "seek": 598552,
        "start": 5995.200000000001,
        "temperature": 0,
        "text": " I can't figure it out, but tidy here kind of fixes it.",
        "tokens": [
          50848,
          286,
          393,
          380,
          2573,
          309,
          484,
          11,
          457,
          34646,
          510,
          733,
          295,
          32539,
          309,
          13,
          50990
        ]
      },
      {
        "avg_logprob": -0.2398868136935764,
        "compression_ratio": 1.5416666666666667,
        "end": 6011.4800000000005,
        "id": 1891,
        "no_speech_prob": 0.0000670920853735879,
        "seek": 598552,
        "start": 6009,
        "temperature": 0,
        "text": " I don't think that this needs to be,",
        "tokens": [
          51538,
          286,
          500,
          380,
          519,
          300,
          341,
          2203,
          281,
          312,
          11,
          51662
        ]
      },
      {
        "avg_logprob": -0.2398868136935764,
        "compression_ratio": 1.5416666666666667,
        "end": 6013.360000000001,
        "id": 1892,
        "no_speech_prob": 0.0000670920853735879,
        "seek": 598552,
        "start": 6011.4800000000005,
        "temperature": 0,
        "text": " this is just an array,",
        "tokens": [
          51662,
          341,
          307,
          445,
          364,
          10225,
          11,
          51756
        ]
      },
      {
        "avg_logprob": -0.2398868136935764,
        "compression_ratio": 1.5416666666666667,
        "end": 6014.92,
        "id": 1893,
        "no_speech_prob": 0.0000670920853735879,
        "seek": 598552,
        "start": 6013.360000000001,
        "temperature": 0,
        "text": " so this doesn't need to be cleaned up.",
        "tokens": [
          51756,
          370,
          341,
          1177,
          380,
          643,
          281,
          312,
          16146,
          493,
          13,
          51834
        ]
      },
      {
        "avg_logprob": -0.293694096226846,
        "compression_ratio": 1.7276785714285714,
        "end": 6016.24,
        "id": 1894,
        "no_speech_prob": 0.0004955293261446059,
        "seek": 601492,
        "start": 6015.28,
        "temperature": 0,
        "text": " I mean, the garbage collector should,",
        "tokens": [
          50382,
          286,
          914,
          11,
          264,
          14150,
          23960,
          820,
          11,
          50430
        ]
      },
      {
        "avg_logprob": -0.293694096226846,
        "compression_ratio": 1.7276785714285714,
        "end": 6018.32,
        "id": 1895,
        "no_speech_prob": 0.0004955293261446059,
        "seek": 601492,
        "start": 6016.24,
        "temperature": 0,
        "text": " that's not a tensor.",
        "tokens": [
          50430,
          300,
          311,
          406,
          257,
          40863,
          13,
          50534
        ]
      },
      {
        "avg_logprob": -0.293694096226846,
        "compression_ratio": 1.7276785714285714,
        "end": 6020.92,
        "id": 1896,
        "no_speech_prob": 0.0004955293261446059,
        "seek": 601492,
        "start": 6018.32,
        "temperature": 0,
        "text": " But did I make some other tensor in here that I,",
        "tokens": [
          50534,
          583,
          630,
          286,
          652,
          512,
          661,
          40863,
          294,
          510,
          300,
          286,
          11,
          50664
        ]
      },
      {
        "avg_logprob": -0.293694096226846,
        "compression_ratio": 1.7276785714285714,
        "end": 6022.2,
        "id": 1897,
        "no_speech_prob": 0.0004955293261446059,
        "seek": 601492,
        "start": 6020.92,
        "temperature": 0,
        "text": " oh, I guess model.predict,",
        "tokens": [
          50664,
          1954,
          11,
          286,
          2041,
          2316,
          13,
          79,
          24945,
          11,
          50728
        ]
      },
      {
        "avg_logprob": -0.293694096226846,
        "compression_ratio": 1.7276785714285714,
        "end": 6026.04,
        "id": 1898,
        "no_speech_prob": 0.0004955293261446059,
        "seek": 601492,
        "start": 6022.2,
        "temperature": 0,
        "text": " maybe it makes some other tensors behind the scenes.",
        "tokens": [
          50728,
          1310,
          309,
          1669,
          512,
          661,
          10688,
          830,
          2261,
          264,
          8026,
          13,
          50920
        ]
      },
      {
        "avg_logprob": -0.293694096226846,
        "compression_ratio": 1.7276785714285714,
        "end": 6028.08,
        "id": 1899,
        "no_speech_prob": 0.0004955293261446059,
        "seek": 601492,
        "start": 6026.04,
        "temperature": 0,
        "text": " Okay, you know what it is.",
        "tokens": [
          50920,
          1033,
          11,
          291,
          458,
          437,
          309,
          307,
          13,
          51022
        ]
      },
      {
        "avg_logprob": -0.293694096226846,
        "compression_ratio": 1.7276785714285714,
        "end": 6031.36,
        "id": 1900,
        "no_speech_prob": 0.0004955293261446059,
        "seek": 601492,
        "start": 6029.4400000000005,
        "temperature": 0,
        "text": " I'm just being silly here.",
        "tokens": [
          51090,
          286,
          478,
          445,
          885,
          11774,
          510,
          13,
          51186
        ]
      },
      {
        "avg_logprob": -0.293694096226846,
        "compression_ratio": 1.7276785714285714,
        "end": 6033.76,
        "id": 1901,
        "no_speech_prob": 0.0004955293261446059,
        "seek": 601492,
        "start": 6031.36,
        "temperature": 0,
        "text": " I think I'm like forgetting that model.predict,",
        "tokens": [
          51186,
          286,
          519,
          286,
          478,
          411,
          25428,
          300,
          2316,
          13,
          79,
          24945,
          11,
          51306
        ]
      },
      {
        "avg_logprob": -0.293694096226846,
        "compression_ratio": 1.7276785714285714,
        "end": 6036.6,
        "id": 1902,
        "no_speech_prob": 0.0004955293261446059,
        "seek": 601492,
        "start": 6033.76,
        "temperature": 0,
        "text": " just like model.fit does other, okay.",
        "tokens": [
          51306,
          445,
          411,
          2316,
          13,
          6845,
          775,
          661,
          11,
          1392,
          13,
          51448
        ]
      },
      {
        "avg_logprob": -0.293694096226846,
        "compression_ratio": 1.7276785714285714,
        "end": 6037.4400000000005,
        "id": 1903,
        "no_speech_prob": 0.0004955293261446059,
        "seek": 601492,
        "start": 6036.6,
        "temperature": 0,
        "text": " Mathieu!",
        "tokens": [
          51448,
          15776,
          19347,
          0,
          51490
        ]
      },
      {
        "avg_logprob": -0.293694096226846,
        "compression_ratio": 1.7276785714285714,
        "end": 6044.12,
        "id": 1904,
        "no_speech_prob": 0.0004955293261446059,
        "seek": 601492,
        "start": 6039.12,
        "temperature": 0,
        "text": " I'm going way back in time, way, way back in time.",
        "tokens": [
          51574,
          286,
          478,
          516,
          636,
          646,
          294,
          565,
          11,
          636,
          11,
          636,
          646,
          294,
          565,
          13,
          51824
        ]
      },
      {
        "avg_logprob": -0.47511768341064453,
        "compression_ratio": 1.1547619047619047,
        "end": 6046.6,
        "id": 1905,
        "no_speech_prob": 0.000020785084416274913,
        "seek": 604492,
        "start": 6045.6,
        "temperature": 0,
        "text": " Too long ago!",
        "tokens": [
          50398,
          11395,
          938,
          2057,
          0,
          50448
        ]
      },
      {
        "avg_logprob": -0.47511768341064453,
        "compression_ratio": 1.1547619047619047,
        "end": 6051.24,
        "id": 1906,
        "no_speech_prob": 0.000020785084416274913,
        "seek": 604492,
        "start": 6048.96,
        "temperature": 0,
        "text": " And I'm going to do my memory.",
        "tokens": [
          50566,
          400,
          286,
          478,
          516,
          281,
          360,
          452,
          4675,
          13,
          50680
        ]
      },
      {
        "avg_logprob": -0.47511768341064453,
        "compression_ratio": 1.1547619047619047,
        "end": 6069.56,
        "id": 1907,
        "no_speech_prob": 0.000020785084416274913,
        "seek": 604492,
        "start": 6067.92,
        "temperature": 0,
        "text": " Now, when did I make that three?",
        "tokens": [
          51514,
          823,
          11,
          562,
          630,
          286,
          652,
          300,
          1045,
          30,
          51596
        ]
      },
      {
        "avg_logprob": -0.47511768341064453,
        "compression_ratio": 1.1547619047619047,
        "end": 6072.28,
        "id": 1908,
        "no_speech_prob": 0.000020785084416274913,
        "seek": 604492,
        "start": 6070.56,
        "temperature": 0,
        "text": " I'm going to do my,",
        "tokens": [
          51646,
          286,
          478,
          516,
          281,
          360,
          452,
          11,
          51732
        ]
      },
      {
        "avg_logprob": -0.3815048933029175,
        "compression_ratio": 0.9857142857142858,
        "end": 6077.8,
        "id": 1909,
        "no_speech_prob": 0.00021986581850796938,
        "seek": 607492,
        "start": 6075.92,
        "temperature": 0,
        "text": " I'm going to go all the way back in memory,",
        "tokens": [
          50414,
          286,
          478,
          516,
          281,
          352,
          439,
          264,
          636,
          646,
          294,
          4675,
          11,
          50508
        ]
      },
      {
        "avg_logprob": -0.3815048933029175,
        "compression_ratio": 0.9857142857142858,
        "end": 6079.16,
        "id": 1910,
        "no_speech_prob": 0.00021986581850796938,
        "seek": 607492,
        "start": 6077.8,
        "temperature": 0,
        "text": " leak it again and fix it.",
        "tokens": [
          50508,
          17143,
          309,
          797,
          293,
          3191,
          309,
          13,
          50576
        ]
      },
      {
        "avg_logprob": -0.40627807867331583,
        "compression_ratio": 1.2451612903225806,
        "end": 6108.76,
        "id": 1911,
        "no_speech_prob": 0.006388234905898571,
        "seek": 610492,
        "start": 6105.76,
        "temperature": 0,
        "text": " Yeah, the epochs will definitely help.",
        "tokens": [
          50406,
          865,
          11,
          264,
          30992,
          28346,
          486,
          2138,
          854,
          13,
          50556
        ]
      },
      {
        "avg_logprob": -0.40627807867331583,
        "compression_ratio": 1.2451612903225806,
        "end": 6116.84,
        "id": 1912,
        "no_speech_prob": 0.006388234905898571,
        "seek": 610492,
        "start": 6113.36,
        "temperature": 0,
        "text": " Ooh, modeling evolution with TensorFlow.js",
        "tokens": [
          50786,
          7951,
          11,
          15983,
          9303,
          365,
          37624,
          13,
          25530,
          50960
        ]
      },
      {
        "avg_logprob": -0.40627807867331583,
        "compression_ratio": 1.2451612903225806,
        "end": 6119.24,
        "id": 1913,
        "no_speech_prob": 0.006388234905898571,
        "seek": 610492,
        "start": 6116.84,
        "temperature": 0,
        "text": " from Siraj Raval.",
        "tokens": [
          50960,
          490,
          6144,
          1805,
          497,
          46868,
          13,
          51080
        ]
      },
      {
        "avg_logprob": -0.40627807867331583,
        "compression_ratio": 1.2451612903225806,
        "end": 6121.08,
        "id": 1914,
        "no_speech_prob": 0.006388234905898571,
        "seek": 610492,
        "start": 6120.24,
        "temperature": 0,
        "text": " New video out.",
        "tokens": [
          51130,
          1873,
          960,
          484,
          13,
          51172
        ]
      },
      {
        "avg_logprob": -0.40627807867331583,
        "compression_ratio": 1.2451612903225806,
        "end": 6129.76,
        "id": 1915,
        "no_speech_prob": 0.006388234905898571,
        "seek": 610492,
        "start": 6128.04,
        "temperature": 0,
        "text": " All right, I just want to get this down a bit",
        "tokens": [
          51520,
          1057,
          558,
          11,
          286,
          445,
          528,
          281,
          483,
          341,
          760,
          257,
          857,
          51606
        ]
      },
      {
        "avg_logprob": -0.40627807867331583,
        "compression_ratio": 1.2451612903225806,
        "end": 6131.88,
        "id": 1916,
        "no_speech_prob": 0.006388234905898571,
        "seek": 610492,
        "start": 6129.76,
        "temperature": 0,
        "text": " and then I'm going to come back.",
        "tokens": [
          51606,
          293,
          550,
          286,
          478,
          516,
          281,
          808,
          646,
          13,
          51712
        ]
      },
      {
        "avg_logprob": -0.5210162798563639,
        "compression_ratio": 1.1917808219178083,
        "end": 6135.76,
        "id": 1917,
        "no_speech_prob": 0.00004198593887849711,
        "seek": 613492,
        "start": 6134.92,
        "temperature": 0,
        "text": " All right.",
        "tokens": [
          50364,
          1057,
          558,
          13,
          50406
        ]
      },
      {
        "avg_logprob": -0.5210162798563639,
        "compression_ratio": 1.1917808219178083,
        "end": 6145.76,
        "id": 1918,
        "no_speech_prob": 0.00004198593887849711,
        "seek": 613492,
        "start": 6144.04,
        "temperature": 0,
        "text": " All right, here we go, here we go.",
        "tokens": [
          50820,
          1057,
          558,
          11,
          510,
          321,
          352,
          11,
          510,
          321,
          352,
          13,
          50906
        ]
      },
      {
        "avg_logprob": -0.5210162798563639,
        "compression_ratio": 1.1917808219178083,
        "end": 6159.8,
        "id": 1919,
        "no_speech_prob": 0.00004198593887849711,
        "seek": 613492,
        "start": 6158.04,
        "temperature": 0,
        "text": " I can't look at the chat right now.",
        "tokens": [
          51520,
          286,
          393,
          380,
          574,
          412,
          264,
          5081,
          558,
          586,
          13,
          51608
        ]
      },
      {
        "avg_logprob": -0.5210162798563639,
        "compression_ratio": 1.1917808219178083,
        "end": 6161.68,
        "id": 1920,
        "no_speech_prob": 0.00004198593887849711,
        "seek": 613492,
        "start": 6160.84,
        "temperature": 0,
        "text": " Chat!",
        "tokens": [
          51660,
          27503,
          0,
          51702
        ]
      },
      {
        "avg_logprob": -0.22349593513890317,
        "compression_ratio": 1.7233333333333334,
        "end": 6163.400000000001,
        "id": 1921,
        "no_speech_prob": 0.000037052916013635695,
        "seek": 616168,
        "start": 6162.56,
        "temperature": 0,
        "text": " All right.",
        "tokens": [
          50408,
          1057,
          558,
          13,
          50450
        ]
      },
      {
        "avg_logprob": -0.22349593513890317,
        "compression_ratio": 1.7233333333333334,
        "end": 6167,
        "id": 1922,
        "no_speech_prob": 0.000037052916013635695,
        "seek": 616168,
        "start": 6164.84,
        "temperature": 0,
        "text": " All right, so you can see, it's kind of working.",
        "tokens": [
          50522,
          1057,
          558,
          11,
          370,
          291,
          393,
          536,
          11,
          309,
          311,
          733,
          295,
          1364,
          13,
          50630
        ]
      },
      {
        "avg_logprob": -0.22349593513890317,
        "compression_ratio": 1.7233333333333334,
        "end": 6168.6,
        "id": 1923,
        "no_speech_prob": 0.000037052916013635695,
        "seek": 616168,
        "start": 6167,
        "temperature": 0,
        "text": " I'm back, it's sort of taking a while,",
        "tokens": [
          50630,
          286,
          478,
          646,
          11,
          309,
          311,
          1333,
          295,
          1940,
          257,
          1339,
          11,
          50710
        ]
      },
      {
        "avg_logprob": -0.22349593513890317,
        "compression_ratio": 1.7233333333333334,
        "end": 6170.88,
        "id": 1924,
        "no_speech_prob": 0.000037052916013635695,
        "seek": 616168,
        "start": 6168.6,
        "temperature": 0,
        "text": " but I want to get this to train a little faster.",
        "tokens": [
          50710,
          457,
          286,
          528,
          281,
          483,
          341,
          281,
          3847,
          257,
          707,
          4663,
          13,
          50824
        ]
      },
      {
        "avg_logprob": -0.22349593513890317,
        "compression_ratio": 1.7233333333333334,
        "end": 6172.96,
        "id": 1925,
        "no_speech_prob": 0.000037052916013635695,
        "seek": 616168,
        "start": 6170.88,
        "temperature": 0,
        "text": " I want to make this, I want to get a little further.",
        "tokens": [
          50824,
          286,
          528,
          281,
          652,
          341,
          11,
          286,
          528,
          281,
          483,
          257,
          707,
          3052,
          13,
          50928
        ]
      },
      {
        "avg_logprob": -0.22349593513890317,
        "compression_ratio": 1.7233333333333334,
        "end": 6174.56,
        "id": 1926,
        "no_speech_prob": 0.000037052916013635695,
        "seek": 616168,
        "start": 6172.96,
        "temperature": 0,
        "text": " First of all, I was reminded by the chat",
        "tokens": [
          50928,
          2386,
          295,
          439,
          11,
          286,
          390,
          15920,
          538,
          264,
          5081,
          51008
        ]
      },
      {
        "avg_logprob": -0.22349593513890317,
        "compression_ratio": 1.7233333333333334,
        "end": 6177.280000000001,
        "id": 1927,
        "no_speech_prob": 0.000037052916013635695,
        "seek": 616168,
        "start": 6174.56,
        "temperature": 0,
        "text": " that I'd forgotten something really crucial and important,",
        "tokens": [
          51008,
          300,
          286,
          1116,
          11832,
          746,
          534,
          11462,
          293,
          1021,
          11,
          51144
        ]
      },
      {
        "avg_logprob": -0.22349593513890317,
        "compression_ratio": 1.7233333333333334,
        "end": 6178.88,
        "id": 1928,
        "no_speech_prob": 0.000037052916013635695,
        "seek": 616168,
        "start": 6177.280000000001,
        "temperature": 0,
        "text": " which is memory management.",
        "tokens": [
          51144,
          597,
          307,
          4675,
          4592,
          13,
          51224
        ]
      },
      {
        "avg_logprob": -0.22349593513890317,
        "compression_ratio": 1.7233333333333334,
        "end": 6182.320000000001,
        "id": 1929,
        "no_speech_prob": 0.000037052916013635695,
        "seek": 616168,
        "start": 6178.88,
        "temperature": 0,
        "text": " And I really should stop this from running right now",
        "tokens": [
          51224,
          400,
          286,
          534,
          820,
          1590,
          341,
          490,
          2614,
          558,
          586,
          51396
        ]
      },
      {
        "avg_logprob": -0.22349593513890317,
        "compression_ratio": 1.7233333333333334,
        "end": 6183.92,
        "id": 1930,
        "no_speech_prob": 0.000037052916013635695,
        "seek": 616168,
        "start": 6182.320000000001,
        "temperature": 0,
        "text": " because there's a huge memory leak happening,",
        "tokens": [
          51396,
          570,
          456,
          311,
          257,
          2603,
          4675,
          17143,
          2737,
          11,
          51476
        ]
      },
      {
        "avg_logprob": -0.22349593513890317,
        "compression_ratio": 1.7233333333333334,
        "end": 6186.240000000001,
        "id": 1931,
        "no_speech_prob": 0.000037052916013635695,
        "seek": 616168,
        "start": 6183.92,
        "temperature": 0,
        "text": " which I haven't cleaned up any of my tensors at all.",
        "tokens": [
          51476,
          597,
          286,
          2378,
          380,
          16146,
          493,
          604,
          295,
          452,
          10688,
          830,
          412,
          439,
          13,
          51592
        ]
      },
      {
        "avg_logprob": -0.22349593513890317,
        "compression_ratio": 1.7233333333333334,
        "end": 6187.08,
        "id": 1932,
        "no_speech_prob": 0.000037052916013635695,
        "seek": 616168,
        "start": 6186.240000000001,
        "temperature": 0,
        "text": " Whoops.",
        "tokens": [
          51592,
          45263,
          13,
          51634
        ]
      },
      {
        "avg_logprob": -0.22349593513890317,
        "compression_ratio": 1.7233333333333334,
        "end": 6189.76,
        "id": 1933,
        "no_speech_prob": 0.000037052916013635695,
        "seek": 616168,
        "start": 6188.400000000001,
        "temperature": 0,
        "text": " Don't look at that, hold on.",
        "tokens": [
          51700,
          1468,
          380,
          574,
          412,
          300,
          11,
          1797,
          322,
          13,
          51768
        ]
      },
      {
        "avg_logprob": -0.40497533480326336,
        "compression_ratio": 1.198019801980198,
        "end": 6191.96,
        "id": 1934,
        "no_speech_prob": 0.00027371488977223635,
        "seek": 618976,
        "start": 6190.72,
        "temperature": 0,
        "text": " Forgot that it was there.",
        "tokens": [
          50412,
          1171,
          13178,
          300,
          309,
          390,
          456,
          13,
          50474
        ]
      },
      {
        "avg_logprob": -0.40497533480326336,
        "compression_ratio": 1.198019801980198,
        "end": 6196.08,
        "id": 1935,
        "no_speech_prob": 0.00027371488977223635,
        "seek": 618976,
        "start": 6194.320000000001,
        "temperature": 0,
        "text": " Okay, oh, and this is there.",
        "tokens": [
          50592,
          1033,
          11,
          1954,
          11,
          293,
          341,
          307,
          456,
          13,
          50680
        ]
      },
      {
        "avg_logprob": -0.40497533480326336,
        "compression_ratio": 1.198019801980198,
        "end": 6198.08,
        "id": 1936,
        "no_speech_prob": 0.00027371488977223635,
        "seek": 618976,
        "start": 6197.24,
        "temperature": 0,
        "text": " Sorry.",
        "tokens": [
          50738,
          4919,
          13,
          50780
        ]
      },
      {
        "avg_logprob": -0.40497533480326336,
        "compression_ratio": 1.198019801980198,
        "end": 6212.84,
        "id": 1937,
        "no_speech_prob": 0.00027371488977223635,
        "seek": 618976,
        "start": 6211.52,
        "temperature": 0,
        "text": " Just do this again.",
        "tokens": [
          51452,
          1449,
          360,
          341,
          797,
          13,
          51518
        ]
      },
      {
        "avg_logprob": -0.40497533480326336,
        "compression_ratio": 1.198019801980198,
        "end": 6214.52,
        "id": 1938,
        "no_speech_prob": 0.00027371488977223635,
        "seek": 618976,
        "start": 6212.84,
        "temperature": 0,
        "text": " Sorry, everybody.",
        "tokens": [
          51518,
          4919,
          11,
          2201,
          13,
          51602
        ]
      },
      {
        "avg_logprob": -0.40497533480326336,
        "compression_ratio": 1.198019801980198,
        "end": 6215.76,
        "id": 1939,
        "no_speech_prob": 0.00027371488977223635,
        "seek": 618976,
        "start": 6214.52,
        "temperature": 0,
        "text": " One more time!",
        "tokens": [
          51602,
          1485,
          544,
          565,
          0,
          51664
        ]
      },
      {
        "avg_logprob": -0.40497533480326336,
        "compression_ratio": 1.198019801980198,
        "end": 6218.08,
        "id": 1940,
        "no_speech_prob": 0.00027371488977223635,
        "seek": 618976,
        "start": 6217.24,
        "temperature": 0,
        "text": " Shoot.",
        "tokens": [
          51738,
          19760,
          13,
          51780
        ]
      },
      {
        "avg_logprob": -0.4650588035583496,
        "compression_ratio": 0.7419354838709677,
        "end": 6221.4400000000005,
        "id": 1941,
        "no_speech_prob": 0.00026946034631691873,
        "seek": 621976,
        "start": 6220.08,
        "temperature": 0,
        "text": " Yay, memory leak.",
        "tokens": [
          50380,
          13268,
          11,
          4675,
          17143,
          13,
          50448
        ]
      },
      {
        "avg_logprob": -0.4650588035583496,
        "compression_ratio": 0.7419354838709677,
        "end": 6223.2,
        "id": 1942,
        "no_speech_prob": 0.00026946034631691873,
        "seek": 621976,
        "start": 6222.360000000001,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          50494,
          1033,
          13,
          50536
        ]
      },
      {
        "avg_logprob": -0.7662509282430013,
        "compression_ratio": 0.8297872340425532,
        "end": 6224.48,
        "id": 1943,
        "no_speech_prob": 0.0014323644572868943,
        "seek": 622320,
        "start": 6223.36,
        "temperature": 0,
        "text": " Whistling",
        "tokens": [
          50372,
          506,
          37174,
          50428
        ]
      },
      {
        "avg_logprob": -0.7662509282430013,
        "compression_ratio": 0.8297872340425532,
        "end": 6249.8,
        "id": 1944,
        "no_speech_prob": 0.0014323644572868943,
        "seek": 622320,
        "start": 6248.48,
        "temperature": 0,
        "text": " Really need that ukulele.",
        "tokens": [
          51628,
          4083,
          643,
          300,
          26769,
          2271,
          306,
          13,
          51694
        ]
      },
      {
        "avg_logprob": -0.7662509282430013,
        "compression_ratio": 0.8297872340425532,
        "end": 6252,
        "id": 1945,
        "no_speech_prob": 0.0014323644572868943,
        "seek": 622320,
        "start": 6251.16,
        "temperature": 0,
        "text": " Ah!",
        "tokens": [
          51762,
          2438,
          0,
          51804
        ]
      },
      {
        "avg_logprob": -0.2791068283552976,
        "compression_ratio": 1.541237113402062,
        "end": 6255.04,
        "id": 1946,
        "no_speech_prob": 0.0001609285973245278,
        "seek": 625320,
        "start": 6254.2,
        "temperature": 0,
        "text": " Ah!",
        "tokens": [
          50414,
          2438,
          0,
          50456
        ]
      },
      {
        "avg_logprob": -0.2791068283552976,
        "compression_ratio": 1.541237113402062,
        "end": 6265.28,
        "id": 1947,
        "no_speech_prob": 0.0001609285973245278,
        "seek": 625320,
        "start": 6264.44,
        "temperature": 0,
        "text": " All right.",
        "tokens": [
          50926,
          1057,
          558,
          13,
          50968
        ]
      },
      {
        "avg_logprob": -0.2791068283552976,
        "compression_ratio": 1.541237113402062,
        "end": 6268.44,
        "id": 1948,
        "no_speech_prob": 0.0001609285973245278,
        "seek": 625320,
        "start": 6267.04,
        "temperature": 0,
        "text": " Whoa, look at this.",
        "tokens": [
          51056,
          7521,
          11,
          574,
          412,
          341,
          13,
          51126
        ]
      },
      {
        "avg_logprob": -0.2791068283552976,
        "compression_ratio": 1.541237113402062,
        "end": 6271.48,
        "id": 1949,
        "no_speech_prob": 0.0001609285973245278,
        "seek": 625320,
        "start": 6268.44,
        "temperature": 0,
        "text": " All right, so you know, it actually is working.",
        "tokens": [
          51126,
          1057,
          558,
          11,
          370,
          291,
          458,
          11,
          309,
          767,
          307,
          1364,
          13,
          51278
        ]
      },
      {
        "avg_logprob": -0.2791068283552976,
        "compression_ratio": 1.541237113402062,
        "end": 6273.679999999999,
        "id": 1950,
        "no_speech_prob": 0.0001609285973245278,
        "seek": 625320,
        "start": 6271.48,
        "temperature": 0,
        "text": " It got the correct training result.",
        "tokens": [
          51278,
          467,
          658,
          264,
          3006,
          3097,
          1874,
          13,
          51388
        ]
      },
      {
        "avg_logprob": -0.2791068283552976,
        "compression_ratio": 1.541237113402062,
        "end": 6275.48,
        "id": 1951,
        "no_speech_prob": 0.0001609285973245278,
        "seek": 625320,
        "start": 6273.679999999999,
        "temperature": 0,
        "text": " It's a little grayscale-y in a way",
        "tokens": [
          51388,
          467,
          311,
          257,
          707,
          677,
          3772,
          37088,
          12,
          88,
          294,
          257,
          636,
          51478
        ]
      },
      {
        "avg_logprob": -0.2791068283552976,
        "compression_ratio": 1.541237113402062,
        "end": 6277.88,
        "id": 1952,
        "no_speech_prob": 0.0001609285973245278,
        "seek": 625320,
        "start": 6275.48,
        "temperature": 0,
        "text": " that I would like to be able to emphasize visually",
        "tokens": [
          51478,
          300,
          286,
          576,
          411,
          281,
          312,
          1075,
          281,
          16078,
          19622,
          51598
        ]
      },
      {
        "avg_logprob": -0.2791068283552976,
        "compression_ratio": 1.541237113402062,
        "end": 6280.599999999999,
        "id": 1953,
        "no_speech_prob": 0.0001609285973245278,
        "seek": 625320,
        "start": 6277.88,
        "temperature": 0,
        "text": " what it's doing, but you can see the loss has gone way down,",
        "tokens": [
          51598,
          437,
          309,
          311,
          884,
          11,
          457,
          291,
          393,
          536,
          264,
          4470,
          575,
          2780,
          636,
          760,
          11,
          51734
        ]
      },
      {
        "avg_logprob": -0.2791068283552976,
        "compression_ratio": 1.541237113402062,
        "end": 6281.76,
        "id": 1954,
        "no_speech_prob": 0.0001609285973245278,
        "seek": 625320,
        "start": 6280.599999999999,
        "temperature": 0,
        "text": " but it took a while to get there.",
        "tokens": [
          51734,
          457,
          309,
          1890,
          257,
          1339,
          281,
          483,
          456,
          13,
          51792
        ]
      },
      {
        "avg_logprob": -0.2530655997140067,
        "compression_ratio": 1.6571428571428573,
        "end": 6283.96,
        "id": 1955,
        "no_speech_prob": 0.00008220177551265806,
        "seek": 628176,
        "start": 6281.76,
        "temperature": 0,
        "text": " But I want to add a few things to this",
        "tokens": [
          50364,
          583,
          286,
          528,
          281,
          909,
          257,
          1326,
          721,
          281,
          341,
          50474
        ]
      },
      {
        "avg_logprob": -0.2530655997140067,
        "compression_ratio": 1.6571428571428573,
        "end": 6285.68,
        "id": 1956,
        "no_speech_prob": 0.00008220177551265806,
        "seek": 628176,
        "start": 6283.96,
        "temperature": 0,
        "text": " and try to fix it up a little bit.",
        "tokens": [
          50474,
          293,
          853,
          281,
          3191,
          309,
          493,
          257,
          707,
          857,
          13,
          50560
        ]
      },
      {
        "avg_logprob": -0.2530655997140067,
        "compression_ratio": 1.6571428571428573,
        "end": 6289.400000000001,
        "id": 1957,
        "no_speech_prob": 0.00008220177551265806,
        "seek": 628176,
        "start": 6285.68,
        "temperature": 0,
        "text": " Before I do anything, I was reminded by the chat",
        "tokens": [
          50560,
          4546,
          286,
          360,
          1340,
          11,
          286,
          390,
          15920,
          538,
          264,
          5081,
          50746
        ]
      },
      {
        "avg_logprob": -0.2530655997140067,
        "compression_ratio": 1.6571428571428573,
        "end": 6290.96,
        "id": 1958,
        "no_speech_prob": 0.00008220177551265806,
        "seek": 628176,
        "start": 6289.400000000001,
        "temperature": 0,
        "text": " being over here that I haven't thought",
        "tokens": [
          50746,
          885,
          670,
          510,
          300,
          286,
          2378,
          380,
          1194,
          50824
        ]
      },
      {
        "avg_logprob": -0.2530655997140067,
        "compression_ratio": 1.6571428571428573,
        "end": 6292.24,
        "id": 1959,
        "no_speech_prob": 0.00008220177551265806,
        "seek": 628176,
        "start": 6290.96,
        "temperature": 0,
        "text": " about memory management at all.",
        "tokens": [
          50824,
          466,
          4675,
          4592,
          412,
          439,
          13,
          50888
        ]
      },
      {
        "avg_logprob": -0.2530655997140067,
        "compression_ratio": 1.6571428571428573,
        "end": 6294.320000000001,
        "id": 1960,
        "no_speech_prob": 0.00008220177551265806,
        "seek": 628176,
        "start": 6292.24,
        "temperature": 0,
        "text": " So I'm going to say no loop for a second",
        "tokens": [
          50888,
          407,
          286,
          478,
          516,
          281,
          584,
          572,
          6367,
          337,
          257,
          1150,
          50992
        ]
      },
      {
        "avg_logprob": -0.2530655997140067,
        "compression_ratio": 1.6571428571428573,
        "end": 6296.62,
        "id": 1961,
        "no_speech_prob": 0.00008220177551265806,
        "seek": 628176,
        "start": 6294.320000000001,
        "temperature": 0,
        "text": " to just sort of turn this off.",
        "tokens": [
          50992,
          281,
          445,
          1333,
          295,
          1261,
          341,
          766,
          13,
          51107
        ]
      },
      {
        "avg_logprob": -0.2530655997140067,
        "compression_ratio": 1.6571428571428573,
        "end": 6300.76,
        "id": 1962,
        "no_speech_prob": 0.00008220177551265806,
        "seek": 628176,
        "start": 6296.62,
        "temperature": 0,
        "text": " Then I'm going to say memory num tensors.",
        "tokens": [
          51107,
          1396,
          286,
          478,
          516,
          281,
          584,
          4675,
          1031,
          10688,
          830,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.2530655997140067,
        "compression_ratio": 1.6571428571428573,
        "end": 6301.6,
        "id": 1963,
        "no_speech_prob": 0.00008220177551265806,
        "seek": 628176,
        "start": 6300.76,
        "temperature": 0,
        "text": " Oops, no, no, no, wait.",
        "tokens": [
          51314,
          21726,
          11,
          572,
          11,
          572,
          11,
          572,
          11,
          1699,
          13,
          51356
        ]
      },
      {
        "avg_logprob": -0.2530655997140067,
        "compression_ratio": 1.6571428571428573,
        "end": 6306.52,
        "id": 1964,
        "no_speech_prob": 0.00008220177551265806,
        "seek": 628176,
        "start": 6301.6,
        "temperature": 0,
        "text": " tf.memory.numTensor.",
        "tokens": [
          51356,
          256,
          69,
          13,
          17886,
          827,
          13,
          77,
          449,
          51,
          23153,
          13,
          51602
        ]
      },
      {
        "avg_logprob": -0.2530655997140067,
        "compression_ratio": 1.6571428571428573,
        "end": 6308.280000000001,
        "id": 1965,
        "no_speech_prob": 0.00008220177551265806,
        "seek": 628176,
        "start": 6306.52,
        "temperature": 0,
        "text": " I don't know, I'm trying to use, ah!",
        "tokens": [
          51602,
          286,
          500,
          380,
          458,
          11,
          286,
          478,
          1382,
          281,
          764,
          11,
          3716,
          0,
          51690
        ]
      },
      {
        "avg_logprob": -0.2530655997140067,
        "compression_ratio": 1.6571428571428573,
        "end": 6309.12,
        "id": 1966,
        "no_speech_prob": 0.00008220177551265806,
        "seek": 628176,
        "start": 6308.280000000001,
        "temperature": 0,
        "text": " I'm going to say",
        "tokens": [
          51690,
          286,
          478,
          516,
          281,
          584,
          51732
        ]
      },
      {
        "avg_logprob": -0.28033654830035043,
        "compression_ratio": 1.6371308016877637,
        "end": 6314.12,
        "id": 1967,
        "no_speech_prob": 0.00005144209717400372,
        "seek": 630912,
        "start": 6310.12,
        "temperature": 0,
        "text": " numTensors, tf.memory.num.",
        "tokens": [
          50414,
          1031,
          51,
          694,
          830,
          11,
          256,
          69,
          13,
          17886,
          827,
          13,
          77,
          449,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.28033654830035043,
        "compression_ratio": 1.6371308016877637,
        "end": 6317.72,
        "id": 1968,
        "no_speech_prob": 0.00005144209717400372,
        "seek": 630912,
        "start": 6315.32,
        "temperature": 0,
        "text": " There it is, there it is, I can get it!",
        "tokens": [
          50674,
          821,
          309,
          307,
          11,
          456,
          309,
          307,
          11,
          286,
          393,
          483,
          309,
          0,
          50794
        ]
      },
      {
        "avg_logprob": -0.28033654830035043,
        "compression_ratio": 1.6371308016877637,
        "end": 6318.5599999999995,
        "id": 1969,
        "no_speech_prob": 0.00005144209717400372,
        "seek": 630912,
        "start": 6317.72,
        "temperature": 0,
        "text": " There it is.",
        "tokens": [
          50794,
          821,
          309,
          307,
          13,
          50836
        ]
      },
      {
        "avg_logprob": -0.28033654830035043,
        "compression_ratio": 1.6371308016877637,
        "end": 6321.8,
        "id": 1970,
        "no_speech_prob": 0.00005144209717400372,
        "seek": 630912,
        "start": 6318.5599999999995,
        "temperature": 0,
        "text": " 32,205 tensors, that's crazy.",
        "tokens": [
          50836,
          8858,
          11,
          2009,
          20,
          10688,
          830,
          11,
          300,
          311,
          3219,
          13,
          50998
        ]
      },
      {
        "avg_logprob": -0.28033654830035043,
        "compression_ratio": 1.6371308016877637,
        "end": 6323.2,
        "id": 1971,
        "no_speech_prob": 0.00005144209717400372,
        "seek": 630912,
        "start": 6321.8,
        "temperature": 0,
        "text": " So I need to deal with that.",
        "tokens": [
          50998,
          407,
          286,
          643,
          281,
          2028,
          365,
          300,
          13,
          51068
        ]
      },
      {
        "avg_logprob": -0.28033654830035043,
        "compression_ratio": 1.6371308016877637,
        "end": 6326.12,
        "id": 1972,
        "no_speech_prob": 0.00005144209717400372,
        "seek": 630912,
        "start": 6323.2,
        "temperature": 0,
        "text": " I'm just making tensors and letting them leak everywhere.",
        "tokens": [
          51068,
          286,
          478,
          445,
          1455,
          10688,
          830,
          293,
          8295,
          552,
          17143,
          5315,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.28033654830035043,
        "compression_ratio": 1.6371308016877637,
        "end": 6328.84,
        "id": 1973,
        "no_speech_prob": 0.00005144209717400372,
        "seek": 630912,
        "start": 6326.12,
        "temperature": 0,
        "text": " So I can manually run dispose,",
        "tokens": [
          51214,
          407,
          286,
          393,
          16945,
          1190,
          42537,
          11,
          51350
        ]
      },
      {
        "avg_logprob": -0.28033654830035043,
        "compression_ratio": 1.6371308016877637,
        "end": 6330.24,
        "id": 1974,
        "no_speech_prob": 0.00005144209717400372,
        "seek": 630912,
        "start": 6328.84,
        "temperature": 0,
        "text": " but I've got kind of an issue",
        "tokens": [
          51350,
          457,
          286,
          600,
          658,
          733,
          295,
          364,
          2734,
          51420
        ]
      },
      {
        "avg_logprob": -0.28033654830035043,
        "compression_ratio": 1.6371308016877637,
        "end": 6332.5599999999995,
        "id": 1975,
        "no_speech_prob": 0.00005144209717400372,
        "seek": 630912,
        "start": 6330.24,
        "temperature": 0,
        "text": " where as predict is going to like make a lot of tensors",
        "tokens": [
          51420,
          689,
          382,
          6069,
          307,
          516,
          281,
          411,
          652,
          257,
          688,
          295,
          10688,
          830,
          51536
        ]
      },
      {
        "avg_logprob": -0.28033654830035043,
        "compression_ratio": 1.6371308016877637,
        "end": 6336.12,
        "id": 1976,
        "no_speech_prob": 0.00005144209717400372,
        "seek": 630912,
        "start": 6332.5599999999995,
        "temperature": 0,
        "text": " behind the scenes as well as model.fit.",
        "tokens": [
          51536,
          2261,
          264,
          8026,
          382,
          731,
          382,
          2316,
          13,
          6845,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.28033654830035043,
        "compression_ratio": 1.6371308016877637,
        "end": 6338.76,
        "id": 1977,
        "no_speech_prob": 0.00005144209717400372,
        "seek": 630912,
        "start": 6336.12,
        "temperature": 0,
        "text": " So I can use the tf.tidy function.",
        "tokens": [
          51714,
          407,
          286,
          393,
          764,
          264,
          256,
          69,
          13,
          83,
          38836,
          2445,
          13,
          51846
        ]
      },
      {
        "avg_logprob": -0.24615251628402013,
        "compression_ratio": 1.7551020408163265,
        "end": 6341.16,
        "id": 1978,
        "no_speech_prob": 0.000004860442004428478,
        "seek": 633876,
        "start": 6339.400000000001,
        "temperature": 0,
        "text": " So I'm going to say tf.tidy.",
        "tokens": [
          50396,
          407,
          286,
          478,
          516,
          281,
          584,
          256,
          69,
          13,
          83,
          38836,
          13,
          50484
        ]
      },
      {
        "avg_logprob": -0.24615251628402013,
        "compression_ratio": 1.7551020408163265,
        "end": 6343.96,
        "id": 1979,
        "no_speech_prob": 0.000004860442004428478,
        "seek": 633876,
        "start": 6342.12,
        "temperature": 0,
        "text": " And then I just need to,",
        "tokens": [
          50532,
          400,
          550,
          286,
          445,
          643,
          281,
          11,
          50624
        ]
      },
      {
        "avg_logprob": -0.24615251628402013,
        "compression_ratio": 1.7551020408163265,
        "end": 6346.56,
        "id": 1980,
        "no_speech_prob": 0.000004860442004428478,
        "seek": 633876,
        "start": 6343.96,
        "temperature": 0,
        "text": " I'm going to use the ES6 arrow notation,",
        "tokens": [
          50624,
          286,
          478,
          516,
          281,
          764,
          264,
          12564,
          21,
          11610,
          24657,
          11,
          50754
        ]
      },
      {
        "avg_logprob": -0.24615251628402013,
        "compression_ratio": 1.7551020408163265,
        "end": 6349.6,
        "id": 1981,
        "no_speech_prob": 0.000004860442004428478,
        "seek": 633876,
        "start": 6347.64,
        "temperature": 0,
        "text": " which you can watch my videos about what that is,",
        "tokens": [
          50808,
          597,
          291,
          393,
          1159,
          452,
          2145,
          466,
          437,
          300,
          307,
          11,
          50906
        ]
      },
      {
        "avg_logprob": -0.24615251628402013,
        "compression_ratio": 1.7551020408163265,
        "end": 6351.76,
        "id": 1982,
        "no_speech_prob": 0.000004860442004428478,
        "seek": 633876,
        "start": 6349.6,
        "temperature": 0,
        "text": " but I've kind of gone through what tidy is.",
        "tokens": [
          50906,
          457,
          286,
          600,
          733,
          295,
          2780,
          807,
          437,
          34646,
          307,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.24615251628402013,
        "compression_ratio": 1.7551020408163265,
        "end": 6354.6,
        "id": 1983,
        "no_speech_prob": 0.000004860442004428478,
        "seek": 633876,
        "start": 6351.76,
        "temperature": 0,
        "text": " Tidy says anything inside of this code,",
        "tokens": [
          51014,
          314,
          38836,
          1619,
          1340,
          1854,
          295,
          341,
          3089,
          11,
          51156
        ]
      },
      {
        "avg_logprob": -0.24615251628402013,
        "compression_ratio": 1.7551020408163265,
        "end": 6357.16,
        "id": 1984,
        "no_speech_prob": 0.000004860442004428478,
        "seek": 633876,
        "start": 6354.6,
        "temperature": 0,
        "text": " clean up the memory afterwards, basically.",
        "tokens": [
          51156,
          2541,
          493,
          264,
          4675,
          10543,
          11,
          1936,
          13,
          51284
        ]
      },
      {
        "avg_logprob": -0.24615251628402013,
        "compression_ratio": 1.7551020408163265,
        "end": 6358,
        "id": 1985,
        "no_speech_prob": 0.000004860442004428478,
        "seek": 633876,
        "start": 6357.16,
        "temperature": 0,
        "text": " And then I'm going to,",
        "tokens": [
          51284,
          400,
          550,
          286,
          478,
          516,
          281,
          11,
          51326
        ]
      },
      {
        "avg_logprob": -0.24615251628402013,
        "compression_ratio": 1.7551020408163265,
        "end": 6359.74,
        "id": 1986,
        "no_speech_prob": 0.000004860442004428478,
        "seek": 633876,
        "start": 6358,
        "temperature": 0,
        "text": " I probably could put this around everything,",
        "tokens": [
          51326,
          286,
          1391,
          727,
          829,
          341,
          926,
          1203,
          11,
          51413
        ]
      },
      {
        "avg_logprob": -0.24615251628402013,
        "compression_ratio": 1.7551020408163265,
        "end": 6362.24,
        "id": 1987,
        "no_speech_prob": 0.000004860442004428478,
        "seek": 633876,
        "start": 6359.74,
        "temperature": 0,
        "text": " but I just want to, and I don't need this stuff anymore.",
        "tokens": [
          51413,
          457,
          286,
          445,
          528,
          281,
          11,
          293,
          286,
          500,
          380,
          643,
          341,
          1507,
          3602,
          13,
          51538
        ]
      },
      {
        "avg_logprob": -0.24615251628402013,
        "compression_ratio": 1.7551020408163265,
        "end": 6365.46,
        "id": 1988,
        "no_speech_prob": 0.000004860442004428478,
        "seek": 633876,
        "start": 6362.24,
        "temperature": 0,
        "text": " I just want to keep these two areas separate",
        "tokens": [
          51538,
          286,
          445,
          528,
          281,
          1066,
          613,
          732,
          3179,
          4994,
          51699
        ]
      },
      {
        "avg_logprob": -0.24615251628402013,
        "compression_ratio": 1.7551020408163265,
        "end": 6366.56,
        "id": 1989,
        "no_speech_prob": 0.000004860442004428478,
        "seek": 633876,
        "start": 6365.46,
        "temperature": 0,
        "text": " because I think I'm going to,",
        "tokens": [
          51699,
          570,
          286,
          519,
          286,
          478,
          516,
          281,
          11,
          51754
        ]
      },
      {
        "avg_logprob": -0.24615251628402013,
        "compression_ratio": 1.7551020408163265,
        "end": 6368.68,
        "id": 1990,
        "no_speech_prob": 0.000004860442004428478,
        "seek": 633876,
        "start": 6366.56,
        "temperature": 0,
        "text": " at some point I really should change the way",
        "tokens": [
          51754,
          412,
          512,
          935,
          286,
          534,
          820,
          1319,
          264,
          636,
          51860
        ]
      },
      {
        "avg_logprob": -0.26494880252414277,
        "compression_ratio": 1.4540816326530612,
        "end": 6371.08,
        "id": 1991,
        "no_speech_prob": 0.00001260692260984797,
        "seek": 636868,
        "start": 6369.400000000001,
        "temperature": 0,
        "text": " the fitting of the model, excuse me,",
        "tokens": [
          50400,
          264,
          15669,
          295,
          264,
          2316,
          11,
          8960,
          385,
          11,
          50484
        ]
      },
      {
        "avg_logprob": -0.26494880252414277,
        "compression_ratio": 1.4540816326530612,
        "end": 6373.08,
        "id": 1992,
        "no_speech_prob": 0.00001260692260984797,
        "seek": 636868,
        "start": 6371.08,
        "temperature": 0,
        "text": " in draw is somewhat problematic.",
        "tokens": [
          50484,
          294,
          2642,
          307,
          8344,
          19011,
          13,
          50584
        ]
      },
      {
        "avg_logprob": -0.26494880252414277,
        "compression_ratio": 1.4540816326530612,
        "end": 6377.66,
        "id": 1993,
        "no_speech_prob": 0.00001260692260984797,
        "seek": 636868,
        "start": 6374.4400000000005,
        "temperature": 0,
        "text": " So now I'm going to just tidy all of this.",
        "tokens": [
          50652,
          407,
          586,
          286,
          478,
          516,
          281,
          445,
          34646,
          439,
          295,
          341,
          13,
          50813
        ]
      },
      {
        "avg_logprob": -0.26494880252414277,
        "compression_ratio": 1.4540816326530612,
        "end": 6380.9800000000005,
        "id": 1994,
        "no_speech_prob": 0.00001260692260984797,
        "seek": 636868,
        "start": 6379.240000000001,
        "temperature": 0,
        "text": " I think that's right.",
        "tokens": [
          50892,
          286,
          519,
          300,
          311,
          558,
          13,
          50979
        ]
      },
      {
        "avg_logprob": -0.26494880252414277,
        "compression_ratio": 1.4540816326530612,
        "end": 6384.320000000001,
        "id": 1995,
        "no_speech_prob": 0.00001260692260984797,
        "seek": 636868,
        "start": 6382.200000000001,
        "temperature": 0,
        "text": " Do I have an extra parentheses there?",
        "tokens": [
          51040,
          1144,
          286,
          362,
          364,
          2857,
          34153,
          456,
          30,
          51146
        ]
      },
      {
        "avg_logprob": -0.26494880252414277,
        "compression_ratio": 1.4540816326530612,
        "end": 6385.16,
        "id": 1996,
        "no_speech_prob": 0.00001260692260984797,
        "seek": 636868,
        "start": 6384.320000000001,
        "temperature": 0,
        "text": " Yes.",
        "tokens": [
          51146,
          1079,
          13,
          51188
        ]
      },
      {
        "avg_logprob": -0.26494880252414277,
        "compression_ratio": 1.4540816326530612,
        "end": 6389.8,
        "id": 1997,
        "no_speech_prob": 0.00001260692260984797,
        "seek": 636868,
        "start": 6385.16,
        "temperature": 0,
        "text": " Okay, so now let's run this again.",
        "tokens": [
          51188,
          1033,
          11,
          370,
          586,
          718,
          311,
          1190,
          341,
          797,
          13,
          51420
        ]
      },
      {
        "avg_logprob": -0.26494880252414277,
        "compression_ratio": 1.4540816326530612,
        "end": 6392.84,
        "id": 1998,
        "no_speech_prob": 0.00001260692260984797,
        "seek": 636868,
        "start": 6389.8,
        "temperature": 0,
        "text": " Let me comment out this console log.",
        "tokens": [
          51420,
          961,
          385,
          2871,
          484,
          341,
          11076,
          3565,
          13,
          51572
        ]
      },
      {
        "avg_logprob": -0.26494880252414277,
        "compression_ratio": 1.4540816326530612,
        "end": 6395.76,
        "id": 1999,
        "no_speech_prob": 0.00001260692260984797,
        "seek": 636868,
        "start": 6394,
        "temperature": 0,
        "text": " I don't want to see that right now.",
        "tokens": [
          51630,
          286,
          500,
          380,
          528,
          281,
          536,
          300,
          558,
          586,
          13,
          51718
        ]
      },
      {
        "avg_logprob": -0.2276487986246745,
        "compression_ratio": 1.6015325670498084,
        "end": 6399.72,
        "id": 2000,
        "no_speech_prob": 0.000019833343685604632,
        "seek": 639868,
        "start": 6398.88,
        "temperature": 0,
        "text": " Oh.",
        "tokens": [
          50374,
          876,
          13,
          50416
        ]
      },
      {
        "avg_logprob": -0.2276487986246745,
        "compression_ratio": 1.6015325670498084,
        "end": 6404.76,
        "id": 2001,
        "no_speech_prob": 0.000019833343685604632,
        "seek": 639868,
        "start": 6402.72,
        "temperature": 0,
        "text": " All right, now let's look at the number of tensors.",
        "tokens": [
          50566,
          1057,
          558,
          11,
          586,
          718,
          311,
          574,
          412,
          264,
          1230,
          295,
          10688,
          830,
          13,
          50668
        ]
      },
      {
        "avg_logprob": -0.2276487986246745,
        "compression_ratio": 1.6015325670498084,
        "end": 6406.56,
        "id": 2002,
        "no_speech_prob": 0.000019833343685604632,
        "seek": 639868,
        "start": 6404.76,
        "temperature": 0,
        "text": " 15, 15, 15.",
        "tokens": [
          50668,
          2119,
          11,
          2119,
          11,
          2119,
          13,
          50758
        ]
      },
      {
        "avg_logprob": -0.2276487986246745,
        "compression_ratio": 1.6015325670498084,
        "end": 6408.280000000001,
        "id": 2003,
        "no_speech_prob": 0.000019833343685604632,
        "seek": 639868,
        "start": 6406.56,
        "temperature": 0,
        "text": " So now I've gotten rid of the memory leak.",
        "tokens": [
          50758,
          407,
          586,
          286,
          600,
          5768,
          3973,
          295,
          264,
          4675,
          17143,
          13,
          50844
        ]
      },
      {
        "avg_logprob": -0.2276487986246745,
        "compression_ratio": 1.6015325670498084,
        "end": 6409.88,
        "id": 2004,
        "no_speech_prob": 0.000019833343685604632,
        "seek": 639868,
        "start": 6408.280000000001,
        "temperature": 0,
        "text": " Let's check out the frame rate.",
        "tokens": [
          50844,
          961,
          311,
          1520,
          484,
          264,
          3920,
          3314,
          13,
          50924
        ]
      },
      {
        "avg_logprob": -0.2276487986246745,
        "compression_ratio": 1.6015325670498084,
        "end": 6413.240000000001,
        "id": 2005,
        "no_speech_prob": 0.000019833343685604632,
        "seek": 639868,
        "start": 6412.12,
        "temperature": 0,
        "text": " 30 frames per second.",
        "tokens": [
          51036,
          2217,
          12083,
          680,
          1150,
          13,
          51092
        ]
      },
      {
        "avg_logprob": -0.2276487986246745,
        "compression_ratio": 1.6015325670498084,
        "end": 6414.240000000001,
        "id": 2006,
        "no_speech_prob": 0.000019833343685604632,
        "seek": 639868,
        "start": 6413.240000000001,
        "temperature": 0,
        "text": " So this is running for all.",
        "tokens": [
          51092,
          407,
          341,
          307,
          2614,
          337,
          439,
          13,
          51142
        ]
      },
      {
        "avg_logprob": -0.2276487986246745,
        "compression_ratio": 1.6015325670498084,
        "end": 6416.56,
        "id": 2007,
        "no_speech_prob": 0.000019833343685604632,
        "seek": 639868,
        "start": 6414.240000000001,
        "temperature": 0,
        "text": " Now, I just want to be able to look at what's happening",
        "tokens": [
          51142,
          823,
          11,
          286,
          445,
          528,
          281,
          312,
          1075,
          281,
          574,
          412,
          437,
          311,
          2737,
          51258
        ]
      },
      {
        "avg_logprob": -0.2276487986246745,
        "compression_ratio": 1.6015325670498084,
        "end": 6417.400000000001,
        "id": 2008,
        "no_speech_prob": 0.000019833343685604632,
        "seek": 639868,
        "start": 6416.56,
        "temperature": 0,
        "text": " a little bit better.",
        "tokens": [
          51258,
          257,
          707,
          857,
          1101,
          13,
          51300
        ]
      },
      {
        "avg_logprob": -0.2276487986246745,
        "compression_ratio": 1.6015325670498084,
        "end": 6419.320000000001,
        "id": 2009,
        "no_speech_prob": 0.000019833343685604632,
        "seek": 639868,
        "start": 6417.400000000001,
        "temperature": 0,
        "text": " So I'm actually going to draw the number",
        "tokens": [
          51300,
          407,
          286,
          478,
          767,
          516,
          281,
          2642,
          264,
          1230,
          51396
        ]
      },
      {
        "avg_logprob": -0.2276487986246745,
        "compression_ratio": 1.6015325670498084,
        "end": 6421.9800000000005,
        "id": 2010,
        "no_speech_prob": 0.000019833343685604632,
        "seek": 639868,
        "start": 6419.320000000001,
        "temperature": 0,
        "text": " of the output inside each one of these things.",
        "tokens": [
          51396,
          295,
          264,
          5598,
          1854,
          1184,
          472,
          295,
          613,
          721,
          13,
          51529
        ]
      },
      {
        "avg_logprob": -0.2276487986246745,
        "compression_ratio": 1.6015325670498084,
        "end": 6423.780000000001,
        "id": 2011,
        "no_speech_prob": 0.000019833343685604632,
        "seek": 639868,
        "start": 6422.9400000000005,
        "temperature": 0,
        "text": " So let's do that.",
        "tokens": [
          51577,
          407,
          718,
          311,
          360,
          300,
          13,
          51619
        ]
      },
      {
        "avg_logprob": -0.2276487986246745,
        "compression_ratio": 1.6015325670498084,
        "end": 6426.240000000001,
        "id": 2012,
        "no_speech_prob": 0.000019833343685604632,
        "seek": 639868,
        "start": 6423.780000000001,
        "temperature": 0,
        "text": " So where am I drawing the rectangles here?",
        "tokens": [
          51619,
          407,
          689,
          669,
          286,
          6316,
          264,
          24077,
          904,
          510,
          30,
          51742
        ]
      },
      {
        "avg_logprob": -0.29107774098714195,
        "compression_ratio": 1.7183908045977012,
        "end": 6431.24,
        "id": 2013,
        "no_speech_prob": 0.000004495175744523294,
        "seek": 642624,
        "start": 6426.24,
        "temperature": 0,
        "text": " I'm going to say let the brightness value equal this.",
        "tokens": [
          50364,
          286,
          478,
          516,
          281,
          584,
          718,
          264,
          21367,
          2158,
          2681,
          341,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.29107774098714195,
        "compression_ratio": 1.7183908045977012,
        "end": 6436.24,
        "id": 2014,
        "no_speech_prob": 0.000004495175744523294,
        "seek": 642624,
        "start": 6432.599999999999,
        "temperature": 0,
        "text": " And I'm going to fill the rectangle with that brightness.",
        "tokens": [
          50682,
          400,
          286,
          478,
          516,
          281,
          2836,
          264,
          21930,
          365,
          300,
          21367,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.29107774098714195,
        "compression_ratio": 1.7183908045977012,
        "end": 6438.5599999999995,
        "id": 2015,
        "no_speech_prob": 0.000004495175744523294,
        "seek": 642624,
        "start": 6436.24,
        "temperature": 0,
        "text": " And then I'm going to say fill 255,",
        "tokens": [
          50864,
          400,
          550,
          286,
          478,
          516,
          281,
          584,
          2836,
          3552,
          20,
          11,
          50980
        ]
      },
      {
        "avg_logprob": -0.29107774098714195,
        "compression_ratio": 1.7183908045977012,
        "end": 6440.36,
        "id": 2016,
        "no_speech_prob": 0.000004495175744523294,
        "seek": 642624,
        "start": 6438.5599999999995,
        "temperature": 0,
        "text": " mind it, like the inverse color.",
        "tokens": [
          50980,
          1575,
          309,
          11,
          411,
          264,
          17340,
          2017,
          13,
          51070
        ]
      },
      {
        "avg_logprob": -0.29107774098714195,
        "compression_ratio": 1.7183908045977012,
        "end": 6444.46,
        "id": 2017,
        "no_speech_prob": 0.000004495175744523294,
        "seek": 642624,
        "start": 6440.36,
        "temperature": 0,
        "text": " I'm going to say text, number format,",
        "tokens": [
          51070,
          286,
          478,
          516,
          281,
          584,
          2487,
          11,
          1230,
          7877,
          11,
          51275
        ]
      },
      {
        "avg_logprob": -0.29107774098714195,
        "compression_ratio": 1.7183908045977012,
        "end": 6449.46,
        "id": 2018,
        "no_speech_prob": 0.000004495175744523294,
        "seek": 642624,
        "start": 6444.46,
        "temperature": 0,
        "text": " the y values, index, with just two decimal places.",
        "tokens": [
          51275,
          264,
          288,
          4190,
          11,
          8186,
          11,
          365,
          445,
          732,
          26601,
          3190,
          13,
          51525
        ]
      },
      {
        "avg_logprob": -0.29107774098714195,
        "compression_ratio": 1.7183908045977012,
        "end": 6454.28,
        "id": 2019,
        "no_speech_prob": 0.000004495175744523294,
        "seek": 642624,
        "start": 6452.2,
        "temperature": 0,
        "text": " And I'm going to put that at,",
        "tokens": [
          51662,
          400,
          286,
          478,
          516,
          281,
          829,
          300,
          412,
          11,
          51766
        ]
      },
      {
        "avg_logprob": -0.22398234595937178,
        "compression_ratio": 1.8028169014084507,
        "end": 6456.96,
        "id": 2020,
        "no_speech_prob": 0.000018058506611851044,
        "seek": 645428,
        "start": 6455.16,
        "temperature": 0,
        "text": " boy, this is awkward.",
        "tokens": [
          50408,
          3237,
          11,
          341,
          307,
          11411,
          13,
          50498
        ]
      },
      {
        "avg_logprob": -0.22398234595937178,
        "compression_ratio": 1.8028169014084507,
        "end": 6458.28,
        "id": 2021,
        "no_speech_prob": 0.000018058506611851044,
        "seek": 645428,
        "start": 6456.96,
        "temperature": 0,
        "text": " The x values, this is going to be",
        "tokens": [
          50498,
          440,
          2031,
          4190,
          11,
          341,
          307,
          516,
          281,
          312,
          50564
        ]
      },
      {
        "avg_logprob": -0.22398234595937178,
        "compression_ratio": 1.8028169014084507,
        "end": 6461.5199999999995,
        "id": 2022,
        "no_speech_prob": 0.000018058506611851044,
        "seek": 645428,
        "start": 6458.28,
        "temperature": 0,
        "text": " i times resolution plus resolution divided by two.",
        "tokens": [
          50564,
          741,
          1413,
          8669,
          1804,
          8669,
          6666,
          538,
          732,
          13,
          50726
        ]
      },
      {
        "avg_logprob": -0.22398234595937178,
        "compression_ratio": 1.8028169014084507,
        "end": 6463.639999999999,
        "id": 2023,
        "no_speech_prob": 0.000018058506611851044,
        "seek": 645428,
        "start": 6461.5199999999995,
        "temperature": 0,
        "text": " I'm going to say text align center,",
        "tokens": [
          50726,
          286,
          478,
          516,
          281,
          584,
          2487,
          7975,
          3056,
          11,
          50832
        ]
      },
      {
        "avg_logprob": -0.22398234595937178,
        "compression_ratio": 1.8028169014084507,
        "end": 6468.639999999999,
        "id": 2024,
        "no_speech_prob": 0.000018058506611851044,
        "seek": 645428,
        "start": 6463.639999999999,
        "temperature": 0,
        "text": " text align center, comma, center.",
        "tokens": [
          50832,
          2487,
          7975,
          3056,
          11,
          22117,
          11,
          3056,
          13,
          51082
        ]
      },
      {
        "avg_logprob": -0.22398234595937178,
        "compression_ratio": 1.8028169014084507,
        "end": 6470.259999999999,
        "id": 2025,
        "no_speech_prob": 0.000018058506611851044,
        "seek": 645428,
        "start": 6468.84,
        "temperature": 0,
        "text": " And then I'm going to put the,",
        "tokens": [
          51092,
          400,
          550,
          286,
          478,
          516,
          281,
          829,
          264,
          11,
          51163
        ]
      },
      {
        "avg_logprob": -0.22398234595937178,
        "compression_ratio": 1.8028169014084507,
        "end": 6473.48,
        "id": 2026,
        "no_speech_prob": 0.000018058506611851044,
        "seek": 645428,
        "start": 6470.259999999999,
        "temperature": 0,
        "text": " I'm just going to draw in the center of the rectangle.",
        "tokens": [
          51163,
          286,
          478,
          445,
          516,
          281,
          2642,
          294,
          264,
          3056,
          295,
          264,
          21930,
          13,
          51324
        ]
      },
      {
        "avg_logprob": -0.22398234595937178,
        "compression_ratio": 1.8028169014084507,
        "end": 6477.48,
        "id": 2027,
        "no_speech_prob": 0.000018058506611851044,
        "seek": 645428,
        "start": 6474.8,
        "temperature": 0,
        "text": " And this should be j, the text.",
        "tokens": [
          51390,
          400,
          341,
          820,
          312,
          361,
          11,
          264,
          2487,
          13,
          51524
        ]
      },
      {
        "avg_logprob": -0.22398234595937178,
        "compression_ratio": 1.8028169014084507,
        "end": 6479.2,
        "id": 2028,
        "no_speech_prob": 0.000018058506611851044,
        "seek": 645428,
        "start": 6477.48,
        "temperature": 0,
        "text": " So let's see, let's do this now.",
        "tokens": [
          51524,
          407,
          718,
          311,
          536,
          11,
          718,
          311,
          360,
          341,
          586,
          13,
          51610
        ]
      },
      {
        "avg_logprob": -0.22398234595937178,
        "compression_ratio": 1.8028169014084507,
        "end": 6483.04,
        "id": 2029,
        "no_speech_prob": 0.000018058506611851044,
        "seek": 645428,
        "start": 6480.719999999999,
        "temperature": 0,
        "text": " So we can see, ooh, look, there's lots of numbers there.",
        "tokens": [
          51686,
          407,
          321,
          393,
          536,
          11,
          17024,
          11,
          574,
          11,
          456,
          311,
          3195,
          295,
          3547,
          456,
          13,
          51802
        ]
      },
      {
        "avg_logprob": -0.21664280187888224,
        "compression_ratio": 1.6099585062240664,
        "end": 6485.2,
        "id": 2030,
        "no_speech_prob": 0.000010616129657137208,
        "seek": 648304,
        "start": 6483.04,
        "temperature": 0,
        "text": " I think my number format thing didn't work.",
        "tokens": [
          50364,
          286,
          519,
          452,
          1230,
          7877,
          551,
          994,
          380,
          589,
          13,
          50472
        ]
      },
      {
        "avg_logprob": -0.21664280187888224,
        "compression_ratio": 1.6099585062240664,
        "end": 6492.22,
        "id": 2031,
        "no_speech_prob": 0.000010616129657137208,
        "seek": 648304,
        "start": 6487.88,
        "temperature": 0,
        "text": " One comma two, and let's use a lower resolution",
        "tokens": [
          50606,
          1485,
          22117,
          732,
          11,
          293,
          718,
          311,
          764,
          257,
          3126,
          8669,
          50823
        ]
      },
      {
        "avg_logprob": -0.21664280187888224,
        "compression_ratio": 1.6099585062240664,
        "end": 6493.68,
        "id": 2032,
        "no_speech_prob": 0.000010616129657137208,
        "seek": 648304,
        "start": 6492.22,
        "temperature": 0,
        "text": " just so I can see it better.",
        "tokens": [
          50823,
          445,
          370,
          286,
          393,
          536,
          309,
          1101,
          13,
          50896
        ]
      },
      {
        "avg_logprob": -0.21664280187888224,
        "compression_ratio": 1.6099585062240664,
        "end": 6496.72,
        "id": 2033,
        "no_speech_prob": 0.000010616129657137208,
        "seek": 648304,
        "start": 6495.88,
        "temperature": 0,
        "text": " There we go.",
        "tokens": [
          51006,
          821,
          321,
          352,
          13,
          51048
        ]
      },
      {
        "avg_logprob": -0.21664280187888224,
        "compression_ratio": 1.6099585062240664,
        "end": 6499.46,
        "id": 2034,
        "no_speech_prob": 0.000010616129657137208,
        "seek": 648304,
        "start": 6497.6,
        "temperature": 0,
        "text": " Now interestingly, I can't see the numbers,",
        "tokens": [
          51092,
          823,
          25873,
          11,
          286,
          393,
          380,
          536,
          264,
          3547,
          11,
          51185
        ]
      },
      {
        "avg_logprob": -0.21664280187888224,
        "compression_ratio": 1.6099585062240664,
        "end": 6500.96,
        "id": 2035,
        "no_speech_prob": 0.000010616129657137208,
        "seek": 648304,
        "start": 6499.46,
        "temperature": 0,
        "text": " but there they go, right?",
        "tokens": [
          51185,
          457,
          456,
          436,
          352,
          11,
          558,
          30,
          51260
        ]
      },
      {
        "avg_logprob": -0.21664280187888224,
        "compression_ratio": 1.6099585062240664,
        "end": 6502.84,
        "id": 2036,
        "no_speech_prob": 0.000010616129657137208,
        "seek": 648304,
        "start": 6500.96,
        "temperature": 0,
        "text": " You can see this is what it's getting,",
        "tokens": [
          51260,
          509,
          393,
          536,
          341,
          307,
          437,
          309,
          311,
          1242,
          11,
          51354
        ]
      },
      {
        "avg_logprob": -0.21664280187888224,
        "compression_ratio": 1.6099585062240664,
        "end": 6505.24,
        "id": 2037,
        "no_speech_prob": 0.000010616129657137208,
        "seek": 648304,
        "start": 6502.84,
        "temperature": 0,
        "text": " the output for each one of these.",
        "tokens": [
          51354,
          264,
          5598,
          337,
          1184,
          472,
          295,
          613,
          13,
          51474
        ]
      },
      {
        "avg_logprob": -0.21664280187888224,
        "compression_ratio": 1.6099585062240664,
        "end": 6507,
        "id": 2038,
        "no_speech_prob": 0.000010616129657137208,
        "seek": 648304,
        "start": 6505.24,
        "temperature": 0,
        "text": " And I want to look at the loss.",
        "tokens": [
          51474,
          400,
          286,
          528,
          281,
          574,
          412,
          264,
          4470,
          13,
          51562
        ]
      },
      {
        "avg_logprob": -0.21664280187888224,
        "compression_ratio": 1.6099585062240664,
        "end": 6510.04,
        "id": 2039,
        "no_speech_prob": 0.000010616129657137208,
        "seek": 648304,
        "start": 6507,
        "temperature": 0,
        "text": " You can see, ah, because it's just going so slow.",
        "tokens": [
          51562,
          509,
          393,
          536,
          11,
          3716,
          11,
          570,
          309,
          311,
          445,
          516,
          370,
          2964,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.21664280187888224,
        "compression_ratio": 1.6099585062240664,
        "end": 6511.6,
        "id": 2040,
        "no_speech_prob": 0.000010616129657137208,
        "seek": 648304,
        "start": 6510.04,
        "temperature": 0,
        "text": " It's getting a little better.",
        "tokens": [
          51714,
          467,
          311,
          1242,
          257,
          707,
          1101,
          13,
          51792
        ]
      },
      {
        "avg_logprob": -0.25211900358746764,
        "compression_ratio": 1.7307692307692308,
        "end": 6513.72,
        "id": 2041,
        "no_speech_prob": 0.00009314566705143079,
        "seek": 651160,
        "start": 6511.64,
        "temperature": 0,
        "text": " It's getting a little bit better.",
        "tokens": [
          50366,
          467,
          311,
          1242,
          257,
          707,
          857,
          1101,
          13,
          50470
        ]
      },
      {
        "avg_logprob": -0.25211900358746764,
        "compression_ratio": 1.7307692307692308,
        "end": 6516.52,
        "id": 2042,
        "no_speech_prob": 0.00009314566705143079,
        "seek": 651160,
        "start": 6513.72,
        "temperature": 0,
        "text": " So over time, it's getting a little better,",
        "tokens": [
          50470,
          407,
          670,
          565,
          11,
          309,
          311,
          1242,
          257,
          707,
          1101,
          11,
          50610
        ]
      },
      {
        "avg_logprob": -0.25211900358746764,
        "compression_ratio": 1.7307692307692308,
        "end": 6519.04,
        "id": 2043,
        "no_speech_prob": 0.00009314566705143079,
        "seek": 651160,
        "start": 6516.52,
        "temperature": 0,
        "text": " but I really want to see it train much faster.",
        "tokens": [
          50610,
          457,
          286,
          534,
          528,
          281,
          536,
          309,
          3847,
          709,
          4663,
          13,
          50736
        ]
      },
      {
        "avg_logprob": -0.25211900358746764,
        "compression_ratio": 1.7307692307692308,
        "end": 6520.84,
        "id": 2044,
        "no_speech_prob": 0.00009314566705143079,
        "seek": 651160,
        "start": 6519.04,
        "temperature": 0,
        "text": " So let me see, I have one idea,",
        "tokens": [
          50736,
          407,
          718,
          385,
          536,
          11,
          286,
          362,
          472,
          1558,
          11,
          50826
        ]
      },
      {
        "avg_logprob": -0.25211900358746764,
        "compression_ratio": 1.7307692307692308,
        "end": 6522.280000000001,
        "id": 2045,
        "no_speech_prob": 0.00009314566705143079,
        "seek": 651160,
        "start": 6520.84,
        "temperature": 0,
        "text": " one last thing I can add to this,",
        "tokens": [
          50826,
          472,
          1036,
          551,
          286,
          393,
          909,
          281,
          341,
          11,
          50898
        ]
      },
      {
        "avg_logprob": -0.25211900358746764,
        "compression_ratio": 1.7307692307692308,
        "end": 6524,
        "id": 2046,
        "no_speech_prob": 0.00009314566705143079,
        "seek": 651160,
        "start": 6522.280000000001,
        "temperature": 0,
        "text": " even though I, and I have some suggestions",
        "tokens": [
          50898,
          754,
          1673,
          286,
          11,
          293,
          286,
          362,
          512,
          13396,
          50984
        ]
      },
      {
        "avg_logprob": -0.25211900358746764,
        "compression_ratio": 1.7307692307692308,
        "end": 6525.160000000001,
        "id": 2047,
        "no_speech_prob": 0.00009314566705143079,
        "seek": 651160,
        "start": 6524,
        "temperature": 0,
        "text": " for what you might do next.",
        "tokens": [
          50984,
          337,
          437,
          291,
          1062,
          360,
          958,
          13,
          51042
        ]
      },
      {
        "avg_logprob": -0.25211900358746764,
        "compression_ratio": 1.7307692307692308,
        "end": 6527.280000000001,
        "id": 2048,
        "no_speech_prob": 0.00009314566705143079,
        "seek": 651160,
        "start": 6525.160000000001,
        "temperature": 0,
        "text": " But you can see, ah, the numbers are starting to appear.",
        "tokens": [
          51042,
          583,
          291,
          393,
          536,
          11,
          3716,
          11,
          264,
          3547,
          366,
          2891,
          281,
          4204,
          13,
          51148
        ]
      },
      {
        "avg_logprob": -0.25211900358746764,
        "compression_ratio": 1.7307692307692308,
        "end": 6528.4400000000005,
        "id": 2049,
        "no_speech_prob": 0.00009314566705143079,
        "seek": 651160,
        "start": 6527.280000000001,
        "temperature": 0,
        "text": " Lovely.",
        "tokens": [
          51148,
          33925,
          13,
          51206
        ]
      },
      {
        "avg_logprob": -0.25211900358746764,
        "compression_ratio": 1.7307692307692308,
        "end": 6531,
        "id": 2050,
        "no_speech_prob": 0.00009314566705143079,
        "seek": 651160,
        "start": 6528.4400000000005,
        "temperature": 0,
        "text": " Because I forgot when it's gray, when it's at.5,",
        "tokens": [
          51206,
          1436,
          286,
          5298,
          562,
          309,
          311,
          10855,
          11,
          562,
          309,
          311,
          412,
          2411,
          20,
          11,
          51334
        ]
      },
      {
        "avg_logprob": -0.25211900358746764,
        "compression_ratio": 1.7307692307692308,
        "end": 6533.6,
        "id": 2051,
        "no_speech_prob": 0.00009314566705143079,
        "seek": 651160,
        "start": 6531,
        "temperature": 0,
        "text": " 255 minus.5, it's going to be the same color,",
        "tokens": [
          51334,
          3552,
          20,
          3175,
          2411,
          20,
          11,
          309,
          311,
          516,
          281,
          312,
          264,
          912,
          2017,
          11,
          51464
        ]
      },
      {
        "avg_logprob": -0.25211900358746764,
        "compression_ratio": 1.7307692307692308,
        "end": 6535.3,
        "id": 2052,
        "no_speech_prob": 0.00009314566705143079,
        "seek": 651160,
        "start": 6533.6,
        "temperature": 0,
        "text": " but I kind of like that effect.",
        "tokens": [
          51464,
          457,
          286,
          733,
          295,
          411,
          300,
          1802,
          13,
          51549
        ]
      },
      {
        "avg_logprob": -0.25211900358746764,
        "compression_ratio": 1.7307692307692308,
        "end": 6539.200000000001,
        "id": 2053,
        "no_speech_prob": 0.00009314566705143079,
        "seek": 651160,
        "start": 6535.3,
        "temperature": 0,
        "text": " So what I want to do is what happens here",
        "tokens": [
          51549,
          407,
          437,
          286,
          528,
          281,
          360,
          307,
          437,
          2314,
          510,
          51744
        ]
      },
      {
        "avg_logprob": -0.25465432890168915,
        "compression_ratio": 1.5238095238095237,
        "end": 6544.099999999999,
        "id": 2054,
        "no_speech_prob": 0.000012411477655405179,
        "seek": 653920,
        "start": 6539.2,
        "temperature": 0,
        "text": " if I actually give it, tell it, don't just do it once.",
        "tokens": [
          50364,
          498,
          286,
          767,
          976,
          309,
          11,
          980,
          309,
          11,
          500,
          380,
          445,
          360,
          309,
          1564,
          13,
          50609
        ]
      },
      {
        "avg_logprob": -0.25465432890168915,
        "compression_ratio": 1.5238095238095237,
        "end": 6549.84,
        "id": 2055,
        "no_speech_prob": 0.000012411477655405179,
        "seek": 653920,
        "start": 6545.599999999999,
        "temperature": 0,
        "text": " Like do it 10 times, do 10 epochs per cycle of fitting.",
        "tokens": [
          50684,
          1743,
          360,
          309,
          1266,
          1413,
          11,
          360,
          1266,
          30992,
          28346,
          680,
          6586,
          295,
          15669,
          13,
          50896
        ]
      },
      {
        "avg_logprob": -0.25465432890168915,
        "compression_ratio": 1.5238095238095237,
        "end": 6553.58,
        "id": 2056,
        "no_speech_prob": 0.000012411477655405179,
        "seek": 653920,
        "start": 6552.28,
        "temperature": 0,
        "text": " Let me run this again.",
        "tokens": [
          51018,
          961,
          385,
          1190,
          341,
          797,
          13,
          51083
        ]
      },
      {
        "avg_logprob": -0.25465432890168915,
        "compression_ratio": 1.5238095238095237,
        "end": 6558.72,
        "id": 2057,
        "no_speech_prob": 0.000012411477655405179,
        "seek": 653920,
        "start": 6555.44,
        "temperature": 0,
        "text": " And let me look at the, let's actually have the loss",
        "tokens": [
          51176,
          400,
          718,
          385,
          574,
          412,
          264,
          11,
          718,
          311,
          767,
          362,
          264,
          4470,
          51340
        ]
      },
      {
        "avg_logprob": -0.25465432890168915,
        "compression_ratio": 1.5238095238095237,
        "end": 6560.2,
        "id": 2058,
        "no_speech_prob": 0.000012411477655405179,
        "seek": 653920,
        "start": 6558.72,
        "temperature": 0,
        "text": " continue to print out.",
        "tokens": [
          51340,
          2354,
          281,
          4482,
          484,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.25465432890168915,
        "compression_ratio": 1.5238095238095237,
        "end": 6563.5599999999995,
        "id": 2059,
        "no_speech_prob": 0.000012411477655405179,
        "seek": 653920,
        "start": 6561.36,
        "temperature": 0,
        "text": " And there we go.",
        "tokens": [
          51472,
          400,
          456,
          321,
          352,
          13,
          51582
        ]
      },
      {
        "avg_logprob": -0.25465432890168915,
        "compression_ratio": 1.5238095238095237,
        "end": 6566.34,
        "id": 2060,
        "no_speech_prob": 0.000012411477655405179,
        "seek": 653920,
        "start": 6565,
        "temperature": 0,
        "text": " Still running pretty fast.",
        "tokens": [
          51654,
          8291,
          2614,
          1238,
          2370,
          13,
          51721
        ]
      },
      {
        "avg_logprob": -0.25465432890168915,
        "compression_ratio": 1.5238095238095237,
        "end": 6567.84,
        "id": 2061,
        "no_speech_prob": 0.000012411477655405179,
        "seek": 653920,
        "start": 6566.34,
        "temperature": 0,
        "text": " You can see the loss is going down",
        "tokens": [
          51721,
          509,
          393,
          536,
          264,
          4470,
          307,
          516,
          760,
          51796
        ]
      },
      {
        "avg_logprob": -0.22042739050728935,
        "compression_ratio": 1.7142857142857142,
        "end": 6572.04,
        "id": 2062,
        "no_speech_prob": 0.00006108838715590537,
        "seek": 656784,
        "start": 6568,
        "temperature": 0,
        "text": " and relatively quickly I am getting myself",
        "tokens": [
          50372,
          293,
          7226,
          2661,
          286,
          669,
          1242,
          2059,
          50574
        ]
      },
      {
        "avg_logprob": -0.22042739050728935,
        "compression_ratio": 1.7142857142857142,
        "end": 6574.04,
        "id": 2063,
        "no_speech_prob": 0.00006108838715590537,
        "seek": 656784,
        "start": 6572.04,
        "temperature": 0,
        "text": " to the point where I'm starting to see,",
        "tokens": [
          50574,
          281,
          264,
          935,
          689,
          286,
          478,
          2891,
          281,
          536,
          11,
          50674
        ]
      },
      {
        "avg_logprob": -0.22042739050728935,
        "compression_ratio": 1.7142857142857142,
        "end": 6575.4400000000005,
        "id": 2064,
        "no_speech_prob": 0.00006108838715590537,
        "seek": 656784,
        "start": 6574.04,
        "temperature": 0,
        "text": " this is definitely all the way,",
        "tokens": [
          50674,
          341,
          307,
          2138,
          439,
          264,
          636,
          11,
          50744
        ]
      },
      {
        "avg_logprob": -0.22042739050728935,
        "compression_ratio": 1.7142857142857142,
        "end": 6577.3,
        "id": 2065,
        "no_speech_prob": 0.00006108838715590537,
        "seek": 656784,
        "start": 6575.4400000000005,
        "temperature": 0,
        "text": " getting all the way down to zero there.",
        "tokens": [
          50744,
          1242,
          439,
          264,
          636,
          760,
          281,
          4018,
          456,
          13,
          50837
        ]
      },
      {
        "avg_logprob": -0.22042739050728935,
        "compression_ratio": 1.7142857142857142,
        "end": 6578.96,
        "id": 2066,
        "no_speech_prob": 0.00006108838715590537,
        "seek": 656784,
        "start": 6577.3,
        "temperature": 0,
        "text": " This is getting way up to one there.",
        "tokens": [
          50837,
          639,
          307,
          1242,
          636,
          493,
          281,
          472,
          456,
          13,
          50920
        ]
      },
      {
        "avg_logprob": -0.22042739050728935,
        "compression_ratio": 1.7142857142857142,
        "end": 6580.02,
        "id": 2067,
        "no_speech_prob": 0.00006108838715590537,
        "seek": 656784,
        "start": 6578.96,
        "temperature": 0,
        "text": " It's getting a little bit stuck.",
        "tokens": [
          50920,
          467,
          311,
          1242,
          257,
          707,
          857,
          5541,
          13,
          50973
        ]
      },
      {
        "avg_logprob": -0.22042739050728935,
        "compression_ratio": 1.7142857142857142,
        "end": 6582.18,
        "id": 2068,
        "no_speech_prob": 0.00006108838715590537,
        "seek": 656784,
        "start": 6580.02,
        "temperature": 0,
        "text": " It's having trouble with this side.",
        "tokens": [
          50973,
          467,
          311,
          1419,
          5253,
          365,
          341,
          1252,
          13,
          51081
        ]
      },
      {
        "avg_logprob": -0.22042739050728935,
        "compression_ratio": 1.7142857142857142,
        "end": 6583.72,
        "id": 2069,
        "no_speech_prob": 0.00006108838715590537,
        "seek": 656784,
        "start": 6582.18,
        "temperature": 0,
        "text": " I imagine it'll get there eventually.",
        "tokens": [
          51081,
          286,
          3811,
          309,
          603,
          483,
          456,
          4728,
          13,
          51158
        ]
      },
      {
        "avg_logprob": -0.22042739050728935,
        "compression_ratio": 1.7142857142857142,
        "end": 6585.24,
        "id": 2070,
        "no_speech_prob": 0.00006108838715590537,
        "seek": 656784,
        "start": 6583.72,
        "temperature": 0,
        "text": " We could do some fun stuff.",
        "tokens": [
          51158,
          492,
          727,
          360,
          512,
          1019,
          1507,
          13,
          51234
        ]
      },
      {
        "avg_logprob": -0.22042739050728935,
        "compression_ratio": 1.7142857142857142,
        "end": 6587.64,
        "id": 2071,
        "no_speech_prob": 0.00006108838715590537,
        "seek": 656784,
        "start": 6585.24,
        "temperature": 0,
        "text": " For example, I'm going to just let it have,",
        "tokens": [
          51234,
          1171,
          1365,
          11,
          286,
          478,
          516,
          281,
          445,
          718,
          309,
          362,
          11,
          51354
        ]
      },
      {
        "avg_logprob": -0.22042739050728935,
        "compression_ratio": 1.7142857142857142,
        "end": 6589.2,
        "id": 2072,
        "no_speech_prob": 0.00006108838715590537,
        "seek": 656784,
        "start": 6587.64,
        "temperature": 0,
        "text": " it's totally unnecessary,",
        "tokens": [
          51354,
          309,
          311,
          3879,
          19350,
          11,
          51432
        ]
      },
      {
        "avg_logprob": -0.22042739050728935,
        "compression_ratio": 1.7142857142857142,
        "end": 6593.16,
        "id": 2073,
        "no_speech_prob": 0.00006108838715590537,
        "seek": 656784,
        "start": 6589.2,
        "temperature": 0,
        "text": " but I'm going to give it four hidden nodes",
        "tokens": [
          51432,
          457,
          286,
          478,
          516,
          281,
          976,
          309,
          1451,
          7633,
          13891,
          51630
        ]
      },
      {
        "avg_logprob": -0.22042739050728935,
        "compression_ratio": 1.7142857142857142,
        "end": 6596.96,
        "id": 2074,
        "no_speech_prob": 0.00006108838715590537,
        "seek": 656784,
        "start": 6593.16,
        "temperature": 0,
        "text": " and I'm also going to put the resolution back to 25.",
        "tokens": [
          51630,
          293,
          286,
          478,
          611,
          516,
          281,
          829,
          264,
          8669,
          646,
          281,
          3552,
          13,
          51820
        ]
      },
      {
        "avg_logprob": -0.25509683187905846,
        "compression_ratio": 1.39375,
        "end": 6599.6,
        "id": 2075,
        "no_speech_prob": 5.122890911479772e-7,
        "seek": 659784,
        "start": 6598.04,
        "temperature": 0,
        "text": " And let's run this again.",
        "tokens": [
          50374,
          400,
          718,
          311,
          1190,
          341,
          797,
          13,
          50452
        ]
      },
      {
        "avg_logprob": -0.25509683187905846,
        "compression_ratio": 1.39375,
        "end": 6603.2,
        "id": 2076,
        "no_speech_prob": 5.122890911479772e-7,
        "seek": 659784,
        "start": 6601.16,
        "temperature": 0,
        "text": " And let's see how this goes.",
        "tokens": [
          50530,
          400,
          718,
          311,
          536,
          577,
          341,
          1709,
          13,
          50632
        ]
      },
      {
        "avg_logprob": -0.25509683187905846,
        "compression_ratio": 1.39375,
        "end": 6604.6,
        "id": 2077,
        "no_speech_prob": 5.122890911479772e-7,
        "seek": 659784,
        "start": 6603.2,
        "temperature": 0,
        "text": " So I'll give it a minute, I'll come back.",
        "tokens": [
          50632,
          407,
          286,
          603,
          976,
          309,
          257,
          3456,
          11,
          286,
          603,
          808,
          646,
          13,
          50702
        ]
      },
      {
        "avg_logprob": -0.25509683187905846,
        "compression_ratio": 1.39375,
        "end": 6606.7,
        "id": 2078,
        "no_speech_prob": 5.122890911479772e-7,
        "seek": 659784,
        "start": 6604.6,
        "temperature": 0,
        "text": " Oh, the font is too big.",
        "tokens": [
          50702,
          876,
          11,
          264,
          10703,
          307,
          886,
          955,
          13,
          50807
        ]
      },
      {
        "avg_logprob": -0.25509683187905846,
        "compression_ratio": 1.39375,
        "end": 6613.92,
        "id": 2079,
        "no_speech_prob": 5.122890911479772e-7,
        "seek": 659784,
        "start": 6612.02,
        "temperature": 0,
        "text": " But you can see it's learning pretty quickly right now.",
        "tokens": [
          51073,
          583,
          291,
          393,
          536,
          309,
          311,
          2539,
          1238,
          2661,
          558,
          586,
          13,
          51168
        ]
      },
      {
        "avg_logprob": -0.25509683187905846,
        "compression_ratio": 1.39375,
        "end": 6614.76,
        "id": 2080,
        "no_speech_prob": 5.122890911479772e-7,
        "seek": 659784,
        "start": 6613.92,
        "temperature": 0,
        "text": " Hold on.",
        "tokens": [
          51168,
          6962,
          322,
          13,
          51210
        ]
      },
      {
        "avg_logprob": -0.25509683187905846,
        "compression_ratio": 1.39375,
        "end": 6622.02,
        "id": 2081,
        "no_speech_prob": 5.122890911479772e-7,
        "seek": 659784,
        "start": 6620.04,
        "temperature": 0,
        "text": " Well, let me go back, do that again.",
        "tokens": [
          51474,
          1042,
          11,
          718,
          385,
          352,
          646,
          11,
          360,
          300,
          797,
          13,
          51573
        ]
      },
      {
        "avg_logprob": -0.30384104410807294,
        "compression_ratio": 1.420731707317073,
        "end": 6631.4400000000005,
        "id": 2082,
        "no_speech_prob": 0.00003705290146172047,
        "seek": 662784,
        "start": 6628.68,
        "temperature": 0,
        "text": " So I'm going to give it, for no real reason at all,",
        "tokens": [
          50406,
          407,
          286,
          478,
          516,
          281,
          976,
          309,
          11,
          337,
          572,
          957,
          1778,
          412,
          439,
          11,
          50544
        ]
      },
      {
        "avg_logprob": -0.30384104410807294,
        "compression_ratio": 1.420731707317073,
        "end": 6633.92,
        "id": 2083,
        "no_speech_prob": 0.00003705290146172047,
        "seek": 662784,
        "start": 6631.4400000000005,
        "temperature": 0,
        "text": " but just for fun, four hidden nodes.",
        "tokens": [
          50544,
          457,
          445,
          337,
          1019,
          11,
          1451,
          7633,
          13891,
          13,
          50668
        ]
      },
      {
        "avg_logprob": -0.30384104410807294,
        "compression_ratio": 1.420731707317073,
        "end": 6637.4400000000005,
        "id": 2084,
        "no_speech_prob": 0.00003705290146172047,
        "seek": 662784,
        "start": 6633.92,
        "temperature": 0,
        "text": " And I'm also going to, let me change the resolution to 25.",
        "tokens": [
          50668,
          400,
          286,
          478,
          611,
          516,
          281,
          11,
          718,
          385,
          1319,
          264,
          8669,
          281,
          3552,
          13,
          50844
        ]
      },
      {
        "avg_logprob": -0.30384104410807294,
        "compression_ratio": 1.420731707317073,
        "end": 6642.4400000000005,
        "id": 2085,
        "no_speech_prob": 0.00003705290146172047,
        "seek": 662784,
        "start": 6637.4400000000005,
        "temperature": 0,
        "text": " Let me make the text size something like eight point.",
        "tokens": [
          50844,
          961,
          385,
          652,
          264,
          2487,
          2744,
          746,
          411,
          3180,
          935,
          13,
          51094
        ]
      },
      {
        "avg_logprob": -0.30384104410807294,
        "compression_ratio": 1.420731707317073,
        "end": 6646.56,
        "id": 2086,
        "no_speech_prob": 0.00003705290146172047,
        "seek": 662784,
        "start": 6644.32,
        "temperature": 0,
        "text": " And let me, whoops.",
        "tokens": [
          51188,
          400,
          718,
          385,
          11,
          567,
          3370,
          13,
          51300
        ]
      },
      {
        "avg_logprob": -0.30384104410807294,
        "compression_ratio": 1.420731707317073,
        "end": 6650.4800000000005,
        "id": 2087,
        "no_speech_prob": 0.00003705290146172047,
        "seek": 662784,
        "start": 6649.52,
        "temperature": 0,
        "text": " Refresh it.",
        "tokens": [
          51448,
          16957,
          3644,
          309,
          13,
          51496
        ]
      },
      {
        "avg_logprob": -0.5140510241190592,
        "compression_ratio": 1.221311475409836,
        "end": 6651.5599999999995,
        "id": 2088,
        "no_speech_prob": 0.0018101613968610764,
        "seek": 665048,
        "start": 6650.48,
        "temperature": 0,
        "text": " Oh, I'm sorry.",
        "tokens": [
          50364,
          876,
          11,
          286,
          478,
          2597,
          13,
          50418
        ]
      },
      {
        "avg_logprob": -0.5140510241190592,
        "compression_ratio": 1.221311475409836,
        "end": 6657.799999999999,
        "id": 2089,
        "no_speech_prob": 0.0018101613968610764,
        "seek": 665048,
        "start": 6656.5599999999995,
        "temperature": 0,
        "text": " Why did it, um.",
        "tokens": [
          50668,
          1545,
          630,
          309,
          11,
          1105,
          13,
          50730
        ]
      },
      {
        "avg_logprob": -0.5140510241190592,
        "compression_ratio": 1.221311475409836,
        "end": 6671.5199999999995,
        "id": 2090,
        "no_speech_prob": 0.0018101613968610764,
        "seek": 665048,
        "start": 6670.679999999999,
        "temperature": 0,
        "text": " Yeah, I want to.",
        "tokens": [
          51374,
          865,
          11,
          286,
          528,
          281,
          13,
          51416
        ]
      },
      {
        "avg_logprob": -0.5140510241190592,
        "compression_ratio": 1.221311475409836,
        "end": 6676.08,
        "id": 2091,
        "no_speech_prob": 0.0018101613968610764,
        "seek": 665048,
        "start": 6674.679999999999,
        "temperature": 0,
        "text": " All right, I let this run for a bit",
        "tokens": [
          51574,
          1057,
          558,
          11,
          286,
          718,
          341,
          1190,
          337,
          257,
          857,
          51644
        ]
      },
      {
        "avg_logprob": -0.5140510241190592,
        "compression_ratio": 1.221311475409836,
        "end": 6677.48,
        "id": 2092,
        "no_speech_prob": 0.0018101613968610764,
        "seek": 665048,
        "start": 6676.08,
        "temperature": 0,
        "text": " and you can kind of see here.",
        "tokens": [
          51644,
          293,
          291,
          393,
          733,
          295,
          536,
          510,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.5140510241190592,
        "compression_ratio": 1.221311475409836,
        "end": 6679.4,
        "id": 2093,
        "no_speech_prob": 0.0018101613968610764,
        "seek": 665048,
        "start": 6677.48,
        "temperature": 0,
        "text": " Now you can see all the XOR values.",
        "tokens": [
          51714,
          823,
          291,
          393,
          536,
          439,
          264,
          1783,
          2483,
          4190,
          13,
          51810
        ]
      },
      {
        "avg_logprob": -0.21214876419458634,
        "compression_ratio": 1.6164383561643836,
        "end": 6681.04,
        "id": 2094,
        "no_speech_prob": 0.00009170184785034508,
        "seek": 667940,
        "start": 6679.4,
        "temperature": 0,
        "text": " Here's a nice, beautiful little map,",
        "tokens": [
          50364,
          1692,
          311,
          257,
          1481,
          11,
          2238,
          707,
          4471,
          11,
          50446
        ]
      },
      {
        "avg_logprob": -0.21214876419458634,
        "compression_ratio": 1.6164383561643836,
        "end": 6682.5599999999995,
        "id": 2095,
        "no_speech_prob": 0.00009170184785034508,
        "seek": 667940,
        "start": 6681.04,
        "temperature": 0,
        "text": " grayscale map of all XOR.",
        "tokens": [
          50446,
          677,
          3772,
          37088,
          4471,
          295,
          439,
          1783,
          2483,
          13,
          50522
        ]
      },
      {
        "avg_logprob": -0.21214876419458634,
        "compression_ratio": 1.6164383561643836,
        "end": 6684.639999999999,
        "id": 2096,
        "no_speech_prob": 0.00009170184785034508,
        "seek": 667940,
        "start": 6682.5599999999995,
        "temperature": 0,
        "text": " It's getting all the way up to true",
        "tokens": [
          50522,
          467,
          311,
          1242,
          439,
          264,
          636,
          493,
          281,
          2074,
          50626
        ]
      },
      {
        "avg_logprob": -0.21214876419458634,
        "compression_ratio": 1.6164383561643836,
        "end": 6687.839999999999,
        "id": 2097,
        "no_speech_prob": 0.00009170184785034508,
        "seek": 667940,
        "start": 6684.639999999999,
        "temperature": 0,
        "text": " and all the way down to zero at the corners.",
        "tokens": [
          50626,
          293,
          439,
          264,
          636,
          760,
          281,
          4018,
          412,
          264,
          12413,
          13,
          50786
        ]
      },
      {
        "avg_logprob": -0.21214876419458634,
        "compression_ratio": 1.6164383561643836,
        "end": 6688.679999999999,
        "id": 2098,
        "no_speech_prob": 0.00009170184785034508,
        "seek": 667940,
        "start": 6687.839999999999,
        "temperature": 0,
        "text": " This is pretty good.",
        "tokens": [
          50786,
          639,
          307,
          1238,
          665,
          13,
          50828
        ]
      },
      {
        "avg_logprob": -0.21214876419458634,
        "compression_ratio": 1.6164383561643836,
        "end": 6691.639999999999,
        "id": 2099,
        "no_speech_prob": 0.00009170184785034508,
        "seek": 667940,
        "start": 6688.679999999999,
        "temperature": 0,
        "text": " So, and this is running at,",
        "tokens": [
          50828,
          407,
          11,
          293,
          341,
          307,
          2614,
          412,
          11,
          50976
        ]
      },
      {
        "avg_logprob": -0.21214876419458634,
        "compression_ratio": 1.6164383561643836,
        "end": 6694.639999999999,
        "id": 2100,
        "no_speech_prob": 0.00009170184785034508,
        "seek": 667940,
        "start": 6691.639999999999,
        "temperature": 0,
        "text": " if I take out this console log,",
        "tokens": [
          50976,
          498,
          286,
          747,
          484,
          341,
          11076,
          3565,
          11,
          51126
        ]
      },
      {
        "avg_logprob": -0.21214876419458634,
        "compression_ratio": 1.6164383561643836,
        "end": 6701.719999999999,
        "id": 2101,
        "no_speech_prob": 0.00009170184785034508,
        "seek": 667940,
        "start": 6696.799999999999,
        "temperature": 0,
        "text": " I can now take a look at the frame rate.",
        "tokens": [
          51234,
          286,
          393,
          586,
          747,
          257,
          574,
          412,
          264,
          3920,
          3314,
          13,
          51480
        ]
      },
      {
        "avg_logprob": -0.21214876419458634,
        "compression_ratio": 1.6164383561643836,
        "end": 6703.679999999999,
        "id": 2102,
        "no_speech_prob": 0.00009170184785034508,
        "seek": 667940,
        "start": 6701.719999999999,
        "temperature": 0,
        "text": " It's running kind of slow.",
        "tokens": [
          51480,
          467,
          311,
          2614,
          733,
          295,
          2964,
          13,
          51578
        ]
      },
      {
        "avg_logprob": -0.21214876419458634,
        "compression_ratio": 1.6164383561643836,
        "end": 6704.679999999999,
        "id": 2103,
        "no_speech_prob": 0.00009170184785034508,
        "seek": 667940,
        "start": 6703.679999999999,
        "temperature": 0,
        "text": " So here's the thing.",
        "tokens": [
          51578,
          407,
          510,
          311,
          264,
          551,
          13,
          51628
        ]
      },
      {
        "avg_logprob": -0.21214876419458634,
        "compression_ratio": 1.6164383561643836,
        "end": 6708.28,
        "id": 2104,
        "no_speech_prob": 0.00009170184785034508,
        "seek": 667940,
        "start": 6704.679999999999,
        "temperature": 0,
        "text": " I have done something that I don't like,",
        "tokens": [
          51628,
          286,
          362,
          1096,
          746,
          300,
          286,
          500,
          380,
          411,
          11,
          51808
        ]
      },
      {
        "avg_logprob": -0.3025771431300951,
        "compression_ratio": 1.5704225352112675,
        "end": 6713.28,
        "id": 2105,
        "no_speech_prob": 0.00000729637167751207,
        "seek": 670828,
        "start": 6708.28,
        "temperature": 0,
        "text": " which is this train model is being called inside draw.",
        "tokens": [
          50364,
          597,
          307,
          341,
          3847,
          2316,
          307,
          885,
          1219,
          1854,
          2642,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.3025771431300951,
        "compression_ratio": 1.5704225352112675,
        "end": 6717.639999999999,
        "id": 2106,
        "no_speech_prob": 0.00000729637167751207,
        "seek": 670828,
        "start": 6715.16,
        "temperature": 0,
        "text": " And I really shouldn't be doing that",
        "tokens": [
          50708,
          400,
          286,
          534,
          4659,
          380,
          312,
          884,
          300,
          50832
        ]
      },
      {
        "avg_logprob": -0.3025771431300951,
        "compression_ratio": 1.5704225352112675,
        "end": 6721.599999999999,
        "id": 2107,
        "no_speech_prob": 0.00000729637167751207,
        "seek": 670828,
        "start": 6719.32,
        "temperature": 0,
        "text": " because I don't want,",
        "tokens": [
          50916,
          570,
          286,
          500,
          380,
          528,
          11,
          51030
        ]
      },
      {
        "avg_logprob": -0.3025771431300951,
        "compression_ratio": 1.5704225352112675,
        "end": 6724.4,
        "id": 2108,
        "no_speech_prob": 0.00000729637167751207,
        "seek": 670828,
        "start": 6721.599999999999,
        "temperature": 0,
        "text": " I don't want to call train model over,",
        "tokens": [
          51030,
          286,
          500,
          380,
          528,
          281,
          818,
          3847,
          2316,
          670,
          11,
          51170
        ]
      },
      {
        "avg_logprob": -0.3025771431300951,
        "compression_ratio": 1.5704225352112675,
        "end": 6726,
        "id": 2109,
        "no_speech_prob": 0.00000729637167751207,
        "seek": 670828,
        "start": 6724.4,
        "temperature": 0,
        "text": " I can call train model.",
        "tokens": [
          51170,
          286,
          393,
          818,
          3847,
          2316,
          13,
          51250
        ]
      },
      {
        "avg_logprob": -0.3025771431300951,
        "compression_ratio": 1.5704225352112675,
        "end": 6727.92,
        "id": 2110,
        "no_speech_prob": 0.00000729637167751207,
        "seek": 670828,
        "start": 6726,
        "temperature": 0,
        "text": " Let me think about what I'm saying here.",
        "tokens": [
          51250,
          961,
          385,
          519,
          466,
          437,
          286,
          478,
          1566,
          510,
          13,
          51346
        ]
      },
      {
        "avg_logprob": -0.3025771431300951,
        "compression_ratio": 1.5704225352112675,
        "end": 6733.32,
        "id": 2111,
        "no_speech_prob": 0.00000729637167751207,
        "seek": 670828,
        "start": 6732.48,
        "temperature": 0,
        "text": " Yeah.",
        "tokens": [
          51574,
          865,
          13,
          51616
        ]
      },
      {
        "avg_logprob": -0.3030108716114458,
        "compression_ratio": 1.5402298850574712,
        "end": 6737.32,
        "id": 2112,
        "no_speech_prob": 0.000003905482117261272,
        "seek": 673332,
        "start": 6734.32,
        "temperature": 0,
        "text": " I have to, how did I finish this up?",
        "tokens": [
          50414,
          286,
          362,
          281,
          11,
          577,
          630,
          286,
          2413,
          341,
          493,
          30,
          50564
        ]
      },
      {
        "avg_logprob": -0.3030108716114458,
        "compression_ratio": 1.5402298850574712,
        "end": 6743.759999999999,
        "id": 2113,
        "no_speech_prob": 0.000003905482117261272,
        "seek": 673332,
        "start": 6742,
        "temperature": 0,
        "text": " I have to go in just like a minute.",
        "tokens": [
          50798,
          286,
          362,
          281,
          352,
          294,
          445,
          411,
          257,
          3456,
          13,
          50886
        ]
      },
      {
        "avg_logprob": -0.3030108716114458,
        "compression_ratio": 1.5402298850574712,
        "end": 6747.599999999999,
        "id": 2114,
        "no_speech_prob": 0.000003905482117261272,
        "seek": 673332,
        "start": 6744.96,
        "temperature": 0,
        "text": " I'm trying to think of what I want to finish up here.",
        "tokens": [
          50946,
          286,
          478,
          1382,
          281,
          519,
          295,
          437,
          286,
          528,
          281,
          2413,
          493,
          510,
          13,
          51078
        ]
      },
      {
        "avg_logprob": -0.3030108716114458,
        "compression_ratio": 1.5402298850574712,
        "end": 6752.4,
        "id": 2115,
        "no_speech_prob": 0.000003905482117261272,
        "seek": 673332,
        "start": 6749.48,
        "temperature": 0,
        "text": " So I don't think I have time to do the TF frame thing,",
        "tokens": [
          51172,
          407,
          286,
          500,
          380,
          519,
          286,
          362,
          565,
          281,
          360,
          264,
          40964,
          3920,
          551,
          11,
          51318
        ]
      },
      {
        "avg_logprob": -0.3030108716114458,
        "compression_ratio": 1.5402298850574712,
        "end": 6756.639999999999,
        "id": 2116,
        "no_speech_prob": 0.000003905482117261272,
        "seek": 673332,
        "start": 6753.639999999999,
        "temperature": 0,
        "text": " but should I do, would it make sense for me",
        "tokens": [
          51380,
          457,
          820,
          286,
          360,
          11,
          576,
          309,
          652,
          2020,
          337,
          385,
          51530
        ]
      },
      {
        "avg_logprob": -0.3030108716114458,
        "compression_ratio": 1.5402298850574712,
        "end": 6761.28,
        "id": 2117,
        "no_speech_prob": 0.000003905482117261272,
        "seek": 673332,
        "start": 6756.639999999999,
        "temperature": 0,
        "text": " to at least do something like set time out",
        "tokens": [
          51530,
          281,
          412,
          1935,
          360,
          746,
          411,
          992,
          565,
          484,
          51762
        ]
      },
      {
        "avg_logprob": -0.32660872847945605,
        "compression_ratio": 1.3272727272727274,
        "end": 6765.48,
        "id": 2118,
        "no_speech_prob": 0.000019525823518051766,
        "seek": 676332,
        "start": 6763.5199999999995,
        "temperature": 0,
        "text": " train model.",
        "tokens": [
          50374,
          3847,
          2316,
          13,
          50472
        ]
      },
      {
        "avg_logprob": -0.32660872847945605,
        "compression_ratio": 1.3272727272727274,
        "end": 6768.08,
        "id": 2119,
        "no_speech_prob": 0.000019525823518051766,
        "seek": 676332,
        "start": 6765.48,
        "temperature": 0,
        "text": " Let me just say, hey, do that.",
        "tokens": [
          50472,
          961,
          385,
          445,
          584,
          11,
          4177,
          11,
          360,
          300,
          13,
          50602
        ]
      },
      {
        "avg_logprob": -0.32660872847945605,
        "compression_ratio": 1.3272727272727274,
        "end": 6769.24,
        "id": 2120,
        "no_speech_prob": 0.000019525823518051766,
        "seek": 676332,
        "start": 6768.08,
        "temperature": 0,
        "text": " And then,",
        "tokens": [
          50602,
          400,
          550,
          11,
          50660
        ]
      },
      {
        "avg_logprob": -0.32660872847945605,
        "compression_ratio": 1.3272727272727274,
        "end": 6778.799999999999,
        "id": 2121,
        "no_speech_prob": 0.000019525823518051766,
        "seek": 676332,
        "start": 6776.04,
        "temperature": 0,
        "text": " like, what if I did this function train,",
        "tokens": [
          51000,
          411,
          11,
          437,
          498,
          286,
          630,
          341,
          2445,
          3847,
          11,
          51138
        ]
      },
      {
        "avg_logprob": -0.32660872847945605,
        "compression_ratio": 1.3272727272727274,
        "end": 6787.759999999999,
        "id": 2122,
        "no_speech_prob": 0.000019525823518051766,
        "seek": 676332,
        "start": 6782.92,
        "temperature": 0,
        "text": " set time out train model.",
        "tokens": [
          51344,
          992,
          565,
          484,
          3847,
          2316,
          13,
          51586
        ]
      },
      {
        "avg_logprob": -0.32660872847945605,
        "compression_ratio": 1.3272727272727274,
        "end": 6792.12,
        "id": 2123,
        "no_speech_prob": 0.000019525823518051766,
        "seek": 676332,
        "start": 6790.88,
        "temperature": 0,
        "text": " I want to do like a then,",
        "tokens": [
          51742,
          286,
          528,
          281,
          360,
          411,
          257,
          550,
          11,
          51804
        ]
      },
      {
        "avg_logprob": -0.4848188400268555,
        "compression_ratio": 0.9696969696969697,
        "end": 6792.96,
        "id": 2124,
        "no_speech_prob": 0.00002586729715403635,
        "seek": 679212,
        "start": 6792.12,
        "temperature": 0,
        "text": " but,",
        "tokens": [
          50364,
          457,
          11,
          50406
        ]
      },
      {
        "avg_logprob": -0.4848188400268555,
        "compression_ratio": 0.9696969696969697,
        "end": 6799.36,
        "id": 2125,
        "no_speech_prob": 0.00002586729715403635,
        "seek": 679212,
        "start": 6796.64,
        "temperature": 0,
        "text": " well, or what if I just did this?",
        "tokens": [
          50590,
          731,
          11,
          420,
          437,
          498,
          286,
          445,
          630,
          341,
          30,
          50726
        ]
      },
      {
        "avg_logprob": -0.4848188400268555,
        "compression_ratio": 0.9696969696969697,
        "end": 6819.76,
        "id": 2126,
        "no_speech_prob": 0.00002586729715403635,
        "seek": 679212,
        "start": 6818.12,
        "temperature": 0,
        "text": " Like something like this.",
        "tokens": [
          51664,
          1743,
          746,
          411,
          341,
          13,
          51746
        ]
      },
      {
        "avg_logprob": -0.4469639350628031,
        "compression_ratio": 1.3037037037037038,
        "end": 6821.12,
        "id": 2127,
        "no_speech_prob": 0.000006643421329499688,
        "seek": 681976,
        "start": 6820.280000000001,
        "temperature": 0,
        "text": " Right.",
        "tokens": [
          50390,
          1779,
          13,
          50432
        ]
      },
      {
        "avg_logprob": -0.4469639350628031,
        "compression_ratio": 1.3037037037037038,
        "end": 6823.92,
        "id": 2128,
        "no_speech_prob": 0.000006643421329499688,
        "seek": 681976,
        "start": 6822.360000000001,
        "temperature": 0,
        "text": " This is what I'm thinking.",
        "tokens": [
          50494,
          639,
          307,
          437,
          286,
          478,
          1953,
          13,
          50572
        ]
      },
      {
        "avg_logprob": -0.4469639350628031,
        "compression_ratio": 1.3037037037037038,
        "end": 6825,
        "id": 2129,
        "no_speech_prob": 0.000006643421329499688,
        "seek": 681976,
        "start": 6823.92,
        "temperature": 0,
        "text": " And then,",
        "tokens": [
          50572,
          400,
          550,
          11,
          50626
        ]
      },
      {
        "avg_logprob": -0.4469639350628031,
        "compression_ratio": 1.3037037037037038,
        "end": 6832.04,
        "id": 2130,
        "no_speech_prob": 0.000006643421329499688,
        "seek": 681976,
        "start": 6830.96,
        "temperature": 0,
        "text": " this would,",
        "tokens": [
          50924,
          341,
          576,
          11,
          50978
        ]
      },
      {
        "avg_logprob": -0.4469639350628031,
        "compression_ratio": 1.3037037037037038,
        "end": 6836.4800000000005,
        "id": 2131,
        "no_speech_prob": 0.000006643421329499688,
        "seek": 681976,
        "start": 6835.64,
        "temperature": 0,
        "text": " right.",
        "tokens": [
          51158,
          558,
          13,
          51200
        ]
      },
      {
        "avg_logprob": -0.4469639350628031,
        "compression_ratio": 1.3037037037037038,
        "end": 6837.320000000001,
        "id": 2132,
        "no_speech_prob": 0.000006643421329499688,
        "seek": 681976,
        "start": 6836.4800000000005,
        "temperature": 0,
        "text": " Does this make sense?",
        "tokens": [
          51200,
          4402,
          341,
          652,
          2020,
          30,
          51242
        ]
      },
      {
        "avg_logprob": -0.4469639350628031,
        "compression_ratio": 1.3037037037037038,
        "end": 6839.280000000001,
        "id": 2133,
        "no_speech_prob": 0.000006643421329499688,
        "seek": 681976,
        "start": 6837.320000000001,
        "temperature": 0,
        "text": " So I'm going to explain this in a second.",
        "tokens": [
          51242,
          407,
          286,
          478,
          516,
          281,
          2903,
          341,
          294,
          257,
          1150,
          13,
          51340
        ]
      },
      {
        "avg_logprob": -0.4469639350628031,
        "compression_ratio": 1.3037037037037038,
        "end": 6844.400000000001,
        "id": 2134,
        "no_speech_prob": 0.000006643421329499688,
        "seek": 681976,
        "start": 6840.72,
        "temperature": 0,
        "text": " Like this would basically be happening elsewhere.",
        "tokens": [
          51412,
          1743,
          341,
          576,
          1936,
          312,
          2737,
          14517,
          13,
          51596
        ]
      },
      {
        "avg_logprob": -0.2958921099465991,
        "compression_ratio": 1.3428571428571427,
        "end": 6854.76,
        "id": 2135,
        "no_speech_prob": 0.00003373707295395434,
        "seek": 684976,
        "start": 6849.76,
        "temperature": 0,
        "text": " But I think I need the set time out to like,",
        "tokens": [
          50364,
          583,
          286,
          519,
          286,
          643,
          264,
          992,
          565,
          484,
          281,
          411,
          11,
          50614
        ]
      },
      {
        "avg_logprob": -0.2958921099465991,
        "compression_ratio": 1.3428571428571427,
        "end": 6859.84,
        "id": 2136,
        "no_speech_prob": 0.00003373707295395434,
        "seek": 684976,
        "start": 6857.56,
        "temperature": 0,
        "text": " yeah, this is never going to release anything.",
        "tokens": [
          50754,
          1338,
          11,
          341,
          307,
          1128,
          516,
          281,
          4374,
          1340,
          13,
          50868
        ]
      },
      {
        "avg_logprob": -0.2958921099465991,
        "compression_ratio": 1.3428571428571427,
        "end": 6865.320000000001,
        "id": 2137,
        "no_speech_prob": 0.00003373707295395434,
        "seek": 684976,
        "start": 6863.4800000000005,
        "temperature": 0,
        "text": " Oh, this is like superfluous",
        "tokens": [
          51050,
          876,
          11,
          341,
          307,
          411,
          1687,
          49253,
          563,
          51142
        ]
      },
      {
        "avg_logprob": -0.2958921099465991,
        "compression_ratio": 1.3428571428571427,
        "end": 6868.04,
        "id": 2138,
        "no_speech_prob": 0.00003373707295395434,
        "seek": 684976,
        "start": 6866.24,
        "temperature": 0,
        "text": " cause it's just returning a promise.",
        "tokens": [
          51188,
          3082,
          309,
          311,
          445,
          12678,
          257,
          6228,
          13,
          51278
        ]
      },
      {
        "avg_logprob": -0.2958921099465991,
        "compression_ratio": 1.3428571428571427,
        "end": 6870.4400000000005,
        "id": 2139,
        "no_speech_prob": 0.00003373707295395434,
        "seek": 684976,
        "start": 6869.2,
        "temperature": 0,
        "text": " Yeah.",
        "tokens": [
          51336,
          865,
          13,
          51398
        ]
      },
      {
        "avg_logprob": -0.2958921099465991,
        "compression_ratio": 1.3428571428571427,
        "end": 6871.280000000001,
        "id": 2140,
        "no_speech_prob": 0.00003373707295395434,
        "seek": 684976,
        "start": 6870.4400000000005,
        "temperature": 0,
        "text": " All right.",
        "tokens": [
          51398,
          1057,
          558,
          13,
          51440
        ]
      },
      {
        "avg_logprob": -0.2958921099465991,
        "compression_ratio": 1.3428571428571427,
        "end": 6872.12,
        "id": 2141,
        "no_speech_prob": 0.00003373707295395434,
        "seek": 684976,
        "start": 6871.280000000001,
        "temperature": 0,
        "text": " I'll do that.",
        "tokens": [
          51440,
          286,
          603,
          360,
          300,
          13,
          51482
        ]
      },
      {
        "avg_logprob": -0.4418635368347168,
        "compression_ratio": 1.1222222222222222,
        "end": 6880.6,
        "id": 2142,
        "no_speech_prob": 0.00003071817263844423,
        "seek": 687976,
        "start": 6879.76,
        "temperature": 0,
        "text": " Like,",
        "tokens": [
          50364,
          1743,
          11,
          50406
        ]
      },
      {
        "avg_logprob": -0.4418635368347168,
        "compression_ratio": 1.1222222222222222,
        "end": 6885.68,
        "id": 2143,
        "no_speech_prob": 0.00003071817263844423,
        "seek": 687976,
        "start": 6884,
        "temperature": 0,
        "text": " like what if I did this?",
        "tokens": [
          50576,
          411,
          437,
          498,
          286,
          630,
          341,
          30,
          50660
        ]
      },
      {
        "avg_logprob": -0.4418635368347168,
        "compression_ratio": 1.1222222222222222,
        "end": 6887.96,
        "id": 2144,
        "no_speech_prob": 0.00003071817263844423,
        "seek": 687976,
        "start": 6886.6,
        "temperature": 0,
        "text": " This is weird though.",
        "tokens": [
          50706,
          639,
          307,
          3657,
          1673,
          13,
          50774
        ]
      },
      {
        "avg_logprob": -0.4418635368347168,
        "compression_ratio": 1.1222222222222222,
        "end": 6898.4800000000005,
        "id": 2145,
        "no_speech_prob": 0.00003071817263844423,
        "seek": 687976,
        "start": 6896.52,
        "temperature": 0,
        "text": " I've killed this completely.",
        "tokens": [
          51202,
          286,
          600,
          4652,
          341,
          2584,
          13,
          51300
        ]
      },
      {
        "avg_logprob": -0.4418635368347168,
        "compression_ratio": 1.1222222222222222,
        "end": 6899.84,
        "id": 2146,
        "no_speech_prob": 0.00003071817263844423,
        "seek": 687976,
        "start": 6898.4800000000005,
        "temperature": 0,
        "text": " Killed the browser.",
        "tokens": [
          51300,
          591,
          6261,
          264,
          11185,
          13,
          51368
        ]
      },
      {
        "avg_logprob": -0.4478271756853376,
        "compression_ratio": 1.0786516853932584,
        "end": 6910.6,
        "id": 2147,
        "no_speech_prob": 0.000017778485926100984,
        "seek": 690976,
        "start": 6909.76,
        "temperature": 0,
        "text": " Yeah.",
        "tokens": [
          50364,
          865,
          13,
          50406
        ]
      },
      {
        "avg_logprob": -0.4478271756853376,
        "compression_ratio": 1.0786516853932584,
        "end": 6920.12,
        "id": 2148,
        "no_speech_prob": 0.000017778485926100984,
        "seek": 690976,
        "start": 6919.280000000001,
        "temperature": 0,
        "text": " Yeah.",
        "tokens": [
          50840,
          865,
          13,
          50882
        ]
      },
      {
        "avg_logprob": -0.4478271756853376,
        "compression_ratio": 1.0786516853932584,
        "end": 6921.280000000001,
        "id": 2149,
        "no_speech_prob": 0.000017778485926100984,
        "seek": 690976,
        "start": 6920.12,
        "temperature": 0,
        "text": " It's not really that much faster,",
        "tokens": [
          50882,
          467,
          311,
          406,
          534,
          300,
          709,
          4663,
          11,
          50940
        ]
      },
      {
        "avg_logprob": -0.4478271756853376,
        "compression_ratio": 1.0786516853932584,
        "end": 6925.280000000001,
        "id": 2150,
        "no_speech_prob": 0.000017778485926100984,
        "seek": 690976,
        "start": 6922.52,
        "temperature": 0,
        "text": " but this is kind of like what I want to do, right?",
        "tokens": [
          51002,
          457,
          341,
          307,
          733,
          295,
          411,
          437,
          286,
          528,
          281,
          360,
          11,
          558,
          30,
          51140
        ]
      },
      {
        "avg_logprob": -0.2700234353542328,
        "compression_ratio": 1.4294871794871795,
        "end": 6941.52,
        "id": 2151,
        "no_speech_prob": 0.00003373720028321259,
        "seek": 693976,
        "start": 6940.68,
        "temperature": 0,
        "text": " Yeah.",
        "tokens": [
          50410,
          865,
          13,
          50452
        ]
      },
      {
        "avg_logprob": -0.2700234353542328,
        "compression_ratio": 1.4294871794871795,
        "end": 6942.92,
        "id": 2152,
        "no_speech_prob": 0.00003373720028321259,
        "seek": 693976,
        "start": 6941.52,
        "temperature": 0,
        "text": " Now I can get a much faster frame rate",
        "tokens": [
          50452,
          823,
          286,
          393,
          483,
          257,
          709,
          4663,
          3920,
          3314,
          50522
        ]
      },
      {
        "avg_logprob": -0.2700234353542328,
        "compression_ratio": 1.4294871794871795,
        "end": 6949.320000000001,
        "id": 2153,
        "no_speech_prob": 0.00003373720028321259,
        "seek": 693976,
        "start": 6946.92,
        "temperature": 0,
        "text": " and I could actually give it more epochs, right?",
        "tokens": [
          50722,
          293,
          286,
          727,
          767,
          976,
          309,
          544,
          30992,
          28346,
          11,
          558,
          30,
          50842
        ]
      },
      {
        "avg_logprob": -0.2700234353542328,
        "compression_ratio": 1.4294871794871795,
        "end": 6958.88,
        "id": 2154,
        "no_speech_prob": 0.00003373720028321259,
        "seek": 693976,
        "start": 6958.04,
        "temperature": 0,
        "text": " Yeah.",
        "tokens": [
          51278,
          865,
          13,
          51320
        ]
      },
      {
        "avg_logprob": -0.2700234353542328,
        "compression_ratio": 1.4294871794871795,
        "end": 6961.08,
        "id": 2155,
        "no_speech_prob": 0.00003373720028321259,
        "seek": 693976,
        "start": 6958.88,
        "temperature": 0,
        "text": " The training is happening more slowly,",
        "tokens": [
          51320,
          440,
          3097,
          307,
          2737,
          544,
          5692,
          11,
          51430
        ]
      },
      {
        "avg_logprob": -0.2700234353542328,
        "compression_ratio": 1.4294871794871795,
        "end": 6963.24,
        "id": 2156,
        "no_speech_prob": 0.00003373720028321259,
        "seek": 693976,
        "start": 6961.08,
        "temperature": 0,
        "text": " but the frame rate is happening faster.",
        "tokens": [
          51430,
          457,
          264,
          3920,
          3314,
          307,
          2737,
          4663,
          13,
          51538
        ]
      },
      {
        "avg_logprob": -0.2700234353542328,
        "compression_ratio": 1.4294871794871795,
        "end": 6968,
        "id": 2157,
        "no_speech_prob": 0.00003373720028321259,
        "seek": 693976,
        "start": 6965.84,
        "temperature": 0,
        "text": " Perhaps it results in a video about workers.",
        "tokens": [
          51668,
          10517,
          309,
          3542,
          294,
          257,
          960,
          466,
          5600,
          13,
          51776
        ]
      },
      {
        "avg_logprob": -0.39764320244223383,
        "compression_ratio": 1.3358778625954197,
        "end": 6971,
        "id": 2158,
        "no_speech_prob": 0.00001863169381977059,
        "seek": 696976,
        "start": 6970.16,
        "temperature": 0,
        "text": " Yeah.",
        "tokens": [
          50384,
          865,
          13,
          50426
        ]
      },
      {
        "avg_logprob": -0.39764320244223383,
        "compression_ratio": 1.3358778625954197,
        "end": 6974.24,
        "id": 2159,
        "no_speech_prob": 0.00001863169381977059,
        "seek": 696976,
        "start": 6972.280000000001,
        "temperature": 0,
        "text": " What tidy does nothing?",
        "tokens": [
          50490,
          708,
          34646,
          775,
          1825,
          30,
          50588
        ]
      },
      {
        "avg_logprob": -0.39764320244223383,
        "compression_ratio": 1.3358778625954197,
        "end": 6976.4800000000005,
        "id": 2160,
        "no_speech_prob": 0.00001863169381977059,
        "seek": 696976,
        "start": 6974.24,
        "temperature": 0,
        "text": " Look at this crazy way that it learned.",
        "tokens": [
          50588,
          2053,
          412,
          341,
          3219,
          636,
          300,
          309,
          3264,
          13,
          50700
        ]
      },
      {
        "avg_logprob": -0.39764320244223383,
        "compression_ratio": 1.3358778625954197,
        "end": 6984.320000000001,
        "id": 2161,
        "no_speech_prob": 0.00001863169381977059,
        "seek": 696976,
        "start": 6982.56,
        "temperature": 0,
        "text": " Where's the tidy that does nothing?",
        "tokens": [
          51004,
          2305,
          311,
          264,
          34646,
          300,
          775,
          1825,
          30,
          51092
        ]
      },
      {
        "avg_logprob": -0.39764320244223383,
        "compression_ratio": 1.3358778625954197,
        "end": 6985.320000000001,
        "id": 2162,
        "no_speech_prob": 0.00001863169381977059,
        "seek": 696976,
        "start": 6984.320000000001,
        "temperature": 0,
        "text": " Me, I am, sumi.",
        "tokens": [
          51092,
          1923,
          11,
          286,
          669,
          11,
          2408,
          72,
          13,
          51142
        ]
      },
      {
        "avg_logprob": -0.39764320244223383,
        "compression_ratio": 1.3358778625954197,
        "end": 6987.52,
        "id": 2163,
        "no_speech_prob": 0.00001863169381977059,
        "seek": 696976,
        "start": 6986.68,
        "temperature": 0,
        "text": " Right.",
        "tokens": [
          51210,
          1779,
          13,
          51252
        ]
      },
      {
        "avg_logprob": -0.39764320244223383,
        "compression_ratio": 1.3358778625954197,
        "end": 6991.52,
        "id": 2164,
        "no_speech_prob": 0.00001863169381977059,
        "seek": 696976,
        "start": 6987.52,
        "temperature": 0,
        "text": " Is this an improvement over what I had before?",
        "tokens": [
          51252,
          1119,
          341,
          364,
          10444,
          670,
          437,
          286,
          632,
          949,
          30,
          51452
        ]
      },
      {
        "avg_logprob": -0.4661859599026767,
        "compression_ratio": 0.8461538461538461,
        "end": 7000.6,
        "id": 2165,
        "no_speech_prob": 0.0012447639601305127,
        "seek": 699976,
        "start": 6999.76,
        "temperature": 0,
        "text": " Yeah.",
        "tokens": [
          50364,
          865,
          13,
          50406
        ]
      },
      {
        "avg_logprob": -0.4661859599026767,
        "compression_ratio": 0.8461538461538461,
        "end": 7023.96,
        "id": 2166,
        "no_speech_prob": 0.0012447639601305127,
        "seek": 699976,
        "start": 7021.360000000001,
        "temperature": 0,
        "text": " No, I need this TF tidy.",
        "tokens": [
          51444,
          883,
          11,
          286,
          643,
          341,
          40964,
          34646,
          13,
          51574
        ]
      },
      {
        "avg_logprob": -0.4661859599026767,
        "compression_ratio": 0.8461538461538461,
        "end": 7027.12,
        "id": 2167,
        "no_speech_prob": 0.0012447639601305127,
        "seek": 699976,
        "start": 7025.88,
        "temperature": 0,
        "text": " What?",
        "tokens": [
          51670,
          708,
          30,
          51732
        ]
      },
      {
        "avg_logprob": -0.4661859599026767,
        "compression_ratio": 0.8461538461538461,
        "end": 7028.16,
        "id": 2168,
        "no_speech_prob": 0.0012447639601305127,
        "seek": 699976,
        "start": 7027.12,
        "temperature": 0,
        "text": " Because",
        "tokens": [
          51732,
          1436,
          51784
        ]
      },
      {
        "avg_logprob": -0.3019094921293713,
        "compression_ratio": 1.28099173553719,
        "end": 7031.88,
        "id": 2169,
        "no_speech_prob": 0.00004757638453156687,
        "seek": 702976,
        "start": 7030.400000000001,
        "temperature": 0,
        "text": " this has to get tidied.",
        "tokens": [
          50396,
          341,
          575,
          281,
          483,
          9422,
          1091,
          13,
          50470
        ]
      },
      {
        "avg_logprob": -0.3019094921293713,
        "compression_ratio": 1.28099173553719,
        "end": 7038.400000000001,
        "id": 2170,
        "no_speech_prob": 0.00004757638453156687,
        "seek": 702976,
        "start": 7037.56,
        "temperature": 0,
        "text": " Right?",
        "tokens": [
          50754,
          1779,
          30,
          50796
        ]
      },
      {
        "avg_logprob": -0.3019094921293713,
        "compression_ratio": 1.28099173553719,
        "end": 7039.56,
        "id": 2171,
        "no_speech_prob": 0.00004757638453156687,
        "seek": 702976,
        "start": 7038.400000000001,
        "temperature": 0,
        "text": " This is what it's doing right now.",
        "tokens": [
          50796,
          639,
          307,
          437,
          309,
          311,
          884,
          558,
          586,
          13,
          50854
        ]
      },
      {
        "avg_logprob": -0.3019094921293713,
        "compression_ratio": 1.28099173553719,
        "end": 7042.84,
        "id": 2172,
        "no_speech_prob": 0.00004757638453156687,
        "seek": 702976,
        "start": 7041.52,
        "temperature": 0,
        "text": " If I take that out.",
        "tokens": [
          50952,
          759,
          286,
          747,
          300,
          484,
          13,
          51018
        ]
      },
      {
        "avg_logprob": -0.3019094921293713,
        "compression_ratio": 1.28099173553719,
        "end": 7049.2,
        "id": 2173,
        "no_speech_prob": 0.00004757638453156687,
        "seek": 702976,
        "start": 7048.16,
        "temperature": 0,
        "text": " Oh, you're right.",
        "tokens": [
          51284,
          876,
          11,
          291,
          434,
          558,
          13,
          51336
        ]
      },
      {
        "avg_logprob": -0.3019094921293713,
        "compression_ratio": 1.28099173553719,
        "end": 7057.72,
        "id": 2174,
        "no_speech_prob": 0.00004757638453156687,
        "seek": 702976,
        "start": 7053.8,
        "temperature": 0,
        "text": " Oh, I don't need a TF tidy for model.fit.",
        "tokens": [
          51566,
          876,
          11,
          286,
          500,
          380,
          643,
          257,
          40964,
          34646,
          337,
          2316,
          13,
          6845,
          13,
          51762
        ]
      },
      {
        "avg_logprob": -0.3019094921293713,
        "compression_ratio": 1.28099173553719,
        "end": 7059.400000000001,
        "id": 2175,
        "no_speech_prob": 0.00004757638453156687,
        "seek": 702976,
        "start": 7057.72,
        "temperature": 0,
        "text": " Oh, okay.",
        "tokens": [
          51762,
          876,
          11,
          1392,
          13,
          51846
        ]
      },
      {
        "avg_logprob": -0.2680982887198072,
        "compression_ratio": 1.684782608695652,
        "end": 7060.88,
        "id": 2176,
        "no_speech_prob": 0.0000064390278566861525,
        "seek": 705976,
        "start": 7060.04,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          50378,
          1033,
          13,
          50420
        ]
      },
      {
        "avg_logprob": -0.2680982887198072,
        "compression_ratio": 1.684782608695652,
        "end": 7063.88,
        "id": 2177,
        "no_speech_prob": 0.0000064390278566861525,
        "seek": 705976,
        "start": 7062,
        "temperature": 0,
        "text": " Is this an improvement?",
        "tokens": [
          50476,
          1119,
          341,
          364,
          10444,
          30,
          50570
        ]
      },
      {
        "avg_logprob": -0.2680982887198072,
        "compression_ratio": 1.684782608695652,
        "end": 7065.24,
        "id": 2178,
        "no_speech_prob": 0.0000064390278566861525,
        "seek": 705976,
        "start": 7063.88,
        "temperature": 0,
        "text": " Like to have pulled this out,",
        "tokens": [
          50570,
          1743,
          281,
          362,
          7373,
          341,
          484,
          11,
          50638
        ]
      },
      {
        "avg_logprob": -0.2680982887198072,
        "compression_ratio": 1.684782608695652,
        "end": 7067.2,
        "id": 2179,
        "no_speech_prob": 0.0000064390278566861525,
        "seek": 705976,
        "start": 7065.24,
        "temperature": 0,
        "text": " at least pulled this out of draw.",
        "tokens": [
          50638,
          412,
          1935,
          7373,
          341,
          484,
          295,
          2642,
          13,
          50736
        ]
      },
      {
        "avg_logprob": -0.2680982887198072,
        "compression_ratio": 1.684782608695652,
        "end": 7070.64,
        "id": 2180,
        "no_speech_prob": 0.0000064390278566861525,
        "seek": 705976,
        "start": 7069.8,
        "temperature": 0,
        "text": " And a way,",
        "tokens": [
          50866,
          400,
          257,
          636,
          11,
          50908
        ]
      },
      {
        "avg_logprob": -0.2680982887198072,
        "compression_ratio": 1.684782608695652,
        "end": 7074.280000000001,
        "id": 2181,
        "no_speech_prob": 0.0000064390278566861525,
        "seek": 705976,
        "start": 7072.56,
        "temperature": 0,
        "text": " model.fit is tidied internally.",
        "tokens": [
          51004,
          2316,
          13,
          6845,
          307,
          9422,
          1091,
          19501,
          13,
          51090
        ]
      },
      {
        "avg_logprob": -0.2680982887198072,
        "compression_ratio": 1.684782608695652,
        "end": 7075.12,
        "id": 2182,
        "no_speech_prob": 0.0000064390278566861525,
        "seek": 705976,
        "start": 7074.280000000001,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          51090,
          1033,
          13,
          51132
        ]
      },
      {
        "avg_logprob": -0.2680982887198072,
        "compression_ratio": 1.684782608695652,
        "end": 7078.96,
        "id": 2183,
        "no_speech_prob": 0.0000064390278566861525,
        "seek": 705976,
        "start": 7077.56,
        "temperature": 0,
        "text": " And tidy doesn't work with promises.",
        "tokens": [
          51254,
          400,
          34646,
          1177,
          380,
          589,
          365,
          16403,
          13,
          51324
        ]
      },
      {
        "avg_logprob": -0.2680982887198072,
        "compression_ratio": 1.684782608695652,
        "end": 7079.84,
        "id": 2184,
        "no_speech_prob": 0.0000064390278566861525,
        "seek": 705976,
        "start": 7078.96,
        "temperature": 0,
        "text": " Got it.",
        "tokens": [
          51324,
          5803,
          309,
          13,
          51368
        ]
      },
      {
        "avg_logprob": -0.2680982887198072,
        "compression_ratio": 1.684782608695652,
        "end": 7082.68,
        "id": 2185,
        "no_speech_prob": 0.0000064390278566861525,
        "seek": 705976,
        "start": 7079.84,
        "temperature": 0,
        "text": " Got it, got it, got it, got it, got it.",
        "tokens": [
          51368,
          5803,
          309,
          11,
          658,
          309,
          11,
          658,
          309,
          11,
          658,
          309,
          11,
          658,
          309,
          13,
          51510
        ]
      },
      {
        "avg_logprob": -0.2680982887198072,
        "compression_ratio": 1.684782608695652,
        "end": 7083.52,
        "id": 2186,
        "no_speech_prob": 0.0000064390278566861525,
        "seek": 705976,
        "start": 7082.68,
        "temperature": 0,
        "text": " All right.",
        "tokens": [
          51510,
          1057,
          558,
          13,
          51552
        ]
      },
      {
        "avg_logprob": -0.2680982887198072,
        "compression_ratio": 1.684782608695652,
        "end": 7086.8,
        "id": 2187,
        "no_speech_prob": 0.0000064390278566861525,
        "seek": 705976,
        "start": 7083.52,
        "temperature": 0,
        "text": " Is this an improvement or should I just stay where I was",
        "tokens": [
          51552,
          1119,
          341,
          364,
          10444,
          420,
          820,
          286,
          445,
          1754,
          689,
          286,
          390,
          51716
        ]
      },
      {
        "avg_logprob": -0.2680982887198072,
        "compression_ratio": 1.684782608695652,
        "end": 7089.24,
        "id": 2188,
        "no_speech_prob": 0.0000064390278566861525,
        "seek": 705976,
        "start": 7086.8,
        "temperature": 0,
        "text": " and let it be?",
        "tokens": [
          51716,
          293,
          718,
          309,
          312,
          30,
          51838
        ]
      },
      {
        "avg_logprob": -0.2359712839126587,
        "compression_ratio": 1.3910614525139664,
        "end": 7091.52,
        "id": 2189,
        "no_speech_prob": 0.000028857068173238076,
        "seek": 708976,
        "start": 7089.96,
        "temperature": 0,
        "text": " Like leave it in draw and talk about",
        "tokens": [
          50374,
          1743,
          1856,
          309,
          294,
          2642,
          293,
          751,
          466,
          50452
        ]
      },
      {
        "avg_logprob": -0.2359712839126587,
        "compression_ratio": 1.3910614525139664,
        "end": 7094.4400000000005,
        "id": 2190,
        "no_speech_prob": 0.000028857068173238076,
        "seek": 708976,
        "start": 7091.52,
        "temperature": 0,
        "text": " how that probably should do TF frame instead,",
        "tokens": [
          50452,
          577,
          300,
          1391,
          820,
          360,
          40964,
          3920,
          2602,
          11,
          50598
        ]
      },
      {
        "avg_logprob": -0.2359712839126587,
        "compression_ratio": 1.3910614525139664,
        "end": 7096.280000000001,
        "id": 2191,
        "no_speech_prob": 0.000028857068173238076,
        "seek": 708976,
        "start": 7094.4400000000005,
        "temperature": 0,
        "text": " web workers, yada, yada, yada.",
        "tokens": [
          50598,
          3670,
          5600,
          11,
          288,
          1538,
          11,
          288,
          1538,
          11,
          288,
          1538,
          13,
          50690
        ]
      },
      {
        "avg_logprob": -0.2359712839126587,
        "compression_ratio": 1.3910614525139664,
        "end": 7100.84,
        "id": 2192,
        "no_speech_prob": 0.000028857068173238076,
        "seek": 708976,
        "start": 7099.64,
        "temperature": 0,
        "text": " Answer fast.",
        "tokens": [
          50858,
          24545,
          2370,
          13,
          50918
        ]
      },
      {
        "avg_logprob": -0.2359712839126587,
        "compression_ratio": 1.3910614525139664,
        "end": 7102.68,
        "id": 2193,
        "no_speech_prob": 0.000028857068173238076,
        "seek": 708976,
        "start": 7101.72,
        "temperature": 0,
        "text": " I got to go.",
        "tokens": [
          50962,
          286,
          658,
          281,
          352,
          13,
          51010
        ]
      },
      {
        "avg_logprob": -0.2359712839126587,
        "compression_ratio": 1.3910614525139664,
        "end": 7106.56,
        "id": 2194,
        "no_speech_prob": 0.000028857068173238076,
        "seek": 708976,
        "start": 7103.68,
        "temperature": 0,
        "text": " Async while loop is definitely a good suggestion.",
        "tokens": [
          51060,
          1018,
          34015,
          1339,
          6367,
          307,
          2138,
          257,
          665,
          16541,
          13,
          51204
        ]
      },
      {
        "avg_logprob": -0.2359712839126587,
        "compression_ratio": 1.3910614525139664,
        "end": 7117.92,
        "id": 2195,
        "no_speech_prob": 0.000028857068173238076,
        "seek": 708976,
        "start": 7116.16,
        "temperature": 0,
        "text": " Technically, this is a much better way to do it.",
        "tokens": [
          51684,
          42494,
          11,
          341,
          307,
          257,
          709,
          1101,
          636,
          281,
          360,
          309,
          13,
          51772
        ]
      },
      {
        "avg_logprob": -0.2359712839126587,
        "compression_ratio": 1.3910614525139664,
        "end": 7119,
        "id": 2196,
        "no_speech_prob": 0.000028857068173238076,
        "seek": 708976,
        "start": 7117.92,
        "temperature": 0,
        "text": " All right.",
        "tokens": [
          51772,
          1057,
          558,
          13,
          51826
        ]
      },
      {
        "avg_logprob": -0.22951343059539794,
        "compression_ratio": 0.8490566037735849,
        "end": 7120.48,
        "id": 2197,
        "no_speech_prob": 0.0016743153100833297,
        "seek": 711900,
        "start": 7119.04,
        "temperature": 0,
        "text": " Thank you.",
        "tokens": [
          50366,
          1044,
          291,
          13,
          50438
        ]
      },
      {
        "avg_logprob": -0.22951343059539794,
        "compression_ratio": 0.8490566037735849,
        "end": 7121.88,
        "id": 2198,
        "no_speech_prob": 0.0016743153100833297,
        "seek": 711900,
        "start": 7120.48,
        "temperature": 0,
        "text": " That's all I needed to know.",
        "tokens": [
          50438,
          663,
          311,
          439,
          286,
          2978,
          281,
          458,
          13,
          50508
        ]
      },
      {
        "avg_logprob": -0.22951343059539794,
        "compression_ratio": 0.8490566037735849,
        "end": 7125.12,
        "id": 2199,
        "no_speech_prob": 0.0016743153100833297,
        "seek": 711900,
        "start": 7124.28,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          50628,
          1033,
          13,
          50670
        ]
      },
      {
        "avg_logprob": -0.4428512997097439,
        "compression_ratio": 1.502439024390244,
        "end": 7150.52,
        "id": 2200,
        "no_speech_prob": 0.01205331552773714,
        "seek": 714900,
        "start": 7149.68,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          50398,
          1033,
          13,
          50440
        ]
      },
      {
        "avg_logprob": -0.4428512997097439,
        "compression_ratio": 1.502439024390244,
        "end": 7159.52,
        "id": 2201,
        "no_speech_prob": 0.01205331552773714,
        "seek": 714900,
        "start": 7157.64,
        "temperature": 0,
        "text": " So I'm going to go back to.",
        "tokens": [
          50796,
          407,
          286,
          478,
          516,
          281,
          352,
          646,
          281,
          13,
          50890
        ]
      },
      {
        "avg_logprob": -0.4428512997097439,
        "compression_ratio": 1.502439024390244,
        "end": 7164.52,
        "id": 2202,
        "no_speech_prob": 0.01205331552773714,
        "seek": 714900,
        "start": 7161.8,
        "temperature": 0,
        "text": " All right, so the chat has given me some really helpful tips.",
        "tokens": [
          51004,
          1057,
          558,
          11,
          370,
          264,
          5081,
          575,
          2212,
          385,
          512,
          534,
          4961,
          6082,
          13,
          51140
        ]
      },
      {
        "avg_logprob": -0.4428512997097439,
        "compression_ratio": 1.502439024390244,
        "end": 7166.52,
        "id": 2203,
        "no_speech_prob": 0.01205331552773714,
        "seek": 714900,
        "start": 7164.52,
        "temperature": 0,
        "text": " I've made quite a few little like weird little errors",
        "tokens": [
          51140,
          286,
          600,
          1027,
          1596,
          257,
          1326,
          707,
          411,
          3657,
          707,
          13603,
          51240
        ]
      },
      {
        "avg_logprob": -0.4428512997097439,
        "compression_ratio": 1.502439024390244,
        "end": 7169.68,
        "id": 2204,
        "no_speech_prob": 0.01205331552773714,
        "seek": 714900,
        "start": 7166.52,
        "temperature": 0,
        "text": " and mistakes here and I want to just fix this up a bit.",
        "tokens": [
          51240,
          293,
          8038,
          510,
          293,
          286,
          528,
          281,
          445,
          3191,
          341,
          493,
          257,
          857,
          13,
          51398
        ]
      },
      {
        "avg_logprob": -0.4428512997097439,
        "compression_ratio": 1.502439024390244,
        "end": 7172.04,
        "id": 2205,
        "no_speech_prob": 0.01205331552773714,
        "seek": 714900,
        "start": 7169.68,
        "temperature": 0,
        "text": " I think it's actually going to be easier to look at",
        "tokens": [
          51398,
          286,
          519,
          309,
          311,
          767,
          516,
          281,
          312,
          3571,
          281,
          574,
          412,
          51516
        ]
      },
      {
        "avg_logprob": -0.4428512997097439,
        "compression_ratio": 1.502439024390244,
        "end": 7177.04,
        "id": 2206,
        "no_speech_prob": 0.01205331552773714,
        "seek": 714900,
        "start": 7172.04,
        "temperature": 0,
        "text": " and watch if I just go back to a lower resolution.",
        "tokens": [
          51516,
          293,
          1159,
          498,
          286,
          445,
          352,
          646,
          281,
          257,
          3126,
          8669,
          13,
          51766
        ]
      },
      {
        "avg_logprob": -0.3462908333594646,
        "compression_ratio": 1.6031746031746033,
        "end": 7182.8,
        "id": 2207,
        "no_speech_prob": 0.000009666087862569839,
        "seek": 717704,
        "start": 7177.8,
        "temperature": 0,
        "text": " So let's make this 40 and let me refresh this.",
        "tokens": [
          50402,
          407,
          718,
          311,
          652,
          341,
          3356,
          293,
          718,
          385,
          15134,
          341,
          13,
          50652
        ]
      },
      {
        "avg_logprob": -0.3462908333594646,
        "compression_ratio": 1.6031746031746033,
        "end": 7184.68,
        "id": 2208,
        "no_speech_prob": 0.000009666087862569839,
        "seek": 717704,
        "start": 7183.32,
        "temperature": 0,
        "text": " Okay, so here we go.",
        "tokens": [
          50678,
          1033,
          11,
          370,
          510,
          321,
          352,
          13,
          50746
        ]
      },
      {
        "avg_logprob": -0.3462908333594646,
        "compression_ratio": 1.6031746031746033,
        "end": 7189,
        "id": 2209,
        "no_speech_prob": 0.000009666087862569839,
        "seek": 717704,
        "start": 7184.68,
        "temperature": 0,
        "text": " So this is now working, training itself for XOR.",
        "tokens": [
          50746,
          407,
          341,
          307,
          586,
          1364,
          11,
          3097,
          2564,
          337,
          1783,
          2483,
          13,
          50962
        ]
      },
      {
        "avg_logprob": -0.3462908333594646,
        "compression_ratio": 1.6031746031746033,
        "end": 7191.28,
        "id": 2210,
        "no_speech_prob": 0.000009666087862569839,
        "seek": 717704,
        "start": 7189,
        "temperature": 0,
        "text": " You can see it's kind of moving along here.",
        "tokens": [
          50962,
          509,
          393,
          536,
          309,
          311,
          733,
          295,
          2684,
          2051,
          510,
          13,
          51076
        ]
      },
      {
        "avg_logprob": -0.3462908333594646,
        "compression_ratio": 1.6031746031746033,
        "end": 7195.68,
        "id": 2211,
        "no_speech_prob": 0.000009666087862569839,
        "seek": 717704,
        "start": 7191.28,
        "temperature": 0,
        "text": " Now, what the real thing that's problematic here",
        "tokens": [
          51076,
          823,
          11,
          437,
          264,
          957,
          551,
          300,
          311,
          19011,
          510,
          51296
        ]
      },
      {
        "avg_logprob": -0.3462908333594646,
        "compression_ratio": 1.6031746031746033,
        "end": 7198.32,
        "id": 2212,
        "no_speech_prob": 0.000009666087862569839,
        "seek": 717704,
        "start": 7195.68,
        "temperature": 0,
        "text": " is the draw loop is happening over and over again",
        "tokens": [
          51296,
          307,
          264,
          2642,
          6367,
          307,
          2737,
          670,
          293,
          670,
          797,
          51428
        ]
      },
      {
        "avg_logprob": -0.3462908333594646,
        "compression_ratio": 1.6031746031746033,
        "end": 7201.16,
        "id": 2213,
        "no_speech_prob": 0.000009666087862569839,
        "seek": 717704,
        "start": 7198.32,
        "temperature": 0,
        "text": " and then I'm triggering something asynchronous in draw",
        "tokens": [
          51428,
          293,
          550,
          286,
          478,
          40406,
          746,
          49174,
          294,
          2642,
          51570
        ]
      },
      {
        "avg_logprob": -0.3462908333594646,
        "compression_ratio": 1.6031746031746033,
        "end": 7202.96,
        "id": 2214,
        "no_speech_prob": 0.000009666087862569839,
        "seek": 717704,
        "start": 7201.16,
        "temperature": 0,
        "text": " and I could be asking to train the model",
        "tokens": [
          51570,
          293,
          286,
          727,
          312,
          3365,
          281,
          3847,
          264,
          2316,
          51660
        ]
      },
      {
        "avg_logprob": -0.3462908333594646,
        "compression_ratio": 1.6031746031746033,
        "end": 7205.16,
        "id": 2215,
        "no_speech_prob": 0.000009666087862569839,
        "seek": 717704,
        "start": 7202.96,
        "temperature": 0,
        "text": " before it's even done with the previous training",
        "tokens": [
          51660,
          949,
          309,
          311,
          754,
          1096,
          365,
          264,
          3894,
          3097,
          51770
        ]
      },
      {
        "avg_logprob": -0.4452549969708478,
        "compression_ratio": 1.683453237410072,
        "end": 7208.2,
        "id": 2216,
        "no_speech_prob": 0.00039204084896482527,
        "seek": 720516,
        "start": 7205.36,
        "temperature": 0,
        "text": " cycle, so this really should not be happening in draw.",
        "tokens": [
          50374,
          6586,
          11,
          370,
          341,
          534,
          820,
          406,
          312,
          2737,
          294,
          2642,
          13,
          50516
        ]
      },
      {
        "avg_logprob": -0.4452549969708478,
        "compression_ratio": 1.683453237410072,
        "end": 7213.2,
        "id": 2217,
        "no_speech_prob": 0.00039204084896482527,
        "seek": 720516,
        "start": 7208.2,
        "temperature": 0,
        "text": " Now, TensorFlow.js has a function called tf.nextframe.",
        "tokens": [
          50516,
          823,
          11,
          37624,
          13,
          25530,
          575,
          257,
          2445,
          1219,
          256,
          69,
          13,
          716,
          734,
          17265,
          13,
          50766
        ]
      },
      {
        "avg_logprob": -0.4452549969708478,
        "compression_ratio": 1.683453237410072,
        "end": 7216.5599999999995,
        "id": 2218,
        "no_speech_prob": 0.00039204084896482527,
        "seek": 720516,
        "start": 7213.32,
        "temperature": 0,
        "text": " I want you to explore it and make a version of this",
        "tokens": [
          50772,
          286,
          528,
          291,
          281,
          6839,
          309,
          293,
          652,
          257,
          3037,
          295,
          341,
          50934
        ]
      },
      {
        "avg_logprob": -0.4452549969708478,
        "compression_ratio": 1.683453237410072,
        "end": 7218.96,
        "id": 2219,
        "no_speech_prob": 0.00039204084896482527,
        "seek": 720516,
        "start": 7216.5599999999995,
        "temperature": 0,
        "text": " with tf.nextframe as like an exercise",
        "tokens": [
          50934,
          365,
          256,
          69,
          13,
          716,
          734,
          17265,
          382,
          411,
          364,
          5380,
          51054
        ]
      },
      {
        "avg_logprob": -0.4452549969708478,
        "compression_ratio": 1.683453237410072,
        "end": 7220.16,
        "id": 2220,
        "no_speech_prob": 0.00039204084896482527,
        "seek": 720516,
        "start": 7218.96,
        "temperature": 0,
        "text": " after this video is over,",
        "tokens": [
          51054,
          934,
          341,
          960,
          307,
          670,
          11,
          51114
        ]
      },
      {
        "avg_logprob": -0.4452549969708478,
        "compression_ratio": 1.683453237410072,
        "end": 7221.599999999999,
        "id": 2221,
        "no_speech_prob": 0.00039204084896482527,
        "seek": 720516,
        "start": 7220.16,
        "temperature": 0,
        "text": " but I'm going to do it a different way without that",
        "tokens": [
          51114,
          457,
          286,
          478,
          516,
          281,
          360,
          309,
          257,
          819,
          636,
          1553,
          300,
          51186
        ]
      },
      {
        "avg_logprob": -0.4452549969708478,
        "compression_ratio": 1.683453237410072,
        "end": 7223.92,
        "id": 2222,
        "no_speech_prob": 0.00039204084896482527,
        "seek": 720516,
        "start": 7221.599999999999,
        "temperature": 0,
        "text": " because I got to come back to that in a different video,",
        "tokens": [
          51186,
          570,
          286,
          658,
          281,
          808,
          646,
          281,
          300,
          294,
          257,
          819,
          960,
          11,
          51302
        ]
      },
      {
        "avg_logprob": -0.4452549969708478,
        "compression_ratio": 1.683453237410072,
        "end": 7225.92,
        "id": 2223,
        "no_speech_prob": 0.00039204084896482527,
        "seek": 720516,
        "start": 7223.92,
        "temperature": 0,
        "text": " but first of all, this I also learned,",
        "tokens": [
          51302,
          457,
          700,
          295,
          439,
          11,
          341,
          286,
          611,
          3264,
          11,
          51402
        ]
      },
      {
        "avg_logprob": -0.4452549969708478,
        "compression_ratio": 1.683453237410072,
        "end": 7227.4,
        "id": 2224,
        "no_speech_prob": 0.00039204084896482527,
        "seek": 720516,
        "start": 7225.92,
        "temperature": 0,
        "text": " this is totally unnecessary.",
        "tokens": [
          51402,
          341,
          307,
          3879,
          19350,
          13,
          51476
        ]
      },
      {
        "avg_logprob": -0.4452549969708478,
        "compression_ratio": 1.683453237410072,
        "end": 7231.96,
        "id": 2225,
        "no_speech_prob": 0.00039204084896482527,
        "seek": 720516,
        "start": 7228.72,
        "temperature": 0,
        "text": " The await, a couple things.",
        "tokens": [
          51542,
          440,
          19670,
          11,
          257,
          1916,
          721,
          13,
          51704
        ]
      },
      {
        "avg_logprob": -0.4452549969708478,
        "compression_ratio": 1.683453237410072,
        "end": 7234.16,
        "id": 2226,
        "no_speech_prob": 0.00039204084896482527,
        "seek": 720516,
        "start": 7231.96,
        "temperature": 0,
        "text": " Number one is that the await function",
        "tokens": [
          51704,
          5118,
          472,
          307,
          300,
          264,
          19670,
          2445,
          51814
        ]
      },
      {
        "avg_logprob": -0.24270546891307102,
        "compression_ratio": 1.7095588235294117,
        "end": 7237.2,
        "id": 2227,
        "no_speech_prob": 0.0000043568793444137555,
        "seek": 723416,
        "start": 7234.72,
        "temperature": 0,
        "text": " number one is because there's just one thing",
        "tokens": [
          50392,
          1230,
          472,
          307,
          570,
          456,
          311,
          445,
          472,
          551,
          50516
        ]
      },
      {
        "avg_logprob": -0.24270546891307102,
        "compression_ratio": 1.7095588235294117,
        "end": 7239.94,
        "id": 2228,
        "no_speech_prob": 0.0000043568793444137555,
        "seek": 723416,
        "start": 7237.2,
        "temperature": 0,
        "text": " happening in here, I could just return the promise.",
        "tokens": [
          50516,
          2737,
          294,
          510,
          11,
          286,
          727,
          445,
          2736,
          264,
          6228,
          13,
          50653
        ]
      },
      {
        "avg_logprob": -0.24270546891307102,
        "compression_ratio": 1.7095588235294117,
        "end": 7243.12,
        "id": 2229,
        "no_speech_prob": 0.0000043568793444137555,
        "seek": 723416,
        "start": 7239.94,
        "temperature": 0,
        "text": " This doesn't actually have to be an async function",
        "tokens": [
          50653,
          639,
          1177,
          380,
          767,
          362,
          281,
          312,
          364,
          382,
          34015,
          2445,
          50812
        ]
      },
      {
        "avg_logprob": -0.24270546891307102,
        "compression_ratio": 1.7095588235294117,
        "end": 7245.76,
        "id": 2230,
        "no_speech_prob": 0.0000043568793444137555,
        "seek": 723416,
        "start": 7243.12,
        "temperature": 0,
        "text": " and then I do not need the tf.tidy",
        "tokens": [
          50812,
          293,
          550,
          286,
          360,
          406,
          643,
          264,
          256,
          69,
          13,
          83,
          38836,
          50944
        ]
      },
      {
        "avg_logprob": -0.24270546891307102,
        "compression_ratio": 1.7095588235294117,
        "end": 7248.72,
        "id": 2231,
        "no_speech_prob": 0.0000043568793444137555,
        "seek": 723416,
        "start": 7245.76,
        "temperature": 0,
        "text": " because model.fit kind of will clean itself up",
        "tokens": [
          50944,
          570,
          2316,
          13,
          6845,
          733,
          295,
          486,
          2541,
          2564,
          493,
          51092
        ]
      },
      {
        "avg_logprob": -0.24270546891307102,
        "compression_ratio": 1.7095588235294117,
        "end": 7252.36,
        "id": 2232,
        "no_speech_prob": 0.0000043568793444137555,
        "seek": 723416,
        "start": 7248.72,
        "temperature": 0,
        "text": " automatically for you, so this should still work just fine",
        "tokens": [
          51092,
          6772,
          337,
          291,
          11,
          370,
          341,
          820,
          920,
          589,
          445,
          2489,
          51274
        ]
      },
      {
        "avg_logprob": -0.24270546891307102,
        "compression_ratio": 1.7095588235294117,
        "end": 7256.3,
        "id": 2233,
        "no_speech_prob": 0.0000043568793444137555,
        "seek": 723416,
        "start": 7254.5199999999995,
        "temperature": 0,
        "text": " and I should be able to see the number of tensors",
        "tokens": [
          51382,
          293,
          286,
          820,
          312,
          1075,
          281,
          536,
          264,
          1230,
          295,
          10688,
          830,
          51471
        ]
      },
      {
        "avg_logprob": -0.24270546891307102,
        "compression_ratio": 1.7095588235294117,
        "end": 7259.08,
        "id": 2234,
        "no_speech_prob": 0.0000043568793444137555,
        "seek": 723416,
        "start": 7256.3,
        "temperature": 0,
        "text": " is still 15, so that was something that I didn't need",
        "tokens": [
          51471,
          307,
          920,
          2119,
          11,
          370,
          300,
          390,
          746,
          300,
          286,
          994,
          380,
          643,
          51610
        ]
      },
      {
        "avg_logprob": -0.24270546891307102,
        "compression_ratio": 1.7095588235294117,
        "end": 7260.28,
        "id": 2235,
        "no_speech_prob": 0.0000043568793444137555,
        "seek": 723416,
        "start": 7259.08,
        "temperature": 0,
        "text": " that I've now fixed.",
        "tokens": [
          51610,
          300,
          286,
          600,
          586,
          6806,
          13,
          51670
        ]
      },
      {
        "avg_logprob": -0.24270546891307102,
        "compression_ratio": 1.7095588235294117,
        "end": 7262.36,
        "id": 2236,
        "no_speech_prob": 0.0000043568793444137555,
        "seek": 723416,
        "start": 7260.28,
        "temperature": 0,
        "text": " Now, what I really want to do is I want to get this",
        "tokens": [
          51670,
          823,
          11,
          437,
          286,
          534,
          528,
          281,
          360,
          307,
          286,
          528,
          281,
          483,
          341,
          51774
        ]
      },
      {
        "avg_logprob": -0.2402791793529804,
        "compression_ratio": 2.012121212121212,
        "end": 7265.759999999999,
        "id": 2237,
        "no_speech_prob": 0.00004198626265861094,
        "seek": 726236,
        "start": 7262.36,
        "temperature": 0,
        "text": " out of draw, so let's comment this out here",
        "tokens": [
          50364,
          484,
          295,
          2642,
          11,
          370,
          718,
          311,
          2871,
          341,
          484,
          510,
          50534
        ]
      },
      {
        "avg_logprob": -0.2402791793529804,
        "compression_ratio": 2.012121212121212,
        "end": 7267.92,
        "id": 2238,
        "no_speech_prob": 0.00004198626265861094,
        "seek": 726236,
        "start": 7265.759999999999,
        "temperature": 0,
        "text": " and what I'm actually going to do",
        "tokens": [
          50534,
          293,
          437,
          286,
          478,
          767,
          516,
          281,
          360,
          50642
        ]
      },
      {
        "avg_logprob": -0.2402791793529804,
        "compression_ratio": 2.012121212121212,
        "end": 7270.96,
        "id": 2239,
        "no_speech_prob": 0.00004198626265861094,
        "seek": 726236,
        "start": 7267.92,
        "temperature": 0,
        "text": " is I'm going to write a separate function called train",
        "tokens": [
          50642,
          307,
          286,
          478,
          516,
          281,
          2464,
          257,
          4994,
          2445,
          1219,
          3847,
          50794
        ]
      },
      {
        "avg_logprob": -0.2402791793529804,
        "compression_ratio": 2.012121212121212,
        "end": 7277.58,
        "id": 2240,
        "no_speech_prob": 0.00004198626265861094,
        "seek": 726236,
        "start": 7272.58,
        "temperature": 0,
        "text": " and in that function, I'm going to say set time,",
        "tokens": [
          50875,
          293,
          294,
          300,
          2445,
          11,
          286,
          478,
          516,
          281,
          584,
          992,
          565,
          11,
          51125
        ]
      },
      {
        "avg_logprob": -0.2402791793529804,
        "compression_ratio": 2.012121212121212,
        "end": 7282.44,
        "id": 2241,
        "no_speech_prob": 0.00004198626265861094,
        "seek": 726236,
        "start": 7279.599999999999,
        "temperature": 0,
        "text": " okay, wait, wait, wait, I'm going to call train model,",
        "tokens": [
          51226,
          1392,
          11,
          1699,
          11,
          1699,
          11,
          1699,
          11,
          286,
          478,
          516,
          281,
          818,
          3847,
          2316,
          11,
          51368
        ]
      },
      {
        "avg_logprob": -0.2402791793529804,
        "compression_ratio": 2.012121212121212,
        "end": 7283.28,
        "id": 2242,
        "no_speech_prob": 0.00004198626265861094,
        "seek": 726236,
        "start": 7282.44,
        "temperature": 0,
        "text": " wait, hold on.",
        "tokens": [
          51368,
          1699,
          11,
          1797,
          322,
          13,
          51410
        ]
      },
      {
        "avg_logprob": -0.2402791793529804,
        "compression_ratio": 2.012121212121212,
        "end": 7288.08,
        "id": 2243,
        "no_speech_prob": 0.00004198626265861094,
        "seek": 726236,
        "start": 7284.92,
        "temperature": 0,
        "text": " I'm going to call train model, yes, yes.",
        "tokens": [
          51492,
          286,
          478,
          516,
          281,
          818,
          3847,
          2316,
          11,
          2086,
          11,
          2086,
          13,
          51650
        ]
      },
      {
        "avg_logprob": -0.2402791793529804,
        "compression_ratio": 2.012121212121212,
        "end": 7290.04,
        "id": 2244,
        "no_speech_prob": 0.00004198626265861094,
        "seek": 726236,
        "start": 7288.08,
        "temperature": 0,
        "text": " In that function, I'm going to do this.",
        "tokens": [
          51650,
          682,
          300,
          2445,
          11,
          286,
          478,
          516,
          281,
          360,
          341,
          13,
          51748
        ]
      },
      {
        "avg_logprob": -0.28418966020856584,
        "compression_ratio": 1.855140186915888,
        "end": 7297.96,
        "id": 2245,
        "no_speech_prob": 0.000050644666771404445,
        "seek": 729236,
        "start": 7293.2,
        "temperature": 0,
        "text": " I'm going to separate function that does this piece of it,",
        "tokens": [
          50406,
          286,
          478,
          516,
          281,
          4994,
          2445,
          300,
          775,
          341,
          2522,
          295,
          309,
          11,
          50644
        ]
      },
      {
        "avg_logprob": -0.28418966020856584,
        "compression_ratio": 1.855140186915888,
        "end": 7301.719999999999,
        "id": 2246,
        "no_speech_prob": 0.000050644666771404445,
        "seek": 729236,
        "start": 7297.96,
        "temperature": 0,
        "text": " that console logs the history and I could use",
        "tokens": [
          50644,
          300,
          11076,
          20820,
          264,
          2503,
          293,
          286,
          727,
          764,
          50832
        ]
      },
      {
        "avg_logprob": -0.28418966020856584,
        "compression_ratio": 1.855140186915888,
        "end": 7306.719999999999,
        "id": 2247,
        "no_speech_prob": 0.000050644666771404445,
        "seek": 729236,
        "start": 7301.719999999999,
        "temperature": 0,
        "text": " and what I want to do is I want to say set time out,",
        "tokens": [
          50832,
          293,
          437,
          286,
          528,
          281,
          360,
          307,
          286,
          528,
          281,
          584,
          992,
          565,
          484,
          11,
          51082
        ]
      },
      {
        "avg_logprob": -0.28418966020856584,
        "compression_ratio": 1.855140186915888,
        "end": 7309.44,
        "id": 2248,
        "no_speech_prob": 0.000050644666771404445,
        "seek": 729236,
        "start": 7306.88,
        "temperature": 0,
        "text": " call the train function in 100 milliseconds,",
        "tokens": [
          51090,
          818,
          264,
          3847,
          2445,
          294,
          2319,
          34184,
          11,
          51218
        ]
      },
      {
        "avg_logprob": -0.28418966020856584,
        "compression_ratio": 1.855140186915888,
        "end": 7310.96,
        "id": 2249,
        "no_speech_prob": 0.000050644666771404445,
        "seek": 729236,
        "start": 7309.44,
        "temperature": 0,
        "text": " so I want to just let the program start,",
        "tokens": [
          51218,
          370,
          286,
          528,
          281,
          445,
          718,
          264,
          1461,
          722,
          11,
          51294
        ]
      },
      {
        "avg_logprob": -0.28418966020856584,
        "compression_ratio": 1.855140186915888,
        "end": 7313.96,
        "id": 2250,
        "no_speech_prob": 0.000050644666771404445,
        "seek": 729236,
        "start": 7310.96,
        "temperature": 0,
        "text": " say 100 milliseconds later, call this train function.",
        "tokens": [
          51294,
          584,
          2319,
          34184,
          1780,
          11,
          818,
          341,
          3847,
          2445,
          13,
          51444
        ]
      },
      {
        "avg_logprob": -0.28418966020856584,
        "compression_ratio": 1.855140186915888,
        "end": 7315.96,
        "id": 2251,
        "no_speech_prob": 0.000050644666771404445,
        "seek": 729236,
        "start": 7313.96,
        "temperature": 0,
        "text": " Train the model, which does the fitting.",
        "tokens": [
          51444,
          28029,
          264,
          2316,
          11,
          597,
          775,
          264,
          15669,
          13,
          51544
        ]
      },
      {
        "avg_logprob": -0.28418966020856584,
        "compression_ratio": 1.855140186915888,
        "end": 7320.96,
        "id": 2252,
        "no_speech_prob": 0.000050644666771404445,
        "seek": 729236,
        "start": 7315.96,
        "temperature": 0,
        "text": " When that's done, log the history and now say set time out",
        "tokens": [
          51544,
          1133,
          300,
          311,
          1096,
          11,
          3565,
          264,
          2503,
          293,
          586,
          584,
          992,
          565,
          484,
          51794
        ]
      },
      {
        "avg_logprob": -0.26101929800851004,
        "compression_ratio": 1.756183745583039,
        "end": 7327.08,
        "id": 2253,
        "no_speech_prob": 0.00007843780622351915,
        "seek": 732236,
        "start": 7323.28,
        "temperature": 0,
        "text": " train 100, so this is sort of like recursion.",
        "tokens": [
          50410,
          3847,
          2319,
          11,
          370,
          341,
          307,
          1333,
          295,
          411,
          20560,
          313,
          13,
          50600
        ]
      },
      {
        "avg_logprob": -0.26101929800851004,
        "compression_ratio": 1.756183745583039,
        "end": 7328.679999999999,
        "id": 2254,
        "no_speech_prob": 0.00007843780622351915,
        "seek": 732236,
        "start": 7327.08,
        "temperature": 0,
        "text": " I don't want to use set interval here",
        "tokens": [
          50600,
          286,
          500,
          380,
          528,
          281,
          764,
          992,
          15035,
          510,
          50680
        ]
      },
      {
        "avg_logprob": -0.26101929800851004,
        "compression_ratio": 1.756183745583039,
        "end": 7330.28,
        "id": 2255,
        "no_speech_prob": 0.00007843780622351915,
        "seek": 732236,
        "start": 7328.679999999999,
        "temperature": 0,
        "text": " because I only want to call train again",
        "tokens": [
          50680,
          570,
          286,
          787,
          528,
          281,
          818,
          3847,
          797,
          50760
        ]
      },
      {
        "avg_logprob": -0.26101929800851004,
        "compression_ratio": 1.756183745583039,
        "end": 7333.08,
        "id": 2256,
        "no_speech_prob": 0.00007843780622351915,
        "seek": 732236,
        "start": 7330.28,
        "temperature": 0,
        "text": " once it's finished with training the model itself,",
        "tokens": [
          50760,
          1564,
          309,
          311,
          4335,
          365,
          3097,
          264,
          2316,
          2564,
          11,
          50900
        ]
      },
      {
        "avg_logprob": -0.26101929800851004,
        "compression_ratio": 1.756183745583039,
        "end": 7335.62,
        "id": 2257,
        "no_speech_prob": 0.00007843780622351915,
        "seek": 732236,
        "start": 7333.08,
        "temperature": 0,
        "text": " so this is kind of like, hey, train and by the way,",
        "tokens": [
          50900,
          370,
          341,
          307,
          733,
          295,
          411,
          11,
          4177,
          11,
          3847,
          293,
          538,
          264,
          636,
          11,
          51027
        ]
      },
      {
        "avg_logprob": -0.26101929800851004,
        "compression_ratio": 1.756183745583039,
        "end": 7337.86,
        "id": 2258,
        "no_speech_prob": 0.00007843780622351915,
        "seek": 732236,
        "start": 7335.62,
        "temperature": 0,
        "text": " I could just increase the number of epics",
        "tokens": [
          51027,
          286,
          727,
          445,
          3488,
          264,
          1230,
          295,
          2388,
          1167,
          51139
        ]
      },
      {
        "avg_logprob": -0.26101929800851004,
        "compression_ratio": 1.756183745583039,
        "end": 7339.12,
        "id": 2259,
        "no_speech_prob": 0.00007843780622351915,
        "seek": 732236,
        "start": 7337.86,
        "temperature": 0,
        "text": " or maybe do some kind of loop,",
        "tokens": [
          51139,
          420,
          1310,
          360,
          512,
          733,
          295,
          6367,
          11,
          51202
        ]
      },
      {
        "avg_logprob": -0.26101929800851004,
        "compression_ratio": 1.756183745583039,
        "end": 7340.5199999999995,
        "id": 2260,
        "no_speech_prob": 0.00007843780622351915,
        "seek": 732236,
        "start": 7339.12,
        "temperature": 0,
        "text": " but I think this would be a sort of nice way",
        "tokens": [
          51202,
          457,
          286,
          519,
          341,
          576,
          312,
          257,
          1333,
          295,
          1481,
          636,
          51272
        ]
      },
      {
        "avg_logprob": -0.26101929800851004,
        "compression_ratio": 1.756183745583039,
        "end": 7343.44,
        "id": 2261,
        "no_speech_prob": 0.00007843780622351915,
        "seek": 732236,
        "start": 7340.5199999999995,
        "temperature": 0,
        "text": " to demonstrate it and if I just called train directly",
        "tokens": [
          51272,
          281,
          11698,
          309,
          293,
          498,
          286,
          445,
          1219,
          3847,
          3838,
          51418
        ]
      },
      {
        "avg_logprob": -0.26101929800851004,
        "compression_ratio": 1.756183745583039,
        "end": 7349.16,
        "id": 2262,
        "no_speech_prob": 0.00007843780622351915,
        "seek": 732236,
        "start": 7345.96,
        "temperature": 0,
        "text": " without a set timeout, I'm never going to be giving back",
        "tokens": [
          51544,
          1553,
          257,
          992,
          565,
          346,
          11,
          286,
          478,
          1128,
          516,
          281,
          312,
          2902,
          646,
          51704
        ]
      },
      {
        "avg_logprob": -0.26101929800851004,
        "compression_ratio": 1.756183745583039,
        "end": 7350.799999999999,
        "id": 2263,
        "no_speech_prob": 0.00007843780622351915,
        "seek": 732236,
        "start": 7349.16,
        "temperature": 0,
        "text": " control for a second, I could end up with",
        "tokens": [
          51704,
          1969,
          337,
          257,
          1150,
          11,
          286,
          727,
          917,
          493,
          365,
          51786
        ]
      },
      {
        "avg_logprob": -0.2558337620326451,
        "compression_ratio": 1.6615384615384616,
        "end": 7353.16,
        "id": 2264,
        "no_speech_prob": 0.0005442115943878889,
        "seek": 735080,
        "start": 7351.24,
        "temperature": 0,
        "text": " blocking, so I might even be able to get this down",
        "tokens": [
          50386,
          17776,
          11,
          370,
          286,
          1062,
          754,
          312,
          1075,
          281,
          483,
          341,
          760,
          50482
        ]
      },
      {
        "avg_logprob": -0.2558337620326451,
        "compression_ratio": 1.6615384615384616,
        "end": 7355.64,
        "id": 2265,
        "no_speech_prob": 0.0005442115943878889,
        "seek": 735080,
        "start": 7353.16,
        "temperature": 0,
        "text": " to 10 milliseconds, just something really, really low,",
        "tokens": [
          50482,
          281,
          1266,
          34184,
          11,
          445,
          746,
          534,
          11,
          534,
          2295,
          11,
          50606
        ]
      },
      {
        "avg_logprob": -0.2558337620326451,
        "compression_ratio": 1.6615384615384616,
        "end": 7359.360000000001,
        "id": 2266,
        "no_speech_prob": 0.0005442115943878889,
        "seek": 735080,
        "start": 7355.64,
        "temperature": 0,
        "text": " so let's run this and sort of see.",
        "tokens": [
          50606,
          370,
          718,
          311,
          1190,
          341,
          293,
          1333,
          295,
          536,
          13,
          50792
        ]
      },
      {
        "avg_logprob": -0.2558337620326451,
        "compression_ratio": 1.6615384615384616,
        "end": 7361.56,
        "id": 2267,
        "no_speech_prob": 0.0005442115943878889,
        "seek": 735080,
        "start": 7359.360000000001,
        "temperature": 0,
        "text": " Same result, we can see, there we go,",
        "tokens": [
          50792,
          10635,
          1874,
          11,
          321,
          393,
          536,
          11,
          456,
          321,
          352,
          11,
          50902
        ]
      },
      {
        "avg_logprob": -0.2558337620326451,
        "compression_ratio": 1.6615384615384616,
        "end": 7363.52,
        "id": 2268,
        "no_speech_prob": 0.0005442115943878889,
        "seek": 735080,
        "start": 7361.56,
        "temperature": 0,
        "text": " things are working, but at least now,",
        "tokens": [
          50902,
          721,
          366,
          1364,
          11,
          457,
          412,
          1935,
          586,
          11,
          51000
        ]
      },
      {
        "avg_logprob": -0.2558337620326451,
        "compression_ratio": 1.6615384615384616,
        "end": 7366.16,
        "id": 2269,
        "no_speech_prob": 0.0005442115943878889,
        "seek": 735080,
        "start": 7363.52,
        "temperature": 0,
        "text": " I have gotten that out of draw,",
        "tokens": [
          51000,
          286,
          362,
          5768,
          300,
          484,
          295,
          2642,
          11,
          51132
        ]
      },
      {
        "avg_logprob": -0.2558337620326451,
        "compression_ratio": 1.6615384615384616,
        "end": 7368.56,
        "id": 2270,
        "no_speech_prob": 0.0005442115943878889,
        "seek": 735080,
        "start": 7366.16,
        "temperature": 0,
        "text": " so draw is happening on its own and in fact,",
        "tokens": [
          51132,
          370,
          2642,
          307,
          2737,
          322,
          1080,
          1065,
          293,
          294,
          1186,
          11,
          51252
        ]
      },
      {
        "avg_logprob": -0.2558337620326451,
        "compression_ratio": 1.6615384615384616,
        "end": 7369.92,
        "id": 2271,
        "no_speech_prob": 0.0005442115943878889,
        "seek": 735080,
        "start": 7368.56,
        "temperature": 0,
        "text": " what I could really do is I could say,",
        "tokens": [
          51252,
          437,
          286,
          727,
          534,
          360,
          307,
          286,
          727,
          584,
          11,
          51320
        ]
      },
      {
        "avg_logprob": -0.2558337620326451,
        "compression_ratio": 1.6615384615384616,
        "end": 7373.400000000001,
        "id": 2272,
        "no_speech_prob": 0.0005442115943878889,
        "seek": 735080,
        "start": 7369.92,
        "temperature": 0,
        "text": " hey, try doing this with 100 epics each time.",
        "tokens": [
          51320,
          4177,
          11,
          853,
          884,
          341,
          365,
          2319,
          2388,
          1167,
          1184,
          565,
          13,
          51494
        ]
      },
      {
        "avg_logprob": -0.2558337620326451,
        "compression_ratio": 1.6615384615384616,
        "end": 7375.24,
        "id": 2273,
        "no_speech_prob": 0.0005442115943878889,
        "seek": 735080,
        "start": 7373.400000000001,
        "temperature": 0,
        "text": " Epochs, what is it?",
        "tokens": [
          51494,
          462,
          2259,
          28346,
          11,
          437,
          307,
          309,
          30,
          51586
        ]
      },
      {
        "avg_logprob": -0.2558337620326451,
        "compression_ratio": 1.6615384615384616,
        "end": 7378.68,
        "id": 2274,
        "no_speech_prob": 0.0005442115943878889,
        "seek": 735080,
        "start": 7376.84,
        "temperature": 0,
        "text": " And you can see the loss function",
        "tokens": [
          51666,
          400,
          291,
          393,
          536,
          264,
          4470,
          2445,
          51758
        ]
      },
      {
        "avg_logprob": -0.37714784536788715,
        "compression_ratio": 1.435897435897436,
        "end": 7380.8,
        "id": 2275,
        "no_speech_prob": 0.00003321418262203224,
        "seek": 737868,
        "start": 7378.68,
        "temperature": 0,
        "text": " is coming out much more slowly,",
        "tokens": [
          50364,
          307,
          1348,
          484,
          709,
          544,
          5692,
          11,
          50470
        ]
      },
      {
        "avg_logprob": -0.37714784536788715,
        "compression_ratio": 1.435897435897436,
        "end": 7386.34,
        "id": 2276,
        "no_speech_prob": 0.00003321418262203224,
        "seek": 737868,
        "start": 7381.84,
        "temperature": 0,
        "text": " but the frame rate, let me just clear this for a second.",
        "tokens": [
          50522,
          457,
          264,
          3920,
          3314,
          11,
          718,
          385,
          445,
          1850,
          341,
          337,
          257,
          1150,
          13,
          50747
        ]
      },
      {
        "avg_logprob": -0.37714784536788715,
        "compression_ratio": 1.435897435897436,
        "end": 7393.16,
        "id": 2277,
        "no_speech_prob": 0.00003321418262203224,
        "seek": 737868,
        "start": 7388.16,
        "temperature": 0,
        "text": " The frame rate is quite fast, hold on,",
        "tokens": [
          50838,
          440,
          3920,
          3314,
          307,
          1596,
          2370,
          11,
          1797,
          322,
          11,
          51088
        ]
      },
      {
        "avg_logprob": -0.37714784536788715,
        "compression_ratio": 1.435897435897436,
        "end": 7395.8,
        "id": 2278,
        "no_speech_prob": 0.00003321418262203224,
        "seek": 737868,
        "start": 7394.56,
        "temperature": 0,
        "text": " this is too confusing.",
        "tokens": [
          51158,
          341,
          307,
          886,
          13181,
          13,
          51220
        ]
      },
      {
        "avg_logprob": -0.37714784536788715,
        "compression_ratio": 1.435897435897436,
        "end": 7404.4400000000005,
        "id": 2279,
        "no_speech_prob": 0.00003321418262203224,
        "seek": 737868,
        "start": 7401.5,
        "temperature": 0,
        "text": " I probably need to give it back more time,",
        "tokens": [
          51505,
          286,
          1391,
          643,
          281,
          976,
          309,
          646,
          544,
          565,
          11,
          51652
        ]
      },
      {
        "avg_logprob": -0.37714784536788715,
        "compression_ratio": 1.435897435897436,
        "end": 7406.08,
        "id": 2280,
        "no_speech_prob": 0.00003321418262203224,
        "seek": 737868,
        "start": 7404.4400000000005,
        "temperature": 0,
        "text": " let's do another little break.",
        "tokens": [
          51652,
          718,
          311,
          360,
          1071,
          707,
          1821,
          13,
          51734
        ]
      },
      {
        "avg_logprob": -0.24374488446352294,
        "compression_ratio": 1.7402135231316727,
        "end": 7410.68,
        "id": 2281,
        "no_speech_prob": 0.0003353494103066623,
        "seek": 740608,
        "start": 7406.92,
        "temperature": 0,
        "text": " Let me, I just want to take out the console log thing",
        "tokens": [
          50406,
          961,
          385,
          11,
          286,
          445,
          528,
          281,
          747,
          484,
          264,
          11076,
          3565,
          551,
          50594
        ]
      },
      {
        "avg_logprob": -0.24374488446352294,
        "compression_ratio": 1.7402135231316727,
        "end": 7411.64,
        "id": 2282,
        "no_speech_prob": 0.0003353494103066623,
        "seek": 740608,
        "start": 7410.68,
        "temperature": 0,
        "text": " so I can look at the frame rate,",
        "tokens": [
          50594,
          370,
          286,
          393,
          574,
          412,
          264,
          3920,
          3314,
          11,
          50642
        ]
      },
      {
        "avg_logprob": -0.24374488446352294,
        "compression_ratio": 1.7402135231316727,
        "end": 7414.28,
        "id": 2283,
        "no_speech_prob": 0.0003353494103066623,
        "seek": 740608,
        "start": 7411.64,
        "temperature": 0,
        "text": " I should just put the frame rate in the DOM,",
        "tokens": [
          50642,
          286,
          820,
          445,
          829,
          264,
          3920,
          3314,
          294,
          264,
          35727,
          11,
          50774
        ]
      },
      {
        "avg_logprob": -0.24374488446352294,
        "compression_ratio": 1.7402135231316727,
        "end": 7416.6,
        "id": 2284,
        "no_speech_prob": 0.0003353494103066623,
        "seek": 740608,
        "start": 7414.28,
        "temperature": 0,
        "text": " wouldn't that be smart?",
        "tokens": [
          50774,
          2759,
          380,
          300,
          312,
          4069,
          30,
          50890
        ]
      },
      {
        "avg_logprob": -0.24374488446352294,
        "compression_ratio": 1.7402135231316727,
        "end": 7419.08,
        "id": 2285,
        "no_speech_prob": 0.0003353494103066623,
        "seek": 740608,
        "start": 7416.6,
        "temperature": 0,
        "text": " But you can see, now I'm getting 30 frames,",
        "tokens": [
          50890,
          583,
          291,
          393,
          536,
          11,
          586,
          286,
          478,
          1242,
          2217,
          12083,
          11,
          51014
        ]
      },
      {
        "avg_logprob": -0.24374488446352294,
        "compression_ratio": 1.7402135231316727,
        "end": 7421.24,
        "id": 2286,
        "no_speech_prob": 0.0003353494103066623,
        "seek": 740608,
        "start": 7419.08,
        "temperature": 0,
        "text": " I'm getting a pretty high frame rate,",
        "tokens": [
          51014,
          286,
          478,
          1242,
          257,
          1238,
          1090,
          3920,
          3314,
          11,
          51122
        ]
      },
      {
        "avg_logprob": -0.24374488446352294,
        "compression_ratio": 1.7402135231316727,
        "end": 7422.96,
        "id": 2287,
        "no_speech_prob": 0.0003353494103066623,
        "seek": 740608,
        "start": 7421.24,
        "temperature": 0,
        "text": " even though the training is happening,",
        "tokens": [
          51122,
          754,
          1673,
          264,
          3097,
          307,
          2737,
          11,
          51208
        ]
      },
      {
        "avg_logprob": -0.24374488446352294,
        "compression_ratio": 1.7402135231316727,
        "end": 7425.44,
        "id": 2288,
        "no_speech_prob": 0.0003353494103066623,
        "seek": 740608,
        "start": 7422.96,
        "temperature": 0,
        "text": " it's almost, it's kind of like a,",
        "tokens": [
          51208,
          309,
          311,
          1920,
          11,
          309,
          311,
          733,
          295,
          411,
          257,
          11,
          51332
        ]
      },
      {
        "avg_logprob": -0.24374488446352294,
        "compression_ratio": 1.7402135231316727,
        "end": 7427.32,
        "id": 2289,
        "no_speech_prob": 0.0003353494103066623,
        "seek": 740608,
        "start": 7425.44,
        "temperature": 0,
        "text": " there is no threading in JavaScript,",
        "tokens": [
          51332,
          456,
          307,
          572,
          7207,
          278,
          294,
          15778,
          11,
          51426
        ]
      },
      {
        "avg_logprob": -0.24374488446352294,
        "compression_ratio": 1.7402135231316727,
        "end": 7429.44,
        "id": 2290,
        "no_speech_prob": 0.0003353494103066623,
        "seek": 740608,
        "start": 7427.32,
        "temperature": 0,
        "text": " so these things are just passing off",
        "tokens": [
          51426,
          370,
          613,
          721,
          366,
          445,
          8437,
          766,
          51532
        ]
      },
      {
        "avg_logprob": -0.24374488446352294,
        "compression_ratio": 1.7402135231316727,
        "end": 7431.86,
        "id": 2291,
        "no_speech_prob": 0.0003353494103066623,
        "seek": 740608,
        "start": 7429.44,
        "temperature": 0,
        "text": " and really, this might be a place where web workers",
        "tokens": [
          51532,
          293,
          534,
          11,
          341,
          1062,
          312,
          257,
          1081,
          689,
          3670,
          5600,
          51653
        ]
      },
      {
        "avg_logprob": -0.24374488446352294,
        "compression_ratio": 1.7402135231316727,
        "end": 7433.68,
        "id": 2292,
        "no_speech_prob": 0.0003353494103066623,
        "seek": 740608,
        "start": 7431.86,
        "temperature": 0,
        "text": " or something could do the training behind the scenes",
        "tokens": [
          51653,
          420,
          746,
          727,
          360,
          264,
          3097,
          2261,
          264,
          8026,
          51744
        ]
      },
      {
        "avg_logprob": -0.247536997156819,
        "compression_ratio": 1.5613382899628252,
        "end": 7436.56,
        "id": 2293,
        "no_speech_prob": 0.000011659524716378655,
        "seek": 743368,
        "start": 7433.68,
        "temperature": 0,
        "text": " in some fancy way, which maybe I will get to at some point.",
        "tokens": [
          50364,
          294,
          512,
          10247,
          636,
          11,
          597,
          1310,
          286,
          486,
          483,
          281,
          412,
          512,
          935,
          13,
          50508
        ]
      },
      {
        "avg_logprob": -0.247536997156819,
        "compression_ratio": 1.5613382899628252,
        "end": 7437.860000000001,
        "id": 2294,
        "no_speech_prob": 0.000011659524716378655,
        "seek": 743368,
        "start": 7436.56,
        "temperature": 0,
        "text": " Oh my goodness!",
        "tokens": [
          50508,
          876,
          452,
          8387,
          0,
          50573
        ]
      },
      {
        "avg_logprob": -0.247536997156819,
        "compression_ratio": 1.5613382899628252,
        "end": 7443.9800000000005,
        "id": 2295,
        "no_speech_prob": 0.000011659524716378655,
        "seek": 743368,
        "start": 7439.56,
        "temperature": 0,
        "text": " So, Alka is suggesting it might be better",
        "tokens": [
          50658,
          407,
          11,
          967,
          2330,
          307,
          18094,
          309,
          1062,
          312,
          1101,
          50879
        ]
      },
      {
        "avg_logprob": -0.247536997156819,
        "compression_ratio": 1.5613382899628252,
        "end": 7445.84,
        "id": 2296,
        "no_speech_prob": 0.000011659524716378655,
        "seek": 743368,
        "start": 7443.9800000000005,
        "temperature": 0,
        "text": " to use the draw loop and a Boolean",
        "tokens": [
          50879,
          281,
          764,
          264,
          2642,
          6367,
          293,
          257,
          23351,
          28499,
          50972
        ]
      },
      {
        "avg_logprob": -0.247536997156819,
        "compression_ratio": 1.5613382899628252,
        "end": 7447.400000000001,
        "id": 2297,
        "no_speech_prob": 0.000011659524716378655,
        "seek": 743368,
        "start": 7445.84,
        "temperature": 0,
        "text": " to know when it's safe to call it again,",
        "tokens": [
          50972,
          281,
          458,
          562,
          309,
          311,
          3273,
          281,
          818,
          309,
          797,
          11,
          51050
        ]
      },
      {
        "avg_logprob": -0.247536997156819,
        "compression_ratio": 1.5613382899628252,
        "end": 7449.16,
        "id": 2298,
        "no_speech_prob": 0.000011659524716378655,
        "seek": 743368,
        "start": 7447.400000000001,
        "temperature": 0,
        "text": " that would also be a good idea.",
        "tokens": [
          51050,
          300,
          576,
          611,
          312,
          257,
          665,
          1558,
          13,
          51138
        ]
      },
      {
        "avg_logprob": -0.247536997156819,
        "compression_ratio": 1.5613382899628252,
        "end": 7452.6,
        "id": 2299,
        "no_speech_prob": 0.000011659524716378655,
        "seek": 743368,
        "start": 7449.16,
        "temperature": 0,
        "text": " So you can see what kind of, I'm pulling my hair out,",
        "tokens": [
          51138,
          407,
          291,
          393,
          536,
          437,
          733,
          295,
          11,
          286,
          478,
          8407,
          452,
          2578,
          484,
          11,
          51310
        ]
      },
      {
        "avg_logprob": -0.247536997156819,
        "compression_ratio": 1.5613382899628252,
        "end": 7455.3,
        "id": 2300,
        "no_speech_prob": 0.000011659524716378655,
        "seek": 743368,
        "start": 7452.6,
        "temperature": 0,
        "text": " what kind of hassle situation we've gotten in.",
        "tokens": [
          51310,
          437,
          733,
          295,
          39526,
          2590,
          321,
          600,
          5768,
          294,
          13,
          51445
        ]
      },
      {
        "avg_logprob": -0.247536997156819,
        "compression_ratio": 1.5613382899628252,
        "end": 7459,
        "id": 2301,
        "no_speech_prob": 0.000011659524716378655,
        "seek": 743368,
        "start": 7455.3,
        "temperature": 0,
        "text": " But really, let's just put this back to two epochs,",
        "tokens": [
          51445,
          583,
          534,
          11,
          718,
          311,
          445,
          829,
          341,
          646,
          281,
          732,
          30992,
          28346,
          11,
          51630
        ]
      },
      {
        "avg_logprob": -0.247536997156819,
        "compression_ratio": 1.5613382899628252,
        "end": 7462.96,
        "id": 2302,
        "no_speech_prob": 0.000011659524716378655,
        "seek": 743368,
        "start": 7459,
        "temperature": 0,
        "text": " let's put this to little 10 milliseconds,",
        "tokens": [
          51630,
          718,
          311,
          829,
          341,
          281,
          707,
          1266,
          34184,
          11,
          51828
        ]
      },
      {
        "avg_logprob": -0.2203107803098617,
        "compression_ratio": 1.6059322033898304,
        "end": 7465.04,
        "id": 2303,
        "no_speech_prob": 0.00004400102261570282,
        "seek": 746296,
        "start": 7462.96,
        "temperature": 0,
        "text": " and we can sort of feel like, there we go,",
        "tokens": [
          50364,
          293,
          321,
          393,
          1333,
          295,
          841,
          411,
          11,
          456,
          321,
          352,
          11,
          50468
        ]
      },
      {
        "avg_logprob": -0.2203107803098617,
        "compression_ratio": 1.6059322033898304,
        "end": 7466.72,
        "id": 2304,
        "no_speech_prob": 0.00004400102261570282,
        "seek": 746296,
        "start": 7465.04,
        "temperature": 0,
        "text": " and I can look at the frame rate,",
        "tokens": [
          50468,
          293,
          286,
          393,
          574,
          412,
          264,
          3920,
          3314,
          11,
          50552
        ]
      },
      {
        "avg_logprob": -0.2203107803098617,
        "compression_ratio": 1.6059322033898304,
        "end": 7468.88,
        "id": 2305,
        "no_speech_prob": 0.00004400102261570282,
        "seek": 746296,
        "start": 7466.72,
        "temperature": 0,
        "text": " it's running nice 30 frames per second,",
        "tokens": [
          50552,
          309,
          311,
          2614,
          1481,
          2217,
          12083,
          680,
          1150,
          11,
          50660
        ]
      },
      {
        "avg_logprob": -0.2203107803098617,
        "compression_ratio": 1.6059322033898304,
        "end": 7470.84,
        "id": 2306,
        "no_speech_prob": 0.00004400102261570282,
        "seek": 746296,
        "start": 7468.88,
        "temperature": 0,
        "text": " and even though, and at some point,",
        "tokens": [
          50660,
          293,
          754,
          1673,
          11,
          293,
          412,
          512,
          935,
          11,
          50758
        ]
      },
      {
        "avg_logprob": -0.2203107803098617,
        "compression_ratio": 1.6059322033898304,
        "end": 7473.08,
        "id": 2307,
        "no_speech_prob": 0.00004400102261570282,
        "seek": 746296,
        "start": 7470.84,
        "temperature": 0,
        "text": " it's going to get there, what's that loss?",
        "tokens": [
          50758,
          309,
          311,
          516,
          281,
          483,
          456,
          11,
          437,
          311,
          300,
          4470,
          30,
          50870
        ]
      },
      {
        "avg_logprob": -0.2203107803098617,
        "compression_ratio": 1.6059322033898304,
        "end": 7475.76,
        "id": 2308,
        "no_speech_prob": 0.00004400102261570282,
        "seek": 746296,
        "start": 7473.08,
        "temperature": 0,
        "text": " I forgot to console log the loss, come back to me!",
        "tokens": [
          50870,
          286,
          5298,
          281,
          11076,
          3565,
          264,
          4470,
          11,
          808,
          646,
          281,
          385,
          0,
          51004
        ]
      },
      {
        "avg_logprob": -0.2203107803098617,
        "compression_ratio": 1.6059322033898304,
        "end": 7479.3,
        "id": 2309,
        "no_speech_prob": 0.00004400102261570282,
        "seek": 746296,
        "start": 7478.24,
        "temperature": 0,
        "text": " Come on!",
        "tokens": [
          51128,
          2492,
          322,
          0,
          51181
        ]
      },
      {
        "avg_logprob": -0.2203107803098617,
        "compression_ratio": 1.6059322033898304,
        "end": 7480.8,
        "id": 2310,
        "no_speech_prob": 0.00004400102261570282,
        "seek": 746296,
        "start": 7479.3,
        "temperature": 0,
        "text": " Oh, but let's see, I have an idea.",
        "tokens": [
          51181,
          876,
          11,
          457,
          718,
          311,
          536,
          11,
          286,
          362,
          364,
          1558,
          13,
          51256
        ]
      },
      {
        "avg_logprob": -0.2203107803098617,
        "compression_ratio": 1.6059322033898304,
        "end": 7483.68,
        "id": 2311,
        "no_speech_prob": 0.00004400102261570282,
        "seek": 746296,
        "start": 7480.8,
        "temperature": 0,
        "text": " What if, just before I go, just before I go,",
        "tokens": [
          51256,
          708,
          498,
          11,
          445,
          949,
          286,
          352,
          11,
          445,
          949,
          286,
          352,
          11,
          51400
        ]
      },
      {
        "avg_logprob": -0.2203107803098617,
        "compression_ratio": 1.6059322033898304,
        "end": 7488.68,
        "id": 2312,
        "no_speech_prob": 0.00004400102261570282,
        "seek": 746296,
        "start": 7483.68,
        "temperature": 0,
        "text": " what if we try using a different optimizer?",
        "tokens": [
          51400,
          437,
          498,
          321,
          853,
          1228,
          257,
          819,
          5028,
          6545,
          30,
          51650
        ]
      },
      {
        "avg_logprob": -0.3081813267299107,
        "compression_ratio": 1.4375,
        "end": 7492.5,
        "id": 2313,
        "no_speech_prob": 0.0001740050211083144,
        "seek": 748868,
        "start": 7489.56,
        "temperature": 0,
        "text": " What if we try using, for example,",
        "tokens": [
          50408,
          708,
          498,
          321,
          853,
          1228,
          11,
          337,
          1365,
          11,
          50555
        ]
      },
      {
        "avg_logprob": -0.3081813267299107,
        "compression_ratio": 1.4375,
        "end": 7496.04,
        "id": 2314,
        "no_speech_prob": 0.0001740050211083144,
        "seek": 748868,
        "start": 7494.200000000001,
        "temperature": 0,
        "text": " a different loss function?",
        "tokens": [
          50640,
          257,
          819,
          4470,
          2445,
          30,
          50732
        ]
      },
      {
        "avg_logprob": -0.3081813267299107,
        "compression_ratio": 1.4375,
        "end": 7500.84,
        "id": 2315,
        "no_speech_prob": 0.0001740050211083144,
        "seek": 748868,
        "start": 7500,
        "temperature": 0,
        "text": " Hold on.",
        "tokens": [
          50930,
          6962,
          322,
          13,
          50972
        ]
      },
      {
        "avg_logprob": -0.3081813267299107,
        "compression_ratio": 1.4375,
        "end": 7504.88,
        "id": 2316,
        "no_speech_prob": 0.0001740050211083144,
        "seek": 748868,
        "start": 7502.360000000001,
        "temperature": 0,
        "text": " This video's already 18 hours long.",
        "tokens": [
          51048,
          639,
          960,
          311,
          1217,
          2443,
          2496,
          938,
          13,
          51174
        ]
      },
      {
        "avg_logprob": -0.3081813267299107,
        "compression_ratio": 1.4375,
        "end": 7507.88,
        "id": 2317,
        "no_speech_prob": 0.0001740050211083144,
        "seek": 748868,
        "start": 7504.88,
        "temperature": 0,
        "text": " What if, oh no, no, no, a different optimizer, sorry.",
        "tokens": [
          51174,
          708,
          498,
          11,
          1954,
          572,
          11,
          572,
          11,
          572,
          11,
          257,
          819,
          5028,
          6545,
          11,
          2597,
          13,
          51324
        ]
      },
      {
        "avg_logprob": -0.3081813267299107,
        "compression_ratio": 1.4375,
        "end": 7509.9400000000005,
        "id": 2318,
        "no_speech_prob": 0.0001740050211083144,
        "seek": 748868,
        "start": 7507.88,
        "temperature": 0,
        "text": " What if I tried using the,",
        "tokens": [
          51324,
          708,
          498,
          286,
          3031,
          1228,
          264,
          11,
          51427
        ]
      },
      {
        "avg_logprob": -0.3081813267299107,
        "compression_ratio": 1.4375,
        "end": 7514.400000000001,
        "id": 2319,
        "no_speech_prob": 0.0001740050211083144,
        "seek": 748868,
        "start": 7512.96,
        "temperature": 0,
        "text": " the atom optimizer?",
        "tokens": [
          51578,
          264,
          12018,
          5028,
          6545,
          30,
          51650
        ]
      },
      {
        "avg_logprob": -0.4479172819404192,
        "compression_ratio": 1.4331210191082802,
        "end": 7519.12,
        "id": 2320,
        "no_speech_prob": 0.00002507153112674132,
        "seek": 751440,
        "start": 7515.24,
        "temperature": 0,
        "text": " So let's just try that, just for fun times.",
        "tokens": [
          50406,
          407,
          718,
          311,
          445,
          853,
          300,
          11,
          445,
          337,
          1019,
          1413,
          13,
          50600
        ]
      },
      {
        "avg_logprob": -0.4479172819404192,
        "compression_ratio": 1.4331210191082802,
        "end": 7520.92,
        "id": 2321,
        "no_speech_prob": 0.00002507153112674132,
        "seek": 751440,
        "start": 7519.12,
        "temperature": 0,
        "text": " Let's give it a lower learning rate.",
        "tokens": [
          50600,
          961,
          311,
          976,
          309,
          257,
          3126,
          2539,
          3314,
          13,
          50690
        ]
      },
      {
        "avg_logprob": -0.4479172819404192,
        "compression_ratio": 1.4331210191082802,
        "end": 7528.32,
        "id": 2322,
        "no_speech_prob": 0.00002507153112674132,
        "seek": 751440,
        "start": 7527.24,
        "temperature": 0,
        "text": " Whoa, look at that!",
        "tokens": [
          51006,
          7521,
          11,
          574,
          412,
          300,
          0,
          51060
        ]
      },
      {
        "avg_logprob": -0.4479172819404192,
        "compression_ratio": 1.4331210191082802,
        "end": 7529.9,
        "id": 2323,
        "no_speech_prob": 0.00002507153112674132,
        "seek": 751440,
        "start": 7528.32,
        "temperature": 0,
        "text": " Ha ha!",
        "tokens": [
          51060,
          4064,
          324,
          0,
          51139
        ]
      },
      {
        "avg_logprob": -0.4479172819404192,
        "compression_ratio": 1.4331210191082802,
        "end": 7531.2,
        "id": 2324,
        "no_speech_prob": 0.00002507153112674132,
        "seek": 751440,
        "start": 7529.9,
        "temperature": 0,
        "text": " Woo!",
        "tokens": [
          51139,
          10468,
          0,
          51204
        ]
      },
      {
        "avg_logprob": -0.4479172819404192,
        "compression_ratio": 1.4331210191082802,
        "end": 7532.04,
        "id": 2325,
        "no_speech_prob": 0.00002507153112674132,
        "seek": 751440,
        "start": 7531.2,
        "temperature": 0,
        "text": " Boom!",
        "tokens": [
          51204,
          15523,
          0,
          51246
        ]
      },
      {
        "avg_logprob": -0.4479172819404192,
        "compression_ratio": 1.4331210191082802,
        "end": 7532.879999999999,
        "id": 2326,
        "no_speech_prob": 0.00002507153112674132,
        "seek": 751440,
        "start": 7532.04,
        "temperature": 0,
        "text": " Yeah!",
        "tokens": [
          51246,
          865,
          0,
          51288
        ]
      },
      {
        "avg_logprob": -0.4479172819404192,
        "compression_ratio": 1.4331210191082802,
        "end": 7533.7,
        "id": 2327,
        "no_speech_prob": 0.00002507153112674132,
        "seek": 751440,
        "start": 7532.879999999999,
        "temperature": 0,
        "text": " Wow!",
        "tokens": [
          51288,
          3153,
          0,
          51329
        ]
      },
      {
        "avg_logprob": -0.4479172819404192,
        "compression_ratio": 1.4331210191082802,
        "end": 7534.7,
        "id": 2328,
        "no_speech_prob": 0.00002507153112674132,
        "seek": 751440,
        "start": 7533.7,
        "temperature": 0,
        "text": " Oh, stop it!",
        "tokens": [
          51329,
          876,
          11,
          1590,
          309,
          0,
          51379
        ]
      },
      {
        "avg_logprob": -0.4479172819404192,
        "compression_ratio": 1.4331210191082802,
        "end": 7538.12,
        "id": 2329,
        "no_speech_prob": 0.00002507153112674132,
        "seek": 751440,
        "start": 7536.48,
        "temperature": 0,
        "text": " All this time, all this time!",
        "tokens": [
          51468,
          1057,
          341,
          565,
          11,
          439,
          341,
          565,
          0,
          51550
        ]
      },
      {
        "avg_logprob": -0.4479172819404192,
        "compression_ratio": 1.4331210191082802,
        "end": 7539.799999999999,
        "id": 2330,
        "no_speech_prob": 0.00002507153112674132,
        "seek": 751440,
        "start": 7538.12,
        "temperature": 0,
        "text": " That was pretty exciting.",
        "tokens": [
          51550,
          663,
          390,
          1238,
          4670,
          13,
          51634
        ]
      },
      {
        "avg_logprob": -0.4479172819404192,
        "compression_ratio": 1.4331210191082802,
        "end": 7543,
        "id": 2331,
        "no_speech_prob": 0.00002507153112674132,
        "seek": 751440,
        "start": 7539.799999999999,
        "temperature": 0,
        "text": " Let's go, let's go, let's,",
        "tokens": [
          51634,
          961,
          311,
          352,
          11,
          718,
          311,
          352,
          11,
          718,
          311,
          11,
          51794
        ]
      },
      {
        "avg_logprob": -0.3009280274245913,
        "compression_ratio": 1.8203125,
        "end": 7547.44,
        "id": 2332,
        "no_speech_prob": 0.000010129977454198524,
        "seek": 754300,
        "start": 7543,
        "temperature": 0,
        "text": " let's make the resolution back to like 20.",
        "tokens": [
          50364,
          718,
          311,
          652,
          264,
          8669,
          646,
          281,
          411,
          945,
          13,
          50586
        ]
      },
      {
        "avg_logprob": -0.3009280274245913,
        "compression_ratio": 1.8203125,
        "end": 7551.32,
        "id": 2333,
        "no_speech_prob": 0.000010129977454198524,
        "seek": 754300,
        "start": 7547.44,
        "temperature": 0,
        "text": " Let me make the font size nice and tiny for us.",
        "tokens": [
          50586,
          961,
          385,
          652,
          264,
          10703,
          2744,
          1481,
          293,
          5870,
          337,
          505,
          13,
          50780
        ]
      },
      {
        "avg_logprob": -0.3009280274245913,
        "compression_ratio": 1.8203125,
        "end": 7553.04,
        "id": 2334,
        "no_speech_prob": 0.000010129977454198524,
        "seek": 754300,
        "start": 7551.32,
        "temperature": 0,
        "text": " Let me give myself some more space here.",
        "tokens": [
          50780,
          961,
          385,
          976,
          2059,
          512,
          544,
          1901,
          510,
          13,
          50866
        ]
      },
      {
        "avg_logprob": -0.3009280274245913,
        "compression_ratio": 1.8203125,
        "end": 7554.24,
        "id": 2335,
        "no_speech_prob": 0.000010129977454198524,
        "seek": 754300,
        "start": 7553.04,
        "temperature": 0,
        "text": " Hit refresh.",
        "tokens": [
          50866,
          9217,
          15134,
          13,
          50926
        ]
      },
      {
        "avg_logprob": -0.3009280274245913,
        "compression_ratio": 1.8203125,
        "end": 7556.58,
        "id": 2336,
        "no_speech_prob": 0.000010129977454198524,
        "seek": 754300,
        "start": 7555.12,
        "temperature": 0,
        "text": " And then let's look at this.",
        "tokens": [
          50970,
          400,
          550,
          718,
          311,
          574,
          412,
          341,
          13,
          51043
        ]
      },
      {
        "avg_logprob": -0.3009280274245913,
        "compression_ratio": 1.8203125,
        "end": 7559.08,
        "id": 2337,
        "no_speech_prob": 0.000010129977454198524,
        "seek": 754300,
        "start": 7557.72,
        "temperature": 0,
        "text": " Look at it learning there.",
        "tokens": [
          51100,
          2053,
          412,
          309,
          2539,
          456,
          13,
          51168
        ]
      },
      {
        "avg_logprob": -0.3009280274245913,
        "compression_ratio": 1.8203125,
        "end": 7560.58,
        "id": 2338,
        "no_speech_prob": 0.000010129977454198524,
        "seek": 754300,
        "start": 7559.08,
        "temperature": 0,
        "text": " Ah, look at that, that is beautiful.",
        "tokens": [
          51168,
          2438,
          11,
          574,
          412,
          300,
          11,
          300,
          307,
          2238,
          13,
          51243
        ]
      },
      {
        "avg_logprob": -0.3009280274245913,
        "compression_ratio": 1.8203125,
        "end": 7563.24,
        "id": 2339,
        "no_speech_prob": 0.000010129977454198524,
        "seek": 754300,
        "start": 7560.58,
        "temperature": 0,
        "text": " Look at it learning XOR so nice and fast.",
        "tokens": [
          51243,
          2053,
          412,
          309,
          2539,
          1783,
          2483,
          370,
          1481,
          293,
          2370,
          13,
          51376
        ]
      },
      {
        "avg_logprob": -0.3009280274245913,
        "compression_ratio": 1.8203125,
        "end": 7565.16,
        "id": 2340,
        "no_speech_prob": 0.000010129977454198524,
        "seek": 754300,
        "start": 7563.24,
        "temperature": 0,
        "text": " I'm just going to hit refresh again.",
        "tokens": [
          51376,
          286,
          478,
          445,
          516,
          281,
          2045,
          15134,
          797,
          13,
          51472
        ]
      },
      {
        "avg_logprob": -0.3009280274245913,
        "compression_ratio": 1.8203125,
        "end": 7566,
        "id": 2341,
        "no_speech_prob": 0.000010129977454198524,
        "seek": 754300,
        "start": 7565.16,
        "temperature": 0,
        "text": " We can see it.",
        "tokens": [
          51472,
          492,
          393,
          536,
          309,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.3009280274245913,
        "compression_ratio": 1.8203125,
        "end": 7567.52,
        "id": 2342,
        "no_speech_prob": 0.000010129977454198524,
        "seek": 754300,
        "start": 7566,
        "temperature": 0,
        "text": " Blah, blah, blah, blah, blah, blah, blah, blah.",
        "tokens": [
          51514,
          2177,
          545,
          11,
          12288,
          11,
          12288,
          11,
          12288,
          11,
          12288,
          11,
          12288,
          11,
          12288,
          11,
          12288,
          13,
          51590
        ]
      },
      {
        "avg_logprob": -0.3009280274245913,
        "compression_ratio": 1.8203125,
        "end": 7569.08,
        "id": 2343,
        "no_speech_prob": 0.000010129977454198524,
        "seek": 754300,
        "start": 7567.52,
        "temperature": 0,
        "text": " All right, so we can see,",
        "tokens": [
          51590,
          1057,
          558,
          11,
          370,
          321,
          393,
          536,
          11,
          51668
        ]
      },
      {
        "avg_logprob": -0.3009280274245913,
        "compression_ratio": 1.8203125,
        "end": 7572.44,
        "id": 2344,
        "no_speech_prob": 0.000010129977454198524,
        "seek": 754300,
        "start": 7569.08,
        "temperature": 0,
        "text": " I got, we really should look at what this atom optimizer is.",
        "tokens": [
          51668,
          286,
          658,
          11,
          321,
          534,
          820,
          574,
          412,
          437,
          341,
          12018,
          5028,
          6545,
          307,
          13,
          51836
        ]
      },
      {
        "avg_logprob": -0.4341080592228816,
        "compression_ratio": 1.2937062937062938,
        "end": 7577.36,
        "id": 2345,
        "no_speech_prob": 0.00004539754445431754,
        "seek": 757244,
        "start": 7572.719999999999,
        "temperature": 0,
        "text": " And I will link to a paper and some more information",
        "tokens": [
          50378,
          400,
          286,
          486,
          2113,
          281,
          257,
          3035,
          293,
          512,
          544,
          1589,
          50610
        ]
      },
      {
        "avg_logprob": -0.4341080592228816,
        "compression_ratio": 1.2937062937062938,
        "end": 7581.639999999999,
        "id": 2346,
        "no_speech_prob": 0.00004539754445431754,
        "seek": 757244,
        "start": 7577.36,
        "temperature": 0,
        "text": " about what the atom optimizer is.",
        "tokens": [
          50610,
          466,
          437,
          264,
          12018,
          5028,
          6545,
          307,
          13,
          50824
        ]
      },
      {
        "avg_logprob": -0.4341080592228816,
        "compression_ratio": 1.2937062937062938,
        "end": 7584.36,
        "id": 2347,
        "no_speech_prob": 0.00004539754445431754,
        "seek": 757244,
        "start": 7581.639999999999,
        "temperature": 0,
        "text": " You can find out, actually we should just go.",
        "tokens": [
          50824,
          509,
          393,
          915,
          484,
          11,
          767,
          321,
          820,
          445,
          352,
          13,
          50960
        ]
      },
      {
        "avg_logprob": -0.4341080592228816,
        "compression_ratio": 1.2937062937062938,
        "end": 7587.96,
        "id": 2348,
        "no_speech_prob": 0.00004539754445431754,
        "seek": 757244,
        "start": 7586.599999999999,
        "temperature": 0,
        "text": " Yeah, I'm sorry, I'm like.",
        "tokens": [
          51072,
          865,
          11,
          286,
          478,
          2597,
          11,
          286,
          478,
          411,
          13,
          51140
        ]
      },
      {
        "avg_logprob": -0.4341080592228816,
        "compression_ratio": 1.2937062937062938,
        "end": 7591.12,
        "id": 2349,
        "no_speech_prob": 0.00004539754445431754,
        "seek": 757244,
        "start": 7590.28,
        "temperature": 0,
        "text": " Ha ha!",
        "tokens": [
          51256,
          4064,
          324,
          0,
          51298
        ]
      },
      {
        "avg_logprob": -0.4341080592228816,
        "compression_ratio": 1.2937062937062938,
        "end": 7594.919999999999,
        "id": 2350,
        "no_speech_prob": 0.00004539754445431754,
        "seek": 757244,
        "start": 7594.08,
        "temperature": 0,
        "text": " This one.",
        "tokens": [
          51446,
          639,
          472,
          13,
          51488
        ]
      },
      {
        "avg_logprob": -0.4341080592228816,
        "compression_ratio": 1.2937062937062938,
        "end": 7600.66,
        "id": 2351,
        "no_speech_prob": 0.00004539754445431754,
        "seek": 757244,
        "start": 7599.419999999999,
        "temperature": 0,
        "text": " Hold on.",
        "tokens": [
          51713,
          6962,
          322,
          13,
          51775
        ]
      },
      {
        "avg_logprob": -0.22055599357508407,
        "compression_ratio": 1.7628205128205128,
        "end": 7602.58,
        "id": 2352,
        "no_speech_prob": 0.00017400509386789054,
        "seek": 760066,
        "start": 7600.66,
        "temperature": 0,
        "text": " We should really, I should really talk at some point",
        "tokens": [
          50364,
          492,
          820,
          534,
          11,
          286,
          820,
          534,
          751,
          412,
          512,
          935,
          50460
        ]
      },
      {
        "avg_logprob": -0.22055599357508407,
        "compression_ratio": 1.7628205128205128,
        "end": 7604.98,
        "id": 2353,
        "no_speech_prob": 0.00017400509386789054,
        "seek": 760066,
        "start": 7602.58,
        "temperature": 0,
        "text": " about what some of these other optimizer functions are.",
        "tokens": [
          50460,
          466,
          437,
          512,
          295,
          613,
          661,
          5028,
          6545,
          6828,
          366,
          13,
          50580
        ]
      },
      {
        "avg_logprob": -0.22055599357508407,
        "compression_ratio": 1.7628205128205128,
        "end": 7607.099999999999,
        "id": 2354,
        "no_speech_prob": 0.00017400509386789054,
        "seek": 760066,
        "start": 7604.98,
        "temperature": 0,
        "text": " For now, what I would suggest that you do",
        "tokens": [
          50580,
          1171,
          586,
          11,
          437,
          286,
          576,
          3402,
          300,
          291,
          360,
          50686
        ]
      },
      {
        "avg_logprob": -0.22055599357508407,
        "compression_ratio": 1.7628205128205128,
        "end": 7610.7,
        "id": 2355,
        "no_speech_prob": 0.00017400509386789054,
        "seek": 760066,
        "start": 7607.099999999999,
        "temperature": 0,
        "text": " is if I, again, if I go back to the API reference",
        "tokens": [
          50686,
          307,
          498,
          286,
          11,
          797,
          11,
          498,
          286,
          352,
          646,
          281,
          264,
          9362,
          6408,
          50866
        ]
      },
      {
        "avg_logprob": -0.22055599357508407,
        "compression_ratio": 1.7628205128205128,
        "end": 7613.5,
        "id": 2356,
        "no_speech_prob": 0.00017400509386789054,
        "seek": 760066,
        "start": 7610.7,
        "temperature": 0,
        "text": " and I go all the way down and I find the,",
        "tokens": [
          50866,
          293,
          286,
          352,
          439,
          264,
          636,
          760,
          293,
          286,
          915,
          264,
          11,
          51006
        ]
      },
      {
        "avg_logprob": -0.22055599357508407,
        "compression_ratio": 1.7628205128205128,
        "end": 7615.0599999999995,
        "id": 2357,
        "no_speech_prob": 0.00017400509386789054,
        "seek": 760066,
        "start": 7613.5,
        "temperature": 0,
        "text": " oh, let me just look this way.",
        "tokens": [
          51006,
          1954,
          11,
          718,
          385,
          445,
          574,
          341,
          636,
          13,
          51084
        ]
      },
      {
        "avg_logprob": -0.22055599357508407,
        "compression_ratio": 1.7628205128205128,
        "end": 7618.22,
        "id": 2358,
        "no_speech_prob": 0.00017400509386789054,
        "seek": 760066,
        "start": 7615.0599999999995,
        "temperature": 0,
        "text": " The, if I go here and I go train.atom, we can see here.",
        "tokens": [
          51084,
          440,
          11,
          498,
          286,
          352,
          510,
          293,
          286,
          352,
          3847,
          13,
          267,
          298,
          11,
          321,
          393,
          536,
          510,
          13,
          51242
        ]
      },
      {
        "avg_logprob": -0.22055599357508407,
        "compression_ratio": 1.7628205128205128,
        "end": 7619.34,
        "id": 2359,
        "no_speech_prob": 0.00017400509386789054,
        "seek": 760066,
        "start": 7618.22,
        "temperature": 0,
        "text": " This is what you're going to want to click on.",
        "tokens": [
          51242,
          639,
          307,
          437,
          291,
          434,
          516,
          281,
          528,
          281,
          2052,
          322,
          13,
          51298
        ]
      },
      {
        "avg_logprob": -0.22055599357508407,
        "compression_ratio": 1.7628205128205128,
        "end": 7622.98,
        "id": 2360,
        "no_speech_prob": 0.00017400509386789054,
        "seek": 760066,
        "start": 7619.34,
        "temperature": 0,
        "text": " This is the paper that describes the atom algorithm.",
        "tokens": [
          51298,
          639,
          307,
          264,
          3035,
          300,
          15626,
          264,
          12018,
          9284,
          13,
          51480
        ]
      },
      {
        "avg_logprob": -0.22055599357508407,
        "compression_ratio": 1.7628205128205128,
        "end": 7627.0199999999995,
        "id": 2361,
        "no_speech_prob": 0.00017400509386789054,
        "seek": 760066,
        "start": 7622.98,
        "temperature": 0,
        "text": " It's different, but it's optimizing the loss function",
        "tokens": [
          51480,
          467,
          311,
          819,
          11,
          457,
          309,
          311,
          40425,
          264,
          4470,
          2445,
          51682
        ]
      },
      {
        "avg_logprob": -0.22055599357508407,
        "compression_ratio": 1.7628205128205128,
        "end": 7627.86,
        "id": 2362,
        "no_speech_prob": 0.00017400509386789054,
        "seek": 760066,
        "start": 7627.0199999999995,
        "temperature": 0,
        "text": " in a slightly different way",
        "tokens": [
          51682,
          294,
          257,
          4748,
          819,
          636,
          51724
        ]
      },
      {
        "avg_logprob": -0.22055599357508407,
        "compression_ratio": 1.7628205128205128,
        "end": 7630.54,
        "id": 2363,
        "no_speech_prob": 0.00017400509386789054,
        "seek": 760066,
        "start": 7627.86,
        "temperature": 0,
        "text": " than stochastic gradient descent does.",
        "tokens": [
          51724,
          813,
          342,
          8997,
          2750,
          16235,
          23475,
          775,
          13,
          51858
        ]
      },
      {
        "avg_logprob": -0.31169969770643446,
        "compression_ratio": 1.5885416666666667,
        "end": 7633.34,
        "id": 2364,
        "no_speech_prob": 0.00008888075535651296,
        "seek": 763054,
        "start": 7631.42,
        "temperature": 0,
        "text": " We could also try starting to,",
        "tokens": [
          50408,
          492,
          727,
          611,
          853,
          2891,
          281,
          11,
          50504
        ]
      },
      {
        "avg_logprob": -0.31169969770643446,
        "compression_ratio": 1.5885416666666667,
        "end": 7636.5,
        "id": 2365,
        "no_speech_prob": 0.00008888075535651296,
        "seek": 763054,
        "start": 7633.34,
        "temperature": 0,
        "text": " we could just never stop and I could start,",
        "tokens": [
          50504,
          321,
          727,
          445,
          1128,
          1590,
          293,
          286,
          727,
          722,
          11,
          50662
        ]
      },
      {
        "avg_logprob": -0.31169969770643446,
        "compression_ratio": 1.5885416666666667,
        "end": 7641.5,
        "id": 2366,
        "no_speech_prob": 0.00008888075535651296,
        "seek": 763054,
        "start": 7636.5,
        "temperature": 0,
        "text": " I think, using the ReLU activation function instead.",
        "tokens": [
          50662,
          286,
          519,
          11,
          1228,
          264,
          1300,
          43,
          52,
          24433,
          2445,
          2602,
          13,
          50912
        ]
      },
      {
        "avg_logprob": -0.31169969770643446,
        "compression_ratio": 1.5885416666666667,
        "end": 7644.58,
        "id": 2367,
        "no_speech_prob": 0.00008888075535651296,
        "seek": 763054,
        "start": 7642.68,
        "temperature": 0,
        "text": " Whoops, is that not what it's called?",
        "tokens": [
          50971,
          45263,
          11,
          307,
          300,
          406,
          437,
          309,
          311,
          1219,
          30,
          51066
        ]
      },
      {
        "avg_logprob": -0.31169969770643446,
        "compression_ratio": 1.5885416666666667,
        "end": 7651.68,
        "id": 2368,
        "no_speech_prob": 0.00008888075535651296,
        "seek": 763054,
        "start": 7650.14,
        "temperature": 0,
        "text": " Where are the activation functions?",
        "tokens": [
          51344,
          2305,
          366,
          264,
          24433,
          6828,
          30,
          51421
        ]
      },
      {
        "avg_logprob": -0.31169969770643446,
        "compression_ratio": 1.5885416666666667,
        "end": 7655.98,
        "id": 2369,
        "no_speech_prob": 0.00008888075535651296,
        "seek": 763054,
        "start": 7651.68,
        "temperature": 0,
        "text": " Oh, it's, there's no, it's just all lowercase.",
        "tokens": [
          51421,
          876,
          11,
          309,
          311,
          11,
          456,
          311,
          572,
          11,
          309,
          311,
          445,
          439,
          3126,
          9765,
          13,
          51636
        ]
      },
      {
        "avg_logprob": -0.31169969770643446,
        "compression_ratio": 1.5885416666666667,
        "end": 7659.34,
        "id": 2370,
        "no_speech_prob": 0.00008888075535651296,
        "seek": 763054,
        "start": 7655.98,
        "temperature": 0,
        "text": " So there's just so many things you can play around with,",
        "tokens": [
          51636,
          407,
          456,
          311,
          445,
          370,
          867,
          721,
          291,
          393,
          862,
          926,
          365,
          11,
          51804
        ]
      },
      {
        "avg_logprob": -0.323269342121325,
        "compression_ratio": 1.4012738853503184,
        "end": 7660.4800000000005,
        "id": 2371,
        "no_speech_prob": 0.00020988276810385287,
        "seek": 765934,
        "start": 7659.5,
        "temperature": 0,
        "text": " these things.",
        "tokens": [
          50372,
          613,
          721,
          13,
          50421
        ]
      },
      {
        "avg_logprob": -0.323269342121325,
        "compression_ratio": 1.4012738853503184,
        "end": 7666.58,
        "id": 2372,
        "no_speech_prob": 0.00020988276810385287,
        "seek": 765934,
        "start": 7665.34,
        "temperature": 0,
        "text": " That was a failure.",
        "tokens": [
          50664,
          663,
          390,
          257,
          7763,
          13,
          50726
        ]
      },
      {
        "avg_logprob": -0.323269342121325,
        "compression_ratio": 1.4012738853503184,
        "end": 7670.900000000001,
        "id": 2373,
        "no_speech_prob": 0.00020988276810385287,
        "seek": 765934,
        "start": 7669.54,
        "temperature": 0,
        "text": " I think because I have the,",
        "tokens": [
          50874,
          286,
          519,
          570,
          286,
          362,
          264,
          11,
          50942
        ]
      },
      {
        "avg_logprob": -0.323269342121325,
        "compression_ratio": 1.4012738853503184,
        "end": 7677.26,
        "id": 2374,
        "no_speech_prob": 0.00020988276810385287,
        "seek": 765934,
        "start": 7675.58,
        "temperature": 0,
        "text": " all right, let's, I'm not going to add,",
        "tokens": [
          51176,
          439,
          558,
          11,
          718,
          311,
          11,
          286,
          478,
          406,
          516,
          281,
          909,
          11,
          51260
        ]
      },
      {
        "avg_logprob": -0.323269342121325,
        "compression_ratio": 1.4012738853503184,
        "end": 7679.22,
        "id": 2375,
        "no_speech_prob": 0.00020988276810385287,
        "seek": 765934,
        "start": 7677.26,
        "temperature": 0,
        "text": " I'm going to, hold on, go back.",
        "tokens": [
          51260,
          286,
          478,
          516,
          281,
          11,
          1797,
          322,
          11,
          352,
          646,
          13,
          51358
        ]
      },
      {
        "avg_logprob": -0.323269342121325,
        "compression_ratio": 1.4012738853503184,
        "end": 7683.18,
        "id": 2376,
        "no_speech_prob": 0.00020988276810385287,
        "seek": 765934,
        "start": 7680.66,
        "temperature": 0,
        "text": " Back to where I was explaining the atom optimizer.",
        "tokens": [
          51430,
          5833,
          281,
          689,
          286,
          390,
          13468,
          264,
          12018,
          5028,
          6545,
          13,
          51556
        ]
      },
      {
        "avg_logprob": -0.323269342121325,
        "compression_ratio": 1.4012738853503184,
        "end": 7687.58,
        "id": 2377,
        "no_speech_prob": 0.00020988276810385287,
        "seek": 765934,
        "start": 7684.74,
        "temperature": 0,
        "text": " Oh, I made this such a mess to edit",
        "tokens": [
          51634,
          876,
          11,
          286,
          1027,
          341,
          1270,
          257,
          2082,
          281,
          8129,
          51776
        ]
      },
      {
        "avg_logprob": -0.25801991841879235,
        "compression_ratio": 1.5612244897959184,
        "end": 7689.0599999999995,
        "id": 2378,
        "no_speech_prob": 0.000014064025890547782,
        "seek": 768758,
        "start": 7687.62,
        "temperature": 0,
        "text": " and I really have to go.",
        "tokens": [
          50366,
          293,
          286,
          534,
          362,
          281,
          352,
          13,
          50438
        ]
      },
      {
        "avg_logprob": -0.25801991841879235,
        "compression_ratio": 1.5612244897959184,
        "end": 7704.22,
        "id": 2379,
        "no_speech_prob": 0.000014064025890547782,
        "seek": 768758,
        "start": 7701.62,
        "temperature": 0,
        "text": " I really should explain what these optimizers are,",
        "tokens": [
          51066,
          286,
          534,
          820,
          2903,
          437,
          613,
          5028,
          22525,
          366,
          11,
          51196
        ]
      },
      {
        "avg_logprob": -0.25801991841879235,
        "compression_ratio": 1.5612244897959184,
        "end": 7706.3,
        "id": 2380,
        "no_speech_prob": 0.000014064025890547782,
        "seek": 768758,
        "start": 7704.22,
        "temperature": 0,
        "text": " but if I go back and look under here,",
        "tokens": [
          51196,
          457,
          498,
          286,
          352,
          646,
          293,
          574,
          833,
          510,
          11,
          51300
        ]
      },
      {
        "avg_logprob": -0.25801991841879235,
        "compression_ratio": 1.5612244897959184,
        "end": 7707.46,
        "id": 2381,
        "no_speech_prob": 0.000014064025890547782,
        "seek": 768758,
        "start": 7706.3,
        "temperature": 0,
        "text": " we can see what some of these are.",
        "tokens": [
          51300,
          321,
          393,
          536,
          437,
          512,
          295,
          613,
          366,
          13,
          51358
        ]
      },
      {
        "avg_logprob": -0.25801991841879235,
        "compression_ratio": 1.5612244897959184,
        "end": 7710.9,
        "id": 2382,
        "no_speech_prob": 0.000014064025890547782,
        "seek": 768758,
        "start": 7707.46,
        "temperature": 0,
        "text": " Atom, the ADA coming from the word adaptive,",
        "tokens": [
          51358,
          1711,
          298,
          11,
          264,
          39354,
          1348,
          490,
          264,
          1349,
          27912,
          11,
          51530
        ]
      },
      {
        "avg_logprob": -0.25801991841879235,
        "compression_ratio": 1.5612244897959184,
        "end": 7713.1,
        "id": 2383,
        "no_speech_prob": 0.000014064025890547782,
        "seek": 768758,
        "start": 7710.9,
        "temperature": 0,
        "text": " and you could always click here and look at this paper,",
        "tokens": [
          51530,
          293,
          291,
          727,
          1009,
          2052,
          510,
          293,
          574,
          412,
          341,
          3035,
          11,
          51640
        ]
      },
      {
        "avg_logprob": -0.25801991841879235,
        "compression_ratio": 1.5612244897959184,
        "end": 7717.04,
        "id": 2384,
        "no_speech_prob": 0.000014064025890547782,
        "seek": 768758,
        "start": 7713.1,
        "temperature": 0,
        "text": " which describes this particular method for optimization,",
        "tokens": [
          51640,
          597,
          15626,
          341,
          1729,
          3170,
          337,
          19618,
          11,
          51837
        ]
      },
      {
        "avg_logprob": -0.2543482358763818,
        "compression_ratio": 1.685430463576159,
        "end": 7718.32,
        "id": 2385,
        "no_speech_prob": 0.00015598002937622368,
        "seek": 771704,
        "start": 7717.48,
        "temperature": 0,
        "text": " which is a little bit different",
        "tokens": [
          50386,
          597,
          307,
          257,
          707,
          857,
          819,
          50428
        ]
      },
      {
        "avg_logprob": -0.2543482358763818,
        "compression_ratio": 1.685430463576159,
        "end": 7719.84,
        "id": 2386,
        "no_speech_prob": 0.00015598002937622368,
        "seek": 771704,
        "start": 7718.32,
        "temperature": 0,
        "text": " than stochastic gradient descent,",
        "tokens": [
          50428,
          813,
          342,
          8997,
          2750,
          16235,
          23475,
          11,
          50504
        ]
      },
      {
        "avg_logprob": -0.2543482358763818,
        "compression_ratio": 1.685430463576159,
        "end": 7722.38,
        "id": 2387,
        "no_speech_prob": 0.00015598002937622368,
        "seek": 771704,
        "start": 7719.84,
        "temperature": 0,
        "text": " and apparently things work a lot faster",
        "tokens": [
          50504,
          293,
          7970,
          721,
          589,
          257,
          688,
          4663,
          50631
        ]
      },
      {
        "avg_logprob": -0.2543482358763818,
        "compression_ratio": 1.685430463576159,
        "end": 7723.4,
        "id": 2388,
        "no_speech_prob": 0.00015598002937622368,
        "seek": 771704,
        "start": 7722.38,
        "temperature": 0,
        "text": " with this XOR problem.",
        "tokens": [
          50631,
          365,
          341,
          1783,
          2483,
          1154,
          13,
          50682
        ]
      },
      {
        "avg_logprob": -0.2543482358763818,
        "compression_ratio": 1.685430463576159,
        "end": 7726.16,
        "id": 2389,
        "no_speech_prob": 0.00015598002937622368,
        "seek": 771704,
        "start": 7723.4,
        "temperature": 0,
        "text": " So as I go forward into more of these videos,",
        "tokens": [
          50682,
          407,
          382,
          286,
          352,
          2128,
          666,
          544,
          295,
          613,
          2145,
          11,
          50820
        ]
      },
      {
        "avg_logprob": -0.2543482358763818,
        "compression_ratio": 1.685430463576159,
        "end": 7727.8,
        "id": 2390,
        "no_speech_prob": 0.00015598002937622368,
        "seek": 771704,
        "start": 7726.16,
        "temperature": 0,
        "text": " hopefully we can dig into what some",
        "tokens": [
          50820,
          4696,
          321,
          393,
          2528,
          666,
          437,
          512,
          50902
        ]
      },
      {
        "avg_logprob": -0.2543482358763818,
        "compression_ratio": 1.685430463576159,
        "end": 7729.6,
        "id": 2391,
        "no_speech_prob": 0.00015598002937622368,
        "seek": 771704,
        "start": 7727.8,
        "temperature": 0,
        "text": " of these different optimizers do",
        "tokens": [
          50902,
          295,
          613,
          819,
          5028,
          22525,
          360,
          50992
        ]
      },
      {
        "avg_logprob": -0.2543482358763818,
        "compression_ratio": 1.685430463576159,
        "end": 7731.4,
        "id": 2392,
        "no_speech_prob": 0.00015598002937622368,
        "seek": 771704,
        "start": 7729.6,
        "temperature": 0,
        "text": " and kind of understand why I might pick one",
        "tokens": [
          50992,
          293,
          733,
          295,
          1223,
          983,
          286,
          1062,
          1888,
          472,
          51082
        ]
      },
      {
        "avg_logprob": -0.2543482358763818,
        "compression_ratio": 1.685430463576159,
        "end": 7733.48,
        "id": 2393,
        "no_speech_prob": 0.00015598002937622368,
        "seek": 771704,
        "start": 7731.4,
        "temperature": 0,
        "text": " over the other in certain situations.",
        "tokens": [
          51082,
          670,
          264,
          661,
          294,
          1629,
          6851,
          13,
          51186
        ]
      },
      {
        "avg_logprob": -0.2543482358763818,
        "compression_ratio": 1.685430463576159,
        "end": 7736.72,
        "id": 2394,
        "no_speech_prob": 0.00015598002937622368,
        "seek": 771704,
        "start": 7733.48,
        "temperature": 0,
        "text": " All right, but I'm just going to just leave this be.",
        "tokens": [
          51186,
          1057,
          558,
          11,
          457,
          286,
          478,
          445,
          516,
          281,
          445,
          1856,
          341,
          312,
          13,
          51348
        ]
      },
      {
        "avg_logprob": -0.2543482358763818,
        "compression_ratio": 1.685430463576159,
        "end": 7738.36,
        "id": 2395,
        "no_speech_prob": 0.00015598002937622368,
        "seek": 771704,
        "start": 7736.72,
        "temperature": 0,
        "text": " I'm going to hit refresh.",
        "tokens": [
          51348,
          286,
          478,
          516,
          281,
          2045,
          15134,
          13,
          51430
        ]
      },
      {
        "avg_logprob": -0.2543482358763818,
        "compression_ratio": 1.685430463576159,
        "end": 7741,
        "id": 2396,
        "no_speech_prob": 0.00015598002937622368,
        "seek": 771704,
        "start": 7738.36,
        "temperature": 0,
        "text": " I'm going to watch it learn and train.",
        "tokens": [
          51430,
          286,
          478,
          516,
          281,
          1159,
          309,
          1466,
          293,
          3847,
          13,
          51562
        ]
      },
      {
        "avg_logprob": -0.2543482358763818,
        "compression_ratio": 1.685430463576159,
        "end": 7743.68,
        "id": 2397,
        "no_speech_prob": 0.00015598002937622368,
        "seek": 771704,
        "start": 7741,
        "temperature": 0,
        "text": " Train, train, train, XOR.",
        "tokens": [
          51562,
          28029,
          11,
          3847,
          11,
          3847,
          11,
          1783,
          2483,
          13,
          51696
        ]
      },
      {
        "avg_logprob": -0.2543482358763818,
        "compression_ratio": 1.685430463576159,
        "end": 7745.28,
        "id": 2398,
        "no_speech_prob": 0.00015598002937622368,
        "seek": 771704,
        "start": 7743.68,
        "temperature": 0,
        "text": " I don't know, some things you could do,",
        "tokens": [
          51696,
          286,
          500,
          380,
          458,
          11,
          512,
          721,
          291,
          727,
          360,
          11,
          51776
        ]
      },
      {
        "avg_logprob": -0.2635685872223418,
        "compression_ratio": 1.6590038314176245,
        "end": 7748.679999999999,
        "id": 2399,
        "no_speech_prob": 0.005910987034440041,
        "seek": 774528,
        "start": 7745.28,
        "temperature": 0,
        "text": " investigate tf.frame, give me a little slider,",
        "tokens": [
          50364,
          15013,
          256,
          69,
          13,
          17265,
          11,
          976,
          385,
          257,
          707,
          26046,
          11,
          50534
        ]
      },
      {
        "avg_logprob": -0.2635685872223418,
        "compression_ratio": 1.6590038314176245,
        "end": 7750.719999999999,
        "id": 2400,
        "no_speech_prob": 0.005910987034440041,
        "seek": 774528,
        "start": 7748.679999999999,
        "temperature": 0,
        "text": " try different architectures, different optimizers,",
        "tokens": [
          50534,
          853,
          819,
          6331,
          1303,
          11,
          819,
          5028,
          22525,
          11,
          50636
        ]
      },
      {
        "avg_logprob": -0.2635685872223418,
        "compression_ratio": 1.6590038314176245,
        "end": 7752.599999999999,
        "id": 2401,
        "no_speech_prob": 0.005910987034440041,
        "seek": 774528,
        "start": 7750.719999999999,
        "temperature": 0,
        "text": " try some different activation functions.",
        "tokens": [
          50636,
          853,
          512,
          819,
          24433,
          6828,
          13,
          50730
        ]
      },
      {
        "avg_logprob": -0.2635685872223418,
        "compression_ratio": 1.6590038314176245,
        "end": 7753.88,
        "id": 2402,
        "no_speech_prob": 0.005910987034440041,
        "seek": 774528,
        "start": 7752.599999999999,
        "temperature": 0,
        "text": " I don't know.",
        "tokens": [
          50730,
          286,
          500,
          380,
          458,
          13,
          50794
        ]
      },
      {
        "avg_logprob": -0.2635685872223418,
        "compression_ratio": 1.6590038314176245,
        "end": 7758.219999999999,
        "id": 2403,
        "no_speech_prob": 0.005910987034440041,
        "seek": 774528,
        "start": 7753.88,
        "temperature": 0,
        "text": " If you actually made it all the way to the end of this video,",
        "tokens": [
          50794,
          759,
          291,
          767,
          1027,
          309,
          439,
          264,
          636,
          281,
          264,
          917,
          295,
          341,
          960,
          11,
          51011
        ]
      },
      {
        "avg_logprob": -0.2635685872223418,
        "compression_ratio": 1.6590038314176245,
        "end": 7760.8,
        "id": 2404,
        "no_speech_prob": 0.005910987034440041,
        "seek": 774528,
        "start": 7759.139999999999,
        "temperature": 0,
        "text": " I don't know, hashtag something.",
        "tokens": [
          51057,
          286,
          500,
          380,
          458,
          11,
          20379,
          746,
          13,
          51140
        ]
      },
      {
        "avg_logprob": -0.2635685872223418,
        "compression_ratio": 1.6590038314176245,
        "end": 7765.04,
        "id": 2405,
        "no_speech_prob": 0.005910987034440041,
        "seek": 774528,
        "start": 7763.5199999999995,
        "temperature": 0,
        "text": " Eric is telling me to watch one of those videos",
        "tokens": [
          51276,
          9336,
          307,
          3585,
          385,
          281,
          1159,
          472,
          295,
          729,
          2145,
          51352
        ]
      },
      {
        "avg_logprob": -0.2635685872223418,
        "compression_ratio": 1.6590038314176245,
        "end": 7766.84,
        "id": 2406,
        "no_speech_prob": 0.005910987034440041,
        "seek": 774528,
        "start": 7765.04,
        "temperature": 0,
        "text": " reviewing the JavaScript event loop,",
        "tokens": [
          51352,
          19576,
          264,
          15778,
          2280,
          6367,
          11,
          51442
        ]
      },
      {
        "avg_logprob": -0.2635685872223418,
        "compression_ratio": 1.6590038314176245,
        "end": 7767.88,
        "id": 2407,
        "no_speech_prob": 0.005910987034440041,
        "seek": 774528,
        "start": 7766.84,
        "temperature": 0,
        "text": " which I definitely need to do.",
        "tokens": [
          51442,
          597,
          286,
          2138,
          643,
          281,
          360,
          13,
          51494
        ]
      },
      {
        "avg_logprob": -0.2635685872223418,
        "compression_ratio": 1.6590038314176245,
        "end": 7771.099999999999,
        "id": 2408,
        "no_speech_prob": 0.005910987034440041,
        "seek": 774528,
        "start": 7767.88,
        "temperature": 0,
        "text": " So I'm going to be back with more someday.",
        "tokens": [
          51494,
          407,
          286,
          478,
          516,
          281,
          312,
          646,
          365,
          544,
          19412,
          13,
          51655
        ]
      },
      {
        "avg_logprob": -0.2635685872223418,
        "compression_ratio": 1.6590038314176245,
        "end": 7774.92,
        "id": 2409,
        "no_speech_prob": 0.005910987034440041,
        "seek": 774528,
        "start": 7772.639999999999,
        "temperature": 0,
        "text": " Goodbye, goodbye, goodbye.",
        "tokens": [
          51732,
          15528,
          11,
          12084,
          11,
          12084,
          13,
          51846
        ]
      },
      {
        "avg_logprob": -0.32444943879780014,
        "compression_ratio": 1.4065040650406504,
        "end": 7776.12,
        "id": 2410,
        "no_speech_prob": 0.000012805436199414544,
        "seek": 777528,
        "start": 7775.28,
        "temperature": 0,
        "text": " Thank you.",
        "tokens": [
          50364,
          1044,
          291,
          13,
          50406
        ]
      },
      {
        "avg_logprob": -0.32444943879780014,
        "compression_ratio": 1.4065040650406504,
        "end": 7784.759999999999,
        "id": 2411,
        "no_speech_prob": 0.000012805436199414544,
        "seek": 777528,
        "start": 7783.639999999999,
        "temperature": 0,
        "text": " Momentum.",
        "tokens": [
          50782,
          19093,
          449,
          13,
          50838
        ]
      },
      {
        "avg_logprob": -0.32444943879780014,
        "compression_ratio": 1.4065040650406504,
        "end": 7794.8,
        "id": 2412,
        "no_speech_prob": 0.000012805436199414544,
        "seek": 777528,
        "start": 7791.78,
        "temperature": 0,
        "text": " Is add and not for adaptive, did I just make that up?",
        "tokens": [
          51189,
          1119,
          909,
          293,
          406,
          337,
          27912,
          11,
          630,
          286,
          445,
          652,
          300,
          493,
          30,
          51340
        ]
      },
      {
        "avg_logprob": -0.32444943879780014,
        "compression_ratio": 1.4065040650406504,
        "end": 7799.599999999999,
        "id": 2413,
        "no_speech_prob": 0.000012805436199414544,
        "seek": 777528,
        "start": 7797.82,
        "temperature": 0,
        "text": " Adaptive estimates.",
        "tokens": [
          51491,
          49643,
          488,
          20561,
          13,
          51580
        ]
      },
      {
        "avg_logprob": -0.32444943879780014,
        "compression_ratio": 1.4065040650406504,
        "end": 7801.58,
        "id": 2414,
        "no_speech_prob": 0.000012805436199414544,
        "seek": 777528,
        "start": 7799.599999999999,
        "temperature": 0,
        "text": " So maybe the M is for estimates.",
        "tokens": [
          51580,
          407,
          1310,
          264,
          376,
          307,
          337,
          20561,
          13,
          51679
        ]
      },
      {
        "avg_logprob": -0.32444943879780014,
        "compression_ratio": 1.4065040650406504,
        "end": 7804.599999999999,
        "id": 2415,
        "no_speech_prob": 0.000012805436199414544,
        "seek": 777528,
        "start": 7801.58,
        "temperature": 0,
        "text": " Moments, low order moments, M is for moments.",
        "tokens": [
          51679,
          5576,
          791,
          11,
          2295,
          1668,
          6065,
          11,
          376,
          307,
          337,
          6065,
          13,
          51830
        ]
      },
      {
        "avg_logprob": -0.4414825439453125,
        "compression_ratio": 1.467005076142132,
        "end": 7806.12,
        "id": 2416,
        "no_speech_prob": 0.000017778431356418878,
        "seek": 780528,
        "start": 7805.28,
        "temperature": 0.2,
        "text": " I don't know.",
        "tokens": [
          50364,
          286,
          500,
          380,
          458,
          13,
          50406
        ]
      },
      {
        "avg_logprob": -0.4414825439453125,
        "compression_ratio": 1.467005076142132,
        "end": 7814.599999999999,
        "id": 2417,
        "no_speech_prob": 0.000017778431356418878,
        "seek": 780528,
        "start": 7812.12,
        "temperature": 0.2,
        "text": " Yeah, all right everybody.",
        "tokens": [
          50706,
          865,
          11,
          439,
          558,
          2201,
          13,
          50830
        ]
      },
      {
        "avg_logprob": -0.4414825439453125,
        "compression_ratio": 1.467005076142132,
        "end": 7816.8,
        "id": 2418,
        "no_speech_prob": 0.000017778431356418878,
        "seek": 780528,
        "start": 7814.599999999999,
        "temperature": 0.2,
        "text": " Well, you know, today was one of those days.",
        "tokens": [
          50830,
          1042,
          11,
          291,
          458,
          11,
          965,
          390,
          472,
          295,
          729,
          1708,
          13,
          50940
        ]
      },
      {
        "avg_logprob": -0.4414825439453125,
        "compression_ratio": 1.467005076142132,
        "end": 7820.12,
        "id": 2419,
        "no_speech_prob": 0.000017778431356418878,
        "seek": 780528,
        "start": 7817.599999999999,
        "temperature": 0.2,
        "text": " I should really be doing my old style coding challenges",
        "tokens": [
          50980,
          286,
          820,
          534,
          312,
          884,
          452,
          1331,
          3758,
          17720,
          4759,
          51106
        ]
      },
      {
        "avg_logprob": -0.4414825439453125,
        "compression_ratio": 1.467005076142132,
        "end": 7822.88,
        "id": 2420,
        "no_speech_prob": 0.000017778431356418878,
        "seek": 780528,
        "start": 7820.12,
        "temperature": 0.2,
        "text": " again, read out of the random numbers book, okay.",
        "tokens": [
          51106,
          797,
          11,
          1401,
          484,
          295,
          264,
          4974,
          3547,
          1446,
          11,
          1392,
          13,
          51244
        ]
      },
      {
        "avg_logprob": -0.4414825439453125,
        "compression_ratio": 1.467005076142132,
        "end": 7826.219999999999,
        "id": 2421,
        "no_speech_prob": 0.000017778431356418878,
        "seek": 780528,
        "start": 7823.719999999999,
        "temperature": 0.2,
        "text": " Okay, I really, I'm running late.",
        "tokens": [
          51286,
          1033,
          11,
          286,
          534,
          11,
          286,
          478,
          2614,
          3469,
          13,
          51411
        ]
      },
      {
        "avg_logprob": -0.4414825439453125,
        "compression_ratio": 1.467005076142132,
        "end": 7827.639999999999,
        "id": 2422,
        "no_speech_prob": 0.000017778431356418878,
        "seek": 780528,
        "start": 7826.219999999999,
        "temperature": 0.2,
        "text": " I gotta go.",
        "tokens": [
          51411,
          286,
          3428,
          352,
          13,
          51482
        ]
      },
      {
        "avg_logprob": -0.4414825439453125,
        "compression_ratio": 1.467005076142132,
        "end": 7831.44,
        "id": 2423,
        "no_speech_prob": 0.000017778431356418878,
        "seek": 780528,
        "start": 7829.12,
        "temperature": 0.2,
        "text": " Everyone lie down, go to sleep.",
        "tokens": [
          51556,
          5198,
          4544,
          760,
          11,
          352,
          281,
          2817,
          13,
          51672
        ]
      },
      {
        "avg_logprob": -0.4414825439453125,
        "compression_ratio": 1.467005076142132,
        "end": 7834.139999999999,
        "id": 2424,
        "no_speech_prob": 0.000017778431356418878,
        "seek": 780528,
        "start": 7832.48,
        "temperature": 0.2,
        "text": " We're gonna, let's.",
        "tokens": [
          51724,
          492,
          434,
          799,
          11,
          718,
          311,
          13,
          51807
        ]
      },
      {
        "avg_logprob": -0.41395658765520366,
        "compression_ratio": 1.0222222222222221,
        "end": 7838.36,
        "id": 2425,
        "no_speech_prob": 0.000021782574549433775,
        "seek": 783528,
        "start": 7835.96,
        "temperature": 0,
        "text": " Let's artificially make this happen much slower.",
        "tokens": [
          50398,
          961,
          311,
          39905,
          2270,
          652,
          341,
          1051,
          709,
          14009,
          13,
          50518
        ]
      },
      {
        "avg_logprob": -0.41395658765520366,
        "compression_ratio": 1.0222222222222221,
        "end": 7847.639999999999,
        "id": 2426,
        "no_speech_prob": 0.000021782574549433775,
        "seek": 783528,
        "start": 7845.84,
        "temperature": 0,
        "text": " Let's train, let's go, okay, ready?",
        "tokens": [
          50892,
          961,
          311,
          3847,
          11,
          718,
          311,
          352,
          11,
          1392,
          11,
          1919,
          30,
          50982
        ]
      },
      {
        "avg_logprob": -0.41395658765520366,
        "compression_ratio": 1.0222222222222221,
        "end": 7858.639999999999,
        "id": 2427,
        "no_speech_prob": 0.000021782574549433775,
        "seek": 783528,
        "start": 7857.8,
        "temperature": 0,
        "text": " 32,985.",
        "tokens": [
          51490,
          8858,
          11,
          24,
          19287,
          13,
          51532
        ]
      },
      {
        "avg_logprob": -0.45028578001877356,
        "compression_ratio": 1.1272727272727272,
        "end": 7860.4800000000005,
        "id": 2428,
        "no_speech_prob": 0.009124735370278358,
        "seek": 785864,
        "start": 7859.64,
        "temperature": 0,
        "text": " 26,814.",
        "tokens": [
          50414,
          7551,
          11,
          23,
          7271,
          13,
          50456
        ]
      },
      {
        "avg_logprob": -0.45028578001877356,
        "compression_ratio": 1.1272727272727272,
        "end": 7868.360000000001,
        "id": 2429,
        "no_speech_prob": 0.009124735370278358,
        "seek": 785864,
        "start": 7867.52,
        "temperature": 0,
        "text": " 51,833.",
        "tokens": [
          50808,
          18485,
          11,
          23,
          10191,
          13,
          50850
        ]
      },
      {
        "avg_logprob": -0.45028578001877356,
        "compression_ratio": 1.1272727272727272,
        "end": 7871.240000000001,
        "id": 2430,
        "no_speech_prob": 0.009124735370278358,
        "seek": 785864,
        "start": 7870.400000000001,
        "temperature": 0,
        "text": " 57,363.",
        "tokens": [
          50952,
          21423,
          11,
          11309,
          18,
          13,
          50994
        ]
      },
      {
        "avg_logprob": -0.45028578001877356,
        "compression_ratio": 1.1272727272727272,
        "end": 7874.68,
        "id": 2431,
        "no_speech_prob": 0.009124735370278358,
        "seek": 785864,
        "start": 7873.84,
        "temperature": 0,
        "text": " 4,067.",
        "tokens": [
          51124,
          1017,
          11,
          12791,
          22,
          13,
          51166
        ]
      },
      {
        "avg_logprob": -0.45028578001877356,
        "compression_ratio": 1.1272727272727272,
        "end": 7877.08,
        "id": 2432,
        "no_speech_prob": 0.009124735370278358,
        "seek": 785864,
        "start": 7876.240000000001,
        "temperature": 0,
        "text": " 84,648.",
        "tokens": [
          51244,
          29018,
          11,
          21,
          13318,
          13,
          51286
        ]
      },
      {
        "avg_logprob": -0.45028578001877356,
        "compression_ratio": 1.1272727272727272,
        "end": 7880.320000000001,
        "id": 2433,
        "no_speech_prob": 0.009124735370278358,
        "seek": 785864,
        "start": 7879.4800000000005,
        "temperature": 0,
        "text": " 85,505.",
        "tokens": [
          51406,
          14695,
          11,
          2803,
          20,
          13,
          51448
        ]
      },
      {
        "avg_logprob": -0.45028578001877356,
        "compression_ratio": 1.1272727272727272,
        "end": 7883.320000000001,
        "id": 2434,
        "no_speech_prob": 0.009124735370278358,
        "seek": 785864,
        "start": 7882.4800000000005,
        "temperature": 0,
        "text": " 41,465.",
        "tokens": [
          51556,
          18173,
          11,
          16169,
          20,
          13,
          51598
        ]
      },
      {
        "avg_logprob": -0.45028578001877356,
        "compression_ratio": 1.1272727272727272,
        "end": 7886.160000000001,
        "id": 2435,
        "no_speech_prob": 0.009124735370278358,
        "seek": 785864,
        "start": 7885.320000000001,
        "temperature": 0,
        "text": " 71,769.",
        "tokens": [
          51698,
          30942,
          11,
          25026,
          24,
          13,
          51740
        ]
      },
      {
        "avg_logprob": -0.2517391600698795,
        "compression_ratio": 1.6355140186915889,
        "end": 7887.96,
        "id": 2436,
        "no_speech_prob": 0.00009027927444549277,
        "seek": 788616,
        "start": 7887.12,
        "temperature": 0,
        "text": " 99,550.",
        "tokens": [
          50412,
          11803,
          11,
          20,
          2803,
          13,
          50454
        ]
      },
      {
        "avg_logprob": -0.2517391600698795,
        "compression_ratio": 1.6355140186915889,
        "end": 7891.599999999999,
        "id": 2437,
        "no_speech_prob": 0.00009027927444549277,
        "seek": 788616,
        "start": 7890.76,
        "temperature": 0,
        "text": " 55,904.",
        "tokens": [
          50594,
          12330,
          11,
          7771,
          19,
          13,
          50636
        ]
      },
      {
        "avg_logprob": -0.2517391600698795,
        "compression_ratio": 1.6355140186915889,
        "end": 7898.5599999999995,
        "id": 2438,
        "no_speech_prob": 0.00009027927444549277,
        "seek": 788616,
        "start": 7896.76,
        "temperature": 0,
        "text": " Will there be a second livestream today?",
        "tokens": [
          50894,
          3099,
          456,
          312,
          257,
          1150,
          29782,
          965,
          30,
          50984
        ]
      },
      {
        "avg_logprob": -0.2517391600698795,
        "compression_ratio": 1.6355140186915889,
        "end": 7899.48,
        "id": 2439,
        "no_speech_prob": 0.00009027927444549277,
        "seek": 788616,
        "start": 7898.5599999999995,
        "temperature": 0,
        "text": " No, unfortunately.",
        "tokens": [
          50984,
          883,
          11,
          7015,
          13,
          51030
        ]
      },
      {
        "avg_logprob": -0.2517391600698795,
        "compression_ratio": 1.6355140186915889,
        "end": 7900.5199999999995,
        "id": 2440,
        "no_speech_prob": 0.00009027927444549277,
        "seek": 788616,
        "start": 7899.48,
        "temperature": 0,
        "text": " Will I livestream on the weekend?",
        "tokens": [
          51030,
          3099,
          286,
          29782,
          322,
          264,
          6711,
          30,
          51082
        ]
      },
      {
        "avg_logprob": -0.2517391600698795,
        "compression_ratio": 1.6355140186915889,
        "end": 7901.68,
        "id": 2441,
        "no_speech_prob": 0.00009027927444549277,
        "seek": 788616,
        "start": 7900.5199999999995,
        "temperature": 0,
        "text": " No, unfortunately.",
        "tokens": [
          51082,
          883,
          11,
          7015,
          13,
          51140
        ]
      },
      {
        "avg_logprob": -0.2517391600698795,
        "compression_ratio": 1.6355140186915889,
        "end": 7904.68,
        "id": 2442,
        "no_speech_prob": 0.00009027927444549277,
        "seek": 788616,
        "start": 7901.68,
        "temperature": 0,
        "text": " So apologies, I wish I could livestream more often",
        "tokens": [
          51140,
          407,
          34929,
          11,
          286,
          3172,
          286,
          727,
          29782,
          544,
          2049,
          51290
        ]
      },
      {
        "avg_logprob": -0.2517391600698795,
        "compression_ratio": 1.6355140186915889,
        "end": 7906.72,
        "id": 2443,
        "no_speech_prob": 0.00009027927444549277,
        "seek": 788616,
        "start": 7904.68,
        "temperature": 0,
        "text": " all the time, make more stuff, blah, blah, blah.",
        "tokens": [
          51290,
          439,
          264,
          565,
          11,
          652,
          544,
          1507,
          11,
          12288,
          11,
          12288,
          11,
          12288,
          13,
          51392
        ]
      },
      {
        "avg_logprob": -0.2517391600698795,
        "compression_ratio": 1.6355140186915889,
        "end": 7909.5599999999995,
        "id": 2444,
        "no_speech_prob": 0.00009027927444549277,
        "seek": 788616,
        "start": 7906.72,
        "temperature": 0,
        "text": " The next livestream will likely be next Wednesday",
        "tokens": [
          51392,
          440,
          958,
          29782,
          486,
          3700,
          312,
          958,
          10579,
          51534
        ]
      },
      {
        "avg_logprob": -0.2517391600698795,
        "compression_ratio": 1.6355140186915889,
        "end": 7911.36,
        "id": 2445,
        "no_speech_prob": 0.00009027927444549277,
        "seek": 788616,
        "start": 7909.5599999999995,
        "temperature": 0,
        "text": " and next Thursday.",
        "tokens": [
          51534,
          293,
          958,
          10383,
          13,
          51624
        ]
      },
      {
        "avg_logprob": -0.2517391600698795,
        "compression_ratio": 1.6355140186915889,
        "end": 7914.68,
        "id": 2446,
        "no_speech_prob": 0.00009027927444549277,
        "seek": 788616,
        "start": 7911.36,
        "temperature": 0,
        "text": " And I'm gonna be working on a lot more of this stuff",
        "tokens": [
          51624,
          400,
          286,
          478,
          799,
          312,
          1364,
          322,
          257,
          688,
          544,
          295,
          341,
          1507,
          51790
        ]
      },
      {
        "avg_logprob": -0.33465782801310223,
        "compression_ratio": 1.5841584158415842,
        "end": 7915.76,
        "id": 2447,
        "no_speech_prob": 0.00006204994861036539,
        "seek": 791468,
        "start": 7914.68,
        "temperature": 0,
        "text": " in between.",
        "tokens": [
          50364,
          294,
          1296,
          13,
          50418
        ]
      },
      {
        "avg_logprob": -0.33465782801310223,
        "compression_ratio": 1.5841584158415842,
        "end": 7918.56,
        "id": 2448,
        "no_speech_prob": 0.00006204994861036539,
        "seek": 791468,
        "start": 7917.08,
        "temperature": 0,
        "text": " Hopefully we will.",
        "tokens": [
          50484,
          10429,
          321,
          486,
          13,
          50558
        ]
      },
      {
        "avg_logprob": -0.33465782801310223,
        "compression_ratio": 1.5841584158415842,
        "end": 7922.88,
        "id": 2449,
        "no_speech_prob": 0.00006204994861036539,
        "seek": 791468,
        "start": 7920.84,
        "temperature": 0,
        "text": " The things that I really need to look at are,",
        "tokens": [
          50672,
          440,
          721,
          300,
          286,
          534,
          643,
          281,
          574,
          412,
          366,
          11,
          50774
        ]
      },
      {
        "avg_logprob": -0.33465782801310223,
        "compression_ratio": 1.5841584158415842,
        "end": 7925.08,
        "id": 2450,
        "no_speech_prob": 0.00006204994861036539,
        "seek": 791468,
        "start": 7922.88,
        "temperature": 0,
        "text": " I need to look at that event loop article",
        "tokens": [
          50774,
          286,
          643,
          281,
          574,
          412,
          300,
          2280,
          6367,
          7222,
          50884
        ]
      },
      {
        "avg_logprob": -0.33465782801310223,
        "compression_ratio": 1.5841584158415842,
        "end": 7929.02,
        "id": 2451,
        "no_speech_prob": 0.00006204994861036539,
        "seek": 791468,
        "start": 7925.08,
        "temperature": 0,
        "text": " that I, just to get a better sense of how to use this stuff",
        "tokens": [
          50884,
          300,
          286,
          11,
          445,
          281,
          483,
          257,
          1101,
          2020,
          295,
          577,
          281,
          764,
          341,
          1507,
          51081
        ]
      },
      {
        "avg_logprob": -0.33465782801310223,
        "compression_ratio": 1.5841584158415842,
        "end": 7932.8,
        "id": 2452,
        "no_speech_prob": 0.00006204994861036539,
        "seek": 791468,
        "start": 7929.02,
        "temperature": 0,
        "text": " together with the request animation frame better",
        "tokens": [
          51081,
          1214,
          365,
          264,
          5308,
          9603,
          3920,
          1101,
          51270
        ]
      },
      {
        "avg_logprob": -0.33465782801310223,
        "compression_ratio": 1.5841584158415842,
        "end": 7934.200000000001,
        "id": 2453,
        "no_speech_prob": 0.00006204994861036539,
        "seek": 791468,
        "start": 7932.8,
        "temperature": 0,
        "text": " and tf.frame.",
        "tokens": [
          51270,
          293,
          256,
          69,
          13,
          17265,
          13,
          51340
        ]
      },
      {
        "avg_logprob": -0.33465782801310223,
        "compression_ratio": 1.5841584158415842,
        "end": 7938.320000000001,
        "id": 2454,
        "no_speech_prob": 0.00006204994861036539,
        "seek": 791468,
        "start": 7935.8,
        "temperature": 0,
        "text": " All right, so any last,",
        "tokens": [
          51420,
          1057,
          558,
          11,
          370,
          604,
          1036,
          11,
          51546
        ]
      },
      {
        "avg_logprob": -0.33465782801310223,
        "compression_ratio": 1.5841584158415842,
        "end": 7943.280000000001,
        "id": 2455,
        "no_speech_prob": 0.00006204994861036539,
        "seek": 791468,
        "start": 7940.04,
        "temperature": 0,
        "text": " if my real time that I had to leave was three o'clock,",
        "tokens": [
          51632,
          498,
          452,
          957,
          565,
          300,
          286,
          632,
          281,
          1856,
          390,
          1045,
          277,
          6,
          9023,
          11,
          51794
        ]
      },
      {
        "avg_logprob": -0.41948311001646754,
        "compression_ratio": 1.3553719008264462,
        "end": 7948.72,
        "id": 2456,
        "no_speech_prob": 0.000006853977538412437,
        "seek": 794468,
        "start": 7945.68,
        "temperature": 0,
        "text": " I got two minutes to answer questions.",
        "tokens": [
          50414,
          286,
          658,
          732,
          2077,
          281,
          1867,
          1651,
          13,
          50566
        ]
      },
      {
        "avg_logprob": -0.41948311001646754,
        "compression_ratio": 1.3553719008264462,
        "end": 7954.84,
        "id": 2457,
        "no_speech_prob": 0.000006853977538412437,
        "seek": 794468,
        "start": 7953.8,
        "temperature": 0,
        "text": " Let's try like.",
        "tokens": [
          50820,
          961,
          311,
          853,
          411,
          13,
          50872
        ]
      },
      {
        "avg_logprob": -0.41948311001646754,
        "compression_ratio": 1.3553719008264462,
        "end": 7963.72,
        "id": 2458,
        "no_speech_prob": 0.000006853977538412437,
        "seek": 794468,
        "start": 7961.6,
        "temperature": 0,
        "text": " I like doing it with like a high learning rate.",
        "tokens": [
          51210,
          286,
          411,
          884,
          309,
          365,
          411,
          257,
          1090,
          2539,
          3314,
          13,
          51316
        ]
      },
      {
        "avg_logprob": -0.41948311001646754,
        "compression_ratio": 1.3553719008264462,
        "end": 7965.96,
        "id": 2459,
        "no_speech_prob": 0.000006853977538412437,
        "seek": 794468,
        "start": 7963.72,
        "temperature": 0,
        "text": " You can see like it gets to,",
        "tokens": [
          51316,
          509,
          393,
          536,
          411,
          309,
          2170,
          281,
          11,
          51428
        ]
      },
      {
        "avg_logprob": -0.41948311001646754,
        "compression_ratio": 1.3553719008264462,
        "end": 7967.56,
        "id": 2460,
        "no_speech_prob": 0.000006853977538412437,
        "seek": 794468,
        "start": 7965.96,
        "temperature": 0,
        "text": " you can sort of see it bouncing.",
        "tokens": [
          51428,
          291,
          393,
          1333,
          295,
          536,
          309,
          27380,
          13,
          51508
        ]
      },
      {
        "avg_logprob": -0.36011021407609134,
        "compression_ratio": 1.5631067961165048,
        "end": 7975.76,
        "id": 2461,
        "no_speech_prob": 0.00012533701374195516,
        "seek": 797468,
        "start": 7974.68,
        "temperature": 0,
        "text": " Look at this.",
        "tokens": [
          50364,
          2053,
          412,
          341,
          13,
          50418
        ]
      },
      {
        "avg_logprob": -0.36011021407609134,
        "compression_ratio": 1.5631067961165048,
        "end": 7981.4400000000005,
        "id": 2462,
        "no_speech_prob": 0.00012533701374195516,
        "seek": 797468,
        "start": 7980,
        "temperature": 0,
        "text": " Look at this, learning rate is too high.",
        "tokens": [
          50630,
          2053,
          412,
          341,
          11,
          2539,
          3314,
          307,
          886,
          1090,
          13,
          50702
        ]
      },
      {
        "avg_logprob": -0.36011021407609134,
        "compression_ratio": 1.5631067961165048,
        "end": 7984.04,
        "id": 2463,
        "no_speech_prob": 0.00012533701374195516,
        "seek": 797468,
        "start": 7981.4400000000005,
        "temperature": 0,
        "text": " It's kind of gets stuck, it kind of can't get there.",
        "tokens": [
          50702,
          467,
          311,
          733,
          295,
          2170,
          5541,
          11,
          309,
          733,
          295,
          393,
          380,
          483,
          456,
          13,
          50832
        ]
      },
      {
        "avg_logprob": -0.36011021407609134,
        "compression_ratio": 1.5631067961165048,
        "end": 7990.320000000001,
        "id": 2464,
        "no_speech_prob": 0.00012533701374195516,
        "seek": 797468,
        "start": 7987.76,
        "temperature": 0,
        "text": " And then if we could do, we could do weird stuff like,",
        "tokens": [
          51018,
          400,
          550,
          498,
          321,
          727,
          360,
          11,
          321,
          727,
          360,
          3657,
          1507,
          411,
          11,
          51146
        ]
      },
      {
        "avg_logprob": -0.36011021407609134,
        "compression_ratio": 1.5631067961165048,
        "end": 7992.38,
        "id": 2465,
        "no_speech_prob": 0.00012533701374195516,
        "seek": 797468,
        "start": 7990.320000000001,
        "temperature": 0,
        "text": " like what if I gave the hidden layer 16 units",
        "tokens": [
          51146,
          411,
          437,
          498,
          286,
          2729,
          264,
          7633,
          4583,
          3165,
          6815,
          51249
        ]
      },
      {
        "avg_logprob": -0.36011021407609134,
        "compression_ratio": 1.5631067961165048,
        "end": 7993.72,
        "id": 2466,
        "no_speech_prob": 0.00012533701374195516,
        "seek": 797468,
        "start": 7992.38,
        "temperature": 0,
        "text": " for like no reason?",
        "tokens": [
          51249,
          337,
          411,
          572,
          1778,
          30,
          51316
        ]
      },
      {
        "avg_logprob": -0.36011021407609134,
        "compression_ratio": 1.5631067961165048,
        "end": 8001.4800000000005,
        "id": 2467,
        "no_speech_prob": 0.00012533701374195516,
        "seek": 797468,
        "start": 7998.62,
        "temperature": 0,
        "text": " Like, look how, because there's no correct answer.",
        "tokens": [
          51561,
          1743,
          11,
          574,
          577,
          11,
          570,
          456,
          311,
          572,
          3006,
          1867,
          13,
          51704
        ]
      },
      {
        "avg_logprob": -0.36011021407609134,
        "compression_ratio": 1.5631067961165048,
        "end": 8003.56,
        "id": 2468,
        "no_speech_prob": 0.00012533701374195516,
        "seek": 797468,
        "start": 8001.4800000000005,
        "temperature": 0,
        "text": " There's only training data at the corners.",
        "tokens": [
          51704,
          821,
          311,
          787,
          3097,
          1412,
          412,
          264,
          12413,
          13,
          51808
        ]
      },
      {
        "avg_logprob": -0.3276656317332434,
        "compression_ratio": 1.5081967213114753,
        "end": 8005.160000000001,
        "id": 2469,
        "no_speech_prob": 0.0002269324177177623,
        "seek": 800356,
        "start": 8003.56,
        "temperature": 0,
        "text": " What, learned a rainbow.",
        "tokens": [
          50364,
          708,
          11,
          3264,
          257,
          18526,
          13,
          50444
        ]
      },
      {
        "avg_logprob": -0.3276656317332434,
        "compression_ratio": 1.5081967213114753,
        "end": 8008.8,
        "id": 2470,
        "no_speech_prob": 0.0002269324177177623,
        "seek": 800356,
        "start": 8006.360000000001,
        "temperature": 0,
        "text": " Look, it's a rainbow.",
        "tokens": [
          50504,
          2053,
          11,
          309,
          311,
          257,
          18526,
          13,
          50626
        ]
      },
      {
        "avg_logprob": -0.3276656317332434,
        "compression_ratio": 1.5081967213114753,
        "end": 8010.68,
        "id": 2471,
        "no_speech_prob": 0.0002269324177177623,
        "seek": 800356,
        "start": 8008.8,
        "temperature": 0,
        "text": " XOR learned a rainbow.",
        "tokens": [
          50626,
          1783,
          2483,
          3264,
          257,
          18526,
          13,
          50720
        ]
      },
      {
        "avg_logprob": -0.3276656317332434,
        "compression_ratio": 1.5081967213114753,
        "end": 8012.160000000001,
        "id": 2472,
        "no_speech_prob": 0.0002269324177177623,
        "seek": 800356,
        "start": 8010.68,
        "temperature": 0,
        "text": " People are asking me questions.",
        "tokens": [
          50720,
          3432,
          366,
          3365,
          385,
          1651,
          13,
          50794
        ]
      },
      {
        "avg_logprob": -0.3276656317332434,
        "compression_ratio": 1.5081967213114753,
        "end": 8014.72,
        "id": 2473,
        "no_speech_prob": 0.0002269324177177623,
        "seek": 800356,
        "start": 8012.160000000001,
        "temperature": 0,
        "text": " Are you going to do convolutional 2D soon?",
        "tokens": [
          50794,
          2014,
          291,
          516,
          281,
          360,
          45216,
          304,
          568,
          35,
          2321,
          30,
          50922
        ]
      },
      {
        "avg_logprob": -0.3276656317332434,
        "compression_ratio": 1.5081967213114753,
        "end": 8019.280000000001,
        "id": 2474,
        "no_speech_prob": 0.0002269324177177623,
        "seek": 800356,
        "start": 8014.72,
        "temperature": 0,
        "text": " That's why I hope to, plan to, yes.",
        "tokens": [
          50922,
          663,
          311,
          983,
          286,
          1454,
          281,
          11,
          1393,
          281,
          11,
          2086,
          13,
          51150
        ]
      },
      {
        "avg_logprob": -0.3276656317332434,
        "compression_ratio": 1.5081967213114753,
        "end": 8020.360000000001,
        "id": 2475,
        "no_speech_prob": 0.0002269324177177623,
        "seek": 800356,
        "start": 8019.280000000001,
        "temperature": 0,
        "text": " All right, everybody.",
        "tokens": [
          51150,
          1057,
          558,
          11,
          2201,
          13,
          51204
        ]
      },
      {
        "avg_logprob": -0.3276656317332434,
        "compression_ratio": 1.5081967213114753,
        "end": 8024.280000000001,
        "id": 2476,
        "no_speech_prob": 0.0002269324177177623,
        "seek": 800356,
        "start": 8022.360000000001,
        "temperature": 0,
        "text": " So this is my list.",
        "tokens": [
          51304,
          407,
          341,
          307,
          452,
          1329,
          13,
          51400
        ]
      },
      {
        "avg_logprob": -0.3276656317332434,
        "compression_ratio": 1.5081967213114753,
        "end": 8026.4400000000005,
        "id": 2477,
        "no_speech_prob": 0.0002269324177177623,
        "seek": 800356,
        "start": 8024.280000000001,
        "temperature": 0,
        "text": " Oh, thank you, Joshua Myers.",
        "tokens": [
          51400,
          876,
          11,
          1309,
          291,
          11,
          24005,
          45088,
          13,
          51508
        ]
      },
      {
        "avg_logprob": -0.3276656317332434,
        "compression_ratio": 1.5081967213114753,
        "end": 8027.280000000001,
        "id": 2478,
        "no_speech_prob": 0.0002269324177177623,
        "seek": 800356,
        "start": 8026.4400000000005,
        "temperature": 0,
        "text": " That's very kind of you.",
        "tokens": [
          51508,
          663,
          311,
          588,
          733,
          295,
          291,
          13,
          51550
        ]
      },
      {
        "avg_logprob": -0.3276656317332434,
        "compression_ratio": 1.5081967213114753,
        "end": 8030,
        "id": 2479,
        "no_speech_prob": 0.0002269324177177623,
        "seek": 800356,
        "start": 8027.280000000001,
        "temperature": 0,
        "text": " If I had my Philips light bulb, it would have flashed.",
        "tokens": [
          51550,
          759,
          286,
          632,
          452,
          7777,
          2600,
          1442,
          21122,
          11,
          309,
          576,
          362,
          7319,
          292,
          13,
          51686
        ]
      },
      {
        "avg_logprob": -0.3276656317332434,
        "compression_ratio": 1.5081967213114753,
        "end": 8033.200000000001,
        "id": 2480,
        "no_speech_prob": 0.0002269324177177623,
        "seek": 800356,
        "start": 8031.8,
        "temperature": 0,
        "text": " By the way, oh, let me just mention,",
        "tokens": [
          51776,
          3146,
          264,
          636,
          11,
          1954,
          11,
          718,
          385,
          445,
          2152,
          11,
          51846
        ]
      },
      {
        "avg_logprob": -0.22531262101798222,
        "compression_ratio": 1.7375415282392026,
        "end": 8036.24,
        "id": 2481,
        "no_speech_prob": 0.00006014109749230556,
        "seek": 803320,
        "start": 8033.2,
        "temperature": 0,
        "text": " if any of you are sponsors,",
        "tokens": [
          50364,
          498,
          604,
          295,
          291,
          366,
          22593,
          11,
          50516
        ]
      },
      {
        "avg_logprob": -0.22531262101798222,
        "compression_ratio": 1.7375415282392026,
        "end": 8037.72,
        "id": 2482,
        "no_speech_prob": 0.00006014109749230556,
        "seek": 803320,
        "start": 8036.24,
        "temperature": 0,
        "text": " you can now sponsor the channel",
        "tokens": [
          50516,
          291,
          393,
          586,
          16198,
          264,
          2269,
          50590
        ]
      },
      {
        "avg_logprob": -0.22531262101798222,
        "compression_ratio": 1.7375415282392026,
        "end": 8040.54,
        "id": 2483,
        "no_speech_prob": 0.00006014109749230556,
        "seek": 803320,
        "start": 8037.72,
        "temperature": 0,
        "text": " through the YouTube interface itself.",
        "tokens": [
          50590,
          807,
          264,
          3088,
          9226,
          2564,
          13,
          50731
        ]
      },
      {
        "avg_logprob": -0.22531262101798222,
        "compression_ratio": 1.7375415282392026,
        "end": 8043.48,
        "id": 2484,
        "no_speech_prob": 0.00006014109749230556,
        "seek": 803320,
        "start": 8040.54,
        "temperature": 0,
        "text": " Make sure you go and check the community tab",
        "tokens": [
          50731,
          4387,
          988,
          291,
          352,
          293,
          1520,
          264,
          1768,
          4421,
          50878
        ]
      },
      {
        "avg_logprob": -0.22531262101798222,
        "compression_ratio": 1.7375415282392026,
        "end": 8046.24,
        "id": 2485,
        "no_speech_prob": 0.00006014109749230556,
        "seek": 803320,
        "start": 8043.48,
        "temperature": 0,
        "text": " and look for a post that links to a Google form",
        "tokens": [
          50878,
          293,
          574,
          337,
          257,
          2183,
          300,
          6123,
          281,
          257,
          3329,
          1254,
          51016
        ]
      },
      {
        "avg_logprob": -0.22531262101798222,
        "compression_ratio": 1.7375415282392026,
        "end": 8048.16,
        "id": 2486,
        "no_speech_prob": 0.00006014109749230556,
        "seek": 803320,
        "start": 8046.24,
        "temperature": 0,
        "text": " to enter your email so I can send you an invitation",
        "tokens": [
          51016,
          281,
          3242,
          428,
          3796,
          370,
          286,
          393,
          2845,
          291,
          364,
          17890,
          51112
        ]
      },
      {
        "avg_logprob": -0.22531262101798222,
        "compression_ratio": 1.7375415282392026,
        "end": 8049.04,
        "id": 2487,
        "no_speech_prob": 0.00006014109749230556,
        "seek": 803320,
        "start": 8048.16,
        "temperature": 0,
        "text": " to the Slack group.",
        "tokens": [
          51112,
          281,
          264,
          37211,
          1594,
          13,
          51156
        ]
      },
      {
        "avg_logprob": -0.22531262101798222,
        "compression_ratio": 1.7375415282392026,
        "end": 8050.44,
        "id": 2488,
        "no_speech_prob": 0.00006014109749230556,
        "seek": 803320,
        "start": 8049.04,
        "temperature": 0,
        "text": " I need a better system for doing that.",
        "tokens": [
          51156,
          286,
          643,
          257,
          1101,
          1185,
          337,
          884,
          300,
          13,
          51226
        ]
      },
      {
        "avg_logprob": -0.22531262101798222,
        "compression_ratio": 1.7375415282392026,
        "end": 8052.7,
        "id": 2489,
        "no_speech_prob": 0.00006014109749230556,
        "seek": 803320,
        "start": 8050.44,
        "temperature": 0,
        "text": " I have a thing set up that it actually like,",
        "tokens": [
          51226,
          286,
          362,
          257,
          551,
          992,
          493,
          300,
          309,
          767,
          411,
          11,
          51339
        ]
      },
      {
        "avg_logprob": -0.22531262101798222,
        "compression_ratio": 1.7375415282392026,
        "end": 8054.88,
        "id": 2490,
        "no_speech_prob": 0.00006014109749230556,
        "seek": 803320,
        "start": 8052.7,
        "temperature": 0,
        "text": " I have a, I get alerts and a spreadsheet and I can look,",
        "tokens": [
          51339,
          286,
          362,
          257,
          11,
          286,
          483,
          28061,
          293,
          257,
          27733,
          293,
          286,
          393,
          574,
          11,
          51448
        ]
      },
      {
        "avg_logprob": -0.22531262101798222,
        "compression_ratio": 1.7375415282392026,
        "end": 8056.5599999999995,
        "id": 2491,
        "no_speech_prob": 0.00006014109749230556,
        "seek": 803320,
        "start": 8054.88,
        "temperature": 0,
        "text": " but I don't get your email address.",
        "tokens": [
          51448,
          457,
          286,
          500,
          380,
          483,
          428,
          3796,
          2985,
          13,
          51532
        ]
      },
      {
        "avg_logprob": -0.22531262101798222,
        "compression_ratio": 1.7375415282392026,
        "end": 8059,
        "id": 2492,
        "no_speech_prob": 0.00006014109749230556,
        "seek": 803320,
        "start": 8056.5599999999995,
        "temperature": 0,
        "text": " So there's no automatic way to invite you to Slack",
        "tokens": [
          51532,
          407,
          456,
          311,
          572,
          12509,
          636,
          281,
          7980,
          291,
          281,
          37211,
          51654
        ]
      },
      {
        "avg_logprob": -0.22531262101798222,
        "compression_ratio": 1.7375415282392026,
        "end": 8060.679999999999,
        "id": 2493,
        "no_speech_prob": 0.00006014109749230556,
        "seek": 803320,
        "start": 8059,
        "temperature": 0,
        "text": " other than by doing it manually.",
        "tokens": [
          51654,
          661,
          813,
          538,
          884,
          309,
          16945,
          13,
          51738
        ]
      },
      {
        "avg_logprob": -0.31114357787293273,
        "compression_ratio": 1.5,
        "end": 8065.64,
        "id": 2494,
        "no_speech_prob": 0.000028857088182121515,
        "seek": 806068,
        "start": 8061.68,
        "temperature": 0,
        "text": " And yeah, so this is where I'm,",
        "tokens": [
          50414,
          400,
          1338,
          11,
          370,
          341,
          307,
          689,
          286,
          478,
          11,
          50612
        ]
      },
      {
        "avg_logprob": -0.31114357787293273,
        "compression_ratio": 1.5,
        "end": 8069.06,
        "id": 2495,
        "no_speech_prob": 0.000028857088182121515,
        "seek": 806068,
        "start": 8066.8,
        "temperature": 0,
        "text": " this is where I am going to next.",
        "tokens": [
          50670,
          341,
          307,
          689,
          286,
          669,
          516,
          281,
          958,
          13,
          50783
        ]
      },
      {
        "avg_logprob": -0.31114357787293273,
        "compression_ratio": 1.5,
        "end": 8075.12,
        "id": 2496,
        "no_speech_prob": 0.000028857088182121515,
        "seek": 806068,
        "start": 8070.96,
        "temperature": 0,
        "text": " I am going to do a, ah,",
        "tokens": [
          50878,
          286,
          669,
          516,
          281,
          360,
          257,
          11,
          3716,
          11,
          51086
        ]
      },
      {
        "avg_logprob": -0.31114357787293273,
        "compression_ratio": 1.5,
        "end": 8077.780000000001,
        "id": 2497,
        "no_speech_prob": 0.000028857088182121515,
        "seek": 806068,
        "start": 8075.12,
        "temperature": 0,
        "text": " I want to do the TF playground idea",
        "tokens": [
          51086,
          286,
          528,
          281,
          360,
          264,
          40964,
          24646,
          1558,
          51219
        ]
      },
      {
        "avg_logprob": -0.31114357787293273,
        "compression_ratio": 1.5,
        "end": 8080.12,
        "id": 2498,
        "no_speech_prob": 0.000028857088182121515,
        "seek": 806068,
        "start": 8077.780000000001,
        "temperature": 0,
        "text": " and the classification idea.",
        "tokens": [
          51219,
          293,
          264,
          21538,
          1558,
          13,
          51336
        ]
      },
      {
        "avg_logprob": -0.31114357787293273,
        "compression_ratio": 1.5,
        "end": 8084.6,
        "id": 2499,
        "no_speech_prob": 0.000028857088182121515,
        "seek": 806068,
        "start": 8081.4800000000005,
        "temperature": 0,
        "text": " So if anybody has any ideas for really simple,",
        "tokens": [
          51404,
          407,
          498,
          4472,
          575,
          604,
          3487,
          337,
          534,
          2199,
          11,
          51560
        ]
      },
      {
        "avg_logprob": -0.31114357787293273,
        "compression_ratio": 1.5,
        "end": 8089.1,
        "id": 2500,
        "no_speech_prob": 0.000028857088182121515,
        "seek": 806068,
        "start": 8084.6,
        "temperature": 0,
        "text": " goofy, just like basic numeric data sets,",
        "tokens": [
          51560,
          42995,
          11,
          445,
          411,
          3875,
          7866,
          299,
          1412,
          6352,
          11,
          51785
        ]
      },
      {
        "avg_logprob": -0.27169906731807825,
        "compression_ratio": 1.6222222222222222,
        "end": 8090.54,
        "id": 2501,
        "no_speech_prob": 0.00004133507900405675,
        "seek": 808910,
        "start": 8089.14,
        "temperature": 0,
        "text": " I'm probably going to do something",
        "tokens": [
          50366,
          286,
          478,
          1391,
          516,
          281,
          360,
          746,
          50436
        ]
      },
      {
        "avg_logprob": -0.27169906731807825,
        "compression_ratio": 1.6222222222222222,
        "end": 8092.620000000001,
        "id": 2502,
        "no_speech_prob": 0.00004133507900405675,
        "seek": 808910,
        "start": 8090.54,
        "temperature": 0,
        "text": " where I'm going to look for some color data set,",
        "tokens": [
          50436,
          689,
          286,
          478,
          516,
          281,
          574,
          337,
          512,
          2017,
          1412,
          992,
          11,
          50540
        ]
      },
      {
        "avg_logprob": -0.27169906731807825,
        "compression_ratio": 1.6222222222222222,
        "end": 8096.200000000001,
        "id": 2503,
        "no_speech_prob": 0.00004133507900405675,
        "seek": 808910,
        "start": 8092.620000000001,
        "temperature": 0,
        "text": " which takes any RGB, set of RGB numbers",
        "tokens": [
          50540,
          597,
          2516,
          604,
          31231,
          11,
          992,
          295,
          31231,
          3547,
          50719
        ]
      },
      {
        "avg_logprob": -0.27169906731807825,
        "compression_ratio": 1.6222222222222222,
        "end": 8098.900000000001,
        "id": 2504,
        "no_speech_prob": 0.00004133507900405675,
        "seek": 808910,
        "start": 8096.200000000001,
        "temperature": 0,
        "text": " and like categorizes it in like a few,",
        "tokens": [
          50719,
          293,
          411,
          19250,
          5660,
          309,
          294,
          411,
          257,
          1326,
          11,
          50854
        ]
      },
      {
        "avg_logprob": -0.27169906731807825,
        "compression_ratio": 1.6222222222222222,
        "end": 8100.26,
        "id": 2505,
        "no_speech_prob": 0.00004133507900405675,
        "seek": 808910,
        "start": 8098.900000000001,
        "temperature": 0,
        "text": " with a few different like labels.",
        "tokens": [
          50854,
          365,
          257,
          1326,
          819,
          411,
          16949,
          13,
          50922
        ]
      },
      {
        "avg_logprob": -0.27169906731807825,
        "compression_ratio": 1.6222222222222222,
        "end": 8102.820000000001,
        "id": 2506,
        "no_speech_prob": 0.00004133507900405675,
        "seek": 808910,
        "start": 8100.26,
        "temperature": 0,
        "text": " That's why, so if you have some suggestions for that,",
        "tokens": [
          50922,
          663,
          311,
          983,
          11,
          370,
          498,
          291,
          362,
          512,
          13396,
          337,
          300,
          11,
          51050
        ]
      },
      {
        "avg_logprob": -0.27169906731807825,
        "compression_ratio": 1.6222222222222222,
        "end": 8104.820000000001,
        "id": 2507,
        "no_speech_prob": 0.00004133507900405675,
        "seek": 808910,
        "start": 8102.820000000001,
        "temperature": 0,
        "text": " please let me know,",
        "tokens": [
          51050,
          1767,
          718,
          385,
          458,
          11,
          51150
        ]
      },
      {
        "avg_logprob": -0.27169906731807825,
        "compression_ratio": 1.6222222222222222,
        "end": 8107.320000000001,
        "id": 2508,
        "no_speech_prob": 0.00004133507900405675,
        "seek": 808910,
        "start": 8104.820000000001,
        "temperature": 0,
        "text": " at Schiffman on Twitter is probably the best way.",
        "tokens": [
          51150,
          412,
          2065,
          3661,
          1601,
          322,
          5794,
          307,
          1391,
          264,
          1151,
          636,
          13,
          51275
        ]
      },
      {
        "avg_logprob": -0.27169906731807825,
        "compression_ratio": 1.6222222222222222,
        "end": 8108.320000000001,
        "id": 2509,
        "no_speech_prob": 0.00004133507900405675,
        "seek": 808910,
        "start": 8107.320000000001,
        "temperature": 0,
        "text": " All right, everyone.",
        "tokens": [
          51275,
          1057,
          558,
          11,
          1518,
          13,
          51325
        ]
      },
      {
        "avg_logprob": -0.27169906731807825,
        "compression_ratio": 1.6222222222222222,
        "end": 8110.46,
        "id": 2510,
        "no_speech_prob": 0.00004133507900405675,
        "seek": 808910,
        "start": 8109.620000000001,
        "temperature": 0,
        "text": " I don't know.",
        "tokens": [
          51390,
          286,
          500,
          380,
          458,
          13,
          51432
        ]
      },
      {
        "avg_logprob": -0.27169906731807825,
        "compression_ratio": 1.6222222222222222,
        "end": 8112.56,
        "id": 2511,
        "no_speech_prob": 0.00004133507900405675,
        "seek": 808910,
        "start": 8111.34,
        "temperature": 0,
        "text": " Add more layers.",
        "tokens": [
          51476,
          5349,
          544,
          7914,
          13,
          51537
        ]
      },
      {
        "avg_logprob": -0.27169906731807825,
        "compression_ratio": 1.6222222222222222,
        "end": 8115.14,
        "id": 2512,
        "no_speech_prob": 0.00004133507900405675,
        "seek": 808910,
        "start": 8114.02,
        "temperature": 0,
        "text": " Sorry, everybody.",
        "tokens": [
          51610,
          4919,
          11,
          2201,
          13,
          51666
        ]
      },
      {
        "avg_logprob": -0.27169906731807825,
        "compression_ratio": 1.6222222222222222,
        "end": 8119.08,
        "id": 2513,
        "no_speech_prob": 0.00004133507900405675,
        "seek": 808910,
        "start": 8115.14,
        "temperature": 0,
        "text": " I hope today, I hope you enjoyed today somehow.",
        "tokens": [
          51666,
          286,
          1454,
          965,
          11,
          286,
          1454,
          291,
          4626,
          965,
          6063,
          13,
          51863
        ]
      },
      {
        "avg_logprob": -0.20015647612422346,
        "compression_ratio": 1.9228187919463087,
        "end": 8121.44,
        "id": 2514,
        "no_speech_prob": 0.000017778536857804283,
        "seek": 811908,
        "start": 8120.08,
        "temperature": 0,
        "text": " I just, I don't know.",
        "tokens": [
          50414,
          286,
          445,
          11,
          286,
          500,
          380,
          458,
          13,
          50482
        ]
      },
      {
        "avg_logprob": -0.20015647612422346,
        "compression_ratio": 1.9228187919463087,
        "end": 8122.4,
        "id": 2515,
        "no_speech_prob": 0.000017778536857804283,
        "seek": 811908,
        "start": 8121.44,
        "temperature": 0,
        "text": " Maybe I shouldn't be covering.",
        "tokens": [
          50482,
          2704,
          286,
          4659,
          380,
          312,
          10322,
          13,
          50530
        ]
      },
      {
        "avg_logprob": -0.20015647612422346,
        "compression_ratio": 1.9228187919463087,
        "end": 8123.4,
        "id": 2516,
        "no_speech_prob": 0.000017778536857804283,
        "seek": 811908,
        "start": 8122.4,
        "temperature": 0,
        "text": " Next week, let me really,",
        "tokens": [
          50530,
          3087,
          1243,
          11,
          718,
          385,
          534,
          11,
          50580
        ]
      },
      {
        "avg_logprob": -0.20015647612422346,
        "compression_ratio": 1.9228187919463087,
        "end": 8125.04,
        "id": 2517,
        "no_speech_prob": 0.000017778536857804283,
        "seek": 811908,
        "start": 8123.4,
        "temperature": 0,
        "text": " maybe I'll try to at least do a coding challenge",
        "tokens": [
          50580,
          1310,
          286,
          603,
          853,
          281,
          412,
          1935,
          360,
          257,
          17720,
          3430,
          50662
        ]
      },
      {
        "avg_logprob": -0.20015647612422346,
        "compression_ratio": 1.9228187919463087,
        "end": 8126.44,
        "id": 2518,
        "no_speech_prob": 0.000017778536857804283,
        "seek": 811908,
        "start": 8125.04,
        "temperature": 0,
        "text": " that's not machine learning related.",
        "tokens": [
          50662,
          300,
          311,
          406,
          3479,
          2539,
          4077,
          13,
          50732
        ]
      },
      {
        "avg_logprob": -0.20015647612422346,
        "compression_ratio": 1.9228187919463087,
        "end": 8128.5199999999995,
        "id": 2519,
        "no_speech_prob": 0.000017778536857804283,
        "seek": 811908,
        "start": 8126.44,
        "temperature": 0,
        "text": " I want to get through all this machine learning content,",
        "tokens": [
          50732,
          286,
          528,
          281,
          483,
          807,
          439,
          341,
          3479,
          2539,
          2701,
          11,
          50836
        ]
      },
      {
        "avg_logprob": -0.20015647612422346,
        "compression_ratio": 1.9228187919463087,
        "end": 8131.36,
        "id": 2520,
        "no_speech_prob": 0.000017778536857804283,
        "seek": 811908,
        "start": 8128.5199999999995,
        "temperature": 0,
        "text": " but it is kind of overwhelming and taking over everything.",
        "tokens": [
          50836,
          457,
          309,
          307,
          733,
          295,
          13373,
          293,
          1940,
          670,
          1203,
          13,
          50978
        ]
      },
      {
        "avg_logprob": -0.20015647612422346,
        "compression_ratio": 1.9228187919463087,
        "end": 8133.08,
        "id": 2521,
        "no_speech_prob": 0.000017778536857804283,
        "seek": 811908,
        "start": 8131.36,
        "temperature": 0,
        "text": " Weather prediction, but I need,",
        "tokens": [
          50978,
          34441,
          17630,
          11,
          457,
          286,
          643,
          11,
          51064
        ]
      },
      {
        "avg_logprob": -0.20015647612422346,
        "compression_ratio": 1.9228187919463087,
        "end": 8134.68,
        "id": 2522,
        "no_speech_prob": 0.000017778536857804283,
        "seek": 811908,
        "start": 8133.08,
        "temperature": 0,
        "text": " I want to do classification.",
        "tokens": [
          51064,
          286,
          528,
          281,
          360,
          21538,
          13,
          51144
        ]
      },
      {
        "avg_logprob": -0.20015647612422346,
        "compression_ratio": 1.9228187919463087,
        "end": 8136.98,
        "id": 2523,
        "no_speech_prob": 0.000017778536857804283,
        "seek": 811908,
        "start": 8134.68,
        "temperature": 0,
        "text": " So I don't want to do time series,",
        "tokens": [
          51144,
          407,
          286,
          500,
          380,
          528,
          281,
          360,
          565,
          2638,
          11,
          51259
        ]
      },
      {
        "avg_logprob": -0.20015647612422346,
        "compression_ratio": 1.9228187919463087,
        "end": 8138.58,
        "id": 2524,
        "no_speech_prob": 0.000017778536857804283,
        "seek": 811908,
        "start": 8136.98,
        "temperature": 0,
        "text": " all these, these things will come,",
        "tokens": [
          51259,
          439,
          613,
          11,
          613,
          721,
          486,
          808,
          11,
          51339
        ]
      },
      {
        "avg_logprob": -0.20015647612422346,
        "compression_ratio": 1.9228187919463087,
        "end": 8141.48,
        "id": 2525,
        "no_speech_prob": 0.000017778536857804283,
        "seek": 811908,
        "start": 8138.58,
        "temperature": 0,
        "text": " but I want to do a really basic classification.",
        "tokens": [
          51339,
          457,
          286,
          528,
          281,
          360,
          257,
          534,
          3875,
          21538,
          13,
          51484
        ]
      },
      {
        "avg_logprob": -0.20015647612422346,
        "compression_ratio": 1.9228187919463087,
        "end": 8143.36,
        "id": 2526,
        "no_speech_prob": 0.000017778536857804283,
        "seek": 811908,
        "start": 8141.48,
        "temperature": 0,
        "text": " I don't want to use images.",
        "tokens": [
          51484,
          286,
          500,
          380,
          528,
          281,
          764,
          5267,
          13,
          51578
        ]
      },
      {
        "avg_logprob": -0.20015647612422346,
        "compression_ratio": 1.9228187919463087,
        "end": 8144.92,
        "id": 2527,
        "no_speech_prob": 0.000017778536857804283,
        "seek": 811908,
        "start": 8143.36,
        "temperature": 0,
        "text": " I don't want to use text data.",
        "tokens": [
          51578,
          286,
          500,
          380,
          528,
          281,
          764,
          2487,
          1412,
          13,
          51656
        ]
      },
      {
        "avg_logprob": -0.20015647612422346,
        "compression_ratio": 1.9228187919463087,
        "end": 8148.28,
        "id": 2528,
        "no_speech_prob": 0.000017778536857804283,
        "seek": 811908,
        "start": 8144.92,
        "temperature": 0,
        "text": " That's like, I don't use time series, sequential data.",
        "tokens": [
          51656,
          663,
          311,
          411,
          11,
          286,
          500,
          380,
          764,
          565,
          2638,
          11,
          42881,
          1412,
          13,
          51824
        ]
      },
      {
        "avg_logprob": -0.2674593979053283,
        "compression_ratio": 1.7018633540372672,
        "end": 8149.599999999999,
        "id": 2529,
        "no_speech_prob": 0.0000036119765809417004,
        "seek": 814828,
        "start": 8148.32,
        "temperature": 0,
        "text": " I just want like, you know,",
        "tokens": [
          50366,
          286,
          445,
          528,
          411,
          11,
          291,
          458,
          11,
          50430
        ]
      },
      {
        "avg_logprob": -0.2674593979053283,
        "compression_ratio": 1.7018633540372672,
        "end": 8151.92,
        "id": 2530,
        "no_speech_prob": 0.0000036119765809417004,
        "seek": 814828,
        "start": 8149.599999999999,
        "temperature": 0,
        "text": " like it's like house prediction, the iris data set.",
        "tokens": [
          50430,
          411,
          309,
          311,
          411,
          1782,
          17630,
          11,
          264,
          3418,
          271,
          1412,
          992,
          13,
          50546
        ]
      },
      {
        "avg_logprob": -0.2674593979053283,
        "compression_ratio": 1.7018633540372672,
        "end": 8154.08,
        "id": 2531,
        "no_speech_prob": 0.0000036119765809417004,
        "seek": 814828,
        "start": 8151.92,
        "temperature": 0,
        "text": " These are the kind of thing, house price prediction.",
        "tokens": [
          50546,
          1981,
          366,
          264,
          733,
          295,
          551,
          11,
          1782,
          3218,
          17630,
          13,
          50654
        ]
      },
      {
        "avg_logprob": -0.2674593979053283,
        "compression_ratio": 1.7018633540372672,
        "end": 8154.92,
        "id": 2532,
        "no_speech_prob": 0.0000036119765809417004,
        "seek": 814828,
        "start": 8154.08,
        "temperature": 0,
        "text": " Well, that's prediction.",
        "tokens": [
          50654,
          1042,
          11,
          300,
          311,
          17630,
          13,
          50696
        ]
      },
      {
        "avg_logprob": -0.2674593979053283,
        "compression_ratio": 1.7018633540372672,
        "end": 8156.84,
        "id": 2533,
        "no_speech_prob": 0.0000036119765809417004,
        "seek": 814828,
        "start": 8154.92,
        "temperature": 0,
        "text": " That's not classification even, but regression,",
        "tokens": [
          50696,
          663,
          311,
          406,
          21538,
          754,
          11,
          457,
          24590,
          11,
          50792
        ]
      },
      {
        "avg_logprob": -0.2674593979053283,
        "compression_ratio": 1.7018633540372672,
        "end": 8158.12,
        "id": 2534,
        "no_speech_prob": 0.0000036119765809417004,
        "seek": 814828,
        "start": 8156.84,
        "temperature": 0,
        "text": " but something like that,",
        "tokens": [
          50792,
          457,
          746,
          411,
          300,
          11,
          50856
        ]
      },
      {
        "avg_logprob": -0.2674593979053283,
        "compression_ratio": 1.7018633540372672,
        "end": 8160.78,
        "id": 2535,
        "no_speech_prob": 0.0000036119765809417004,
        "seek": 814828,
        "start": 8158.12,
        "temperature": 0,
        "text": " but I want it to feel goofy, creative,",
        "tokens": [
          50856,
          457,
          286,
          528,
          309,
          281,
          841,
          42995,
          11,
          5880,
          11,
          50989
        ]
      },
      {
        "avg_logprob": -0.2674593979053283,
        "compression_ratio": 1.7018633540372672,
        "end": 8162.92,
        "id": 2536,
        "no_speech_prob": 0.0000036119765809417004,
        "seek": 814828,
        "start": 8160.78,
        "temperature": 0,
        "text": " in the art world space, that kind of thing.",
        "tokens": [
          50989,
          294,
          264,
          1523,
          1002,
          1901,
          11,
          300,
          733,
          295,
          551,
          13,
          51096
        ]
      },
      {
        "avg_logprob": -0.2674593979053283,
        "compression_ratio": 1.7018633540372672,
        "end": 8165.759999999999,
        "id": 2537,
        "no_speech_prob": 0.0000036119765809417004,
        "seek": 814828,
        "start": 8163.88,
        "temperature": 0,
        "text": " All right, tic-tac-toe game.",
        "tokens": [
          51144,
          1057,
          558,
          11,
          256,
          299,
          12,
          83,
          326,
          12,
          1353,
          68,
          1216,
          13,
          51238
        ]
      },
      {
        "avg_logprob": -0.2674593979053283,
        "compression_ratio": 1.7018633540372672,
        "end": 8166.58,
        "id": 2538,
        "no_speech_prob": 0.0000036119765809417004,
        "seek": 814828,
        "start": 8165.759999999999,
        "temperature": 0,
        "text": " Okay, goodbye, everybody.",
        "tokens": [
          51238,
          1033,
          11,
          12084,
          11,
          2201,
          13,
          51279
        ]
      },
      {
        "avg_logprob": -0.2674593979053283,
        "compression_ratio": 1.7018633540372672,
        "end": 8167.84,
        "id": 2539,
        "no_speech_prob": 0.0000036119765809417004,
        "seek": 814828,
        "start": 8166.58,
        "temperature": 0,
        "text": " I'm going to hit stop streaming.",
        "tokens": [
          51279,
          286,
          478,
          516,
          281,
          2045,
          1590,
          11791,
          13,
          51342
        ]
      },
      {
        "avg_logprob": -0.2674593979053283,
        "compression_ratio": 1.7018633540372672,
        "end": 8169.92,
        "id": 2540,
        "no_speech_prob": 0.0000036119765809417004,
        "seek": 814828,
        "start": 8167.84,
        "temperature": 0,
        "text": " I guess I will play you out with my weird trailer",
        "tokens": [
          51342,
          286,
          2041,
          286,
          486,
          862,
          291,
          484,
          365,
          452,
          3657,
          11724,
          51446
        ]
      },
      {
        "avg_logprob": -0.2674593979053283,
        "compression_ratio": 1.7018633540372672,
        "end": 8171.28,
        "id": 2541,
        "no_speech_prob": 0.0000036119765809417004,
        "seek": 814828,
        "start": 8169.92,
        "temperature": 0,
        "text": " since that's what I do now.",
        "tokens": [
          51446,
          1670,
          300,
          311,
          437,
          286,
          360,
          586,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.2674593979053283,
        "compression_ratio": 1.7018633540372672,
        "end": 8175.2,
        "id": 2542,
        "no_speech_prob": 0.0000036119765809417004,
        "seek": 814828,
        "start": 8173.16,
        "temperature": 0,
        "text": " ♪ Let's find something we want to make ♪",
        "tokens": [
          51608,
          220,
          158,
          247,
          103,
          961,
          311,
          915,
          746,
          321,
          528,
          281,
          652,
          220,
          158,
          247,
          103,
          51710
        ]
      },
      {
        "avg_logprob": -0.2674593979053283,
        "compression_ratio": 1.7018633540372672,
        "end": 8177.44,
        "id": 2543,
        "no_speech_prob": 0.0000036119765809417004,
        "seek": 814828,
        "start": 8175.2,
        "temperature": 0,
        "text": " ♪ Some crazy idea ♪",
        "tokens": [
          51710,
          220,
          158,
          247,
          103,
          2188,
          3219,
          1558,
          220,
          158,
          247,
          103,
          51822
        ]
      },
      {
        "avg_logprob": -0.3057746887207031,
        "compression_ratio": 1.662162162162162,
        "end": 8180.719999999999,
        "id": 2544,
        "no_speech_prob": 0.0000019033833495996078,
        "seek": 817744,
        "start": 8177.44,
        "temperature": 0,
        "text": " ♪ We'll figure out what it takes to make that dream appear ♪",
        "tokens": [
          50364,
          220,
          158,
          247,
          103,
          492,
          603,
          2573,
          484,
          437,
          309,
          2516,
          281,
          652,
          300,
          3055,
          4204,
          220,
          158,
          247,
          103,
          50528
        ]
      },
      {
        "avg_logprob": -0.3057746887207031,
        "compression_ratio": 1.662162162162162,
        "end": 8182.839999999999,
        "id": 2545,
        "no_speech_prob": 0.0000019033833495996078,
        "seek": 817744,
        "start": 8180.719999999999,
        "temperature": 0,
        "text": " ♪ We'll try to understand now as we're living our day ♪",
        "tokens": [
          50528,
          220,
          158,
          247,
          103,
          492,
          603,
          853,
          281,
          1223,
          586,
          220,
          296,
          321,
          434,
          2647,
          527,
          786,
          220,
          158,
          247,
          103,
          50634
        ]
      },
      {
        "avg_logprob": -0.3057746887207031,
        "compression_ratio": 1.662162162162162,
        "end": 8184.36,
        "id": 2546,
        "no_speech_prob": 0.0000019033833495996078,
        "seek": 817744,
        "start": 8182.839999999999,
        "temperature": 0,
        "text": " While the trailer is playing,",
        "tokens": [
          50634,
          3987,
          264,
          11724,
          307,
          2433,
          11,
          50710
        ]
      },
      {
        "avg_logprob": -0.3057746887207031,
        "compression_ratio": 1.662162162162162,
        "end": 8187.5199999999995,
        "id": 2547,
        "no_speech_prob": 0.0000019033833495996078,
        "seek": 817744,
        "start": 8184.36,
        "temperature": 0,
        "text": " I will attempt to explain",
        "tokens": [
          50710,
          286,
          486,
          5217,
          281,
          2903,
          50868
        ]
      },
      {
        "avg_logprob": -0.3057746887207031,
        "compression_ratio": 1.662162162162162,
        "end": 8190.2,
        "id": 2548,
        "no_speech_prob": 0.0000019033833495996078,
        "seek": 817744,
        "start": 8187.5199999999995,
        "temperature": 0,
        "text": " why doesn't it dispose of tensors automatically,",
        "tokens": [
          50868,
          983,
          1177,
          380,
          309,
          42537,
          295,
          10688,
          830,
          6772,
          11,
          51002
        ]
      },
      {
        "avg_logprob": -0.3057746887207031,
        "compression_ratio": 1.662162162162162,
        "end": 8195.199999999999,
        "id": 2549,
        "no_speech_prob": 0.0000019033833495996078,
        "seek": 817744,
        "start": 8190.2,
        "temperature": 0,
        "text": " as asks Ray Jackson, asks Arnav.",
        "tokens": [
          51002,
          382,
          8962,
          10883,
          10647,
          11,
          8962,
          1587,
          629,
          85,
          13,
          51252
        ]
      },
      {
        "avg_logprob": -0.3057746887207031,
        "compression_ratio": 1.662162162162162,
        "end": 8196.58,
        "id": 2550,
        "no_speech_prob": 0.0000019033833495996078,
        "seek": 817744,
        "start": 8195.279999999999,
        "temperature": 0,
        "text": " I don't actually know",
        "tokens": [
          51256,
          286,
          500,
          380,
          767,
          458,
          51321
        ]
      },
      {
        "avg_logprob": -0.3057746887207031,
        "compression_ratio": 1.662162162162162,
        "end": 8198.56,
        "id": 2551,
        "no_speech_prob": 0.0000019033833495996078,
        "seek": 817744,
        "start": 8196.58,
        "temperature": 0,
        "text": " why it doesn't dispose of tensors automatically,",
        "tokens": [
          51321,
          983,
          309,
          1177,
          380,
          42537,
          295,
          10688,
          830,
          6772,
          11,
          51420
        ]
      },
      {
        "avg_logprob": -0.3057746887207031,
        "compression_ratio": 1.662162162162162,
        "end": 8201.6,
        "id": 2552,
        "no_speech_prob": 0.0000019033833495996078,
        "seek": 817744,
        "start": 8198.56,
        "temperature": 0,
        "text": " but this is the thing that there is no way",
        "tokens": [
          51420,
          457,
          341,
          307,
          264,
          551,
          300,
          456,
          307,
          572,
          636,
          51572
        ]
      },
      {
        "avg_logprob": -0.3057746887207031,
        "compression_ratio": 1.662162162162162,
        "end": 8203.859999999999,
        "id": 2553,
        "no_speech_prob": 0.0000019033833495996078,
        "seek": 817744,
        "start": 8201.6,
        "temperature": 0,
        "text": " to clean up the memory on the GPU",
        "tokens": [
          51572,
          281,
          2541,
          493,
          264,
          4675,
          322,
          264,
          18407,
          51685
        ]
      },
      {
        "avg_logprob": -0.3057746887207031,
        "compression_ratio": 1.662162162162162,
        "end": 8205.439999999999,
        "id": 2554,
        "no_speech_prob": 0.0000019033833495996078,
        "seek": 817744,
        "start": 8203.859999999999,
        "temperature": 0,
        "text": " with a garbage collector in the same way,",
        "tokens": [
          51685,
          365,
          257,
          14150,
          23960,
          294,
          264,
          912,
          636,
          11,
          51764
        ]
      },
      {
        "avg_logprob": -0.3057746887207031,
        "compression_ratio": 1.662162162162162,
        "end": 8207.119999999999,
        "id": 2555,
        "no_speech_prob": 0.0000019033833495996078,
        "seek": 817744,
        "start": 8205.439999999999,
        "temperature": 0,
        "text": " and this is like a lower level question",
        "tokens": [
          51764,
          293,
          341,
          307,
          411,
          257,
          3126,
          1496,
          1168,
          51848
        ]
      },
      {
        "avg_logprob": -0.40989811373072743,
        "compression_ratio": 1.6612903225806452,
        "end": 8208.640000000001,
        "id": 2556,
        "no_speech_prob": 0.00016343864263035357,
        "seek": 820712,
        "start": 8207.800000000001,
        "temperature": 0,
        "text": " that I would be curious.",
        "tokens": [
          50398,
          300,
          286,
          576,
          312,
          6369,
          13,
          50440
        ]
      },
      {
        "avg_logprob": -0.40989811373072743,
        "compression_ratio": 1.6612903225806452,
        "end": 8211.6,
        "id": 2557,
        "no_speech_prob": 0.00016343864263035357,
        "seek": 820712,
        "start": 8208.640000000001,
        "temperature": 0,
        "text": " We have to investigate more about how TensorFlow.js works.",
        "tokens": [
          50440,
          492,
          362,
          281,
          15013,
          544,
          466,
          577,
          37624,
          13,
          25530,
          1985,
          13,
          50588
        ]
      },
      {
        "avg_logprob": -0.40989811373072743,
        "compression_ratio": 1.6612903225806452,
        "end": 8213.28,
        "id": 2558,
        "no_speech_prob": 0.00016343864263035357,
        "seek": 820712,
        "start": 8211.6,
        "temperature": 0,
        "text": " ♪ Fireworks, fireballs, super ships ♪",
        "tokens": [
          50588,
          220,
          158,
          247,
          103,
          7652,
          18357,
          11,
          2610,
          19194,
          11,
          1687,
          11434,
          220,
          158,
          247,
          103,
          50672
        ]
      },
      {
        "avg_logprob": -0.40989811373072743,
        "compression_ratio": 1.6612903225806452,
        "end": 8215.160000000002,
        "id": 2559,
        "no_speech_prob": 0.00016343864263035357,
        "seek": 820712,
        "start": 8213.28,
        "temperature": 0,
        "text": " ♪ We can do anything in the outer space ♪",
        "tokens": [
          50672,
          220,
          158,
          247,
          103,
          492,
          393,
          360,
          1340,
          294,
          264,
          10847,
          1901,
          220,
          158,
          247,
          103,
          50766
        ]
      },
      {
        "avg_logprob": -0.40989811373072743,
        "compression_ratio": 1.6612903225806452,
        "end": 8217.240000000002,
        "id": 2560,
        "no_speech_prob": 0.00016343864263035357,
        "seek": 820712,
        "start": 8215.160000000002,
        "temperature": 0,
        "text": " ♪ We can generate sounds or trees or mazes ♪",
        "tokens": [
          50766,
          220,
          158,
          247,
          103,
          492,
          393,
          8460,
          3263,
          420,
          5852,
          420,
          463,
          12214,
          220,
          158,
          247,
          103,
          50870
        ]
      },
      {
        "avg_logprob": -0.40989811373072743,
        "compression_ratio": 1.6612903225806452,
        "end": 8219.08,
        "id": 2561,
        "no_speech_prob": 0.00016343864263035357,
        "seek": 820712,
        "start": 8217.240000000002,
        "temperature": 0,
        "text": " ♪ Make a butterfly or reflect our faces ♪",
        "tokens": [
          50870,
          220,
          158,
          247,
          103,
          4387,
          257,
          22140,
          420,
          5031,
          527,
          8475,
          220,
          158,
          247,
          103,
          50962
        ]
      },
      {
        "avg_logprob": -0.40989811373072743,
        "compression_ratio": 1.6612903225806452,
        "end": 8220.84,
        "id": 2562,
        "no_speech_prob": 0.00016343864263035357,
        "seek": 820712,
        "start": 8219.08,
        "temperature": 0,
        "text": " ♪ A retro game for a toy device ♪",
        "tokens": [
          50962,
          220,
          158,
          247,
          103,
          316,
          18820,
          1216,
          337,
          257,
          12058,
          4302,
          220,
          158,
          247,
          103,
          51050
        ]
      },
      {
        "avg_logprob": -0.40989811373072743,
        "compression_ratio": 1.6612903225806452,
        "end": 8222.240000000002,
        "id": 2563,
        "no_speech_prob": 0.00016343864263035357,
        "seek": 820712,
        "start": 8220.84,
        "temperature": 0,
        "text": " ♪ And never forget that there's that ♪",
        "tokens": [
          51050,
          220,
          158,
          247,
          103,
          400,
          1128,
          2870,
          300,
          456,
          311,
          300,
          220,
          158,
          247,
          103,
          51120
        ]
      },
      {
        "avg_logprob": -0.40989811373072743,
        "compression_ratio": 1.6612903225806452,
        "end": 8227.240000000002,
        "id": 2564,
        "no_speech_prob": 0.00016343864263035357,
        "seek": 820712,
        "start": 8222.240000000002,
        "temperature": 0,
        "text": " ♪ Just hop on the coding train, coding train, coding train ♪",
        "tokens": [
          51120,
          220,
          158,
          247,
          103,
          1449,
          3818,
          322,
          264,
          17720,
          3847,
          11,
          17720,
          3847,
          11,
          17720,
          3847,
          220,
          158,
          247,
          103,
          51370
        ]
      },
      {
        "avg_logprob": -0.2625998071877353,
        "compression_ratio": 2.0492610837438425,
        "end": 8242.12,
        "id": 2565,
        "no_speech_prob": 0.9939379692077637,
        "seek": 823712,
        "start": 8237.12,
        "temperature": 0,
        "text": " ♪ Fireworks, fireballs, super ships ♪",
        "tokens": [
          50364,
          220,
          158,
          247,
          103,
          7652,
          18357,
          11,
          2610,
          19194,
          11,
          1687,
          11434,
          220,
          158,
          247,
          103,
          50614
        ]
      },
      {
        "avg_logprob": -0.2625998071877353,
        "compression_ratio": 2.0492610837438425,
        "end": 8244.12,
        "id": 2566,
        "no_speech_prob": 0.9939379692077637,
        "seek": 823712,
        "start": 8242.12,
        "temperature": 0,
        "text": " ♪ We can do anything in the outer space ♪",
        "tokens": [
          50614,
          220,
          158,
          247,
          103,
          492,
          393,
          360,
          1340,
          294,
          264,
          10847,
          1901,
          220,
          158,
          247,
          103,
          50714
        ]
      },
      {
        "avg_logprob": -0.2625998071877353,
        "compression_ratio": 2.0492610837438425,
        "end": 8246.12,
        "id": 2567,
        "no_speech_prob": 0.9939379692077637,
        "seek": 823712,
        "start": 8244.12,
        "temperature": 0,
        "text": " ♪ We can generate sounds or trees or mazes ♪",
        "tokens": [
          50714,
          220,
          158,
          247,
          103,
          492,
          393,
          8460,
          3263,
          420,
          5852,
          420,
          463,
          12214,
          220,
          158,
          247,
          103,
          50814
        ]
      },
      {
        "avg_logprob": -0.2625998071877353,
        "compression_ratio": 2.0492610837438425,
        "end": 8248.12,
        "id": 2568,
        "no_speech_prob": 0.9939379692077637,
        "seek": 823712,
        "start": 8246.12,
        "temperature": 0,
        "text": " ♪ Make a butterfly or reflect our faces ♪",
        "tokens": [
          50814,
          220,
          158,
          247,
          103,
          4387,
          257,
          22140,
          420,
          5031,
          527,
          8475,
          220,
          158,
          247,
          103,
          50914
        ]
      },
      {
        "avg_logprob": -0.2625998071877353,
        "compression_ratio": 2.0492610837438425,
        "end": 8250.12,
        "id": 2569,
        "no_speech_prob": 0.9939379692077637,
        "seek": 823712,
        "start": 8248.12,
        "temperature": 0,
        "text": " ♪ A retro game for a toy device ♪",
        "tokens": [
          50914,
          220,
          158,
          247,
          103,
          316,
          18820,
          1216,
          337,
          257,
          12058,
          4302,
          220,
          158,
          247,
          103,
          51014
        ]
      },
      {
        "avg_logprob": -0.2625998071877353,
        "compression_ratio": 2.0492610837438425,
        "end": 8252.12,
        "id": 2570,
        "no_speech_prob": 0.9939379692077637,
        "seek": 823712,
        "start": 8250.12,
        "temperature": 0,
        "text": " ♪ And never forget that there's that ♪",
        "tokens": [
          51014,
          220,
          158,
          247,
          103,
          400,
          1128,
          2870,
          300,
          456,
          311,
          300,
          220,
          158,
          247,
          103,
          51114
        ]
      },
      {
        "avg_logprob": -0.2625998071877353,
        "compression_ratio": 2.0492610837438425,
        "end": 8257.12,
        "id": 2571,
        "no_speech_prob": 0.9939379692077637,
        "seek": 823712,
        "start": 8252.12,
        "temperature": 0,
        "text": " ♪ Just hop on the coding train, coding train, coding train ♪",
        "tokens": [
          51114,
          220,
          158,
          247,
          103,
          1449,
          3818,
          322,
          264,
          17720,
          3847,
          11,
          17720,
          3847,
          11,
          17720,
          3847,
          220,
          158,
          247,
          103,
          51364
        ]
      },
      {
        "avg_logprob": -0.2625998071877353,
        "compression_ratio": 2.0492610837438425,
        "end": 8259.12,
        "id": 2572,
        "no_speech_prob": 0.9939379692077637,
        "seek": 823712,
        "start": 8257.12,
        "temperature": 0,
        "text": " ♪ Fireworks, fireballs, super ships ♪",
        "tokens": [
          51364,
          220,
          158,
          247,
          103,
          7652,
          18357,
          11,
          2610,
          19194,
          11,
          1687,
          11434,
          220,
          158,
          247,
          103,
          51464
        ]
      },
      {
        "avg_logprob": -0.2625998071877353,
        "compression_ratio": 2.0492610837438425,
        "end": 8261.12,
        "id": 2573,
        "no_speech_prob": 0.9939379692077637,
        "seek": 823712,
        "start": 8259.12,
        "temperature": 0,
        "text": " ♪ We can do anything in the outer space ♪",
        "tokens": [
          51464,
          220,
          158,
          247,
          103,
          492,
          393,
          360,
          1340,
          294,
          264,
          10847,
          1901,
          220,
          158,
          247,
          103,
          51564
        ]
      },
      {
        "avg_logprob": -0.8134900093078613,
        "compression_ratio": 0.68,
        "end": 8263.12,
        "id": 2574,
        "no_speech_prob": 0.9957748055458069,
        "seek": 826112,
        "start": 8261.12,
        "temperature": 0,
        "text": " www.microsoft.com",
        "tokens": [
          50364,
          220,
          17919,
          13,
          13195,
          7856,
          13,
          1112,
          50464
        ]
      }
    ],
    "transcription": " Hello good evening. It's not the evening at all. Is the afternoon. Welcome to the coding train on a Friday which is my usual day for the coding train but this summer it has not been my usual day. I was having a lot of trouble getting the start streaming button to start. I had restricted mode enabled on this laptop for a variety of reasons that I'm not entirely sure of. And interestingly enough I cannot start streaming. I cannot actually I have to. It's a long story but I couldn't get that start streaming button to work while it was in restricted mode. But I fixed that. So here I am. How are you? What's going on? What's up? What's happening? Totally weird how you can't speak to me. Oh I guess there is a chat. So you sort of can type to me in the chat. It's night in India writes Melvin. In Israel it is 20 o'clock which I think is 8 p.m. Alright so I have to admit something. Although this is nothing new. I mean I feel like normally I'm so well prepared and I spent all week making notes and scheduling things out and knowing exactly what I'm going to do. And then I like I've got all this energy and I turn on the streaming and I'm go, go, go. And I do a tutorial and I turn off the streaming and the day is over. Right now I feel like it was a I had to make a heroic effort just to make it here and press the start streaming button. So I have to admit that I'm a little bit out of sorts. But and I have two hours today. Good news is I am planning for two live streams next week. So I am planning to live stream both Wednesday and Thursday it looks like next week. And I will publish times to the home page of this YouTube channel thing soon enough. And so I'm hoping I'm going to get some get into but I really want to do. I really want to do some practical. Ah practical is the wrong word. I don't want to do anything practical whatsoever. I want to do some machine learning demonstrations in the browser with data. And data that might interest you or inspire you to use your own data and do something else with it. But I'm not there yet. Let me try to figure out where I am. I'm going to go to YouTube the coding train. And I'm going to go to neural networks and machine learning. I'm going to go to session six. Hello and welcome. Hello and welcome. I'm not going to watch that. All right so this is what I have so far. I have to do this at the beginning of every live stream to sort of recap and reframe and recenter myself. I am going to put this over here so it doesn't block the view. You may or may not be aware. There is something out in the world called TensorFlow.js. This is a TensorFlow, an implementation of the TensorFlow API in JavaScript that runs in the browser with no other dependencies. All of the math is done and computed using WebGL and shaders and all sorts of amazing gymnastics in ways that I might never understand. But it opens the door and enables possibilities for us. The people who program like this. It's a high program. To try it and experiment and learn a bit about machine learning. And get our hands in there and ask the right questions and be critical about the role of AI and machine learning in our world today. So that's this. I have started doing a series of tutorials. These are not super beginner friendly. There's some advanced JavaScript, advanced aspects of the JavaScript language that I'm using that are confusing like promises and await and async. You have to do lower level memory management yourself when you make these arrays of data. You have to allocate the memory and deallocate the memory. And then there's all these scary weird terms like stochastic gradient descent. Well that's one of them. Optimizer, root mean squared. So but I'm doing this series for an audience who perhaps has already learned a bit about JavaScript programming. Maybe watched some of my other basic intro to neural network videos. And just kind of like follow along and see how a larger machine learning library works in the browser and can be used. So the tutorials that I have so far are sort of an introduction to what TensorFlow.js is. Talking about what it is to be a tensor. What is it to be a tensor? I'm a tensor, I'm very tense all the time. I want to be more relaxed. I want to be a variable instead of a tensor. Although a tensor, whatever, okay. Then variables and operations, talking about memory management. I implemented a version of linear regression which is a kind of like a classic machine learning algorithm where you try to fit a line to a bunch of data points. Kind of serves as the foundation for a lot of machine learning research. I also looked at polynomial regression where instead of a line we could fit a polynomial function which curves around. And then, ah then, then, then, then, then, I finally, finally, finally started looking at the layers API. And the layers API is a higher level API inside of TensorFlow.js which allows you to create machine learning models as sequences of layers. And that has, you know, how that works has to do with how neural networks are architected with inputs and outputs and layers that are in between and there's different kinds of layers and different kinds of math functions that happen with those layers, all that sort of stuff. So this is where I am at the moment. This is where I am. Where am I going to? Where am I going to? Don't ask anymore. Ah, I forgot my ukulele. I learned to play the ukulele a couple weeks ago. Thinking I'm ruining this YouTube channel with me playing the ukulele. Where am I going to? Don't ask anymore. Okay. Ah, so. What's next? Let me make a list. Really for me, but you're watching so you can watch. XOR with TF layers. I want to do a classification example. I'm thinking of do, what I'm thinking of right now. So I'm going to go through these one at a time. Classification, and I'll come back to the details on these. I want to do image. Then I want to do image classification. Then I want to do image classification again with convolutional layer. So then I want to talk about what that is. Do I want to do some type of regression example? Maybe. Maybe. So classification, and then maybe sort of like as inside, a part of B of like a basic regression. So this is kind of what I want to do in terms of the basic building blocks of machine learning with neural networks. And I want to build all of these with the TensorFlow.js library. So just to lower your expectations for a minute. If I were able to get even just this done today, I would be very happy about that. Okay? So this is kind of my goal. That's my goal for today. Now, I am doing things backwards. In one sense, I'm doing something like that. These are not super beginner-friendly. I mean, they're as beginner-friendly as I can make them. I want them to be friendly. But you know, if this was my first day watching a coding video, I might not want to jump into the image classification with the TensorFlow Layers API video, which doesn't exist yet. But once I get through this, or actually once June 15th hits, or maybe even a little bit before June 15th, that's next week, I'm going to start doing some beginner-friendly, and I'm hopefully going to have guests come and do these with me. Maybe somebody who's watching this right now who's worked on this ML5 project would like to come. Beginner-friendly ML with some hearts and some stars, like a little rainbow. And then there's a train going by. I can't draw a train. Oh yeah. Da da da da da da da da da da da da da da da da da da. Yeah, okay. And with a library called ml5.js. So I'm going to come back to this in a second. So just briefly, let me just show you. Uke.js, that's a great idea for a... So if you go right now on the internet to a URL, ml5js.org, you will find this website. This is going to be fun. Let's do something fun here. So what you'll see right here on the homepage is this interactive demonstration. This is a picture of a robin, which the MobileNet model labeled this as a robin, American robin, Turtis migratorious, with a confidence of 98.77%. So now I'm going to upload an image. Do I have any images here? This is, hold on. Let's go get a rainbow. Images. This looks good. Download. Oh, I should have done a train. Let's try rainbow.jpg. Where am I going? Desktop, that looks good. Let's go for a train. This one looks good. Oh, save images. Train. Train. Let's go back to the ml5 webpage, and what I'm going to do, I could drag and drop it, but I'm just going to do this. Let's try, whoops. Let's try the, a train. Trailer truck, tractor trailer, trucking rig, rig articulated lorry, semi with a confidence of 42.94%. Let's try doing the dragging and dropping thing with the rainbow. Bring it over here, and now we have a parachute shoot with a confidence of 49.29%. So, how does this work? Well, I will show you if you scroll down here, you will see here is the code for such a thing. And so, the ml5 library is a machine learning library built on top of TensorFlow.js. This library would not at all be possible without TensorFlow.js running behind the scenes to try to create some simple code examples to work with, at the moment, mostly pre-trained models in the browser. And there's lots more coming here, and I'm going to do a bunch of tutorials with this. But this project is, I'm mentioning it now because Hannah Davis at the I-O Festival, totally not in the Slack channel here, at the I-O Festival, talked about ml5 in her presentation. Hopefully, the I-O Festival, just finished up in Minneapolis. The videos, all the talks there are amazing. Go find their Vimeo channel. And all the ones from last year you can watch, and then the ones from this year will be out soon. And we're looking at trying to launch this more officially on June 15th. And I will mention that if you're interested in kind of poking around, if you go to all of our GitHub repos, first, let me just go over here. We can see here's all sorts of wonderful people who have been working on this project, more than just these 10 people, but here are 10 people. And what I want to show you here is under projects, this is my first foray into using the project management tool that's part of GitHub. Did you know that Microsoft bought GitHub? Some people think that's a problem. Some people think it's great. I don't know. I'm going to just keep using it for a little while longer until somebody tells me not to. Okay, so, but this project management tool is the first time I've used it. If anyone wants to jump on in and get involved and kind of have a little sprint here from now until June 15th, there's a lot, if you look at that website, there's a lot of stuff that's missing. There's a lot of stuff that's broken. And so, you know, reach out to me on Twitter, at Schiffman. Type in a comment somewhere on GitHub if you want to get involved and help us kind of push forward some of this code stuff for the release. And okay, so that's what I wanted to mention there. Do, do, do, do, looking in the chat, looking in the chat, looking in the chat. Okay, so now, ah, coming back over here. So this is what's coming. This is what I hope to eventually have on this YouTube channel is a playlist which is machine learning for beginners in the browser. I don't know what to call it exactly. And I'm going to be using ml5 and p5.js for that together. By the way, the five in ml5 is an homage to p5 and processing because the ml5 library aspires to be kind of friendly and accessible in the same ways that processing and p5 have been over the years. And there we go. My camera's still shut off. Now, back to today. It's one o'clock already. So what, now, I have a pretty clear picture of what I want to do with my image classification examples that I'm going to build. I want to use the Quick Draw dataset. So one of my goals with making my machine learning tutorials is to use non-traditional datasets. And maybe non-traditional is the wrong word, but datasets that are outside of what you would typically find in machine learning and data science curriculum. I want them, I want to use different ones that are kind of in the creative space to get people thinking more creatively about what kinds of data they encounter in their life that they could maybe use. I want to use datasets that are really simple and kind of like easy to understand and look at. And I also want to use datasets that are representative of the world that we live in and all of the cultures and people that we share this great earth with. So, you know, things like, I'm trying to avoid things like MNIST, which is the sort of classic handwritten digits dataset, things like the Iris dataset, which is wonderful and I love flowers. Nothing could possibly be wrong with a flowers dataset, but things that you wouldn't, that kind of made me feel a bit more approachable. So I really, I asked this question a bunch of places a bunch of times, I don't get any responses because I don't, I mean it's hard to find these kind of datasets. I feel like the Google Quick Draw dataset is a great one for learning about image classification. And then what I'm thinking of doing, an XOR is like, it's not really a dataset, it's just made up. Oh, I have something else I want to add in here. Okay, hold on, hold on. And then classification, what I'm, right now the only thing, so TensorFlow.js, there's a node version of TensorFlow.js that used this MLB, Major League Baseball dataset to classify pitches and I love that. First of all, I'm kind of a little bit of a baseball nerd. You know, anywhere, so that's kind of interests me, but I don't know that baseball is perfect for what I want to do that's going to be, you know, a lot of people don't know about baseball or are interested in baseball, it's maybe not reaching the more general audience that I'm imagining for this channel. So, but something like that that's really simple. So all I can think of right now, because I, from Jabril, go check out S-E-F-D Science, S-E-F-D Science, I can never say his channel name. It's probably like, there's like a really easy way to say that channel name and I just can't do it, I don't know why, I'm almost falling over for no reason. I was talking about something. Ah, datasets. Jabril's had this demonstration of a color predictor. One of my students actually, this semester, created a variation on that, which was kind of predicting more about a color than just A or B, and so I was thinking of kind of using that as an inspiration. And so like, what if I made a color classifier that classified colors into like, bluish, grayish, or aqua, like the sea, I don't know, some kind of set of arbitrary labels, like five to 10 labels that, but I need to, so maybe I would crowdsource that dataset, I'm not sure yet. So that's what I'm thinking about for classification. I kind of had hoped to do that today, but I talk too much, and there's limited time. But that's coming next week. Another thing I forgot in here. I wanted to make, like, make your own TF Playground. So just briefly, one last thing that I'll mention here on this to-do list. If you go to, I believe it's playground.tensorflow.js. Is that? Well, hold on. J, whatever, TensorFlow Playground. This is a project from the Big Picture group, the research group from Google that created, where TensorFlow.js itself came out of. And you can kind of create this little playground in the browser where you can configure a neural network, you can have this kind of 2D dataset, you can actually, there's like a play button, so you can run it, and you can watch it try to either classify, and there it goes, sort of classify, or I don't know whether it's doing classification or regression. It looks like classification to me, they're sort of blue and orange. So I have no interest in building out something that has this level of sophistication in design, visual design, but I would like to show you, well, could you, similarly to how I made the linear regression, the polynomial regression examples, maybe I'll just do like a basic 2D classification problem with drawing stuff. Okay, so. That's my introductory talk. I love this. Go, you little neurons, send that data, whoosh. Whoosh. All right. Oh, oh, I can break it. I'm very good at breaking things. All right, so that's where I am. So I think when all is said and done, I think right now I'm just going to tackle today, from now until about 2.30, which is an hour and a half, XOR, and I really am torn, like I don't want to do it, because it's sort of, but it's good for me, so I'm going to do it. All right, but before I do that, let me see if I can get some questions and get myself organized. Anybody have any questions about ML5, TensorFlow.js? Life, the universe. How to play the ukulele. All right, so what do I need to do here? There's a couple things that I need. Number one is... Where is websites? Just looking at the... If anyone who is a sponsor, a patron, there's an interesting question in the YouTube chat that I might like to answer. You can paste it into the Slack channel. This is not right. Where am I? Nope, nope, nope. Oh. Poodly, poppidly, dooby dooby, wah. There we go. All right. All right, there's two bits of code that I need to get started with this. One... Is the actual previous XOR. Oh, you gotta be kidding me. No, here. Here we go, coding challenge 92. And then I also want... To get under, maybe it's under courses, intelligence and learning session. Wait. No, how come it's not there? Is this a different... Oh, past, I'm in a different place. Tsk. I have this in too many places. Courses, intelligence and learning session six. The layers API, I need that. And then p5 TensorFlow. Let's put these in there. And I don't need these anymore. And let's go over here. I don't know which would be better to start from. Let's start from this. This will be coding challenge what? What coding challenge number? Isn't this the third time we do XOR? Is it really? Oh, you're really torturing me because I really feel like I have a thing. I have a little bit of a thing. It's kind of a little... If I'm listening to podcasts, I have to listen to all of it every minute. I can't not listen to one episode. So somehow in my stuff, I just have to do the XOR now with TensorFlow.js because I have to, but maybe I should skip it. What coding challenge number am I on? Did somebody tell me? No. But I can find that out by going here. 105 was polynomial regression. So this would be 106. Okay, totally didn't do this right. Hey, how come there we go? Now, do I have the atom editor open? No. See, here's the thing. What's interesting about doing this YouTube channel is if I were teaching a course, like I do, supposedly, at NYU, I just would not, I would just skip a lot of stuff because there's limited amounts of time. And I do, to some extent, do that here, but I have this false, it's like this false sense of infinite time and I must do every single step which I need to move away from. Um. Kweekbunt writes, it's a good example, comma, but, dot, dot, dot, and I get it. I get it, but I'm waiting for what's coming next. I think I could fill it in, but. But. But I think it's, ah. Well, that's what I'm doing today. Unless. I mean, I'm going to do that, no, no, no. Okay, that's what I'm doing. All right, all right, all right. So let's see. Here we are, this is my list. Um. Ah, pfft, thank you, thank you. Xor Shiffman. See, I think I only actually made one, even though it's like probably the third or fourth time I'm doing it on this channel, I do only have one video, it appears. Yeah. Look, here's Simon talking about Xor. Some other videos, okay. All right. And now, did I run a server, yes. Let me open up the browser. I would love to do like some kind of little just fun algorithmic thing, the equivalent of like phylotaxis today before I go if there's time, but I doubt there is. Okay. All right. Yeah, see, Guy writes, I miss the non-machine learning coding challenges. Totally agree. Yeah, I don't know. Burger Bob asks, could you please read the chat more often? I totally get the sentiment, I appreciate the question. I can certainly try. It is very hard to follow the chat and do the live stream at the same time. And maybe someday I'll have a better system for doing that. I have some ideas for how to do that, but I need time to get some more screens and maybe have some help with that and that sort of thing. All right. Ada, she writes, did he say filing taxes? Yes. And now, coding challenge number 327. Filing your taxes. Let's go see. IRS tax filing API. Hmm. Ooh. IRS Gov eFileProvider Software Developer. Ooh. Ooh. Ooh. Ooh. Ooh. Ooh. Okay, I guess XOR isn't so bad. Filotaxis. The spiral, beautiful Fibonacci spiral pattern of a sunflower. That's what I was saying. All right, see what happens. Burger Bob, that's exactly, Burger Bob, I was worried about a giant screen which shows the chat behind the camera. That is exactly what I would like. And I will snap my fingers and giant screen will be mounted there behind the camera. Somehow that didn't happen. I'm not sure why. So, I do like that suggestion. Whoops. Whoops, yes, Chris writes, it might be worth having a mod pull interesting questions out of both chats and give them to Dan at Q&A breaks. I'm absolutely game for trying that and wants to sort of volunteer. At this point, I think I would need a volunteer to help facilitate that. That would be great. All right, let's... Let's see. Let me get over all of my anxiety and hangups about doing XOR again and talk about them when I start. And then... And then... And then... And then I will begin. I see all these people typing, and Ada, and Kweekman, and Eric, but I got to move on. I think I got to start. Because time is a wasting. Yes, thank you. Okay, Eric in the chat writes, sometimes it's important when learning something new to base your exploration around an example which is fairly trivial and you understand intimately well. True or were better, I could not have put it better myself. Thank you. I'm going to read that sentence at the beginning of this coding challenge, if you don't mind. Hello, welcome to a coding challenge. Now, I know what you're thinking. I mean, I don't know what you're thinking, but I know what I'm thinking. That looks like coding challenge number 92, XOR, which is probably one of the less interesting, creative, like, sort of just technical coding challenge demonstrations that you've done. Why, why, why are you doing it again? Well, Eric from the Coding Train community writes, nice explanation, because I was, just before I started this, having a real hangup about this. Sometimes it's important when learning something new to base your exploration around an example which is fairly trivial and you understand intimately well. So, here's the thing. I am learning something new. Oh, come back here. And the thing that I am learning something new is this TensorFlow.js thing. And wouldn't it be fun to make, like, play Pac-Man with it, or the Emoji Scavenger Hunt project, or Teachable Machine, or play a piano with it, all these things. Oh, PoseNet, oh my god, we got it, we got it. I want to get to that. And I could just sort of go there right now. I will get there eventually. But I'm trying to learn the basics of how the library works. And I'm trying to step through this slowly. So, I will say that if you're watching this video right now, where you are is not necessarily in the most beginner-friendly place because I'm working with TensorFlow.js natively to implement basically, like, a weird math problem. It's not that weird of a problem, actually, but a very basic, trivial math problem just to see how TensorFlow.js works. That's what I'm trying to do in this coding challenge. And in about 20 or 30 minutes, I'll be coding. This coding challenge is, just look, it's probably like four hours and 72 minutes long, which is why I say 72 minutes because that's five hours and 12 minutes, but I don't know what's going on. But the trajectory that I'm on is I'm going to start doing some stuff, inching my way towards, oh, let's actually use some data. Let's use some more data, maybe some images. And so, I've got a bunch of things that I'm stepping through and I'm trying to get to the point where I'm going to use this other machine learning library called ml5, which at the time of this recording hasn't really officially been released yet, but builds on top of TensorFlow.js. Thank you, everyone who made TensorFlow.js, wherever you are, to try to create some more accessible interfaces to some of the algorithms and models, things that you can do with TensorFlow.js without having to do the lower-level memory management and math operation stuff. All of that is coming, and I just took a lot of time in this coding challenge to say that to you. But as much as I kind of don't, I'm not so sure, but what I'm going to do, so y is x source. So here's the thing. This is y. I need an example. This is the first time I'm going to ever, in any of my videos except for the other one that I made, but this is the first time that I'm actually going to use the tf.layers API to train a model with a dataset to produce a certain output. I did two tutorials about what the tf.layers API is. You can pause now and go and watch those and then come back here, but in those videos, I didn't actually do anything with tf.layers. I just sort of talked through and typed out some code. So the problem that I want to solve, and apologies for explaining this probably for like the 15th time on this YouTube channel, is very well known from machine learning, XOR, because when the original perceptron was invented, the single perceptron, the model of an individual neuron that could receive inputs and generate an output, it could not solve XOR. It just couldn't. It's not a linearly separable problem, and I've talked about that in other videos about why we need multilayer perceptrons. So the nice thing about XOR is I can diagram for you. Hold on a sec. Ha. I'm back. I can diagram for you the architecture of the model that we need to create. There are two inputs. There is one output. So the inputs to the XOR problem are true and false values. So if I made a little truth table, and, or, XOR, right? I could have true true, true false, false true, false false. An and operation would only ever give me true when both are true, false, false, false. An or operation would only ever give me, would give me true if just one of them is true. True, true, true, false. Can you even see that? I can't see on my monitor, but hopefully you can. Now, XOR, the X for exclusive, gives me true only if one is true. They can't both be true, only one. So in that case, I get false, true, true, false. And the idea of linearly separable comes up here because I can draw a line here to separate true from false. I can draw a line here to separate true from false. But here, I can't draw a line, I could do this. But I can't draw a single line to separate true from false. We need a more sophisticated model with a hidden layer. So the inputs are things like a one and a zero. Feed forward into the hidden layer, activate, feed to the output, and the output should be a zero or a one. It's really, in some ways, a classification problem, but I'm going to do this as a regression, essentially, where I'm just going to get some number between zero and one. If you watched the previous coding challenge, the reason why that is is because... Oh, thank you very much, good night. This video is now over. I hit my sound effect by accident. Because what I'm trying to do is visualize the true-false space. All right, pause for a second. I'm just taking a pause for a second. How long was that? It was like 10 minutes at least, right? But it's important. It's important for me to talk about what I'm doing. All right. So I'm just thinking here, where am I going next? Looking at the chat, no one's complaining too terribly. And I think I'm going to move on. I guess I could transition back over here, in case Matu, you want to edit out the weird sound effect thing. Oh, they're good sounding, okay, that's good. Hugo asks, will you ever do non-JavaScript videos? Well, I do some processing in Java videos. Those aren't JavaScript. But at this point, I'm kind of doing the JavaScript thing. Okay, let me transition back, Matu. Maybe the sound effect little thing was a funny little bit. But I think I'm going to just transition back. Because ultimately what I'm going to do is visualize the output of the model. And I'm going to send in numbers all the way between zero and one. I don't even know what I'm saying. It's fine. Because ultimately I'm going to visualize the output as grayscale values. And I want to see grayscale values all the way between zero and one. It's the same thing I did in the previous coding challenge, if you happen to have watched that one. All right, so now I actually, I'm going to also do something where I start from the code, from the previous coding challenge. And so we can see there's this idea of training data. The inputs to the XOR problem are zero, zero gives me a zero. Zero, one gives me a one. One, zero gives me a one. And one, one gives me a zero. This is the training data. And in my previous version of this, I used my own neural network library. So in theory, I'm going to get rid of the idea of a learning rate slider, just for, we can add that back in later. But let me get rid of the learning rate slider. Basically, I want to do exactly the same thing. The difference is I'm going to say neural network equals tf.layers.sequential. And maybe I'll call this the model instead of neural network. So the idea, oh, this is neural network here. So the idea here is that I want to replace my neural network library with TensorFlow.js. And so this, for me, what the usefulness of this video is of me learning, I spent all this time trying to build my own rather sort of terrible neural network JavaScript library. And going through that was sort of helpful in thinking about how the stuff works. Now if I can translate that into TensorFlow.js, things are going to hopefully start to sell and make more sense into my brain. Bruno is asking something in the chat about the true false table. Yeah, usually you draw it as a, I might come back to this later. Usually you draw it as a matrix. And I sort of did something weird there. But I think it's fine. I'm sorry, I'm looking at, see, this is what happens when I look at the chat too much. All right. Okay. All right. Okay, so now we need to, what this constructor here said, and let's just put this back to this. This constructor here said, make a neural network with two inputs, two hidden nodes, and one output. So I need to duplicate that idea here with tf.layers. So let's go to the TensorFlow.js API reference. And we're going to go all, scroll down to tf.layers. And what I want to make is a dense layer. tf.layers.dense. A dense layer is a fully connected layer. So what I'm going to do is I am going to say, let hidden equal tf.layers.dense. And then I can put inside there an object that has the parameters of how I want to configure that layer. And so how do I want to configure it? The two things that I really need to do is this is the hidden layer, right? I need to give it an input shape, right? I need to say what's coming in. What's coming in, that's what this is here. I need to say how many nodes it has. That's the number of units. And then it probably has a default one, but I can specify an activation function. And again, I'm just going to use sigmoid as this historical activation function that I've been using in all my videos to date. I'm going to soon talk about softmax, what that is, as well as some other activation functions like rel, which is maybe more commonly used. By the way, nobody pronounces it that way but me, so don't get confused. All right, so I want to say input shape, I believe is just, there's just two inputs. I also want to have two units, two nodes, and activation is going to be sigmoid. So now I have created the hidden layer. Yay! The other layer that I need to create is the output layer. And so what am I going to do with the output layer? I don't need to provide an input shape because the input shape can be inferred if I add them sequentially. The inputs are not a layer, so for this first layer, the hidden layer, I've got to say how many there are. But now once I'm creating this next layer, it can just, the input shape is going to be defined by what was before it. So now I'm going to say, I really have to stop hitting the sound effects by accident. And now I'm going to say let output equal tf.layers.dense. And all I need to say is units one activation sigmoid. Then all I have to do is say model.addHidden, model.addOutput. So this is the model. Now, one thing I need to do is I definitely need to import the TensorFlow.js library, which I happen to have from one of my previous examples. So I'm going, right now I only have, I have the p5 libraries in my index.html plus my crazy neural network thing and my actual code in Sketch.js. Someday maybe I'll use the fancy new import syntax stuff. Let me just have everything kind of line up. Let me add this in here. So now tf.js should be there. I should be able to go back and run this and not see any errors, aha! Tf.layers.sequential is not a function. Sorry, I'm seeing things in the chat. Chat's really off the rails with this XOR thing. All right, so I probably just didn't name tf.layers.sequential the right thing. I could go look, by the way, I made an example. Oh, it's just tf.sequential. Okay, so all I want to say is I just got that wrong. It's tf.sequential. So I could go, hopefully I would find this here, tf.sequential, yeah, models creation. There it is, tf.sequential. So I just had that wrong. Okay, let's try refreshing this yet again. Slider is not defined. Hold on. Sorry, Matzia. I have to turn the notifications off on my watch. I'm getting phone calls and buzzing things. Take a minute here. Somebody said that I'm good at drinking drinks in profile, that I could be like a coding train brought to you, I'm Buzz marketing clean canteen. Not an official sponsor. Okay. Where was I? Right. All right, let me fix this learning rate issue, 0.1. I just want the thing to run. Okay, so it's going, it's still working with my neural network library, not the new TensorFlow.js one. But let's keep stepping through. So, ah, so what am I missing here? So when I make a model, this is, now I've architected the model. I've architected this particular architecture, but I need to do another step. I need to compile the model, and I need to define the loss function and the optimizer. Basically, I need to say like, okay, well, this is how I'm going to determine how well the model is currently performing with the training data and testing data potentially. But I'm not getting, testing data will come in my next video about classification. But here, I'm not making a distinction between training and testing data. I'm conflating those two concepts, which is a big mistake and a problem, but we're stepping through this stuff little by little, little by little, like a butterfly flapping its wings. It's not at all like a butterfly, but I felt like I was being like a butterfly. And then an optimizer is what sort of function, what sort of algorithm am I using to adjust all of the weights of all these connections according to the loss function itself. So I need to define those things. I forgot how. I know it's in the thing I made last week, but this stuff just isn't. So let me try to type it out how I think it is, and then we'll go check. So I know I need to create an optimizer. TF optimizer, like this, and with a learning rate. Something like this. Like I want to have, use stochastic gradient descent with some learning rate. That's not correct. This is me like trying to remember what the code is. And then I need to say like model.compile. And then I think when I compile it, I'll say things like this, I'm going to compile it with this optimizer and this loss function like root mean squared or something like that. So this is what I'm remembering from when I looked at this at one time, and I probably got this wrong. So let's actually go look at the API docs. Well, first, what's the chance that any of this actually makes sense? Okay, TF optimizer is not a function. So let's see, how do we create the optimizer? Optimizer. Ah, yes. So this is what I want. I want a tf.train.sgd. This is how I create the other. Optimizer is not a key word in the API. I just, I imagined that for myself. So I need to say tf.train.sgd and then give it a learning rate. So tf.train.sgd. And there are other kinds of optimizers that I think I've even shown you and we'll use more and give it a learning rate like 0.1. Then I want to look at model.compile. So let's look for compile. Well, we can see in some examples here. What I'm looking for is where the actual compile, there it is, compile. So the compile function compiles it and give an optimizer a loss. And I can also do some metric stuff. I'm not going to worry about the metrics too much, although maybe I'll try to come back towards the end of this video. Okay, model.compile, optimizer, loss. I think this might actually be fine. Is it root mean squared? So let's look for the loss functions. Loss, root mean, mean squared. Oh, why did I, I keep saying root. I'm on the floor lying down. Is that so sad? I said root because I have it in my head from something that I did a very long time ago where I was always taking the square root of the mean squared error. So I always say root mean squared. There's no root here involved. I guess I have to get back up and continue this tutorial. How long was I saying root for? How annoying will that be for the people who watch this later? Okay, whoop, don't, you know, I have to get up slowly or else I get kind of lightheaded. All right, apologies. I've been saying root mean squared error because I'm stuck in this world where you have to take the square root which you don't need to do here. So just mean squared error, that's all I need. This is my loss function, mean squared error. Now, let us now go back here, hit refresh. All right, things are happening, things are going. So the model is built. The model is compiled and the next thing that I am ready to do is now actually start putting data in the model. Time out for a second, why did I lose? All right, just give me a second here. I really have to watch the time. I've got an hour. I have to be at Little League practice. I am not a strange 44 year old person who plays in Little League but my son is playing Little League for the first time this year. I have to be at the practice, cannot be late. So I have another hour though, okay. I'm not the coach, don't worry. I'm just, stand by the side, you cheer. Do my little, hold my little signs, that's it. I don't have any signs, should have signs. I was actually thinking of sponsoring a Little League team like the Coding Train sponsored Little League team but I didn't get it together this year, maybe next year. All right. All right. There are two next steps. Oops. Oh, why is this completely died? I just, I know that I'm saying 44 a lot because it's about to be 45 so I feel like I might as well say 44. I like number 44 much better than number 45 for a variety of reasons I will not get into right now. If anyone can figure out what I'm talking about. All right, it's pretty obvious probably. All right so, the two things that we need to do now. What are the two main steps? I don't know why I came over here but since I'm over here. So first of all, I drew this truth table thing a little bit weirdly and so you might recall, just to be clear about what's going on, this is my little drawing of the canvas right now and the idea of the canvas is that I want to see what the neural network thinks false false is at zero zero. I want to see what it thinks true false is at this right hand, top right hand side. The bottom left hand side I want to see it zero one and then I want to see here one one. So false is black for zero and true is white for one. That's the way I'm going to map the color. So I should see some kind of bands of like, I should be getting something like this. So darker here and like this. So let's go look, does that match? Yeah, that's exactly what I'm seeing here. So, the reason why I came over here is what I need, what I think, there's two things that I need to do. Number one is I need to train the model to produce this output, my desired output that I think it should do and then I also need to ask the model to predict so I can draw what it thinks its output is. So the two, and so the two steps here, I'm running out of space, but in the TensorFlow.js library, I need to look at the predict function and the fit function. Predict for just saying here's the inputs, what is your output? The fit function for saying here's labeled inputs, inputs with known outputs, adjust, optimize yourself according to that. So I'm going to do things backwards. I'm going to do just the predict step first. I just want to see when it starts up with no training, what visual output do we get? So coming back to the code, let's look here. So this, this is what I need to replace. I need to say, now I need to say, let, whoops, y equal model.predict. Model.predict, now let's go look at the documentation. I need to send in the inputs. So let's go back to the documentation, model.predict. I need a better way of browsing this documentation. Here it is. So I need to, sorry, model.predict, I need to give it the x's. What are the x's? This are the x's, but remember, I'm using tensorflow.js now. Tensorflow.js, oy, oy, oy, vague vault. I have to make them a tensor, I can't use regular arrays. So I could say, let x's equal tensor one d, oh no, sorry, I got confused. tf.tensor one d inputs, and then model x's. Now here's the thing, so this is the, there's many problems what I've done so far, okay? Many problems, which I will solve slowly, this could be a very long video, I apologize in advance. You can take a break now, pause, take a break, go do something else, come back. So what's problem number one? Problem number one is predict happens asynchronously. Oh boy, pause for a second here. How did I do this in, so I made an example, I just need to think about this for a second. Wait, my glasses are steaming up, why is it getting all warm in here? Hold on, oh and Eric, thank you for that pull request. I probably should merge that and then look at, because he probably fixed a bunch of things, I just want to see something. Can we do this as a batch? Oh, no, predict happens synchronously. It's fit that's asynchronous, oh good, that's why I'm doing this. Right? Predict happens, can happen synchronously. Let me look at, actually I should show you what I'm looking at. I know why I'm looking at it on this other computer. Oops, I'm just looking up some stuff for how this stuff works. Okay. Oh wait, wait, wait, wait, wait, wait, wait, wait. No, hold on, hold on, let me show you what I'm looking at. Because I don't know why I'm looking at this. So I have a repo called 145, it's not called 145, that's the time. TensorFlow.js examples, xor sketch, right? So I know I have to do it as a batch. Neural network predicts. Oh, or did I do it, and so I was putting it in a class, which I'm not going to do here. Tidy return, oh, I, no, predict happens synchronously, but then pulling the data off happens asynchronously, but I can use data sync even though I probably should be using tf.nextframe. I don't know how to use that yet. So I will deal with that later. Okay, sorry. Okay. Okay. Okay, here I am back. All right, sorry. I'm gonna just back up a bit. Mathieu, you can splice things however you feel so inclined. Whoops. Okay. So I need to, now I need to ask the TensorFlow layer, sequential model thingy to give me the why. Neural model.predict, but what does it expect? Its predict function, unlike my predict function, cannot get a regular array, it expects a tensor. So I need to make the x's into tf.tensor1d with those inputs and pass those through predict. Now here's the thing. There's a lot of issues with this that I need to resolve, and this is gonna run really slow, and I need to actually do this as a batch process. I'm gonna get to all that, but just looking at what I've got so far, model.predict, there's a question of like, is this happening synchronously or asynchronously? This actually is happening synchronously, but the problem is I need to say fill with the result, like I need to get that number out, and to get the number out, I actually wanna call.data, and that happens asynchronously. So because I'm working with such teeny bits of data right now, I think I'm gonna use data sync, and there could be issues with that, and as I move more forward, we're gonna see when I really need to be more thoughtful about callbacks and promises, but I'm gonna use data sync right now. So I should be able to predict the output with this input, get that data, and then, let me just say console.log y, and I'm gonna make the resolution here of the, oh yeah, the resolution really big, like 50, because I just wanna look at very, very little data to start with, and let's look, I'm not gonna draw anything, let's just look and see what's coming out. What's coming out here, y, and then let me just say no loop. So let's look in the console and see if we get anything. Error. Expected when checking dense one input to have two dimensions, but it got array with shape two. Oh, once again, I have the same problem I've had every single time I've done this with TensorFlow.js. So the good news is, I don't want to just give this 1D tensor. Even though my data is just two values, zero, one, one, zero, one, one, and it's a one-dimensional array with two numbers in it, I actually wanna be able to do something like, hey, take these 15 data points and give me the results, the predictions for all 15 of those. And so what I really wanna be doing is I always need to send in kind of like one order higher, one degree, one rank higher. So this actually, I'm just sending in one piece of data in point, in point input. Brain stopped working in the middle of this video. That's 17 hours long. Ah, and this now, I also have to say tensor 2D now because it's a 2D tensor. There we go. Ah, so we can see, look at this. The results came out for all those little spots. You can see little numbers between zero and one in an array. So now I can, instead of console logging y, and I just want that, it comes back in an array, but there's only one number I care about. I can put this back in here. I can take out no loop, and I can run it. We can see, look, there is my current visualization of XOR. I'm not really done. I have so much left to do in this video that is, been recording for the last three or four days. All right, one thing I want to do is I just want to say stroke 255. So I just want to sort of see a little bit more. Okay, that's actually what I'm looking at here. I actually want to make the resolution, for debugging wise, I also want to make the resolution a little bit bigger. So let's see. Now, one thing I'm curious about, let's look at the frame rate here. That's running at 30 frames per second, so that's fine. Let me now actually make the resolution much, much higher, like this. Oh my goodness. Oh, it's not even getting to the first frame. Oh, boom, oh, oh, oh, there we go. Look at the frame rate. Oh, it can't even give me a frame rate. It's so stuck. It can't even get one frame per second. So here's the thing. I have done something very, very, very bad. Ha, ha, ha. And I need it to stop. No loop, stop. You don't have to do any more work. And let's put the resolution back at 100, and let's think about this. What's going on here? Look at this. Look at this predict function, and look at this data sync function. What am I doing? I am calling that function multiple times, every single, for every single spot on that grid. When I'm working with something like TensorFlow.js, whenever I create a tensor or feed data into a model, the data has to go from my code onto the GPU. And then when it's done, that data sync is pulling it off of the GPU so I can use it again in my code, that graphics processing unit where all the math is happening behind the scenes. I want to do that as few times as possible. Look how this is, I'm creating this two-dimensional array with one thing in it, you know, 100 times. I could just create one array with 100 things in it and call predict once. That's what I want to do. So what I need is for this nested loop to happen twice. Once to set up the data, and another to draw all the results. So I'm going to copy paste this, just put it right below. So this, now what we need to do is create the input data. So I'm going to say let inputs be a blank array. Then I'm going to say inputs.push. And I'm going to just push in x1, x2. So I'm going to put every single x1, x2 all the way along. I don't want to create the tensor or do this here. I don't want to do the drawing stuff here. I just want to create, I just want to have a loop that creates all the data. Now, I can get the x's is all of those inputs into a 2D tensor and the y's, this is now the y's, is, and now here's the thing, I don't just, let's so, hold on, I got to look at what that's going to look like. Let's comment this out for a second. Let's look at the y's and see what that looks like. Oh, okay, sketch.78 error. Oh, no let there, just inputs.push. Okay, oh, I want to say no loop. Let me leave that no loop in, put it back. I just want to look at it once. So you can see, what did I get? I got a big array of 16 numbers. I got all the results. So now what I want to do is, back here, now I just need to do the drawing. And I don't need the input data, I don't need the model, all I need to do is draw and I need to say fill, y's, index, what? I plus j times the number of columns maybe? Right, because this is a one dimensional array to describe each spot in that grid. I could do something like, maybe I'll just do this, let index equal zero, and I'm going to say fill based on this particular one. And I don't need this even, sorry. And I just need to say then index plus plus. So what are the steps here? Create the data, get the predictions, draw the results, okay? There we go. So now we can see this is working. I mean, it's not doing anything, but now let's check this frame rate question. We don't need to console log the y's. I'm going to get rid of the no loop. Let's refresh this. Let's look at the frame rate. 30 frames per second. Let's pump it up a little. Let's pump you up a little. And where was the resolution there? Let's make this 20. Don't want to go crazy. And look at the frame rate. There we go, 30 frames per second, no problem, because I'm only one time through draw trying to copy data onto the GPU and get it. I'm only calling predict once. And we can, just to check, we can go to 10. And we can look at the frame rate. And you can see it's like kind of running a little bit slow, but this is because I'm not being too thoughtful about the asynchronous nature of this stuff. I could do other things to optimize it, but I'm just going to ignore that and leave it at, let me make it 25. Hey, time out for a sec. This should definitely be multiple parts. Oh yeah, create inputs at the start, they are constant. Oh, that's such a good point. Okay, I'm going to do that right now. That's a very good point. Who said that in the chat? Probably lots of people have. Pre-calculate them, set up error. Bunch of people have. Yeah, okay. Oh, this. All right, all right, everybody's saying that. All right. The chat is giving me some even further optimization, which is why am I bothering to do this in draw? This is something that, these inputs never change. I can just do them once at the beginning, because, and I can ask for them many times in draw. So let's actually fix that. So I'm actually going to, I'm going to take this and say, I'm going to make these global variables. I don't know if you guys can hear the music. It's coming from the room next to me, but it's there. Beh, wah, wah, wah, wah. All right, then, ooh. Oh, but the width and height does not exist until after create canvas. So let me do this. And let me do this. Okay, so now that's there. Now I should be able to take this, the input data, and put this right here in the beginning. And then I'm going to make a variable called xs. And xs, and where did I do that? Here, and then create those xs. So I'm now doing this in setup. And then in draw, the only thing I need to do in draw is run the predict. This is going to make things run a lot faster. Let's make sure it still works. Here we go. Okay, so you notice we get like a different color each time I refresh, because the neural network model, the sequential model, is initializing everything randomly. But now I get to train it. Yes! Now I think we're ready to train it. So here is what I did when I had my previous, my own JavaScript neural network library. I called neural network.train, data.inputs, data.outputs. Sorry, I'm reading the chat. You guys couldn't hear the music? Well. All right, so if only I could remember exactly what I wrote when I made that tf.layers tutorial. But I know that what I need to do here is I need to do something like this. Model.fit some xs and some ys. That's the training, that's the equivalent. And the learning rate is irrelevant. And I don't necessarily need to do it. This is basically what I want to do. Every time through draw, I want to try to fit the model with some training data. So let's first make the training data. This is not exactly right. I need to figure it out and I need to use a weight. I need to think asynchronously. But this is the idea. So if I go back to the top here, this is my training data. Now one thing I definitely need to change is I'm going to keep the xs and ys separate in training. So I'm going to do this is, I'm just going to do this kind of manually because what's the big deal? So let me make the training set. And then one, one. Those are the xs. Now let me look at the ys. And the ys would be zero, one, one, zero. Then I need those to be tensors. So I need to say const tf xs. So I'm trying to think of good naming for this. I kind of want them to be called. Actually, you know what? I'm just going to call it, do I have a global x? Yeah, I have a global xs already. tf xs equals tensor 2d. Oh, tf tensor 2d. You know what I'm going to do? I don't need these. I don't need two separate sets of variables. I'm just going to create it. I'm going to call this, ah, everything is so much more complicated than I make it. So much more simple than I make it. I'm just going to make these tensors directly by saying tf.tensor2d. And then I'll put the parentheses around this. And there, now I made it a tensor. Then I'll say tf.tensor2d. And now I made this a tensor. Okay. Now I've got the training data. And I'm going to get rid of this. This is the old way that I had the training data, which is totally unnecessary. So the training xs and the training ys. You with me? How long have you been watching? If you're still watching, I don't know. Do it, get up and do it, some jumping jacks. Let's see. Now, I need to do model.fit. Now, model.fit happens asynchronously. So let's put it in its own async function called trainModel. Now, if you don't know what it means to write a function that is tagged with the keyword async, this is part of ES8, a very newish version of JavaScript. And I made a bunch of videos about what that is that you can go back and watch. But this is basically a way for me to now say, wait, model.fit. And then let's look at actually, let's look at the fit function. Model.evaluate, compile, predict, fit. So what I need is to give it the xs and the ys. There's batch size I'm not going to worry about. There's epochs I'm not going to worry about, or epics. And so h will give me back the history. So let's just see here. I'm now going to say trainModel.then, h console.log, h.loss, index zero. Let's say no loop again. So basically what I'm doing here is I want to call this function trainModel. And I'm using this idea of promises. It's going to await the model, oh and I need to return. Do I say await return or return await? No. I must say return await. Return await model.fit. So I'm going to return a promise which will have the result of the fit function. And I don't know if this is right. I want to just look, I want to do that. I want to call to trainModel every time in draw. I might need to do this somewhere else just for right now and then see what the loss is. On x73, async function. Async function, I've got to say function. Function, it's an async function, not an async. There we go. Ys is not defined where in trainModel. Oh right, this is, I forgot to call it trainXs and trainYs. So my training data, trainXs and trainYs. Isn't it nice how the word train just appears everywhere when you're doing machine learning? Drink your glass of milk or whatever it is you're having while you're watching this coding train stuff. Cannot read property zero of undefined at trainModel then h. All right. Let's just console log h. I don't know what that is, what I've done. Okay. History, loss, zero. Okay. Oh no, by the way, I didn't give it any testing data. So what's it computing the loss from? History, so this is, I'm going to call this result. Result, history.loss, index zero. All right, there we go. There we go. Now let's let it do that over and over again in draw. Do do do do do do do do do do do do do do do do do do do. All right. So this is a bit of a fail here. Oh. No, if we're returning the promise, that's a good point. There we go. All right. So I let this run a little bit and unfortunately you can see it's getting nowhere. This loss, which I'm not sure exactly how it's calculating that, I'll think about that and come back to it, is not going down anymore. So what could be some problems here? Number one is maybe my learning rate is no good. Not that it's no good, maybe it's too low. So where did I set up that learning rate again? Let me get rid of, by the way, I just want to now delete. I want to make sure I'm not using any of my old neural network code. So I'm deleting all references to that. So this is now purely TensorFlow.js and let me refresh and run this again. And let me look into Sketch.js and find where did I set the learning rate right here. Let's set it to 0.5. And see what we get. It's getting better. I'm going to let this run for a little bit and I'll be back. Let me look at... So one thing I want to do also is I want to write, it looks nice if I write in the numbers actually of what the output is, where it is. You can see that it's actually getting there just very slowly. Just want to see what settings I used in my other example. Try different optimizers and activation functions. Yeah, I'm going to do that in a second. I want to get it to work with this first. I just want to see what settings I used. Um... Um... Um... Oh, did I forget to put shuffle in? It should shuffle it by default. I wonder if I... Ah, you know what? I forgot to put shuffle in. It's actually working. All right, I'm back and you can see the loss is now kind of much lower and you can start to see the visual that I'm expecting, which has a true value in this corner, true value in the top corner, and sort of darker false values in those corners. But it's still kind of performing rather poorly. One thing that I forgot to do is when I call the fit function, there are a set of options that I can pass in for the number of epochs and all sorts of things. But one of the ones that I really want to pass in here is called shuffle. Shuffle takes the training data and it shuffles the order of it each time. Right now I'm training it with the same four data points in the same order every time, which could be a bit of a problem. And, okay, so let me now, let me refresh here and run this again. Okay. Whoops, I can't see the frame rate because. Timeout a sec. Point five, optimizer, oh! Optimizer, yeah, this is all the same. Sigmoid, sigmoid. Data. Train. Did I, am I giving it, oh, you know what I probably did. No, I thought maybe I was giving it more epochs or something. Shuffle for XOR is not a big help, apparently not. I don't think I'm curious I could do. Just out of curiosity. Because if I go to that thing I was showing everybody. Oh. Where, this is. This should be hosted via GitHub Pages. I'm not sure. For loop and epochs will really help, yeah. I just wanted to see, I'm pretty sure, I don't know why this isn't loading. I mean, the other thing is, I probably should create a separate, I mean, there's no such thing as a thread, but I probably should have, I should just run the training, like this async function I should just. Like I don't need to, like I shouldn't be calling this in draw, but I just wanted to start doing that. I was gonna fix that later. What time is it? I have a half an hour. And get through this. Whoops. Why is this not loading? Oh, is it because, oh, it's probably because this is running. I don't know why my example, I wanted to just see the performance of my example. Hold on, I think I need to restart Chrome. Whoops. Why is this not working? Here we go. Yeah, I know I should do, I was gonna do the set interval thing, but I actually wasn't gonna do set interval. I was gonna do set timeout and then have it recursively call itself when it's done. I'm just, I got lost and this is not important. I just thought I could run the thing that I made before just to see how it performed, but I don't know what it's stuck. Is anybody else, anybody else try running this example? Maybe I'll merge Eric's pull request. It's like stuck. Weird. Okay. Okay. Yeah, that's what I wanted to do next frame. So, me, I am, so me, let me come back to that. I didn't wanna do that first, but yeah, but thank you for that. Oh my goodness. I forgot to tidy everything. Oh, well, but yeah, the why's I need to dispose and I also need to tidy this. Oh yeah. Let me at least just go back to where I was. I'm gonna let this go for a little bit. Just wanna, did anybody see what that was? There it is. Where is it? Yeah, look at that. That's a mess. Okay. Okay. All right, so things are still working, but it's still running kind of slow. We can see I'm getting the loss down. Hold on. Let me see. Okay, things are still lose. Okay, this is not working. This can be happening. It's not working. This can be happening. And I can appraiseWhitesail. I'm a referee, I get no red rattle. Okay, things are working. It's kind of getting close to the right result. You can see the loss is going down. I've realized, thanks to the chat, of course, that I forgot something really important. I want to try to make it learn faster, which I will kind of get to, and I want to think about the sort of asynchronous nature of using p5's draw loop and using the model.fit at the same time. But before I do any of that, I just realized I haven't thought about memory management at all. And there's a big problem. If I just take out for a second this, and let me do this here. Take out this console.log, and I run this again, and I look at, say, if I say in the, oops. Yeah, I'm like killing my computer. It can barely run it again, because watch what tf memory num tensors. 3,455, 4,479. I'm just generating tensors. I'm filling up all the memory. Performance on this is going to be a disaster. So let me stop it before it gets too bad, and let's see, where do I need to do some cleanup? So these x's, these training tensors, I never need to clean those up. Those I can keep forever. But in train model, I should probably tf.tidy this whole thing. Let me think about that. Let's first actually, the y's, after I do this, I can just dispose those. So the y's, I definitely need to dispose. Let's at least just do that first, and let's see where that gets, oh. Oh, look at this. Ah, because I used data sync, I could use tf.tidy, but what I'm going to do now is y's, and then I'm going to say let y underscore values equals y's dot data sync. I can't clean it up once it's also been data synced, so now I do the y's dot dispose. Whoops, do I have no loop on? No. And still going up. That's weird. Oh, this has to be y values. Also, I have to change that to y values, so that helped. This video is so long. Now, what I want to do is I need to, ah, let's just do this, tf.tidy. Let's just put the tf.tidy here. So like whatever happens in this function, just tidy it all up. I could put it probably up here. It's the model.fit that I need to tidy, but I'm just going to do this. Let's do this. 540, 900, ooh, I'm still missing something. What tensor is being created over and over again that I didn't tidy? Oh, it's 220. Oh, this is turning into a disaster. Hmm, what did I not tidy? I guess maybe I need to put tidy in here. Like. Hmm. Or I can just say, like this, right? Hold on. Oh. Hmm. I'm so confused. Like this? No. Okay. I'm so confused, hold on. I have to make the arrow function async? Yeah, this is like, I'm like lost here. Let me back up for a second. This is why I wanted to tidy outside of it. Get rid of tf.tidy for a second. What did I have to start? Hmm. Can I just put this here? What am I missing? I can't use promises in a tidy. Oh, right. So I was doing this right. Okay. Hold on a sec. What was wrong with what I had here? What was wrong with this? Okay. Like why is this, this should be fine, right? Which version of? Okay. Well, let me also go back to making the resolution much bigger. Oh. Oh, I had it right before. I just didn't hit save. Ah! Ah! I'm gonna do a back flip, ready? One, two, no, no, no, I'm not doing a back flip. I had it right the whole time. No. Well, that's so weird. When the resolution is higher, I have a memory leak? Hmm. That's weird. What am I missing? Why do I have three in there? That was weird. Okay. I'm going out of my mind here. What is it? What, I have some like weird bug here that I'm not thinking of. Xs? Let's. Let me tf.tidy this whole thing. Hmm. Ah! So why with a different resolution? That's so weird. I feel like that's a bug. Yeah, the slower the resolution, the less early. I sort of feel like there's some bug that's not my code. I can't figure it out, but tidy here kind of fixes it. I don't think that this needs to be, this is just an array, so this doesn't need to be cleaned up. I mean, the garbage collector should, that's not a tensor. But did I make some other tensor in here that I, oh, I guess model.predict, maybe it makes some other tensors behind the scenes. Okay, you know what it is. I'm just being silly here. I think I'm like forgetting that model.predict, just like model.fit does other, okay. Mathieu! I'm going way back in time, way, way back in time. Too long ago! And I'm going to do my memory. Now, when did I make that three? I'm going to do my, I'm going to go all the way back in memory, leak it again and fix it. Yeah, the epochs will definitely help. Ooh, modeling evolution with TensorFlow.js from Siraj Raval. New video out. All right, I just want to get this down a bit and then I'm going to come back. All right. All right, here we go, here we go. I can't look at the chat right now. Chat! All right. All right, so you can see, it's kind of working. I'm back, it's sort of taking a while, but I want to get this to train a little faster. I want to make this, I want to get a little further. First of all, I was reminded by the chat that I'd forgotten something really crucial and important, which is memory management. And I really should stop this from running right now because there's a huge memory leak happening, which I haven't cleaned up any of my tensors at all. Whoops. Don't look at that, hold on. Forgot that it was there. Okay, oh, and this is there. Sorry. Just do this again. Sorry, everybody. One more time! Shoot. Yay, memory leak. Okay. Whistling Really need that ukulele. Ah! Ah! All right. Whoa, look at this. All right, so you know, it actually is working. It got the correct training result. It's a little grayscale-y in a way that I would like to be able to emphasize visually what it's doing, but you can see the loss has gone way down, but it took a while to get there. But I want to add a few things to this and try to fix it up a little bit. Before I do anything, I was reminded by the chat being over here that I haven't thought about memory management at all. So I'm going to say no loop for a second to just sort of turn this off. Then I'm going to say memory num tensors. Oops, no, no, no, wait. tf.memory.numTensor. I don't know, I'm trying to use, ah! I'm going to say numTensors, tf.memory.num. There it is, there it is, I can get it! There it is. 32,205 tensors, that's crazy. So I need to deal with that. I'm just making tensors and letting them leak everywhere. So I can manually run dispose, but I've got kind of an issue where as predict is going to like make a lot of tensors behind the scenes as well as model.fit. So I can use the tf.tidy function. So I'm going to say tf.tidy. And then I just need to, I'm going to use the ES6 arrow notation, which you can watch my videos about what that is, but I've kind of gone through what tidy is. Tidy says anything inside of this code, clean up the memory afterwards, basically. And then I'm going to, I probably could put this around everything, but I just want to, and I don't need this stuff anymore. I just want to keep these two areas separate because I think I'm going to, at some point I really should change the way the fitting of the model, excuse me, in draw is somewhat problematic. So now I'm going to just tidy all of this. I think that's right. Do I have an extra parentheses there? Yes. Okay, so now let's run this again. Let me comment out this console log. I don't want to see that right now. Oh. All right, now let's look at the number of tensors. 15, 15, 15. So now I've gotten rid of the memory leak. Let's check out the frame rate. 30 frames per second. So this is running for all. Now, I just want to be able to look at what's happening a little bit better. So I'm actually going to draw the number of the output inside each one of these things. So let's do that. So where am I drawing the rectangles here? I'm going to say let the brightness value equal this. And I'm going to fill the rectangle with that brightness. And then I'm going to say fill 255, mind it, like the inverse color. I'm going to say text, number format, the y values, index, with just two decimal places. And I'm going to put that at, boy, this is awkward. The x values, this is going to be i times resolution plus resolution divided by two. I'm going to say text align center, text align center, comma, center. And then I'm going to put the, I'm just going to draw in the center of the rectangle. And this should be j, the text. So let's see, let's do this now. So we can see, ooh, look, there's lots of numbers there. I think my number format thing didn't work. One comma two, and let's use a lower resolution just so I can see it better. There we go. Now interestingly, I can't see the numbers, but there they go, right? You can see this is what it's getting, the output for each one of these. And I want to look at the loss. You can see, ah, because it's just going so slow. It's getting a little better. It's getting a little bit better. So over time, it's getting a little better, but I really want to see it train much faster. So let me see, I have one idea, one last thing I can add to this, even though I, and I have some suggestions for what you might do next. But you can see, ah, the numbers are starting to appear. Lovely. Because I forgot when it's gray, when it's at.5, 255 minus.5, it's going to be the same color, but I kind of like that effect. So what I want to do is what happens here if I actually give it, tell it, don't just do it once. Like do it 10 times, do 10 epochs per cycle of fitting. Let me run this again. And let me look at the, let's actually have the loss continue to print out. And there we go. Still running pretty fast. You can see the loss is going down and relatively quickly I am getting myself to the point where I'm starting to see, this is definitely all the way, getting all the way down to zero there. This is getting way up to one there. It's getting a little bit stuck. It's having trouble with this side. I imagine it'll get there eventually. We could do some fun stuff. For example, I'm going to just let it have, it's totally unnecessary, but I'm going to give it four hidden nodes and I'm also going to put the resolution back to 25. And let's run this again. And let's see how this goes. So I'll give it a minute, I'll come back. Oh, the font is too big. But you can see it's learning pretty quickly right now. Hold on. Well, let me go back, do that again. So I'm going to give it, for no real reason at all, but just for fun, four hidden nodes. And I'm also going to, let me change the resolution to 25. Let me make the text size something like eight point. And let me, whoops. Refresh it. Oh, I'm sorry. Why did it, um. Yeah, I want to. All right, I let this run for a bit and you can kind of see here. Now you can see all the XOR values. Here's a nice, beautiful little map, grayscale map of all XOR. It's getting all the way up to true and all the way down to zero at the corners. This is pretty good. So, and this is running at, if I take out this console log, I can now take a look at the frame rate. It's running kind of slow. So here's the thing. I have done something that I don't like, which is this train model is being called inside draw. And I really shouldn't be doing that because I don't want, I don't want to call train model over, I can call train model. Let me think about what I'm saying here. Yeah. I have to, how did I finish this up? I have to go in just like a minute. I'm trying to think of what I want to finish up here. So I don't think I have time to do the TF frame thing, but should I do, would it make sense for me to at least do something like set time out train model. Let me just say, hey, do that. And then, like, what if I did this function train, set time out train model. I want to do like a then, but, well, or what if I just did this? Like something like this. Right. This is what I'm thinking. And then, this would, right. Does this make sense? So I'm going to explain this in a second. Like this would basically be happening elsewhere. But I think I need the set time out to like, yeah, this is never going to release anything. Oh, this is like superfluous cause it's just returning a promise. Yeah. All right. I'll do that. Like, like what if I did this? This is weird though. I've killed this completely. Killed the browser. Yeah. Yeah. It's not really that much faster, but this is kind of like what I want to do, right? Yeah. Now I can get a much faster frame rate and I could actually give it more epochs, right? Yeah. The training is happening more slowly, but the frame rate is happening faster. Perhaps it results in a video about workers. Yeah. What tidy does nothing? Look at this crazy way that it learned. Where's the tidy that does nothing? Me, I am, sumi. Right. Is this an improvement over what I had before? Yeah. No, I need this TF tidy. What? Because this has to get tidied. Right? This is what it's doing right now. If I take that out. Oh, you're right. Oh, I don't need a TF tidy for model.fit. Oh, okay. Okay. Is this an improvement? Like to have pulled this out, at least pulled this out of draw. And a way, model.fit is tidied internally. Okay. And tidy doesn't work with promises. Got it. Got it, got it, got it, got it, got it. All right. Is this an improvement or should I just stay where I was and let it be? Like leave it in draw and talk about how that probably should do TF frame instead, web workers, yada, yada, yada. Answer fast. I got to go. Async while loop is definitely a good suggestion. Technically, this is a much better way to do it. All right. Thank you. That's all I needed to know. Okay. Okay. So I'm going to go back to. All right, so the chat has given me some really helpful tips. I've made quite a few little like weird little errors and mistakes here and I want to just fix this up a bit. I think it's actually going to be easier to look at and watch if I just go back to a lower resolution. So let's make this 40 and let me refresh this. Okay, so here we go. So this is now working, training itself for XOR. You can see it's kind of moving along here. Now, what the real thing that's problematic here is the draw loop is happening over and over again and then I'm triggering something asynchronous in draw and I could be asking to train the model before it's even done with the previous training cycle, so this really should not be happening in draw. Now, TensorFlow.js has a function called tf.nextframe. I want you to explore it and make a version of this with tf.nextframe as like an exercise after this video is over, but I'm going to do it a different way without that because I got to come back to that in a different video, but first of all, this I also learned, this is totally unnecessary. The await, a couple things. Number one is that the await function number one is because there's just one thing happening in here, I could just return the promise. This doesn't actually have to be an async function and then I do not need the tf.tidy because model.fit kind of will clean itself up automatically for you, so this should still work just fine and I should be able to see the number of tensors is still 15, so that was something that I didn't need that I've now fixed. Now, what I really want to do is I want to get this out of draw, so let's comment this out here and what I'm actually going to do is I'm going to write a separate function called train and in that function, I'm going to say set time, okay, wait, wait, wait, I'm going to call train model, wait, hold on. I'm going to call train model, yes, yes. In that function, I'm going to do this. I'm going to separate function that does this piece of it, that console logs the history and I could use and what I want to do is I want to say set time out, call the train function in 100 milliseconds, so I want to just let the program start, say 100 milliseconds later, call this train function. Train the model, which does the fitting. When that's done, log the history and now say set time out train 100, so this is sort of like recursion. I don't want to use set interval here because I only want to call train again once it's finished with training the model itself, so this is kind of like, hey, train and by the way, I could just increase the number of epics or maybe do some kind of loop, but I think this would be a sort of nice way to demonstrate it and if I just called train directly without a set timeout, I'm never going to be giving back control for a second, I could end up with blocking, so I might even be able to get this down to 10 milliseconds, just something really, really low, so let's run this and sort of see. Same result, we can see, there we go, things are working, but at least now, I have gotten that out of draw, so draw is happening on its own and in fact, what I could really do is I could say, hey, try doing this with 100 epics each time. Epochs, what is it? And you can see the loss function is coming out much more slowly, but the frame rate, let me just clear this for a second. The frame rate is quite fast, hold on, this is too confusing. I probably need to give it back more time, let's do another little break. Let me, I just want to take out the console log thing so I can look at the frame rate, I should just put the frame rate in the DOM, wouldn't that be smart? But you can see, now I'm getting 30 frames, I'm getting a pretty high frame rate, even though the training is happening, it's almost, it's kind of like a, there is no threading in JavaScript, so these things are just passing off and really, this might be a place where web workers or something could do the training behind the scenes in some fancy way, which maybe I will get to at some point. Oh my goodness! So, Alka is suggesting it might be better to use the draw loop and a Boolean to know when it's safe to call it again, that would also be a good idea. So you can see what kind of, I'm pulling my hair out, what kind of hassle situation we've gotten in. But really, let's just put this back to two epochs, let's put this to little 10 milliseconds, and we can sort of feel like, there we go, and I can look at the frame rate, it's running nice 30 frames per second, and even though, and at some point, it's going to get there, what's that loss? I forgot to console log the loss, come back to me! Come on! Oh, but let's see, I have an idea. What if, just before I go, just before I go, what if we try using a different optimizer? What if we try using, for example, a different loss function? Hold on. This video's already 18 hours long. What if, oh no, no, no, a different optimizer, sorry. What if I tried using the, the atom optimizer? So let's just try that, just for fun times. Let's give it a lower learning rate. Whoa, look at that! Ha ha! Woo! Boom! Yeah! Wow! Oh, stop it! All this time, all this time! That was pretty exciting. Let's go, let's go, let's, let's make the resolution back to like 20. Let me make the font size nice and tiny for us. Let me give myself some more space here. Hit refresh. And then let's look at this. Look at it learning there. Ah, look at that, that is beautiful. Look at it learning XOR so nice and fast. I'm just going to hit refresh again. We can see it. Blah, blah, blah, blah, blah, blah, blah, blah. All right, so we can see, I got, we really should look at what this atom optimizer is. And I will link to a paper and some more information about what the atom optimizer is. You can find out, actually we should just go. Yeah, I'm sorry, I'm like. Ha ha! This one. Hold on. We should really, I should really talk at some point about what some of these other optimizer functions are. For now, what I would suggest that you do is if I, again, if I go back to the API reference and I go all the way down and I find the, oh, let me just look this way. The, if I go here and I go train.atom, we can see here. This is what you're going to want to click on. This is the paper that describes the atom algorithm. It's different, but it's optimizing the loss function in a slightly different way than stochastic gradient descent does. We could also try starting to, we could just never stop and I could start, I think, using the ReLU activation function instead. Whoops, is that not what it's called? Where are the activation functions? Oh, it's, there's no, it's just all lowercase. So there's just so many things you can play around with, these things. That was a failure. I think because I have the, all right, let's, I'm not going to add, I'm going to, hold on, go back. Back to where I was explaining the atom optimizer. Oh, I made this such a mess to edit and I really have to go. I really should explain what these optimizers are, but if I go back and look under here, we can see what some of these are. Atom, the ADA coming from the word adaptive, and you could always click here and look at this paper, which describes this particular method for optimization, which is a little bit different than stochastic gradient descent, and apparently things work a lot faster with this XOR problem. So as I go forward into more of these videos, hopefully we can dig into what some of these different optimizers do and kind of understand why I might pick one over the other in certain situations. All right, but I'm just going to just leave this be. I'm going to hit refresh. I'm going to watch it learn and train. Train, train, train, XOR. I don't know, some things you could do, investigate tf.frame, give me a little slider, try different architectures, different optimizers, try some different activation functions. I don't know. If you actually made it all the way to the end of this video, I don't know, hashtag something. Eric is telling me to watch one of those videos reviewing the JavaScript event loop, which I definitely need to do. So I'm going to be back with more someday. Goodbye, goodbye, goodbye. Thank you. Momentum. Is add and not for adaptive, did I just make that up? Adaptive estimates. So maybe the M is for estimates. Moments, low order moments, M is for moments. I don't know. Yeah, all right everybody. Well, you know, today was one of those days. I should really be doing my old style coding challenges again, read out of the random numbers book, okay. Okay, I really, I'm running late. I gotta go. Everyone lie down, go to sleep. We're gonna, let's. Let's artificially make this happen much slower. Let's train, let's go, okay, ready? 32,985. 26,814. 51,833. 57,363. 4,067. 84,648. 85,505. 41,465. 71,769. 99,550. 55,904. Will there be a second livestream today? No, unfortunately. Will I livestream on the weekend? No, unfortunately. So apologies, I wish I could livestream more often all the time, make more stuff, blah, blah, blah. The next livestream will likely be next Wednesday and next Thursday. And I'm gonna be working on a lot more of this stuff in between. Hopefully we will. The things that I really need to look at are, I need to look at that event loop article that I, just to get a better sense of how to use this stuff together with the request animation frame better and tf.frame. All right, so any last, if my real time that I had to leave was three o'clock, I got two minutes to answer questions. Let's try like. I like doing it with like a high learning rate. You can see like it gets to, you can sort of see it bouncing. Look at this. Look at this, learning rate is too high. It's kind of gets stuck, it kind of can't get there. And then if we could do, we could do weird stuff like, like what if I gave the hidden layer 16 units for like no reason? Like, look how, because there's no correct answer. There's only training data at the corners. What, learned a rainbow. Look, it's a rainbow. XOR learned a rainbow. People are asking me questions. Are you going to do convolutional 2D soon? That's why I hope to, plan to, yes. All right, everybody. So this is my list. Oh, thank you, Joshua Myers. That's very kind of you. If I had my Philips light bulb, it would have flashed. By the way, oh, let me just mention, if any of you are sponsors, you can now sponsor the channel through the YouTube interface itself. Make sure you go and check the community tab and look for a post that links to a Google form to enter your email so I can send you an invitation to the Slack group. I need a better system for doing that. I have a thing set up that it actually like, I have a, I get alerts and a spreadsheet and I can look, but I don't get your email address. So there's no automatic way to invite you to Slack other than by doing it manually. And yeah, so this is where I'm, this is where I am going to next. I am going to do a, ah, I want to do the TF playground idea and the classification idea. So if anybody has any ideas for really simple, goofy, just like basic numeric data sets, I'm probably going to do something where I'm going to look for some color data set, which takes any RGB, set of RGB numbers and like categorizes it in like a few, with a few different like labels. That's why, so if you have some suggestions for that, please let me know, at Schiffman on Twitter is probably the best way. All right, everyone. I don't know. Add more layers. Sorry, everybody. I hope today, I hope you enjoyed today somehow. I just, I don't know. Maybe I shouldn't be covering. Next week, let me really, maybe I'll try to at least do a coding challenge that's not machine learning related. I want to get through all this machine learning content, but it is kind of overwhelming and taking over everything. Weather prediction, but I need, I want to do classification. So I don't want to do time series, all these, these things will come, but I want to do a really basic classification. I don't want to use images. I don't want to use text data. That's like, I don't use time series, sequential data. I just want like, you know, like it's like house prediction, the iris data set. These are the kind of thing, house price prediction. Well, that's prediction. That's not classification even, but regression, but something like that, but I want it to feel goofy, creative, in the art world space, that kind of thing. All right, tic-tac-toe game. Okay, goodbye, everybody. I'm going to hit stop streaming. I guess I will play you out with my weird trailer since that's what I do now. ♪ Let's find something we want to make ♪ ♪ Some crazy idea ♪ ♪ We'll figure out what it takes to make that dream appear ♪ ♪ We'll try to understand now as we're living our day ♪ While the trailer is playing, I will attempt to explain why doesn't it dispose of tensors automatically, as asks Ray Jackson, asks Arnav. I don't actually know why it doesn't dispose of tensors automatically, but this is the thing that there is no way to clean up the memory on the GPU with a garbage collector in the same way, and this is like a lower level question that I would be curious. We have to investigate more about how TensorFlow.js works. ♪ Fireworks, fireballs, super ships ♪ ♪ We can do anything in the outer space ♪ ♪ We can generate sounds or trees or mazes ♪ ♪ Make a butterfly or reflect our faces ♪ ♪ A retro game for a toy device ♪ ♪ And never forget that there's that ♪ ♪ Just hop on the coding train, coding train, coding train ♪ ♪ Fireworks, fireballs, super ships ♪ ♪ We can do anything in the outer space ♪ ♪ We can generate sounds or trees or mazes ♪ ♪ Make a butterfly or reflect our faces ♪ ♪ A retro game for a toy device ♪ ♪ And never forget that there's that ♪ ♪ Just hop on the coding train, coding train, coding train ♪ ♪ Fireworks, fireballs, super ships ♪ ♪ We can do anything in the outer space ♪ www.microsoft.com",
    "translation": null
  },
  "error": null,
  "status": "succeeded",
  "created_at": "2023-09-26T21:03:50.486527Z",
  "started_at": "2023-09-26T21:18:30.818531Z",
  "completed_at": "2023-09-26T21:42:34.964656Z",
  "webhook": "https://83ceaa0b612c.ngrok.app/?video_id=_wC4sn5qKQw",
  "webhook_events_filter": [
    "completed"
  ],
  "metrics": {
    "predict_time": 1444.146125
  },
  "urls": {
    "cancel": "https://api.replicate.com/v1/predictions/o6xmpibbmg7gkr2nu3ejppzqj4/cancel",
    "get": "https://api.replicate.com/v1/predictions/o6xmpibbmg7gkr2nu3ejppzqj4"
  }
}