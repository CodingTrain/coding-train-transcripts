{
  "id": "yrmtdlzb4cfnecctakk5zzrgdm",
  "version": "91ee9c0c3df30478510ff8c8a3a545add1ad0259ad3a9f78fba57fbc05ee64f7",
  "input": {
    "audio": "https://upcdn.io/FW25b4F/raw/coding-train/v4kL0OHuxXs.m4a"
  },
  "logs": "Transcribe with large-v2 model\nDetected language: English\n  0%|          | 0/49217 [00:00<?, ?frames/s]\n  5%|▌         | 2700/49217 [00:06<01:51, 416.96frames/s]\n 11%|█▏        | 5618/49217 [00:13<01:40, 432.81frames/s]\n 17%|█▋        | 8474/49217 [00:20<01:40, 405.70frames/s]\n 23%|██▎       | 11318/49217 [00:26<01:28, 426.99frames/s]\n 28%|██▊       | 14014/49217 [00:33<01:24, 416.90frames/s]\n 34%|███▍      | 16854/49217 [00:39<01:15, 426.73frames/s]\n 40%|████      | 19794/49217 [00:47<01:11, 414.06frames/s]\n 46%|████▌     | 22606/49217 [00:53<01:02, 425.69frames/s]\n 51%|█████▏    | 25286/49217 [00:58<00:53, 446.67frames/s]\n 57%|█████▋    | 27898/49217 [01:04<00:46, 460.33frames/s]\n 62%|██████▏   | 30718/49217 [01:09<00:39, 474.22frames/s]\n 68%|██████▊   | 33534/49217 [01:15<00:33, 473.23frames/s]\n 74%|███████▍  | 36486/49217 [01:20<00:25, 506.44frames/s]\n 80%|███████▉  | 39326/49217 [01:26<00:19, 499.57frames/s]\n 86%|████████▌ | 42182/49217 [01:32<00:14, 485.67frames/s]\n 91%|█████████ | 44894/49217 [01:38<00:09, 470.03frames/s]\n 97%|█████████▋| 47694/49217 [01:45<00:03, 461.15frames/s]\n 98%|█████████▊| 48226/49217 [01:46<00:02, 459.61frames/s]\n98%|█████████▊| 48226/49217 [01:50<00:02, 435.79frames/s]\n",
  "output": {
    "detected_language": "english",
    "segments": [
      {
        "avg_logprob": -0.2571656234621063,
        "compression_ratio": 1.6085271317829457,
        "end": 1.44,
        "id": 0,
        "no_speech_prob": 0.0075722308829426765,
        "seek": 0,
        "start": 0,
        "temperature": 0,
        "text": " Hello.",
        "tokens": [
          50364,
          2425,
          13,
          50436
        ]
      },
      {
        "avg_logprob": -0.2571656234621063,
        "compression_ratio": 1.6085271317829457,
        "end": 4.12,
        "id": 1,
        "no_speech_prob": 0.0075722308829426765,
        "seek": 0,
        "start": 1.44,
        "temperature": 0,
        "text": " Welcome to session six, or week six.",
        "tokens": [
          50436,
          4027,
          281,
          5481,
          2309,
          11,
          420,
          1243,
          2309,
          13,
          50570
        ]
      },
      {
        "avg_logprob": -0.2571656234621063,
        "compression_ratio": 1.6085271317829457,
        "end": 6.28,
        "id": 2,
        "no_speech_prob": 0.0075722308829426765,
        "seek": 0,
        "start": 4.12,
        "temperature": 0,
        "text": " I don't know, are you doing this every day, every week,",
        "tokens": [
          50570,
          286,
          500,
          380,
          458,
          11,
          366,
          291,
          884,
          341,
          633,
          786,
          11,
          633,
          1243,
          11,
          50678
        ]
      },
      {
        "avg_logprob": -0.2571656234621063,
        "compression_ratio": 1.6085271317829457,
        "end": 6.78,
        "id": 3,
        "no_speech_prob": 0.0075722308829426765,
        "seek": 0,
        "start": 6.28,
        "temperature": 0,
        "text": " every month?",
        "tokens": [
          50678,
          633,
          1618,
          30,
          50703
        ]
      },
      {
        "avg_logprob": -0.2571656234621063,
        "compression_ratio": 1.6085271317829457,
        "end": 9.08,
        "id": 4,
        "no_speech_prob": 0.0075722308829426765,
        "seek": 0,
        "start": 6.78,
        "temperature": 0,
        "text": " This could be year six for you if you wanted it to be.",
        "tokens": [
          50703,
          639,
          727,
          312,
          1064,
          2309,
          337,
          291,
          498,
          291,
          1415,
          309,
          281,
          312,
          13,
          50818
        ]
      },
      {
        "avg_logprob": -0.2571656234621063,
        "compression_ratio": 1.6085271317829457,
        "end": 11.1,
        "id": 5,
        "no_speech_prob": 0.0075722308829426765,
        "seek": 0,
        "start": 9.08,
        "temperature": 0,
        "text": " But this is programming from A to Z.",
        "tokens": [
          50818,
          583,
          341,
          307,
          9410,
          490,
          316,
          281,
          1176,
          13,
          50919
        ]
      },
      {
        "avg_logprob": -0.2571656234621063,
        "compression_ratio": 1.6085271317829457,
        "end": 13.92,
        "id": 6,
        "no_speech_prob": 0.0075722308829426765,
        "seek": 0,
        "start": 11.1,
        "temperature": 0,
        "text": " It's a set of tutorials, a kind of online course",
        "tokens": [
          50919,
          467,
          311,
          257,
          992,
          295,
          17616,
          11,
          257,
          733,
          295,
          2950,
          1164,
          51060
        ]
      },
      {
        "avg_logprob": -0.2571656234621063,
        "compression_ratio": 1.6085271317829457,
        "end": 17.04,
        "id": 7,
        "no_speech_prob": 0.0075722308829426765,
        "seek": 0,
        "start": 13.92,
        "temperature": 0,
        "text": " you could follow, all about programming and algorithms",
        "tokens": [
          51060,
          291,
          727,
          1524,
          11,
          439,
          466,
          9410,
          293,
          14642,
          51216
        ]
      },
      {
        "avg_logprob": -0.2571656234621063,
        "compression_ratio": 1.6085271317829457,
        "end": 18.28,
        "id": 8,
        "no_speech_prob": 0.0075722308829426765,
        "seek": 0,
        "start": 17.04,
        "temperature": 0,
        "text": " with text.",
        "tokens": [
          51216,
          365,
          2487,
          13,
          51278
        ]
      },
      {
        "avg_logprob": -0.2571656234621063,
        "compression_ratio": 1.6085271317829457,
        "end": 19.06,
        "id": 9,
        "no_speech_prob": 0.0075722308829426765,
        "seek": 0,
        "start": 18.28,
        "temperature": 0,
        "text": " Text.",
        "tokens": [
          51278,
          18643,
          13,
          51317
        ]
      },
      {
        "avg_logprob": -0.2571656234621063,
        "compression_ratio": 1.6085271317829457,
        "end": 22.88,
        "id": 10,
        "no_speech_prob": 0.0075722308829426765,
        "seek": 0,
        "start": 19.06,
        "temperature": 0,
        "text": " Language, text, words, letters, all that sort of stuff.",
        "tokens": [
          51317,
          24445,
          11,
          2487,
          11,
          2283,
          11,
          7825,
          11,
          439,
          300,
          1333,
          295,
          1507,
          13,
          51508
        ]
      },
      {
        "avg_logprob": -0.2571656234621063,
        "compression_ratio": 1.6085271317829457,
        "end": 27,
        "id": 11,
        "no_speech_prob": 0.0075722308829426765,
        "seek": 0,
        "start": 22.88,
        "temperature": 0,
        "text": " So today, in this week's session,",
        "tokens": [
          51508,
          407,
          965,
          11,
          294,
          341,
          1243,
          311,
          5481,
          11,
          51714
        ]
      },
      {
        "avg_logprob": -0.2664982428917518,
        "compression_ratio": 1.6920289855072463,
        "end": 31.6,
        "id": 12,
        "no_speech_prob": 0.0004582894325722009,
        "seek": 2700,
        "start": 27,
        "temperature": 0,
        "text": " the focus will be about, the focus that I want to have",
        "tokens": [
          50364,
          264,
          1879,
          486,
          312,
          466,
          11,
          264,
          1879,
          300,
          286,
          528,
          281,
          362,
          50594
        ]
      },
      {
        "avg_logprob": -0.2664982428917518,
        "compression_ratio": 1.6920289855072463,
        "end": 33,
        "id": 13,
        "no_speech_prob": 0.0004582894325722009,
        "seek": 2700,
        "start": 31.6,
        "temperature": 0,
        "text": " is Markov chains.",
        "tokens": [
          50594,
          307,
          3934,
          5179,
          12626,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.2664982428917518,
        "compression_ratio": 1.6920289855072463,
        "end": 34.480000000000004,
        "id": 14,
        "no_speech_prob": 0.0004582894325722009,
        "seek": 2700,
        "start": 33,
        "temperature": 0,
        "text": " Whoa, what's a Markov chain?",
        "tokens": [
          50664,
          7521,
          11,
          437,
          311,
          257,
          3934,
          5179,
          5021,
          30,
          50738
        ]
      },
      {
        "avg_logprob": -0.2664982428917518,
        "compression_ratio": 1.6920289855072463,
        "end": 35.08,
        "id": 15,
        "no_speech_prob": 0.0004582894325722009,
        "seek": 2700,
        "start": 34.480000000000004,
        "temperature": 0,
        "text": " What's the deal?",
        "tokens": [
          50738,
          708,
          311,
          264,
          2028,
          30,
          50768
        ]
      },
      {
        "avg_logprob": -0.2664982428917518,
        "compression_ratio": 1.6920289855072463,
        "end": 35.72,
        "id": 16,
        "no_speech_prob": 0.0004582894325722009,
        "seek": 2700,
        "start": 35.08,
        "temperature": 0,
        "text": " What's going on?",
        "tokens": [
          50768,
          708,
          311,
          516,
          322,
          30,
          50800
        ]
      },
      {
        "avg_logprob": -0.2664982428917518,
        "compression_ratio": 1.6920289855072463,
        "end": 39.44,
        "id": 17,
        "no_speech_prob": 0.0004582894325722009,
        "seek": 2700,
        "start": 35.72,
        "temperature": 0,
        "text": " So in the last session, I focused on something,",
        "tokens": [
          50800,
          407,
          294,
          264,
          1036,
          5481,
          11,
          286,
          5178,
          322,
          746,
          11,
          50986
        ]
      },
      {
        "avg_logprob": -0.2664982428917518,
        "compression_ratio": 1.6920289855072463,
        "end": 41.6,
        "id": 18,
        "no_speech_prob": 0.0004582894325722009,
        "seek": 2700,
        "start": 39.44,
        "temperature": 0,
        "text": " the sort of topic of text analysis.",
        "tokens": [
          50986,
          264,
          1333,
          295,
          4829,
          295,
          2487,
          5215,
          13,
          51094
        ]
      },
      {
        "avg_logprob": -0.2664982428917518,
        "compression_ratio": 1.6920289855072463,
        "end": 44.400000000000006,
        "id": 19,
        "no_speech_prob": 0.0004582894325722009,
        "seek": 2700,
        "start": 41.6,
        "temperature": 0,
        "text": " So in last week, the idea was really exclusively",
        "tokens": [
          51094,
          407,
          294,
          1036,
          1243,
          11,
          264,
          1558,
          390,
          534,
          20638,
          51234
        ]
      },
      {
        "avg_logprob": -0.2664982428917518,
        "compression_ratio": 1.6920289855072463,
        "end": 47.400000000000006,
        "id": 20,
        "no_speech_prob": 0.0004582894325722009,
        "seek": 2700,
        "start": 44.400000000000006,
        "temperature": 0,
        "text": " about reading text in and analyzing it.",
        "tokens": [
          51234,
          466,
          3760,
          2487,
          294,
          293,
          23663,
          309,
          13,
          51384
        ]
      },
      {
        "avg_logprob": -0.2664982428917518,
        "compression_ratio": 1.6920289855072463,
        "end": 50.480000000000004,
        "id": 21,
        "no_speech_prob": 0.0004582894325722009,
        "seek": 2700,
        "start": 47.400000000000006,
        "temperature": 0,
        "text": " Counting how many times different words appear,",
        "tokens": [
          51384,
          5247,
          278,
          577,
          867,
          1413,
          819,
          2283,
          4204,
          11,
          51538
        ]
      },
      {
        "avg_logprob": -0.2664982428917518,
        "compression_ratio": 1.6920289855072463,
        "end": 53.16,
        "id": 22,
        "no_speech_prob": 0.0004582894325722009,
        "seek": 2700,
        "start": 50.480000000000004,
        "temperature": 0,
        "text": " trying to think about how you might do sentiment analysis.",
        "tokens": [
          51538,
          1382,
          281,
          519,
          466,
          577,
          291,
          1062,
          360,
          16149,
          5215,
          13,
          51672
        ]
      },
      {
        "avg_logprob": -0.2664982428917518,
        "compression_ratio": 1.6920289855072463,
        "end": 56.18,
        "id": 23,
        "no_speech_prob": 0.0004582894325722009,
        "seek": 2700,
        "start": 53.16,
        "temperature": 0,
        "text": " What happens when a computer program reads in text?",
        "tokens": [
          51672,
          708,
          2314,
          562,
          257,
          3820,
          1461,
          15700,
          294,
          2487,
          30,
          51823
        ]
      },
      {
        "avg_logprob": -0.2261713646553658,
        "compression_ratio": 1.704968944099379,
        "end": 58.94,
        "id": 24,
        "no_speech_prob": 0.00003426807597861625,
        "seek": 5618,
        "start": 56.18,
        "temperature": 0,
        "text": " I want to turn now towards what happens when a computer",
        "tokens": [
          50364,
          286,
          528,
          281,
          1261,
          586,
          3030,
          437,
          2314,
          562,
          257,
          3820,
          50502
        ]
      },
      {
        "avg_logprob": -0.2261713646553658,
        "compression_ratio": 1.704968944099379,
        "end": 61.34,
        "id": 25,
        "no_speech_prob": 0.00003426807597861625,
        "seek": 5618,
        "start": 58.94,
        "temperature": 0,
        "text": " program writes its own text.",
        "tokens": [
          50502,
          1461,
          13657,
          1080,
          1065,
          2487,
          13,
          50622
        ]
      },
      {
        "avg_logprob": -0.2261713646553658,
        "compression_ratio": 1.704968944099379,
        "end": 63.06,
        "id": 26,
        "no_speech_prob": 0.00003426807597861625,
        "seek": 5618,
        "start": 61.34,
        "temperature": 0,
        "text": " And there, of course, are many, many ways",
        "tokens": [
          50622,
          400,
          456,
          11,
          295,
          1164,
          11,
          366,
          867,
          11,
          867,
          2098,
          50708
        ]
      },
      {
        "avg_logprob": -0.2261713646553658,
        "compression_ratio": 1.704968944099379,
        "end": 64.1,
        "id": 27,
        "no_speech_prob": 0.00003426807597861625,
        "seek": 5618,
        "start": 63.06,
        "temperature": 0,
        "text": " that you could do this.",
        "tokens": [
          50708,
          300,
          291,
          727,
          360,
          341,
          13,
          50760
        ]
      },
      {
        "avg_logprob": -0.2261713646553658,
        "compression_ratio": 1.704968944099379,
        "end": 65.46,
        "id": 28,
        "no_speech_prob": 0.00003426807597861625,
        "seek": 5618,
        "start": 64.1,
        "temperature": 0,
        "text": " In next week's session, I'm going",
        "tokens": [
          50760,
          682,
          958,
          1243,
          311,
          5481,
          11,
          286,
          478,
          516,
          50828
        ]
      },
      {
        "avg_logprob": -0.2261713646553658,
        "compression_ratio": 1.704968944099379,
        "end": 68.62,
        "id": 29,
        "no_speech_prob": 0.00003426807597861625,
        "seek": 5618,
        "start": 65.46,
        "temperature": 0,
        "text": " to look at something called a context-free grammar.",
        "tokens": [
          50828,
          281,
          574,
          412,
          746,
          1219,
          257,
          4319,
          12,
          10792,
          22317,
          13,
          50986
        ]
      },
      {
        "avg_logprob": -0.2261713646553658,
        "compression_ratio": 1.704968944099379,
        "end": 71,
        "id": 30,
        "no_speech_prob": 0.00003426807597861625,
        "seek": 5618,
        "start": 68.62,
        "temperature": 0,
        "text": " In other sessions, I hope to look at some machine learning",
        "tokens": [
          50986,
          682,
          661,
          11081,
          11,
          286,
          1454,
          281,
          574,
          412,
          512,
          3479,
          2539,
          51105
        ]
      },
      {
        "avg_logprob": -0.2261713646553658,
        "compression_ratio": 1.704968944099379,
        "end": 73.9,
        "id": 31,
        "no_speech_prob": 0.00003426807597861625,
        "seek": 5618,
        "start": 71,
        "temperature": 0,
        "text": " techniques for generating text, as well as other just kind",
        "tokens": [
          51105,
          7512,
          337,
          17746,
          2487,
          11,
          382,
          731,
          382,
          661,
          445,
          733,
          51250
        ]
      },
      {
        "avg_logprob": -0.2261713646553658,
        "compression_ratio": 1.704968944099379,
        "end": 76.7,
        "id": 32,
        "no_speech_prob": 0.00003426807597861625,
        "seek": 5618,
        "start": 73.9,
        "temperature": 0,
        "text": " of creative ideas for ways to mix and match and have",
        "tokens": [
          51250,
          295,
          5880,
          3487,
          337,
          2098,
          281,
          2890,
          293,
          2995,
          293,
          362,
          51390
        ]
      },
      {
        "avg_logprob": -0.2261713646553658,
        "compression_ratio": 1.704968944099379,
        "end": 79.3,
        "id": 33,
        "no_speech_prob": 0.00003426807597861625,
        "seek": 5618,
        "start": 76.7,
        "temperature": 0,
        "text": " a program put together text as if it's writing it.",
        "tokens": [
          51390,
          257,
          1461,
          829,
          1214,
          2487,
          382,
          498,
          309,
          311,
          3579,
          309,
          13,
          51520
        ]
      },
      {
        "avg_logprob": -0.2261713646553658,
        "compression_ratio": 1.704968944099379,
        "end": 81.46000000000001,
        "id": 34,
        "no_speech_prob": 0.00003426807597861625,
        "seek": 5618,
        "start": 79.3,
        "temperature": 0,
        "text": " Now, one thing I should say about this week's topic",
        "tokens": [
          51520,
          823,
          11,
          472,
          551,
          286,
          820,
          584,
          466,
          341,
          1243,
          311,
          4829,
          51628
        ]
      },
      {
        "avg_logprob": -0.2261713646553658,
        "compression_ratio": 1.704968944099379,
        "end": 84.74000000000001,
        "id": 35,
        "no_speech_prob": 0.00003426807597861625,
        "seek": 5618,
        "start": 81.46000000000001,
        "temperature": 0,
        "text": " of Markov chains is it, by definition,",
        "tokens": [
          51628,
          295,
          3934,
          5179,
          12626,
          307,
          309,
          11,
          538,
          7123,
          11,
          51792
        ]
      },
      {
        "avg_logprob": -0.24397178457564667,
        "compression_ratio": 1.6706349206349207,
        "end": 89.1,
        "id": 36,
        "no_speech_prob": 0.0008167327614501119,
        "seek": 8474,
        "start": 84.74,
        "temperature": 0,
        "text": " requires a source text from which to generate text.",
        "tokens": [
          50364,
          7029,
          257,
          4009,
          2487,
          490,
          597,
          281,
          8460,
          2487,
          13,
          50582
        ]
      },
      {
        "avg_logprob": -0.24397178457564667,
        "compression_ratio": 1.6706349206349207,
        "end": 91.66,
        "id": 37,
        "no_speech_prob": 0.0008167327614501119,
        "seek": 8474,
        "start": 89.1,
        "temperature": 0,
        "text": " So this is something you'll see in a lot of these algorithms",
        "tokens": [
          50582,
          407,
          341,
          307,
          746,
          291,
          603,
          536,
          294,
          257,
          688,
          295,
          613,
          14642,
          50710
        ]
      },
      {
        "avg_logprob": -0.24397178457564667,
        "compression_ratio": 1.6706349206349207,
        "end": 92.94,
        "id": 38,
        "no_speech_prob": 0.0008167327614501119,
        "seek": 8474,
        "start": 91.66,
        "temperature": 0,
        "text": " for generating text.",
        "tokens": [
          50710,
          337,
          17746,
          2487,
          13,
          50774
        ]
      },
      {
        "avg_logprob": -0.24397178457564667,
        "compression_ratio": 1.6706349206349207,
        "end": 95.58,
        "id": 39,
        "no_speech_prob": 0.0008167327614501119,
        "seek": 8474,
        "start": 92.94,
        "temperature": 0,
        "text": " They also include a reading text component.",
        "tokens": [
          50774,
          814,
          611,
          4090,
          257,
          3760,
          2487,
          6542,
          13,
          50906
        ]
      },
      {
        "avg_logprob": -0.24397178457564667,
        "compression_ratio": 1.6706349206349207,
        "end": 98.53999999999999,
        "id": 40,
        "no_speech_prob": 0.0008167327614501119,
        "seek": 8474,
        "start": 95.58,
        "temperature": 0,
        "text": " So now, a Markov chain is not something",
        "tokens": [
          50906,
          407,
          586,
          11,
          257,
          3934,
          5179,
          5021,
          307,
          406,
          746,
          51054
        ]
      },
      {
        "avg_logprob": -0.24397178457564667,
        "compression_ratio": 1.6706349206349207,
        "end": 100.94,
        "id": 41,
        "no_speech_prob": 0.0008167327614501119,
        "seek": 8474,
        "start": 98.53999999999999,
        "temperature": 0,
        "text": " exclusive to the idea of text.",
        "tokens": [
          51054,
          13005,
          281,
          264,
          1558,
          295,
          2487,
          13,
          51174
        ]
      },
      {
        "avg_logprob": -0.24397178457564667,
        "compression_ratio": 1.6706349206349207,
        "end": 102.97999999999999,
        "id": 42,
        "no_speech_prob": 0.0008167327614501119,
        "seek": 8474,
        "start": 100.94,
        "temperature": 0,
        "text": " And in fact, a Markov chain really just",
        "tokens": [
          51174,
          400,
          294,
          1186,
          11,
          257,
          3934,
          5179,
          5021,
          534,
          445,
          51276
        ]
      },
      {
        "avg_logprob": -0.24397178457564667,
        "compression_ratio": 1.6706349206349207,
        "end": 108.22,
        "id": 43,
        "no_speech_prob": 0.0008167327614501119,
        "seek": 8474,
        "start": 102.97999999999999,
        "temperature": 0,
        "text": " describes a sequence or a chain of states, like I am happy,",
        "tokens": [
          51276,
          15626,
          257,
          8310,
          420,
          257,
          5021,
          295,
          4368,
          11,
          411,
          286,
          669,
          2055,
          11,
          51538
        ]
      },
      {
        "avg_logprob": -0.24397178457564667,
        "compression_ratio": 1.6706349206349207,
        "end": 110.66,
        "id": 44,
        "no_speech_prob": 0.0008167327614501119,
        "seek": 8474,
        "start": 108.22,
        "temperature": 0,
        "text": " I am sad, I am running.",
        "tokens": [
          51538,
          286,
          669,
          4227,
          11,
          286,
          669,
          2614,
          13,
          51660
        ]
      },
      {
        "avg_logprob": -0.24397178457564667,
        "compression_ratio": 1.6706349206349207,
        "end": 113.17999999999999,
        "id": 45,
        "no_speech_prob": 0.0008167327614501119,
        "seek": 8474,
        "start": 110.66,
        "temperature": 0,
        "text": " And I might typically, on any given day, be sad.",
        "tokens": [
          51660,
          400,
          286,
          1062,
          5850,
          11,
          322,
          604,
          2212,
          786,
          11,
          312,
          4227,
          13,
          51786
        ]
      },
      {
        "avg_logprob": -0.24551692153468277,
        "compression_ratio": 1.844,
        "end": 114.18,
        "id": 46,
        "no_speech_prob": 0.0008969322661869228,
        "seek": 11318,
        "start": 113.18,
        "temperature": 0,
        "text": " And then I start running.",
        "tokens": [
          50364,
          400,
          550,
          286,
          722,
          2614,
          13,
          50414
        ]
      },
      {
        "avg_logprob": -0.24551692153468277,
        "compression_ratio": 1.844,
        "end": 115.10000000000001,
        "id": 47,
        "no_speech_prob": 0.0008969322661869228,
        "seek": 11318,
        "start": 114.18,
        "temperature": 0,
        "text": " And then I feel happy.",
        "tokens": [
          50414,
          400,
          550,
          286,
          841,
          2055,
          13,
          50460
        ]
      },
      {
        "avg_logprob": -0.24551692153468277,
        "compression_ratio": 1.844,
        "end": 116.98,
        "id": 48,
        "no_speech_prob": 0.0008969322661869228,
        "seek": 11318,
        "start": 115.10000000000001,
        "temperature": 0,
        "text": " And that's kind of my sequence.",
        "tokens": [
          50460,
          400,
          300,
          311,
          733,
          295,
          452,
          8310,
          13,
          50554
        ]
      },
      {
        "avg_logprob": -0.24551692153468277,
        "compression_ratio": 1.844,
        "end": 122.42,
        "id": 49,
        "no_speech_prob": 0.0008969322661869228,
        "seek": 11318,
        "start": 116.98,
        "temperature": 0,
        "text": " So with a Markov chain, looking at how certain states are",
        "tokens": [
          50554,
          407,
          365,
          257,
          3934,
          5179,
          5021,
          11,
          1237,
          412,
          577,
          1629,
          4368,
          366,
          50826
        ]
      },
      {
        "avg_logprob": -0.24551692153468277,
        "compression_ratio": 1.844,
        "end": 125.42,
        "id": 50,
        "no_speech_prob": 0.0008969322661869228,
        "seek": 11318,
        "start": 122.42,
        "temperature": 0,
        "text": " sequenced and the probability of a given state following",
        "tokens": [
          50826,
          5123,
          14672,
          293,
          264,
          8482,
          295,
          257,
          2212,
          1785,
          3480,
          50976
        ]
      },
      {
        "avg_logprob": -0.24551692153468277,
        "compression_ratio": 1.844,
        "end": 129.1,
        "id": 51,
        "no_speech_prob": 0.0008969322661869228,
        "seek": 11318,
        "start": 125.42,
        "temperature": 0,
        "text": " another state, we can use, we can evaluate",
        "tokens": [
          50976,
          1071,
          1785,
          11,
          321,
          393,
          764,
          11,
          321,
          393,
          13059,
          51160
        ]
      },
      {
        "avg_logprob": -0.24551692153468277,
        "compression_ratio": 1.844,
        "end": 130.86,
        "id": 52,
        "no_speech_prob": 0.0008969322661869228,
        "seek": 11318,
        "start": 129.1,
        "temperature": 0,
        "text": " sort of existing data.",
        "tokens": [
          51160,
          1333,
          295,
          6741,
          1412,
          13,
          51248
        ]
      },
      {
        "avg_logprob": -0.24551692153468277,
        "compression_ratio": 1.844,
        "end": 132.74,
        "id": 53,
        "no_speech_prob": 0.0008969322661869228,
        "seek": 11318,
        "start": 130.86,
        "temperature": 0,
        "text": " I can look and say, like, oh, what's",
        "tokens": [
          51248,
          286,
          393,
          574,
          293,
          584,
          11,
          411,
          11,
          1954,
          11,
          437,
          311,
          51342
        ]
      },
      {
        "avg_logprob": -0.24551692153468277,
        "compression_ratio": 1.844,
        "end": 133.54000000000002,
        "id": 54,
        "no_speech_prob": 0.0008969322661869228,
        "seek": 11318,
        "start": 132.74,
        "temperature": 0,
        "text": " the weather like today?",
        "tokens": [
          51342,
          264,
          5503,
          411,
          965,
          30,
          51382
        ]
      },
      {
        "avg_logprob": -0.24551692153468277,
        "compression_ratio": 1.844,
        "end": 134.46,
        "id": 55,
        "no_speech_prob": 0.0008969322661869228,
        "seek": 11318,
        "start": 133.54000000000002,
        "temperature": 0,
        "text": " What's the weather like tomorrow?",
        "tokens": [
          51382,
          708,
          311,
          264,
          5503,
          411,
          4153,
          30,
          51428
        ]
      },
      {
        "avg_logprob": -0.24551692153468277,
        "compression_ratio": 1.844,
        "end": 135.96,
        "id": 56,
        "no_speech_prob": 0.0008969322661869228,
        "seek": 11318,
        "start": 134.46,
        "temperature": 0,
        "text": " What's the weather like the next day?",
        "tokens": [
          51428,
          708,
          311,
          264,
          5503,
          411,
          264,
          958,
          786,
          30,
          51503
        ]
      },
      {
        "avg_logprob": -0.24551692153468277,
        "compression_ratio": 1.844,
        "end": 140.14000000000001,
        "id": 57,
        "no_speech_prob": 0.0008969322661869228,
        "seek": 11318,
        "start": 135.96,
        "temperature": 0,
        "text": " Over a year, and try to use that to either predict the new weather",
        "tokens": [
          51503,
          4886,
          257,
          1064,
          11,
          293,
          853,
          281,
          764,
          300,
          281,
          2139,
          6069,
          264,
          777,
          5503,
          51712
        ]
      },
      {
        "avg_logprob": -0.19320924377441406,
        "compression_ratio": 1.7605042016806722,
        "end": 142.85999999999999,
        "id": 58,
        "no_speech_prob": 0.005301775876432657,
        "seek": 14014,
        "start": 140.14,
        "temperature": 0,
        "text": " or to recreate a simulation of weather",
        "tokens": [
          50364,
          420,
          281,
          25833,
          257,
          16575,
          295,
          5503,
          50500
        ]
      },
      {
        "avg_logprob": -0.19320924377441406,
        "compression_ratio": 1.7605042016806722,
        "end": 145.01999999999998,
        "id": 59,
        "no_speech_prob": 0.005301775876432657,
        "seek": 14014,
        "start": 142.85999999999999,
        "temperature": 0,
        "text": " based on the sequence of states.",
        "tokens": [
          50500,
          2361,
          322,
          264,
          8310,
          295,
          4368,
          13,
          50608
        ]
      },
      {
        "avg_logprob": -0.19320924377441406,
        "compression_ratio": 1.7605042016806722,
        "end": 146.89999999999998,
        "id": 60,
        "no_speech_prob": 0.005301775876432657,
        "seek": 14014,
        "start": 145.01999999999998,
        "temperature": 0,
        "text": " So this is something I'll look at in more detail",
        "tokens": [
          50608,
          407,
          341,
          307,
          746,
          286,
          603,
          574,
          412,
          294,
          544,
          2607,
          50702
        ]
      },
      {
        "avg_logprob": -0.19320924377441406,
        "compression_ratio": 1.7605042016806722,
        "end": 148.29999999999998,
        "id": 61,
        "no_speech_prob": 0.005301775876432657,
        "seek": 14014,
        "start": 146.89999999999998,
        "temperature": 0,
        "text": " in the next video.",
        "tokens": [
          50702,
          294,
          264,
          958,
          960,
          13,
          50772
        ]
      },
      {
        "avg_logprob": -0.19320924377441406,
        "compression_ratio": 1.7605042016806722,
        "end": 150.29999999999998,
        "id": 62,
        "no_speech_prob": 0.005301775876432657,
        "seek": 14014,
        "start": 148.29999999999998,
        "temperature": 0,
        "text": " But there's a piece of that, which",
        "tokens": [
          50772,
          583,
          456,
          311,
          257,
          2522,
          295,
          300,
          11,
          597,
          50872
        ]
      },
      {
        "avg_logprob": -0.19320924377441406,
        "compression_ratio": 1.7605042016806722,
        "end": 154.57999999999998,
        "id": 63,
        "no_speech_prob": 0.005301775876432657,
        "seek": 14014,
        "start": 150.29999999999998,
        "temperature": 0,
        "text": " is, if I want to apply this idea of a Markov chain to text,",
        "tokens": [
          50872,
          307,
          11,
          498,
          286,
          528,
          281,
          3079,
          341,
          1558,
          295,
          257,
          3934,
          5179,
          5021,
          281,
          2487,
          11,
          51086
        ]
      },
      {
        "avg_logprob": -0.19320924377441406,
        "compression_ratio": 1.7605042016806722,
        "end": 158.01999999999998,
        "id": 64,
        "no_speech_prob": 0.005301775876432657,
        "seek": 14014,
        "start": 154.57999999999998,
        "temperature": 0,
        "text": " what I want is for the characters or words",
        "tokens": [
          51086,
          437,
          286,
          528,
          307,
          337,
          264,
          4342,
          420,
          2283,
          51258
        ]
      },
      {
        "avg_logprob": -0.19320924377441406,
        "compression_ratio": 1.7605042016806722,
        "end": 160.73999999999998,
        "id": 65,
        "no_speech_prob": 0.005301775876432657,
        "seek": 14014,
        "start": 158.01999999999998,
        "temperature": 0,
        "text": " of a piece of text to be states.",
        "tokens": [
          51258,
          295,
          257,
          2522,
          295,
          2487,
          281,
          312,
          4368,
          13,
          51394
        ]
      },
      {
        "avg_logprob": -0.19320924377441406,
        "compression_ratio": 1.7605042016806722,
        "end": 164.61999999999998,
        "id": 66,
        "no_speech_prob": 0.005301775876432657,
        "seek": 14014,
        "start": 160.73999999999998,
        "temperature": 0,
        "text": " For example, the state is I. The next state is M.",
        "tokens": [
          51394,
          1171,
          1365,
          11,
          264,
          1785,
          307,
          286,
          13,
          440,
          958,
          1785,
          307,
          376,
          13,
          51588
        ]
      },
      {
        "avg_logprob": -0.19320924377441406,
        "compression_ratio": 1.7605042016806722,
        "end": 166.45999999999998,
        "id": 67,
        "no_speech_prob": 0.005301775876432657,
        "seek": 14014,
        "start": 164.61999999999998,
        "temperature": 0,
        "text": " The next state is feeling.",
        "tokens": [
          51588,
          440,
          958,
          1785,
          307,
          2633,
          13,
          51680
        ]
      },
      {
        "avg_logprob": -0.19320924377441406,
        "compression_ratio": 1.7605042016806722,
        "end": 168.54,
        "id": 68,
        "no_speech_prob": 0.005301775876432657,
        "seek": 14014,
        "start": 166.45999999999998,
        "temperature": 0,
        "text": " The next state is like dancing.",
        "tokens": [
          51680,
          440,
          958,
          1785,
          307,
          411,
          8898,
          13,
          51784
        ]
      },
      {
        "avg_logprob": -0.26023756491171346,
        "compression_ratio": 1.7566666666666666,
        "end": 169.54,
        "id": 69,
        "no_speech_prob": 0.0007208338938653469,
        "seek": 16854,
        "start": 168.57999999999998,
        "temperature": 0,
        "text": " So those are states.",
        "tokens": [
          50366,
          407,
          729,
          366,
          4368,
          13,
          50414
        ]
      },
      {
        "avg_logprob": -0.26023756491171346,
        "compression_ratio": 1.7566666666666666,
        "end": 172.26,
        "id": 70,
        "no_speech_prob": 0.0007208338938653469,
        "seek": 16854,
        "start": 169.54,
        "temperature": 0,
        "text": " And whenever I say M, I usually say feeling.",
        "tokens": [
          50414,
          400,
          5699,
          286,
          584,
          376,
          11,
          286,
          2673,
          584,
          2633,
          13,
          50550
        ]
      },
      {
        "avg_logprob": -0.26023756491171346,
        "compression_ratio": 1.7566666666666666,
        "end": 174.82,
        "id": 71,
        "no_speech_prob": 0.0007208338938653469,
        "seek": 16854,
        "start": 172.26,
        "temperature": 0,
        "text": " And then whenever I say feeling, I usually say like.",
        "tokens": [
          50550,
          400,
          550,
          5699,
          286,
          584,
          2633,
          11,
          286,
          2673,
          584,
          411,
          13,
          50678
        ]
      },
      {
        "avg_logprob": -0.26023756491171346,
        "compression_ratio": 1.7566666666666666,
        "end": 176.45999999999998,
        "id": 72,
        "no_speech_prob": 0.0007208338938653469,
        "seek": 16854,
        "start": 174.82,
        "temperature": 0,
        "text": " But I might say, the other day, I'm",
        "tokens": [
          50678,
          583,
          286,
          1062,
          584,
          11,
          264,
          661,
          786,
          11,
          286,
          478,
          50760
        ]
      },
      {
        "avg_logprob": -0.26023756491171346,
        "compression_ratio": 1.7566666666666666,
        "end": 180.66,
        "id": 73,
        "no_speech_prob": 0.0007208338938653469,
        "seek": 16854,
        "start": 176.45999999999998,
        "temperature": 0,
        "text": " feeling like eating some kale salad or something like that,",
        "tokens": [
          50760,
          2633,
          411,
          3936,
          512,
          34699,
          12604,
          420,
          746,
          411,
          300,
          11,
          50970
        ]
      },
      {
        "avg_logprob": -0.26023756491171346,
        "compression_ratio": 1.7566666666666666,
        "end": 181.14,
        "id": 74,
        "no_speech_prob": 0.0007208338938653469,
        "seek": 16854,
        "start": 180.66,
        "temperature": 0,
        "text": " too.",
        "tokens": [
          50970,
          886,
          13,
          50994
        ]
      },
      {
        "avg_logprob": -0.26023756491171346,
        "compression_ratio": 1.7566666666666666,
        "end": 184.57999999999998,
        "id": 75,
        "no_speech_prob": 0.0007208338938653469,
        "seek": 16854,
        "start": 181.14,
        "temperature": 0,
        "text": " So this is quite possibly the worst explanation of Markov",
        "tokens": [
          50994,
          407,
          341,
          307,
          1596,
          6264,
          264,
          5855,
          10835,
          295,
          3934,
          5179,
          51166
        ]
      },
      {
        "avg_logprob": -0.26023756491171346,
        "compression_ratio": 1.7566666666666666,
        "end": 185.73999999999998,
        "id": 76,
        "no_speech_prob": 0.0007208338938653469,
        "seek": 16854,
        "start": 184.57999999999998,
        "temperature": 0,
        "text": " chains ever on the internet.",
        "tokens": [
          51166,
          12626,
          1562,
          322,
          264,
          4705,
          13,
          51224
        ]
      },
      {
        "avg_logprob": -0.26023756491171346,
        "compression_ratio": 1.7566666666666666,
        "end": 188.26,
        "id": 77,
        "no_speech_prob": 0.0007208338938653469,
        "seek": 16854,
        "start": 185.73999999999998,
        "temperature": 0,
        "text": " But you can skip to the next video, where I'm sure",
        "tokens": [
          51224,
          583,
          291,
          393,
          10023,
          281,
          264,
          958,
          960,
          11,
          689,
          286,
          478,
          988,
          51350
        ]
      },
      {
        "avg_logprob": -0.26023756491171346,
        "compression_ratio": 1.7566666666666666,
        "end": 189.42,
        "id": 78,
        "no_speech_prob": 0.0007208338938653469,
        "seek": 16854,
        "start": 188.26,
        "temperature": 0,
        "text": " it will make a lot of sense.",
        "tokens": [
          51350,
          309,
          486,
          652,
          257,
          688,
          295,
          2020,
          13,
          51408
        ]
      },
      {
        "avg_logprob": -0.26023756491171346,
        "compression_ratio": 1.7566666666666666,
        "end": 193.22,
        "id": 79,
        "no_speech_prob": 0.0007208338938653469,
        "seek": 16854,
        "start": 189.42,
        "temperature": 0,
        "text": " But a piece of evaluating the statistical properties",
        "tokens": [
          51408,
          583,
          257,
          2522,
          295,
          27479,
          264,
          22820,
          7221,
          51598
        ]
      },
      {
        "avg_logprob": -0.26023756491171346,
        "compression_ratio": 1.7566666666666666,
        "end": 196.1,
        "id": 80,
        "no_speech_prob": 0.0007208338938653469,
        "seek": 16854,
        "start": 193.22,
        "temperature": 0,
        "text": " of characters and words, how they appear next to each other,",
        "tokens": [
          51598,
          295,
          4342,
          293,
          2283,
          11,
          577,
          436,
          4204,
          958,
          281,
          1184,
          661,
          11,
          51742
        ]
      },
      {
        "avg_logprob": -0.26023756491171346,
        "compression_ratio": 1.7566666666666666,
        "end": 197.94,
        "id": 81,
        "no_speech_prob": 0.0007208338938653469,
        "seek": 16854,
        "start": 196.1,
        "temperature": 0,
        "text": " is this idea of an n-gram.",
        "tokens": [
          51742,
          307,
          341,
          1558,
          295,
          364,
          297,
          12,
          1342,
          13,
          51834
        ]
      },
      {
        "avg_logprob": -0.19033213359553638,
        "compression_ratio": 1.6045627376425855,
        "end": 200.1,
        "id": 82,
        "no_speech_prob": 0.0000547594390809536,
        "seek": 19794,
        "start": 197.94,
        "temperature": 0,
        "text": " So this will also be a piece of the example",
        "tokens": [
          50364,
          407,
          341,
          486,
          611,
          312,
          257,
          2522,
          295,
          264,
          1365,
          50472
        ]
      },
      {
        "avg_logprob": -0.19033213359553638,
        "compression_ratio": 1.6045627376425855,
        "end": 203.3,
        "id": 83,
        "no_speech_prob": 0.0000547594390809536,
        "seek": 19794,
        "start": 200.1,
        "temperature": 0,
        "text": " that I build today of, how do we look at a body of text",
        "tokens": [
          50472,
          300,
          286,
          1322,
          965,
          295,
          11,
          577,
          360,
          321,
          574,
          412,
          257,
          1772,
          295,
          2487,
          50632
        ]
      },
      {
        "avg_logprob": -0.19033213359553638,
        "compression_ratio": 1.6045627376425855,
        "end": 205.06,
        "id": 84,
        "no_speech_prob": 0.0000547594390809536,
        "seek": 19794,
        "start": 203.3,
        "temperature": 0,
        "text": " and look at this idea of n-grams?",
        "tokens": [
          50632,
          293,
          574,
          412,
          341,
          1558,
          295,
          297,
          12,
          1342,
          82,
          30,
          50720
        ]
      },
      {
        "avg_logprob": -0.19033213359553638,
        "compression_ratio": 1.6045627376425855,
        "end": 210.14,
        "id": 85,
        "no_speech_prob": 0.0000547594390809536,
        "seek": 19794,
        "start": 205.06,
        "temperature": 0,
        "text": " Now, Google has this massive treasure trove repository",
        "tokens": [
          50720,
          823,
          11,
          3329,
          575,
          341,
          5994,
          12985,
          4495,
          303,
          25841,
          50974
        ]
      },
      {
        "avg_logprob": -0.19033213359553638,
        "compression_ratio": 1.6045627376425855,
        "end": 213.26,
        "id": 86,
        "no_speech_prob": 0.0000547594390809536,
        "seek": 19794,
        "start": 210.14,
        "temperature": 0,
        "text": " of text, corpuses of text from 1800",
        "tokens": [
          50974,
          295,
          2487,
          11,
          1181,
          79,
          8355,
          295,
          2487,
          490,
          24327,
          51130
        ]
      },
      {
        "avg_logprob": -0.19033213359553638,
        "compression_ratio": 1.6045627376425855,
        "end": 215.18,
        "id": 87,
        "no_speech_prob": 0.0000547594390809536,
        "seek": 19794,
        "start": 213.26,
        "temperature": 0,
        "text": " all the way up until present day.",
        "tokens": [
          51130,
          439,
          264,
          636,
          493,
          1826,
          1974,
          786,
          13,
          51226
        ]
      },
      {
        "avg_logprob": -0.19033213359553638,
        "compression_ratio": 1.6045627376425855,
        "end": 218.9,
        "id": 88,
        "no_speech_prob": 0.0000547594390809536,
        "seek": 19794,
        "start": 215.18,
        "temperature": 0,
        "text": " And you can search for the frequency of certain n-grams.",
        "tokens": [
          51226,
          400,
          291,
          393,
          3164,
          337,
          264,
          7893,
          295,
          1629,
          297,
          12,
          1342,
          82,
          13,
          51412
        ]
      },
      {
        "avg_logprob": -0.19033213359553638,
        "compression_ratio": 1.6045627376425855,
        "end": 221.46,
        "id": 89,
        "no_speech_prob": 0.0000547594390809536,
        "seek": 19794,
        "start": 218.9,
        "temperature": 0,
        "text": " So these are what might be called bigrams,",
        "tokens": [
          51412,
          407,
          613,
          366,
          437,
          1062,
          312,
          1219,
          955,
          2356,
          82,
          11,
          51540
        ]
      },
      {
        "avg_logprob": -0.19033213359553638,
        "compression_ratio": 1.6045627376425855,
        "end": 224.82,
        "id": 90,
        "no_speech_prob": 0.0000547594390809536,
        "seek": 19794,
        "start": 221.46,
        "temperature": 0,
        "text": " meaning two, computer science, creative code,",
        "tokens": [
          51540,
          3620,
          732,
          11,
          3820,
          3497,
          11,
          5880,
          3089,
          11,
          51708
        ]
      },
      {
        "avg_logprob": -0.19033213359553638,
        "compression_ratio": 1.6045627376425855,
        "end": 226.06,
        "id": 91,
        "no_speech_prob": 0.0000547594390809536,
        "seek": 19794,
        "start": 224.82,
        "temperature": 0,
        "text": " creative writing.",
        "tokens": [
          51708,
          5880,
          3579,
          13,
          51770
        ]
      },
      {
        "avg_logprob": -0.25673614427881336,
        "compression_ratio": 1.5913043478260869,
        "end": 229.98,
        "id": 92,
        "no_speech_prob": 0.00005307474566507153,
        "seek": 22606,
        "start": 226.06,
        "temperature": 0,
        "text": " We could think of other ones like IM.",
        "tokens": [
          50364,
          492,
          727,
          519,
          295,
          661,
          2306,
          411,
          21463,
          13,
          50560
        ]
      },
      {
        "avg_logprob": -0.25673614427881336,
        "compression_ratio": 1.5913043478260869,
        "end": 234.26,
        "id": 93,
        "no_speech_prob": 0.00005307474566507153,
        "seek": 22606,
        "start": 229.98,
        "temperature": 0,
        "text": " And I could search for any of these bigrams",
        "tokens": [
          50560,
          400,
          286,
          727,
          3164,
          337,
          604,
          295,
          613,
          955,
          2356,
          82,
          50774
        ]
      },
      {
        "avg_logprob": -0.25673614427881336,
        "compression_ratio": 1.5913043478260869,
        "end": 235.9,
        "id": 94,
        "no_speech_prob": 0.00005307474566507153,
        "seek": 22606,
        "start": 234.26,
        "temperature": 0,
        "text": " and their frequency in text.",
        "tokens": [
          50774,
          293,
          641,
          7893,
          294,
          2487,
          13,
          50856
        ]
      },
      {
        "avg_logprob": -0.25673614427881336,
        "compression_ratio": 1.5913043478260869,
        "end": 238.22,
        "id": 95,
        "no_speech_prob": 0.00005307474566507153,
        "seek": 22606,
        "start": 235.9,
        "temperature": 0,
        "text": " And we can see that, first of all,",
        "tokens": [
          50856,
          400,
          321,
          393,
          536,
          300,
          11,
          700,
          295,
          439,
          11,
          50972
        ]
      },
      {
        "avg_logprob": -0.25673614427881336,
        "compression_ratio": 1.5913043478260869,
        "end": 241.02,
        "id": 96,
        "no_speech_prob": 0.00005307474566507153,
        "seek": 22606,
        "start": 238.22,
        "temperature": 0,
        "text": " computer science started to appear more and more frequently",
        "tokens": [
          50972,
          3820,
          3497,
          1409,
          281,
          4204,
          544,
          293,
          544,
          10374,
          51112
        ]
      },
      {
        "avg_logprob": -0.25673614427881336,
        "compression_ratio": 1.5913043478260869,
        "end": 242.98000000000002,
        "id": 97,
        "no_speech_prob": 0.00005307474566507153,
        "seek": 22606,
        "start": 241.02,
        "temperature": 0,
        "text": " in starting in the 1960s.",
        "tokens": [
          51112,
          294,
          2891,
          294,
          264,
          16157,
          82,
          13,
          51210
        ]
      },
      {
        "avg_logprob": -0.25673614427881336,
        "compression_ratio": 1.5913043478260869,
        "end": 245.74,
        "id": 98,
        "no_speech_prob": 0.00005307474566507153,
        "seek": 22606,
        "start": 242.98000000000002,
        "temperature": 0,
        "text": " You can see a more consistent amount of IM.",
        "tokens": [
          51210,
          509,
          393,
          536,
          257,
          544,
          8398,
          2372,
          295,
          21463,
          13,
          51348
        ]
      },
      {
        "avg_logprob": -0.25673614427881336,
        "compression_ratio": 1.5913043478260869,
        "end": 248.9,
        "id": 99,
        "no_speech_prob": 0.00005307474566507153,
        "seek": 22606,
        "start": 245.74,
        "temperature": 0,
        "text": " You can see creative writing, creative code down here.",
        "tokens": [
          51348,
          509,
          393,
          536,
          5880,
          3579,
          11,
          5880,
          3089,
          760,
          510,
          13,
          51506
        ]
      },
      {
        "avg_logprob": -0.25673614427881336,
        "compression_ratio": 1.5913043478260869,
        "end": 252.86,
        "id": 100,
        "no_speech_prob": 0.00005307474566507153,
        "seek": 22606,
        "start": 248.9,
        "temperature": 0,
        "text": " So this is a way of looking at how,",
        "tokens": [
          51506,
          407,
          341,
          307,
          257,
          636,
          295,
          1237,
          412,
          577,
          11,
          51704
        ]
      },
      {
        "avg_logprob": -0.17731901315542367,
        "compression_ratio": 1.6226415094339623,
        "end": 257.66,
        "id": 101,
        "no_speech_prob": 0.00013135068002156913,
        "seek": 25286,
        "start": 252.86,
        "temperature": 0,
        "text": " and we can look at trigrams, n-grams with an order,",
        "tokens": [
          50364,
          293,
          321,
          393,
          574,
          412,
          504,
          33737,
          82,
          11,
          297,
          12,
          1342,
          82,
          365,
          364,
          1668,
          11,
          50604
        ]
      },
      {
        "avg_logprob": -0.17731901315542367,
        "compression_ratio": 1.6226415094339623,
        "end": 262.38,
        "id": 102,
        "no_speech_prob": 0.00013135068002156913,
        "seek": 25286,
        "start": 257.66,
        "temperature": 0,
        "text": " an order of four, the order referring to the number.",
        "tokens": [
          50604,
          364,
          1668,
          295,
          1451,
          11,
          264,
          1668,
          13761,
          281,
          264,
          1230,
          13,
          50840
        ]
      },
      {
        "avg_logprob": -0.17731901315542367,
        "compression_ratio": 1.6226415094339623,
        "end": 265.18,
        "id": 103,
        "no_speech_prob": 0.00013135068002156913,
        "seek": 25286,
        "start": 262.38,
        "temperature": 0,
        "text": " And you can do creative projects with this.",
        "tokens": [
          50840,
          400,
          291,
          393,
          360,
          5880,
          4455,
          365,
          341,
          13,
          50980
        ]
      },
      {
        "avg_logprob": -0.17731901315542367,
        "compression_ratio": 1.6226415094339623,
        "end": 267.42,
        "id": 104,
        "no_speech_prob": 0.00013135068002156913,
        "seek": 25286,
        "start": 265.18,
        "temperature": 0,
        "text": " So here's a great project by Chris Harrison",
        "tokens": [
          50980,
          407,
          510,
          311,
          257,
          869,
          1716,
          538,
          6688,
          34272,
          51092
        ]
      },
      {
        "avg_logprob": -0.17731901315542367,
        "compression_ratio": 1.6226415094339623,
        "end": 272.02000000000004,
        "id": 105,
        "no_speech_prob": 0.00013135068002156913,
        "seek": 25286,
        "start": 267.42,
        "temperature": 0,
        "text": " called Web Trigrams, Visualizing Google's Trigram Data.",
        "tokens": [
          51092,
          1219,
          9573,
          1765,
          33737,
          82,
          11,
          23187,
          3319,
          3329,
          311,
          1765,
          33737,
          11888,
          13,
          51322
        ]
      },
      {
        "avg_logprob": -0.17731901315542367,
        "compression_ratio": 1.6226415094339623,
        "end": 276.42,
        "id": 106,
        "no_speech_prob": 0.00013135068002156913,
        "seek": 25286,
        "start": 272.02000000000004,
        "temperature": 0,
        "text": " And we can see here, if we just look at this PDF,",
        "tokens": [
          51322,
          400,
          321,
          393,
          536,
          510,
          11,
          498,
          321,
          445,
          574,
          412,
          341,
          17752,
          11,
          51542
        ]
      },
      {
        "avg_logprob": -0.17731901315542367,
        "compression_ratio": 1.6226415094339623,
        "end": 278.98,
        "id": 107,
        "no_speech_prob": 0.00013135068002156913,
        "seek": 25286,
        "start": 276.42,
        "temperature": 0,
        "text": " and I'm going to zoom into it so you can see,",
        "tokens": [
          51542,
          293,
          286,
          478,
          516,
          281,
          8863,
          666,
          309,
          370,
          291,
          393,
          536,
          11,
          51670
        ]
      },
      {
        "avg_logprob": -0.214194731278853,
        "compression_ratio": 1.7644230769230769,
        "end": 283.70000000000005,
        "id": 108,
        "no_speech_prob": 0.0001088964709197171,
        "seek": 27898,
        "start": 278.98,
        "temperature": 0,
        "text": " you can see here that in this project,",
        "tokens": [
          50364,
          291,
          393,
          536,
          510,
          300,
          294,
          341,
          1716,
          11,
          50600
        ]
      },
      {
        "avg_logprob": -0.214194731278853,
        "compression_ratio": 1.7644230769230769,
        "end": 288.66,
        "id": 109,
        "no_speech_prob": 0.0001088964709197171,
        "seek": 27898,
        "start": 283.70000000000005,
        "temperature": 0,
        "text": " Chris is visualizing all the words that tend to follow he,",
        "tokens": [
          50600,
          6688,
          307,
          5056,
          3319,
          439,
          264,
          2283,
          300,
          3928,
          281,
          1524,
          415,
          11,
          50848
        ]
      },
      {
        "avg_logprob": -0.214194731278853,
        "compression_ratio": 1.7644230769230769,
        "end": 290.3,
        "id": 110,
        "no_speech_prob": 0.0001088964709197171,
        "seek": 27898,
        "start": 288.66,
        "temperature": 0,
        "text": " and then from there, all the words",
        "tokens": [
          50848,
          293,
          550,
          490,
          456,
          11,
          439,
          264,
          2283,
          50930
        ]
      },
      {
        "avg_logprob": -0.214194731278853,
        "compression_ratio": 1.7644230769230769,
        "end": 291.46000000000004,
        "id": 111,
        "no_speech_prob": 0.0001088964709197171,
        "seek": 27898,
        "start": 290.3,
        "temperature": 0,
        "text": " that tend to follow that.",
        "tokens": [
          50930,
          300,
          3928,
          281,
          1524,
          300,
          13,
          50988
        ]
      },
      {
        "avg_logprob": -0.214194731278853,
        "compression_ratio": 1.7644230769230769,
        "end": 295.42,
        "id": 112,
        "no_speech_prob": 0.0001088964709197171,
        "seek": 27898,
        "start": 291.46000000000004,
        "temperature": 0,
        "text": " So another, I think these are some nice examples to look at.",
        "tokens": [
          50988,
          407,
          1071,
          11,
          286,
          519,
          613,
          366,
          512,
          1481,
          5110,
          281,
          574,
          412,
          13,
          51186
        ]
      },
      {
        "avg_logprob": -0.214194731278853,
        "compression_ratio": 1.7644230769230769,
        "end": 300.1,
        "id": 113,
        "no_speech_prob": 0.0001088964709197171,
        "seek": 27898,
        "start": 295.42,
        "temperature": 0,
        "text": " And you can kind of hear, imagine now, I have a,",
        "tokens": [
          51186,
          400,
          291,
          393,
          733,
          295,
          1568,
          11,
          3811,
          586,
          11,
          286,
          362,
          257,
          11,
          51420
        ]
      },
      {
        "avg_logprob": -0.214194731278853,
        "compression_ratio": 1.7644230769230769,
        "end": 304.22,
        "id": 114,
        "no_speech_prob": 0.0001088964709197171,
        "seek": 27898,
        "start": 300.1,
        "temperature": 0,
        "text": " I am not, I was not, I do not, I can a.",
        "tokens": [
          51420,
          286,
          669,
          406,
          11,
          286,
          390,
          406,
          11,
          286,
          360,
          406,
          11,
          286,
          393,
          257,
          13,
          51626
        ]
      },
      {
        "avg_logprob": -0.214194731278853,
        "compression_ratio": 1.7644230769230769,
        "end": 307.18,
        "id": 115,
        "no_speech_prob": 0.0001088964709197171,
        "seek": 27898,
        "start": 304.22,
        "temperature": 0,
        "text": " So you can sort of see the frequencies of these sequences.",
        "tokens": [
          51626,
          407,
          291,
          393,
          1333,
          295,
          536,
          264,
          20250,
          295,
          613,
          22978,
          13,
          51774
        ]
      },
      {
        "avg_logprob": -0.20727368990580242,
        "compression_ratio": 1.7125,
        "end": 309.90000000000003,
        "id": 116,
        "no_speech_prob": 0.0005192955140955746,
        "seek": 30718,
        "start": 307.18,
        "temperature": 0,
        "text": " And if you can evaluate those frequencies,",
        "tokens": [
          50364,
          400,
          498,
          291,
          393,
          13059,
          729,
          20250,
          11,
          50500
        ]
      },
      {
        "avg_logprob": -0.20727368990580242,
        "compression_ratio": 1.7125,
        "end": 312.66,
        "id": 117,
        "no_speech_prob": 0.0005192955140955746,
        "seek": 30718,
        "start": 309.90000000000003,
        "temperature": 0,
        "text": " you can use those frequencies as probabilities from which",
        "tokens": [
          50500,
          291,
          393,
          764,
          729,
          20250,
          382,
          33783,
          490,
          597,
          50638
        ]
      },
      {
        "avg_logprob": -0.20727368990580242,
        "compression_ratio": 1.7125,
        "end": 314.66,
        "id": 118,
        "no_speech_prob": 0.0005192955140955746,
        "seek": 30718,
        "start": 312.66,
        "temperature": 0,
        "text": " to generate new text.",
        "tokens": [
          50638,
          281,
          8460,
          777,
          2487,
          13,
          50738
        ]
      },
      {
        "avg_logprob": -0.20727368990580242,
        "compression_ratio": 1.7125,
        "end": 319.54,
        "id": 119,
        "no_speech_prob": 0.0005192955140955746,
        "seek": 30718,
        "start": 314.66,
        "temperature": 0,
        "text": " So here's an example of a project made by Alison Parrish.",
        "tokens": [
          50738,
          407,
          510,
          311,
          364,
          1365,
          295,
          257,
          1716,
          1027,
          538,
          41001,
          3457,
          81,
          742,
          13,
          50982
        ]
      },
      {
        "avg_logprob": -0.20727368990580242,
        "compression_ratio": 1.7125,
        "end": 321.46000000000004,
        "id": 120,
        "no_speech_prob": 0.0005192955140955746,
        "seek": 30718,
        "start": 319.54,
        "temperature": 0,
        "text": " The Interactive Telecommunications Program",
        "tokens": [
          50982,
          440,
          5751,
          12596,
          14889,
          25451,
          24847,
          8338,
          51078
        ]
      },
      {
        "avg_logprob": -0.20727368990580242,
        "compression_ratio": 1.7125,
        "end": 323.02,
        "id": 121,
        "no_speech_prob": 0.0005192955140955746,
        "seek": 30718,
        "start": 321.46000000000004,
        "temperature": 0,
        "text": " is a program at ITP.",
        "tokens": [
          51078,
          307,
          257,
          1461,
          412,
          6783,
          47,
          13,
          51156
        ]
      },
      {
        "avg_logprob": -0.20727368990580242,
        "compression_ratio": 1.7125,
        "end": 324.74,
        "id": 122,
        "no_speech_prob": 0.0005192955140955746,
        "seek": 30718,
        "start": 323.02,
        "temperature": 0,
        "text": " It's called IT, it's a program at ITP.",
        "tokens": [
          51156,
          467,
          311,
          1219,
          6783,
          11,
          309,
          311,
          257,
          1461,
          412,
          6783,
          47,
          13,
          51242
        ]
      },
      {
        "avg_logprob": -0.20727368990580242,
        "compression_ratio": 1.7125,
        "end": 326.1,
        "id": 123,
        "no_speech_prob": 0.0005192955140955746,
        "seek": 30718,
        "start": 324.74,
        "temperature": 0,
        "text": " It is ITP.",
        "tokens": [
          51242,
          467,
          307,
          6783,
          47,
          13,
          51310
        ]
      },
      {
        "avg_logprob": -0.20727368990580242,
        "compression_ratio": 1.7125,
        "end": 328.06,
        "id": 124,
        "no_speech_prob": 0.0005192955140955746,
        "seek": 30718,
        "start": 326.1,
        "temperature": 0,
        "text": " It's where I teach.",
        "tokens": [
          51310,
          467,
          311,
          689,
          286,
          2924,
          13,
          51408
        ]
      },
      {
        "avg_logprob": -0.20727368990580242,
        "compression_ratio": 1.7125,
        "end": 329.46000000000004,
        "id": 125,
        "no_speech_prob": 0.0005192955140955746,
        "seek": 30718,
        "start": 328.06,
        "temperature": 0,
        "text": " And we have courses every spring.",
        "tokens": [
          51408,
          400,
          321,
          362,
          7712,
          633,
          5587,
          13,
          51478
        ]
      },
      {
        "avg_logprob": -0.20727368990580242,
        "compression_ratio": 1.7125,
        "end": 335.34000000000003,
        "id": 126,
        "no_speech_prob": 0.0005192955140955746,
        "seek": 30718,
        "start": 329.46000000000004,
        "temperature": 0,
        "text": " And what Alison did is read all of the courses into a program,",
        "tokens": [
          51478,
          400,
          437,
          41001,
          630,
          307,
          1401,
          439,
          295,
          264,
          7712,
          666,
          257,
          1461,
          11,
          51772
        ]
      },
      {
        "avg_logprob": -0.2523315196134606,
        "compression_ratio": 1.548780487804878,
        "end": 338.14,
        "id": 127,
        "no_speech_prob": 0.0009253693278878927,
        "seek": 33534,
        "start": 335.34,
        "temperature": 0,
        "text": " look at all the statistical properties of all",
        "tokens": [
          50364,
          574,
          412,
          439,
          264,
          22820,
          7221,
          295,
          439,
          50504
        ]
      },
      {
        "avg_logprob": -0.2523315196134606,
        "compression_ratio": 1.548780487804878,
        "end": 340.9,
        "id": 128,
        "no_speech_prob": 0.0009253693278878927,
        "seek": 33534,
        "start": 338.14,
        "temperature": 0,
        "text": " the characters and words and how they appear next to each other,",
        "tokens": [
          50504,
          264,
          4342,
          293,
          2283,
          293,
          577,
          436,
          4204,
          958,
          281,
          1184,
          661,
          11,
          50642
        ]
      },
      {
        "avg_logprob": -0.2523315196134606,
        "compression_ratio": 1.548780487804878,
        "end": 345.21999999999997,
        "id": 129,
        "no_speech_prob": 0.0009253693278878927,
        "seek": 33534,
        "start": 340.9,
        "temperature": 0,
        "text": " and use that to generate new courses.",
        "tokens": [
          50642,
          293,
          764,
          300,
          281,
          8460,
          777,
          7712,
          13,
          50858
        ]
      },
      {
        "avg_logprob": -0.2523315196134606,
        "compression_ratio": 1.548780487804878,
        "end": 349.65999999999997,
        "id": 130,
        "no_speech_prob": 0.0009253693278878927,
        "seek": 33534,
        "start": 345.21999999999997,
        "temperature": 0,
        "text": " So I'm going to, let's find one that looks good.",
        "tokens": [
          50858,
          407,
          286,
          478,
          516,
          281,
          11,
          718,
          311,
          915,
          472,
          300,
          1542,
          665,
          13,
          51080
        ]
      },
      {
        "avg_logprob": -0.2523315196134606,
        "compression_ratio": 1.548780487804878,
        "end": 355.05999999999995,
        "id": 131,
        "no_speech_prob": 0.0009253693278878927,
        "seek": 33534,
        "start": 352.21999999999997,
        "temperature": 0,
        "text": " The Anthropologies of Virtual Design Workshop, MIDI",
        "tokens": [
          51208,
          440,
          12727,
          1513,
          6204,
          295,
          23887,
          12748,
          48366,
          11,
          41474,
          51350
        ]
      },
      {
        "avg_logprob": -0.2523315196134606,
        "compression_ratio": 1.548780487804878,
        "end": 356.58,
        "id": 132,
        "no_speech_prob": 0.0009253693278878927,
        "seek": 33534,
        "start": 355.05999999999995,
        "temperature": 0,
        "text": " and Cinematic Objects.",
        "tokens": [
          51350,
          293,
          18310,
          14911,
          24753,
          82,
          13,
          51426
        ]
      },
      {
        "avg_logprob": -0.2523315196134606,
        "compression_ratio": 1.548780487804878,
        "end": 359.02,
        "id": 133,
        "no_speech_prob": 0.0009253693278878927,
        "seek": 33534,
        "start": 356.58,
        "temperature": 0,
        "text": " This course, constraints of weekly sessions",
        "tokens": [
          51426,
          639,
          1164,
          11,
          18491,
          295,
          12460,
          11081,
          51548
        ]
      },
      {
        "avg_logprob": -0.2523315196134606,
        "compression_ratio": 1.548780487804878,
        "end": 362.82,
        "id": 134,
        "no_speech_prob": 0.0009253693278878927,
        "seek": 33534,
        "start": 359.02,
        "temperature": 0,
        "text": " beyond exercises and inspire the possible.",
        "tokens": [
          51548,
          4399,
          11900,
          293,
          15638,
          264,
          1944,
          13,
          51738
        ]
      },
      {
        "avg_logprob": -0.2523315196134606,
        "compression_ratio": 1.548780487804878,
        "end": 364.85999999999996,
        "id": 135,
        "no_speech_prob": 0.0009253693278878927,
        "seek": 33534,
        "start": 362.82,
        "temperature": 0,
        "text": " So this sounds great.",
        "tokens": [
          51738,
          407,
          341,
          3263,
          869,
          13,
          51840
        ]
      },
      {
        "avg_logprob": -0.22427300845875459,
        "compression_ratio": 1.5451505016722409,
        "end": 366.74,
        "id": 136,
        "no_speech_prob": 0.00021995024872012436,
        "seek": 36486,
        "start": 364.86,
        "temperature": 0,
        "text": " I think I'll take that course.",
        "tokens": [
          50364,
          286,
          519,
          286,
          603,
          747,
          300,
          1164,
          13,
          50458
        ]
      },
      {
        "avg_logprob": -0.22427300845875459,
        "compression_ratio": 1.5451505016722409,
        "end": 371.34000000000003,
        "id": 137,
        "no_speech_prob": 0.00021995024872012436,
        "seek": 36486,
        "start": 366.74,
        "temperature": 0,
        "text": " This is another example of a project called King James",
        "tokens": [
          50458,
          639,
          307,
          1071,
          1365,
          295,
          257,
          1716,
          1219,
          3819,
          5678,
          50688
        ]
      },
      {
        "avg_logprob": -0.22427300845875459,
        "compression_ratio": 1.5451505016722409,
        "end": 372.22,
        "id": 138,
        "no_speech_prob": 0.00021995024872012436,
        "seek": 36486,
        "start": 371.34000000000003,
        "temperature": 0,
        "text": " Programming.",
        "tokens": [
          50688,
          8338,
          2810,
          13,
          50732
        ]
      },
      {
        "avg_logprob": -0.22427300845875459,
        "compression_ratio": 1.5451505016722409,
        "end": 375.74,
        "id": 139,
        "no_speech_prob": 0.00021995024872012436,
        "seek": 36486,
        "start": 372.22,
        "temperature": 0,
        "text": " And these are posts generated by a Markov chain that has mixed",
        "tokens": [
          50732,
          400,
          613,
          366,
          12300,
          10833,
          538,
          257,
          3934,
          5179,
          5021,
          300,
          575,
          7467,
          50908
        ]
      },
      {
        "avg_logprob": -0.22427300845875459,
        "compression_ratio": 1.5451505016722409,
        "end": 378.02000000000004,
        "id": 140,
        "no_speech_prob": 0.00021995024872012436,
        "seek": 36486,
        "start": 375.74,
        "temperature": 0,
        "text": " several different input texts.",
        "tokens": [
          50908,
          2940,
          819,
          4846,
          15765,
          13,
          51022
        ]
      },
      {
        "avg_logprob": -0.22427300845875459,
        "compression_ratio": 1.5451505016722409,
        "end": 380.78000000000003,
        "id": 141,
        "no_speech_prob": 0.00021995024872012436,
        "seek": 36486,
        "start": 378.02000000000004,
        "temperature": 0,
        "text": " The King James Bible, Structured Interpretation",
        "tokens": [
          51022,
          440,
          3819,
          5678,
          6544,
          11,
          745,
          46847,
          5751,
          6629,
          399,
          51160
        ]
      },
      {
        "avg_logprob": -0.22427300845875459,
        "compression_ratio": 1.5451505016722409,
        "end": 383.74,
        "id": 142,
        "no_speech_prob": 0.00021995024872012436,
        "seek": 36486,
        "start": 380.78000000000003,
        "temperature": 0,
        "text": " of Computer Programs, and some of Eric S. Raymond's writings",
        "tokens": [
          51160,
          295,
          22289,
          44762,
          11,
          293,
          512,
          295,
          9336,
          318,
          13,
          42813,
          311,
          30083,
          51308
        ]
      },
      {
        "avg_logprob": -0.22427300845875459,
        "compression_ratio": 1.5451505016722409,
        "end": 385.38,
        "id": 143,
        "no_speech_prob": 0.00021995024872012436,
        "seek": 36486,
        "start": 383.74,
        "temperature": 0,
        "text": " run by Michael Walker.",
        "tokens": [
          51308,
          1190,
          538,
          5116,
          23974,
          13,
          51390
        ]
      },
      {
        "avg_logprob": -0.22427300845875459,
        "compression_ratio": 1.5451505016722409,
        "end": 388.66,
        "id": 144,
        "no_speech_prob": 0.00021995024872012436,
        "seek": 36486,
        "start": 385.38,
        "temperature": 0,
        "text": " So you can see here, these are different things",
        "tokens": [
          51390,
          407,
          291,
          393,
          536,
          510,
          11,
          613,
          366,
          819,
          721,
          51554
        ]
      },
      {
        "avg_logprob": -0.22427300845875459,
        "compression_ratio": 1.5451505016722409,
        "end": 389.90000000000003,
        "id": 145,
        "no_speech_prob": 0.00021995024872012436,
        "seek": 36486,
        "start": 388.66,
        "temperature": 0,
        "text": " that are generated from that.",
        "tokens": [
          51554,
          300,
          366,
          10833,
          490,
          300,
          13,
          51616
        ]
      },
      {
        "avg_logprob": -0.22427300845875459,
        "compression_ratio": 1.5451505016722409,
        "end": 393.26,
        "id": 146,
        "no_speech_prob": 0.00021995024872012436,
        "seek": 36486,
        "start": 389.90000000000003,
        "temperature": 0,
        "text": " Exercise 3.67 addresses why we want a local variable rather",
        "tokens": [
          51616,
          44307,
          805,
          13,
          22452,
          16862,
          983,
          321,
          528,
          257,
          2654,
          7006,
          2831,
          51784
        ]
      },
      {
        "avg_logprob": -0.23058917030455575,
        "compression_ratio": 1.6765799256505576,
        "end": 397.34,
        "id": 147,
        "no_speech_prob": 0.0015978383598849177,
        "seek": 39326,
        "start": 393.26,
        "temperature": 0,
        "text": " than a simple map as in the days of Herod the King.",
        "tokens": [
          50364,
          813,
          257,
          2199,
          4471,
          382,
          294,
          264,
          1708,
          295,
          3204,
          378,
          264,
          3819,
          13,
          50568
        ]
      },
      {
        "avg_logprob": -0.23058917030455575,
        "compression_ratio": 1.6765799256505576,
        "end": 401.26,
        "id": 148,
        "no_speech_prob": 0.0015978383598849177,
        "seek": 39326,
        "start": 397.34,
        "temperature": 0,
        "text": " OK, so there's a lot of possibilities",
        "tokens": [
          50568,
          2264,
          11,
          370,
          456,
          311,
          257,
          688,
          295,
          12178,
          50764
        ]
      },
      {
        "avg_logprob": -0.23058917030455575,
        "compression_ratio": 1.6765799256505576,
        "end": 406.3,
        "id": 149,
        "no_speech_prob": 0.0015978383598849177,
        "seek": 39326,
        "start": 401.26,
        "temperature": 0,
        "text": " for how you might use Markov chains for a creative output.",
        "tokens": [
          50764,
          337,
          577,
          291,
          1062,
          764,
          3934,
          5179,
          12626,
          337,
          257,
          5880,
          5598,
          13,
          51016
        ]
      },
      {
        "avg_logprob": -0.23058917030455575,
        "compression_ratio": 1.6765799256505576,
        "end": 408.82,
        "id": 150,
        "no_speech_prob": 0.0015978383598849177,
        "seek": 39326,
        "start": 406.3,
        "temperature": 0,
        "text": " And on the one hand, this is nothing new.",
        "tokens": [
          51016,
          400,
          322,
          264,
          472,
          1011,
          11,
          341,
          307,
          1825,
          777,
          13,
          51142
        ]
      },
      {
        "avg_logprob": -0.23058917030455575,
        "compression_ratio": 1.6765799256505576,
        "end": 412.34,
        "id": 151,
        "no_speech_prob": 0.0015978383598849177,
        "seek": 39326,
        "start": 408.82,
        "temperature": 0,
        "text": " This has been done and done and done and done again.",
        "tokens": [
          51142,
          639,
          575,
          668,
          1096,
          293,
          1096,
          293,
          1096,
          293,
          1096,
          797,
          13,
          51318
        ]
      },
      {
        "avg_logprob": -0.23058917030455575,
        "compression_ratio": 1.6765799256505576,
        "end": 414.26,
        "id": 152,
        "no_speech_prob": 0.0015978383598849177,
        "seek": 39326,
        "start": 412.34,
        "temperature": 0,
        "text": " This idea of reading in a source text,",
        "tokens": [
          51318,
          639,
          1558,
          295,
          3760,
          294,
          257,
          4009,
          2487,
          11,
          51414
        ]
      },
      {
        "avg_logprob": -0.23058917030455575,
        "compression_ratio": 1.6765799256505576,
        "end": 417.26,
        "id": 153,
        "no_speech_prob": 0.0015978383598849177,
        "seek": 39326,
        "start": 414.26,
        "temperature": 0,
        "text": " evaluate the probabilities on a character or word-based level,",
        "tokens": [
          51414,
          13059,
          264,
          33783,
          322,
          257,
          2517,
          420,
          1349,
          12,
          6032,
          1496,
          11,
          51564
        ]
      },
      {
        "avg_logprob": -0.23058917030455575,
        "compression_ratio": 1.6765799256505576,
        "end": 418.88,
        "id": 154,
        "no_speech_prob": 0.0015978383598849177,
        "seek": 39326,
        "start": 417.26,
        "temperature": 0,
        "text": " and I'll talk about that as I implement",
        "tokens": [
          51564,
          293,
          286,
          603,
          751,
          466,
          300,
          382,
          286,
          4445,
          51645
        ]
      },
      {
        "avg_logprob": -0.23058917030455575,
        "compression_ratio": 1.6765799256505576,
        "end": 420.09999999999997,
        "id": 155,
        "no_speech_prob": 0.0015978383598849177,
        "seek": 39326,
        "start": 418.88,
        "temperature": 0,
        "text": " the code in the next video.",
        "tokens": [
          51645,
          264,
          3089,
          294,
          264,
          958,
          960,
          13,
          51706
        ]
      },
      {
        "avg_logprob": -0.23058917030455575,
        "compression_ratio": 1.6765799256505576,
        "end": 421.82,
        "id": 156,
        "no_speech_prob": 0.0015978383598849177,
        "seek": 39326,
        "start": 420.09999999999997,
        "temperature": 0,
        "text": " And then text generating out of that.",
        "tokens": [
          51706,
          400,
          550,
          2487,
          17746,
          484,
          295,
          300,
          13,
          51792
        ]
      },
      {
        "avg_logprob": -0.3137179651568013,
        "compression_ratio": 1.6286764705882353,
        "end": 423.9,
        "id": 157,
        "no_speech_prob": 0.003707155119627714,
        "seek": 42182,
        "start": 421.82,
        "temperature": 0,
        "text": " You could make a Twitter bot that generates text",
        "tokens": [
          50364,
          509,
          727,
          652,
          257,
          5794,
          10592,
          300,
          23815,
          2487,
          50468
        ]
      },
      {
        "avg_logprob": -0.3137179651568013,
        "compression_ratio": 1.6286764705882353,
        "end": 425.06,
        "id": 158,
        "no_speech_prob": 0.003707155119627714,
        "seek": 42182,
        "start": 423.9,
        "temperature": 0,
        "text": " based on a Markov chain.",
        "tokens": [
          50468,
          2361,
          322,
          257,
          3934,
          5179,
          5021,
          13,
          50526
        ]
      },
      {
        "avg_logprob": -0.3137179651568013,
        "compression_ratio": 1.6286764705882353,
        "end": 427.58,
        "id": 159,
        "no_speech_prob": 0.003707155119627714,
        "seek": 42182,
        "start": 425.06,
        "temperature": 0,
        "text": " So I think there's value, and hopefully you",
        "tokens": [
          50526,
          407,
          286,
          519,
          456,
          311,
          2158,
          11,
          293,
          4696,
          291,
          50652
        ]
      },
      {
        "avg_logprob": -0.3137179651568013,
        "compression_ratio": 1.6286764705882353,
        "end": 429.18,
        "id": 160,
        "no_speech_prob": 0.003707155119627714,
        "seek": 42182,
        "start": 427.58,
        "temperature": 0,
        "text": " might enjoy exploring the idea.",
        "tokens": [
          50652,
          1062,
          2103,
          12736,
          264,
          1558,
          13,
          50732
        ]
      },
      {
        "avg_logprob": -0.3137179651568013,
        "compression_ratio": 1.6286764705882353,
        "end": 431.54,
        "id": 161,
        "no_speech_prob": 0.003707155119627714,
        "seek": 42182,
        "start": 429.18,
        "temperature": 0,
        "text": " And you might even just take the examples that I provide",
        "tokens": [
          50732,
          400,
          291,
          1062,
          754,
          445,
          747,
          264,
          5110,
          300,
          286,
          2893,
          50850
        ]
      },
      {
        "avg_logprob": -0.3137179651568013,
        "compression_ratio": 1.6286764705882353,
        "end": 433.54,
        "id": 162,
        "no_speech_prob": 0.003707155119627714,
        "seek": 42182,
        "start": 431.54,
        "temperature": 0,
        "text": " and find your own source text in.",
        "tokens": [
          50850,
          293,
          915,
          428,
          1065,
          4009,
          2487,
          294,
          13,
          50950
        ]
      },
      {
        "avg_logprob": -0.3137179651568013,
        "compression_ratio": 1.6286764705882353,
        "end": 435.74,
        "id": 163,
        "no_speech_prob": 0.003707155119627714,
        "seek": 42182,
        "start": 433.54,
        "temperature": 0,
        "text": " But I think for you to think about what",
        "tokens": [
          50950,
          583,
          286,
          519,
          337,
          291,
          281,
          519,
          466,
          437,
          51060
        ]
      },
      {
        "avg_logprob": -0.3137179651568013,
        "compression_ratio": 1.6286764705882353,
        "end": 437.94,
        "id": 164,
        "no_speech_prob": 0.003707155119627714,
        "seek": 42182,
        "start": 435.74,
        "temperature": 0,
        "text": " is the reason why you might do this, where might it",
        "tokens": [
          51060,
          307,
          264,
          1778,
          983,
          291,
          1062,
          360,
          341,
          11,
          689,
          1062,
          309,
          51170
        ]
      },
      {
        "avg_logprob": -0.3137179651568013,
        "compression_ratio": 1.6286764705882353,
        "end": 440.74,
        "id": 165,
        "no_speech_prob": 0.003707155119627714,
        "seek": 42182,
        "start": 437.94,
        "temperature": 0,
        "text": " fit into an existing project.",
        "tokens": [
          51170,
          3318,
          666,
          364,
          6741,
          1716,
          13,
          51310
        ]
      },
      {
        "avg_logprob": -0.3137179651568013,
        "compression_ratio": 1.6286764705882353,
        "end": 441.82,
        "id": 166,
        "no_speech_prob": 0.003707155119627714,
        "seek": 42182,
        "start": 440.74,
        "temperature": 0,
        "text": " I hear a walkie talkie.",
        "tokens": [
          51310,
          286,
          1568,
          257,
          1792,
          414,
          751,
          414,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.3137179651568013,
        "compression_ratio": 1.6286764705882353,
        "end": 444.53999999999996,
        "id": 167,
        "no_speech_prob": 0.003707155119627714,
        "seek": 42182,
        "start": 441.82,
        "temperature": 0,
        "text": " I want to.",
        "tokens": [
          51364,
          286,
          528,
          281,
          13,
          51500
        ]
      },
      {
        "avg_logprob": -0.3137179651568013,
        "compression_ratio": 1.6286764705882353,
        "end": 448.94,
        "id": 168,
        "no_speech_prob": 0.003707155119627714,
        "seek": 42182,
        "start": 444.53999999999996,
        "temperature": 0,
        "text": " And come up with some creative possibilities.",
        "tokens": [
          51500,
          400,
          808,
          493,
          365,
          512,
          5880,
          12178,
          13,
          51720
        ]
      },
      {
        "avg_logprob": -0.2680535614490509,
        "compression_ratio": 1.6724738675958188,
        "end": 452.02,
        "id": 169,
        "no_speech_prob": 0.048126738518476486,
        "seek": 44894,
        "start": 448.94,
        "temperature": 0,
        "text": " So in the next video, I'm going to focus on the code.",
        "tokens": [
          50364,
          407,
          294,
          264,
          958,
          960,
          11,
          286,
          478,
          516,
          281,
          1879,
          322,
          264,
          3089,
          13,
          50518
        ]
      },
      {
        "avg_logprob": -0.2680535614490509,
        "compression_ratio": 1.6724738675958188,
        "end": 455.5,
        "id": 170,
        "no_speech_prob": 0.048126738518476486,
        "seek": 44894,
        "start": 452.02,
        "temperature": 0,
        "text": " How to write the code to implement a Markov generator.",
        "tokens": [
          50518,
          1012,
          281,
          2464,
          264,
          3089,
          281,
          4445,
          257,
          3934,
          5179,
          19265,
          13,
          50692
        ]
      },
      {
        "avg_logprob": -0.2680535614490509,
        "compression_ratio": 1.6724738675958188,
        "end": 458.86,
        "id": 171,
        "no_speech_prob": 0.048126738518476486,
        "seek": 44894,
        "start": 455.5,
        "temperature": 0,
        "text": " I'm going to go through it entirely from scratch.",
        "tokens": [
          50692,
          286,
          478,
          516,
          281,
          352,
          807,
          309,
          7696,
          490,
          8459,
          13,
          50860
        ]
      },
      {
        "avg_logprob": -0.2680535614490509,
        "compression_ratio": 1.6724738675958188,
        "end": 461.1,
        "id": 172,
        "no_speech_prob": 0.048126738518476486,
        "seek": 44894,
        "start": 458.86,
        "temperature": 0,
        "text": " And then I'm going to show you a few additional examples",
        "tokens": [
          50860,
          400,
          550,
          286,
          478,
          516,
          281,
          855,
          291,
          257,
          1326,
          4497,
          5110,
          50972
        ]
      },
      {
        "avg_logprob": -0.2680535614490509,
        "compression_ratio": 1.6724738675958188,
        "end": 463.86,
        "id": 173,
        "no_speech_prob": 0.048126738518476486,
        "seek": 44894,
        "start": 461.1,
        "temperature": 0,
        "text": " and then come back with some exercise ideas for things",
        "tokens": [
          50972,
          293,
          550,
          808,
          646,
          365,
          512,
          5380,
          3487,
          337,
          721,
          51110
        ]
      },
      {
        "avg_logprob": -0.2680535614490509,
        "compression_ratio": 1.6724738675958188,
        "end": 467.22,
        "id": 174,
        "no_speech_prob": 0.048126738518476486,
        "seek": 44894,
        "start": 463.86,
        "temperature": 0,
        "text": " that you might want to try doing yourself",
        "tokens": [
          51110,
          300,
          291,
          1062,
          528,
          281,
          853,
          884,
          1803,
          51278
        ]
      },
      {
        "avg_logprob": -0.2680535614490509,
        "compression_ratio": 1.6724738675958188,
        "end": 468.5,
        "id": 175,
        "no_speech_prob": 0.048126738518476486,
        "seek": 44894,
        "start": 467.22,
        "temperature": 0,
        "text": " after watching these videos.",
        "tokens": [
          51278,
          934,
          1976,
          613,
          2145,
          13,
          51342
        ]
      },
      {
        "avg_logprob": -0.2680535614490509,
        "compression_ratio": 1.6724738675958188,
        "end": 470.62,
        "id": 176,
        "no_speech_prob": 0.048126738518476486,
        "seek": 44894,
        "start": 468.5,
        "temperature": 0,
        "text": " And then I hope you'll share them with me on Twitter",
        "tokens": [
          51342,
          400,
          550,
          286,
          1454,
          291,
          603,
          2073,
          552,
          365,
          385,
          322,
          5794,
          51448
        ]
      },
      {
        "avg_logprob": -0.2680535614490509,
        "compression_ratio": 1.6724738675958188,
        "end": 472.86,
        "id": 177,
        "no_speech_prob": 0.048126738518476486,
        "seek": 44894,
        "start": 470.62,
        "temperature": 0,
        "text": " at Schiffman, or you can subscribe to the Patreon",
        "tokens": [
          51448,
          412,
          2065,
          3661,
          1601,
          11,
          420,
          291,
          393,
          3022,
          281,
          264,
          15692,
          51560
        ]
      },
      {
        "avg_logprob": -0.2680535614490509,
        "compression_ratio": 1.6724738675958188,
        "end": 476.94,
        "id": 178,
        "no_speech_prob": 0.048126738518476486,
        "seek": 44894,
        "start": 472.86,
        "temperature": 0,
        "text": " to post your work in Slack as well.",
        "tokens": [
          51560,
          281,
          2183,
          428,
          589,
          294,
          37211,
          382,
          731,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.4526272381053251,
        "compression_ratio": 0.8490566037735849,
        "end": 482.26,
        "id": 179,
        "no_speech_prob": 0.00021992367692291737,
        "seek": 47694,
        "start": 476.94,
        "temperature": 0,
        "text": " OK, so I will see you guys in the next video.",
        "tokens": [
          50364,
          2264,
          11,
          370,
          286,
          486,
          536,
          291,
          1074,
          294,
          264,
          958,
          960,
          13,
          50630
        ]
      }
    ],
    "transcription": " Hello. Welcome to session six, or week six. I don't know, are you doing this every day, every week, every month? This could be year six for you if you wanted it to be. But this is programming from A to Z. It's a set of tutorials, a kind of online course you could follow, all about programming and algorithms with text. Text. Language, text, words, letters, all that sort of stuff. So today, in this week's session, the focus will be about, the focus that I want to have is Markov chains. Whoa, what's a Markov chain? What's the deal? What's going on? So in the last session, I focused on something, the sort of topic of text analysis. So in last week, the idea was really exclusively about reading text in and analyzing it. Counting how many times different words appear, trying to think about how you might do sentiment analysis. What happens when a computer program reads in text? I want to turn now towards what happens when a computer program writes its own text. And there, of course, are many, many ways that you could do this. In next week's session, I'm going to look at something called a context-free grammar. In other sessions, I hope to look at some machine learning techniques for generating text, as well as other just kind of creative ideas for ways to mix and match and have a program put together text as if it's writing it. Now, one thing I should say about this week's topic of Markov chains is it, by definition, requires a source text from which to generate text. So this is something you'll see in a lot of these algorithms for generating text. They also include a reading text component. So now, a Markov chain is not something exclusive to the idea of text. And in fact, a Markov chain really just describes a sequence or a chain of states, like I am happy, I am sad, I am running. And I might typically, on any given day, be sad. And then I start running. And then I feel happy. And that's kind of my sequence. So with a Markov chain, looking at how certain states are sequenced and the probability of a given state following another state, we can use, we can evaluate sort of existing data. I can look and say, like, oh, what's the weather like today? What's the weather like tomorrow? What's the weather like the next day? Over a year, and try to use that to either predict the new weather or to recreate a simulation of weather based on the sequence of states. So this is something I'll look at in more detail in the next video. But there's a piece of that, which is, if I want to apply this idea of a Markov chain to text, what I want is for the characters or words of a piece of text to be states. For example, the state is I. The next state is M. The next state is feeling. The next state is like dancing. So those are states. And whenever I say M, I usually say feeling. And then whenever I say feeling, I usually say like. But I might say, the other day, I'm feeling like eating some kale salad or something like that, too. So this is quite possibly the worst explanation of Markov chains ever on the internet. But you can skip to the next video, where I'm sure it will make a lot of sense. But a piece of evaluating the statistical properties of characters and words, how they appear next to each other, is this idea of an n-gram. So this will also be a piece of the example that I build today of, how do we look at a body of text and look at this idea of n-grams? Now, Google has this massive treasure trove repository of text, corpuses of text from 1800 all the way up until present day. And you can search for the frequency of certain n-grams. So these are what might be called bigrams, meaning two, computer science, creative code, creative writing. We could think of other ones like IM. And I could search for any of these bigrams and their frequency in text. And we can see that, first of all, computer science started to appear more and more frequently in starting in the 1960s. You can see a more consistent amount of IM. You can see creative writing, creative code down here. So this is a way of looking at how, and we can look at trigrams, n-grams with an order, an order of four, the order referring to the number. And you can do creative projects with this. So here's a great project by Chris Harrison called Web Trigrams, Visualizing Google's Trigram Data. And we can see here, if we just look at this PDF, and I'm going to zoom into it so you can see, you can see here that in this project, Chris is visualizing all the words that tend to follow he, and then from there, all the words that tend to follow that. So another, I think these are some nice examples to look at. And you can kind of hear, imagine now, I have a, I am not, I was not, I do not, I can a. So you can sort of see the frequencies of these sequences. And if you can evaluate those frequencies, you can use those frequencies as probabilities from which to generate new text. So here's an example of a project made by Alison Parrish. The Interactive Telecommunications Program is a program at ITP. It's called IT, it's a program at ITP. It is ITP. It's where I teach. And we have courses every spring. And what Alison did is read all of the courses into a program, look at all the statistical properties of all the characters and words and how they appear next to each other, and use that to generate new courses. So I'm going to, let's find one that looks good. The Anthropologies of Virtual Design Workshop, MIDI and Cinematic Objects. This course, constraints of weekly sessions beyond exercises and inspire the possible. So this sounds great. I think I'll take that course. This is another example of a project called King James Programming. And these are posts generated by a Markov chain that has mixed several different input texts. The King James Bible, Structured Interpretation of Computer Programs, and some of Eric S. Raymond's writings run by Michael Walker. So you can see here, these are different things that are generated from that. Exercise 3.67 addresses why we want a local variable rather than a simple map as in the days of Herod the King. OK, so there's a lot of possibilities for how you might use Markov chains for a creative output. And on the one hand, this is nothing new. This has been done and done and done and done again. This idea of reading in a source text, evaluate the probabilities on a character or word-based level, and I'll talk about that as I implement the code in the next video. And then text generating out of that. You could make a Twitter bot that generates text based on a Markov chain. So I think there's value, and hopefully you might enjoy exploring the idea. And you might even just take the examples that I provide and find your own source text in. But I think for you to think about what is the reason why you might do this, where might it fit into an existing project. I hear a walkie talkie. I want to. And come up with some creative possibilities. So in the next video, I'm going to focus on the code. How to write the code to implement a Markov generator. I'm going to go through it entirely from scratch. And then I'm going to show you a few additional examples and then come back with some exercise ideas for things that you might want to try doing yourself after watching these videos. And then I hope you'll share them with me on Twitter at Schiffman, or you can subscribe to the Patreon to post your work in Slack as well. OK, so I will see you guys in the next video.",
    "translation": null
  },
  "error": null,
  "status": "succeeded",
  "created_at": "2023-09-26T20:41:45.250673Z",
  "started_at": "2023-09-26T20:49:13.616957Z",
  "completed_at": "2023-09-26T20:51:06.844882Z",
  "webhook": "https://83ceaa0b612c.ngrok.app/?video_id=v4kL0OHuxXs",
  "webhook_events_filter": [
    "completed"
  ],
  "metrics": {
    "predict_time": 113.227925
  },
  "urls": {
    "cancel": "https://api.replicate.com/v1/predictions/yrmtdlzb4cfnecctakk5zzrgdm/cancel",
    "get": "https://api.replicate.com/v1/predictions/yrmtdlzb4cfnecctakk5zzrgdm"
  }
}