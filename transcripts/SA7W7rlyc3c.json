{
  "id": "kjhg4jrbjyz5rgs3dvbxreggxu",
  "version": "91ee9c0c3df30478510ff8c8a3a545add1ad0259ad3a9f78fba57fbc05ee64f7",
  "input": {
    "audio": "https://upcdn.io/FW25b4F/raw/coding-train/SA7W7rlyc3c.m4a"
  },
  "logs": "Transcribe with large-v2 model\nDetected language: English\n  0%|          | 0/900007 [00:00<?, ?frames/s]\n  0%|          | 3000/900007 [00:01<06:20, 2357.68frames/s]\n  1%|          | 6000/900007 [00:01<04:21, 3418.72frames/s]\n  1%|          | 9000/900007 [00:02<03:42, 4000.71frames/s]\n  1%|▏         | 12000/900007 [00:03<03:46, 3923.40frames/s]\n  2%|▏         | 15000/900007 [00:04<03:45, 3925.67frames/s]\n  2%|▏         | 18000/900007 [00:08<09:40, 1518.64frames/s]\n  2%|▏         | 21000/900007 [00:09<07:59, 1834.84frames/s]\n  3%|▎         | 24000/900007 [00:09<06:23, 2282.98frames/s]\n  3%|▎         | 27000/900007 [00:10<05:12, 2794.89frames/s]\n  3%|▎         | 30000/900007 [00:11<04:35, 3155.68frames/s]\n  4%|▎         | 33000/900007 [00:11<04:10, 3463.44frames/s]\n  4%|▍         | 36000/900007 [00:12<03:54, 3680.69frames/s]\n  4%|▍         | 37600/900007 [00:13<04:25, 3251.70frames/s]\n  5%|▍         | 40600/900007 [00:15<06:47, 2107.71frames/s]\n  5%|▍         | 43464/900007 [00:22<15:18, 932.55frames/s] \n  5%|▌         | 46176/900007 [00:28<20:21, 698.81frames/s]\n  5%|▌         | 48824/900007 [00:35<24:29, 579.27frames/s]\n  6%|▌         | 51280/900007 [00:40<26:22, 536.46frames/s]\n  6%|▌         | 54040/900007 [00:45<26:19, 535.46frames/s]\n  6%|▋         | 56988/900007 [00:53<29:43, 472.79frames/s]\n  7%|▋         | 59560/900007 [00:58<29:37, 472.85frames/s]\n  7%|▋         | 62196/900007 [01:04<30:15, 461.49frames/s]\n  7%|▋         | 65196/900007 [01:13<32:37, 426.55frames/s]\n  8%|▊         | 68076/900007 [01:18<30:32, 454.03frames/s]\n  8%|▊         | 70536/900007 [01:22<28:32, 484.43frames/s]\n  8%|▊         | 73040/900007 [01:27<28:33, 482.75frames/s]\n  8%|▊         | 75844/900007 [01:31<25:16, 543.31frames/s]\n  9%|▊         | 78572/900007 [01:37<26:08, 523.74frames/s]\n  9%|▉         | 81196/900007 [01:43<27:42, 492.46frames/s]\n  9%|▉         | 83792/900007 [01:49<29:03, 468.16frames/s]\n 10%|▉         | 86432/900007 [01:56<30:24, 445.99frames/s]\n 10%|▉         | 88824/900007 [02:01<29:59, 450.73frames/s]\n 10%|█         | 91800/900007 [02:07<29:46, 452.39frames/s]\n 10%|█         | 94480/900007 [02:13<29:22, 457.08frames/s]\n 11%|█         | 97212/900007 [02:19<29:23, 455.22frames/s]\n 11%|█         | 99988/900007 [02:25<29:21, 454.07frames/s]\n 11%|█▏        | 102684/900007 [02:30<27:30, 483.21frames/s]\n 12%|█▏        | 105212/900007 [02:37<29:23, 450.79frames/s]\n 12%|█▏        | 107488/900007 [02:41<28:53, 457.11frames/s]\n 12%|█▏        | 107488/900007 [02:56<28:53, 457.11frames/s]\n 12%|█▏        | 110242/900007 [03:09<1:01:00, 215.75frames/s]\n 13%|█▎        | 113242/900007 [03:13<46:16, 283.39frames/s]  \n 13%|█▎        | 115878/900007 [03:18<40:06, 325.90frames/s]\n 13%|█▎        | 118448/900007 [03:24<37:29, 347.51frames/s]\n 13%|█▎        | 120838/900007 [03:30<36:05, 359.76frames/s]\n 14%|█▎        | 123678/900007 [03:36<33:05, 391.05frames/s]\n 14%|█▍        | 126494/900007 [03:42<31:17, 411.94frames/s]\n 14%|█▍        | 129194/900007 [03:48<29:50, 430.52frames/s]\n 15%|█▍        | 131678/900007 [03:54<30:07, 425.01frames/s]\n 15%|█▍        | 134306/900007 [04:00<30:48, 414.13frames/s]\n 15%|█▌        | 137242/900007 [04:08<31:12, 407.41frames/s]\n 15%|█▌        | 139390/900007 [04:12<29:38, 427.75frames/s]\n 16%|█▌        | 141758/900007 [04:18<30:06, 419.64frames/s]\n 16%|█▌        | 144430/900007 [04:23<28:46, 437.64frames/s]\n 16%|█▋        | 147430/900007 [04:30<27:57, 448.64frames/s]\n 17%|█▋        | 150146/900007 [04:35<26:03, 479.74frames/s]\n 17%|█▋        | 153146/900007 [04:40<24:52, 500.40frames/s]\n 17%|█▋        | 156146/900007 [04:41<17:51, 694.26frames/s]\n 18%|█▊        | 159146/900007 [04:47<20:39, 597.47frames/s]\n 18%|█▊        | 161634/900007 [04:53<22:29, 547.12frames/s]\n 18%|█▊        | 164262/900007 [04:59<24:50, 493.64frames/s]\n 19%|█▊        | 166886/900007 [05:06<25:53, 471.91frames/s]\n 19%|█▉        | 169886/900007 [05:10<23:25, 519.53frames/s]\n 19%|█▉        | 172422/900007 [05:16<23:59, 505.40frames/s]\n 19%|█▉        | 174986/900007 [05:23<27:21, 441.60frames/s]\n 20%|█▉        | 177374/900007 [05:27<25:28, 472.68frames/s]\n 20%|█▉        | 179850/900007 [05:32<24:04, 498.72frames/s]\n 20%|██        | 182442/900007 [05:38<26:06, 458.15frames/s]\n 21%|██        | 185442/900007 [05:47<28:34, 416.87frames/s]\n 21%|██        | 188442/900007 [05:54<28:00, 423.44frames/s]\n 21%|██▏       | 191252/900007 [05:58<25:24, 464.86frames/s]\n 22%|██▏       | 194252/900007 [06:05<25:22, 463.40frames/s]\n 22%|██▏       | 197064/900007 [06:10<23:39, 495.31frames/s]\n 22%|██▏       | 199836/900007 [06:14<21:53, 533.16frames/s]\n 23%|██▎       | 202596/900007 [06:19<22:23, 518.95frames/s]\n 23%|██▎       | 205596/900007 [06:26<23:39, 489.25frames/s]\n 23%|██▎       | 208596/900007 [06:32<22:25, 513.83frames/s]\n 23%|██▎       | 211172/900007 [06:37<23:25, 490.10frames/s]\n 24%|██▎       | 212968/900007 [06:41<23:28, 487.95frames/s]\n 24%|██▍       | 215968/900007 [06:44<18:42, 609.14frames/s]\n 24%|██▍       | 218120/900007 [06:46<16:36, 683.94frames/s]\n 24%|██▍       | 220416/900007 [06:48<15:13, 743.63frames/s]\n 25%|██▍       | 223416/900007 [06:52<14:55, 755.19frames/s]\n 25%|██▌       | 226416/900007 [06:55<13:44, 817.15frames/s]\n 25%|██▌       | 228804/900007 [06:58<13:42, 815.74frames/s]\n 26%|██▌       | 231804/900007 [07:01<12:27, 894.04frames/s]\n 26%|██▌       | 234728/900007 [07:06<14:14, 778.41frames/s]\n 26%|██▋       | 237728/900007 [07:10<14:49, 744.39frames/s]\n 27%|██▋       | 240728/900007 [07:12<12:12, 900.46frames/s]\n 27%|██▋       | 242860/900007 [07:14<11:58, 914.40frames/s]\n 27%|██▋       | 245464/900007 [07:16<10:53, 1001.66frames/s]\n 28%|██▊       | 247688/900007 [07:17<09:47, 1109.43frames/s]\n 28%|██▊       | 250688/900007 [07:20<10:10, 1063.43frames/s]\n 28%|██▊       | 253688/900007 [07:22<08:34, 1255.31frames/s]\n 28%|██▊       | 255356/900007 [07:24<09:54, 1084.90frames/s]\n 29%|██▊       | 258356/900007 [07:26<08:22, 1276.61frames/s]\n 29%|██▉       | 261356/900007 [07:30<10:24, 1022.60frames/s]\n 29%|██▉       | 264356/900007 [07:33<10:44, 986.80frames/s] \n 30%|██▉       | 266872/900007 [07:36<10:48, 975.87frames/s]\n 30%|██▉       | 269504/900007 [07:40<11:54, 883.05frames/s]\n 30%|███       | 272504/900007 [07:42<10:43, 975.24frames/s]\n 31%|███       | 275504/900007 [07:45<10:43, 970.11frames/s]\n 31%|███       | 278204/900007 [07:50<12:55, 801.82frames/s]\n 31%|███       | 281204/900007 [07:55<14:24, 715.53frames/s]\n 32%|███▏      | 284204/900007 [07:58<13:15, 773.70frames/s]\n 32%|███▏      | 287204/900007 [08:00<11:06, 919.37frames/s]\n 32%|███▏      | 290204/900007 [08:05<12:33, 808.96frames/s]\n 33%|███▎      | 292708/900007 [08:09<13:57, 724.94frames/s]\n 33%|███▎      | 295332/900007 [08:13<14:30, 694.86frames/s]\n 33%|███▎      | 297836/900007 [08:16<13:14, 758.22frames/s]\n 33%|███▎      | 300616/900007 [08:19<12:33, 795.83frames/s]\n 34%|███▎      | 303316/900007 [08:23<13:12, 752.55frames/s]\n 34%|███▍      | 304244/900007 [08:25<13:31, 734.56frames/s]\n 34%|███▍      | 307244/900007 [08:35<20:39, 478.34frames/s]\n 34%|███▍      | 309156/900007 [08:37<18:15, 539.22frames/s]\n 35%|███▍      | 311624/900007 [08:39<15:08, 647.89frames/s]\n 35%|███▍      | 313740/900007 [08:40<11:59, 814.96frames/s]\n 35%|███▌      | 315460/900007 [08:42<11:28, 849.34frames/s]\n 35%|███▌      | 317916/900007 [08:42<08:32, 1136.81frames/s]\n 36%|███▌      | 320692/900007 [08:44<07:12, 1338.90frames/s]\n 36%|███▌      | 322012/900007 [08:46<08:27, 1138.57frames/s]\n 36%|███▌      | 324220/900007 [08:47<07:48, 1229.64frames/s]\n 36%|███▌      | 325748/900007 [08:50<10:02, 953.50frames/s] \n 36%|███▋      | 328144/900007 [08:52<09:33, 996.85frames/s]\n 37%|███▋      | 330988/900007 [08:59<14:24, 658.52frames/s]\n 37%|███▋      | 332176/900007 [09:00<14:11, 666.88frames/s]\n 37%|███▋      | 334728/900007 [09:02<11:15, 836.59frames/s]\n 37%|███▋      | 337036/900007 [09:04<09:54, 946.44frames/s]\n 38%|███▊      | 339880/900007 [09:08<10:45, 867.27frames/s]\n 38%|███▊      | 341640/900007 [09:13<14:40, 634.05frames/s]\n 38%|███▊      | 344020/900007 [09:15<12:58, 714.38frames/s]\n 38%|███▊      | 346076/900007 [09:19<13:56, 662.17frames/s]\n 39%|███▉      | 349012/900007 [09:21<11:21, 808.37frames/s]\n 39%|███▉      | 351712/900007 [09:23<09:43, 939.92frames/s]\n 39%|███▉      | 354608/900007 [09:25<08:37, 1054.56frames/s]\n 40%|███▉      | 356944/900007 [09:27<08:47, 1029.64frames/s]\n 40%|███▉      | 359468/900007 [09:31<10:22, 869.00frames/s] \n 40%|████      | 361884/900007 [09:37<13:02, 687.36frames/s]\n 40%|████      | 363636/900007 [09:39<12:16, 727.81frames/s]\n 41%|████      | 364880/900007 [09:41<13:00, 685.32frames/s]\n 41%|████      | 366760/900007 [09:43<11:42, 758.85frames/s]\n 41%|████      | 369500/900007 [09:45<10:00, 883.37frames/s]\n 41%|████      | 370920/900007 [09:48<11:22, 775.03frames/s]\n 41%|████▏     | 372260/900007 [09:50<12:38, 696.12frames/s]\n 42%|████▏     | 375260/900007 [09:52<09:17, 940.84frames/s]\n 42%|████▏     | 377140/900007 [09:55<10:47, 807.12frames/s]\n 42%|████▏     | 380140/900007 [09:57<08:46, 986.52frames/s]\n 42%|████▏     | 381980/900007 [09:58<07:59, 1081.13frames/s]\n 43%|████▎     | 384980/900007 [10:00<07:12, 1192.16frames/s]\n 43%|████▎     | 386980/900007 [10:03<07:56, 1075.70frames/s]\n 43%|████▎     | 389080/900007 [10:05<08:33, 995.64frames/s] \n 44%|████▎     | 391580/900007 [10:08<08:38, 980.01frames/s]\n 44%|████▎     | 392280/900007 [10:10<10:09, 833.17frames/s]\n 44%|████▍     | 394480/900007 [10:12<10:10, 828.45frames/s]\n 44%|████▍     | 395480/900007 [10:14<10:59, 764.46frames/s]\n 44%|████▍     | 397280/900007 [10:15<09:06, 920.21frames/s]\n 44%|████▍     | 399480/900007 [10:17<08:37, 967.96frames/s]\n 45%|████▍     | 400680/900007 [10:19<09:37, 864.00frames/s]\n 45%|████▍     | 402080/900007 [10:22<11:06, 746.73frames/s]\n 45%|████▍     | 403480/900007 [10:24<11:32, 717.11frames/s]\n 45%|████▌     | 406280/900007 [10:26<08:28, 970.74frames/s]\n 45%|████▌     | 407480/900007 [10:28<09:54, 828.50frames/s]\n 45%|████▌     | 409380/900007 [10:30<09:57, 821.49frames/s]\n 46%|████▌     | 411580/900007 [10:32<09:18, 875.30frames/s]\n 46%|████▌     | 413280/900007 [10:35<10:32, 769.92frames/s]\n 46%|████▌     | 415580/900007 [10:40<12:41, 636.47frames/s]\n 46%|████▋     | 416580/900007 [10:43<14:18, 563.11frames/s]\n 47%|████▋     | 419280/900007 [10:46<12:39, 633.32frames/s]\n 47%|████▋     | 421880/900007 [10:50<12:24, 642.53frames/s]\n 47%|████▋     | 424780/900007 [10:53<10:11, 777.51frames/s]\n 47%|████▋     | 426380/900007 [10:56<11:25, 691.26frames/s]\n 48%|████▊     | 428580/900007 [10:59<11:27, 686.02frames/s]\n 48%|████▊     | 430980/900007 [11:04<12:27, 627.74frames/s]\n 48%|████▊     | 433180/900007 [11:08<13:38, 570.21frames/s]\n 48%|████▊     | 436180/900007 [11:14<13:46, 561.26frames/s]\n 49%|████▉     | 439180/900007 [11:19<13:27, 570.55frames/s]\n 49%|████▉     | 441280/900007 [11:22<13:15, 576.45frames/s]\n 49%|████▉     | 443780/900007 [11:28<14:26, 526.59frames/s]\n 50%|████▉     | 446480/900007 [11:33<14:16, 529.77frames/s]\n 50%|████▉     | 449280/900007 [11:38<13:50, 542.97frames/s]\n 50%|█████     | 451780/900007 [11:45<15:59, 467.29frames/s]\n 50%|█████     | 454180/900007 [11:50<15:27, 480.69frames/s]\n 50%|█████     | 454180/900007 [12:06<15:27, 480.69frames/s]\n 51%|█████     | 456080/900007 [12:06<27:01, 273.76frames/s]\n 51%|█████     | 456080/900007 [12:26<27:01, 273.76frames/s]\n 51%|█████     | 458180/900007 [12:31<44:11, 166.61frames/s]\n 51%|█████     | 458180/900007 [12:46<44:11, 166.61frames/s]\n 51%|█████     | 461180/900007 [13:09<1:01:28, 118.96frames/s]\n 52%|█████▏    | 464180/900007 [13:10<40:52, 177.69frames/s]  \n 52%|█████▏    | 467080/900007 [13:18<33:30, 215.31frames/s]\n 52%|█████▏    | 469480/900007 [13:24<29:04, 246.78frames/s]\n 52%|█████▏    | 472080/900007 [13:28<24:00, 297.03frames/s]\n 53%|█████▎    | 474780/900007 [13:33<20:22, 347.71frames/s]\n 53%|█████▎    | 477180/900007 [13:38<18:44, 375.95frames/s]\n 53%|█████▎    | 478980/900007 [13:42<17:59, 389.99frames/s]\n 53%|█████▎    | 481380/900007 [13:46<16:06, 433.14frames/s]\n 54%|█████▍    | 483980/900007 [13:52<16:20, 424.19frames/s]\n 54%|█████▍    | 486280/900007 [13:58<15:58, 431.56frames/s]\n 54%|█████▍    | 488080/900007 [14:01<15:27, 444.27frames/s]\n 55%|█████▍    | 490980/900007 [14:07<14:15, 478.03frames/s]\n 55%|█████▍    | 493880/900007 [14:15<16:01, 422.53frames/s]\n 55%|█████▌    | 496280/900007 [14:21<16:35, 405.65frames/s]\n 55%|█████▌    | 498880/900007 [14:28<16:38, 401.55frames/s]\n 56%|█████▌    | 501880/900007 [14:31<12:56, 513.05frames/s]\n 56%|█████▌    | 504480/900007 [14:41<16:43, 394.29frames/s]\n 56%|█████▋    | 507180/900007 [14:45<14:35, 448.87frames/s]\n 57%|█████▋    | 509980/900007 [14:51<14:09, 459.29frames/s]\n 57%|█████▋    | 511980/900007 [14:56<14:56, 432.99frames/s]\n 57%|█████▋    | 514680/900007 [15:01<13:27, 477.32frames/s]\n 57%|█████▋    | 517280/900007 [15:06<13:10, 484.09frames/s]\n 58%|█████▊    | 520180/900007 [15:14<14:44, 429.56frames/s]\n 58%|█████▊    | 522380/900007 [15:20<15:03, 417.77frames/s]\n 58%|█████▊    | 525280/900007 [15:25<13:48, 452.55frames/s]\n 59%|█████▊    | 527580/900007 [15:31<13:54, 446.51frames/s]\n 59%|█████▉    | 530180/900007 [15:36<13:20, 462.02frames/s]\n 59%|█████▉    | 532380/900007 [15:41<13:20, 459.29frames/s]\n 59%|█████▉    | 534780/900007 [15:45<12:17, 495.29frames/s]\n 60%|█████▉    | 537280/900007 [15:48<10:44, 563.02frames/s]\n 60%|█████▉    | 539880/900007 [15:50<09:06, 659.50frames/s]\n 60%|██████    | 542480/900007 [15:54<09:18, 639.62frames/s]\n 61%|██████    | 544980/900007 [16:01<11:15, 525.65frames/s]\n 61%|██████    | 547380/900007 [16:05<10:28, 560.62frames/s]\n 61%|██████    | 550380/900007 [16:08<08:48, 661.20frames/s]\n 61%|██████▏   | 553380/900007 [16:11<08:09, 708.28frames/s]\n 62%|██████▏   | 555480/900007 [16:14<07:45, 740.83frames/s]\n 62%|██████▏   | 558380/900007 [16:17<07:28, 762.29frames/s]\n 62%|██████▏   | 561380/900007 [16:21<07:16, 775.58frames/s]\n 63%|██████▎   | 564080/900007 [16:26<08:14, 679.43frames/s]\n 63%|██████▎   | 566780/900007 [16:31<08:29, 653.69frames/s]\n 63%|██████▎   | 569780/900007 [16:35<08:14, 667.19frames/s]\n 64%|██████▎   | 572280/900007 [16:40<08:39, 631.05frames/s]\n 64%|██████▍   | 575080/900007 [16:44<08:35, 629.73frames/s]\n 64%|██████▍   | 577780/900007 [16:49<09:02, 594.30frames/s]\n 64%|██████▍   | 580480/900007 [16:54<08:58, 593.21frames/s]\n 65%|██████▍   | 583080/900007 [16:58<08:59, 587.92frames/s]\n 65%|██████▌   | 585880/900007 [17:01<07:55, 660.95frames/s]\n 65%|██████▌   | 587480/900007 [17:03<07:36, 684.56frames/s]\n 66%|██████▌   | 589680/900007 [17:06<07:01, 736.81frames/s]\n 66%|██████▌   | 592080/900007 [17:09<07:11, 714.08frames/s]\n 66%|██████▌   | 595080/900007 [17:15<08:03, 631.20frames/s]\n 66%|██████▋   | 597680/900007 [17:20<08:10, 615.91frames/s]\n 67%|██████▋   | 600280/900007 [17:26<09:18, 536.29frames/s]\n 67%|██████▋   | 602980/900007 [17:32<09:57, 496.94frames/s]\n 67%|██████▋   | 605980/900007 [17:36<08:47, 557.05frames/s]\n 68%|██████▊   | 608880/900007 [17:42<08:49, 549.41frames/s]\n 68%|██████▊   | 611880/900007 [17:45<07:38, 628.64frames/s]\n 68%|██████▊   | 614880/900007 [17:46<05:51, 811.21frames/s]\n 69%|██████▊   | 617380/900007 [17:50<06:18, 747.57frames/s]\n 69%|██████▉   | 619180/900007 [17:52<05:48, 805.64frames/s]\n 69%|██████▉   | 619180/900007 [18:06<05:48, 805.64frames/s]\n 69%|██████▉   | 620880/900007 [18:14<18:15, 254.71frames/s]\n 69%|██████▉   | 620880/900007 [18:26<18:15, 254.71frames/s]\n 69%|██████▉   | 623780/900007 [19:01<38:08, 120.70frames/s]\n 70%|██████▉   | 626780/900007 [19:04<26:11, 173.86frames/s]\n 70%|██████▉   | 628580/900007 [19:05<20:59, 215.46frames/s]\n 70%|███████   | 631180/900007 [19:09<16:10, 276.90frames/s]\n 70%|███████   | 633980/900007 [19:15<13:43, 322.86frames/s]\n 71%|███████   | 636880/900007 [19:22<12:36, 347.90frames/s]\n 71%|███████   | 639180/900007 [19:26<11:00, 394.86frames/s]\n 71%|███████▏  | 641280/900007 [19:27<08:58, 480.06frames/s]\n 71%|███████▏  | 642780/900007 [19:31<09:00, 475.91frames/s]\n 72%|███████▏  | 644980/900007 [19:34<08:00, 530.25frames/s]\n 72%|███████▏  | 646780/900007 [19:36<07:23, 571.28frames/s]\n 72%|███████▏  | 649780/900007 [19:37<05:07, 814.00frames/s]\n 72%|███████▏  | 652080/900007 [19:41<05:28, 754.90frames/s]\n 73%|███████▎  | 654780/900007 [19:47<06:46, 603.27frames/s]\n 73%|███████▎  | 656980/900007 [19:49<06:03, 669.18frames/s]\n 73%|███████▎  | 659780/900007 [19:52<05:10, 774.18frames/s]\n 74%|███████▎  | 662780/900007 [19:55<04:37, 853.59frames/s]\n 74%|███████▍  | 664480/900007 [19:56<04:25, 886.47frames/s]\n 74%|███████▍  | 667480/900007 [19:59<03:47, 1021.29frames/s]\n 74%|███████▍  | 670380/900007 [20:03<04:38, 823.10frames/s] \n 75%|███████▍  | 673080/900007 [20:08<05:18, 713.35frames/s]\n 75%|███████▌  | 675080/900007 [20:12<05:34, 672.69frames/s]\n 75%|███████▌  | 677780/900007 [20:14<04:38, 797.53frames/s]\n 75%|███████▌  | 678880/900007 [20:16<04:51, 758.73frames/s]\n 76%|███████▌  | 681780/900007 [20:17<03:31, 1034.05frames/s]\n 76%|███████▌  | 684180/900007 [20:19<03:35, 999.38frames/s] \n 76%|███████▋  | 686780/900007 [20:23<04:05, 868.57frames/s]\n 77%|███████▋  | 689480/900007 [20:30<05:26, 645.67frames/s]\n 77%|███████▋  | 692180/900007 [20:35<05:45, 600.97frames/s]\n 77%|███████▋  | 695080/900007 [20:39<05:28, 624.14frames/s]\n 78%|███████▊  | 697580/900007 [20:44<05:44, 587.02frames/s]\n 78%|███████▊  | 699980/900007 [20:50<06:12, 537.20frames/s]\n 78%|███████▊  | 702880/900007 [20:54<05:47, 567.68frames/s]\n 78%|███████▊  | 705580/900007 [20:58<05:35, 578.97frames/s]\n 79%|███████▊  | 708280/900007 [21:04<05:57, 537.02frames/s]\n 79%|███████▉  | 711180/900007 [21:10<05:55, 531.89frames/s]\n 79%|███████▉  | 714080/900007 [21:13<05:11, 596.16frames/s]\n 80%|███████▉  | 716180/900007 [21:17<05:04, 604.53frames/s]\n 80%|███████▉  | 718780/900007 [21:19<04:06, 734.76frames/s]\n 80%|████████  | 721480/900007 [21:22<03:55, 757.43frames/s]\n 80%|████████  | 723480/900007 [21:25<04:13, 697.27frames/s]\n 81%|████████  | 725680/900007 [21:27<03:29, 831.67frames/s]\n 81%|████████  | 728580/900007 [21:31<03:32, 804.85frames/s]\n 81%|████████▏ | 731380/900007 [21:35<03:54, 718.37frames/s]\n 82%|████████▏ | 733680/900007 [21:38<03:47, 731.21frames/s]\n 82%|████████▏ | 736280/900007 [21:41<03:21, 812.84frames/s]\n 82%|████████▏ | 739080/900007 [21:45<03:32, 758.16frames/s]\n 82%|████████▏ | 741880/900007 [21:48<03:09, 832.79frames/s]\n 83%|████████▎ | 744580/900007 [21:52<03:20, 773.76frames/s]\n 83%|████████▎ | 746480/900007 [21:54<03:22, 756.30frames/s]\n 83%|████████▎ | 748880/900007 [21:56<02:43, 924.19frames/s]\n 84%|████████▎ | 751780/900007 [22:00<03:05, 800.43frames/s]\n 84%|████████▍ | 754180/900007 [22:03<02:53, 842.12frames/s]\n 84%|████████▍ | 757180/900007 [22:05<02:23, 994.23frames/s]\n 84%|████████▍ | 759680/900007 [22:07<02:17, 1021.12frames/s]\n 85%|████████▍ | 762580/900007 [22:10<02:21, 967.83frames/s] \n 85%|████████▌ | 765480/900007 [22:13<02:11, 1020.09frames/s]\n 85%|████████▌ | 768280/900007 [22:17<02:28, 888.55frames/s] \n 86%|████████▌ | 771080/900007 [22:21<02:36, 824.13frames/s]\n 86%|████████▌ | 773780/900007 [22:26<02:54, 724.53frames/s]\n 86%|████████▋ | 776680/900007 [22:29<02:41, 765.14frames/s]\n 87%|████████▋ | 779480/900007 [22:33<02:37, 765.93frames/s]\n 87%|████████▋ | 781480/900007 [22:35<02:28, 796.11frames/s]\n 87%|████████▋ | 784480/900007 [22:37<02:07, 907.09frames/s]\n 87%|████████▋ | 787280/900007 [22:39<01:46, 1057.53frames/s]\n 88%|████████▊ | 789580/900007 [22:41<01:49, 1009.55frames/s]\n 88%|████████▊ | 792180/900007 [22:45<02:03, 871.18frames/s] \n 88%|████████▊ | 794780/900007 [22:48<01:58, 888.61frames/s]\n 89%|████████▊ | 796980/900007 [22:51<02:01, 847.68frames/s]\n 89%|████████▉ | 799280/900007 [22:54<02:04, 811.38frames/s]\n 89%|████████▉ | 800980/900007 [22:57<02:05, 786.04frames/s]\n 89%|████████▉ | 801980/900007 [22:58<02:13, 734.89frames/s]\n 89%|████████▉ | 801980/900007 [23:16<02:13, 734.89frames/s]\n 89%|████████▉ | 804680/900007 [23:22<06:38, 239.23frames/s]\n 90%|████████▉ | 807380/900007 [23:24<04:31, 341.34frames/s]\n 90%|████████▉ | 809980/900007 [23:28<03:49, 392.78frames/s]\n 90%|█████████ | 812580/900007 [23:32<03:14, 449.61frames/s]\n 91%|█████████ | 815180/900007 [23:35<02:38, 533.99frames/s]\n 91%|█████████ | 817380/900007 [23:37<02:12, 621.68frames/s]\n 91%|█████████ | 819880/900007 [23:41<02:06, 630.94frames/s]\n 91%|█████████▏| 822780/900007 [23:45<01:57, 659.95frames/s]\n 92%|█████████▏| 825480/900007 [23:50<02:00, 617.82frames/s]\n 92%|█████████▏| 828080/900007 [23:54<01:57, 612.47frames/s]\n 92%|█████████▏| 830580/900007 [23:57<01:45, 655.45frames/s]\n 93%|█████████▎| 833480/900007 [24:03<01:48, 614.61frames/s]\n 93%|█████████▎| 836280/900007 [24:07<01:43, 613.88frames/s]\n 93%|█████████▎| 839080/900007 [24:12<01:42, 593.36frames/s]\n 94%|█████████▎| 841980/900007 [24:18<01:41, 571.04frames/s]\n 94%|█████████▍| 844780/900007 [24:23<01:38, 560.54frames/s]\n 94%|█████████▍| 847480/900007 [24:27<01:30, 578.47frames/s]\n 94%|█████████▍| 847480/900007 [24:46<01:30, 578.47frames/s]\n 94%|█████████▍| 848280/900007 [25:54<11:38, 74.04frames/s] \n 95%|█████████▍| 850780/900007 [25:58<07:52, 104.21frames/s]\n 95%|█████████▍| 853580/900007 [26:01<05:06, 151.48frames/s]\n 95%|█████████▍| 853580/900007 [26:16<05:06, 151.48frames/s]\n 95%|█████████▌| 856580/900007 [26:18<04:34, 158.20frames/s]\n 96%|█████████▌| 859580/900007 [26:19<02:55, 230.36frames/s]\n 96%|█████████▌| 862580/900007 [26:20<01:54, 325.87frames/s]\n 96%|█████████▌| 862580/900007 [26:36<01:54, 325.87frames/s]\n 96%|█████████▌| 865480/900007 [26:45<02:43, 210.89frames/s]\n 96%|█████████▋| 866480/900007 [26:48<02:32, 220.37frames/s]\n 96%|█████████▋| 867480/900007 [26:49<02:10, 250.12frames/s]\n 97%|█████████▋| 869480/900007 [26:51<01:32, 330.75frames/s]\n 97%|█████████▋| 871480/900007 [26:53<01:07, 423.93frames/s]\n 97%|█████████▋| 873880/900007 [26:54<00:44, 585.24frames/s]\n 97%|█████████▋| 876680/900007 [26:59<00:41, 564.83frames/s]\n 98%|█████████▊| 879480/900007 [27:06<00:39, 514.20frames/s]\n 98%|█████████▊| 881380/900007 [27:08<00:34, 546.97frames/s]\n 98%|█████████▊| 884380/900007 [27:09<00:19, 795.68frames/s]\n 98%|█████████▊| 884380/900007 [27:26<00:19, 795.68frames/s]\n98%|█████████▊| 884380/900007 [27:56<00:29, 527.55frames/s]\n",
  "output": {
    "detected_language": "english",
    "segments": [
      {
        "avg_logprob": -0.8667041659355164,
        "compression_ratio": 0.2727272727272727,
        "end": 2,
        "id": 0,
        "no_speech_prob": 0.6644379496574402,
        "seek": 0,
        "start": 0,
        "temperature": 0.2,
        "text": " You",
        "tokens": [
          50364,
          509,
          50464
        ]
      },
      {
        "avg_logprob": -0.47675395011901855,
        "compression_ratio": 0.2,
        "end": 32,
        "id": 1,
        "no_speech_prob": 0.5098243355751038,
        "seek": 3000,
        "start": 30,
        "temperature": 0,
        "text": " Do",
        "tokens": [
          50364,
          1144,
          50464
        ]
      },
      {
        "avg_logprob": -0.32919061183929443,
        "compression_ratio": 0.2,
        "end": 62,
        "id": 2,
        "no_speech_prob": 0.5262969136238098,
        "seek": 6000,
        "start": 60,
        "temperature": 0,
        "text": " Do",
        "tokens": [
          50364,
          1144,
          50464
        ]
      },
      {
        "avg_logprob": -0.7103438377380371,
        "compression_ratio": 0.38461538461538464,
        "end": 92,
        "id": 3,
        "no_speech_prob": 0.4411148130893707,
        "seek": 9000,
        "start": 90,
        "temperature": 0,
        "text": " Do",
        "tokens": [
          50364,
          1144,
          50464
        ]
      },
      {
        "avg_logprob": -0.7103438377380371,
        "compression_ratio": 0.38461538461538464,
        "end": 108,
        "id": 4,
        "no_speech_prob": 0.4411148130893707,
        "seek": 9000,
        "start": 106,
        "temperature": 0,
        "text": " Do",
        "tokens": [
          51164,
          1144,
          51264
        ]
      },
      {
        "avg_logprob": -0.35556530952453613,
        "compression_ratio": 0.38461538461538464,
        "end": 122,
        "id": 5,
        "no_speech_prob": 0.2041058987379074,
        "seek": 12000,
        "start": 120,
        "temperature": 0,
        "text": " Do",
        "tokens": [
          50364,
          1144,
          50464
        ]
      },
      {
        "avg_logprob": -0.35556530952453613,
        "compression_ratio": 0.38461538461538464,
        "end": 136,
        "id": 6,
        "no_speech_prob": 0.2041058987379074,
        "seek": 12000,
        "start": 134,
        "temperature": 0,
        "text": " Do",
        "tokens": [
          51064,
          1144,
          51164
        ]
      },
      {
        "avg_logprob": -0.3879661560058594,
        "compression_ratio": 1.569377990430622,
        "end": 156.88,
        "id": 7,
        "no_speech_prob": 0.05888158082962036,
        "seek": 15000,
        "start": 150.5,
        "temperature": 0,
        "text": " Hello test one two, I hope my audio is coming through please let me know in the chat",
        "tokens": [
          50389,
          2425,
          1500,
          472,
          732,
          11,
          286,
          1454,
          452,
          6278,
          307,
          1348,
          807,
          1767,
          718,
          385,
          458,
          294,
          264,
          5081,
          50708
        ]
      },
      {
        "avg_logprob": -0.3879661560058594,
        "compression_ratio": 1.569377990430622,
        "end": 160.24,
        "id": 8,
        "no_speech_prob": 0.05888158082962036,
        "seek": 15000,
        "start": 158.8,
        "temperature": 0,
        "text": " Discord",
        "tokens": [
          50804,
          32623,
          50876
        ]
      },
      {
        "avg_logprob": -0.3879661560058594,
        "compression_ratio": 1.569377990430622,
        "end": 161.96,
        "id": 9,
        "no_speech_prob": 0.05888158082962036,
        "seek": 15000,
        "start": 160.24,
        "temperature": 0,
        "text": " in YouTube",
        "tokens": [
          50876,
          294,
          3088,
          50962
        ]
      },
      {
        "avg_logprob": -0.3879661560058594,
        "compression_ratio": 1.569377990430622,
        "end": 167.92000000000002,
        "id": 10,
        "no_speech_prob": 0.05888158082962036,
        "seek": 15000,
        "start": 161.96,
        "temperature": 0,
        "text": " By carrier pigeon smoke signal however you could possibly reach me, please",
        "tokens": [
          50962,
          3146,
          17574,
          37886,
          8439,
          6358,
          4461,
          291,
          727,
          6264,
          2524,
          385,
          11,
          1767,
          51260
        ]
      },
      {
        "avg_logprob": -0.3879661560058594,
        "compression_ratio": 1.569377990430622,
        "end": 173.2,
        "id": 11,
        "no_speech_prob": 0.05888158082962036,
        "seek": 15000,
        "start": 168.6,
        "temperature": 0,
        "text": " Let me know apologies for all the stops and starts today",
        "tokens": [
          51294,
          961,
          385,
          458,
          34929,
          337,
          439,
          264,
          10094,
          293,
          3719,
          965,
          51524
        ]
      },
      {
        "avg_logprob": -0.3879661560058594,
        "compression_ratio": 1.569377990430622,
        "end": 179.44,
        "id": 12,
        "no_speech_prob": 0.05888158082962036,
        "seek": 15000,
        "start": 173.2,
        "temperature": 0,
        "text": " I will be beginning in just a few minutes assuming my audio is coming through loud and clear",
        "tokens": [
          51524,
          286,
          486,
          312,
          2863,
          294,
          445,
          257,
          1326,
          2077,
          11926,
          452,
          6278,
          307,
          1348,
          807,
          6588,
          293,
          1850,
          51836
        ]
      },
      {
        "avg_logprob": -0.5646544969998873,
        "compression_ratio": 0.7948717948717948,
        "end": 182,
        "id": 13,
        "no_speech_prob": 0.016621313989162445,
        "seek": 18000,
        "start": 180,
        "temperature": 0,
        "text": " Okay. See you in a moment",
        "tokens": [
          50364,
          1033,
          13,
          3008,
          291,
          294,
          257,
          1623,
          50464
        ]
      },
      {
        "avg_logprob": -0.5646544969998873,
        "compression_ratio": 0.7948717948717948,
        "end": 207.2,
        "id": 14,
        "no_speech_prob": 0.016621313989162445,
        "seek": 18000,
        "start": 205.2,
        "temperature": 0,
        "text": " Hello",
        "tokens": [
          51624,
          2425,
          51724
        ]
      },
      {
        "avg_logprob": -0.7354933420817057,
        "compression_ratio": 0.6521739130434783,
        "end": 212,
        "id": 15,
        "no_speech_prob": 0.17883965373039246,
        "seek": 21000,
        "start": 210,
        "temperature": 0,
        "text": " Moment you both",
        "tokens": [
          50364,
          19093,
          291,
          1293,
          50464
        ]
      },
      {
        "avg_logprob": -0.5321133732795715,
        "compression_ratio": 0.2,
        "end": 242,
        "id": 16,
        "no_speech_prob": 0.42258745431900024,
        "seek": 24000,
        "start": 240,
        "temperature": 0,
        "text": " Do",
        "tokens": [
          50364,
          1144,
          50464
        ]
      },
      {
        "avg_logprob": -0.7385545458112445,
        "compression_ratio": 0.38461538461538464,
        "end": 272,
        "id": 17,
        "no_speech_prob": 0.29640477895736694,
        "seek": 27000,
        "start": 270,
        "temperature": 0,
        "text": " Do",
        "tokens": [
          50364,
          1144,
          50464
        ]
      },
      {
        "avg_logprob": -0.7385545458112445,
        "compression_ratio": 0.38461538461538464,
        "end": 286,
        "id": 18,
        "no_speech_prob": 0.29640477895736694,
        "seek": 27000,
        "start": 284,
        "temperature": 0,
        "text": " Do",
        "tokens": [
          51064,
          1144,
          51164
        ]
      },
      {
        "avg_logprob": -0.49454808235168457,
        "compression_ratio": 0.38461538461538464,
        "end": 302,
        "id": 19,
        "no_speech_prob": 0.13271468877792358,
        "seek": 30000,
        "start": 300,
        "temperature": 0,
        "text": " Do",
        "tokens": [
          50364,
          1144,
          50464
        ]
      },
      {
        "avg_logprob": -0.49454808235168457,
        "compression_ratio": 0.38461538461538464,
        "end": 316,
        "id": 20,
        "no_speech_prob": 0.13271468877792358,
        "seek": 30000,
        "start": 314,
        "temperature": 0,
        "text": " Do",
        "tokens": [
          51064,
          1144,
          51164
        ]
      },
      {
        "avg_logprob": -0.28629796845572336,
        "compression_ratio": 0.38461538461538464,
        "end": 332,
        "id": 21,
        "no_speech_prob": 0.10677789151668549,
        "seek": 33000,
        "start": 330,
        "temperature": 0,
        "text": " Do",
        "tokens": [
          50364,
          1144,
          50464
        ]
      },
      {
        "avg_logprob": -0.28629796845572336,
        "compression_ratio": 0.38461538461538464,
        "end": 352,
        "id": 22,
        "no_speech_prob": 0.10677789151668549,
        "seek": 33000,
        "start": 350,
        "temperature": 0,
        "text": " Do",
        "tokens": [
          51364,
          1144,
          51464
        ]
      },
      {
        "avg_logprob": -0.3191847801208496,
        "compression_ratio": 0.38461538461538464,
        "end": 362,
        "id": 23,
        "no_speech_prob": 0.08592984825372696,
        "seek": 36000,
        "start": 360,
        "temperature": 0,
        "text": " Do",
        "tokens": [
          50364,
          1144,
          50464
        ]
      },
      {
        "avg_logprob": -0.3191847801208496,
        "compression_ratio": 0.38461538461538464,
        "end": 376,
        "id": 24,
        "no_speech_prob": 0.08592984825372696,
        "seek": 36000,
        "start": 374,
        "temperature": 0,
        "text": " Do",
        "tokens": [
          51064,
          1144,
          51164
        ]
      },
      {
        "avg_logprob": -0.39244265889012536,
        "compression_ratio": 1.4298245614035088,
        "end": 378,
        "id": 25,
        "no_speech_prob": 0.008965679444372654,
        "seek": 37600,
        "start": 376,
        "temperature": 0,
        "text": " Do",
        "tokens": [
          50364,
          1144,
          50464
        ]
      },
      {
        "avg_logprob": -0.39244265889012536,
        "compression_ratio": 1.4298245614035088,
        "end": 391,
        "id": 26,
        "no_speech_prob": 0.008965679444372654,
        "seek": 37600,
        "start": 389,
        "temperature": 0,
        "text": " Hello happy Saturday",
        "tokens": [
          51014,
          2425,
          2055,
          8803,
          51114
        ]
      },
      {
        "avg_logprob": -0.39244265889012536,
        "compression_ratio": 1.4298245614035088,
        "end": 398.4,
        "id": 27,
        "no_speech_prob": 0.008965679444372654,
        "seek": 37600,
        "start": 393.92,
        "temperature": 0,
        "text": " Welcome to the coding train with me minor internet personality",
        "tokens": [
          51260,
          4027,
          281,
          264,
          17720,
          3847,
          365,
          385,
          6696,
          4705,
          9033,
          51484
        ]
      },
      {
        "avg_logprob": -0.39244265889012536,
        "compression_ratio": 1.4298245614035088,
        "end": 404.76,
        "id": 28,
        "no_speech_prob": 0.008965679444372654,
        "seek": 37600,
        "start": 400.28,
        "temperature": 0,
        "text": " I am the host of the coding train. I'm coding train. I am coming to you live",
        "tokens": [
          51578,
          286,
          669,
          264,
          3975,
          295,
          264,
          17720,
          3847,
          13,
          286,
          478,
          17720,
          3847,
          13,
          286,
          669,
          1348,
          281,
          291,
          1621,
          51802
        ]
      },
      {
        "avg_logprob": -0.2857733113425119,
        "compression_ratio": 1.819277108433735,
        "end": 412.48,
        "id": 29,
        "no_speech_prob": 0.03449534997344017,
        "seek": 40600,
        "start": 406.32,
        "temperature": 0,
        "text": " I know it's some kind of miracle that I'm here right now. I don't know how this is gonna last I",
        "tokens": [
          50380,
          286,
          458,
          309,
          311,
          512,
          733,
          295,
          14660,
          300,
          286,
          478,
          510,
          558,
          586,
          13,
          286,
          500,
          380,
          458,
          577,
          341,
          307,
          799,
          1036,
          286,
          50688
        ]
      },
      {
        "avg_logprob": -0.2857733113425119,
        "compression_ratio": 1.819277108433735,
        "end": 416.12,
        "id": 30,
        "no_speech_prob": 0.03449534997344017,
        "seek": 40600,
        "start": 413.28,
        "temperature": 0,
        "text": " Better just very quickly say thank you to",
        "tokens": [
          50728,
          15753,
          445,
          588,
          2661,
          584,
          1309,
          291,
          281,
          50870
        ]
      },
      {
        "avg_logprob": -0.2857733113425119,
        "compression_ratio": 1.819277108433735,
        "end": 419.84,
        "id": 31,
        "no_speech_prob": 0.03449534997344017,
        "seek": 40600,
        "start": 416.76,
        "temperature": 0,
        "text": " Curiosity stream for sponsoring today's live stream",
        "tokens": [
          50902,
          48998,
          4309,
          337,
          30311,
          965,
          311,
          1621,
          4309,
          51056
        ]
      },
      {
        "avg_logprob": -0.2857733113425119,
        "compression_ratio": 1.819277108433735,
        "end": 426.48,
        "id": 32,
        "no_speech_prob": 0.03449534997344017,
        "seek": 40600,
        "start": 419.84,
        "temperature": 0,
        "text": " You can get access to all the documentaries amazing documentaries on curiosity stream as well as the nebula",
        "tokens": [
          51056,
          509,
          393,
          483,
          2105,
          281,
          439,
          264,
          41630,
          2243,
          41630,
          322,
          18769,
          4309,
          382,
          731,
          382,
          264,
          408,
          37775,
          51388
        ]
      },
      {
        "avg_logprob": -0.2857733113425119,
        "compression_ratio": 1.819277108433735,
        "end": 431.28,
        "id": 33,
        "no_speech_prob": 0.03449534997344017,
        "seek": 40600,
        "start": 427.2,
        "temperature": 0,
        "text": " Everything that's on nebula. Can I tell you about something that's on nebula right now?",
        "tokens": [
          51424,
          5471,
          300,
          311,
          322,
          408,
          37775,
          13,
          1664,
          286,
          980,
          291,
          466,
          746,
          300,
          311,
          322,
          408,
          37775,
          558,
          586,
          30,
          51628
        ]
      },
      {
        "avg_logprob": -0.2857733113425119,
        "compression_ratio": 1.819277108433735,
        "end": 434.64,
        "id": 34,
        "no_speech_prob": 0.03449534997344017,
        "seek": 40600,
        "start": 431.52,
        "temperature": 0,
        "text": " Let me tell you something that's on nebula right now. Hold on a sec",
        "tokens": [
          51640,
          961,
          385,
          980,
          291,
          746,
          300,
          311,
          322,
          408,
          37775,
          558,
          586,
          13,
          6962,
          322,
          257,
          907,
          51796
        ]
      },
      {
        "avg_logprob": -0.25282819083567415,
        "compression_ratio": 1.6033755274261603,
        "end": 440.24,
        "id": 35,
        "no_speech_prob": 0.0004653017094824463,
        "seek": 43464,
        "start": 435.56,
        "temperature": 0,
        "text": " On nebula right now is let's go to my library right here. Look at this",
        "tokens": [
          50410,
          1282,
          408,
          37775,
          558,
          586,
          307,
          718,
          311,
          352,
          281,
          452,
          6405,
          558,
          510,
          13,
          2053,
          412,
          341,
          50644
        ]
      },
      {
        "avg_logprob": -0.25282819083567415,
        "compression_ratio": 1.6033755274261603,
        "end": 447.4,
        "id": 36,
        "no_speech_prob": 0.0004653017094824463,
        "seek": 43464,
        "start": 440.76,
        "temperature": 0,
        "text": " This particular video which is going to come out probably hopefully by tomorrow on YouTube still finishing it up",
        "tokens": [
          50670,
          639,
          1729,
          960,
          597,
          307,
          516,
          281,
          808,
          484,
          1391,
          4696,
          538,
          4153,
          322,
          3088,
          920,
          12693,
          309,
          493,
          51002
        ]
      },
      {
        "avg_logprob": -0.25282819083567415,
        "compression_ratio": 1.6033755274261603,
        "end": 452.8,
        "id": 37,
        "no_speech_prob": 0.0004653017094824463,
        "seek": 43464,
        "start": 447.4,
        "temperature": 0,
        "text": " But if you want to get some early access to this particular video along with all sorts of other amazing stuff",
        "tokens": [
          51002,
          583,
          498,
          291,
          528,
          281,
          483,
          512,
          2440,
          2105,
          281,
          341,
          1729,
          960,
          2051,
          365,
          439,
          7527,
          295,
          661,
          2243,
          1507,
          51272
        ]
      },
      {
        "avg_logprob": -0.25282819083567415,
        "compression_ratio": 1.6033755274261603,
        "end": 457.76,
        "id": 38,
        "no_speech_prob": 0.0004653017094824463,
        "seek": 43464,
        "start": 452.8,
        "temperature": 0,
        "text": " You can get you can sign up the whole year of curiosity stream and nebula",
        "tokens": [
          51272,
          509,
          393,
          483,
          291,
          393,
          1465,
          493,
          264,
          1379,
          1064,
          295,
          18769,
          4309,
          293,
          408,
          37775,
          51520
        ]
      },
      {
        "avg_logprob": -0.25282819083567415,
        "compression_ratio": 1.6033755274261603,
        "end": 461.76,
        "id": 39,
        "no_speech_prob": 0.0004653017094824463,
        "seek": 43464,
        "start": 459.76,
        "temperature": 0,
        "text": " At that link",
        "tokens": [
          51620,
          1711,
          300,
          2113,
          51720
        ]
      },
      {
        "avg_logprob": -0.3287856976191203,
        "compression_ratio": 1.5,
        "end": 465.59999999999997,
        "id": 40,
        "no_speech_prob": 0.01363563071936369,
        "seek": 46176,
        "start": 462.08,
        "temperature": 0,
        "text": " 26% off I think that's $14 and 79 cents for the whole year",
        "tokens": [
          50380,
          7551,
          4,
          766,
          286,
          519,
          300,
          311,
          1848,
          7271,
          293,
          32803,
          14941,
          337,
          264,
          1379,
          1064,
          50556
        ]
      },
      {
        "avg_logprob": -0.3287856976191203,
        "compression_ratio": 1.5,
        "end": 472.96,
        "id": 41,
        "no_speech_prob": 0.01363563071936369,
        "seek": 46176,
        "start": 466.32,
        "temperature": 0,
        "text": " Amazing amazing. You should totally check out all the documentaries and all the YouTube creators that are on nebula. Okay",
        "tokens": [
          50592,
          14165,
          2243,
          13,
          509,
          820,
          3879,
          1520,
          484,
          439,
          264,
          41630,
          293,
          439,
          264,
          3088,
          16039,
          300,
          366,
          322,
          408,
          37775,
          13,
          1033,
          50924
        ]
      },
      {
        "avg_logprob": -0.3287856976191203,
        "compression_ratio": 1.5,
        "end": 478.88,
        "id": 42,
        "no_speech_prob": 0.01363563071936369,
        "seek": 46176,
        "start": 475.76,
        "temperature": 0,
        "text": " The stream still working so at least I got that out",
        "tokens": [
          51064,
          440,
          4309,
          920,
          1364,
          370,
          412,
          1935,
          286,
          658,
          300,
          484,
          51220
        ]
      },
      {
        "avg_logprob": -0.3287856976191203,
        "compression_ratio": 1.5,
        "end": 481.68,
        "id": 43,
        "no_speech_prob": 0.01363563071936369,
        "seek": 46176,
        "start": 479.88,
        "temperature": 0,
        "text": " And what am I here to do today?",
        "tokens": [
          51270,
          400,
          437,
          669,
          286,
          510,
          281,
          360,
          965,
          30,
          51360
        ]
      },
      {
        "avg_logprob": -0.3287856976191203,
        "compression_ratio": 1.5,
        "end": 488.24,
        "id": 44,
        "no_speech_prob": 0.01363563071936369,
        "seek": 46176,
        "start": 481.68,
        "temperature": 0,
        "text": " Well, if you might remember a week or so ago and I'm just checking the chat here to see if people are watching",
        "tokens": [
          51360,
          1042,
          11,
          498,
          291,
          1062,
          1604,
          257,
          1243,
          420,
          370,
          2057,
          293,
          286,
          478,
          445,
          8568,
          264,
          5081,
          510,
          281,
          536,
          498,
          561,
          366,
          1976,
          51688
        ]
      },
      {
        "avg_logprob": -0.32011089554752215,
        "compression_ratio": 1.511737089201878,
        "end": 493.88,
        "id": 45,
        "no_speech_prob": 0.0212849210947752,
        "seek": 48824,
        "start": 488.84000000000003,
        "temperature": 0,
        "text": " I'm not seeing any messages, which is a little bit weird if I'm being perfectly honest",
        "tokens": [
          50394,
          286,
          478,
          406,
          2577,
          604,
          7897,
          11,
          597,
          307,
          257,
          707,
          857,
          3657,
          498,
          286,
          478,
          885,
          6239,
          3245,
          50646
        ]
      },
      {
        "avg_logprob": -0.32011089554752215,
        "compression_ratio": 1.511737089201878,
        "end": 497.40000000000003,
        "id": 46,
        "no_speech_prob": 0.0212849210947752,
        "seek": 48824,
        "start": 493.96000000000004,
        "temperature": 0,
        "text": " so hopefully I'm not just speaking into a vacuum, but",
        "tokens": [
          50650,
          370,
          4696,
          286,
          478,
          406,
          445,
          4124,
          666,
          257,
          14224,
          11,
          457,
          50822
        ]
      },
      {
        "avg_logprob": -0.32011089554752215,
        "compression_ratio": 1.511737089201878,
        "end": 503.8,
        "id": 47,
        "no_speech_prob": 0.0212849210947752,
        "seek": 48824,
        "start": 498.84000000000003,
        "temperature": 0,
        "text": " I've been working on a project to create an auto encoder using",
        "tokens": [
          50894,
          286,
          600,
          668,
          1364,
          322,
          257,
          1716,
          281,
          1884,
          364,
          8399,
          2058,
          19866,
          1228,
          51142
        ]
      },
      {
        "avg_logprob": -0.32011089554752215,
        "compression_ratio": 1.511737089201878,
        "end": 510.40000000000003,
        "id": 48,
        "no_speech_prob": 0.0212849210947752,
        "seek": 48824,
        "start": 504.16,
        "temperature": 0,
        "text": " JavaScript with the tensorflow.js library library in node.js and I would like to finish that today",
        "tokens": [
          51160,
          15778,
          365,
          264,
          40863,
          10565,
          13,
          25530,
          6405,
          6405,
          294,
          9984,
          13,
          25530,
          293,
          286,
          576,
          411,
          281,
          2413,
          300,
          965,
          51472
        ]
      },
      {
        "avg_logprob": -0.32011089554752215,
        "compression_ratio": 1.511737089201878,
        "end": 512.8,
        "id": 49,
        "no_speech_prob": 0.0212849210947752,
        "seek": 48824,
        "start": 511.12,
        "temperature": 0,
        "text": " So this is part two",
        "tokens": [
          51508,
          407,
          341,
          307,
          644,
          732,
          51592
        ]
      },
      {
        "avg_logprob": -0.303542744029652,
        "compression_ratio": 1.5378486055776892,
        "end": 520.76,
        "id": 50,
        "no_speech_prob": 0.05833745375275612,
        "seek": 51280,
        "start": 512.8,
        "temperature": 0,
        "text": " If you were looking for part one if I come back to here, I really don't see any chat messages very strange",
        "tokens": [
          50364,
          759,
          291,
          645,
          1237,
          337,
          644,
          472,
          498,
          286,
          808,
          646,
          281,
          510,
          11,
          286,
          534,
          500,
          380,
          536,
          604,
          5081,
          7897,
          588,
          5861,
          50762
        ]
      },
      {
        "avg_logprob": -0.303542744029652,
        "compression_ratio": 1.5378486055776892,
        "end": 528.9599999999999,
        "id": 51,
        "no_speech_prob": 0.05833745375275612,
        "seek": 51280,
        "start": 522.5999999999999,
        "temperature": 0,
        "text": " Okay code Melanik says hi I'm cars waves, okay people are there you're there. Oh, thank goodness",
        "tokens": [
          50854,
          1033,
          3089,
          7375,
          282,
          1035,
          1619,
          4879,
          286,
          478,
          5163,
          9417,
          11,
          1392,
          561,
          366,
          456,
          291,
          434,
          456,
          13,
          876,
          11,
          1309,
          8387,
          51172
        ]
      },
      {
        "avg_logprob": -0.303542744029652,
        "compression_ratio": 1.5378486055776892,
        "end": 536.7199999999999,
        "id": 52,
        "no_speech_prob": 0.05833745375275612,
        "seek": 51280,
        "start": 529.92,
        "temperature": 0,
        "text": " Not very many of you probably because I've totally botched this in the sense that I was supposed to stream this morning at 10 a.m",
        "tokens": [
          51220,
          1726,
          588,
          867,
          295,
          291,
          1391,
          570,
          286,
          600,
          3879,
          10592,
          19318,
          341,
          294,
          264,
          2020,
          300,
          286,
          390,
          3442,
          281,
          4309,
          341,
          2446,
          412,
          1266,
          257,
          13,
          76,
          51560
        ]
      },
      {
        "avg_logprob": -0.303542744029652,
        "compression_ratio": 1.5378486055776892,
        "end": 540.4,
        "id": 53,
        "no_speech_prob": 0.05833745375275612,
        "seek": 51280,
        "start": 536.7199999999999,
        "temperature": 0,
        "text": " And I had scheduled it. I'm using discord events now",
        "tokens": [
          51560,
          400,
          286,
          632,
          15678,
          309,
          13,
          286,
          478,
          1228,
          32989,
          3931,
          586,
          51744
        ]
      },
      {
        "avg_logprob": -0.27726733590674213,
        "compression_ratio": 1.6948051948051948,
        "end": 544.8,
        "id": 54,
        "no_speech_prob": 0.13475030660629272,
        "seek": 54040,
        "start": 540.4,
        "temperature": 0,
        "text": " So you should sign up for the coding train discord somebody post that link into the chat",
        "tokens": [
          50364,
          407,
          291,
          820,
          1465,
          493,
          337,
          264,
          17720,
          3847,
          32989,
          2618,
          2183,
          300,
          2113,
          666,
          264,
          5081,
          50584
        ]
      },
      {
        "avg_logprob": -0.27726733590674213,
        "compression_ratio": 1.6948051948051948,
        "end": 550.4,
        "id": 55,
        "no_speech_prob": 0.13475030660629272,
        "seek": 54040,
        "start": 545.12,
        "temperature": 0,
        "text": " And then I make an event and you know what time and you can like register your interest you'll get a reminder all the things",
        "tokens": [
          50600,
          400,
          550,
          286,
          652,
          364,
          2280,
          293,
          291,
          458,
          437,
          565,
          293,
          291,
          393,
          411,
          7280,
          428,
          1179,
          291,
          603,
          483,
          257,
          13548,
          439,
          264,
          721,
          50864
        ]
      },
      {
        "avg_logprob": -0.27726733590674213,
        "compression_ratio": 1.6948051948051948,
        "end": 557.1999999999999,
        "id": 56,
        "no_speech_prob": 0.13475030660629272,
        "seek": 54040,
        "start": 550.4,
        "temperature": 0,
        "text": " I've always been wanting for wanting to have and then I was like, no, I can't stream because my internet wasn't working. I",
        "tokens": [
          50864,
          286,
          600,
          1009,
          668,
          7935,
          337,
          7935,
          281,
          362,
          293,
          550,
          286,
          390,
          411,
          11,
          572,
          11,
          286,
          393,
          380,
          4309,
          570,
          452,
          4705,
          2067,
          380,
          1364,
          13,
          286,
          51204
        ]
      },
      {
        "avg_logprob": -0.27726733590674213,
        "compression_ratio": 1.6948051948051948,
        "end": 561.72,
        "id": 57,
        "no_speech_prob": 0.13475030660629272,
        "seek": 54040,
        "start": 557.92,
        "temperature": 0,
        "text": " Am in a garage, which is a detached garage from my main house",
        "tokens": [
          51240,
          2012,
          294,
          257,
          14400,
          11,
          597,
          307,
          257,
          42050,
          14400,
          490,
          452,
          2135,
          1782,
          51430
        ]
      },
      {
        "avg_logprob": -0.27726733590674213,
        "compression_ratio": 1.6948051948051948,
        "end": 567.4399999999999,
        "id": 58,
        "no_speech_prob": 0.13475030660629272,
        "seek": 54040,
        "start": 561.72,
        "temperature": 0,
        "text": " Which is where my new studio is and I'm gonna be here all the time every day all day starting in January",
        "tokens": [
          51430,
          3013,
          307,
          689,
          452,
          777,
          6811,
          307,
          293,
          286,
          478,
          799,
          312,
          510,
          439,
          264,
          565,
          633,
          786,
          439,
          786,
          2891,
          294,
          7061,
          51716
        ]
      },
      {
        "avg_logprob": -0.27726733590674213,
        "compression_ratio": 1.6948051948051948,
        "end": 569.88,
        "id": 59,
        "no_speech_prob": 0.13475030660629272,
        "seek": 54040,
        "start": 567.88,
        "temperature": 0,
        "text": " 2022 lots of plans",
        "tokens": [
          51738,
          20229,
          3195,
          295,
          5482,
          51838
        ]
      },
      {
        "avg_logprob": -0.39562365652500897,
        "compression_ratio": 1.7156862745098038,
        "end": 572.4399999999999,
        "id": 60,
        "no_speech_prob": 0.000984826823696494,
        "seek": 56988,
        "start": 569.88,
        "temperature": 0,
        "text": " so I'm working on getting this place wired and",
        "tokens": [
          50364,
          370,
          286,
          478,
          1364,
          322,
          1242,
          341,
          1081,
          27415,
          293,
          50492
        ]
      },
      {
        "avg_logprob": -0.39562365652500897,
        "compression_ratio": 1.7156862745098038,
        "end": 575.84,
        "id": 61,
        "no_speech_prob": 0.000984826823696494,
        "seek": 56988,
        "start": 573.84,
        "temperature": 0,
        "text": " powered by solar energy",
        "tokens": [
          50562,
          17786,
          538,
          7936,
          2281,
          50662
        ]
      },
      {
        "avg_logprob": -0.39562365652500897,
        "compression_ratio": 1.7156862745098038,
        "end": 578.28,
        "id": 62,
        "no_speech_prob": 0.000984826823696494,
        "seek": 56988,
        "start": 576.28,
        "temperature": 0,
        "text": " so",
        "tokens": [
          50684,
          370,
          50784
        ]
      },
      {
        "avg_logprob": -0.39562365652500897,
        "compression_ratio": 1.7156862745098038,
        "end": 584.16,
        "id": 63,
        "no_speech_prob": 0.000984826823696494,
        "seek": 56988,
        "start": 579.04,
        "temperature": 0,
        "text": " Disconnected now when I say I am obviously I heard people to do a lot of this work",
        "tokens": [
          50822,
          4208,
          9826,
          292,
          586,
          562,
          286,
          584,
          286,
          669,
          2745,
          286,
          2198,
          561,
          281,
          360,
          257,
          688,
          295,
          341,
          589,
          51078
        ]
      },
      {
        "avg_logprob": -0.39562365652500897,
        "compression_ratio": 1.7156862745098038,
        "end": 590.52,
        "id": 64,
        "no_speech_prob": 0.000984826823696494,
        "seek": 56988,
        "start": 584.64,
        "temperature": 0,
        "text": " But the electric electrics was disconnected to this building and then a trend we dug a trench",
        "tokens": [
          51102,
          583,
          264,
          5210,
          7072,
          1167,
          390,
          29426,
          281,
          341,
          2390,
          293,
          550,
          257,
          6028,
          321,
          22954,
          257,
          39052,
          51396
        ]
      },
      {
        "avg_logprob": -0.39562365652500897,
        "compression_ratio": 1.7156862745098038,
        "end": 595.6,
        "id": 65,
        "no_speech_prob": 0.000984826823696494,
        "seek": 56988,
        "start": 590.88,
        "temperature": 0,
        "text": " To wire electric to the house so they could put solar panels here to power the house and the garage",
        "tokens": [
          51414,
          1407,
          6234,
          5210,
          281,
          264,
          1782,
          370,
          436,
          727,
          829,
          7936,
          13419,
          510,
          281,
          1347,
          264,
          1782,
          293,
          264,
          14400,
          51650
        ]
      },
      {
        "avg_logprob": -0.30665578647535674,
        "compression_ratio": 1.6008230452674896,
        "end": 598.5600000000001,
        "id": 66,
        "no_speech_prob": 0.06952321529388428,
        "seek": 59560,
        "start": 595.8000000000001,
        "temperature": 0,
        "text": " Ran coax and cat5 underground",
        "tokens": [
          50374,
          27948,
          598,
          2797,
          293,
          3857,
          20,
          14977,
          50512
        ]
      },
      {
        "avg_logprob": -0.30665578647535674,
        "compression_ratio": 1.6008230452674896,
        "end": 604.5600000000001,
        "id": 67,
        "no_speech_prob": 0.06952321529388428,
        "seek": 59560,
        "start": 599.12,
        "temperature": 0,
        "text": " Put it in a splitter so I can have internet in both and for whatever reason I can't get internet and both to work",
        "tokens": [
          50540,
          4935,
          309,
          294,
          257,
          4732,
          3904,
          370,
          286,
          393,
          362,
          4705,
          294,
          1293,
          293,
          337,
          2035,
          1778,
          286,
          393,
          380,
          483,
          4705,
          293,
          1293,
          281,
          589,
          50812
        ]
      },
      {
        "avg_logprob": -0.30665578647535674,
        "compression_ratio": 1.6008230452674896,
        "end": 608.9200000000001,
        "id": 68,
        "no_speech_prob": 0.06952321529388428,
        "seek": 59560,
        "start": 604.88,
        "temperature": 0,
        "text": " And I discovered that if I just turn off",
        "tokens": [
          50828,
          400,
          286,
          6941,
          300,
          498,
          286,
          445,
          1261,
          766,
          51030
        ]
      },
      {
        "avg_logprob": -0.30665578647535674,
        "compression_ratio": 1.6008230452674896,
        "end": 613.28,
        "id": 69,
        "no_speech_prob": 0.06952321529388428,
        "seek": 59560,
        "start": 609.72,
        "temperature": 0,
        "text": " The internet to the house right now. It seems to work here in the garage",
        "tokens": [
          51070,
          440,
          4705,
          281,
          264,
          1782,
          558,
          586,
          13,
          467,
          2544,
          281,
          589,
          510,
          294,
          264,
          14400,
          51248
        ]
      },
      {
        "avg_logprob": -0.30665578647535674,
        "compression_ratio": 1.6008230452674896,
        "end": 618.84,
        "id": 70,
        "no_speech_prob": 0.06952321529388428,
        "seek": 59560,
        "start": 613.28,
        "temperature": 0,
        "text": " So that's my temporary solution at least for today to get this live stream in on Saturday",
        "tokens": [
          51248,
          407,
          300,
          311,
          452,
          13413,
          3827,
          412,
          1935,
          337,
          965,
          281,
          483,
          341,
          1621,
          4309,
          294,
          322,
          8803,
          51526
        ]
      },
      {
        "avg_logprob": -0.30665578647535674,
        "compression_ratio": 1.6008230452674896,
        "end": 621.96,
        "id": 71,
        "no_speech_prob": 0.06952321529388428,
        "seek": 59560,
        "start": 619.2,
        "temperature": 0,
        "text": " November 20th and finish off this project",
        "tokens": [
          51544,
          7674,
          945,
          392,
          293,
          2413,
          766,
          341,
          1716,
          51682
        ]
      },
      {
        "avg_logprob": -0.26257844404740766,
        "compression_ratio": 1.6829268292682926,
        "end": 625.4000000000001,
        "id": 72,
        "no_speech_prob": 0.012428338639438152,
        "seek": 62196,
        "start": 621.96,
        "temperature": 0,
        "text": " I was trying to fig find where I was I was here to show you",
        "tokens": [
          50364,
          286,
          390,
          1382,
          281,
          2147,
          915,
          689,
          286,
          390,
          286,
          390,
          510,
          281,
          855,
          291,
          50536
        ]
      },
      {
        "avg_logprob": -0.26257844404740766,
        "compression_ratio": 1.6829268292682926,
        "end": 630.5600000000001,
        "id": 73,
        "no_speech_prob": 0.012428338639438152,
        "seek": 62196,
        "start": 625.84,
        "temperature": 0,
        "text": " Part one so this doesn't say part one, but you can see oh and look at this",
        "tokens": [
          50558,
          4100,
          472,
          370,
          341,
          1177,
          380,
          584,
          644,
          472,
          11,
          457,
          291,
          393,
          536,
          1954,
          293,
          574,
          412,
          341,
          50794
        ]
      },
      {
        "avg_logprob": -0.26257844404740766,
        "compression_ratio": 1.6829268292682926,
        "end": 635.64,
        "id": 74,
        "no_speech_prob": 0.012428338639438152,
        "seek": 62196,
        "start": 631.1600000000001,
        "temperature": 0,
        "text": " So this is also by the way available here. I just haven't released it yet. It should be out",
        "tokens": [
          50824,
          407,
          341,
          307,
          611,
          538,
          264,
          636,
          2435,
          510,
          13,
          286,
          445,
          2378,
          380,
          4736,
          309,
          1939,
          13,
          467,
          820,
          312,
          484,
          51048
        ]
      },
      {
        "avg_logprob": -0.26257844404740766,
        "compression_ratio": 1.6829268292682926,
        "end": 640.94,
        "id": 75,
        "no_speech_prob": 0.012428338639438152,
        "seek": 62196,
        "start": 636.4000000000001,
        "temperature": 0,
        "text": " Tomorrow I'm just got a lot of slowness here, but I'm logged into my account, which is why I see it",
        "tokens": [
          51086,
          17499,
          286,
          478,
          445,
          658,
          257,
          688,
          295,
          1061,
          648,
          442,
          510,
          11,
          457,
          286,
          478,
          27231,
          666,
          452,
          2696,
          11,
          597,
          307,
          983,
          286,
          536,
          309,
          51313
        ]
      },
      {
        "avg_logprob": -0.26257844404740766,
        "compression_ratio": 1.6829268292682926,
        "end": 647.6800000000001,
        "id": 76,
        "no_speech_prob": 0.012428338639438152,
        "seek": 62196,
        "start": 642.2800000000001,
        "temperature": 0,
        "text": " I'm very excited about this video. Can you please post the discord in the chat or I'm gonna go ahead and do that",
        "tokens": [
          51380,
          286,
          478,
          588,
          2919,
          466,
          341,
          960,
          13,
          1664,
          291,
          1767,
          2183,
          264,
          32989,
          294,
          264,
          5081,
          420,
          286,
          478,
          799,
          352,
          2286,
          293,
          360,
          300,
          51650
        ]
      },
      {
        "avg_logprob": -0.26257844404740766,
        "compression_ratio": 1.6829268292682926,
        "end": 651.44,
        "id": 77,
        "no_speech_prob": 0.012428338639438152,
        "seek": 62196,
        "start": 648.8000000000001,
        "temperature": 0,
        "text": " Since no one else got around to it just yet",
        "tokens": [
          51706,
          4162,
          572,
          472,
          1646,
          658,
          926,
          281,
          309,
          445,
          1939,
          51838
        ]
      },
      {
        "avg_logprob": -0.34139515104747953,
        "compression_ratio": 1.5235602094240839,
        "end": 656.72,
        "id": 78,
        "no_speech_prob": 0.00136696663685143,
        "seek": 65196,
        "start": 651.96,
        "temperature": 0,
        "text": " And I believe that should be oh my god. I posted the wrong link",
        "tokens": [
          50364,
          400,
          286,
          1697,
          300,
          820,
          312,
          1954,
          452,
          3044,
          13,
          286,
          9437,
          264,
          2085,
          2113,
          50602
        ]
      },
      {
        "avg_logprob": -0.34139515104747953,
        "compression_ratio": 1.5235602094240839,
        "end": 669.72,
        "id": 79,
        "no_speech_prob": 0.00136696663685143,
        "seek": 65196,
        "start": 664.2800000000001,
        "temperature": 0,
        "text": " Okay, it's discord.gg slash coding train, okay, so",
        "tokens": [
          50980,
          1033,
          11,
          309,
          311,
          32989,
          13,
          1615,
          17330,
          17720,
          3847,
          11,
          1392,
          11,
          370,
          51252
        ]
      },
      {
        "avg_logprob": -0.34139515104747953,
        "compression_ratio": 1.5235602094240839,
        "end": 674.4000000000001,
        "id": 80,
        "no_speech_prob": 0.00136696663685143,
        "seek": 65196,
        "start": 670.5600000000001,
        "temperature": 0,
        "text": " What was I looking for oh, so that's part one if you watch part one great",
        "tokens": [
          51294,
          708,
          390,
          286,
          1237,
          337,
          1954,
          11,
          370,
          300,
          311,
          644,
          472,
          498,
          291,
          1159,
          644,
          472,
          869,
          51486
        ]
      },
      {
        "avg_logprob": -0.34139515104747953,
        "compression_ratio": 1.5235602094240839,
        "end": 680.76,
        "id": 81,
        "no_speech_prob": 0.00136696663685143,
        "seek": 65196,
        "start": 674.6,
        "temperature": 0,
        "text": " You're in the right place if you didn't watch part one. Well. I'll recap it a little bit as I get into",
        "tokens": [
          51496,
          509,
          434,
          294,
          264,
          558,
          1081,
          498,
          291,
          994,
          380,
          1159,
          644,
          472,
          13,
          1042,
          13,
          286,
          603,
          20928,
          309,
          257,
          707,
          857,
          382,
          286,
          483,
          666,
          51804
        ]
      },
      {
        "avg_logprob": -0.39091688586819556,
        "compression_ratio": 1.5135135135135136,
        "end": 687.04,
        "id": 82,
        "no_speech_prob": 0.0014324752846732736,
        "seek": 68076,
        "start": 681.76,
        "temperature": 0,
        "text": " I'm working on the project so I need to find my way back to where I was before",
        "tokens": [
          50414,
          286,
          478,
          1364,
          322,
          264,
          1716,
          370,
          286,
          643,
          281,
          915,
          452,
          636,
          646,
          281,
          689,
          286,
          390,
          949,
          50678
        ]
      },
      {
        "avg_logprob": -0.39091688586819556,
        "compression_ratio": 1.5135135135135136,
        "end": 689.84,
        "id": 83,
        "no_speech_prob": 0.0014324752846732736,
        "seek": 68076,
        "start": 687.84,
        "temperature": 0,
        "text": " We open up processing",
        "tokens": [
          50718,
          492,
          1269,
          493,
          9007,
          50818
        ]
      },
      {
        "avg_logprob": -0.39091688586819556,
        "compression_ratio": 1.5135135135135136,
        "end": 694.9399999999999,
        "id": 84,
        "no_speech_prob": 0.0014324752846732736,
        "seek": 68076,
        "start": 690.92,
        "temperature": 0,
        "text": " Because I was using processing to generate the images that I want to",
        "tokens": [
          50872,
          1436,
          286,
          390,
          1228,
          9007,
          281,
          8460,
          264,
          5267,
          300,
          286,
          528,
          281,
          51073
        ]
      },
      {
        "avg_logprob": -0.39091688586819556,
        "compression_ratio": 1.5135135135135136,
        "end": 701.04,
        "id": 85,
        "no_speech_prob": 0.0014324752846732736,
        "seek": 68076,
        "start": 696.76,
        "temperature": 0,
        "text": " Use to train the model and",
        "tokens": [
          51164,
          8278,
          281,
          3847,
          264,
          2316,
          293,
          51378
        ]
      },
      {
        "avg_logprob": -0.39091688586819556,
        "compression_ratio": 1.5135135135135136,
        "end": 705.36,
        "id": 86,
        "no_speech_prob": 0.0014324752846732736,
        "seek": 68076,
        "start": 702.96,
        "temperature": 0,
        "text": " I need to I don't need this",
        "tokens": [
          51474,
          286,
          643,
          281,
          286,
          500,
          380,
          643,
          341,
          51594
        ]
      },
      {
        "avg_logprob": -0.3237745732436945,
        "compression_ratio": 1.4879227053140096,
        "end": 711.52,
        "id": 87,
        "no_speech_prob": 0.004399123135954142,
        "seek": 70536,
        "start": 706.36,
        "temperature": 0,
        "text": " And I need to get let me just switch myself back over here",
        "tokens": [
          50414,
          400,
          286,
          643,
          281,
          483,
          718,
          385,
          445,
          3679,
          2059,
          646,
          670,
          510,
          50672
        ]
      },
      {
        "avg_logprob": -0.3237745732436945,
        "compression_ratio": 1.4879227053140096,
        "end": 714.6,
        "id": 88,
        "no_speech_prob": 0.004399123135954142,
        "seek": 70536,
        "start": 711.8000000000001,
        "temperature": 0,
        "text": " While I'm getting various windows set up",
        "tokens": [
          50686,
          3987,
          286,
          478,
          1242,
          3683,
          9309,
          992,
          493,
          50826
        ]
      },
      {
        "avg_logprob": -0.3237745732436945,
        "compression_ratio": 1.4879227053140096,
        "end": 717.16,
        "id": 89,
        "no_speech_prob": 0.004399123135954142,
        "seek": 70536,
        "start": 715.16,
        "temperature": 0,
        "text": " so",
        "tokens": [
          50854,
          370,
          50954
        ]
      },
      {
        "avg_logprob": -0.3237745732436945,
        "compression_ratio": 1.4879227053140096,
        "end": 723.6800000000001,
        "id": 90,
        "no_speech_prob": 0.004399123135954142,
        "seek": 70536,
        "start": 720.32,
        "temperature": 0,
        "text": " Let's see talk amongst yourselves for a minute, please",
        "tokens": [
          51112,
          961,
          311,
          536,
          751,
          12918,
          14791,
          337,
          257,
          3456,
          11,
          1767,
          51280
        ]
      },
      {
        "avg_logprob": -0.3237745732436945,
        "compression_ratio": 1.4879227053140096,
        "end": 728.2,
        "id": 91,
        "no_speech_prob": 0.004399123135954142,
        "seek": 70536,
        "start": 724.2,
        "temperature": 0,
        "text": " You know normally you would think I would have this all set up before I begin streaming",
        "tokens": [
          51306,
          509,
          458,
          5646,
          291,
          576,
          519,
          286,
          576,
          362,
          341,
          439,
          992,
          493,
          949,
          286,
          1841,
          11791,
          51506
        ]
      },
      {
        "avg_logprob": -0.3237745732436945,
        "compression_ratio": 1.4879227053140096,
        "end": 730.4,
        "id": 92,
        "no_speech_prob": 0.004399123135954142,
        "seek": 70536,
        "start": 728.2,
        "temperature": 0,
        "text": " I don't know why I'm hiding this from you. I'm just opening up",
        "tokens": [
          51506,
          286,
          500,
          380,
          458,
          983,
          286,
          478,
          10596,
          341,
          490,
          291,
          13,
          286,
          478,
          445,
          5193,
          493,
          51616
        ]
      },
      {
        "avg_logprob": -0.4595719443427192,
        "compression_ratio": 1.2682926829268293,
        "end": 732.4,
        "id": 93,
        "no_speech_prob": 0.0009849312482401729,
        "seek": 73040,
        "start": 730.4,
        "temperature": 0,
        "text": " So I",
        "tokens": [
          50364,
          407,
          286,
          50464
        ]
      },
      {
        "avg_logprob": -0.4595719443427192,
        "compression_ratio": 1.2682926829268293,
        "end": 737.68,
        "id": 94,
        "no_speech_prob": 0.0009849312482401729,
        "seek": 73040,
        "start": 733.76,
        "temperature": 0,
        "text": " My I term and I think the project is",
        "tokens": [
          50532,
          1222,
          286,
          1433,
          293,
          286,
          519,
          264,
          1716,
          307,
          50728
        ]
      },
      {
        "avg_logprob": -0.4595719443427192,
        "compression_ratio": 1.2682926829268293,
        "end": 740.64,
        "id": 95,
        "no_speech_prob": 0.0009849312482401729,
        "seek": 73040,
        "start": 738.4399999999999,
        "temperature": 0,
        "text": " In the auto encoder TF demo",
        "tokens": [
          50766,
          682,
          264,
          8399,
          2058,
          19866,
          40964,
          10723,
          50876
        ]
      },
      {
        "avg_logprob": -0.4595719443427192,
        "compression_ratio": 1.2682926829268293,
        "end": 743.28,
        "id": 96,
        "no_speech_prob": 0.0009849312482401729,
        "seek": 73040,
        "start": 741.28,
        "temperature": 0,
        "text": " Let's open this up in",
        "tokens": [
          50908,
          961,
          311,
          1269,
          341,
          493,
          294,
          51008
        ]
      },
      {
        "avg_logprob": -0.4595719443427192,
        "compression_ratio": 1.2682926829268293,
        "end": 753.92,
        "id": 97,
        "no_speech_prob": 0.0009849312482401729,
        "seek": 73040,
        "start": 749.1999999999999,
        "temperature": 0,
        "text": " In Visual Studio code all right, okay, let's go back to",
        "tokens": [
          51304,
          682,
          23187,
          13500,
          3089,
          439,
          558,
          11,
          1392,
          11,
          718,
          311,
          352,
          646,
          281,
          51540
        ]
      },
      {
        "avg_logprob": -0.4595719443427192,
        "compression_ratio": 1.2682926829268293,
        "end": 758.4399999999999,
        "id": 98,
        "no_speech_prob": 0.0009849312482401729,
        "seek": 73040,
        "start": 756.4399999999999,
        "temperature": 0,
        "text": " The auto",
        "tokens": [
          51666,
          440,
          8399,
          51766
        ]
      },
      {
        "avg_logprob": -0.36692847761996955,
        "compression_ratio": 1.4952830188679245,
        "end": 760.6800000000001,
        "id": 99,
        "no_speech_prob": 0.0059104785323143005,
        "seek": 75844,
        "start": 758.6800000000001,
        "temperature": 0,
        "text": " Encoder Kairos page",
        "tokens": [
          50376,
          29584,
          19866,
          591,
          1246,
          329,
          3028,
          50476
        ]
      },
      {
        "avg_logprob": -0.36692847761996955,
        "compression_ratio": 1.4952830188679245,
        "end": 766.5200000000001,
        "id": 100,
        "no_speech_prob": 0.0059104785323143005,
        "seek": 75844,
        "start": 762,
        "temperature": 0,
        "text": " which is sort of my a model my tutorial that I am following and",
        "tokens": [
          50542,
          597,
          307,
          1333,
          295,
          452,
          257,
          2316,
          452,
          7073,
          300,
          286,
          669,
          3480,
          293,
          50768
        ]
      },
      {
        "avg_logprob": -0.36692847761996955,
        "compression_ratio": 1.4952830188679245,
        "end": 773.8800000000001,
        "id": 101,
        "no_speech_prob": 0.0059104785323143005,
        "seek": 75844,
        "start": 770.24,
        "temperature": 0,
        "text": " Hi Bruno hi Adrian hi and Barak hi Cyril",
        "tokens": [
          50954,
          2421,
          23046,
          4879,
          31746,
          4879,
          293,
          4156,
          514,
          4879,
          33146,
          388,
          51136
        ]
      },
      {
        "avg_logprob": -0.36692847761996955,
        "compression_ratio": 1.4952830188679245,
        "end": 778.84,
        "id": 102,
        "no_speech_prob": 0.0059104785323143005,
        "seek": 75844,
        "start": 774.2,
        "temperature": 0,
        "text": " I'm seeing some nice message in the chat welcome a bunch of people are joining in that's great",
        "tokens": [
          51152,
          286,
          478,
          2577,
          512,
          1481,
          3636,
          294,
          264,
          5081,
          2928,
          257,
          3840,
          295,
          561,
          366,
          5549,
          294,
          300,
          311,
          869,
          51384
        ]
      },
      {
        "avg_logprob": -0.36692847761996955,
        "compression_ratio": 1.4952830188679245,
        "end": 785.72,
        "id": 103,
        "no_speech_prob": 0.0059104785323143005,
        "seek": 75844,
        "start": 781.08,
        "temperature": 0,
        "text": " So what do I how am I gonna get started here so first let's see if my whiteboard is still working",
        "tokens": [
          51496,
          407,
          437,
          360,
          286,
          577,
          669,
          286,
          799,
          483,
          1409,
          510,
          370,
          700,
          718,
          311,
          536,
          498,
          452,
          2418,
          3787,
          307,
          920,
          1364,
          51728
        ]
      },
      {
        "avg_logprob": -0.2829984777113971,
        "compression_ratio": 1.7478991596638656,
        "end": 790.72,
        "id": 104,
        "no_speech_prob": 0.0028445846401154995,
        "seek": 78572,
        "start": 785.72,
        "temperature": 0,
        "text": " Oh looks like I need to work on the focus there, and wow it's so bright. I think it's brighter in here today",
        "tokens": [
          50364,
          876,
          1542,
          411,
          286,
          643,
          281,
          589,
          322,
          264,
          1879,
          456,
          11,
          293,
          6076,
          309,
          311,
          370,
          4730,
          13,
          286,
          519,
          309,
          311,
          19764,
          294,
          510,
          965,
          50614
        ]
      },
      {
        "avg_logprob": -0.2829984777113971,
        "compression_ratio": 1.7478991596638656,
        "end": 793.08,
        "id": 105,
        "no_speech_prob": 0.0028445846401154995,
        "seek": 78572,
        "start": 791.12,
        "temperature": 0,
        "text": " The Sun is out",
        "tokens": [
          50634,
          440,
          6163,
          307,
          484,
          50732
        ]
      },
      {
        "avg_logprob": -0.2829984777113971,
        "compression_ratio": 1.7478991596638656,
        "end": 797.72,
        "id": 106,
        "no_speech_prob": 0.0028445846401154995,
        "seek": 78572,
        "start": 793.08,
        "temperature": 0,
        "text": " So I do get some sunlight in this room so first thing I need to do is focus this camera",
        "tokens": [
          50732,
          407,
          286,
          360,
          483,
          512,
          18379,
          294,
          341,
          1808,
          370,
          700,
          551,
          286,
          643,
          281,
          360,
          307,
          1879,
          341,
          2799,
          50964
        ]
      },
      {
        "avg_logprob": -0.2829984777113971,
        "compression_ratio": 1.7478991596638656,
        "end": 800.24,
        "id": 107,
        "no_speech_prob": 0.0028445846401154995,
        "seek": 78572,
        "start": 797.72,
        "temperature": 0,
        "text": " I think that's better right. I think I just focused it",
        "tokens": [
          50964,
          286,
          519,
          300,
          311,
          1101,
          558,
          13,
          286,
          519,
          286,
          445,
          5178,
          309,
          51090
        ]
      },
      {
        "avg_logprob": -0.2829984777113971,
        "compression_ratio": 1.7478991596638656,
        "end": 803,
        "id": 108,
        "no_speech_prob": 0.0028445846401154995,
        "seek": 78572,
        "start": 801,
        "temperature": 0,
        "text": " Let me go back and look",
        "tokens": [
          51128,
          961,
          385,
          352,
          646,
          293,
          574,
          51228
        ]
      },
      {
        "avg_logprob": -0.2829984777113971,
        "compression_ratio": 1.7478991596638656,
        "end": 808.36,
        "id": 109,
        "no_speech_prob": 0.0028445846401154995,
        "seek": 78572,
        "start": 803.5600000000001,
        "temperature": 0,
        "text": " Here looks better. Yeah, that looks like it's in focus now. Oh, and I need to",
        "tokens": [
          51256,
          1692,
          1542,
          1101,
          13,
          865,
          11,
          300,
          1542,
          411,
          309,
          311,
          294,
          1879,
          586,
          13,
          876,
          11,
          293,
          286,
          643,
          281,
          51496
        ]
      },
      {
        "avg_logprob": -0.2829984777113971,
        "compression_ratio": 1.7478991596638656,
        "end": 811.96,
        "id": 110,
        "no_speech_prob": 0.0028445846401154995,
        "seek": 78572,
        "start": 809.48,
        "temperature": 0,
        "text": " Okay, hold on everyone. I'm coming back to here",
        "tokens": [
          51552,
          1033,
          11,
          1797,
          322,
          1518,
          13,
          286,
          478,
          1348,
          646,
          281,
          510,
          51676
        ]
      },
      {
        "avg_logprob": -0.2959324972970145,
        "compression_ratio": 1.596638655462185,
        "end": 816.32,
        "id": 111,
        "no_speech_prob": 0.09667704999446869,
        "seek": 81196,
        "start": 811.96,
        "temperature": 0,
        "text": " I also want to record this session to disk just in case",
        "tokens": [
          50364,
          286,
          611,
          528,
          281,
          2136,
          341,
          5481,
          281,
          12355,
          445,
          294,
          1389,
          50582
        ]
      },
      {
        "avg_logprob": -0.2959324972970145,
        "compression_ratio": 1.596638655462185,
        "end": 820.72,
        "id": 112,
        "no_speech_prob": 0.09667704999446869,
        "seek": 81196,
        "start": 817,
        "temperature": 0,
        "text": " The thought experiment is you know do you really?",
        "tokens": [
          50616,
          440,
          1194,
          5120,
          307,
          291,
          458,
          360,
          291,
          534,
          30,
          50802
        ]
      },
      {
        "avg_logprob": -0.2959324972970145,
        "compression_ratio": 1.596638655462185,
        "end": 826.8000000000001,
        "id": 113,
        "no_speech_prob": 0.09667704999446869,
        "seek": 81196,
        "start": 820.9200000000001,
        "temperature": 0,
        "text": " Later if you're not here live with me right now part of the process of figuring it out together",
        "tokens": [
          50812,
          11965,
          498,
          291,
          434,
          406,
          510,
          1621,
          365,
          385,
          558,
          586,
          644,
          295,
          264,
          1399,
          295,
          15213,
          309,
          484,
          1214,
          51106
        ]
      },
      {
        "avg_logprob": -0.2959324972970145,
        "compression_ratio": 1.596638655462185,
        "end": 833.2,
        "id": 114,
        "no_speech_prob": 0.09667704999446869,
        "seek": 81196,
        "start": 827.24,
        "temperature": 0,
        "text": " Would you really want to come back and watch four hours of live streaming about building an auto encoder project?",
        "tokens": [
          51128,
          6068,
          291,
          534,
          528,
          281,
          808,
          646,
          293,
          1159,
          1451,
          2496,
          295,
          1621,
          11791,
          466,
          2390,
          364,
          8399,
          2058,
          19866,
          1716,
          30,
          51426
        ]
      },
      {
        "avg_logprob": -0.2959324972970145,
        "compression_ratio": 1.596638655462185,
        "end": 834.8000000000001,
        "id": 115,
        "no_speech_prob": 0.09667704999446869,
        "seek": 81196,
        "start": 833.64,
        "temperature": 0,
        "text": " Maybe",
        "tokens": [
          51448,
          2704,
          51506
        ]
      },
      {
        "avg_logprob": -0.2959324972970145,
        "compression_ratio": 1.596638655462185,
        "end": 837.9200000000001,
        "id": 116,
        "no_speech_prob": 0.09667704999446869,
        "seek": 81196,
        "start": 834.8000000000001,
        "temperature": 0,
        "text": " But my thought is if I can get everything recorded to disk",
        "tokens": [
          51506,
          583,
          452,
          1194,
          307,
          498,
          286,
          393,
          483,
          1203,
          8287,
          281,
          12355,
          51662
        ]
      },
      {
        "avg_logprob": -0.2678137969970703,
        "compression_ratio": 1.5720524017467248,
        "end": 840.16,
        "id": 117,
        "no_speech_prob": 0.006097307428717613,
        "seek": 83792,
        "start": 838.36,
        "temperature": 0,
        "text": " Then perhaps I can",
        "tokens": [
          50386,
          1396,
          4317,
          286,
          393,
          50476
        ]
      },
      {
        "avg_logprob": -0.2678137969970703,
        "compression_ratio": 1.5720524017467248,
        "end": 843.28,
        "id": 118,
        "no_speech_prob": 0.006097307428717613,
        "seek": 83792,
        "start": 840.16,
        "temperature": 0,
        "text": " Succinctly package this in like a 30 to 45 minute video",
        "tokens": [
          50476,
          318,
          39407,
          5460,
          356,
          7372,
          341,
          294,
          411,
          257,
          2217,
          281,
          6905,
          3456,
          960,
          50632
        ]
      },
      {
        "avg_logprob": -0.2678137969970703,
        "compression_ratio": 1.5720524017467248,
        "end": 848.88,
        "id": 119,
        "no_speech_prob": 0.006097307428717613,
        "seek": 83792,
        "start": 843.5999999999999,
        "temperature": 0,
        "text": " Which skips a lot of the rambling and all that kind of stuff so let me I need to",
        "tokens": [
          50648,
          3013,
          1110,
          2600,
          257,
          688,
          295,
          264,
          367,
          19391,
          293,
          439,
          300,
          733,
          295,
          1507,
          370,
          718,
          385,
          286,
          643,
          281,
          50912
        ]
      },
      {
        "avg_logprob": -0.2678137969970703,
        "compression_ratio": 1.5720524017467248,
        "end": 852.4399999999999,
        "id": 120,
        "no_speech_prob": 0.006097307428717613,
        "seek": 83792,
        "start": 849.4,
        "temperature": 0,
        "text": " I'm kind of like shocked that I'm doing this because as of this morning",
        "tokens": [
          50938,
          286,
          478,
          733,
          295,
          411,
          12763,
          300,
          286,
          478,
          884,
          341,
          570,
          382,
          295,
          341,
          2446,
          51090
        ]
      },
      {
        "avg_logprob": -0.2678137969970703,
        "compression_ratio": 1.5720524017467248,
        "end": 859.92,
        "id": 121,
        "no_speech_prob": 0.006097307428717613,
        "seek": 83792,
        "start": 852.4399999999999,
        "temperature": 0,
        "text": " I was like I'm just gonna reschedule this to like November 30th, so I just need to check my settings here",
        "tokens": [
          51090,
          286,
          390,
          411,
          286,
          478,
          445,
          799,
          725,
          19318,
          2271,
          341,
          281,
          411,
          7674,
          2217,
          392,
          11,
          370,
          286,
          445,
          643,
          281,
          1520,
          452,
          6257,
          510,
          51464
        ]
      },
      {
        "avg_logprob": -0.2678137969970703,
        "compression_ratio": 1.5720524017467248,
        "end": 862.5999999999999,
        "id": 122,
        "no_speech_prob": 0.006097307428717613,
        "seek": 83792,
        "start": 861.24,
        "temperature": 0,
        "text": " output",
        "tokens": [
          51530,
          5598,
          51598
        ]
      },
      {
        "avg_logprob": -0.2678137969970703,
        "compression_ratio": 1.5720524017467248,
        "end": 864.3199999999999,
        "id": 123,
        "no_speech_prob": 0.006097307428717613,
        "seek": 83792,
        "start": 862.5999999999999,
        "temperature": 0,
        "text": " streaming recording",
        "tokens": [
          51598,
          11791,
          6613,
          51684
        ]
      },
      {
        "avg_logprob": -0.32533424377441406,
        "compression_ratio": 1.5384615384615385,
        "end": 868.84,
        "id": 124,
        "no_speech_prob": 0.3774450421333313,
        "seek": 86432,
        "start": 864.32,
        "temperature": 0,
        "text": " Distinguishable quality large file size well no wonder high quality medium file size",
        "tokens": [
          50364,
          9840,
          7050,
          742,
          712,
          3125,
          2416,
          3991,
          2744,
          731,
          572,
          2441,
          1090,
          3125,
          6399,
          3991,
          2744,
          50590
        ]
      },
      {
        "avg_logprob": -0.32533424377441406,
        "compression_ratio": 1.5384615384615385,
        "end": 875.84,
        "id": 125,
        "no_speech_prob": 0.3774450421333313,
        "seek": 86432,
        "start": 869.8000000000001,
        "temperature": 0,
        "text": " Forgot that I done this start recording, so I recorded last session to disk and",
        "tokens": [
          50638,
          1171,
          13178,
          300,
          286,
          1096,
          341,
          722,
          6613,
          11,
          370,
          286,
          8287,
          1036,
          5481,
          281,
          12355,
          293,
          50940
        ]
      },
      {
        "avg_logprob": -0.32533424377441406,
        "compression_ratio": 1.5384615384615385,
        "end": 880.88,
        "id": 126,
        "no_speech_prob": 0.3774450421333313,
        "seek": 86432,
        "start": 877.12,
        "temperature": 0,
        "text": " I looked at the file afterwards, and it was 57 gigabytes",
        "tokens": [
          51004,
          286,
          2956,
          412,
          264,
          3991,
          10543,
          11,
          293,
          309,
          390,
          21423,
          42741,
          51192
        ]
      },
      {
        "avg_logprob": -0.32533424377441406,
        "compression_ratio": 1.5384615384615385,
        "end": 883.8000000000001,
        "id": 127,
        "no_speech_prob": 0.3774450421333313,
        "seek": 86432,
        "start": 881.8000000000001,
        "temperature": 0,
        "text": " Because I'm recording a 4k",
        "tokens": [
          51238,
          1436,
          286,
          478,
          6613,
          257,
          1017,
          74,
          51338
        ]
      },
      {
        "avg_logprob": -0.32533424377441406,
        "compression_ratio": 1.5384615384615385,
        "end": 888.24,
        "id": 128,
        "no_speech_prob": 0.3774450421333313,
        "seek": 86432,
        "start": 884.5200000000001,
        "temperature": 0,
        "text": " Video to disk which has all of the different it has",
        "tokens": [
          51374,
          9777,
          281,
          12355,
          597,
          575,
          439,
          295,
          264,
          819,
          309,
          575,
          51560
        ]
      },
      {
        "avg_logprob": -0.29380572420879475,
        "compression_ratio": 1.5657370517928286,
        "end": 894.5600000000001,
        "id": 129,
        "no_speech_prob": 0.06463931500911713,
        "seek": 88824,
        "start": 889.24,
        "temperature": 0,
        "text": " Just the laptop feed it has me actually me just with the green screen",
        "tokens": [
          50414,
          1449,
          264,
          10732,
          3154,
          309,
          575,
          385,
          767,
          385,
          445,
          365,
          264,
          3092,
          2568,
          50680
        ]
      },
      {
        "avg_logprob": -0.29380572420879475,
        "compression_ratio": 1.5657370517928286,
        "end": 898.64,
        "id": 130,
        "no_speech_prob": 0.06463931500911713,
        "seek": 88824,
        "start": 895.2,
        "temperature": 0,
        "text": " And it has the whiteboard if I had the iPad here",
        "tokens": [
          50712,
          400,
          309,
          575,
          264,
          2418,
          3787,
          498,
          286,
          632,
          264,
          12945,
          510,
          50884
        ]
      },
      {
        "avg_logprob": -0.29380572420879475,
        "compression_ratio": 1.5657370517928286,
        "end": 904,
        "id": 131,
        "no_speech_prob": 0.06463931500911713,
        "seek": 88824,
        "start": 898.64,
        "temperature": 0,
        "text": " I have a iPad hookup, but it's not hooked up right now, so this is my new setup",
        "tokens": [
          50884,
          286,
          362,
          257,
          12945,
          6328,
          1010,
          11,
          457,
          309,
          311,
          406,
          20410,
          493,
          558,
          586,
          11,
          370,
          341,
          307,
          452,
          777,
          8657,
          51152
        ]
      },
      {
        "avg_logprob": -0.29380572420879475,
        "compression_ratio": 1.5657370517928286,
        "end": 908.8,
        "id": 132,
        "no_speech_prob": 0.06463931500911713,
        "seek": 88824,
        "start": 904,
        "temperature": 0,
        "text": " I'm obviously still trying to build up momentum. Thank you to everybody's patience",
        "tokens": [
          51152,
          286,
          478,
          2745,
          920,
          1382,
          281,
          1322,
          493,
          11244,
          13,
          1044,
          291,
          281,
          2201,
          311,
          14826,
          51392
        ]
      },
      {
        "avg_logprob": -0.29380572420879475,
        "compression_ratio": 1.5657370517928286,
        "end": 915.72,
        "id": 133,
        "no_speech_prob": 0.06463931500911713,
        "seek": 88824,
        "start": 909.64,
        "temperature": 0,
        "text": " Kindness and consideration as I try to figure out I feel like the coding train is going to be born anew in",
        "tokens": [
          51434,
          9242,
          1287,
          293,
          12381,
          382,
          286,
          853,
          281,
          2573,
          484,
          286,
          841,
          411,
          264,
          17720,
          3847,
          307,
          516,
          281,
          312,
          4232,
          364,
          1023,
          294,
          51738
        ]
      },
      {
        "avg_logprob": -0.29380572420879475,
        "compression_ratio": 1.5657370517928286,
        "end": 918,
        "id": 134,
        "no_speech_prob": 0.06463931500911713,
        "seek": 88824,
        "start": 916.32,
        "temperature": 0,
        "text": " 2022",
        "tokens": [
          51768,
          20229,
          51852
        ]
      },
      {
        "avg_logprob": -0.3506320009949387,
        "compression_ratio": 1.502183406113537,
        "end": 923.2,
        "id": 135,
        "no_speech_prob": 0.004538040608167648,
        "seek": 91800,
        "start": 919,
        "temperature": 0,
        "text": " Yeah, right this which is quite lovely, okay, I've got a little bit of coffee left",
        "tokens": [
          50414,
          865,
          11,
          558,
          341,
          597,
          307,
          1596,
          7496,
          11,
          1392,
          11,
          286,
          600,
          658,
          257,
          707,
          857,
          295,
          4982,
          1411,
          50624
        ]
      },
      {
        "avg_logprob": -0.3506320009949387,
        "compression_ratio": 1.502183406113537,
        "end": 934.08,
        "id": 136,
        "no_speech_prob": 0.004538040608167648,
        "seek": 91800,
        "start": 927.36,
        "temperature": 0,
        "text": " Got to get back to my children, but I'm giving myself till 330. It's 90 minutes. I'm recording to disk",
        "tokens": [
          50832,
          5803,
          281,
          483,
          646,
          281,
          452,
          2227,
          11,
          457,
          286,
          478,
          2902,
          2059,
          4288,
          805,
          3446,
          13,
          467,
          311,
          4289,
          2077,
          13,
          286,
          478,
          6613,
          281,
          12355,
          51168
        ]
      },
      {
        "avg_logprob": -0.3506320009949387,
        "compression_ratio": 1.502183406113537,
        "end": 940.88,
        "id": 137,
        "no_speech_prob": 0.004538040608167648,
        "seek": 91800,
        "start": 935.4,
        "temperature": 0,
        "text": " And thank you to all of your Thank You Sorelle you are here with me. I appreciate it alright",
        "tokens": [
          51234,
          400,
          1309,
          291,
          281,
          439,
          295,
          428,
          1044,
          509,
          318,
          418,
          2447,
          291,
          366,
          510,
          365,
          385,
          13,
          286,
          4449,
          309,
          5845,
          51508
        ]
      },
      {
        "avg_logprob": -0.3506320009949387,
        "compression_ratio": 1.502183406113537,
        "end": 944.8,
        "id": 138,
        "no_speech_prob": 0.004538040608167648,
        "seek": 91800,
        "start": 941.4,
        "temperature": 0,
        "text": " Little straw poll here, but put a little straw poll into the chat",
        "tokens": [
          51534,
          8022,
          10099,
          6418,
          510,
          11,
          457,
          829,
          257,
          707,
          10099,
          6418,
          666,
          264,
          5081,
          51704
        ]
      },
      {
        "avg_logprob": -0.4751375670074135,
        "compression_ratio": 1.7055837563451777,
        "end": 947.5999999999999,
        "id": 139,
        "no_speech_prob": 0.0027573874685913324,
        "seek": 94480,
        "start": 944.8,
        "temperature": 0,
        "text": " Did you watch part one?",
        "tokens": [
          50364,
          2589,
          291,
          1159,
          644,
          472,
          30,
          50504
        ]
      },
      {
        "avg_logprob": -0.4751375670074135,
        "compression_ratio": 1.7055837563451777,
        "end": 952.8,
        "id": 140,
        "no_speech_prob": 0.0027573874685913324,
        "seek": 94480,
        "start": 949,
        "temperature": 0,
        "text": " Just give me a sense of who watched part one",
        "tokens": [
          50574,
          1449,
          976,
          385,
          257,
          2020,
          295,
          567,
          6337,
          644,
          472,
          50764
        ]
      },
      {
        "avg_logprob": -0.4751375670074135,
        "compression_ratio": 1.7055837563451777,
        "end": 957.8399999999999,
        "id": 141,
        "no_speech_prob": 0.0027573874685913324,
        "seek": 94480,
        "start": 952.8,
        "temperature": 0,
        "text": " I can't see by the way who's answering so you know it's not like you know did you study for the test?",
        "tokens": [
          50764,
          286,
          393,
          380,
          536,
          538,
          264,
          636,
          567,
          311,
          13430,
          370,
          291,
          458,
          309,
          311,
          406,
          411,
          291,
          458,
          630,
          291,
          2979,
          337,
          264,
          1500,
          30,
          51016
        ]
      },
      {
        "avg_logprob": -0.4751375670074135,
        "compression_ratio": 1.7055837563451777,
        "end": 960.4799999999999,
        "id": 142,
        "no_speech_prob": 0.0027573874685913324,
        "seek": 94480,
        "start": 957.8399999999999,
        "temperature": 0,
        "text": " And you don't want to admit it like I would like to know the real information",
        "tokens": [
          51016,
          400,
          291,
          500,
          380,
          528,
          281,
          9796,
          309,
          411,
          286,
          576,
          411,
          281,
          458,
          264,
          957,
          1589,
          51148
        ]
      },
      {
        "avg_logprob": -0.4751375670074135,
        "compression_ratio": 1.7055837563451777,
        "end": 969.4799999999999,
        "id": 143,
        "no_speech_prob": 0.0027573874685913324,
        "seek": 94480,
        "start": 961.4799999999999,
        "temperature": 0,
        "text": " so in the chat now should be a poll asking whether you watched part one or not and",
        "tokens": [
          51198,
          370,
          294,
          264,
          5081,
          586,
          820,
          312,
          257,
          6418,
          3365,
          1968,
          291,
          6337,
          644,
          472,
          420,
          406,
          293,
          51598
        ]
      },
      {
        "avg_logprob": -0.4751375670074135,
        "compression_ratio": 1.7055837563451777,
        "end": 972.12,
        "id": 144,
        "no_speech_prob": 0.0027573874685913324,
        "seek": 94480,
        "start": 970.12,
        "temperature": 0,
        "text": " as I",
        "tokens": [
          51630,
          382,
          286,
          51730
        ]
      },
      {
        "avg_logprob": -0.5625947974194055,
        "compression_ratio": 1.5024875621890548,
        "end": 974.4,
        "id": 145,
        "no_speech_prob": 0.008313965052366257,
        "seek": 97212,
        "start": 972.4,
        "temperature": 0,
        "text": " Kind of get",
        "tokens": [
          50378,
          9242,
          295,
          483,
          50478
        ]
      },
      {
        "avg_logprob": -0.5625947974194055,
        "compression_ratio": 1.5024875621890548,
        "end": 978.8,
        "id": 146,
        "no_speech_prob": 0.008313965052366257,
        "seek": 97212,
        "start": 974.92,
        "temperature": 0,
        "text": " Let's just see if things are still working here. It looks good",
        "tokens": [
          50504,
          961,
          311,
          445,
          536,
          498,
          721,
          366,
          920,
          1364,
          510,
          13,
          467,
          1542,
          665,
          50698
        ]
      },
      {
        "avg_logprob": -0.5625947974194055,
        "compression_ratio": 1.5024875621890548,
        "end": 985.16,
        "id": 147,
        "no_speech_prob": 0.008313965052366257,
        "seek": 97212,
        "start": 980.28,
        "temperature": 0,
        "text": " I'm just sort of checking out my code from before still seems to be running",
        "tokens": [
          50772,
          286,
          478,
          445,
          1333,
          295,
          8568,
          484,
          452,
          3089,
          490,
          949,
          920,
          2544,
          281,
          312,
          2614,
          51016
        ]
      },
      {
        "avg_logprob": -0.5625947974194055,
        "compression_ratio": 1.5024875621890548,
        "end": 991.48,
        "id": 148,
        "no_speech_prob": 0.008313965052366257,
        "seek": 97212,
        "start": 987.2,
        "temperature": 0,
        "text": " That's fine there, but this I term needs to be a",
        "tokens": [
          51118,
          663,
          311,
          2489,
          456,
          11,
          457,
          341,
          286,
          1433,
          2203,
          281,
          312,
          257,
          51332
        ]
      },
      {
        "avg_logprob": -0.5625947974194055,
        "compression_ratio": 1.5024875621890548,
        "end": 995.8,
        "id": 149,
        "no_speech_prob": 0.008313965052366257,
        "seek": 97212,
        "start": 992.36,
        "temperature": 0,
        "text": " Little bit more over. Ah come on. I term",
        "tokens": [
          51376,
          8022,
          857,
          544,
          670,
          13,
          2438,
          808,
          322,
          13,
          286,
          1433,
          51548
        ]
      },
      {
        "avg_logprob": -0.5625947974194055,
        "compression_ratio": 1.5024875621890548,
        "end": 999.88,
        "id": 150,
        "no_speech_prob": 0.008313965052366257,
        "seek": 97212,
        "start": 996.32,
        "temperature": 0,
        "text": " Why do you do me like that? Okay? I think that should be good",
        "tokens": [
          51574,
          1545,
          360,
          291,
          360,
          385,
          411,
          300,
          30,
          1033,
          30,
          286,
          519,
          300,
          820,
          312,
          665,
          51752
        ]
      },
      {
        "avg_logprob": -0.6534056412546259,
        "compression_ratio": 1.52020202020202,
        "end": 1007.88,
        "id": 151,
        "no_speech_prob": 0.01590399444103241,
        "seek": 99988,
        "start": 999.92,
        "temperature": 0,
        "text": " Processing I don't actually know that I'm even gonna need I actually will want this for sure I just realized okay",
        "tokens": [
          50366,
          31093,
          278,
          286,
          500,
          380,
          767,
          458,
          300,
          286,
          478,
          754,
          799,
          643,
          286,
          767,
          486,
          528,
          341,
          337,
          988,
          286,
          445,
          5334,
          1392,
          50764
        ]
      },
      {
        "avg_logprob": -0.6534056412546259,
        "compression_ratio": 1.52020202020202,
        "end": 1010.52,
        "id": 152,
        "no_speech_prob": 0.01590399444103241,
        "seek": 99988,
        "start": 1008.52,
        "temperature": 0,
        "text": " I also remember",
        "tokens": [
          50796,
          286,
          611,
          1604,
          50896
        ]
      },
      {
        "avg_logprob": -0.6534056412546259,
        "compression_ratio": 1.52020202020202,
        "end": 1013.08,
        "id": 153,
        "no_speech_prob": 0.01590399444103241,
        "seek": 99988,
        "start": 1011.08,
        "temperature": 0,
        "text": " K week man",
        "tokens": [
          50924,
          591,
          1243,
          587,
          51024
        ]
      },
      {
        "avg_logprob": -0.6534056412546259,
        "compression_ratio": 1.52020202020202,
        "end": 1017.72,
        "id": 154,
        "no_speech_prob": 0.01590399444103241,
        "seek": 99988,
        "start": 1013.64,
        "temperature": 0,
        "text": " Would you like to be referred to I do it all sorts of different ways",
        "tokens": [
          51052,
          6068,
          291,
          411,
          281,
          312,
          10839,
          281,
          286,
          360,
          309,
          439,
          7527,
          295,
          819,
          2098,
          51256
        ]
      },
      {
        "avg_logprob": -0.6534056412546259,
        "compression_ratio": 1.52020202020202,
        "end": 1021.68,
        "id": 155,
        "no_speech_prob": 0.01590399444103241,
        "seek": 99988,
        "start": 1018.96,
        "temperature": 0,
        "text": " But I remember you saying that",
        "tokens": [
          51318,
          583,
          286,
          1604,
          291,
          1566,
          300,
          51454
        ]
      },
      {
        "avg_logprob": -0.6534056412546259,
        "compression_ratio": 1.52020202020202,
        "end": 1026.84,
        "id": 156,
        "no_speech_prob": 0.01590399444103241,
        "seek": 99988,
        "start": 1022.4,
        "temperature": 0,
        "text": " I should reconsider maybe the optimizer or the loss function",
        "tokens": [
          51490,
          286,
          820,
          40497,
          1310,
          264,
          5028,
          6545,
          420,
          264,
          4470,
          2445,
          51712
        ]
      },
      {
        "avg_logprob": -0.5253498840332032,
        "compression_ratio": 1.565217391304348,
        "end": 1030.24,
        "id": 157,
        "no_speech_prob": 0.006192650645971298,
        "seek": 102684,
        "start": 1026.84,
        "temperature": 0,
        "text": " So again the my my court of working",
        "tokens": [
          50364,
          407,
          797,
          264,
          452,
          452,
          4753,
          295,
          1364,
          50534
        ]
      },
      {
        "avg_logprob": -0.5253498840332032,
        "compression_ratio": 1.565217391304348,
        "end": 1032.24,
        "id": 158,
        "no_speech_prob": 0.006192650645971298,
        "seek": 102684,
        "start": 1030.9599999999998,
        "temperature": 0,
        "text": " sort",
        "tokens": [
          50570,
          1333,
          50634
        ]
      },
      {
        "avg_logprob": -0.5253498840332032,
        "compression_ratio": 1.565217391304348,
        "end": 1039.48,
        "id": 159,
        "no_speech_prob": 0.006192650645971298,
        "seek": 102684,
        "start": 1032.24,
        "temperature": 0,
        "text": " the working philosophy here right now is just to get all the pieces plugged in and then I want to add more layers and",
        "tokens": [
          50634,
          264,
          1364,
          10675,
          510,
          558,
          586,
          307,
          445,
          281,
          483,
          439,
          264,
          3755,
          25679,
          294,
          293,
          550,
          286,
          528,
          281,
          909,
          544,
          7914,
          293,
          50996
        ]
      },
      {
        "avg_logprob": -0.5253498840332032,
        "compression_ratio": 1.565217391304348,
        "end": 1045.04,
        "id": 160,
        "no_speech_prob": 0.006192650645971298,
        "seek": 102684,
        "start": 1039.48,
        "temperature": 0,
        "text": " Sort of think more thoughtfully about the various hyper parameters of the system that I'm building",
        "tokens": [
          50996,
          26149,
          295,
          519,
          544,
          1194,
          2277,
          466,
          264,
          3683,
          9848,
          9834,
          295,
          264,
          1185,
          300,
          286,
          478,
          2390,
          51274
        ]
      },
      {
        "avg_logprob": -0.5253498840332032,
        "compression_ratio": 1.565217391304348,
        "end": 1048.76,
        "id": 161,
        "no_speech_prob": 0.006192650645971298,
        "seek": 102684,
        "start": 1045.04,
        "temperature": 0,
        "text": " And then also hook it up to p5 so I can see the results in the browser",
        "tokens": [
          51274,
          400,
          550,
          611,
          6328,
          309,
          493,
          281,
          280,
          20,
          370,
          286,
          393,
          536,
          264,
          3542,
          294,
          264,
          11185,
          51460
        ]
      },
      {
        "avg_logprob": -0.5253498840332032,
        "compression_ratio": 1.565217391304348,
        "end": 1052.12,
        "id": 162,
        "no_speech_prob": 0.006192650645971298,
        "seek": 102684,
        "start": 1048.76,
        "temperature": 0,
        "text": " Oh by 330 today no problem. There's probably going to be a part two",
        "tokens": [
          51460,
          876,
          538,
          805,
          3446,
          965,
          572,
          1154,
          13,
          821,
          311,
          1391,
          516,
          281,
          312,
          257,
          644,
          732,
          51628
        ]
      },
      {
        "avg_logprob": -0.5879636492047992,
        "compression_ratio": 1.517766497461929,
        "end": 1056.76,
        "id": 163,
        "no_speech_prob": 0.1241876557469368,
        "seek": 105212,
        "start": 1052.12,
        "temperature": 0,
        "text": " But I seem to recall you had left some comments in the discord",
        "tokens": [
          50364,
          583,
          286,
          1643,
          281,
          9901,
          291,
          632,
          1411,
          512,
          3053,
          294,
          264,
          32989,
          50596
        ]
      },
      {
        "avg_logprob": -0.5879636492047992,
        "compression_ratio": 1.517766497461929,
        "end": 1061.6799999999998,
        "id": 164,
        "no_speech_prob": 0.1241876557469368,
        "seek": 105212,
        "start": 1057.4399999999998,
        "temperature": 0,
        "text": " So I let me make sure I come back and revisit that although. Maybe I'm not going to right now",
        "tokens": [
          50630,
          407,
          286,
          718,
          385,
          652,
          988,
          286,
          808,
          646,
          293,
          32676,
          300,
          4878,
          13,
          2704,
          286,
          478,
          406,
          516,
          281,
          558,
          586,
          50842
        ]
      },
      {
        "avg_logprob": -0.5879636492047992,
        "compression_ratio": 1.517766497461929,
        "end": 1064.6399999999999,
        "id": 165,
        "no_speech_prob": 0.1241876557469368,
        "seek": 105212,
        "start": 1061.6799999999998,
        "temperature": 0,
        "text": " I am seeing the poll results that",
        "tokens": [
          50842,
          286,
          669,
          2577,
          264,
          6418,
          3542,
          300,
          50990
        ]
      },
      {
        "avg_logprob": -0.5879636492047992,
        "compression_ratio": 1.517766497461929,
        "end": 1068.12,
        "id": 166,
        "no_speech_prob": 0.1241876557469368,
        "seek": 105212,
        "start": 1065.7199999999998,
        "temperature": 0,
        "text": " 60% of you 73 people have voted",
        "tokens": [
          51044,
          4060,
          4,
          295,
          291,
          28387,
          561,
          362,
          13415,
          51164
        ]
      },
      {
        "avg_logprob": -0.5879636492047992,
        "compression_ratio": 1.517766497461929,
        "end": 1071.76,
        "id": 167,
        "no_speech_prob": 0.1241876557469368,
        "seek": 105212,
        "start": 1068.8799999999999,
        "temperature": 0,
        "text": " 61% of you have did not watch part one and",
        "tokens": [
          51202,
          28294,
          4,
          295,
          291,
          362,
          630,
          406,
          1159,
          644,
          472,
          293,
          51346
        ]
      },
      {
        "avg_logprob": -0.5879636492047992,
        "compression_ratio": 1.517766497461929,
        "end": 1074.8799999999999,
        "id": 168,
        "no_speech_prob": 0.1241876557469368,
        "seek": 105212,
        "start": 1072.32,
        "temperature": 0,
        "text": " 39% of you did watch part two and",
        "tokens": [
          51374,
          15238,
          4,
          295,
          291,
          630,
          1159,
          644,
          732,
          293,
          51502
        ]
      },
      {
        "avg_logprob": -1.3918906810671785,
        "compression_ratio": 1.4261363636363635,
        "end": 1082.3000000000002,
        "id": 169,
        "no_speech_prob": 0.14031624794006348,
        "seek": 107488,
        "start": 1075.6000000000001,
        "temperature": 1,
        "text": " This means this swings the pendulum for me, I'm gonna. Give you a quick recap of kind of everything. I do",
        "tokens": [
          50400,
          220,
          5723,
          1355,
          341,
          32386,
          264,
          44103,
          337,
          385,
          11,
          286,
          478,
          290,
          19968,
          64,
          13,
          5303,
          291,
          257,
          1702,
          20928,
          295,
          733,
          295,
          1203,
          13,
          286,
          360,
          50735
        ]
      },
      {
        "avg_logprob": -1.3918906810671785,
        "compression_ratio": 1.4261363636363635,
        "end": 1088.4,
        "id": 170,
        "no_speech_prob": 0.14031624794006348,
        "seek": 107488,
        "start": 1084.7600000000002,
        "temperature": 1,
        "text": " And let's uh let's put a timer on here, let's timebox this",
        "tokens": [
          50858,
          400,
          718,
          311,
          2232,
          718,
          311,
          829,
          257,
          19247,
          322,
          510,
          11,
          718,
          311,
          565,
          65,
          5230,
          341,
          51040
        ]
      },
      {
        "avg_logprob": -1.3918906810671785,
        "compression_ratio": 1.4261363636363635,
        "end": 1092.2,
        "id": 171,
        "no_speech_prob": 0.14031624794006348,
        "seek": 107488,
        "start": 1090.2,
        "temperature": 1,
        "text": " 10 minute timer",
        "tokens": [
          51130,
          1266,
          3456,
          19247,
          51230
        ]
      },
      {
        "avg_logprob": -1.3918906810671785,
        "compression_ratio": 1.4261363636363635,
        "end": 1095.94,
        "id": 172,
        "no_speech_prob": 0.14031624794006348,
        "seek": 107488,
        "start": 1093.5600000000002,
        "temperature": 1,
        "text": " So I don't want to allow myself",
        "tokens": [
          51298,
          407,
          286,
          500,
          380,
          528,
          281,
          2089,
          452,
          405,
          75,
          69,
          51417
        ]
      },
      {
        "avg_logprob": -1.3918906810671785,
        "compression_ratio": 1.4261363636363635,
        "end": 1098.4,
        "id": 173,
        "no_speech_prob": 0.14031624794006348,
        "seek": 107488,
        "start": 1097.6000000000001,
        "temperature": 1,
        "text": " to",
        "tokens": [
          51500,
          281,
          51540
        ]
      },
      {
        "avg_logprob": -1.3918906810671785,
        "compression_ratio": 1.4261363636363635,
        "end": 1100.4,
        "id": 174,
        "no_speech_prob": 0.14031624794006348,
        "seek": 107488,
        "start": 1098.4,
        "temperature": 1,
        "text": " Let the user",
        "tokens": [
          51540,
          961,
          264,
          344,
          12484,
          51640
        ]
      },
      {
        "avg_logprob": -1.3918906810671785,
        "compression_ratio": 1.4261363636363635,
        "end": 1102.42,
        "id": 175,
        "no_speech_prob": 0.14031624794006348,
        "seek": 107488,
        "start": 1100.42,
        "temperature": 1,
        "text": " Look at whats going on",
        "tokens": [
          51641,
          2053,
          412,
          29625,
          516,
          322,
          51741
        ]
      },
      {
        "avg_logprob": -0.35960365596570465,
        "compression_ratio": 1.5182926829268293,
        "end": 1104.42,
        "id": 176,
        "no_speech_prob": 0.001284271478652954,
        "seek": 110242,
        "start": 1102.42,
        "temperature": 0,
        "text": " to allow myself",
        "tokens": [
          50364,
          281,
          2089,
          2059,
          50464
        ]
      },
      {
        "avg_logprob": -0.35960365596570465,
        "compression_ratio": 1.5182926829268293,
        "end": 1108.68,
        "id": 177,
        "no_speech_prob": 0.001284271478652954,
        "seek": 110242,
        "start": 1106.68,
        "temperature": 0,
        "text": " More than 10 minutes",
        "tokens": [
          50577,
          5048,
          813,
          1266,
          2077,
          50677
        ]
      },
      {
        "avg_logprob": -0.35960365596570465,
        "compression_ratio": 1.5182926829268293,
        "end": 1116.78,
        "id": 178,
        "no_speech_prob": 0.001284271478652954,
        "seek": 110242,
        "start": 1111.1200000000001,
        "temperature": 0,
        "text": " Where oh what I'm using up so much of my time just to put this",
        "tokens": [
          50799,
          2305,
          1954,
          437,
          286,
          478,
          1228,
          493,
          370,
          709,
          295,
          452,
          565,
          445,
          281,
          829,
          341,
          51082
        ]
      },
      {
        "avg_logprob": -0.35960365596570465,
        "compression_ratio": 1.5182926829268293,
        "end": 1119.8600000000001,
        "id": 179,
        "no_speech_prob": 0.001284271478652954,
        "seek": 110242,
        "start": 1117.78,
        "temperature": 0,
        "text": " In the page here, okay",
        "tokens": [
          51132,
          682,
          264,
          3028,
          510,
          11,
          1392,
          51236
        ]
      },
      {
        "avg_logprob": -0.35960365596570465,
        "compression_ratio": 1.5182926829268293,
        "end": 1123.46,
        "id": 180,
        "no_speech_prob": 0.001284271478652954,
        "seek": 110242,
        "start": 1121.0600000000002,
        "temperature": 0,
        "text": " Okay, so there's my 10 minute timer",
        "tokens": [
          51296,
          1033,
          11,
          370,
          456,
          311,
          452,
          1266,
          3456,
          19247,
          51416
        ]
      },
      {
        "avg_logprob": -0.35960365596570465,
        "compression_ratio": 1.5182926829268293,
        "end": 1127.6200000000001,
        "id": 181,
        "no_speech_prob": 0.001284271478652954,
        "seek": 110242,
        "start": 1123.46,
        "temperature": 0,
        "text": " I don't want to I want to be starting on the new stuff by the time that hits zero",
        "tokens": [
          51416,
          286,
          500,
          380,
          528,
          281,
          286,
          528,
          281,
          312,
          2891,
          322,
          264,
          777,
          1507,
          538,
          264,
          565,
          300,
          8664,
          4018,
          51624
        ]
      },
      {
        "avg_logprob": -0.35960365596570465,
        "compression_ratio": 1.5182926829268293,
        "end": 1130.8200000000002,
        "id": 182,
        "no_speech_prob": 0.001284271478652954,
        "seek": 110242,
        "start": 1128.8200000000002,
        "temperature": 0,
        "text": " okay, so",
        "tokens": [
          51684,
          1392,
          11,
          370,
          51784
        ]
      },
      {
        "avg_logprob": -0.38421004159109934,
        "compression_ratio": 1.6894977168949772,
        "end": 1134.3400000000001,
        "id": 183,
        "no_speech_prob": 0.002757573965936899,
        "seek": 113242,
        "start": 1132.8600000000001,
        "temperature": 0,
        "text": " Quickly I",
        "tokens": [
          50386,
          31800,
          286,
          50460
        ]
      },
      {
        "avg_logprob": -0.38421004159109934,
        "compression_ratio": 1.6894977168949772,
        "end": 1140.68,
        "id": 184,
        "no_speech_prob": 0.002757573965936899,
        "seek": 113242,
        "start": 1134.3400000000001,
        "temperature": 0,
        "text": " Am very interested in machine learning generative machine learning models models that generate",
        "tokens": [
          50460,
          2012,
          588,
          3102,
          294,
          3479,
          2539,
          1337,
          1166,
          3479,
          2539,
          5245,
          5245,
          300,
          8460,
          50777
        ]
      },
      {
        "avg_logprob": -0.38421004159109934,
        "compression_ratio": 1.6894977168949772,
        "end": 1143.02,
        "id": 185,
        "no_speech_prob": 0.002757573965936899,
        "seek": 113242,
        "start": 1141.18,
        "temperature": 0,
        "text": " synthetic images",
        "tokens": [
          50802,
          23420,
          5267,
          50894
        ]
      },
      {
        "avg_logprob": -0.38421004159109934,
        "compression_ratio": 1.6894977168949772,
        "end": 1145.5800000000002,
        "id": 186,
        "no_speech_prob": 0.002757573965936899,
        "seek": 113242,
        "start": 1143.02,
        "temperature": 0,
        "text": " Text perhaps sound other kinds of media",
        "tokens": [
          50894,
          18643,
          4317,
          1626,
          661,
          3685,
          295,
          3021,
          51022
        ]
      },
      {
        "avg_logprob": -0.38421004159109934,
        "compression_ratio": 1.6894977168949772,
        "end": 1152.7,
        "id": 187,
        "no_speech_prob": 0.002757573965936899,
        "seek": 113242,
        "start": 1146.3000000000002,
        "temperature": 0,
        "text": " If you have been following the world of deep learning today the what you probably have heard of is something like oh",
        "tokens": [
          51058,
          759,
          291,
          362,
          668,
          3480,
          264,
          1002,
          295,
          2452,
          2539,
          965,
          264,
          437,
          291,
          1391,
          362,
          2198,
          295,
          307,
          746,
          411,
          1954,
          51378
        ]
      },
      {
        "avg_logprob": -0.38421004159109934,
        "compression_ratio": 1.6894977168949772,
        "end": 1158.78,
        "id": 188,
        "no_speech_prob": 0.002757573965936899,
        "seek": 113242,
        "start": 1153.0600000000002,
        "temperature": 0,
        "text": " Again or style Gann or style Gann 2 or style Gann 3 and then there's this like latent space",
        "tokens": [
          51396,
          3764,
          420,
          3758,
          460,
          969,
          420,
          3758,
          460,
          969,
          568,
          420,
          3758,
          460,
          969,
          805,
          293,
          550,
          456,
          311,
          341,
          411,
          48994,
          1901,
          51682
        ]
      },
      {
        "avg_logprob": -0.3416342687125158,
        "compression_ratio": 1.6392156862745098,
        "end": 1164.22,
        "id": 189,
        "no_speech_prob": 0.007937776856124401,
        "seek": 115878,
        "start": 1158.78,
        "temperature": 0,
        "text": " Oh all these images are in the latent space and I can walk through the latent space and look at this AI is dreaming",
        "tokens": [
          50364,
          876,
          439,
          613,
          5267,
          366,
          294,
          264,
          48994,
          1901,
          293,
          286,
          393,
          1792,
          807,
          264,
          48994,
          1901,
          293,
          574,
          412,
          341,
          7318,
          307,
          21475,
          50636
        ]
      },
      {
        "avg_logprob": -0.3416342687125158,
        "compression_ratio": 1.6392156862745098,
        "end": 1169.34,
        "id": 190,
        "no_speech_prob": 0.007937776856124401,
        "seek": 115878,
        "start": 1164.22,
        "temperature": 0,
        "text": " About cats in a style Gann 2 latent space of all cats cats and many more cats",
        "tokens": [
          50636,
          7769,
          11111,
          294,
          257,
          3758,
          460,
          969,
          568,
          48994,
          1901,
          295,
          439,
          11111,
          11111,
          293,
          867,
          544,
          11111,
          50892
        ]
      },
      {
        "avg_logprob": -0.3416342687125158,
        "compression_ratio": 1.6392156862745098,
        "end": 1173.58,
        "id": 191,
        "no_speech_prob": 0.007937776856124401,
        "seek": 115878,
        "start": 1171.58,
        "temperature": 0,
        "text": " If you have no idea what any of that means",
        "tokens": [
          51004,
          759,
          291,
          362,
          572,
          1558,
          437,
          604,
          295,
          300,
          1355,
          51104
        ]
      },
      {
        "avg_logprob": -0.3416342687125158,
        "compression_ratio": 1.6392156862745098,
        "end": 1180.98,
        "id": 192,
        "no_speech_prob": 0.007937776856124401,
        "seek": 115878,
        "start": 1174.22,
        "temperature": 0,
        "text": " How could you possibly get started to learn some of the vocabulary feel comfortable with working with these systems even if you're?",
        "tokens": [
          51136,
          1012,
          727,
          291,
          6264,
          483,
          1409,
          281,
          1466,
          512,
          295,
          264,
          19864,
          841,
          4619,
          365,
          1364,
          365,
          613,
          3652,
          754,
          498,
          291,
          434,
          30,
          51474
        ]
      },
      {
        "avg_logprob": -0.3416342687125158,
        "compression_ratio": 1.6392156862745098,
        "end": 1184.48,
        "id": 193,
        "no_speech_prob": 0.007937776856124401,
        "seek": 115878,
        "start": 1181.42,
        "temperature": 0,
        "text": " Ultimately just an end user of pre-trained models",
        "tokens": [
          51496,
          23921,
          445,
          364,
          917,
          4195,
          295,
          659,
          12,
          17227,
          2001,
          5245,
          51649
        ]
      },
      {
        "avg_logprob": -0.3095715840657552,
        "compression_ratio": 1.6441441441441442,
        "end": 1190.08,
        "id": 194,
        "no_speech_prob": 0.028434697538614273,
        "seek": 118448,
        "start": 1184.96,
        "temperature": 0,
        "text": " You're not designing and training the models yourself for me the process of me trying to",
        "tokens": [
          50388,
          509,
          434,
          406,
          14685,
          293,
          3097,
          264,
          5245,
          1803,
          337,
          385,
          264,
          1399,
          295,
          385,
          1382,
          281,
          50644
        ]
      },
      {
        "avg_logprob": -0.3095715840657552,
        "compression_ratio": 1.6441441441441442,
        "end": 1194.6,
        "id": 195,
        "no_speech_prob": 0.028434697538614273,
        "seek": 118448,
        "start": 1190.56,
        "temperature": 0,
        "text": " Sort out how all this stuff works and understand be able to read the style Gann paper",
        "tokens": [
          50668,
          26149,
          484,
          577,
          439,
          341,
          1507,
          1985,
          293,
          1223,
          312,
          1075,
          281,
          1401,
          264,
          3758,
          460,
          969,
          3035,
          50870
        ]
      },
      {
        "avg_logprob": -0.3095715840657552,
        "compression_ratio": 1.6441441441441442,
        "end": 1198.74,
        "id": 196,
        "no_speech_prob": 0.028434697538614273,
        "seek": 118448,
        "start": 1194.72,
        "temperature": 0,
        "text": " And maybe understand a bit more about it begins with auto encoders",
        "tokens": [
          50876,
          400,
          1310,
          1223,
          257,
          857,
          544,
          466,
          309,
          7338,
          365,
          8399,
          2058,
          378,
          433,
          51077
        ]
      },
      {
        "avg_logprob": -0.3095715840657552,
        "compression_ratio": 1.6441441441441442,
        "end": 1201.56,
        "id": 197,
        "no_speech_prob": 0.028434697538614273,
        "seek": 118448,
        "start": 1199.28,
        "temperature": 0,
        "text": " an auto encoder is a",
        "tokens": [
          51104,
          364,
          8399,
          2058,
          19866,
          307,
          257,
          51218
        ]
      },
      {
        "avg_logprob": -0.3095715840657552,
        "compression_ratio": 1.6441441441441442,
        "end": 1204.16,
        "id": 198,
        "no_speech_prob": 0.028434697538614273,
        "seek": 118448,
        "start": 1202.16,
        "temperature": 0,
        "text": " very simple",
        "tokens": [
          51248,
          588,
          2199,
          51348
        ]
      },
      {
        "avg_logprob": -0.3095715840657552,
        "compression_ratio": 1.6441441441441442,
        "end": 1208.38,
        "id": 199,
        "no_speech_prob": 0.028434697538614273,
        "seek": 118448,
        "start": 1204.56,
        "temperature": 0,
        "text": " Well, I know I don't shouldn't say very simple because none of this is particularly simple",
        "tokens": [
          51368,
          1042,
          11,
          286,
          458,
          286,
          500,
          380,
          4659,
          380,
          584,
          588,
          2199,
          570,
          6022,
          295,
          341,
          307,
          4098,
          2199,
          51559
        ]
      },
      {
        "avg_logprob": -0.2876216343470982,
        "compression_ratio": 1.7456140350877194,
        "end": 1214.74,
        "id": 200,
        "no_speech_prob": 0.03621894493699074,
        "seek": 120838,
        "start": 1208.42,
        "temperature": 0,
        "text": " But it is a good starting point to think about how generative models work and at the last live stream",
        "tokens": [
          50366,
          583,
          309,
          307,
          257,
          665,
          2891,
          935,
          281,
          519,
          466,
          577,
          1337,
          1166,
          5245,
          589,
          293,
          412,
          264,
          1036,
          1621,
          4309,
          50682
        ]
      },
      {
        "avg_logprob": -0.2876216343470982,
        "compression_ratio": 1.7456140350877194,
        "end": 1219.38,
        "id": 201,
        "no_speech_prob": 0.03621894493699074,
        "seek": 120838,
        "start": 1214.74,
        "temperature": 0,
        "text": " I went through building this whole diagram to talk about how we could build",
        "tokens": [
          50682,
          286,
          1437,
          807,
          2390,
          341,
          1379,
          10686,
          281,
          751,
          466,
          577,
          321,
          727,
          1322,
          50914
        ]
      },
      {
        "avg_logprob": -0.2876216343470982,
        "compression_ratio": 1.7456140350877194,
        "end": 1223.22,
        "id": 202,
        "no_speech_prob": 0.03621894493699074,
        "seek": 120838,
        "start": 1219.8200000000002,
        "temperature": 0,
        "text": " Something called a copying machine out of a neural network",
        "tokens": [
          50936,
          6595,
          1219,
          257,
          27976,
          3479,
          484,
          295,
          257,
          18161,
          3209,
          51106
        ]
      },
      {
        "avg_logprob": -0.2876216343470982,
        "compression_ratio": 1.7456140350877194,
        "end": 1229.5,
        "id": 203,
        "no_speech_prob": 0.03621894493699074,
        "seek": 120838,
        "start": 1223.5800000000002,
        "temperature": 0,
        "text": " So if an image is sent into the neural network if we could just get that same image back out",
        "tokens": [
          51124,
          407,
          498,
          364,
          3256,
          307,
          2279,
          666,
          264,
          18161,
          3209,
          498,
          321,
          727,
          445,
          483,
          300,
          912,
          3256,
          646,
          484,
          51420
        ]
      },
      {
        "avg_logprob": -0.2876216343470982,
        "compression_ratio": 1.7456140350877194,
        "end": 1233.6200000000001,
        "id": 204,
        "no_speech_prob": 0.03621894493699074,
        "seek": 120838,
        "start": 1229.8200000000002,
        "temperature": 0,
        "text": " Then somehow the neural network would have learned",
        "tokens": [
          51436,
          1396,
          6063,
          264,
          18161,
          3209,
          576,
          362,
          3264,
          51626
        ]
      },
      {
        "avg_logprob": -0.2876216343470982,
        "compression_ratio": 1.7456140350877194,
        "end": 1236.7800000000002,
        "id": 205,
        "no_speech_prob": 0.03621894493699074,
        "seek": 120838,
        "start": 1234.7800000000002,
        "temperature": 0,
        "text": " some type of like",
        "tokens": [
          51684,
          512,
          2010,
          295,
          411,
          51784
        ]
      },
      {
        "avg_logprob": -0.2820905785811575,
        "compression_ratio": 1.7522522522522523,
        "end": 1242.56,
        "id": 206,
        "no_speech_prob": 0.0003250303561799228,
        "seek": 123678,
        "start": 1236.98,
        "temperature": 0,
        "text": " Represent internal representation of that image in a way that it can reproduce it",
        "tokens": [
          50374,
          19945,
          6920,
          10290,
          295,
          300,
          3256,
          294,
          257,
          636,
          300,
          309,
          393,
          29501,
          309,
          50653
        ]
      },
      {
        "avg_logprob": -0.2820905785811575,
        "compression_ratio": 1.7522522522522523,
        "end": 1246.54,
        "id": 207,
        "no_speech_prob": 0.0003250303561799228,
        "seek": 123678,
        "start": 1242.7,
        "temperature": 0,
        "text": " So obviously to copy an image is a simple well",
        "tokens": [
          50660,
          407,
          2745,
          281,
          5055,
          364,
          3256,
          307,
          257,
          2199,
          731,
          50852
        ]
      },
      {
        "avg_logprob": -0.2820905785811575,
        "compression_ratio": 1.7522522522522523,
        "end": 1249.18,
        "id": 208,
        "no_speech_prob": 0.0003250303561799228,
        "seek": 123678,
        "start": 1246.54,
        "temperature": 0,
        "text": " If this is a simple process with an algorithm",
        "tokens": [
          50852,
          759,
          341,
          307,
          257,
          2199,
          1399,
          365,
          364,
          9284,
          50984
        ]
      },
      {
        "avg_logprob": -0.2820905785811575,
        "compression_ratio": 1.7522522522522523,
        "end": 1255.5,
        "id": 209,
        "no_speech_prob": 0.0003250303561799228,
        "seek": 123678,
        "start": 1249.18,
        "temperature": 0,
        "text": " I can just say for every pixel make a new image take an existing image for every pixel",
        "tokens": [
          50984,
          286,
          393,
          445,
          584,
          337,
          633,
          19261,
          652,
          257,
          777,
          3256,
          747,
          364,
          6741,
          3256,
          337,
          633,
          19261,
          51300
        ]
      },
      {
        "avg_logprob": -0.2820905785811575,
        "compression_ratio": 1.7522522522522523,
        "end": 1257.62,
        "id": 210,
        "no_speech_prob": 0.0003250303561799228,
        "seek": 123678,
        "start": 1255.62,
        "temperature": 0,
        "text": " Put the new pixel in the new image",
        "tokens": [
          51306,
          4935,
          264,
          777,
          19261,
          294,
          264,
          777,
          3256,
          51406
        ]
      },
      {
        "avg_logprob": -0.2820905785811575,
        "compression_ratio": 1.7522522522522523,
        "end": 1259.1,
        "id": 211,
        "no_speech_prob": 0.0003250303561799228,
        "seek": 123678,
        "start": 1258.1399999999999,
        "temperature": 0,
        "text": " so",
        "tokens": [
          51432,
          370,
          51480
        ]
      },
      {
        "avg_logprob": -0.2820905785811575,
        "compression_ratio": 1.7522522522522523,
        "end": 1264.94,
        "id": 212,
        "no_speech_prob": 0.0003250303561799228,
        "seek": 123678,
        "start": 1259.1,
        "temperature": 0,
        "text": " The auto encoder is not an efficient copying machine, but it does give us this ability to",
        "tokens": [
          51480,
          440,
          8399,
          2058,
          19866,
          307,
          406,
          364,
          7148,
          27976,
          3479,
          11,
          457,
          309,
          775,
          976,
          505,
          341,
          3485,
          281,
          51772
        ]
      },
      {
        "avg_logprob": -0.31491826089580405,
        "compression_ratio": 1.7393364928909953,
        "end": 1267.7,
        "id": 213,
        "no_speech_prob": 0.0014779282500967383,
        "seek": 126494,
        "start": 1265.7,
        "temperature": 0,
        "text": " Copy the image while also",
        "tokens": [
          50402,
          25653,
          264,
          3256,
          1339,
          611,
          50502
        ]
      },
      {
        "avg_logprob": -0.31491826089580405,
        "compression_ratio": 1.7393364928909953,
        "end": 1273.14,
        "id": 214,
        "no_speech_prob": 0.0014779282500967383,
        "seek": 126494,
        "start": 1268.06,
        "temperature": 0,
        "text": " compressing the data because the idea is if we start if I have a 28 by 28 image with",
        "tokens": [
          50520,
          14778,
          278,
          264,
          1412,
          570,
          264,
          1558,
          307,
          498,
          321,
          722,
          498,
          286,
          362,
          257,
          7562,
          538,
          7562,
          3256,
          365,
          50774
        ]
      },
      {
        "avg_logprob": -0.31491826089580405,
        "compression_ratio": 1.7393364928909953,
        "end": 1278.9,
        "id": 215,
        "no_speech_prob": 0.0014779282500967383,
        "seek": 126494,
        "start": 1273.6200000000001,
        "temperature": 0,
        "text": " 784 pixels as the data moves through these layers of the neural network",
        "tokens": [
          50798,
          1614,
          25494,
          18668,
          382,
          264,
          1412,
          6067,
          807,
          613,
          7914,
          295,
          264,
          18161,
          3209,
          51062
        ]
      },
      {
        "avg_logprob": -0.31491826089580405,
        "compression_ratio": 1.7393364928909953,
        "end": 1283.94,
        "id": 216,
        "no_speech_prob": 0.0014779282500967383,
        "seek": 126494,
        "start": 1278.9,
        "temperature": 0,
        "text": " We have fewer like I have 784 inputs the first layer might only have",
        "tokens": [
          51062,
          492,
          362,
          13366,
          411,
          286,
          362,
          1614,
          25494,
          15743,
          264,
          700,
          4583,
          1062,
          787,
          362,
          51314
        ]
      },
      {
        "avg_logprob": -0.31491826089580405,
        "compression_ratio": 1.7393364928909953,
        "end": 1291.94,
        "id": 217,
        "no_speech_prob": 0.0014779282500967383,
        "seek": 126494,
        "start": 1285.02,
        "temperature": 0,
        "text": " Half of that in neurons and then another layer might have half of that and then so these numbers have to somehow be",
        "tokens": [
          51368,
          15917,
          295,
          300,
          294,
          22027,
          293,
          550,
          1071,
          4583,
          1062,
          362,
          1922,
          295,
          300,
          293,
          550,
          370,
          613,
          3547,
          362,
          281,
          6063,
          312,
          51714
        ]
      },
      {
        "avg_logprob": -0.2731258514079642,
        "compression_ratio": 1.7165991902834008,
        "end": 1296.94,
        "id": 218,
        "no_speech_prob": 0.0006263293907977641,
        "seek": 129194,
        "start": 1292.1000000000001,
        "temperature": 0,
        "text": " Compressed into a smaller amount of numbers that then get expanded back out to the original image",
        "tokens": [
          50372,
          6620,
          3805,
          666,
          257,
          4356,
          2372,
          295,
          3547,
          300,
          550,
          483,
          14342,
          646,
          484,
          281,
          264,
          3380,
          3256,
          50614
        ]
      },
      {
        "avg_logprob": -0.2731258514079642,
        "compression_ratio": 1.7165991902834008,
        "end": 1304.8,
        "id": 219,
        "no_speech_prob": 0.0006263293907977641,
        "seek": 129194,
        "start": 1297.06,
        "temperature": 0,
        "text": " So this is like a copying machine and an image compression engine. It is not an efficient image compression engine",
        "tokens": [
          50620,
          407,
          341,
          307,
          411,
          257,
          27976,
          3479,
          293,
          364,
          3256,
          19355,
          2848,
          13,
          467,
          307,
          406,
          364,
          7148,
          3256,
          19355,
          2848,
          51007
        ]
      },
      {
        "avg_logprob": -0.2731258514079642,
        "compression_ratio": 1.7165991902834008,
        "end": 1312.06,
        "id": 220,
        "no_speech_prob": 0.0006263293907977641,
        "seek": 129194,
        "start": 1305.54,
        "temperature": 0,
        "text": " Because if we really want to do image compression to save high resolution image with less file space on a on a hard drive",
        "tokens": [
          51044,
          1436,
          498,
          321,
          534,
          528,
          281,
          360,
          3256,
          19355,
          281,
          3155,
          1090,
          8669,
          3256,
          365,
          1570,
          3991,
          1901,
          322,
          257,
          322,
          257,
          1152,
          3332,
          51370
        ]
      },
      {
        "avg_logprob": -0.2731258514079642,
        "compression_ratio": 1.7165991902834008,
        "end": 1316.78,
        "id": 221,
        "no_speech_prob": 0.0006263293907977641,
        "seek": 129194,
        "start": 1312.2,
        "temperature": 0,
        "text": " We could just use JPEG or other kind of known tried-and-true image compression algorithms",
        "tokens": [
          51377,
          492,
          727,
          445,
          764,
          508,
          5208,
          38,
          420,
          661,
          733,
          295,
          2570,
          3031,
          12,
          474,
          12,
          6903,
          622,
          3256,
          19355,
          14642,
          51606
        ]
      },
      {
        "avg_logprob": -0.3225404991293853,
        "compression_ratio": 1.7679324894514767,
        "end": 1324.06,
        "id": 222,
        "no_speech_prob": 0.0017007102724164724,
        "seek": 131678,
        "start": 1316.94,
        "temperature": 0,
        "text": " But if we are able to take the at these images compress them down and have the neural network the auto encoder learn how to",
        "tokens": [
          50372,
          583,
          498,
          321,
          366,
          1075,
          281,
          747,
          264,
          412,
          613,
          5267,
          14778,
          552,
          760,
          293,
          362,
          264,
          18161,
          3209,
          264,
          8399,
          2058,
          19866,
          1466,
          577,
          281,
          50728
        ]
      },
      {
        "avg_logprob": -0.3225404991293853,
        "compression_ratio": 1.7679324894514767,
        "end": 1327.1,
        "id": 223,
        "no_speech_prob": 0.0017007102724164724,
        "seek": 131678,
        "start": 1324.62,
        "temperature": 0,
        "text": " Decode them right we have an encoder and a decoder",
        "tokens": [
          50756,
          12427,
          1429,
          552,
          558,
          321,
          362,
          364,
          2058,
          19866,
          293,
          257,
          979,
          19866,
          50880
        ]
      },
      {
        "avg_logprob": -0.3225404991293853,
        "compression_ratio": 1.7679324894514767,
        "end": 1330.78,
        "id": 224,
        "no_speech_prob": 0.0017007102724164724,
        "seek": 131678,
        "start": 1327.3799999999999,
        "temperature": 0,
        "text": " Then at some point and hopefully I'll get to this part today",
        "tokens": [
          50894,
          1396,
          412,
          512,
          935,
          293,
          4696,
          286,
          603,
          483,
          281,
          341,
          644,
          965,
          51064
        ]
      },
      {
        "avg_logprob": -0.3225404991293853,
        "compression_ratio": 1.7679324894514767,
        "end": 1334.58,
        "id": 225,
        "no_speech_prob": 0.0017007102724164724,
        "seek": 131678,
        "start": 1330.78,
        "temperature": 0,
        "text": " I can take off after I've trained it I can take out",
        "tokens": [
          51064,
          286,
          393,
          747,
          766,
          934,
          286,
          600,
          8895,
          309,
          286,
          393,
          747,
          484,
          51254
        ]
      },
      {
        "avg_logprob": -0.3225404991293853,
        "compression_ratio": 1.7679324894514767,
        "end": 1337.34,
        "id": 226,
        "no_speech_prob": 0.0017007102724164724,
        "seek": 131678,
        "start": 1334.82,
        "temperature": 0,
        "text": " The encoder and just start with the decoder",
        "tokens": [
          51266,
          440,
          2058,
          19866,
          293,
          445,
          722,
          365,
          264,
          979,
          19866,
          51392
        ]
      },
      {
        "avg_logprob": -0.3225404991293853,
        "compression_ratio": 1.7679324894514767,
        "end": 1343.06,
        "id": 227,
        "no_speech_prob": 0.0017007102724164724,
        "seek": 131678,
        "start": 1337.5,
        "temperature": 0,
        "text": " feed in noise and generate new images in the style of the original training data set or",
        "tokens": [
          51400,
          3154,
          294,
          5658,
          293,
          8460,
          777,
          5267,
          294,
          264,
          3758,
          295,
          264,
          3380,
          3097,
          1412,
          992,
          420,
          51678
        ]
      },
      {
        "avg_logprob": -0.29255719020448884,
        "compression_ratio": 1.7715355805243447,
        "end": 1347.82,
        "id": 228,
        "no_speech_prob": 0.0006070707459002733,
        "seek": 134306,
        "start": 1343.22,
        "temperature": 0,
        "text": " I could do certain kinds of operations like image denoising for example",
        "tokens": [
          50372,
          286,
          727,
          360,
          1629,
          3685,
          295,
          7705,
          411,
          3256,
          1441,
          78,
          3436,
          337,
          1365,
          50602
        ]
      },
      {
        "avg_logprob": -0.29255719020448884,
        "compression_ratio": 1.7715355805243447,
        "end": 1352.5,
        "id": 229,
        "no_speech_prob": 0.0006070707459002733,
        "seek": 134306,
        "start": 1347.82,
        "temperature": 0,
        "text": " What if I sent a noisy image in right if these are all the example?",
        "tokens": [
          50602,
          708,
          498,
          286,
          2279,
          257,
          24518,
          3256,
          294,
          558,
          498,
          613,
          366,
          439,
          264,
          1365,
          30,
          50836
        ]
      },
      {
        "avg_logprob": -0.29255719020448884,
        "compression_ratio": 1.7715355805243447,
        "end": 1354.3799999999999,
        "id": 230,
        "no_speech_prob": 0.0006070707459002733,
        "seek": 134306,
        "start": 1352.5,
        "temperature": 0,
        "text": " I'm using is I'm just using geometric shapes",
        "tokens": [
          50836,
          286,
          478,
          1228,
          307,
          286,
          478,
          445,
          1228,
          33246,
          10854,
          50930
        ]
      },
      {
        "avg_logprob": -0.29255719020448884,
        "compression_ratio": 1.7715355805243447,
        "end": 1360.58,
        "id": 231,
        "no_speech_prob": 0.0006070707459002733,
        "seek": 134306,
        "start": 1354.3799999999999,
        "temperature": 0,
        "text": " So if the auto encoder learns the internal and internal representation of what it means to render a square",
        "tokens": [
          50930,
          407,
          498,
          264,
          8399,
          2058,
          19866,
          27152,
          264,
          6920,
          293,
          6920,
          10290,
          295,
          437,
          309,
          1355,
          281,
          15529,
          257,
          3732,
          51240
        ]
      },
      {
        "avg_logprob": -0.29255719020448884,
        "compression_ratio": 1.7715355805243447,
        "end": 1365.7,
        "id": 232,
        "no_speech_prob": 0.0006070707459002733,
        "seek": 134306,
        "start": 1360.7,
        "temperature": 0,
        "text": " If I send it a noisy square it will then take that and in theory",
        "tokens": [
          51246,
          759,
          286,
          2845,
          309,
          257,
          24518,
          3732,
          309,
          486,
          550,
          747,
          300,
          293,
          294,
          5261,
          51496
        ]
      },
      {
        "avg_logprob": -0.29255719020448884,
        "compression_ratio": 1.7715355805243447,
        "end": 1372.4199999999998,
        "id": 233,
        "no_speech_prob": 0.0006070707459002733,
        "seek": 134306,
        "start": 1366.1799999999998,
        "temperature": 0,
        "text": " Rerender it back out without the noise. That's the idea so this is what I'm working with I went through this diagram",
        "tokens": [
          51520,
          497,
          260,
          3216,
          309,
          646,
          484,
          1553,
          264,
          5658,
          13,
          663,
          311,
          264,
          1558,
          370,
          341,
          307,
          437,
          286,
          478,
          1364,
          365,
          286,
          1437,
          807,
          341,
          10686,
          51832
        ]
      },
      {
        "avg_logprob": -0.3993721008300781,
        "compression_ratio": 1.5241379310344827,
        "end": 1375.7,
        "id": 234,
        "no_speech_prob": 0.0016743127489462495,
        "seek": 137242,
        "start": 1372.7,
        "temperature": 0,
        "text": " probably in a much longer period of time and then",
        "tokens": [
          50378,
          1391,
          294,
          257,
          709,
          2854,
          2896,
          295,
          565,
          293,
          550,
          50528
        ]
      },
      {
        "avg_logprob": -0.3993721008300781,
        "compression_ratio": 1.5241379310344827,
        "end": 1379.46,
        "id": 235,
        "no_speech_prob": 0.0016743127489462495,
        "seek": 137242,
        "start": 1377.22,
        "temperature": 0,
        "text": " Looked at if I come back over here",
        "tokens": [
          50604,
          2053,
          292,
          412,
          498,
          286,
          808,
          646,
          670,
          510,
          50716
        ]
      },
      {
        "avg_logprob": -0.3993721008300781,
        "compression_ratio": 1.5241379310344827,
        "end": 1382.98,
        "id": 236,
        "no_speech_prob": 0.0016743127489462495,
        "seek": 137242,
        "start": 1380.98,
        "temperature": 0,
        "text": " And I",
        "tokens": [
          50792,
          400,
          286,
          50892
        ]
      },
      {
        "avg_logprob": -0.3993721008300781,
        "compression_ratio": 1.5241379310344827,
        "end": 1389.74,
        "id": 237,
        "no_speech_prob": 0.0016743127489462495,
        "seek": 137242,
        "start": 1383.5800000000002,
        "temperature": 0,
        "text": " See some comments hold on come back over here now, and I still got five minutes left in my recap of before",
        "tokens": [
          50922,
          3008,
          512,
          3053,
          1797,
          322,
          808,
          646,
          670,
          510,
          586,
          11,
          293,
          286,
          920,
          658,
          1732,
          2077,
          1411,
          294,
          452,
          20928,
          295,
          949,
          51230
        ]
      },
      {
        "avg_logprob": -0.3993721008300781,
        "compression_ratio": 1.5241379310344827,
        "end": 1391.9,
        "id": 238,
        "no_speech_prob": 0.0016743127489462495,
        "seek": 137242,
        "start": 1390.8200000000002,
        "temperature": 0,
        "text": " and",
        "tokens": [
          51284,
          293,
          51338
        ]
      },
      {
        "avg_logprob": -0.3993721008300781,
        "compression_ratio": 1.5241379310344827,
        "end": 1393.9,
        "id": 239,
        "no_speech_prob": 0.0016743127489462495,
        "seek": 137242,
        "start": 1391.9,
        "temperature": 0,
        "text": " If I come back here",
        "tokens": [
          51338,
          759,
          286,
          808,
          646,
          510,
          51438
        ]
      },
      {
        "avg_logprob": -0.37924766540527344,
        "compression_ratio": 1.6008771929824561,
        "end": 1395.8200000000002,
        "id": 240,
        "no_speech_prob": 0.002396688563749194,
        "seek": 139390,
        "start": 1394.46,
        "temperature": 0,
        "text": " What was I trying to say?",
        "tokens": [
          50392,
          708,
          390,
          286,
          1382,
          281,
          584,
          30,
          50460
        ]
      },
      {
        "avg_logprob": -0.37924766540527344,
        "compression_ratio": 1.6008771929824561,
        "end": 1404.18,
        "id": 241,
        "no_speech_prob": 0.002396688563749194,
        "seek": 139390,
        "start": 1395.8200000000002,
        "temperature": 0,
        "text": " François Chollet yes, okay, so this is a article from 2016 so quite a while ago where I first encountered the idea of an auto encoder",
        "tokens": [
          50460,
          1526,
          12368,
          7376,
          761,
          1833,
          302,
          2086,
          11,
          1392,
          11,
          370,
          341,
          307,
          257,
          7222,
          490,
          6549,
          370,
          1596,
          257,
          1339,
          2057,
          689,
          286,
          700,
          20381,
          264,
          1558,
          295,
          364,
          8399,
          2058,
          19866,
          50878
        ]
      },
      {
        "avg_logprob": -0.37924766540527344,
        "compression_ratio": 1.6008771929824561,
        "end": 1409.0600000000002,
        "id": 242,
        "no_speech_prob": 0.002396688563749194,
        "seek": 139390,
        "start": 1404.66,
        "temperature": 0,
        "text": " This encoder and decoder this original input compressed representation",
        "tokens": [
          50902,
          639,
          2058,
          19866,
          293,
          979,
          19866,
          341,
          3380,
          4846,
          30353,
          10290,
          51122
        ]
      },
      {
        "avg_logprob": -0.37924766540527344,
        "compression_ratio": 1.6008771929824561,
        "end": 1412.5800000000002,
        "id": 243,
        "no_speech_prob": 0.002396688563749194,
        "seek": 139390,
        "start": 1409.42,
        "temperature": 0,
        "text": " Reconstructed input the output is the reconstructed input",
        "tokens": [
          51140,
          1300,
          25279,
          1757,
          292,
          4846,
          264,
          5598,
          307,
          264,
          31499,
          292,
          4846,
          51298
        ]
      },
      {
        "avg_logprob": -0.37924766540527344,
        "compression_ratio": 1.6008771929824561,
        "end": 1417.5800000000002,
        "id": 244,
        "no_speech_prob": 0.002396688563749194,
        "seek": 139390,
        "start": 1413.02,
        "temperature": 0,
        "text": " and there is sort of a guide here explanation as well as a guide for how to",
        "tokens": [
          51320,
          293,
          456,
          307,
          1333,
          295,
          257,
          5934,
          510,
          10835,
          382,
          731,
          382,
          257,
          5934,
          337,
          577,
          281,
          51548
        ]
      },
      {
        "avg_logprob": -0.3019700604815816,
        "compression_ratio": 1.663677130044843,
        "end": 1425.02,
        "id": 245,
        "no_speech_prob": 0.05834222212433815,
        "seek": 141758,
        "start": 1418.4199999999998,
        "temperature": 0,
        "text": " Build these layers using a library called Keras which was a sort of higher level",
        "tokens": [
          50406,
          11875,
          613,
          7914,
          1228,
          257,
          6405,
          1219,
          591,
          6985,
          597,
          390,
          257,
          1333,
          295,
          2946,
          1496,
          50736
        ]
      },
      {
        "avg_logprob": -0.3019700604815816,
        "compression_ratio": 1.663677130044843,
        "end": 1429.86,
        "id": 246,
        "no_speech_prob": 0.05834222212433815,
        "seek": 141758,
        "start": 1425.02,
        "temperature": 0,
        "text": " Which is some I should know this maybe somebody in the chat could could kind of explain",
        "tokens": [
          50736,
          3013,
          307,
          512,
          286,
          820,
          458,
          341,
          1310,
          2618,
          294,
          264,
          5081,
          727,
          727,
          733,
          295,
          2903,
          50978
        ]
      },
      {
        "avg_logprob": -0.3019700604815816,
        "compression_ratio": 1.663677130044843,
        "end": 1437.76,
        "id": 247,
        "no_speech_prob": 0.05834222212433815,
        "seek": 141758,
        "start": 1429.86,
        "temperature": 0,
        "text": " But like does Keras still exist or is it really just now fully integrated into tensorflow and not called Keras anymore?",
        "tokens": [
          50978,
          583,
          411,
          775,
          591,
          6985,
          920,
          2514,
          420,
          307,
          309,
          534,
          445,
          586,
          4498,
          10919,
          666,
          40863,
          10565,
          293,
          406,
          1219,
          591,
          6985,
          3602,
          30,
          51373
        ]
      },
      {
        "avg_logprob": -0.3019700604815816,
        "compression_ratio": 1.663677130044843,
        "end": 1444.3,
        "id": 248,
        "no_speech_prob": 0.05834222212433815,
        "seek": 141758,
        "start": 1437.76,
        "temperature": 0,
        "text": " But when Keras was first developed it was a kind of higher level layer if you will",
        "tokens": [
          51373,
          583,
          562,
          591,
          6985,
          390,
          700,
          4743,
          309,
          390,
          257,
          733,
          295,
          2946,
          1496,
          4583,
          498,
          291,
          486,
          51700
        ]
      },
      {
        "avg_logprob": -0.3269200275853737,
        "compression_ratio": 1.654708520179372,
        "end": 1447.44,
        "id": 249,
        "no_speech_prob": 0.002889457391574979,
        "seek": 144430,
        "start": 1444.82,
        "temperature": 0,
        "text": " Above lower level machine learning libraries",
        "tokens": [
          50390,
          32691,
          3126,
          1496,
          3479,
          2539,
          15148,
          50521
        ]
      },
      {
        "avg_logprob": -0.3269200275853737,
        "compression_ratio": 1.654708520179372,
        "end": 1451.58,
        "id": 250,
        "no_speech_prob": 0.002889457391574979,
        "seek": 144430,
        "start": 1447.44,
        "temperature": 0,
        "text": " So you could say things like create a neural network with this kind of architecture in",
        "tokens": [
          50521,
          407,
          291,
          727,
          584,
          721,
          411,
          1884,
          257,
          18161,
          3209,
          365,
          341,
          733,
          295,
          9482,
          294,
          50728
        ]
      },
      {
        "avg_logprob": -0.3269200275853737,
        "compression_ratio": 1.654708520179372,
        "end": 1453.6599999999999,
        "id": 251,
        "no_speech_prob": 0.002889457391574979,
        "seek": 144430,
        "start": 1451.98,
        "temperature": 0,
        "text": " Keras in a sort of higher level way",
        "tokens": [
          50748,
          591,
          6985,
          294,
          257,
          1333,
          295,
          2946,
          1496,
          636,
          50832
        ]
      },
      {
        "avg_logprob": -0.3269200275853737,
        "compression_ratio": 1.654708520179372,
        "end": 1460.6599999999999,
        "id": 252,
        "no_speech_prob": 0.002889457391574979,
        "seek": 144430,
        "start": 1453.6599999999999,
        "temperature": 0,
        "text": " And you could plug tensorflow into it to do the actual lower level of intuition or PyTorch or other ones so the way I",
        "tokens": [
          50832,
          400,
          291,
          727,
          5452,
          40863,
          10565,
          666,
          309,
          281,
          360,
          264,
          3539,
          3126,
          1496,
          295,
          24002,
          420,
          9953,
          51,
          284,
          339,
          420,
          661,
          2306,
          370,
          264,
          636,
          286,
          51182
        ]
      },
      {
        "avg_logprob": -0.3269200275853737,
        "compression_ratio": 1.654708520179372,
        "end": 1463.46,
        "id": 253,
        "no_speech_prob": 0.002889457391574979,
        "seek": 144430,
        "start": 1461.1399999999999,
        "temperature": 0,
        "text": " know and work with Keras is",
        "tokens": [
          51206,
          458,
          293,
          589,
          365,
          591,
          6985,
          307,
          51322
        ]
      },
      {
        "avg_logprob": -0.3269200275853737,
        "compression_ratio": 1.654708520179372,
        "end": 1466.62,
        "id": 254,
        "no_speech_prob": 0.002889457391574979,
        "seek": 144430,
        "start": 1464.62,
        "temperature": 0,
        "text": " by working in",
        "tokens": [
          51380,
          538,
          1364,
          294,
          51480
        ]
      },
      {
        "avg_logprob": -0.3269200275853737,
        "compression_ratio": 1.654708520179372,
        "end": 1468.86,
        "id": 255,
        "no_speech_prob": 0.002889457391574979,
        "seek": 144430,
        "start": 1466.86,
        "temperature": 0,
        "text": " tensorflow.js",
        "tokens": [
          51492,
          40863,
          10565,
          13,
          25530,
          51592
        ]
      },
      {
        "avg_logprob": -0.3269200275853737,
        "compression_ratio": 1.654708520179372,
        "end": 1472.78,
        "id": 256,
        "no_speech_prob": 0.002889457391574979,
        "seek": 144430,
        "start": 1470.78,
        "temperature": 0,
        "text": " Which I want to look at the",
        "tokens": [
          51688,
          3013,
          286,
          528,
          281,
          574,
          412,
          264,
          51788
        ]
      },
      {
        "avg_logprob": -0.33575858567890365,
        "compression_ratio": 1.5748502994011977,
        "end": 1478.54,
        "id": 257,
        "no_speech_prob": 0.0002652958792168647,
        "seek": 147430,
        "start": 1474.98,
        "temperature": 0,
        "text": " This is I want to I think it's just like js.tensorflow",
        "tokens": [
          50398,
          639,
          307,
          286,
          528,
          281,
          286,
          519,
          309,
          311,
          445,
          411,
          42713,
          13,
          83,
          23153,
          10565,
          50576
        ]
      },
      {
        "avg_logprob": -0.33575858567890365,
        "compression_ratio": 1.5748502994011977,
        "end": 1485.08,
        "id": 258,
        "no_speech_prob": 0.0002652958792168647,
        "seek": 147430,
        "start": 1482.4199999999998,
        "temperature": 0,
        "text": " Let's see if this yeah, and I want to go to the API",
        "tokens": [
          50770,
          961,
          311,
          536,
          498,
          341,
          1338,
          11,
          293,
          286,
          528,
          281,
          352,
          281,
          264,
          9362,
          50903
        ]
      },
      {
        "avg_logprob": -0.33575858567890365,
        "compression_ratio": 1.5748502994011977,
        "end": 1490.78,
        "id": 259,
        "no_speech_prob": 0.0002652958792168647,
        "seek": 147430,
        "start": 1486.22,
        "temperature": 0,
        "text": " In the tensorflow.js API there is a particular",
        "tokens": [
          50960,
          682,
          264,
          40863,
          10565,
          13,
          25530,
          9362,
          456,
          307,
          257,
          1729,
          51188
        ]
      },
      {
        "avg_logprob": -0.33575858567890365,
        "compression_ratio": 1.5748502994011977,
        "end": 1493.86,
        "id": 260,
        "no_speech_prob": 0.0002652958792168647,
        "seek": 147430,
        "start": 1491.86,
        "temperature": 0,
        "text": " set of functions",
        "tokens": [
          51242,
          992,
          295,
          6828,
          51342
        ]
      },
      {
        "avg_logprob": -0.33575858567890365,
        "compression_ratio": 1.5748502994011977,
        "end": 1501.46,
        "id": 261,
        "no_speech_prob": 0.0002652958792168647,
        "seek": 147430,
        "start": 1494.06,
        "temperature": 0,
        "text": " objects that are part of the layers that are called layers tf.layers layers model sequential",
        "tokens": [
          51352,
          6565,
          300,
          366,
          644,
          295,
          264,
          7914,
          300,
          366,
          1219,
          7914,
          256,
          69,
          13,
          8376,
          433,
          7914,
          2316,
          42881,
          51722
        ]
      },
      {
        "avg_logprob": -0.31791757401965914,
        "compression_ratio": 1.592783505154639,
        "end": 1507.66,
        "id": 262,
        "no_speech_prob": 0.000282402615994215,
        "seek": 150146,
        "start": 1502.06,
        "temperature": 0,
        "text": " layers here we go and this is a net this is essentially the",
        "tokens": [
          50394,
          7914,
          510,
          321,
          352,
          293,
          341,
          307,
          257,
          2533,
          341,
          307,
          4476,
          264,
          50674
        ]
      },
      {
        "avg_logprob": -0.31791757401965914,
        "compression_ratio": 1.592783505154639,
        "end": 1511.98,
        "id": 263,
        "no_speech_prob": 0.000282402615994215,
        "seek": 150146,
        "start": 1508.18,
        "temperature": 0,
        "text": " original the modeled after or directly ported from the Keras",
        "tokens": [
          50700,
          3380,
          264,
          37140,
          934,
          420,
          3838,
          2436,
          292,
          490,
          264,
          591,
          6985,
          50890
        ]
      },
      {
        "avg_logprob": -0.31791757401965914,
        "compression_ratio": 1.592783505154639,
        "end": 1515.42,
        "id": 264,
        "no_speech_prob": 0.000282402615994215,
        "seek": 150146,
        "start": 1512.8600000000001,
        "temperature": 0,
        "text": " Python library. Oh, I hear somebody",
        "tokens": [
          50934,
          15329,
          6405,
          13,
          876,
          11,
          286,
          1568,
          2618,
          51062
        ]
      },
      {
        "avg_logprob": -0.31791757401965914,
        "compression_ratio": 1.592783505154639,
        "end": 1518.26,
        "id": 265,
        "no_speech_prob": 0.000282402615994215,
        "seek": 150146,
        "start": 1516.26,
        "temperature": 0,
        "text": " Hello",
        "tokens": [
          51104,
          2425,
          51204
        ]
      },
      {
        "avg_logprob": -0.31791757401965914,
        "compression_ratio": 1.592783505154639,
        "end": 1524.3,
        "id": 266,
        "no_speech_prob": 0.000282402615994215,
        "seek": 150146,
        "start": 1519.22,
        "temperature": 0,
        "text": " Take a short intermission. I've got I've got a visitor. I'll be right be right back",
        "tokens": [
          51252,
          3664,
          257,
          2099,
          728,
          29797,
          13,
          286,
          600,
          658,
          286,
          600,
          658,
          257,
          28222,
          13,
          286,
          603,
          312,
          558,
          312,
          558,
          646,
          51506
        ]
      },
      {
        "avg_logprob": -0.31791757401965914,
        "compression_ratio": 1.592783505154639,
        "end": 1528.68,
        "id": 267,
        "no_speech_prob": 0.000282402615994215,
        "seek": 150146,
        "start": 1524.3,
        "temperature": 0,
        "text": " I'm just putting on intermission, and I'll be right back music",
        "tokens": [
          51506,
          286,
          478,
          445,
          3372,
          322,
          728,
          29797,
          11,
          293,
          286,
          603,
          312,
          558,
          646,
          1318,
          51725
        ]
      },
      {
        "avg_logprob": -0.923162579536438,
        "compression_ratio": 0.38461538461538464,
        "end": 1533.46,
        "id": 268,
        "no_speech_prob": 0.9103384613990784,
        "seek": 153146,
        "start": 1531.46,
        "temperature": 0,
        "text": " music",
        "tokens": [
          50364,
          1318,
          50464
        ]
      },
      {
        "avg_logprob": -0.4071474942294034,
        "compression_ratio": 1.3900709219858156,
        "end": 1563.46,
        "id": 269,
        "no_speech_prob": 0.09399115294218063,
        "seek": 156146,
        "start": 1561.46,
        "temperature": 0.2,
        "text": " music",
        "tokens": [
          50364,
          1318,
          50464
        ]
      },
      {
        "avg_logprob": -0.4071474942294034,
        "compression_ratio": 1.3900709219858156,
        "end": 1571.4,
        "id": 270,
        "no_speech_prob": 0.09399115294218063,
        "seek": 156146,
        "start": 1569.4,
        "temperature": 0.2,
        "text": " Okay back",
        "tokens": [
          50761,
          1033,
          646,
          50861
        ]
      },
      {
        "avg_logprob": -0.4071474942294034,
        "compression_ratio": 1.3900709219858156,
        "end": 1576.58,
        "id": 271,
        "no_speech_prob": 0.09399115294218063,
        "seek": 156146,
        "start": 1574.58,
        "temperature": 0.2,
        "text": " Okay, I'm back",
        "tokens": [
          51020,
          1033,
          11,
          286,
          478,
          646,
          51120
        ]
      },
      {
        "avg_logprob": -0.4071474942294034,
        "compression_ratio": 1.3900709219858156,
        "end": 1582.6200000000001,
        "id": 272,
        "no_speech_prob": 0.09399115294218063,
        "seek": 156146,
        "start": 1580.6200000000001,
        "temperature": 0.2,
        "text": " Stretch all right I",
        "tokens": [
          51322,
          38817,
          439,
          558,
          286,
          51422
        ]
      },
      {
        "avg_logprob": -0.4071474942294034,
        "compression_ratio": 1.3900709219858156,
        "end": 1589.66,
        "id": 273,
        "no_speech_prob": 0.09399115294218063,
        "seek": 156146,
        "start": 1583.14,
        "temperature": 0.2,
        "text": " Disconnected the internet in the house, which is causing some some problems, but we're gonna. We're all we're all gonna get through this together",
        "tokens": [
          51448,
          4208,
          9826,
          292,
          264,
          4705,
          294,
          264,
          1782,
          11,
          597,
          307,
          9853,
          512,
          512,
          2740,
          11,
          457,
          321,
          434,
          799,
          13,
          492,
          434,
          439,
          321,
          434,
          439,
          799,
          483,
          807,
          341,
          1214,
          51774
        ]
      },
      {
        "avg_logprob": -0.386131690530216,
        "compression_ratio": 1.4834123222748816,
        "end": 1594.02,
        "id": 274,
        "no_speech_prob": 0.0043992516584694386,
        "seek": 159146,
        "start": 1592.02,
        "temperature": 0,
        "text": " Okay",
        "tokens": [
          50392,
          1033,
          50492
        ]
      },
      {
        "avg_logprob": -0.386131690530216,
        "compression_ratio": 1.4834123222748816,
        "end": 1596.9,
        "id": 275,
        "no_speech_prob": 0.0043992516584694386,
        "seek": 159146,
        "start": 1594.26,
        "temperature": 0,
        "text": " I forgot where I was",
        "tokens": [
          50504,
          286,
          5298,
          689,
          286,
          390,
          50636
        ]
      },
      {
        "avg_logprob": -0.386131690530216,
        "compression_ratio": 1.4834123222748816,
        "end": 1599.5,
        "id": 276,
        "no_speech_prob": 0.0043992516584694386,
        "seek": 159146,
        "start": 1597.6200000000001,
        "temperature": 0,
        "text": " Well, I was talking about",
        "tokens": [
          50672,
          1042,
          11,
          286,
          390,
          1417,
          466,
          50766
        ]
      },
      {
        "avg_logprob": -0.386131690530216,
        "compression_ratio": 1.4834123222748816,
        "end": 1603.7,
        "id": 277,
        "no_speech_prob": 0.0043992516584694386,
        "seek": 159146,
        "start": 1599.5,
        "temperature": 0,
        "text": " TensorFlow.js, so oh and you don't see that now let me come back here",
        "tokens": [
          50766,
          37624,
          13,
          25530,
          11,
          370,
          1954,
          293,
          291,
          500,
          380,
          536,
          300,
          586,
          718,
          385,
          808,
          646,
          510,
          50976
        ]
      },
      {
        "avg_logprob": -0.386131690530216,
        "compression_ratio": 1.4834123222748816,
        "end": 1612.3,
        "id": 278,
        "no_speech_prob": 0.0043992516584694386,
        "seek": 159146,
        "start": 1603.78,
        "temperature": 0,
        "text": " So the code that I began to write is as follows so obviously I went through this in greater detail in the previous stream",
        "tokens": [
          50980,
          407,
          264,
          3089,
          300,
          286,
          4283,
          281,
          2464,
          307,
          382,
          10002,
          370,
          2745,
          286,
          1437,
          807,
          341,
          294,
          5044,
          2607,
          294,
          264,
          3894,
          4309,
          51406
        ]
      },
      {
        "avg_logprob": -0.386131690530216,
        "compression_ratio": 1.4834123222748816,
        "end": 1616.3400000000001,
        "id": 279,
        "no_speech_prob": 0.0043992516584694386,
        "seek": 159146,
        "start": 1612.78,
        "temperature": 0,
        "text": " But I've got a node. I'm eventually gonna turn this into a web server",
        "tokens": [
          51430,
          583,
          286,
          600,
          658,
          257,
          9984,
          13,
          286,
          478,
          4728,
          799,
          1261,
          341,
          666,
          257,
          3670,
          7154,
          51608
        ]
      },
      {
        "avg_logprob": -0.262625908365055,
        "compression_ratio": 1.625,
        "end": 1621.74,
        "id": 280,
        "no_speech_prob": 0.19190357625484467,
        "seek": 161634,
        "start": 1616.34,
        "temperature": 0,
        "text": " But this is just a node script ultimately right now a little node project where I'm creating a sequential model",
        "tokens": [
          50364,
          583,
          341,
          307,
          445,
          257,
          9984,
          5755,
          6284,
          558,
          586,
          257,
          707,
          9984,
          1716,
          689,
          286,
          478,
          4084,
          257,
          42881,
          2316,
          50634
        ]
      },
      {
        "avg_logprob": -0.262625908365055,
        "compression_ratio": 1.625,
        "end": 1626.62,
        "id": 281,
        "no_speech_prob": 0.19190357625484467,
        "seek": 161634,
        "start": 1621.86,
        "temperature": 0,
        "text": " That is exactly I'm trying to recreate this exact model in code now",
        "tokens": [
          50640,
          663,
          307,
          2293,
          286,
          478,
          1382,
          281,
          25833,
          341,
          1900,
          2316,
          294,
          3089,
          586,
          50878
        ]
      },
      {
        "avg_logprob": -0.262625908365055,
        "compression_ratio": 1.625,
        "end": 1630.82,
        "id": 282,
        "no_speech_prob": 0.19190357625484467,
        "seek": 161634,
        "start": 1627.22,
        "temperature": 0,
        "text": " I'm calling it an auto encoder because that's the application that I'm doing",
        "tokens": [
          50908,
          286,
          478,
          5141,
          309,
          364,
          8399,
          2058,
          19866,
          570,
          300,
          311,
          264,
          3861,
          300,
          286,
          478,
          884,
          51088
        ]
      },
      {
        "avg_logprob": -0.262625908365055,
        "compression_ratio": 1.625,
        "end": 1636.6,
        "id": 283,
        "no_speech_prob": 0.19190357625484467,
        "seek": 161634,
        "start": 1631.34,
        "temperature": 0,
        "text": " It starts with an encoder which is a dense layer that receives",
        "tokens": [
          51114,
          467,
          3719,
          365,
          364,
          2058,
          19866,
          597,
          307,
          257,
          18011,
          4583,
          300,
          20717,
          51377
        ]
      },
      {
        "avg_logprob": -0.262625908365055,
        "compression_ratio": 1.625,
        "end": 1642.62,
        "id": 284,
        "no_speech_prob": 0.19190357625484467,
        "seek": 161634,
        "start": 1637.26,
        "temperature": 0,
        "text": " 784 inputs because my images are gonna be 28 by 28. I'm arbitrarily having it be 32",
        "tokens": [
          51410,
          1614,
          25494,
          15743,
          570,
          452,
          5267,
          366,
          799,
          312,
          7562,
          538,
          7562,
          13,
          286,
          478,
          19071,
          3289,
          1419,
          309,
          312,
          8858,
          51678
        ]
      },
      {
        "avg_logprob": -0.26136315310442887,
        "compression_ratio": 1.648068669527897,
        "end": 1646.1799999999998,
        "id": 285,
        "no_speech_prob": 0.00844548549503088,
        "seek": 164262,
        "start": 1643.1399999999999,
        "temperature": 0,
        "text": " Units then it decodes back to 784",
        "tokens": [
          50390,
          1156,
          1208,
          550,
          309,
          979,
          4789,
          646,
          281,
          1614,
          25494,
          50542
        ]
      },
      {
        "avg_logprob": -0.26136315310442887,
        "compression_ratio": 1.648068669527897,
        "end": 1648.78,
        "id": 286,
        "no_speech_prob": 0.00844548549503088,
        "seek": 164262,
        "start": 1646.78,
        "temperature": 0,
        "text": " It's just those it's this is like",
        "tokens": [
          50572,
          467,
          311,
          445,
          729,
          309,
          311,
          341,
          307,
          411,
          50672
        ]
      },
      {
        "avg_logprob": -0.26136315310442887,
        "compression_ratio": 1.648068669527897,
        "end": 1653.82,
        "id": 287,
        "no_speech_prob": 0.00844548549503088,
        "seek": 164262,
        "start": 1648.78,
        "temperature": 0,
        "text": " It's just two layers just one layer for the encoder and one layer for the decoder",
        "tokens": [
          50672,
          467,
          311,
          445,
          732,
          7914,
          445,
          472,
          4583,
          337,
          264,
          2058,
          19866,
          293,
          472,
          4583,
          337,
          264,
          979,
          19866,
          50924
        ]
      },
      {
        "avg_logprob": -0.26136315310442887,
        "compression_ratio": 1.648068669527897,
        "end": 1660.4199999999998,
        "id": 288,
        "no_speech_prob": 0.00844548549503088,
        "seek": 164262,
        "start": 1653.82,
        "temperature": 0,
        "text": " And then I've set up an optimizer a loss function. These are things. I also talked about in the previous",
        "tokens": [
          50924,
          400,
          550,
          286,
          600,
          992,
          493,
          364,
          5028,
          6545,
          257,
          4470,
          2445,
          13,
          1981,
          366,
          721,
          13,
          286,
          611,
          2825,
          466,
          294,
          264,
          3894,
          51254
        ]
      },
      {
        "avg_logprob": -0.26136315310442887,
        "compression_ratio": 1.648068669527897,
        "end": 1665.4399999999998,
        "id": 289,
        "no_speech_prob": 0.00844548549503088,
        "seek": 164262,
        "start": 1661.02,
        "temperature": 0,
        "text": " I've only got a minute left here in my recap so you know I can touch on those as we go",
        "tokens": [
          51284,
          286,
          600,
          787,
          658,
          257,
          3456,
          1411,
          510,
          294,
          452,
          20928,
          370,
          291,
          458,
          286,
          393,
          2557,
          322,
          729,
          382,
          321,
          352,
          51505
        ]
      },
      {
        "avg_logprob": -0.26136315310442887,
        "compression_ratio": 1.648068669527897,
        "end": 1668.86,
        "id": 290,
        "no_speech_prob": 0.00844548549503088,
        "seek": 164262,
        "start": 1665.9799999999998,
        "temperature": 0,
        "text": " And then I just fed it with a random noise",
        "tokens": [
          51532,
          400,
          550,
          286,
          445,
          4636,
          309,
          365,
          257,
          4974,
          5658,
          51676
        ]
      },
      {
        "avg_logprob": -0.30064858888324936,
        "compression_ratio": 1.588235294117647,
        "end": 1675.4399999999998,
        "id": 291,
        "no_speech_prob": 0.002216988243162632,
        "seek": 166886,
        "start": 1669.86,
        "temperature": 0,
        "text": " So where I left off is I now would like to and I have this processing sketch",
        "tokens": [
          50414,
          407,
          689,
          286,
          1411,
          766,
          307,
          286,
          586,
          576,
          411,
          281,
          293,
          286,
          362,
          341,
          9007,
          12325,
          50693
        ]
      },
      {
        "avg_logprob": -0.30064858888324936,
        "compression_ratio": 1.588235294117647,
        "end": 1680.4599999999998,
        "id": 292,
        "no_speech_prob": 0.002216988243162632,
        "seek": 166886,
        "start": 1676.3799999999999,
        "temperature": 0,
        "text": " Which generates a variety of square images of squares?",
        "tokens": [
          50740,
          3013,
          23815,
          257,
          5673,
          295,
          3732,
          5267,
          295,
          19368,
          30,
          50944
        ]
      },
      {
        "avg_logprob": -0.30064858888324936,
        "compression_ratio": 1.588235294117647,
        "end": 1683.26,
        "id": 293,
        "no_speech_prob": 0.002216988243162632,
        "seek": 166886,
        "start": 1681.26,
        "temperature": 0,
        "text": " I have those",
        "tokens": [
          50984,
          286,
          362,
          729,
          51084
        ]
      },
      {
        "avg_logprob": -0.30064858888324936,
        "compression_ratio": 1.588235294117647,
        "end": 1688.1,
        "id": 294,
        "no_speech_prob": 0.002216988243162632,
        "seek": 166886,
        "start": 1683.5,
        "temperature": 0,
        "text": " Hopefully if I could find them here in a folder called data",
        "tokens": [
          51096,
          10429,
          498,
          286,
          727,
          915,
          552,
          510,
          294,
          257,
          10820,
          1219,
          1412,
          51326
        ]
      },
      {
        "avg_logprob": -0.30064858888324936,
        "compression_ratio": 1.588235294117647,
        "end": 1694.1999999999998,
        "id": 295,
        "no_speech_prob": 0.002216988243162632,
        "seek": 166886,
        "start": 1689.4399999999998,
        "temperature": 0,
        "text": " So now I would like to feed the auto encoder these actual images",
        "tokens": [
          51393,
          407,
          586,
          286,
          576,
          411,
          281,
          3154,
          264,
          8399,
          2058,
          19866,
          613,
          3539,
          5267,
          51631
        ]
      },
      {
        "avg_logprob": -0.30064858888324936,
        "compression_ratio": 1.588235294117647,
        "end": 1696.34,
        "id": 296,
        "no_speech_prob": 0.002216988243162632,
        "seek": 166886,
        "start": 1695.1,
        "temperature": 0,
        "text": " expand",
        "tokens": [
          51676,
          5268,
          51738
        ]
      },
      {
        "avg_logprob": -0.30064858888324936,
        "compression_ratio": 1.588235294117647,
        "end": 1698.34,
        "id": 297,
        "no_speech_prob": 0.002216988243162632,
        "seek": 166886,
        "start": 1696.34,
        "temperature": 0,
        "text": " the number of layers",
        "tokens": [
          51738,
          264,
          1230,
          295,
          7914,
          51838
        ]
      },
      {
        "avg_logprob": -0.3745293452821929,
        "compression_ratio": 1.5121951219512195,
        "end": 1700.86,
        "id": 298,
        "no_speech_prob": 0.0043314420618116856,
        "seek": 169886,
        "start": 1698.86,
        "temperature": 0,
        "text": " and",
        "tokens": [
          50364,
          293,
          50464
        ]
      },
      {
        "avg_logprob": -0.3745293452821929,
        "compression_ratio": 1.5121951219512195,
        "end": 1706.06,
        "id": 299,
        "no_speech_prob": 0.0043314420618116856,
        "seek": 169886,
        "start": 1703.78,
        "temperature": 0,
        "text": " I'm reading the chat. Yeah, so my",
        "tokens": [
          50610,
          286,
          478,
          3760,
          264,
          5081,
          13,
          865,
          11,
          370,
          452,
          50724
        ]
      },
      {
        "avg_logprob": -0.3745293452821929,
        "compression_ratio": 1.5121951219512195,
        "end": 1713.34,
        "id": 300,
        "no_speech_prob": 0.0043314420618116856,
        "seek": 169886,
        "start": 1706.8999999999999,
        "temperature": 0,
        "text": " Things are complicated these days for me as they are for everybody my kids are home. I disconnected their internet my wife is out of town",
        "tokens": [
          50766,
          9514,
          366,
          6179,
          613,
          1708,
          337,
          385,
          382,
          436,
          366,
          337,
          2201,
          452,
          2301,
          366,
          1280,
          13,
          286,
          29426,
          641,
          4705,
          452,
          3836,
          307,
          484,
          295,
          3954,
          51088
        ]
      },
      {
        "avg_logprob": -0.3745293452821929,
        "compression_ratio": 1.5121951219512195,
        "end": 1715.58,
        "id": 301,
        "no_speech_prob": 0.0043314420618116856,
        "seek": 169886,
        "start": 1713.9399999999998,
        "temperature": 0,
        "text": " so",
        "tokens": [
          51118,
          370,
          51200
        ]
      },
      {
        "avg_logprob": -0.3745293452821929,
        "compression_ratio": 1.5121951219512195,
        "end": 1717.6599999999999,
        "id": 302,
        "no_speech_prob": 0.0043314420618116856,
        "seek": 169886,
        "start": 1715.58,
        "temperature": 0,
        "text": " They're having a couple hours of free time",
        "tokens": [
          51200,
          814,
          434,
          1419,
          257,
          1916,
          2496,
          295,
          1737,
          565,
          51304
        ]
      },
      {
        "avg_logprob": -0.3745293452821929,
        "compression_ratio": 1.5121951219512195,
        "end": 1720.1799999999998,
        "id": 303,
        "no_speech_prob": 0.0043314420618116856,
        "seek": 169886,
        "start": 1718.54,
        "temperature": 0,
        "text": " but",
        "tokens": [
          51348,
          457,
          51430
        ]
      },
      {
        "avg_logprob": -0.3745293452821929,
        "compression_ratio": 1.5121951219512195,
        "end": 1724.2199999999998,
        "id": 304,
        "no_speech_prob": 0.0043314420618116856,
        "seek": 169886,
        "start": 1720.1799999999998,
        "temperature": 0,
        "text": " And I wanted to get this out of the way because oh oh my god. What is beeping at me?",
        "tokens": [
          51430,
          400,
          286,
          1415,
          281,
          483,
          341,
          484,
          295,
          264,
          636,
          570,
          1954,
          1954,
          452,
          3044,
          13,
          708,
          307,
          34800,
          412,
          385,
          30,
          51632
        ]
      },
      {
        "avg_logprob": -0.32600692340305876,
        "compression_ratio": 1.603921568627451,
        "end": 1730.58,
        "id": 305,
        "no_speech_prob": 0.023688852787017822,
        "seek": 172422,
        "start": 1724.22,
        "temperature": 0,
        "text": " Oh, it's the timer do you hear that like what's happening? There's a beeper going on okay, okay, okay?",
        "tokens": [
          50364,
          876,
          11,
          309,
          311,
          264,
          19247,
          360,
          291,
          1568,
          300,
          411,
          437,
          311,
          2737,
          30,
          821,
          311,
          257,
          28678,
          260,
          516,
          322,
          1392,
          11,
          1392,
          11,
          1392,
          30,
          50682
        ]
      },
      {
        "avg_logprob": -0.32600692340305876,
        "compression_ratio": 1.603921568627451,
        "end": 1733.6200000000001,
        "id": 306,
        "no_speech_prob": 0.023688852787017822,
        "seek": 172422,
        "start": 1730.58,
        "temperature": 0,
        "text": " I got you. We're gonna get started with the code whoops",
        "tokens": [
          50682,
          286,
          658,
          291,
          13,
          492,
          434,
          799,
          483,
          1409,
          365,
          264,
          3089,
          567,
          3370,
          50834
        ]
      },
      {
        "avg_logprob": -0.32600692340305876,
        "compression_ratio": 1.603921568627451,
        "end": 1737.7,
        "id": 307,
        "no_speech_prob": 0.023688852787017822,
        "seek": 172422,
        "start": 1735.14,
        "temperature": 0,
        "text": " But I know I've lost track of what I'm saying",
        "tokens": [
          50910,
          583,
          286,
          458,
          286,
          600,
          2731,
          2837,
          295,
          437,
          286,
          478,
          1566,
          51038
        ]
      },
      {
        "avg_logprob": -0.32600692340305876,
        "compression_ratio": 1.603921568627451,
        "end": 1742.6200000000001,
        "id": 308,
        "no_speech_prob": 0.023688852787017822,
        "seek": 172422,
        "start": 1738.02,
        "temperature": 0,
        "text": " But I I've got lots of things to do with them tomorrow next week through Thanksgiving",
        "tokens": [
          51054,
          583,
          286,
          286,
          600,
          658,
          3195,
          295,
          721,
          281,
          360,
          365,
          552,
          4153,
          958,
          1243,
          807,
          21230,
          51284
        ]
      },
      {
        "avg_logprob": -0.32600692340305876,
        "compression_ratio": 1.603921568627451,
        "end": 1745.18,
        "id": 309,
        "no_speech_prob": 0.023688852787017822,
        "seek": 172422,
        "start": 1742.6200000000001,
        "temperature": 0,
        "text": " And so I was just if I could just do this stream today",
        "tokens": [
          51284,
          400,
          370,
          286,
          390,
          445,
          498,
          286,
          727,
          445,
          360,
          341,
          4309,
          965,
          51412
        ]
      },
      {
        "avg_logprob": -0.32600692340305876,
        "compression_ratio": 1.603921568627451,
        "end": 1749.8600000000001,
        "id": 310,
        "no_speech_prob": 0.023688852787017822,
        "seek": 172422,
        "start": 1746.66,
        "temperature": 0,
        "text": " Then I can kind of figure everything out next week so here I am",
        "tokens": [
          51486,
          1396,
          286,
          393,
          733,
          295,
          2573,
          1203,
          484,
          958,
          1243,
          370,
          510,
          286,
          669,
          51646
        ]
      },
      {
        "avg_logprob": -0.5911369323730469,
        "compression_ratio": 1.4350649350649352,
        "end": 1752.58,
        "id": 311,
        "no_speech_prob": 0.00004264640301698819,
        "seek": 174986,
        "start": 1750.1,
        "temperature": 0,
        "text": " High computational mama in the chat so",
        "tokens": [
          50376,
          5229,
          28270,
          18775,
          294,
          264,
          5081,
          370,
          50500
        ]
      },
      {
        "avg_logprob": -0.5911369323730469,
        "compression_ratio": 1.4350649350649352,
        "end": 1761.54,
        "id": 312,
        "no_speech_prob": 0.00004264640301698819,
        "seek": 174986,
        "start": 1755.6599999999999,
        "temperature": 0,
        "text": " Let's see okay, how we are how we all feeling about that any questions about what I've covered so far",
        "tokens": [
          50654,
          961,
          311,
          536,
          1392,
          11,
          577,
          321,
          366,
          577,
          321,
          439,
          2633,
          466,
          300,
          604,
          1651,
          466,
          437,
          286,
          600,
          5343,
          370,
          1400,
          50948
        ]
      },
      {
        "avg_logprob": -0.5911369323730469,
        "compression_ratio": 1.4350649350649352,
        "end": 1773.74,
        "id": 313,
        "no_speech_prob": 0.00004264640301698819,
        "seek": 174986,
        "start": 1767.8999999999999,
        "temperature": 0,
        "text": " Before I get started here, and I'm thinking I'm gonna need to read in the images",
        "tokens": [
          51266,
          4546,
          286,
          483,
          1409,
          510,
          11,
          293,
          286,
          478,
          1953,
          286,
          478,
          799,
          643,
          281,
          1401,
          294,
          264,
          5267,
          51558
        ]
      },
      {
        "avg_logprob": -0.5668792724609375,
        "compression_ratio": 1.5582822085889572,
        "end": 1775.98,
        "id": 314,
        "no_speech_prob": 0.0012842908035963774,
        "seek": 177374,
        "start": 1773.98,
        "temperature": 0,
        "text": " How do I want to read in the images",
        "tokens": [
          50376,
          1012,
          360,
          286,
          528,
          281,
          1401,
          294,
          264,
          5267,
          50476
        ]
      },
      {
        "avg_logprob": -0.5668792724609375,
        "compression_ratio": 1.5582822085889572,
        "end": 1786.86,
        "id": 315,
        "no_speech_prob": 0.0012842908035963774,
        "seek": 177374,
        "start": 1780.02,
        "temperature": 0,
        "text": " Anybody got a suggestion for a node package that I should use I mean I could use just the file system package to read",
        "tokens": [
          50678,
          19082,
          658,
          257,
          16541,
          337,
          257,
          9984,
          7372,
          300,
          286,
          820,
          764,
          286,
          914,
          286,
          727,
          764,
          445,
          264,
          3991,
          1185,
          7372,
          281,
          1401,
          51020
        ]
      },
      {
        "avg_logprob": -0.5668792724609375,
        "compression_ratio": 1.5582822085889572,
        "end": 1793.58,
        "id": 316,
        "no_speech_prob": 0.0012842908035963774,
        "seek": 177374,
        "start": 1787.42,
        "temperature": 0,
        "text": " The files that I need to unpack them into their pixels and turn those into tensors",
        "tokens": [
          51048,
          440,
          7098,
          300,
          286,
          643,
          281,
          26699,
          552,
          666,
          641,
          18668,
          293,
          1261,
          729,
          666,
          10688,
          830,
          51356
        ]
      },
      {
        "avg_logprob": -0.5668792724609375,
        "compression_ratio": 1.5582822085889572,
        "end": 1798.5,
        "id": 317,
        "no_speech_prob": 0.0012842908035963774,
        "seek": 177374,
        "start": 1796.5,
        "temperature": 0,
        "text": " Oh Gloria Pickles",
        "tokens": [
          51502,
          876,
          34288,
          14129,
          904,
          51602
        ]
      },
      {
        "avg_logprob": -0.5697667076474144,
        "compression_ratio": 1.6512605042016806,
        "end": 1800.5,
        "id": 318,
        "no_speech_prob": 0.09008003771305084,
        "seek": 179850,
        "start": 1798.5,
        "temperature": 0,
        "text": " Oh",
        "tokens": [
          50364,
          876,
          50464
        ]
      },
      {
        "avg_logprob": -0.5697667076474144,
        "compression_ratio": 1.6512605042016806,
        "end": 1804.3,
        "id": 319,
        "no_speech_prob": 0.09008003771305084,
        "seek": 179850,
        "start": 1800.5,
        "temperature": 0,
        "text": " You know what now I'm feeling kind of guilty, but she was out all day",
        "tokens": [
          50464,
          509,
          458,
          437,
          586,
          286,
          478,
          2633,
          733,
          295,
          12341,
          11,
          457,
          750,
          390,
          484,
          439,
          786,
          50654
        ]
      },
      {
        "avg_logprob": -0.5697667076474144,
        "compression_ratio": 1.6512605042016806,
        "end": 1811.42,
        "id": 320,
        "no_speech_prob": 0.09008003771305084,
        "seek": 179850,
        "start": 1805.3,
        "temperature": 0,
        "text": " Earlier today with me as I was going around and we had a nice walk. She's in her sleeping in her crate",
        "tokens": [
          50704,
          24552,
          965,
          365,
          385,
          382,
          286,
          390,
          516,
          926,
          293,
          321,
          632,
          257,
          1481,
          1792,
          13,
          1240,
          311,
          294,
          720,
          8296,
          294,
          720,
          42426,
          51010
        ]
      },
      {
        "avg_logprob": -0.5697667076474144,
        "compression_ratio": 1.6512605042016806,
        "end": 1817.1,
        "id": 321,
        "no_speech_prob": 0.09008003771305084,
        "seek": 179850,
        "start": 1811.42,
        "temperature": 0,
        "text": " She's she's crate trained. She loves her crate. She feels very safe in there. There's ever time about my dog by the way",
        "tokens": [
          51010,
          1240,
          311,
          750,
          311,
          42426,
          8895,
          13,
          1240,
          6752,
          720,
          42426,
          13,
          1240,
          3417,
          588,
          3273,
          294,
          456,
          13,
          821,
          311,
          1562,
          565,
          466,
          452,
          3000,
          538,
          264,
          636,
          51294
        ]
      },
      {
        "avg_logprob": -0.5697667076474144,
        "compression_ratio": 1.6512605042016806,
        "end": 1819.1,
        "id": 322,
        "no_speech_prob": 0.09008003771305084,
        "seek": 179850,
        "start": 1817.1,
        "temperature": 0,
        "text": " Not my daughter",
        "tokens": [
          51294,
          1726,
          452,
          4653,
          51394
        ]
      },
      {
        "avg_logprob": -0.5697667076474144,
        "compression_ratio": 1.6512605042016806,
        "end": 1824.42,
        "id": 323,
        "no_speech_prob": 0.09008003771305084,
        "seek": 179850,
        "start": 1819.1,
        "temperature": 0,
        "text": " My children are free range right now in the house the dog I often have free range",
        "tokens": [
          51394,
          1222,
          2227,
          366,
          1737,
          3613,
          558,
          586,
          294,
          264,
          1782,
          264,
          3000,
          286,
          2049,
          362,
          1737,
          3613,
          51660
        ]
      },
      {
        "avg_logprob": -0.28690655562129336,
        "compression_ratio": 1.7854785478547854,
        "end": 1830.46,
        "id": 324,
        "no_speech_prob": 0.0351385697722435,
        "seek": 182442,
        "start": 1824.42,
        "temperature": 0,
        "text": " My children are free range right now in the house the dog I often have her with me, but she's sleeping in her crate",
        "tokens": [
          50364,
          1222,
          2227,
          366,
          1737,
          3613,
          558,
          586,
          294,
          264,
          1782,
          264,
          3000,
          286,
          2049,
          362,
          720,
          365,
          385,
          11,
          457,
          750,
          311,
          8296,
          294,
          720,
          42426,
          50666
        ]
      },
      {
        "avg_logprob": -0.28690655562129336,
        "compression_ratio": 1.7854785478547854,
        "end": 1832.46,
        "id": 325,
        "no_speech_prob": 0.0351385697722435,
        "seek": 182442,
        "start": 1830.46,
        "temperature": 0,
        "text": " I was about to say like",
        "tokens": [
          50666,
          286,
          390,
          466,
          281,
          584,
          411,
          50766
        ]
      },
      {
        "avg_logprob": -0.28690655562129336,
        "compression_ratio": 1.7854785478547854,
        "end": 1837.42,
        "id": 326,
        "no_speech_prob": 0.0351385697722435,
        "seek": 182442,
        "start": 1833.3000000000002,
        "temperature": 0,
        "text": " That's her favorite spot like if there's a thunderstorm. She's terrified. She just wants to be in her crate",
        "tokens": [
          50808,
          663,
          311,
          720,
          2954,
          4008,
          411,
          498,
          456,
          311,
          257,
          39618,
          13,
          1240,
          311,
          23051,
          13,
          1240,
          445,
          2738,
          281,
          312,
          294,
          720,
          42426,
          51014
        ]
      },
      {
        "avg_logprob": -0.28690655562129336,
        "compression_ratio": 1.7854785478547854,
        "end": 1840.3000000000002,
        "id": 327,
        "no_speech_prob": 0.0351385697722435,
        "seek": 182442,
        "start": 1837.5800000000002,
        "temperature": 0,
        "text": " So she sleeps in her crate at night very comfortable there",
        "tokens": [
          51022,
          407,
          750,
          37991,
          294,
          720,
          42426,
          412,
          1818,
          588,
          4619,
          456,
          51158
        ]
      },
      {
        "avg_logprob": -0.28690655562129336,
        "compression_ratio": 1.7854785478547854,
        "end": 1843.94,
        "id": 328,
        "no_speech_prob": 0.0351385697722435,
        "seek": 182442,
        "start": 1840.3000000000002,
        "temperature": 0,
        "text": " But I don't want to leave her there for more than a couple hours",
        "tokens": [
          51158,
          583,
          286,
          500,
          380,
          528,
          281,
          1856,
          720,
          456,
          337,
          544,
          813,
          257,
          1916,
          2496,
          51340
        ]
      },
      {
        "avg_logprob": -0.28690655562129336,
        "compression_ratio": 1.7854785478547854,
        "end": 1848.54,
        "id": 329,
        "no_speech_prob": 0.0351385697722435,
        "seek": 182442,
        "start": 1843.94,
        "temperature": 0,
        "text": " Then I need to let her out after her nap to roam free outside and be here, okay",
        "tokens": [
          51340,
          1396,
          286,
          643,
          281,
          718,
          720,
          484,
          934,
          720,
          9296,
          281,
          40474,
          1737,
          2380,
          293,
          312,
          510,
          11,
          1392,
          51570
        ]
      },
      {
        "avg_logprob": -0.28690655562129336,
        "compression_ratio": 1.7854785478547854,
        "end": 1853.92,
        "id": 330,
        "no_speech_prob": 0.0351385697722435,
        "seek": 182442,
        "start": 1849.14,
        "temperature": 0,
        "text": " I want to make me some coffee after watching, but don't want to leave this stream, LA new",
        "tokens": [
          51600,
          286,
          528,
          281,
          652,
          385,
          512,
          4982,
          934,
          1976,
          11,
          457,
          500,
          380,
          528,
          281,
          1856,
          341,
          4309,
          11,
          9855,
          777,
          51839
        ]
      },
      {
        "avg_logprob": -0.2953453063964844,
        "compression_ratio": 1.7125,
        "end": 1862.42,
        "id": 331,
        "no_speech_prob": 0.0000822013316792436,
        "seek": 185442,
        "start": 1855.26,
        "temperature": 0,
        "text": " I really think LA noob you should make yourself some coffee. You're not gonna miss anything trust me",
        "tokens": [
          50406,
          286,
          534,
          519,
          9855,
          572,
          996,
          291,
          820,
          652,
          1803,
          512,
          4982,
          13,
          509,
          434,
          406,
          799,
          1713,
          1340,
          3361,
          385,
          50764
        ]
      },
      {
        "avg_logprob": -0.2953453063964844,
        "compression_ratio": 1.7125,
        "end": 1867.5800000000002,
        "id": 332,
        "no_speech_prob": 0.0000822013316792436,
        "seek": 185442,
        "start": 1863.22,
        "temperature": 0,
        "text": " Couple minutes to make some coffee. I really doubt you're gonna miss anything critical",
        "tokens": [
          50804,
          38266,
          2077,
          281,
          652,
          512,
          4982,
          13,
          286,
          534,
          6385,
          291,
          434,
          799,
          1713,
          1340,
          4924,
          51022
        ]
      },
      {
        "avg_logprob": -0.2953453063964844,
        "compression_ratio": 1.7125,
        "end": 1870.3400000000001,
        "id": 333,
        "no_speech_prob": 0.0000822013316792436,
        "seek": 185442,
        "start": 1868.3400000000001,
        "temperature": 0,
        "text": " All right",
        "tokens": [
          51060,
          1057,
          558,
          51160
        ]
      },
      {
        "avg_logprob": -0.2953453063964844,
        "compression_ratio": 1.7125,
        "end": 1873.9,
        "id": 334,
        "no_speech_prob": 0.0000822013316792436,
        "seek": 185442,
        "start": 1871.02,
        "temperature": 0,
        "text": " Can you restate what you need to do with the files, okay, I",
        "tokens": [
          51194,
          1664,
          291,
          1472,
          473,
          437,
          291,
          643,
          281,
          360,
          365,
          264,
          7098,
          11,
          1392,
          11,
          286,
          51338
        ]
      },
      {
        "avg_logprob": -0.2953453063964844,
        "compression_ratio": 1.7125,
        "end": 1880.5,
        "id": 335,
        "no_speech_prob": 0.0000822013316792436,
        "seek": 185442,
        "start": 1875.22,
        "temperature": 0,
        "text": " Need I have all these images. I want to load them, so I want to write. Let's write some pseudocode",
        "tokens": [
          51404,
          16984,
          286,
          362,
          439,
          613,
          5267,
          13,
          286,
          528,
          281,
          3677,
          552,
          11,
          370,
          286,
          528,
          281,
          2464,
          13,
          961,
          311,
          2464,
          512,
          25505,
          532,
          905,
          1429,
          51668
        ]
      },
      {
        "avg_logprob": -0.2953453063964844,
        "compression_ratio": 1.7125,
        "end": 1883.42,
        "id": 336,
        "no_speech_prob": 0.0000822013316792436,
        "seek": 185442,
        "start": 1881.42,
        "temperature": 0,
        "text": " I'm gonna do it right here. I'm gonna write a function",
        "tokens": [
          51714,
          286,
          478,
          799,
          360,
          309,
          558,
          510,
          13,
          286,
          478,
          799,
          2464,
          257,
          2445,
          51814
        ]
      },
      {
        "avg_logprob": -0.3483687251447195,
        "compression_ratio": 1.4636871508379887,
        "end": 1887.14,
        "id": 337,
        "no_speech_prob": 0.001410332159139216,
        "seek": 188442,
        "start": 1884.74,
        "temperature": 0,
        "text": " I will call it load images I",
        "tokens": [
          50380,
          286,
          486,
          818,
          309,
          3677,
          5267,
          286,
          50500
        ]
      },
      {
        "avg_logprob": -0.3483687251447195,
        "compression_ratio": 1.4636871508379887,
        "end": 1890.22,
        "id": 338,
        "no_speech_prob": 0.001410332159139216,
        "seek": 188442,
        "start": 1888.3000000000002,
        "temperature": 0,
        "text": " am going to",
        "tokens": [
          50558,
          669,
          516,
          281,
          50654
        ]
      },
      {
        "avg_logprob": -0.3483687251447195,
        "compression_ratio": 1.4636871508379887,
        "end": 1893.74,
        "id": 339,
        "no_speech_prob": 0.001410332159139216,
        "seek": 188442,
        "start": 1890.22,
        "temperature": 0,
        "text": " Load all image files in the data",
        "tokens": [
          50654,
          48408,
          439,
          3256,
          7098,
          294,
          264,
          1412,
          50830
        ]
      },
      {
        "avg_logprob": -0.3483687251447195,
        "compression_ratio": 1.4636871508379887,
        "end": 1896.18,
        "id": 340,
        "no_speech_prob": 0.001410332159139216,
        "seek": 188442,
        "start": 1894.54,
        "temperature": 0,
        "text": " folder",
        "tokens": [
          50870,
          10820,
          50952
        ]
      },
      {
        "avg_logprob": -0.3483687251447195,
        "compression_ratio": 1.4636871508379887,
        "end": 1898.18,
        "id": 341,
        "no_speech_prob": 0.001410332159139216,
        "seek": 188442,
        "start": 1896.18,
        "temperature": 0,
        "text": " Read the pixels",
        "tokens": [
          50952,
          17604,
          264,
          18668,
          51052
        ]
      },
      {
        "avg_logprob": -0.3483687251447195,
        "compression_ratio": 1.4636871508379887,
        "end": 1901.54,
        "id": 342,
        "no_speech_prob": 0.001410332159139216,
        "seek": 188442,
        "start": 1898.66,
        "temperature": 0,
        "text": " convert the pixels to",
        "tokens": [
          51076,
          7620,
          264,
          18668,
          281,
          51220
        ]
      },
      {
        "avg_logprob": -0.3483687251447195,
        "compression_ratio": 1.4636871508379887,
        "end": 1904.5800000000002,
        "id": 343,
        "no_speech_prob": 0.001410332159139216,
        "seek": 188442,
        "start": 1902.5800000000002,
        "temperature": 0,
        "text": " tensors for TFJS",
        "tokens": [
          51272,
          10688,
          830,
          337,
          40964,
          41,
          50,
          51372
        ]
      },
      {
        "avg_logprob": -0.3483687251447195,
        "compression_ratio": 1.4636871508379887,
        "end": 1906.5800000000002,
        "id": 344,
        "no_speech_prob": 0.001410332159139216,
        "seek": 188442,
        "start": 1905.14,
        "temperature": 0,
        "text": " So this is what I need to do",
        "tokens": [
          51400,
          407,
          341,
          307,
          437,
          286,
          643,
          281,
          360,
          51472
        ]
      },
      {
        "avg_logprob": -0.3483687251447195,
        "compression_ratio": 1.4636871508379887,
        "end": 1912.52,
        "id": 345,
        "no_speech_prob": 0.001410332159139216,
        "seek": 188442,
        "start": 1906.5800000000002,
        "temperature": 0,
        "text": " I know how to do the last stop because I'm familiar with TensorFlow.js. It's stuff that I've done",
        "tokens": [
          51472,
          286,
          458,
          577,
          281,
          360,
          264,
          1036,
          1590,
          570,
          286,
          478,
          4963,
          365,
          37624,
          13,
          25530,
          13,
          467,
          311,
          1507,
          300,
          286,
          600,
          1096,
          51769
        ]
      },
      {
        "avg_logprob": -0.3206601236380783,
        "compression_ratio": 1.6458333333333333,
        "end": 1917.48,
        "id": 346,
        "no_speech_prob": 0.008445496670901775,
        "seek": 191252,
        "start": 1912.68,
        "temperature": 0,
        "text": " I know how to load image files in general. I would use the node file system package",
        "tokens": [
          50372,
          286,
          458,
          577,
          281,
          3677,
          3256,
          7098,
          294,
          2674,
          13,
          286,
          576,
          764,
          264,
          9984,
          3991,
          1185,
          7372,
          50612
        ]
      },
      {
        "avg_logprob": -0.3206601236380783,
        "compression_ratio": 1.6458333333333333,
        "end": 1923.72,
        "id": 347,
        "no_speech_prob": 0.008445496670901775,
        "seek": 191252,
        "start": 1918.76,
        "temperature": 0,
        "text": " Okay, the door open you got your phone. You're good. Does it it'll connect automatically right?",
        "tokens": [
          50676,
          1033,
          11,
          264,
          2853,
          1269,
          291,
          658,
          428,
          2593,
          13,
          509,
          434,
          665,
          13,
          4402,
          309,
          309,
          603,
          1745,
          6772,
          558,
          30,
          50924
        ]
      },
      {
        "avg_logprob": -0.3206601236380783,
        "compression_ratio": 1.6458333333333333,
        "end": 1926.44,
        "id": 348,
        "no_speech_prob": 0.008445496670901775,
        "seek": 191252,
        "start": 1924.44,
        "temperature": 0,
        "text": " Okay, okay",
        "tokens": [
          50960,
          1033,
          11,
          1392,
          51060
        ]
      },
      {
        "avg_logprob": -0.3206601236380783,
        "compression_ratio": 1.6458333333333333,
        "end": 1931.5,
        "id": 349,
        "no_speech_prob": 0.008445496670901775,
        "seek": 191252,
        "start": 1927.52,
        "temperature": 0,
        "text": " It's a little chilly in there because I didn't turn the heat on but you can turn the heat on if you want",
        "tokens": [
          51114,
          467,
          311,
          257,
          707,
          39815,
          294,
          456,
          570,
          286,
          994,
          380,
          1261,
          264,
          3738,
          322,
          457,
          291,
          393,
          1261,
          264,
          3738,
          322,
          498,
          291,
          528,
          51313
        ]
      },
      {
        "avg_logprob": -0.3206601236380783,
        "compression_ratio": 1.6458333333333333,
        "end": 1941.36,
        "id": 350,
        "no_speech_prob": 0.008445496670901775,
        "seek": 191252,
        "start": 1934.12,
        "temperature": 0,
        "text": " The thermostat on the wall, it's a little thing you just go bring it there you're closing this okay",
        "tokens": [
          51444,
          440,
          8810,
          39036,
          322,
          264,
          2929,
          11,
          309,
          311,
          257,
          707,
          551,
          291,
          445,
          352,
          1565,
          309,
          456,
          291,
          434,
          10377,
          341,
          1392,
          51806
        ]
      },
      {
        "avg_logprob": -0.3438217476622699,
        "compression_ratio": 1.5061728395061729,
        "end": 1945.36,
        "id": 351,
        "no_speech_prob": 0.0008167230989784002,
        "seek": 194252,
        "start": 1943.36,
        "temperature": 0,
        "text": " Okay",
        "tokens": [
          50406,
          1033,
          50506
        ]
      },
      {
        "avg_logprob": -0.3438217476622699,
        "compression_ratio": 1.5061728395061729,
        "end": 1948.96,
        "id": 352,
        "no_speech_prob": 0.0008167230989784002,
        "seek": 194252,
        "start": 1945.96,
        "temperature": 0,
        "text": " So I could use the file system package and",
        "tokens": [
          50536,
          407,
          286,
          727,
          764,
          264,
          3991,
          1185,
          7372,
          293,
          50686
        ]
      },
      {
        "avg_logprob": -0.3438217476622699,
        "compression_ratio": 1.5061728395061729,
        "end": 1954.32,
        "id": 353,
        "no_speech_prob": 0.0008167230989784002,
        "seek": 194252,
        "start": 1949.92,
        "temperature": 0,
        "text": " The file system package allows me to load files. Let's just",
        "tokens": [
          50734,
          440,
          3991,
          1185,
          7372,
          4045,
          385,
          281,
          3677,
          7098,
          13,
          961,
          311,
          445,
          50954
        ]
      },
      {
        "avg_logprob": -0.3438217476622699,
        "compression_ratio": 1.5061728395061729,
        "end": 1958.98,
        "id": 354,
        "no_speech_prob": 0.0008167230989784002,
        "seek": 194252,
        "start": 1954.92,
        "temperature": 0,
        "text": " What no no just turn it to like 70 where it says 70. I think it's a good number",
        "tokens": [
          50984,
          708,
          572,
          572,
          445,
          1261,
          309,
          281,
          411,
          5285,
          689,
          309,
          1619,
          5285,
          13,
          286,
          519,
          309,
          311,
          257,
          665,
          1230,
          51187
        ]
      },
      {
        "avg_logprob": -0.3438217476622699,
        "compression_ratio": 1.5061728395061729,
        "end": 1965.48,
        "id": 355,
        "no_speech_prob": 0.0008167230989784002,
        "seek": 194252,
        "start": 1962.96,
        "temperature": 0,
        "text": " So let's see so let's see load",
        "tokens": [
          51386,
          407,
          718,
          311,
          536,
          370,
          718,
          311,
          536,
          3677,
          51512
        ]
      },
      {
        "avg_logprob": -0.3438217476622699,
        "compression_ratio": 1.5061728395061729,
        "end": 1970.6399999999999,
        "id": 356,
        "no_speech_prob": 0.0008167230989784002,
        "seek": 194252,
        "start": 1967.28,
        "temperature": 0,
        "text": " Read image pixels node.js",
        "tokens": [
          51602,
          17604,
          3256,
          18668,
          9984,
          13,
          25530,
          51770
        ]
      },
      {
        "avg_logprob": -0.33695465326309204,
        "compression_ratio": 1.5621621621621622,
        "end": 1979.44,
        "id": 357,
        "no_speech_prob": 0.0007321560406126082,
        "seek": 197064,
        "start": 1971.64,
        "temperature": 0,
        "text": " Get an array of pixels from an image using node.js image pixels get pixels. I just feel like",
        "tokens": [
          50414,
          3240,
          364,
          10225,
          295,
          18668,
          490,
          364,
          3256,
          1228,
          9984,
          13,
          25530,
          3256,
          18668,
          483,
          18668,
          13,
          286,
          445,
          841,
          411,
          50804
        ]
      },
      {
        "avg_logprob": -0.33695465326309204,
        "compression_ratio": 1.5621621621621622,
        "end": 1985.0200000000002,
        "id": 358,
        "no_speech_prob": 0.0007321560406126082,
        "seek": 197064,
        "start": 1982.8400000000001,
        "temperature": 0,
        "text": " Jimp I could use the jimp package",
        "tokens": [
          50974,
          508,
          8814,
          286,
          727,
          764,
          264,
          361,
          8814,
          7372,
          51083
        ]
      },
      {
        "avg_logprob": -0.33695465326309204,
        "compression_ratio": 1.5621621621621622,
        "end": 1991.8000000000002,
        "id": 359,
        "no_speech_prob": 0.0007321560406126082,
        "seek": 197064,
        "start": 1989.8000000000002,
        "temperature": 0,
        "text": " This seems promising",
        "tokens": [
          51322,
          639,
          2544,
          20257,
          51422
        ]
      },
      {
        "avg_logprob": -0.33695465326309204,
        "compression_ratio": 1.5621621621621622,
        "end": 1998.3600000000001,
        "id": 360,
        "no_speech_prob": 0.0007321560406126082,
        "seek": 197064,
        "start": 1992.76,
        "temperature": 0,
        "text": " JavaScript image manipulation program an image processing library for a node written entirely JavaScript with zero dependencies. This is good",
        "tokens": [
          51470,
          15778,
          3256,
          26475,
          1461,
          364,
          3256,
          9007,
          6405,
          337,
          257,
          9984,
          3720,
          7696,
          15778,
          365,
          4018,
          36606,
          13,
          639,
          307,
          665,
          51750
        ]
      },
      {
        "avg_logprob": -0.37992046725365425,
        "compression_ratio": 1.497560975609756,
        "end": 2001.36,
        "id": 361,
        "no_speech_prob": 0.0014325277879834175,
        "seek": 199836,
        "start": 1999.36,
        "temperature": 0,
        "text": " Does it support promises",
        "tokens": [
          50414,
          4402,
          309,
          1406,
          16403,
          50514
        ]
      },
      {
        "avg_logprob": -0.37992046725365425,
        "compression_ratio": 1.497560975609756,
        "end": 2004.7199999999998,
        "id": 362,
        "no_speech_prob": 0.0014325277879834175,
        "seek": 199836,
        "start": 2002.6,
        "temperature": 0,
        "text": " Doesn't look like using promises. Yes",
        "tokens": [
          50576,
          12955,
          380,
          574,
          411,
          1228,
          16403,
          13,
          1079,
          50682
        ]
      },
      {
        "avg_logprob": -0.37992046725365425,
        "compression_ratio": 1.497560975609756,
        "end": 2006.6,
        "id": 363,
        "no_speech_prob": 0.0014325277879834175,
        "seek": 199836,
        "start": 2005.56,
        "temperature": 0,
        "text": " Okay",
        "tokens": [
          50724,
          1033,
          50776
        ]
      },
      {
        "avg_logprob": -0.37992046725365425,
        "compression_ratio": 1.497560975609756,
        "end": 2008.6,
        "id": 364,
        "no_speech_prob": 0.0014325277879834175,
        "seek": 199836,
        "start": 2006.6,
        "temperature": 0,
        "text": " This looks good",
        "tokens": [
          50776,
          639,
          1542,
          665,
          50876
        ]
      },
      {
        "avg_logprob": -0.37992046725365425,
        "compression_ratio": 1.497560975609756,
        "end": 2016.04,
        "id": 365,
        "no_speech_prob": 0.0014325277879834175,
        "seek": 199836,
        "start": 2009.12,
        "temperature": 0,
        "text": " No, so Helmer. Yeah, I got to talk about this no internet. No heat. This is a detached garage and it is",
        "tokens": [
          50902,
          883,
          11,
          370,
          6128,
          936,
          13,
          865,
          11,
          286,
          658,
          281,
          751,
          466,
          341,
          572,
          4705,
          13,
          883,
          3738,
          13,
          639,
          307,
          257,
          42050,
          14400,
          293,
          309,
          307,
          51248
        ]
      },
      {
        "avg_logprob": -0.37992046725365425,
        "compression_ratio": 1.497560975609756,
        "end": 2018.32,
        "id": 366,
        "no_speech_prob": 0.0014325277879834175,
        "seek": 199836,
        "start": 2017.1999999999998,
        "temperature": 0,
        "text": " I'm",
        "tokens": [
          51306,
          286,
          478,
          51362
        ]
      },
      {
        "avg_logprob": -0.37992046725365425,
        "compression_ratio": 1.497560975609756,
        "end": 2021.6,
        "id": 367,
        "no_speech_prob": 0.0014325277879834175,
        "seek": 199836,
        "start": 2018.32,
        "temperature": 0,
        "text": " Trying to get all the stuff in here to make it more",
        "tokens": [
          51362,
          20180,
          281,
          483,
          439,
          264,
          1507,
          294,
          510,
          281,
          652,
          309,
          544,
          51526
        ]
      },
      {
        "avg_logprob": -0.37992046725365425,
        "compression_ratio": 1.497560975609756,
        "end": 2025.9599999999998,
        "id": 368,
        "no_speech_prob": 0.0014325277879834175,
        "seek": 199836,
        "start": 2022.4799999999998,
        "temperature": 0,
        "text": " Livable, but we don't live in the garage, but to have some more",
        "tokens": [
          51570,
          31738,
          712,
          11,
          457,
          321,
          500,
          380,
          1621,
          294,
          264,
          14400,
          11,
          457,
          281,
          362,
          512,
          544,
          51744
        ]
      },
      {
        "avg_logprob": -0.2991417501574365,
        "compression_ratio": 1.583011583011583,
        "end": 2035.1200000000001,
        "id": 369,
        "no_speech_prob": 0.0021826799493283033,
        "seek": 202596,
        "start": 2026.96,
        "temperature": 0,
        "text": " Lounge II relaxing space we have a ping-pong table to have enough like power and internet to power my coding train stuff",
        "tokens": [
          50414,
          441,
          27066,
          6351,
          20103,
          1901,
          321,
          362,
          257,
          26151,
          12,
          79,
          556,
          3199,
          281,
          362,
          1547,
          411,
          1347,
          293,
          4705,
          281,
          1347,
          452,
          17720,
          3847,
          1507,
          50822
        ]
      },
      {
        "avg_logprob": -0.2991417501574365,
        "compression_ratio": 1.583011583011583,
        "end": 2042.1200000000001,
        "id": 370,
        "no_speech_prob": 0.0021826799493283033,
        "seek": 202596,
        "start": 2036.48,
        "temperature": 0,
        "text": " But you know, I don't run the heat in here all day because we're not in here and that would be very wasteful anyway",
        "tokens": [
          50890,
          583,
          291,
          458,
          11,
          286,
          500,
          380,
          1190,
          264,
          3738,
          294,
          510,
          439,
          786,
          570,
          321,
          434,
          406,
          294,
          510,
          293,
          300,
          576,
          312,
          588,
          5964,
          906,
          4033,
          51172
        ]
      },
      {
        "avg_logprob": -0.2991417501574365,
        "compression_ratio": 1.583011583011583,
        "end": 2047.64,
        "id": 371,
        "no_speech_prob": 0.0021826799493283033,
        "seek": 202596,
        "start": 2043.48,
        "temperature": 0,
        "text": " How do I how do you all feel about this jimp library? I think this is looking good for me",
        "tokens": [
          51240,
          1012,
          360,
          286,
          577,
          360,
          291,
          439,
          841,
          466,
          341,
          361,
          8814,
          6405,
          30,
          286,
          519,
          341,
          307,
          1237,
          665,
          337,
          385,
          51448
        ]
      },
      {
        "avg_logprob": -0.2991417501574365,
        "compression_ratio": 1.583011583011583,
        "end": 2054.8,
        "id": 372,
        "no_speech_prob": 0.0021826799493283033,
        "seek": 202596,
        "start": 2047.96,
        "temperature": 0,
        "text": " So I am going to give it a try until someone tells me not to do it npm install jimp",
        "tokens": [
          51464,
          407,
          286,
          669,
          516,
          281,
          976,
          309,
          257,
          853,
          1826,
          1580,
          5112,
          385,
          406,
          281,
          360,
          309,
          297,
          14395,
          3625,
          361,
          8814,
          51806
        ]
      },
      {
        "avg_logprob": -0.33685791798127,
        "compression_ratio": 1.6157894736842104,
        "end": 2058.96,
        "id": 373,
        "no_speech_prob": 0.00018521430320106447,
        "seek": 205596,
        "start": 2056.96,
        "temperature": 0,
        "text": " Yep",
        "tokens": [
          50414,
          7010,
          50514
        ]
      },
      {
        "avg_logprob": -0.33685791798127,
        "compression_ratio": 1.6157894736842104,
        "end": 2063,
        "id": 374,
        "no_speech_prob": 0.00018521430320106447,
        "seek": 205596,
        "start": 2061,
        "temperature": 0,
        "text": " So, let's run that",
        "tokens": [
          50616,
          407,
          11,
          718,
          311,
          1190,
          300,
          50716
        ]
      },
      {
        "avg_logprob": -0.33685791798127,
        "compression_ratio": 1.6157894736842104,
        "end": 2067.04,
        "id": 375,
        "no_speech_prob": 0.00018521430320106447,
        "seek": 205596,
        "start": 2064.44,
        "temperature": 0,
        "text": " So I'm now loading this package",
        "tokens": [
          50788,
          407,
          286,
          478,
          586,
          15114,
          341,
          7372,
          50918
        ]
      },
      {
        "avg_logprob": -0.33685791798127,
        "compression_ratio": 1.6157894736842104,
        "end": 2076.28,
        "id": 376,
        "no_speech_prob": 0.00018521430320106447,
        "seek": 205596,
        "start": 2070.96,
        "temperature": 0,
        "text": " Okay, great, by the way, I'm always curious it always says so some of the packages are looking for funding",
        "tokens": [
          51114,
          1033,
          11,
          869,
          11,
          538,
          264,
          636,
          11,
          286,
          478,
          1009,
          6369,
          309,
          1009,
          1619,
          370,
          512,
          295,
          264,
          17401,
          366,
          1237,
          337,
          6137,
          51380
        ]
      },
      {
        "avg_logprob": -0.33685791798127,
        "compression_ratio": 1.6157894736842104,
        "end": 2078.32,
        "id": 377,
        "no_speech_prob": 0.00018521430320106447,
        "seek": 205596,
        "start": 2077.04,
        "temperature": 0,
        "text": " so",
        "tokens": [
          51418,
          370,
          51482
        ]
      },
      {
        "avg_logprob": -0.33685791798127,
        "compression_ratio": 1.6157894736842104,
        "end": 2084.92,
        "id": 378,
        "no_speech_prob": 0.00018521430320106447,
        "seek": 205596,
        "start": 2078.32,
        "temperature": 0,
        "text": " Always good to support open source projects. So see there's some of the open source projects that I'm using somehow through these dependencies",
        "tokens": [
          51482,
          11270,
          665,
          281,
          1406,
          1269,
          4009,
          4455,
          13,
          407,
          536,
          456,
          311,
          512,
          295,
          264,
          1269,
          4009,
          4455,
          300,
          286,
          478,
          1228,
          6063,
          807,
          613,
          36606,
          51812
        ]
      },
      {
        "avg_logprob": -0.27613882966093967,
        "compression_ratio": 1.5167464114832536,
        "end": 2087.96,
        "id": 379,
        "no_speech_prob": 0.013427220284938812,
        "seek": 208596,
        "start": 2085.96,
        "temperature": 0,
        "text": " Maybe I will come back to that later",
        "tokens": [
          50364,
          2704,
          286,
          486,
          808,
          646,
          281,
          300,
          1780,
          50464
        ]
      },
      {
        "avg_logprob": -0.27613882966093967,
        "compression_ratio": 1.5167464114832536,
        "end": 2090.6,
        "id": 380,
        "no_speech_prob": 0.013427220284938812,
        "seek": 208596,
        "start": 2088.2,
        "temperature": 0,
        "text": " Now up there goes to see the heat's on",
        "tokens": [
          50476,
          823,
          493,
          456,
          1709,
          281,
          536,
          264,
          3738,
          311,
          322,
          50596
        ]
      },
      {
        "avg_logprob": -0.27613882966093967,
        "compression_ratio": 1.5167464114832536,
        "end": 2093.4,
        "id": 381,
        "no_speech_prob": 0.013427220284938812,
        "seek": 208596,
        "start": 2091.4,
        "temperature": 0,
        "text": " So now that's the boiler going",
        "tokens": [
          50636,
          407,
          586,
          300,
          311,
          264,
          39228,
          516,
          50736
        ]
      },
      {
        "avg_logprob": -0.27613882966093967,
        "compression_ratio": 1.5167464114832536,
        "end": 2096.68,
        "id": 382,
        "no_speech_prob": 0.013427220284938812,
        "seek": 208596,
        "start": 2094.4,
        "temperature": 0,
        "text": " So hopefully that doesn't mess my audio up too much",
        "tokens": [
          50786,
          407,
          4696,
          300,
          1177,
          380,
          2082,
          452,
          6278,
          493,
          886,
          709,
          50900
        ]
      },
      {
        "avg_logprob": -0.27613882966093967,
        "compression_ratio": 1.5167464114832536,
        "end": 2106.48,
        "id": 383,
        "no_speech_prob": 0.013427220284938812,
        "seek": 208596,
        "start": 2098.44,
        "temperature": 0,
        "text": " Aman in the chat on pixel data in oh, I could just use tensorflow.js to load the pixel data. Oh TF image",
        "tokens": [
          50988,
          35466,
          294,
          264,
          5081,
          322,
          19261,
          1412,
          294,
          1954,
          11,
          286,
          727,
          445,
          764,
          40863,
          10565,
          13,
          25530,
          281,
          3677,
          264,
          19261,
          1412,
          13,
          876,
          40964,
          3256,
          51390
        ]
      },
      {
        "avg_logprob": -0.27613882966093967,
        "compression_ratio": 1.5167464114832536,
        "end": 2109.12,
        "id": 384,
        "no_speech_prob": 0.013427220284938812,
        "seek": 208596,
        "start": 2107.12,
        "temperature": 0,
        "text": " That's a great point",
        "tokens": [
          51422,
          663,
          311,
          257,
          869,
          935,
          51522
        ]
      },
      {
        "avg_logprob": -0.27613882966093967,
        "compression_ratio": 1.5167464114832536,
        "end": 2111.7200000000003,
        "id": 385,
        "no_speech_prob": 0.013427220284938812,
        "seek": 208596,
        "start": 2109.7200000000003,
        "temperature": 0,
        "text": " Okay, I should probably use that",
        "tokens": [
          51552,
          1033,
          11,
          286,
          820,
          1391,
          764,
          300,
          51652
        ]
      },
      {
        "avg_logprob": -0.2976278131658381,
        "compression_ratio": 1.375,
        "end": 2117.52,
        "id": 386,
        "no_speech_prob": 0.0000061440841818694025,
        "seek": 211172,
        "start": 2112.72,
        "temperature": 0,
        "text": " Great point, okay, so this was interesting to explore but let's",
        "tokens": [
          50414,
          3769,
          935,
          11,
          1392,
          11,
          370,
          341,
          390,
          1880,
          281,
          6839,
          457,
          718,
          311,
          50654
        ]
      },
      {
        "avg_logprob": -0.2976278131658381,
        "compression_ratio": 1.375,
        "end": 2125.24,
        "id": 387,
        "no_speech_prob": 0.0000061440841818694025,
        "seek": 211172,
        "start": 2118.2799999999997,
        "temperature": 0,
        "text": " Let's look at I forgot about that. Thank you for that. That is a great note. So let's go to TF dot image",
        "tokens": [
          50692,
          961,
          311,
          574,
          412,
          286,
          5298,
          466,
          300,
          13,
          1044,
          291,
          337,
          300,
          13,
          663,
          307,
          257,
          869,
          3637,
          13,
          407,
          718,
          311,
          352,
          281,
          40964,
          5893,
          3256,
          51040
        ]
      },
      {
        "avg_logprob": -0.2976278131658381,
        "compression_ratio": 1.375,
        "end": 2129.68,
        "id": 388,
        "no_speech_prob": 0.0000061440841818694025,
        "seek": 211172,
        "start": 2127.68,
        "temperature": 0,
        "text": " Yeah, look at this",
        "tokens": [
          51162,
          865,
          11,
          574,
          412,
          341,
          51262
        ]
      },
      {
        "avg_logprob": -0.49358346121651786,
        "compression_ratio": 1.2234042553191489,
        "end": 2132.44,
        "id": 389,
        "no_speech_prob": 0.00017674325499683619,
        "seek": 212968,
        "start": 2130.44,
        "temperature": 0,
        "text": " You",
        "tokens": [
          50402,
          509,
          50502
        ]
      },
      {
        "avg_logprob": -0.49358346121651786,
        "compression_ratio": 1.2234042553191489,
        "end": 2146.68,
        "id": 390,
        "no_speech_prob": 0.00017674325499683619,
        "seek": 212968,
        "start": 2140.52,
        "temperature": 0,
        "text": " Strap but does it low will it load an image for me? So these are all operations if",
        "tokens": [
          50906,
          745,
          4007,
          457,
          775,
          309,
          2295,
          486,
          309,
          3677,
          364,
          3256,
          337,
          385,
          30,
          407,
          613,
          366,
          439,
          7705,
          498,
          51214
        ]
      },
      {
        "avg_logprob": -0.49358346121651786,
        "compression_ratio": 1.2234042553191489,
        "end": 2154.04,
        "id": 391,
        "no_speech_prob": 0.00017674325499683619,
        "seek": 212968,
        "start": 2150.04,
        "temperature": 0,
        "text": " Hold on what does it expect?",
        "tokens": [
          51382,
          6962,
          322,
          437,
          775,
          309,
          2066,
          30,
          51582
        ]
      },
      {
        "avg_logprob": -0.34800264570448136,
        "compression_ratio": 1.225,
        "end": 2167.08,
        "id": 392,
        "no_speech_prob": 0.0002694696595426649,
        "seek": 215968,
        "start": 2159.68,
        "temperature": 0,
        "text": " Like it expects an image does it expect like like an image HTML image element",
        "tokens": [
          50364,
          1743,
          309,
          33280,
          364,
          3256,
          775,
          309,
          2066,
          411,
          411,
          364,
          3256,
          17995,
          3256,
          4478,
          50734
        ]
      },
      {
        "avg_logprob": -0.34800264570448136,
        "compression_ratio": 1.225,
        "end": 2181.2,
        "id": 393,
        "no_speech_prob": 0.0002694696595426649,
        "seek": 215968,
        "start": 2179.2,
        "temperature": 0,
        "text": " All right, let's see",
        "tokens": [
          51340,
          1057,
          558,
          11,
          718,
          311,
          536,
          51440
        ]
      },
      {
        "avg_logprob": -0.5239253640174866,
        "compression_ratio": 1.2197802197802199,
        "end": 2183.2,
        "id": 394,
        "no_speech_prob": 0.00037998074549250305,
        "seek": 218120,
        "start": 2181.2,
        "temperature": 0,
        "text": " I",
        "tokens": [
          50364,
          286,
          50464
        ]
      },
      {
        "avg_logprob": -0.5239253640174866,
        "compression_ratio": 1.2197802197802199,
        "end": 2197,
        "id": 395,
        "no_speech_prob": 0.00037998074549250305,
        "seek": 218120,
        "start": 2188.68,
        "temperature": 0,
        "text": " From pixels, but this is all stuff happening in the from pixels. Yeah. Okay",
        "tokens": [
          50738,
          3358,
          18668,
          11,
          457,
          341,
          307,
          439,
          1507,
          2737,
          294,
          264,
          490,
          18668,
          13,
          865,
          13,
          1033,
          51154
        ]
      },
      {
        "avg_logprob": -0.5239253640174866,
        "compression_ratio": 1.2197802197802199,
        "end": 2204.16,
        "id": 396,
        "no_speech_prob": 0.00037998074549250305,
        "seek": 218120,
        "start": 2201.72,
        "temperature": 0,
        "text": " There is the from pixels function",
        "tokens": [
          51390,
          821,
          307,
          264,
          490,
          18668,
          2445,
          51512
        ]
      },
      {
        "avg_logprob": -0.34075537035542147,
        "compression_ratio": 1.5338345864661653,
        "end": 2206.16,
        "id": 397,
        "no_speech_prob": 0.0006070621311664581,
        "seek": 220416,
        "start": 2204.16,
        "temperature": 0,
        "text": " Oh",
        "tokens": [
          50364,
          876,
          50464
        ]
      },
      {
        "avg_logprob": -0.34075537035542147,
        "compression_ratio": 1.5338345864661653,
        "end": 2213.2,
        "id": 398,
        "no_speech_prob": 0.0006070621311664581,
        "seek": 220416,
        "start": 2206.3599999999997,
        "temperature": 0,
        "text": " But this is all only in the browser, so I'm not in the browser right now, I mean I could be doing all this in the browser",
        "tokens": [
          50474,
          583,
          341,
          307,
          439,
          787,
          294,
          264,
          11185,
          11,
          370,
          286,
          478,
          406,
          294,
          264,
          11185,
          558,
          586,
          11,
          286,
          914,
          286,
          727,
          312,
          884,
          439,
          341,
          294,
          264,
          11185,
          50816
        ]
      },
      {
        "avg_logprob": -0.34075537035542147,
        "compression_ratio": 1.5338345864661653,
        "end": 2225.64,
        "id": 399,
        "no_speech_prob": 0.0006070621311664581,
        "seek": 220416,
        "start": 2220.48,
        "temperature": 0,
        "text": " TF image decode, okay image decode. How come I didn't see that?",
        "tokens": [
          51180,
          40964,
          3256,
          979,
          1429,
          11,
          1392,
          3256,
          979,
          1429,
          13,
          1012,
          808,
          286,
          994,
          380,
          536,
          300,
          30,
          51438
        ]
      },
      {
        "avg_logprob": -0.34075537035542147,
        "compression_ratio": 1.5338345864661653,
        "end": 2232.96,
        "id": 400,
        "no_speech_prob": 0.0006070621311664581,
        "seek": 220416,
        "start": 2230.56,
        "temperature": 0,
        "text": " TF image decode",
        "tokens": [
          51684,
          40964,
          3256,
          979,
          1429,
          51804
        ]
      },
      {
        "avg_logprob": -0.32854099931388064,
        "compression_ratio": 1.3795620437956204,
        "end": 2236.16,
        "id": 401,
        "no_speech_prob": 0.0005274758441373706,
        "seek": 223416,
        "start": 2234.16,
        "temperature": 0,
        "text": " I don't see that as a function",
        "tokens": [
          50364,
          286,
          500,
          380,
          536,
          300,
          382,
          257,
          2445,
          50464
        ]
      },
      {
        "avg_logprob": -0.32854099931388064,
        "compression_ratio": 1.3795620437956204,
        "end": 2243.6,
        "id": 402,
        "no_speech_prob": 0.0005274758441373706,
        "seek": 223416,
        "start": 2241.12,
        "temperature": 0,
        "text": " TF IO decode image",
        "tokens": [
          50712,
          40964,
          39839,
          979,
          1429,
          3256,
          50836
        ]
      },
      {
        "avg_logprob": -0.32854099931388064,
        "compression_ratio": 1.3795620437956204,
        "end": 2249.8799999999997,
        "id": 403,
        "no_speech_prob": 0.0005274758441373706,
        "seek": 223416,
        "start": 2245.44,
        "temperature": 0,
        "text": " Interesting, oh, but this is tensorflow not TF",
        "tokens": [
          50928,
          14711,
          11,
          1954,
          11,
          457,
          341,
          307,
          40863,
          10565,
          406,
          40964,
          51150
        ]
      },
      {
        "avg_logprob": -0.32854099931388064,
        "compression_ratio": 1.3795620437956204,
        "end": 2256,
        "id": 404,
        "no_speech_prob": 0.0005274758441373706,
        "seek": 223416,
        "start": 2254,
        "temperature": 0,
        "text": " Yeah, so it doesn't look like",
        "tokens": [
          51356,
          865,
          11,
          370,
          309,
          1177,
          380,
          574,
          411,
          51456
        ]
      },
      {
        "avg_logprob": -0.32854099931388064,
        "compression_ratio": 1.3795620437956204,
        "end": 2258.6,
        "id": 405,
        "no_speech_prob": 0.0005274758441373706,
        "seek": 223416,
        "start": 2256.6,
        "temperature": 0,
        "text": " some of those",
        "tokens": [
          51486,
          512,
          295,
          729,
          51586
        ]
      },
      {
        "avg_logprob": -0.32854099931388064,
        "compression_ratio": 1.3795620437956204,
        "end": 2263.16,
        "id": 406,
        "no_speech_prob": 0.0005274758441373706,
        "seek": 223416,
        "start": 2258.92,
        "temperature": 0,
        "text": " That like decoding an image file is present here",
        "tokens": [
          51602,
          663,
          411,
          979,
          8616,
          364,
          3256,
          3991,
          307,
          1974,
          510,
          51814
        ]
      },
      {
        "avg_logprob": -0.3270454077885069,
        "compression_ratio": 1.515527950310559,
        "end": 2272.54,
        "id": 407,
        "no_speech_prob": 0.0030277734622359276,
        "seek": 226416,
        "start": 2265,
        "temperature": 0,
        "text": " It probably wants to work with images from the browser check this out what I just sent should work says",
        "tokens": [
          50406,
          467,
          1391,
          2738,
          281,
          589,
          365,
          5267,
          490,
          264,
          11185,
          1520,
          341,
          484,
          437,
          286,
          445,
          2279,
          820,
          589,
          1619,
          50783
        ]
      },
      {
        "avg_logprob": -0.3270454077885069,
        "compression_ratio": 1.515527950310559,
        "end": 2278.2,
        "id": 408,
        "no_speech_prob": 0.0030277734622359276,
        "seek": 226416,
        "start": 2274.7999999999997,
        "temperature": 0,
        "text": " So the thing is like of course we could improve this later",
        "tokens": [
          50896,
          407,
          264,
          551,
          307,
          411,
          295,
          1164,
          321,
          727,
          3470,
          341,
          1780,
          51066
        ]
      },
      {
        "avg_logprob": -0.3270454077885069,
        "compression_ratio": 1.515527950310559,
        "end": 2288.04,
        "id": 409,
        "no_speech_prob": 0.0030277734622359276,
        "seek": 226416,
        "start": 2280.2799999999997,
        "temperature": 0,
        "text": " Image data. All right. So the parameters are image data. So pixel data image data",
        "tokens": [
          51170,
          29903,
          1412,
          13,
          1057,
          558,
          13,
          407,
          264,
          9834,
          366,
          3256,
          1412,
          13,
          407,
          19261,
          1412,
          3256,
          1412,
          51558
        ]
      },
      {
        "avg_logprob": -0.5412926307091346,
        "compression_ratio": 1.441860465116279,
        "end": 2296.4,
        "id": 410,
        "no_speech_prob": 0.001048463978804648,
        "seek": 228804,
        "start": 2288.4,
        "temperature": 0,
        "text": " Image data can I do this in yeah, this is all canvas stuff. So I'm kind of in headless mode right now",
        "tokens": [
          50382,
          29903,
          1412,
          393,
          286,
          360,
          341,
          294,
          1338,
          11,
          341,
          307,
          439,
          16267,
          1507,
          13,
          407,
          286,
          478,
          733,
          295,
          294,
          1378,
          1832,
          4391,
          558,
          586,
          50782
        ]
      },
      {
        "avg_logprob": -0.5412926307091346,
        "compression_ratio": 1.441860465116279,
        "end": 2302.84,
        "id": 411,
        "no_speech_prob": 0.001048463978804648,
        "seek": 228804,
        "start": 2299.32,
        "temperature": 0,
        "text": " So I sort of feel like no JS canvas image data",
        "tokens": [
          50928,
          407,
          286,
          1333,
          295,
          841,
          411,
          572,
          33063,
          16267,
          3256,
          1412,
          51104
        ]
      },
      {
        "avg_logprob": -0.5412926307091346,
        "compression_ratio": 1.441860465116279,
        "end": 2313.68,
        "id": 412,
        "no_speech_prob": 0.001048463978804648,
        "seek": 228804,
        "start": 2311.16,
        "temperature": 0,
        "text": " So I could use the node canvas module",
        "tokens": [
          51520,
          407,
          286,
          727,
          764,
          264,
          9984,
          16267,
          10088,
          51646
        ]
      },
      {
        "avg_logprob": -0.3184473450119431,
        "compression_ratio": 1.541899441340782,
        "end": 2325.2799999999997,
        "id": 413,
        "no_speech_prob": 0.000032192278013098985,
        "seek": 231804,
        "start": 2319.04,
        "temperature": 0,
        "text": " So I could use node canvas and then load an image",
        "tokens": [
          50414,
          407,
          286,
          727,
          764,
          9984,
          16267,
          293,
          550,
          3677,
          364,
          3256,
          50726
        ]
      },
      {
        "avg_logprob": -0.3184473450119431,
        "compression_ratio": 1.541899441340782,
        "end": 2336.32,
        "id": 414,
        "no_speech_prob": 0.000032192278013098985,
        "seek": 231804,
        "start": 2329.92,
        "temperature": 0,
        "text": " It's the load image function, okay. Ah, all right. Maybe I should do that. Maybe that makes sense",
        "tokens": [
          50958,
          467,
          311,
          264,
          3677,
          3256,
          2445,
          11,
          1392,
          13,
          2438,
          11,
          439,
          558,
          13,
          2704,
          286,
          820,
          360,
          300,
          13,
          2704,
          300,
          1669,
          2020,
          51278
        ]
      },
      {
        "avg_logprob": -0.3184473450119431,
        "compression_ratio": 1.541899441340782,
        "end": 2341.7599999999998,
        "id": 415,
        "no_speech_prob": 0.000032192278013098985,
        "seek": 231804,
        "start": 2340.16,
        "temperature": 0,
        "text": " So, all right, this is interesting",
        "tokens": [
          51470,
          407,
          11,
          439,
          558,
          11,
          341,
          307,
          1880,
          51550
        ]
      },
      {
        "avg_logprob": -0.3184473450119431,
        "compression_ratio": 1.541899441340782,
        "end": 2347.2799999999997,
        "id": 416,
        "no_speech_prob": 0.000032192278013098985,
        "seek": 231804,
        "start": 2341.7599999999998,
        "temperature": 0,
        "text": " Let's try this because the other reason to do this is it'll translate nicely to working in p5",
        "tokens": [
          51550,
          961,
          311,
          853,
          341,
          570,
          264,
          661,
          1778,
          281,
          360,
          341,
          307,
          309,
          603,
          13799,
          9594,
          281,
          1364,
          294,
          280,
          20,
          51826
        ]
      },
      {
        "avg_logprob": -0.24639984818755603,
        "compression_ratio": 1.4335664335664335,
        "end": 2351.32,
        "id": 417,
        "no_speech_prob": 0.000057387424021726474,
        "seek": 234728,
        "start": 2347.6000000000004,
        "temperature": 0,
        "text": " but I'm a little bit skeptical of this working in node, but",
        "tokens": [
          50380,
          457,
          286,
          478,
          257,
          707,
          857,
          28601,
          295,
          341,
          1364,
          294,
          9984,
          11,
          457,
          50566
        ]
      },
      {
        "avg_logprob": -0.24639984818755603,
        "compression_ratio": 1.4335664335664335,
        "end": 2356.84,
        "id": 418,
        "no_speech_prob": 0.000057387424021726474,
        "seek": 234728,
        "start": 2352.5600000000004,
        "temperature": 0,
        "text": " I'll give myself a little bit of time. Let's try installing canvas",
        "tokens": [
          50628,
          286,
          603,
          976,
          2059,
          257,
          707,
          857,
          295,
          565,
          13,
          961,
          311,
          853,
          20762,
          16267,
          50842
        ]
      },
      {
        "avg_logprob": -0.24639984818755603,
        "compression_ratio": 1.4335664335664335,
        "end": 2362.4,
        "id": 419,
        "no_speech_prob": 0.000057387424021726474,
        "seek": 234728,
        "start": 2360.4,
        "temperature": 0,
        "text": " So",
        "tokens": [
          51020,
          407,
          51120
        ]
      },
      {
        "avg_logprob": -0.24639984818755603,
        "compression_ratio": 1.4335664335664335,
        "end": 2368.7200000000003,
        "id": 420,
        "no_speech_prob": 0.000057387424021726474,
        "seek": 234728,
        "start": 2366.2000000000003,
        "temperature": 0,
        "text": " Let's comment all this stuff out right now",
        "tokens": [
          51310,
          961,
          311,
          2871,
          439,
          341,
          1507,
          484,
          558,
          586,
          51436
        ]
      },
      {
        "avg_logprob": -0.24639984818755603,
        "compression_ratio": 1.4335664335664335,
        "end": 2373.28,
        "id": 421,
        "no_speech_prob": 0.000057387424021726474,
        "seek": 234728,
        "start": 2371.28,
        "temperature": 0,
        "text": " Come back to it",
        "tokens": [
          51564,
          2492,
          646,
          281,
          309,
          51664
        ]
      },
      {
        "avg_logprob": -0.24639984818755603,
        "compression_ratio": 1.4335664335664335,
        "end": 2377.0800000000004,
        "id": 422,
        "no_speech_prob": 0.000057387424021726474,
        "seek": 234728,
        "start": 2375.0800000000004,
        "temperature": 0,
        "text": " So and let's say",
        "tokens": [
          51754,
          407,
          293,
          718,
          311,
          584,
          51854
        ]
      },
      {
        "avg_logprob": -0.8061309087844122,
        "compression_ratio": 1.2040816326530612,
        "end": 2380.28,
        "id": 423,
        "no_speech_prob": 0.0000736853398848325,
        "seek": 237728,
        "start": 2378.28,
        "temperature": 0,
        "text": " Import",
        "tokens": [
          50414,
          26391,
          50514
        ]
      },
      {
        "avg_logprob": -0.8061309087844122,
        "compression_ratio": 1.2040816326530612,
        "end": 2382.92,
        "id": 424,
        "no_speech_prob": 0.0000736853398848325,
        "seek": 237728,
        "start": 2380.92,
        "temperature": 0,
        "text": " How do I do an import with this",
        "tokens": [
          50546,
          1012,
          360,
          286,
          360,
          364,
          974,
          365,
          341,
          50646
        ]
      },
      {
        "avg_logprob": -0.8061309087844122,
        "compression_ratio": 1.2040816326530612,
        "end": 2391.88,
        "id": 425,
        "no_speech_prob": 0.0000736853398848325,
        "seek": 237728,
        "start": 2389.44,
        "temperature": 0,
        "text": " Can I do this import",
        "tokens": [
          50972,
          1664,
          286,
          360,
          341,
          974,
          51094
        ]
      },
      {
        "avg_logprob": -0.4479681212326576,
        "compression_ratio": 1.131578947368421,
        "end": 2409.28,
        "id": 426,
        "no_speech_prob": 0.0038841175846755505,
        "seek": 240728,
        "start": 2407.28,
        "temperature": 0,
        "text": " Import",
        "tokens": [
          50364,
          26391,
          50464
        ]
      },
      {
        "avg_logprob": -0.4479681212326576,
        "compression_ratio": 1.131578947368421,
        "end": 2418.84,
        "id": 427,
        "no_speech_prob": 0.0038841175846755505,
        "seek": 240728,
        "start": 2413.96,
        "temperature": 0,
        "text": " How do I do this is it like this that possibly be right",
        "tokens": [
          50698,
          1012,
          360,
          286,
          360,
          341,
          307,
          309,
          411,
          341,
          300,
          6264,
          312,
          558,
          50942
        ]
      },
      {
        "avg_logprob": -0.4479681212326576,
        "compression_ratio": 1.131578947368421,
        "end": 2428.6000000000004,
        "id": 428,
        "no_speech_prob": 0.0038841175846755505,
        "seek": 240728,
        "start": 2426.6000000000004,
        "temperature": 0,
        "text": " All right, so let's see",
        "tokens": [
          51330,
          1057,
          558,
          11,
          370,
          718,
          311,
          536,
          51430
        ]
      },
      {
        "avg_logprob": -0.7959530421665737,
        "compression_ratio": 1.0842105263157895,
        "end": 2433.88,
        "id": 429,
        "no_speech_prob": 0.0035379223991185427,
        "seek": 242860,
        "start": 2429,
        "temperature": 0,
        "text": " Import create can't let's just see. Okay. So now let's try",
        "tokens": [
          50384,
          26391,
          1884,
          393,
          380,
          718,
          311,
          445,
          536,
          13,
          1033,
          13,
          407,
          586,
          718,
          311,
          853,
          50628
        ]
      },
      {
        "avg_logprob": -0.7959530421665737,
        "compression_ratio": 1.0842105263157895,
        "end": 2438.16,
        "id": 430,
        "no_speech_prob": 0.0035379223991185427,
        "seek": 242860,
        "start": 2436.16,
        "temperature": 0,
        "text": " Load image",
        "tokens": [
          50742,
          48408,
          3256,
          50842
        ]
      },
      {
        "avg_logprob": -0.7959530421665737,
        "compression_ratio": 1.0842105263157895,
        "end": 2447.92,
        "id": 431,
        "no_speech_prob": 0.0035379223991185427,
        "seek": 242860,
        "start": 2445.92,
        "temperature": 0,
        "text": " Make this in a sync function",
        "tokens": [
          51230,
          4387,
          341,
          294,
          257,
          20271,
          2445,
          51330
        ]
      },
      {
        "avg_logprob": -0.7959530421665737,
        "compression_ratio": 1.0842105263157895,
        "end": 2454.64,
        "id": 432,
        "no_speech_prob": 0.0035379223991185427,
        "seek": 242860,
        "start": 2452.64,
        "temperature": 0,
        "text": " Data",
        "tokens": [
          51566,
          11888,
          51666
        ]
      },
      {
        "avg_logprob": -0.4117031530900435,
        "compression_ratio": 1.0357142857142858,
        "end": 2457.04,
        "id": 433,
        "no_speech_prob": 0.002934797666966915,
        "seek": 245464,
        "start": 2455.04,
        "temperature": 0,
        "text": " Data",
        "tokens": [
          50384,
          11888,
          50484
        ]
      },
      {
        "avg_logprob": -0.4117031530900435,
        "compression_ratio": 1.0357142857142858,
        "end": 2461.3199999999997,
        "id": 434,
        "no_speech_prob": 0.002934797666966915,
        "seek": 245464,
        "start": 2459.3199999999997,
        "temperature": 0,
        "text": " Square zero zero zero",
        "tokens": [
          50598,
          16463,
          4018,
          4018,
          4018,
          50698
        ]
      },
      {
        "avg_logprob": -0.4117031530900435,
        "compression_ratio": 1.0357142857142858,
        "end": 2471.92,
        "id": 435,
        "no_speech_prob": 0.002934797666966915,
        "seek": 245464,
        "start": 2469.92,
        "temperature": 0,
        "text": " Yeah, and then",
        "tokens": [
          51128,
          865,
          11,
          293,
          550,
          51228
        ]
      },
      {
        "avg_logprob": -0.4117031530900435,
        "compression_ratio": 1.0357142857142858,
        "end": 2476.8799999999997,
        "id": 436,
        "no_speech_prob": 0.002934797666966915,
        "seek": 245464,
        "start": 2474.8799999999997,
        "temperature": 0,
        "text": " See what happens",
        "tokens": [
          51376,
          3008,
          437,
          2314,
          51476
        ]
      },
      {
        "avg_logprob": -0.2777773823056902,
        "compression_ratio": 1.4405594405594406,
        "end": 2479.7200000000003,
        "id": 437,
        "no_speech_prob": 0.0004373280389700085,
        "seek": 247688,
        "start": 2477.7200000000003,
        "temperature": 0,
        "text": " So",
        "tokens": [
          50406,
          407,
          50506
        ]
      },
      {
        "avg_logprob": -0.2777773823056902,
        "compression_ratio": 1.4405594405594406,
        "end": 2485.88,
        "id": 438,
        "no_speech_prob": 0.0004373280389700085,
        "seek": 247688,
        "start": 2480.04,
        "temperature": 0,
        "text": " I'm just testing this canvas load image function to see if it will load the file",
        "tokens": [
          50522,
          286,
          478,
          445,
          4997,
          341,
          16267,
          3677,
          3256,
          2445,
          281,
          536,
          498,
          309,
          486,
          3677,
          264,
          3991,
          50814
        ]
      },
      {
        "avg_logprob": -0.2777773823056902,
        "compression_ratio": 1.4405594405594406,
        "end": 2490.12,
        "id": 439,
        "no_speech_prob": 0.0004373280389700085,
        "seek": 247688,
        "start": 2488.12,
        "temperature": 0,
        "text": " Import",
        "tokens": [
          50926,
          26391,
          51026
        ]
      },
      {
        "avg_logprob": -0.2777773823056902,
        "compression_ratio": 1.4405594405594406,
        "end": 2493.8,
        "id": 440,
        "no_speech_prob": 0.0004373280389700085,
        "seek": 247688,
        "start": 2491.8,
        "temperature": 0,
        "text": " And see what happens",
        "tokens": [
          51110,
          400,
          536,
          437,
          2314,
          51210
        ]
      },
      {
        "avg_logprob": -0.2777773823056902,
        "compression_ratio": 1.4405594405594406,
        "end": 2500.48,
        "id": 441,
        "no_speech_prob": 0.0004373280389700085,
        "seek": 247688,
        "start": 2495.84,
        "temperature": 0,
        "text": " Okay, is it really called canvas it's not called node canvas, but okay",
        "tokens": [
          51312,
          1033,
          11,
          307,
          309,
          534,
          1219,
          16267,
          309,
          311,
          406,
          1219,
          9984,
          16267,
          11,
          457,
          1392,
          51544
        ]
      },
      {
        "avg_logprob": -0.2777773823056902,
        "compression_ratio": 1.4405594405594406,
        "end": 2506.44,
        "id": 442,
        "no_speech_prob": 0.0004373280389700085,
        "seek": 247688,
        "start": 2504.44,
        "temperature": 0,
        "text": " Create canvas not found",
        "tokens": [
          51742,
          20248,
          16267,
          406,
          1352,
          51842
        ]
      },
      {
        "avg_logprob": -0.7174379929252293,
        "compression_ratio": 1,
        "end": 2509.88,
        "id": 443,
        "no_speech_prob": 0.00026117745437659323,
        "seek": 250688,
        "start": 2507.88,
        "temperature": 0,
        "text": " Import",
        "tokens": [
          50414,
          26391,
          50514
        ]
      },
      {
        "avg_logprob": -0.7174379929252293,
        "compression_ratio": 1,
        "end": 2514.88,
        "id": 444,
        "no_speech_prob": 0.00026117745437659323,
        "seek": 250688,
        "start": 2512.88,
        "temperature": 0,
        "text": " Import oh I see",
        "tokens": [
          50664,
          26391,
          1954,
          286,
          536,
          50764
        ]
      },
      {
        "avg_logprob": -0.7174379929252293,
        "compression_ratio": 1,
        "end": 2531.88,
        "id": 445,
        "no_speech_prob": 0.00026117745437659323,
        "seek": 250688,
        "start": 2529.88,
        "temperature": 0,
        "text": " Let's try this",
        "tokens": [
          51514,
          961,
          311,
          853,
          341,
          51614
        ]
      },
      {
        "avg_logprob": -0.7174379929252293,
        "compression_ratio": 1,
        "end": 2535.88,
        "id": 446,
        "no_speech_prob": 0.00026117745437659323,
        "seek": 250688,
        "start": 2533.88,
        "temperature": 0,
        "text": " Okay, look at this",
        "tokens": [
          51714,
          1033,
          11,
          574,
          412,
          341,
          51814
        ]
      },
      {
        "avg_logprob": -0.31527186603080937,
        "compression_ratio": 1.1794871794871795,
        "end": 2542.52,
        "id": 447,
        "no_speech_prob": 0.00020342353673186153,
        "seek": 253688,
        "start": 2536.88,
        "temperature": 0,
        "text": " Image 28 by 28 data square complete. Huh? Okay. This is interesting",
        "tokens": [
          50364,
          29903,
          7562,
          538,
          7562,
          1412,
          3732,
          3566,
          13,
          8063,
          30,
          1033,
          13,
          639,
          307,
          1880,
          50646
        ]
      },
      {
        "avg_logprob": -0.31527186603080937,
        "compression_ratio": 1.1794871794871795,
        "end": 2549.12,
        "id": 448,
        "no_speech_prob": 0.00020342353673186153,
        "seek": 253688,
        "start": 2543.84,
        "temperature": 0,
        "text": " Import star as canvas. I don't think my my",
        "tokens": [
          50712,
          26391,
          3543,
          382,
          16267,
          13,
          286,
          500,
          380,
          519,
          452,
          452,
          50976
        ]
      },
      {
        "avg_logprob": -0.31527186603080937,
        "compression_ratio": 1.1794871794871795,
        "end": 2553.56,
        "id": 449,
        "no_speech_prob": 0.00020342353673186153,
        "seek": 253688,
        "start": 2551.56,
        "temperature": 0,
        "text": " Import is right. So hold on",
        "tokens": [
          51098,
          26391,
          307,
          558,
          13,
          407,
          1797,
          322,
          51198
        ]
      },
      {
        "avg_logprob": -0.4342685317993164,
        "compression_ratio": 0.9852941176470589,
        "end": 2555.56,
        "id": 450,
        "no_speech_prob": 0.0028005256317555904,
        "seek": 255356,
        "start": 2553.56,
        "temperature": 0,
        "text": " You",
        "tokens": [
          50364,
          509,
          50464
        ]
      },
      {
        "avg_logprob": -0.4342685317993164,
        "compression_ratio": 0.9852941176470589,
        "end": 2567.72,
        "id": 451,
        "no_speech_prob": 0.0028005256317555904,
        "seek": 255356,
        "start": 2565.72,
        "temperature": 0,
        "text": " Is this",
        "tokens": [
          50972,
          1119,
          341,
          51072
        ]
      },
      {
        "avg_logprob": -0.4342685317993164,
        "compression_ratio": 0.9852941176470589,
        "end": 2580.64,
        "id": 452,
        "no_speech_prob": 0.0028005256317555904,
        "seek": 255356,
        "start": 2573.84,
        "temperature": 0,
        "text": " This work no, I don't know how to use these es6 imports",
        "tokens": [
          51378,
          639,
          589,
          572,
          11,
          286,
          500,
          380,
          458,
          577,
          281,
          764,
          613,
          785,
          21,
          41596,
          51718
        ]
      },
      {
        "avg_logprob": -0.29362174611032743,
        "compression_ratio": 1.451086956521739,
        "end": 2585.92,
        "id": 453,
        "no_speech_prob": 0.000804037437774241,
        "seek": 258356,
        "start": 2583.92,
        "temperature": 0,
        "text": " So",
        "tokens": [
          50382,
          407,
          50482
        ]
      },
      {
        "avg_logprob": -0.29362174611032743,
        "compression_ratio": 1.451086956521739,
        "end": 2590.88,
        "id": 454,
        "no_speech_prob": 0.000804037437774241,
        "seek": 258356,
        "start": 2588.88,
        "temperature": 0,
        "text": " For whatever reason",
        "tokens": [
          50630,
          1171,
          2035,
          1778,
          50730
        ]
      },
      {
        "avg_logprob": -0.29362174611032743,
        "compression_ratio": 1.451086956521739,
        "end": 2597.08,
        "id": 455,
        "no_speech_prob": 0.000804037437774241,
        "seek": 258356,
        "start": 2592.24,
        "temperature": 0,
        "text": " This works, but this is not the correct way to do it. I'll have to revisit that later",
        "tokens": [
          50798,
          639,
          1985,
          11,
          457,
          341,
          307,
          406,
          264,
          3006,
          636,
          281,
          360,
          309,
          13,
          286,
          603,
          362,
          281,
          32676,
          300,
          1780,
          51040
        ]
      },
      {
        "avg_logprob": -0.29362174611032743,
        "compression_ratio": 1.451086956521739,
        "end": 2601.96,
        "id": 456,
        "no_speech_prob": 0.000804037437774241,
        "seek": 258356,
        "start": 2599.04,
        "temperature": 0,
        "text": " I'm so used to using require. Okay, so",
        "tokens": [
          51138,
          286,
          478,
          370,
          1143,
          281,
          1228,
          3651,
          13,
          1033,
          11,
          370,
          51284
        ]
      },
      {
        "avg_logprob": -0.29362174611032743,
        "compression_ratio": 1.451086956521739,
        "end": 2604.7599999999998,
        "id": 457,
        "no_speech_prob": 0.000804037437774241,
        "seek": 258356,
        "start": 2602.7599999999998,
        "temperature": 0,
        "text": " first of all, let's",
        "tokens": [
          51324,
          700,
          295,
          439,
          11,
          718,
          311,
          51424
        ]
      },
      {
        "avg_logprob": -0.29362174611032743,
        "compression_ratio": 1.451086956521739,
        "end": 2610.52,
        "id": 458,
        "no_speech_prob": 0.000804037437774241,
        "seek": 258356,
        "start": 2604.92,
        "temperature": 0,
        "text": " Just for a minute here. I just want to know I guess I want to leave TF jazz",
        "tokens": [
          51432,
          1449,
          337,
          257,
          3456,
          510,
          13,
          286,
          445,
          528,
          281,
          458,
          286,
          2041,
          286,
          528,
          281,
          1856,
          40964,
          15066,
          51712
        ]
      },
      {
        "avg_logprob": -0.29362174611032743,
        "compression_ratio": 1.451086956521739,
        "end": 2613.16,
        "id": 459,
        "no_speech_prob": 0.000804037437774241,
        "seek": 258356,
        "start": 2611.16,
        "temperature": 0,
        "text": " loaded for right now it",
        "tokens": [
          51744,
          13210,
          337,
          558,
          586,
          309,
          51844
        ]
      },
      {
        "avg_logprob": -0.3388208266227476,
        "compression_ratio": 1.3870967741935485,
        "end": 2617,
        "id": 460,
        "no_speech_prob": 0.0017005663830786943,
        "seek": 261356,
        "start": 2613.56,
        "temperature": 0,
        "text": " Is that what is its console logging there? Yeah, okay",
        "tokens": [
          50364,
          1119,
          300,
          437,
          307,
          1080,
          11076,
          27991,
          456,
          30,
          865,
          11,
          1392,
          50536
        ]
      },
      {
        "avg_logprob": -0.3388208266227476,
        "compression_ratio": 1.3870967741935485,
        "end": 2620.44,
        "id": 461,
        "no_speech_prob": 0.0017005663830786943,
        "seek": 261356,
        "start": 2617.88,
        "temperature": 0,
        "text": " So now if I want to load all the images",
        "tokens": [
          50580,
          407,
          586,
          498,
          286,
          528,
          281,
          3677,
          439,
          264,
          5267,
          50708
        ]
      },
      {
        "avg_logprob": -0.3388208266227476,
        "compression_ratio": 1.3870967741935485,
        "end": 2625.96,
        "id": 462,
        "no_speech_prob": 0.0017005663830786943,
        "seek": 261356,
        "start": 2624.68,
        "temperature": 0,
        "text": " I",
        "tokens": [
          50920,
          286,
          50984
        ]
      },
      {
        "avg_logprob": -0.3388208266227476,
        "compression_ratio": 1.3870967741935485,
        "end": 2630.92,
        "id": 463,
        "no_speech_prob": 0.0017005663830786943,
        "seek": 261356,
        "start": 2625.96,
        "temperature": 0,
        "text": " Mean I could use file system to like figure that out, but I'm just gonna hardcode this",
        "tokens": [
          50984,
          12302,
          286,
          727,
          764,
          3991,
          1185,
          281,
          411,
          2573,
          300,
          484,
          11,
          457,
          286,
          478,
          445,
          799,
          1152,
          22332,
          341,
          51232
        ]
      },
      {
        "avg_logprob": -0.3388208266227476,
        "compression_ratio": 1.3870967741935485,
        "end": 2634.92,
        "id": 464,
        "no_speech_prob": 0.0017005663830786943,
        "seek": 261356,
        "start": 2631.96,
        "temperature": 0,
        "text": " I have how many I have a hundred",
        "tokens": [
          51284,
          286,
          362,
          577,
          867,
          286,
          362,
          257,
          3262,
          51432
        ]
      },
      {
        "avg_logprob": -0.4010450901129307,
        "compression_ratio": 1.1844660194174756,
        "end": 2648.68,
        "id": 465,
        "no_speech_prob": 0.016913915053009987,
        "seek": 264356,
        "start": 2644.12,
        "temperature": 0,
        "text": " And then let's make this a template literal and",
        "tokens": [
          50392,
          400,
          550,
          718,
          311,
          652,
          341,
          257,
          12379,
          20411,
          293,
          50620
        ]
      },
      {
        "avg_logprob": -0.4010450901129307,
        "compression_ratio": 1.1844660194174756,
        "end": 2656.88,
        "id": 466,
        "no_speech_prob": 0.016913915053009987,
        "seek": 264356,
        "start": 2654.88,
        "temperature": 0,
        "text": " So",
        "tokens": [
          50930,
          407,
          51030
        ]
      },
      {
        "avg_logprob": -0.4010450901129307,
        "compression_ratio": 1.1844660194174756,
        "end": 2661.08,
        "id": 467,
        "no_speech_prob": 0.016913915053009987,
        "seek": 264356,
        "start": 2658.7999999999997,
        "temperature": 0,
        "text": " How do I do number formatting in node",
        "tokens": [
          51126,
          1012,
          360,
          286,
          360,
          1230,
          39366,
          294,
          9984,
          51240
        ]
      },
      {
        "avg_logprob": -0.4010450901129307,
        "compression_ratio": 1.1844660194174756,
        "end": 2665.24,
        "id": 468,
        "no_speech_prob": 0.016913915053009987,
        "seek": 264356,
        "start": 2663.24,
        "temperature": 0,
        "text": " Is that native oh",
        "tokens": [
          51348,
          1119,
          300,
          8470,
          1954,
          51448
        ]
      },
      {
        "avg_logprob": -0.4010450901129307,
        "compression_ratio": 1.1844660194174756,
        "end": 2668.72,
        "id": 469,
        "no_speech_prob": 0.016913915053009987,
        "seek": 264356,
        "start": 2666.72,
        "temperature": 0,
        "text": " There's numeral",
        "tokens": [
          51522,
          821,
          311,
          1031,
          2790,
          51622
        ]
      },
      {
        "avg_logprob": -0.6057909085200384,
        "compression_ratio": 1.3409090909090908,
        "end": 2671.08,
        "id": 470,
        "no_speech_prob": 0.0002002706314669922,
        "seek": 266872,
        "start": 2669.08,
        "temperature": 0,
        "text": " All right, let's try numeral this looks cool",
        "tokens": [
          50382,
          1057,
          558,
          11,
          718,
          311,
          853,
          1031,
          2790,
          341,
          1542,
          1627,
          50482
        ]
      },
      {
        "avg_logprob": -0.6057909085200384,
        "compression_ratio": 1.3409090909090908,
        "end": 2675.52,
        "id": 471,
        "no_speech_prob": 0.0002002706314669922,
        "seek": 266872,
        "start": 2672.2799999999997,
        "temperature": 0,
        "text": " And this might be over overkill for what I need to do",
        "tokens": [
          50542,
          400,
          341,
          1062,
          312,
          670,
          670,
          34213,
          337,
          437,
          286,
          643,
          281,
          360,
          50704
        ]
      },
      {
        "avg_logprob": -0.6057909085200384,
        "compression_ratio": 1.3409090909090908,
        "end": 2678.08,
        "id": 472,
        "no_speech_prob": 0.0002002706314669922,
        "seek": 266872,
        "start": 2676.08,
        "temperature": 0,
        "text": " but",
        "tokens": [
          50732,
          457,
          50832
        ]
      },
      {
        "avg_logprob": -0.6057909085200384,
        "compression_ratio": 1.3409090909090908,
        "end": 2683.7599999999998,
        "id": 473,
        "no_speech_prob": 0.0002002706314669922,
        "seek": 266872,
        "start": 2681.7599999999998,
        "temperature": 0,
        "text": " Import load image from canvas",
        "tokens": [
          51016,
          26391,
          3677,
          3256,
          490,
          16267,
          51116
        ]
      },
      {
        "avg_logprob": -0.6057909085200384,
        "compression_ratio": 1.3409090909090908,
        "end": 2695.04,
        "id": 474,
        "no_speech_prob": 0.0002002706314669922,
        "seek": 266872,
        "start": 2693.04,
        "temperature": 0,
        "text": " What if I want to import more than one thing",
        "tokens": [
          51580,
          708,
          498,
          286,
          528,
          281,
          974,
          544,
          813,
          472,
          551,
          51680
        ]
      },
      {
        "avg_logprob": -0.32182281248031125,
        "compression_ratio": 1.1046511627906976,
        "end": 2697.84,
        "id": 475,
        "no_speech_prob": 0.0008969179471023381,
        "seek": 269504,
        "start": 2695.68,
        "temperature": 0,
        "text": " What if I want to import more than one thing",
        "tokens": [
          50396,
          708,
          498,
          286,
          528,
          281,
          974,
          544,
          813,
          472,
          551,
          50504
        ]
      },
      {
        "avg_logprob": -0.32182281248031125,
        "compression_ratio": 1.1046511627906976,
        "end": 2712.8,
        "id": 476,
        "no_speech_prob": 0.0008969179471023381,
        "seek": 269504,
        "start": 2706.44,
        "temperature": 0,
        "text": " Okay, so now let's see how do I use numeral",
        "tokens": [
          50934,
          1033,
          11,
          370,
          586,
          718,
          311,
          536,
          577,
          360,
          286,
          764,
          1031,
          2790,
          51252
        ]
      },
      {
        "avg_logprob": -0.32182281248031125,
        "compression_ratio": 1.1046511627906976,
        "end": 2717.2,
        "id": 477,
        "no_speech_prob": 0.0008969179471023381,
        "seek": 269504,
        "start": 2715.2,
        "temperature": 0,
        "text": " Import",
        "tokens": [
          51372,
          26391,
          51472
        ]
      },
      {
        "avg_logprob": -0.42296364193870906,
        "compression_ratio": 1.1844660194174756,
        "end": 2730.72,
        "id": 478,
        "no_speech_prob": 0.0020829453133046627,
        "seek": 272504,
        "start": 2726.04,
        "temperature": 0,
        "text": " If I want to like call it nl for numeral, I don't know",
        "tokens": [
          50414,
          759,
          286,
          528,
          281,
          411,
          818,
          309,
          297,
          75,
          337,
          1031,
          2790,
          11,
          286,
          500,
          380,
          458,
          50648
        ]
      },
      {
        "avg_logprob": -0.42296364193870906,
        "compression_ratio": 1.1844660194174756,
        "end": 2734.68,
        "id": 479,
        "no_speech_prob": 0.0020829453133046627,
        "seek": 272504,
        "start": 2732.2799999999997,
        "temperature": 0,
        "text": " And then nl",
        "tokens": [
          50726,
          400,
          550,
          297,
          75,
          50846
        ]
      },
      {
        "avg_logprob": -0.42296364193870906,
        "compression_ratio": 1.1844660194174756,
        "end": 2742.56,
        "id": 480,
        "no_speech_prob": 0.0020829453133046627,
        "seek": 272504,
        "start": 2739,
        "temperature": 0,
        "text": " This this might not actually be format, okay",
        "tokens": [
          51062,
          639,
          341,
          1062,
          406,
          767,
          312,
          7877,
          11,
          1392,
          51240
        ]
      },
      {
        "avg_logprob": -0.42296364193870906,
        "compression_ratio": 1.1844660194174756,
        "end": 2749.64,
        "id": 481,
        "no_speech_prob": 0.0020829453133046627,
        "seek": 272504,
        "start": 2747.64,
        "temperature": 0,
        "text": " Nli format",
        "tokens": [
          51494,
          426,
          2081,
          7877,
          51594
        ]
      },
      {
        "avg_logprob": -0.3699315560830606,
        "compression_ratio": 1.4720496894409938,
        "end": 2758.04,
        "id": 482,
        "no_speech_prob": 0.0011694991262629628,
        "seek": 275504,
        "start": 2756.04,
        "temperature": 0,
        "text": " This",
        "tokens": [
          50414,
          639,
          50514
        ]
      },
      {
        "avg_logprob": -0.3699315560830606,
        "compression_ratio": 1.4720496894409938,
        "end": 2761.88,
        "id": 483,
        "no_speech_prob": 0.0011694991262629628,
        "seek": 275504,
        "start": 2758.56,
        "temperature": 0,
        "text": " Is like the format I want is ah so it's",
        "tokens": [
          50540,
          1119,
          411,
          264,
          7877,
          286,
          528,
          307,
          3716,
          370,
          309,
          311,
          50706
        ]
      },
      {
        "avg_logprob": -0.3699315560830606,
        "compression_ratio": 1.4720496894409938,
        "end": 2764.96,
        "id": 484,
        "no_speech_prob": 0.0011694991262629628,
        "seek": 275504,
        "start": 2762.96,
        "temperature": 0,
        "text": " That's the format I want",
        "tokens": [
          50760,
          663,
          311,
          264,
          7877,
          286,
          528,
          50860
        ]
      },
      {
        "avg_logprob": -0.3699315560830606,
        "compression_ratio": 1.4720496894409938,
        "end": 2767.2,
        "id": 485,
        "no_speech_prob": 0.0011694991262629628,
        "seek": 275504,
        "start": 2765,
        "temperature": 0,
        "text": " so now this I",
        "tokens": [
          50862,
          370,
          586,
          341,
          286,
          50972
        ]
      },
      {
        "avg_logprob": -0.3699315560830606,
        "compression_ratio": 1.4720496894409938,
        "end": 2775.04,
        "id": 486,
        "no_speech_prob": 0.0011694991262629628,
        "seek": 275504,
        "start": 2768.08,
        "temperature": 0,
        "text": " Think this should give me all of the file names I to string pad start",
        "tokens": [
          51016,
          6557,
          341,
          820,
          976,
          385,
          439,
          295,
          264,
          3991,
          5288,
          286,
          281,
          6798,
          6887,
          722,
          51364
        ]
      },
      {
        "avg_logprob": -0.3699315560830606,
        "compression_ratio": 1.4720496894409938,
        "end": 2776.68,
        "id": 487,
        "no_speech_prob": 0.0011694991262629628,
        "seek": 275504,
        "start": 2775.16,
        "temperature": 0,
        "text": " Okay, okay",
        "tokens": [
          51370,
          1033,
          11,
          1392,
          51446
        ]
      },
      {
        "avg_logprob": -0.3699315560830606,
        "compression_ratio": 1.4720496894409938,
        "end": 2778.68,
        "id": 488,
        "no_speech_prob": 0.0011694991262629628,
        "seek": 275504,
        "start": 2776.68,
        "temperature": 0,
        "text": " Import ABC from X. Yeah",
        "tokens": [
          51446,
          26391,
          22342,
          490,
          1783,
          13,
          865,
          51546
        ]
      },
      {
        "avg_logprob": -0.3699315560830606,
        "compression_ratio": 1.4720496894409938,
        "end": 2782.04,
        "id": 489,
        "no_speech_prob": 0.0011694991262629628,
        "seek": 275504,
        "start": 2779.48,
        "temperature": 0,
        "text": " Thank you for all these helpful tips in the chat",
        "tokens": [
          51586,
          1044,
          291,
          337,
          439,
          613,
          4961,
          6082,
          294,
          264,
          5081,
          51714
        ]
      },
      {
        "avg_logprob": -0.28018171576004997,
        "compression_ratio": 1.5260115606936415,
        "end": 2787.2,
        "id": 490,
        "no_speech_prob": 0.00006814805237809196,
        "seek": 278204,
        "start": 2783.04,
        "temperature": 0,
        "text": " Okay, I'm running out of space here, let's see if I can give myself some more room",
        "tokens": [
          50414,
          1033,
          11,
          286,
          478,
          2614,
          484,
          295,
          1901,
          510,
          11,
          718,
          311,
          536,
          498,
          286,
          393,
          976,
          2059,
          512,
          544,
          1808,
          50622
        ]
      },
      {
        "avg_logprob": -0.28018171576004997,
        "compression_ratio": 1.5260115606936415,
        "end": 2792.44,
        "id": 491,
        "no_speech_prob": 0.00006814805237809196,
        "seek": 278204,
        "start": 2788.2,
        "temperature": 0,
        "text": " Okay, so then let's just do console dot log image",
        "tokens": [
          50672,
          1033,
          11,
          370,
          550,
          718,
          311,
          445,
          360,
          11076,
          5893,
          3565,
          3256,
          50884
        ]
      },
      {
        "avg_logprob": -0.28018171576004997,
        "compression_ratio": 1.5260115606936415,
        "end": 2795.84,
        "id": 492,
        "no_speech_prob": 0.00006814805237809196,
        "seek": 278204,
        "start": 2793.48,
        "temperature": 0,
        "text": " Let's just do ten images to start",
        "tokens": [
          50936,
          961,
          311,
          445,
          360,
          2064,
          5267,
          281,
          722,
          51054
        ]
      },
      {
        "avg_logprob": -0.28018171576004997,
        "compression_ratio": 1.5260115606936415,
        "end": 2798.88,
        "id": 493,
        "no_speech_prob": 0.00006814805237809196,
        "seek": 278204,
        "start": 2796.88,
        "temperature": 0,
        "text": " See if this works",
        "tokens": [
          51106,
          3008,
          498,
          341,
          1985,
          51206
        ]
      },
      {
        "avg_logprob": -0.28018171576004997,
        "compression_ratio": 1.5260115606936415,
        "end": 2805,
        "id": 494,
        "no_speech_prob": 0.00006814805237809196,
        "seek": 278204,
        "start": 2799.56,
        "temperature": 0,
        "text": " No, no, no, no, so numeral I didn't need because I could just do it with string",
        "tokens": [
          51240,
          883,
          11,
          572,
          11,
          572,
          11,
          572,
          11,
          370,
          1031,
          2790,
          286,
          994,
          380,
          643,
          570,
          286,
          727,
          445,
          360,
          309,
          365,
          6798,
          51512
        ]
      },
      {
        "avg_logprob": -0.5522312251004305,
        "compression_ratio": 1.3425925925925926,
        "end": 2819.44,
        "id": 495,
        "no_speech_prob": 0.000044001080823363736,
        "seek": 281204,
        "start": 2812.96,
        "temperature": 0,
        "text": " Let's try did I did I install numeral I did so how come this didn't work",
        "tokens": [
          50410,
          961,
          311,
          853,
          630,
          286,
          630,
          286,
          3625,
          1031,
          2790,
          286,
          630,
          370,
          577,
          808,
          341,
          994,
          380,
          589,
          50734
        ]
      },
      {
        "avg_logprob": -0.5522312251004305,
        "compression_ratio": 1.3425925925925926,
        "end": 2823.84,
        "id": 496,
        "no_speech_prob": 0.000044001080823363736,
        "seek": 281204,
        "start": 2821.84,
        "temperature": 0,
        "text": " Import",
        "tokens": [
          50854,
          26391,
          50954
        ]
      },
      {
        "avg_logprob": -0.5522312251004305,
        "compression_ratio": 1.3425925925925926,
        "end": 2827.96,
        "id": 497,
        "no_speech_prob": 0.000044001080823363736,
        "seek": 281204,
        "start": 2825.56,
        "temperature": 0,
        "text": " Numeral from numeral maybe it's that",
        "tokens": [
          51040,
          22592,
          2790,
          490,
          1031,
          2790,
          1310,
          309,
          311,
          300,
          51160
        ]
      },
      {
        "avg_logprob": -0.5522312251004305,
        "compression_ratio": 1.3425925925925926,
        "end": 2839.16,
        "id": 498,
        "no_speech_prob": 0.000044001080823363736,
        "seek": 281204,
        "start": 2837.16,
        "temperature": 0,
        "text": " Load image is not a function",
        "tokens": [
          51620,
          48408,
          3256,
          307,
          406,
          257,
          2445,
          51720
        ]
      },
      {
        "avg_logprob": -0.6047782500584921,
        "compression_ratio": 0.971830985915493,
        "end": 2845.04,
        "id": 499,
        "no_speech_prob": 0.000869273382704705,
        "seek": 284204,
        "start": 2843.04,
        "temperature": 0,
        "text": " Didn't like this for",
        "tokens": [
          50414,
          11151,
          380,
          411,
          341,
          337,
          50514
        ]
      },
      {
        "avg_logprob": -0.6047782500584921,
        "compression_ratio": 0.971830985915493,
        "end": 2858.8,
        "id": 500,
        "no_speech_prob": 0.000869273382704705,
        "seek": 284204,
        "start": 2855.88,
        "temperature": 0,
        "text": " I don't know. What did how did I get it working?",
        "tokens": [
          51056,
          286,
          500,
          380,
          458,
          13,
          708,
          630,
          577,
          630,
          286,
          483,
          309,
          1364,
          30,
          51202
        ]
      },
      {
        "avg_logprob": -0.27840232849121094,
        "compression_ratio": 1.456043956043956,
        "end": 2874.04,
        "id": 501,
        "no_speech_prob": 0.0028008061926811934,
        "seek": 287204,
        "start": 2872.04,
        "temperature": 0,
        "text": " Okay",
        "tokens": [
          50364,
          1033,
          50464
        ]
      },
      {
        "avg_logprob": -0.27840232849121094,
        "compression_ratio": 1.456043956043956,
        "end": 2878.24,
        "id": 502,
        "no_speech_prob": 0.0028008061926811934,
        "seek": 287204,
        "start": 2876.24,
        "temperature": 0,
        "text": " So",
        "tokens": [
          50574,
          407,
          50674
        ]
      },
      {
        "avg_logprob": -0.27840232849121094,
        "compression_ratio": 1.456043956043956,
        "end": 2884.6,
        "id": 503,
        "no_speech_prob": 0.0028008061926811934,
        "seek": 287204,
        "start": 2879.04,
        "temperature": 0,
        "text": " I'm doing things in some awkward unnecessary ways like first of all, I don't need this numeral package",
        "tokens": [
          50714,
          286,
          478,
          884,
          721,
          294,
          512,
          11411,
          19350,
          2098,
          411,
          700,
          295,
          439,
          11,
          286,
          500,
          380,
          643,
          341,
          1031,
          2790,
          7372,
          50992
        ]
      },
      {
        "avg_logprob": -0.27840232849121094,
        "compression_ratio": 1.456043956043956,
        "end": 2891.7599999999998,
        "id": 504,
        "no_speech_prob": 0.0028008061926811934,
        "seek": 287204,
        "start": 2885.12,
        "temperature": 0,
        "text": " because I could just use like number to string or something, but it works nicely for me and I",
        "tokens": [
          51018,
          570,
          286,
          727,
          445,
          764,
          411,
          1230,
          281,
          6798,
          420,
          746,
          11,
          457,
          309,
          1985,
          9594,
          337,
          385,
          293,
          286,
          51350
        ]
      },
      {
        "avg_logprob": -0.27840232849121094,
        "compression_ratio": 1.456043956043956,
        "end": 2896.2,
        "id": 505,
        "no_speech_prob": 0.0028008061926811934,
        "seek": 287204,
        "start": 2892.6,
        "temperature": 0,
        "text": " Don't understand why I'm doing it this way import",
        "tokens": [
          51392,
          1468,
          380,
          1223,
          983,
          286,
          478,
          884,
          309,
          341,
          636,
          974,
          51572
        ]
      },
      {
        "avg_logprob": -0.27840232849121094,
        "compression_ratio": 1.456043956043956,
        "end": 2900.36,
        "id": 506,
        "no_speech_prob": 0.0028008061926811934,
        "seek": 287204,
        "start": 2898.36,
        "temperature": 0,
        "text": " Load image",
        "tokens": [
          51680,
          48408,
          3256,
          51780
        ]
      },
      {
        "avg_logprob": -0.32970331632173977,
        "compression_ratio": 1.4465408805031446,
        "end": 2904.7599999999998,
        "id": 507,
        "no_speech_prob": 0.0012842941796407104,
        "seek": 290204,
        "start": 2902.7599999999998,
        "temperature": 0,
        "text": " That no, I",
        "tokens": [
          50400,
          663,
          572,
          11,
          286,
          50500
        ]
      },
      {
        "avg_logprob": -0.32970331632173977,
        "compression_ratio": 1.4465408805031446,
        "end": 2908.88,
        "id": 508,
        "no_speech_prob": 0.0012842941796407104,
        "seek": 290204,
        "start": 2905.36,
        "temperature": 0,
        "text": " Don't I still don't understand how yes, I should read up on how these",
        "tokens": [
          50530,
          1468,
          380,
          286,
          920,
          500,
          380,
          1223,
          577,
          2086,
          11,
          286,
          820,
          1401,
          493,
          322,
          577,
          613,
          50706
        ]
      },
      {
        "avg_logprob": -0.32970331632173977,
        "compression_ratio": 1.4465408805031446,
        "end": 2912,
        "id": 509,
        "no_speech_prob": 0.0012842941796407104,
        "seek": 290204,
        "start": 2909.64,
        "temperature": 0,
        "text": " Import statements work, but this works",
        "tokens": [
          50744,
          26391,
          12363,
          589,
          11,
          457,
          341,
          1985,
          50862
        ]
      },
      {
        "avg_logprob": -0.32970331632173977,
        "compression_ratio": 1.4465408805031446,
        "end": 2918.92,
        "id": 510,
        "no_speech_prob": 0.0012842941796407104,
        "seek": 290204,
        "start": 2915,
        "temperature": 0,
        "text": " Yeah, I tried that import load image from canvas",
        "tokens": [
          51012,
          865,
          11,
          286,
          3031,
          300,
          974,
          3677,
          3256,
          490,
          16267,
          51208
        ]
      },
      {
        "avg_logprob": -0.32970331632173977,
        "compression_ratio": 1.4465408805031446,
        "end": 2927.08,
        "id": 511,
        "no_speech_prob": 0.0012842941796407104,
        "seek": 290204,
        "start": 2923.44,
        "temperature": 0,
        "text": " Right look watch I don't want to get stuck on this stuff, but",
        "tokens": [
          51434,
          1779,
          574,
          1159,
          286,
          500,
          380,
          528,
          281,
          483,
          5541,
          322,
          341,
          1507,
          11,
          457,
          51616
        ]
      },
      {
        "avg_logprob": -0.6202312469482422,
        "compression_ratio": 1.3655172413793104,
        "end": 2930.08,
        "id": 512,
        "no_speech_prob": 0.004198647104203701,
        "seek": 292708,
        "start": 2928.08,
        "temperature": 0,
        "text": " Right, I believe this should work",
        "tokens": [
          50414,
          1779,
          11,
          286,
          1697,
          341,
          820,
          589,
          50514
        ]
      },
      {
        "avg_logprob": -0.6202312469482422,
        "compression_ratio": 1.3655172413793104,
        "end": 2936.7599999999998,
        "id": 513,
        "no_speech_prob": 0.004198647104203701,
        "seek": 292708,
        "start": 2932.68,
        "temperature": 0,
        "text": " And it's not so you got me",
        "tokens": [
          50644,
          400,
          309,
          311,
          406,
          370,
          291,
          658,
          385,
          50848
        ]
      },
      {
        "avg_logprob": -0.6202312469482422,
        "compression_ratio": 1.3655172413793104,
        "end": 2943.84,
        "id": 514,
        "no_speech_prob": 0.004198647104203701,
        "seek": 292708,
        "start": 2938.48,
        "temperature": 0,
        "text": " As to why that doesn't work, but this is working",
        "tokens": [
          50934,
          1018,
          281,
          983,
          300,
          1177,
          380,
          589,
          11,
          457,
          341,
          307,
          1364,
          51202
        ]
      },
      {
        "avg_logprob": -0.6202312469482422,
        "compression_ratio": 1.3655172413793104,
        "end": 2949.7599999999998,
        "id": 515,
        "no_speech_prob": 0.004198647104203701,
        "seek": 292708,
        "start": 2946.48,
        "temperature": 0,
        "text": " Okay, so now the question is can I then",
        "tokens": [
          51334,
          1033,
          11,
          370,
          586,
          264,
          1168,
          307,
          393,
          286,
          550,
          51498
        ]
      },
      {
        "avg_logprob": -0.6202312469482422,
        "compression_ratio": 1.3655172413793104,
        "end": 2953.3199999999997,
        "id": 516,
        "no_speech_prob": 0.004198647104203701,
        "seek": 292708,
        "start": 2950.7999999999997,
        "temperature": 0,
        "text": " The point of this was to convert them to tensors",
        "tokens": [
          51550,
          440,
          935,
          295,
          341,
          390,
          281,
          7620,
          552,
          281,
          10688,
          830,
          51676
        ]
      },
      {
        "avg_logprob": -0.37833001878526473,
        "compression_ratio": 1.1428571428571428,
        "end": 2955.84,
        "id": 517,
        "no_speech_prob": 0.004905016161501408,
        "seek": 295332,
        "start": 2953.32,
        "temperature": 0,
        "text": " The point of this was to convert them to tensors",
        "tokens": [
          50364,
          440,
          935,
          295,
          341,
          390,
          281,
          7620,
          552,
          281,
          10688,
          830,
          50490
        ]
      },
      {
        "avg_logprob": -0.37833001878526473,
        "compression_ratio": 1.1428571428571428,
        "end": 2962,
        "id": 518,
        "no_speech_prob": 0.004905016161501408,
        "seek": 295332,
        "start": 2957.28,
        "temperature": 0,
        "text": " Now from pixels image",
        "tokens": [
          50562,
          823,
          490,
          18668,
          3256,
          50798
        ]
      },
      {
        "avg_logprob": -0.37833001878526473,
        "compression_ratio": 1.1428571428571428,
        "end": 2967.1600000000003,
        "id": 519,
        "no_speech_prob": 0.004905016161501408,
        "seek": 295332,
        "start": 2965.1600000000003,
        "temperature": 0,
        "text": " T no not",
        "tokens": [
          50956,
          314,
          572,
          406,
          51056
        ]
      },
      {
        "avg_logprob": -0.37833001878526473,
        "compression_ratio": 1.1428571428571428,
        "end": 2974.88,
        "id": 520,
        "no_speech_prob": 0.004905016161501408,
        "seek": 295332,
        "start": 2972.88,
        "temperature": 0,
        "text": " Wait",
        "tokens": [
          51342,
          3802,
          51442
        ]
      },
      {
        "avg_logprob": -0.37833001878526473,
        "compression_ratio": 1.1428571428571428,
        "end": 2978.36,
        "id": 521,
        "no_speech_prob": 0.004905016161501408,
        "seek": 295332,
        "start": 2976.36,
        "temperature": 0,
        "text": " So I've loaded them",
        "tokens": [
          51516,
          407,
          286,
          600,
          13210,
          552,
          51616
        ]
      },
      {
        "avg_logprob": -0.36378724234444754,
        "compression_ratio": 1.2735849056603774,
        "end": 2981.36,
        "id": 522,
        "no_speech_prob": 0.0014323827344924212,
        "seek": 297836,
        "start": 2979.36,
        "temperature": 0,
        "text": " I",
        "tokens": [
          50414,
          286,
          50514
        ]
      },
      {
        "avg_logprob": -0.36378724234444754,
        "compression_ratio": 1.2735849056603774,
        "end": 2984.1200000000003,
        "id": 523,
        "no_speech_prob": 0.0014323827344924212,
        "seek": 297836,
        "start": 2982,
        "temperature": 0,
        "text": " Promise is with browser",
        "tokens": [
          50546,
          34878,
          307,
          365,
          11185,
          50652
        ]
      },
      {
        "avg_logprob": -0.36378724234444754,
        "compression_ratio": 1.2735849056603774,
        "end": 2988.7200000000003,
        "id": 524,
        "no_speech_prob": 0.0014323827344924212,
        "seek": 297836,
        "start": 2986.7200000000003,
        "temperature": 0,
        "text": " So I don't have a",
        "tokens": [
          50782,
          407,
          286,
          500,
          380,
          362,
          257,
          50882
        ]
      },
      {
        "avg_logprob": -0.36378724234444754,
        "compression_ratio": 1.2735849056603774,
        "end": 2991.32,
        "id": 525,
        "no_speech_prob": 0.0014323827344924212,
        "seek": 297836,
        "start": 2989.32,
        "temperature": 0,
        "text": " Browser I",
        "tokens": [
          50912,
          1603,
          30947,
          286,
          51012
        ]
      },
      {
        "avg_logprob": -0.36378724234444754,
        "compression_ratio": 1.2735849056603774,
        "end": 2995.6400000000003,
        "id": 526,
        "no_speech_prob": 0.0014323827344924212,
        "seek": 297836,
        "start": 2992.76,
        "temperature": 0,
        "text": " Should just have done it the way I was starting to do it",
        "tokens": [
          51084,
          6454,
          445,
          362,
          1096,
          309,
          264,
          636,
          286,
          390,
          2891,
          281,
          360,
          309,
          51228
        ]
      },
      {
        "avg_logprob": -0.36378724234444754,
        "compression_ratio": 1.2735849056603774,
        "end": 3006.1600000000003,
        "id": 527,
        "no_speech_prob": 0.0014323827344924212,
        "seek": 297836,
        "start": 3003.92,
        "temperature": 0,
        "text": " Yeah, yes, that's a good",
        "tokens": [
          51642,
          865,
          11,
          2086,
          11,
          300,
          311,
          257,
          665,
          51754
        ]
      },
      {
        "avg_logprob": -0.5485496520996094,
        "compression_ratio": 1.295774647887324,
        "end": 3011.16,
        "id": 528,
        "no_speech_prob": 0.00031015006243251264,
        "seek": 300616,
        "start": 3006.7599999999998,
        "temperature": 0,
        "text": " So just out of curiosity, I'm going to take Sorrell's I'm probably mispronouncing your name",
        "tokens": [
          50394,
          407,
          445,
          484,
          295,
          18769,
          11,
          286,
          478,
          516,
          281,
          747,
          21421,
          19771,
          311,
          286,
          478,
          1391,
          3346,
          1424,
          266,
          1733,
          2175,
          428,
          1315,
          50614
        ]
      },
      {
        "avg_logprob": -0.5485496520996094,
        "compression_ratio": 1.295774647887324,
        "end": 3014.68,
        "id": 529,
        "no_speech_prob": 0.00031015006243251264,
        "seek": 300616,
        "start": 3012.68,
        "temperature": 0,
        "text": " Import",
        "tokens": [
          50690,
          26391,
          50790
        ]
      },
      {
        "avg_logprob": -0.5485496520996094,
        "compression_ratio": 1.295774647887324,
        "end": 3019.2799999999997,
        "id": 530,
        "no_speech_prob": 0.00031015006243251264,
        "seek": 300616,
        "start": 3017.2799999999997,
        "temperature": 0,
        "text": " And then I could say",
        "tokens": [
          50920,
          400,
          550,
          286,
          727,
          584,
          51020
        ]
      },
      {
        "avg_logprob": -0.5485496520996094,
        "compression_ratio": 1.295774647887324,
        "end": 3025.3199999999997,
        "id": 531,
        "no_speech_prob": 0.00031015006243251264,
        "seek": 300616,
        "start": 3022.3599999999997,
        "temperature": 0,
        "text": " I mean, it's a little bit more verbose",
        "tokens": [
          51174,
          286,
          914,
          11,
          309,
          311,
          257,
          707,
          857,
          544,
          9595,
          541,
          51322
        ]
      },
      {
        "avg_logprob": -0.5485496520996094,
        "compression_ratio": 1.295774647887324,
        "end": 3029.7599999999998,
        "id": 532,
        "no_speech_prob": 0.00031015006243251264,
        "seek": 300616,
        "start": 3027.7599999999998,
        "temperature": 0,
        "text": " Yeah, I I'm lost",
        "tokens": [
          51444,
          865,
          11,
          286,
          286,
          478,
          2731,
          51544
        ]
      },
      {
        "avg_logprob": -0.5485496520996094,
        "compression_ratio": 1.295774647887324,
        "end": 3033.16,
        "id": 533,
        "no_speech_prob": 0.00031015006243251264,
        "seek": 300616,
        "start": 3031.16,
        "temperature": 0,
        "text": " But also",
        "tokens": [
          51614,
          583,
          611,
          51714
        ]
      },
      {
        "avg_logprob": -0.7746211781221277,
        "compression_ratio": 0.8928571428571429,
        "end": 3042.44,
        "id": 534,
        "no_speech_prob": 0.0002652971597854048,
        "seek": 303316,
        "start": 3033.96,
        "temperature": 0,
        "text": " How do I convert it now to a tensor can I just say",
        "tokens": [
          50404,
          1012,
          360,
          286,
          7620,
          309,
          586,
          281,
          257,
          40863,
          393,
          286,
          445,
          584,
          50828
        ]
      },
      {
        "avg_logprob": -0.5576953252156576,
        "compression_ratio": 0.84,
        "end": 3049.88,
        "id": 535,
        "no_speech_prob": 0.1275884062051773,
        "seek": 304244,
        "start": 3042.44,
        "temperature": 0.8,
        "text": " Convert it now to a tensor. Can I just say",
        "tokens": [
          50364,
          2656,
          3281,
          309,
          586,
          281,
          257,
          40863,
          13,
          1664,
          286,
          445,
          584,
          50736
        ]
      },
      {
        "avg_logprob": -0.38703250885009766,
        "compression_ratio": 1.1012658227848102,
        "end": 3091.56,
        "id": 536,
        "no_speech_prob": 0.05339024215936661,
        "seek": 307244,
        "start": 3072.44,
        "temperature": 0,
        "text": " this is what I want to do, but I don't think it's going to let me. It's not a function.",
        "tokens": [
          50364,
          341,
          307,
          437,
          286,
          528,
          281,
          360,
          11,
          457,
          286,
          500,
          380,
          519,
          309,
          311,
          516,
          281,
          718,
          385,
          13,
          467,
          311,
          406,
          257,
          2445,
          13,
          51320
        ]
      },
      {
        "avg_logprob": -0.48132462337099274,
        "compression_ratio": 1.024390243902439,
        "end": 3116.24,
        "id": 537,
        "no_speech_prob": 0.12764178216457367,
        "seek": 309156,
        "start": 3091.56,
        "temperature": 0,
        "text": " Can I get this to work from node? Just add support to tf.fromPixels in node. This is",
        "tokens": [
          50364,
          1664,
          286,
          483,
          341,
          281,
          589,
          490,
          9984,
          30,
          1449,
          909,
          1406,
          281,
          256,
          69,
          13,
          20579,
          47,
          970,
          1625,
          294,
          9984,
          13,
          639,
          307,
          51598
        ]
      },
      {
        "avg_logprob": -0.8680190443992615,
        "compression_ratio": 0.68,
        "end": 3137.3999999999996,
        "id": 538,
        "no_speech_prob": 0.34156113862991333,
        "seek": 311624,
        "start": 3116.24,
        "temperature": 0,
        "text": " supposed to work.",
        "tokens": [
          50364,
          3442,
          281,
          589,
          13,
          51422
        ]
      },
      {
        "avg_logprob": -0.3335801230536567,
        "compression_ratio": 1.0470588235294118,
        "end": 3154.6,
        "id": 539,
        "no_speech_prob": 0.15610159933567047,
        "seek": 313740,
        "start": 3137.4,
        "temperature": 0,
        "text": " This should work according to this. Am I in the wrong version of tf.js somehow? Do I need",
        "tokens": [
          50364,
          639,
          820,
          589,
          4650,
          281,
          341,
          13,
          2012,
          286,
          294,
          264,
          2085,
          3037,
          295,
          256,
          69,
          13,
          25530,
          6063,
          30,
          1144,
          286,
          643,
          51224
        ]
      },
      {
        "avg_logprob": -0.8023945263453892,
        "compression_ratio": 0.4666666666666667,
        "end": 3179.16,
        "id": 540,
        "no_speech_prob": 0.9821158647537231,
        "seek": 315460,
        "start": 3154.6,
        "temperature": 0,
        "text": " a core?",
        "tokens": [
          50364,
          257,
          4965,
          30,
          51592
        ]
      },
      {
        "avg_logprob": -0.6659340651138969,
        "compression_ratio": 0.813953488372093,
        "end": 3188.64,
        "id": 541,
        "no_speech_prob": 0.8536255359649658,
        "seek": 317916,
        "start": 3179.16,
        "temperature": 0,
        "text": " fix tf.fromPixels.",
        "tokens": [
          50364,
          3191,
          256,
          69,
          13,
          20579,
          47,
          970,
          1625,
          13,
          50838
        ]
      },
      {
        "avg_logprob": -0.6659340651138969,
        "compression_ratio": 0.813953488372093,
        "end": 3192.04,
        "id": 542,
        "no_speech_prob": 0.8536255359649658,
        "seek": 317916,
        "start": 3188.64,
        "temperature": 0,
        "text": " Why?",
        "tokens": [
          50838,
          1545,
          30,
          51008
        ]
      },
      {
        "avg_logprob": -0.6659340651138969,
        "compression_ratio": 0.813953488372093,
        "end": 3206.92,
        "id": 543,
        "no_speech_prob": 0.8536255359649658,
        "seek": 317916,
        "start": 3192.04,
        "temperature": 0,
        "text": " Supposedly.",
        "tokens": [
          51008,
          9391,
          1744,
          356,
          13,
          51752
        ]
      },
      {
        "avg_logprob": -0.42942271694060297,
        "compression_ratio": 1.0909090909090908,
        "end": 3220.12,
        "id": 544,
        "no_speech_prob": 0.2226608544588089,
        "seek": 320692,
        "start": 3206.92,
        "temperature": 0,
        "text": " tf.fromPixels is not a function. It must have changed. Let me just see which version am I using.",
        "tokens": [
          50364,
          256,
          69,
          13,
          20579,
          47,
          970,
          1625,
          307,
          406,
          257,
          2445,
          13,
          467,
          1633,
          362,
          3105,
          13,
          961,
          385,
          445,
          536,
          597,
          3037,
          669,
          286,
          1228,
          13,
          51024
        ]
      },
      {
        "avg_logprob": -0.5478927438909357,
        "compression_ratio": 0.9733333333333334,
        "end": 3242.2,
        "id": 545,
        "no_speech_prob": 0.7181883454322815,
        "seek": 322012,
        "start": 3220.12,
        "temperature": 0,
        "text": " 3. Is this somehow different? This is the node version. Did that go away?",
        "tokens": [
          50364,
          805,
          13,
          1119,
          341,
          6063,
          819,
          30,
          639,
          307,
          264,
          9984,
          3037,
          13,
          2589,
          300,
          352,
          1314,
          30,
          51468
        ]
      },
      {
        "avg_logprob": -0.45961123875209264,
        "compression_ratio": 1.1222222222222222,
        "end": 3256.48,
        "id": 546,
        "no_speech_prob": 0.800433874130249,
        "seek": 324220,
        "start": 3242.2,
        "temperature": 0,
        "text": " Oh, tf.image. Can I just put the browser in there and it will figure it out? Is it",
        "tokens": [
          50364,
          876,
          11,
          256,
          69,
          13,
          26624,
          13,
          1664,
          286,
          445,
          829,
          264,
          11185,
          294,
          456,
          293,
          309,
          486,
          2573,
          309,
          484,
          30,
          1119,
          309,
          51078
        ]
      },
      {
        "avg_logprob": -0.45961123875209264,
        "compression_ratio": 1.1222222222222222,
        "end": 3257.48,
        "id": 547,
        "no_speech_prob": 0.800433874130249,
        "seek": 324220,
        "start": 3256.48,
        "temperature": 0,
        "text": " as simple as that?",
        "tokens": [
          51078,
          382,
          2199,
          382,
          300,
          30,
          51128
        ]
      },
      {
        "avg_logprob": -0.4729172035499855,
        "compression_ratio": 0.9743589743589743,
        "end": 3281.44,
        "id": 548,
        "no_speech_prob": 0.4920095205307007,
        "seek": 325748,
        "start": 3257.48,
        "temperature": 0,
        "text": " Did I forget? Pixels pass to tf.browser must either be image data in Brower.",
        "tokens": [
          50364,
          2589,
          286,
          2870,
          30,
          18652,
          1625,
          1320,
          281,
          256,
          69,
          13,
          1443,
          30947,
          1633,
          2139,
          312,
          3256,
          1412,
          294,
          1603,
          305,
          260,
          13,
          51562
        ]
      },
      {
        "avg_logprob": -0.28552444613709743,
        "compression_ratio": 1.8041237113402062,
        "end": 3289.36,
        "id": 549,
        "no_speech_prob": 0.9552208185195923,
        "seek": 328144,
        "start": 3281.44,
        "temperature": 0,
        "text": " I should go back to my original solution. tf.fromPixels was deprecated. I should just",
        "tokens": [
          50364,
          286,
          820,
          352,
          646,
          281,
          452,
          3380,
          3827,
          13,
          256,
          69,
          13,
          20579,
          47,
          970,
          1625,
          390,
          1367,
          13867,
          770,
          13,
          286,
          820,
          445,
          50760
        ]
      },
      {
        "avg_logprob": -0.28552444613709743,
        "compression_ratio": 1.8041237113402062,
        "end": 3295.8,
        "id": 550,
        "no_speech_prob": 0.9552208185195923,
        "seek": 328144,
        "start": 3289.36,
        "temperature": 0,
        "text": " go back to my original solution. I'm going to go back to my original solution using GIMP.",
        "tokens": [
          50760,
          352,
          646,
          281,
          452,
          3380,
          3827,
          13,
          286,
          478,
          516,
          281,
          352,
          646,
          281,
          452,
          3380,
          3827,
          1228,
          460,
          6324,
          47,
          13,
          51082
        ]
      },
      {
        "avg_logprob": -0.28552444613709743,
        "compression_ratio": 1.8041237113402062,
        "end": 3300.2000000000003,
        "id": 551,
        "no_speech_prob": 0.9552208185195923,
        "seek": 328144,
        "start": 3295.8,
        "temperature": 0,
        "text": " I can make a tensor very easily with this small amount of data. We could come back if",
        "tokens": [
          51082,
          286,
          393,
          652,
          257,
          40863,
          588,
          3612,
          365,
          341,
          1359,
          2372,
          295,
          1412,
          13,
          492,
          727,
          808,
          646,
          498,
          51302
        ]
      },
      {
        "avg_logprob": -0.28552444613709743,
        "compression_ratio": 1.8041237113402062,
        "end": 3309.88,
        "id": 552,
        "no_speech_prob": 0.9552208185195923,
        "seek": 328144,
        "start": 3300.2000000000003,
        "temperature": 0,
        "text": " there's a more efficient way of doing this. Let's just go back to GIMP. I could probably",
        "tokens": [
          51302,
          456,
          311,
          257,
          544,
          7148,
          636,
          295,
          884,
          341,
          13,
          961,
          311,
          445,
          352,
          646,
          281,
          460,
          6324,
          47,
          13,
          286,
          727,
          1391,
          51786
        ]
      },
      {
        "avg_logprob": -0.4217601255937056,
        "compression_ratio": 1.1025641025641026,
        "end": 3321.76,
        "id": 553,
        "no_speech_prob": 0.9871200323104858,
        "seek": 330988,
        "start": 3309.88,
        "temperature": 0,
        "text": " read the pixels just with node canvas, which might be useful because then if I want to",
        "tokens": [
          50364,
          1401,
          264,
          18668,
          445,
          365,
          9984,
          16267,
          11,
          597,
          1062,
          312,
          4420,
          570,
          550,
          498,
          286,
          528,
          281,
          50958
        ]
      },
      {
        "avg_logprob": -0.31678423514732945,
        "compression_ratio": 1.0625,
        "end": 3347.28,
        "id": 554,
        "no_speech_prob": 0.5270770788192749,
        "seek": 332176,
        "start": 3321.76,
        "temperature": 0,
        "text": " ever just do this in the browser. Let's not do it this way. Actually, can I just read",
        "tokens": [
          50364,
          1562,
          445,
          360,
          341,
          294,
          264,
          11185,
          13,
          961,
          311,
          406,
          360,
          309,
          341,
          636,
          13,
          5135,
          11,
          393,
          286,
          445,
          1401,
          51640
        ]
      },
      {
        "avg_logprob": -0.3968311592384621,
        "compression_ratio": 1.12987012987013,
        "end": 3370.36,
        "id": 555,
        "no_speech_prob": 0.9323456287384033,
        "seek": 334728,
        "start": 3347.28,
        "temperature": 0,
        "text": " the pixels here? This is what comes up first in my search. Image data. Image data.data.",
        "tokens": [
          50364,
          264,
          18668,
          510,
          30,
          639,
          307,
          437,
          1487,
          493,
          700,
          294,
          452,
          3164,
          13,
          29903,
          1412,
          13,
          29903,
          1412,
          13,
          67,
          3274,
          13,
          51518
        ]
      },
      {
        "avg_logprob": -0.24350460938044957,
        "compression_ratio": 1.3357664233576643,
        "end": 3389.84,
        "id": 556,
        "no_speech_prob": 0.5543808937072754,
        "seek": 337036,
        "start": 3370.36,
        "temperature": 0,
        "text": " Is it there? Is it there? Do I have the pixels? No. It's such a weird thing for it to console",
        "tokens": [
          50364,
          1119,
          309,
          456,
          30,
          1119,
          309,
          456,
          30,
          1144,
          286,
          362,
          264,
          18668,
          30,
          883,
          13,
          467,
          311,
          1270,
          257,
          3657,
          551,
          337,
          309,
          281,
          11076,
          51338
        ]
      },
      {
        "avg_logprob": -0.24350460938044957,
        "compression_ratio": 1.3357664233576643,
        "end": 3398.8,
        "id": 557,
        "no_speech_prob": 0.5543808937072754,
        "seek": 337036,
        "start": 3389.84,
        "temperature": 0,
        "text": " log. Yeah, Sean, this is such a good question. I don't really know why I started doing. I",
        "tokens": [
          51338,
          3565,
          13,
          865,
          11,
          14839,
          11,
          341,
          307,
          1270,
          257,
          665,
          1168,
          13,
          286,
          500,
          380,
          534,
          458,
          983,
          286,
          1409,
          884,
          13,
          286,
          51786
        ]
      },
      {
        "avg_logprob": -0.2347378797934089,
        "compression_ratio": 1.4858757062146892,
        "end": 3407.2000000000003,
        "id": 558,
        "no_speech_prob": 0.9018326997756958,
        "seek": 339880,
        "start": 3398.8,
        "temperature": 0,
        "text": " was imagining that at some point I wanted to process huge amounts of data. I don't know.",
        "tokens": [
          50364,
          390,
          27798,
          300,
          412,
          512,
          935,
          286,
          1415,
          281,
          1399,
          2603,
          11663,
          295,
          1412,
          13,
          286,
          500,
          380,
          458,
          13,
          50784
        ]
      },
      {
        "avg_logprob": -0.2347378797934089,
        "compression_ratio": 1.4858757062146892,
        "end": 3410.32,
        "id": 559,
        "no_speech_prob": 0.9018326997756958,
        "seek": 339880,
        "start": 3407.2000000000003,
        "temperature": 0,
        "text": " There's not really a good reason. It's just where I started because it was easier for",
        "tokens": [
          50784,
          821,
          311,
          406,
          534,
          257,
          665,
          1778,
          13,
          467,
          311,
          445,
          689,
          286,
          1409,
          570,
          309,
          390,
          3571,
          337,
          50940
        ]
      },
      {
        "avg_logprob": -0.2347378797934089,
        "compression_ratio": 1.4858757062146892,
        "end": 3416.4,
        "id": 560,
        "no_speech_prob": 0.9018326997756958,
        "seek": 339880,
        "start": 3410.32,
        "temperature": 0,
        "text": " me to work it out. I could just use the file system, like I said. This is silly. I could",
        "tokens": [
          50940,
          385,
          281,
          589,
          309,
          484,
          13,
          286,
          727,
          445,
          764,
          264,
          3991,
          1185,
          11,
          411,
          286,
          848,
          13,
          639,
          307,
          11774,
          13,
          286,
          727,
          51244
        ]
      },
      {
        "avg_logprob": -0.3460366249084473,
        "compression_ratio": 1.1,
        "end": 3440.2000000000003,
        "id": 561,
        "no_speech_prob": 0.3450416028499603,
        "seek": 341640,
        "start": 3416.4,
        "temperature": 0,
        "text": " come back to get image data. I have to draw it as I go. Okay. All right. All right. I've",
        "tokens": [
          50364,
          808,
          646,
          281,
          483,
          3256,
          1412,
          13,
          286,
          362,
          281,
          2642,
          309,
          382,
          286,
          352,
          13,
          1033,
          13,
          1057,
          558,
          13,
          1057,
          558,
          13,
          286,
          600,
          51554
        ]
      },
      {
        "avg_logprob": -0.2455120475924745,
        "compression_ratio": 1.3384615384615384,
        "end": 3455.3599999999997,
        "id": 562,
        "no_speech_prob": 0.6858841776847839,
        "seek": 344020,
        "start": 3440.2,
        "temperature": 0,
        "text": " gone far enough with this silly way. Okay. Get array of pixels from an image file. Image",
        "tokens": [
          50364,
          2780,
          1400,
          1547,
          365,
          341,
          11774,
          636,
          13,
          1033,
          13,
          3240,
          10225,
          295,
          18668,
          490,
          364,
          3256,
          3991,
          13,
          29903,
          51122
        ]
      },
      {
        "avg_logprob": -0.2455120475924745,
        "compression_ratio": 1.3384615384615384,
        "end": 3460.7599999999998,
        "id": 563,
        "no_speech_prob": 0.6858841776847839,
        "seek": 344020,
        "start": 3455.3599999999997,
        "temperature": 0,
        "text": " pixel color. Okay. Right. This is where I started. Okay. Great. So we're going to use",
        "tokens": [
          51122,
          19261,
          2017,
          13,
          1033,
          13,
          1779,
          13,
          639,
          307,
          689,
          286,
          1409,
          13,
          1033,
          13,
          3769,
          13,
          407,
          321,
          434,
          516,
          281,
          764,
          51392
        ]
      },
      {
        "avg_logprob": -0.4673349176134382,
        "compression_ratio": 1.0476190476190477,
        "end": 3490.1200000000003,
        "id": 564,
        "no_speech_prob": 0.911050021648407,
        "seek": 346076,
        "start": 3460.76,
        "temperature": 0,
        "text": " promises and we're going to read. So import Jim. I don't know. Maybe that's right. Okay.",
        "tokens": [
          50364,
          16403,
          293,
          321,
          434,
          516,
          281,
          1401,
          13,
          407,
          974,
          6637,
          13,
          286,
          500,
          380,
          458,
          13,
          2704,
          300,
          311,
          558,
          13,
          1033,
          13,
          51832
        ]
      },
      {
        "avg_logprob": -0.4896304918372113,
        "compression_ratio": 1.04,
        "end": 3517.12,
        "id": 565,
        "no_speech_prob": 0.9727679491043091,
        "seek": 349012,
        "start": 3491.12,
        "temperature": 0,
        "text": " And then now we should be able to say let's just try this just real quick. And",
        "tokens": [
          50414,
          400,
          550,
          586,
          321,
          820,
          312,
          1075,
          281,
          584,
          718,
          311,
          445,
          853,
          341,
          445,
          957,
          1702,
          13,
          400,
          51714
        ]
      },
      {
        "avg_logprob": -0.2709966989663931,
        "compression_ratio": 1.0740740740740742,
        "end": 3546.08,
        "id": 566,
        "no_speech_prob": 0.7824751734733582,
        "seek": 351712,
        "start": 3517.12,
        "temperature": 0,
        "text": " let's see what happens here. Jim dot read is not a function. I don't know how to import",
        "tokens": [
          50364,
          718,
          311,
          536,
          437,
          2314,
          510,
          13,
          6637,
          5893,
          1401,
          307,
          406,
          257,
          2445,
          13,
          286,
          500,
          380,
          458,
          577,
          281,
          974,
          51812
        ]
      },
      {
        "avg_logprob": -0.34046843956256734,
        "compression_ratio": 1.0963855421686748,
        "end": 3569.44,
        "id": 567,
        "no_speech_prob": 0.8310967087745667,
        "seek": 354608,
        "start": 3546.08,
        "temperature": 0,
        "text": " anything. Okay. We got something. Decoders. How do I? Okay. Okay. Instead of using require.",
        "tokens": [
          50364,
          1340,
          13,
          1033,
          13,
          492,
          658,
          746,
          13,
          12427,
          378,
          433,
          13,
          1012,
          360,
          286,
          30,
          1033,
          13,
          1033,
          13,
          7156,
          295,
          1228,
          3651,
          13,
          51532
        ]
      },
      {
        "avg_logprob": -0.38295876538311996,
        "compression_ratio": 1.2835820895522387,
        "end": 3587.04,
        "id": 568,
        "no_speech_prob": 0.8823344707489014,
        "seek": 356944,
        "start": 3569.44,
        "temperature": 0,
        "text": " There we go. Just as simple as that. Okay. I over complicated it. Okay. Oh, look. It",
        "tokens": [
          50364,
          821,
          321,
          352,
          13,
          1449,
          382,
          2199,
          382,
          300,
          13,
          1033,
          13,
          286,
          670,
          6179,
          309,
          13,
          1033,
          13,
          876,
          11,
          574,
          13,
          467,
          51244
        ]
      },
      {
        "avg_logprob": -0.38295876538311996,
        "compression_ratio": 1.2835820895522387,
        "end": 3594.68,
        "id": 569,
        "no_speech_prob": 0.8823344707489014,
        "seek": 356944,
        "start": 3587.04,
        "temperature": 0,
        "text": " redrew the image. Great. Okay. So this is working. Let's go back. Boy, this stuff takes",
        "tokens": [
          51244,
          2182,
          2236,
          264,
          3256,
          13,
          3769,
          13,
          1033,
          13,
          407,
          341,
          307,
          1364,
          13,
          961,
          311,
          352,
          646,
          13,
          9486,
          11,
          341,
          1507,
          2516,
          51626
        ]
      },
      {
        "avg_logprob": -0.3164740228033685,
        "compression_ratio": 1.4766839378238341,
        "end": 3601.44,
        "id": 570,
        "no_speech_prob": 0.9755016565322876,
        "seek": 359468,
        "start": 3594.68,
        "temperature": 0,
        "text": " forever. Okay. So just to figure out where we are for a moment. And I'm going to take a short",
        "tokens": [
          50364,
          5680,
          13,
          1033,
          13,
          407,
          445,
          281,
          2573,
          484,
          689,
          321,
          366,
          337,
          257,
          1623,
          13,
          400,
          286,
          478,
          516,
          281,
          747,
          257,
          2099,
          50702
        ]
      },
      {
        "avg_logprob": -0.3164740228033685,
        "compression_ratio": 1.4766839378238341,
        "end": 3609.96,
        "id": 571,
        "no_speech_prob": 0.9755016565322876,
        "seek": 359468,
        "start": 3601.44,
        "temperature": 0,
        "text": " break in a second. Check on my daughter. And talk about curiosity stream. But this is where we are.",
        "tokens": [
          50702,
          1821,
          294,
          257,
          1150,
          13,
          6881,
          322,
          452,
          4653,
          13,
          400,
          751,
          466,
          18769,
          4309,
          13,
          583,
          341,
          307,
          689,
          321,
          366,
          13,
          51128
        ]
      },
      {
        "avg_logprob": -0.3164740228033685,
        "compression_ratio": 1.4766839378238341,
        "end": 3618.8399999999997,
        "id": 572,
        "no_speech_prob": 0.9755016565322876,
        "seek": 359468,
        "start": 3609.96,
        "temperature": 0,
        "text": " Let's see. I am currently just trying to load the image to read the pixels to put it into a",
        "tokens": [
          51128,
          961,
          311,
          536,
          13,
          286,
          669,
          4362,
          445,
          1382,
          281,
          3677,
          264,
          3256,
          281,
          1401,
          264,
          18668,
          281,
          829,
          309,
          666,
          257,
          51572
        ]
      },
      {
        "avg_logprob": -0.448581600189209,
        "compression_ratio": 1.1222222222222222,
        "end": 3636.36,
        "id": 573,
        "no_speech_prob": 0.9240598678588867,
        "seek": 361884,
        "start": 3618.84,
        "temperature": 0,
        "text": " tensor. And I'm going to say this now. And the question is, how do I? Where is the Jim documentation?",
        "tokens": [
          50364,
          40863,
          13,
          400,
          286,
          478,
          516,
          281,
          584,
          341,
          586,
          13,
          400,
          264,
          1168,
          307,
          11,
          577,
          360,
          286,
          30,
          2305,
          307,
          264,
          6637,
          14333,
          30,
          51240
        ]
      },
      {
        "avg_logprob": -0.46330754897173715,
        "compression_ratio": 1.2048192771084338,
        "end": 3648.8,
        "id": 574,
        "no_speech_prob": 0.8006139397621155,
        "seek": 363636,
        "start": 3636.36,
        "temperature": 0,
        "text": " Contained scale, auto crop, crop, blit, composite, mask, convolute, flip, pixelate, displace, clone,",
        "tokens": [
          50364,
          4839,
          3563,
          4373,
          11,
          8399,
          9086,
          11,
          9086,
          11,
          888,
          270,
          11,
          25557,
          11,
          6094,
          11,
          3754,
          401,
          1169,
          11,
          7929,
          11,
          19261,
          473,
          11,
          717,
          6742,
          11,
          26506,
          11,
          50986
        ]
      },
      {
        "avg_logprob": -0.35443856639246785,
        "compression_ratio": 1.0777777777777777,
        "end": 3667.6000000000004,
        "id": 575,
        "no_speech_prob": 0.6332983374595642,
        "seek": 364880,
        "start": 3648.8,
        "temperature": 0,
        "text": " resize. Well, I'm looking for like pixels. Okay. No. It's got to be a way to just read the pixels",
        "tokens": [
          50364,
          50069,
          13,
          1042,
          11,
          286,
          478,
          1237,
          337,
          411,
          18668,
          13,
          1033,
          13,
          883,
          13,
          467,
          311,
          658,
          281,
          312,
          257,
          636,
          281,
          445,
          1401,
          264,
          18668,
          51304
        ]
      },
      {
        "avg_logprob": -0.3830359198830344,
        "compression_ratio": 1.150943396226415,
        "end": 3695,
        "id": 576,
        "no_speech_prob": 0.7929351925849915,
        "seek": 366760,
        "start": 3667.6,
        "temperature": 0,
        "text": " directly to get the pixels as an array. Neighbor pixels. Boy, I'm making this so hard. Let's see if this gives us anything",
        "tokens": [
          50364,
          3838,
          281,
          483,
          264,
          18668,
          382,
          364,
          10225,
          13,
          47729,
          18668,
          13,
          9486,
          11,
          286,
          478,
          1455,
          341,
          370,
          1152,
          13,
          961,
          311,
          536,
          498,
          341,
          2709,
          505,
          1340,
          51734
        ]
      },
      {
        "avg_logprob": -0.3600107399193016,
        "compression_ratio": 1.1553398058252426,
        "end": 3709.2,
        "id": 577,
        "no_speech_prob": 0.8055459856987,
        "seek": 369500,
        "start": 3695,
        "temperature": 0,
        "text": " we can use. Data. All right. That's promising. There's a get base 64, get buffer, get pixel color. Well, that's kind of",
        "tokens": [
          50364,
          321,
          393,
          764,
          13,
          11888,
          13,
          1057,
          558,
          13,
          663,
          311,
          20257,
          13,
          821,
          311,
          257,
          483,
          3096,
          12145,
          11,
          483,
          21762,
          11,
          483,
          19261,
          2017,
          13,
          1042,
          11,
          300,
          311,
          733,
          295,
          51074
        ]
      },
      {
        "avg_logprob": -0.37917962755475726,
        "compression_ratio": 1.1574074074074074,
        "end": 3722.6,
        "id": 578,
        "no_speech_prob": 0.760456383228302,
        "seek": 370920,
        "start": 3709.2,
        "temperature": 0,
        "text": " useful. But I don't want to go through and get the pixel colors one at a time. Undefined. Wasn't there something called data?",
        "tokens": [
          50364,
          4420,
          13,
          583,
          286,
          500,
          380,
          528,
          281,
          352,
          807,
          293,
          483,
          264,
          19261,
          4577,
          472,
          412,
          257,
          565,
          13,
          2719,
          5666,
          2001,
          13,
          28782,
          380,
          456,
          746,
          1219,
          1412,
          30,
          51034
        ]
      },
      {
        "avg_logprob": -0.557908108359889,
        "compression_ratio": 0.9591836734693877,
        "end": 3739,
        "id": 579,
        "no_speech_prob": 0.8649969696998596,
        "seek": 372260,
        "start": 3722.6,
        "temperature": 0,
        "text": " Oh, bitmap. Bitmap. Okay. There's the raw data.",
        "tokens": [
          50364,
          876,
          11,
          857,
          24223,
          13,
          9101,
          24223,
          13,
          1033,
          13,
          821,
          311,
          264,
          8936,
          1412,
          13,
          51184
        ]
      },
      {
        "avg_logprob": -0.3149816556410356,
        "compression_ratio": 1.3070866141732282,
        "end": 3771.4,
        "id": 580,
        "no_speech_prob": 0.8331716656684875,
        "seek": 375260,
        "start": 3752.6,
        "temperature": 0,
        "text": " Let's see what this looks like. Mine must be a string. I got some weird error there. That didn't work. I can't believe how much trouble I'm having getting the pixels.",
        "tokens": [
          50364,
          961,
          311,
          536,
          437,
          341,
          1542,
          411,
          13,
          11620,
          1633,
          312,
          257,
          6798,
          13,
          286,
          658,
          512,
          3657,
          6713,
          456,
          13,
          663,
          994,
          380,
          589,
          13,
          286,
          393,
          380,
          1697,
          577,
          709,
          5253,
          286,
          478,
          1419,
          1242,
          264,
          18668,
          13,
          51304
        ]
      },
      {
        "avg_logprob": -0.3160857200622559,
        "compression_ratio": 1.025974025974026,
        "end": 3775,
        "id": 581,
        "no_speech_prob": 0.9486436247825623,
        "seek": 377140,
        "start": 3771.4,
        "temperature": 0,
        "text": " Am I really going to get the pixels one at a time? All right. Let's just do it.",
        "tokens": [
          50364,
          2012,
          286,
          534,
          516,
          281,
          483,
          264,
          18668,
          472,
          412,
          257,
          565,
          30,
          1057,
          558,
          13,
          961,
          311,
          445,
          360,
          309,
          13,
          50544
        ]
      },
      {
        "avg_logprob": -0.44947301424466646,
        "compression_ratio": 0.8421052631578947,
        "end": 3819.8,
        "id": 582,
        "no_speech_prob": 0.9319976568222046,
        "seek": 380140,
        "start": 3801.4,
        "temperature": 0,
        "text": " This is so crazy what I'm doing.",
        "tokens": [
          50364,
          639,
          307,
          370,
          3219,
          437,
          286,
          478,
          884,
          13,
          51284
        ]
      },
      {
        "avg_logprob": -0.46872262601499204,
        "compression_ratio": 0.9647058823529412,
        "end": 3841.8,
        "id": 583,
        "no_speech_prob": 0.9657738208770752,
        "seek": 381980,
        "start": 3819.8,
        "temperature": 0,
        "text": " Get pixel color. J, K. What? Oh, pixels I doesn't even mean anything. Okay. Sorry.",
        "tokens": [
          50364,
          3240,
          19261,
          2017,
          13,
          508,
          11,
          591,
          13,
          708,
          30,
          876,
          11,
          18668,
          286,
          1177,
          380,
          754,
          914,
          1340,
          13,
          1033,
          13,
          4919,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.28693732619285583,
        "compression_ratio": 1.1485148514851484,
        "end": 3869.8,
        "id": 584,
        "no_speech_prob": 0.855724036693573,
        "seek": 384980,
        "start": 3849.8,
        "temperature": 0,
        "text": " This is me reconstructing the pixel array. What are you doing? Automating things for me that I don't want you to do.",
        "tokens": [
          50364,
          639,
          307,
          385,
          31499,
          278,
          264,
          19261,
          10225,
          13,
          708,
          366,
          291,
          884,
          30,
          24619,
          990,
          721,
          337,
          385,
          300,
          286,
          500,
          380,
          528,
          291,
          281,
          360,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.4200293597053079,
        "compression_ratio": 1.1238095238095238,
        "end": 3890.8,
        "id": 585,
        "no_speech_prob": 0.9171440005302429,
        "seek": 386980,
        "start": 3869.8,
        "temperature": 0,
        "text": " This actually makes kind of sense. This bit image scan. Hey, wait. Amr is giving me something. Scan? Is that from Jim?",
        "tokens": [
          50364,
          639,
          767,
          1669,
          733,
          295,
          2020,
          13,
          639,
          857,
          3256,
          11049,
          13,
          1911,
          11,
          1699,
          13,
          2012,
          81,
          307,
          2902,
          385,
          746,
          13,
          41177,
          30,
          1119,
          300,
          490,
          6637,
          30,
          51414
        ]
      },
      {
        "avg_logprob": -0.39661550521850586,
        "compression_ratio": 1.1531531531531531,
        "end": 3915.8,
        "id": 586,
        "no_speech_prob": 0.9122552871704102,
        "seek": 389080,
        "start": 3891.8,
        "temperature": 0,
        "text": " Here's a good reference. Your URL probably won't work, Sorel. So, this is giving me probably like the integer. This bitmap data.",
        "tokens": [
          50414,
          1692,
          311,
          257,
          665,
          6408,
          13,
          2260,
          12905,
          1391,
          1582,
          380,
          589,
          11,
          407,
          4419,
          13,
          407,
          11,
          341,
          307,
          2902,
          385,
          1391,
          411,
          264,
          24922,
          13,
          639,
          857,
          24223,
          1412,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.41007767552914826,
        "compression_ratio": 0.9565217391304348,
        "end": 3922.8,
        "id": 587,
        "no_speech_prob": 0.8961355090141296,
        "seek": 391580,
        "start": 3916.8,
        "temperature": 0,
        "text": " This is in the Jim documentation. Oh, image.scan. Thank you. Okay.",
        "tokens": [
          50414,
          639,
          307,
          294,
          264,
          6637,
          14333,
          13,
          876,
          11,
          3256,
          13,
          4417,
          282,
          13,
          1044,
          291,
          13,
          1033,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.3075549409196183,
        "compression_ratio": 1.1666666666666667,
        "end": 3944.8,
        "id": 588,
        "no_speech_prob": 0.7517667412757874,
        "seek": 392280,
        "start": 3922.8,
        "temperature": 0,
        "text": " Scan. Ah, scan a region. Image bitmap data. Got it. Got it, got it, got it. Okay, okay. Let's see.",
        "tokens": [
          50364,
          41177,
          13,
          2438,
          11,
          11049,
          257,
          4458,
          13,
          29903,
          857,
          24223,
          1412,
          13,
          5803,
          309,
          13,
          5803,
          309,
          11,
          658,
          309,
          11,
          658,
          309,
          13,
          1033,
          11,
          1392,
          13,
          961,
          311,
          536,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.46700533953579987,
        "compression_ratio": 1.048780487804878,
        "end": 3954.8,
        "id": 589,
        "no_speech_prob": 0.7689899206161499,
        "seek": 394480,
        "start": 3944.8,
        "temperature": 0,
        "text": " Scan. Jim enables low images in memory through the bitmap property of each Jim object.",
        "tokens": [
          50364,
          41177,
          13,
          6637,
          17077,
          2295,
          5267,
          294,
          4675,
          807,
          264,
          857,
          24223,
          4707,
          295,
          1184,
          6637,
          2657,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.41903898932717065,
        "compression_ratio": 0.8333333333333334,
        "end": 3972.8,
        "id": 590,
        "no_speech_prob": 0.7212920784950256,
        "seek": 395480,
        "start": 3954.8,
        "temperature": 0,
        "text": " Why is the this so weird?",
        "tokens": [
          50364,
          1545,
          307,
          264,
          341,
          370,
          3657,
          30,
          51264
        ]
      },
      {
        "avg_logprob": -0.40055098357024016,
        "compression_ratio": 1.105263157894737,
        "end": 3994.8,
        "id": 591,
        "no_speech_prob": 0.7119917869567871,
        "seek": 397280,
        "start": 3972.8,
        "temperature": 0,
        "text": " Yeah. R. Jeez. This is so, this is so insane how much this is like driving me crazy.",
        "tokens": [
          50364,
          865,
          13,
          497,
          13,
          48516,
          13,
          639,
          307,
          370,
          11,
          341,
          307,
          370,
          10838,
          577,
          709,
          341,
          307,
          411,
          4840,
          385,
          3219,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.30985132217407224,
        "compression_ratio": 1.0617283950617284,
        "end": 4006.8,
        "id": 592,
        "no_speech_prob": 0.8353276252746582,
        "seek": 399480,
        "start": 3994.8,
        "temperature": 0,
        "text": " Like how much I'm getting stuck in this. This makes me want to go back to the browser.",
        "tokens": [
          50364,
          1743,
          577,
          709,
          286,
          478,
          1242,
          5541,
          294,
          341,
          13,
          639,
          1669,
          385,
          528,
          281,
          352,
          646,
          281,
          264,
          11185,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.3094440187726702,
        "compression_ratio": 1.146788990825688,
        "end": 4020.8,
        "id": 593,
        "no_speech_prob": 0.5925789475440979,
        "seek": 400680,
        "start": 4006.8,
        "temperature": 0,
        "text": " All right. Let's go for this. This is really weird, but scans a region of the bitmap and calls the function F on every pixel.",
        "tokens": [
          50364,
          1057,
          558,
          13,
          961,
          311,
          352,
          337,
          341,
          13,
          639,
          307,
          534,
          3657,
          11,
          457,
          35116,
          257,
          4458,
          295,
          264,
          857,
          24223,
          293,
          5498,
          264,
          2445,
          479,
          322,
          633,
          19261,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.3801210607801165,
        "compression_ratio": 1.0119047619047619,
        "end": 4034.8,
        "id": 594,
        "no_speech_prob": 0.6991168260574341,
        "seek": 402080,
        "start": 4020.8,
        "temperature": 0,
        "text": " But couldn't I just do this myself? Is the data, hold on a second. Bitmap data. Okay.",
        "tokens": [
          50364,
          583,
          2809,
          380,
          286,
          445,
          360,
          341,
          2059,
          30,
          1119,
          264,
          1412,
          11,
          1797,
          322,
          257,
          1150,
          13,
          9101,
          24223,
          1412,
          13,
          1033,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.3254869862606651,
        "compression_ratio": 0.9253731343283582,
        "end": 4062.8,
        "id": 595,
        "no_speech_prob": 0.7183600068092346,
        "seek": 403480,
        "start": 4034.8,
        "temperature": 0,
        "text": " Let me just try something. Let R equal image bitmap data zero.",
        "tokens": [
          50364,
          961,
          385,
          445,
          853,
          746,
          13,
          961,
          497,
          2681,
          3256,
          857,
          24223,
          1412,
          4018,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.23541596840167867,
        "compression_ratio": 1.048780487804878,
        "end": 4074.8,
        "id": 596,
        "no_speech_prob": 0.5467005372047424,
        "seek": 406280,
        "start": 4062.8,
        "temperature": 0,
        "text": " Is it just, can I operate the bitmap like an array? Ah, there we go. This was so easy.",
        "tokens": [
          50364,
          1119,
          309,
          445,
          11,
          393,
          286,
          9651,
          264,
          857,
          24223,
          411,
          364,
          10225,
          30,
          2438,
          11,
          456,
          321,
          352,
          13,
          639,
          390,
          370,
          1858,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.3435029089450836,
        "compression_ratio": 1.0113636363636365,
        "end": 4093.8,
        "id": 597,
        "no_speech_prob": 0.7400283813476562,
        "seek": 407480,
        "start": 4074.8,
        "temperature": 0,
        "text": " Ah, I'm such a dummy. Okay, okay. There we go. So now I can do, index equals zero. Index.",
        "tokens": [
          50364,
          2438,
          11,
          286,
          478,
          1270,
          257,
          35064,
          13,
          1033,
          11,
          1392,
          13,
          821,
          321,
          352,
          13,
          407,
          586,
          286,
          393,
          360,
          11,
          8186,
          6915,
          4018,
          13,
          33552,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.19735970990411167,
        "compression_ratio": 1.05,
        "end": 4115.8,
        "id": 598,
        "no_speech_prob": 0.9194238185882568,
        "seek": 409380,
        "start": 4093.8,
        "temperature": 0,
        "text": " I'm just going to, I know it's everything's 28 by 28, so I'm just hard coding it in.",
        "tokens": [
          50364,
          286,
          478,
          445,
          516,
          281,
          11,
          286,
          458,
          309,
          311,
          1203,
          311,
          7562,
          538,
          7562,
          11,
          370,
          286,
          478,
          445,
          1152,
          17720,
          309,
          294,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.42051401138305666,
        "compression_ratio": 1.2621359223300972,
        "end": 4132.8,
        "id": 599,
        "no_speech_prob": 0.9072439670562744,
        "seek": 411580,
        "start": 4115.8,
        "temperature": 0,
        "text": " I'm just going to use N and then the actual pixel, the actual index is N times four. The R is N plus zero, N plus one, N plus two.",
        "tokens": [
          50364,
          286,
          478,
          445,
          516,
          281,
          764,
          426,
          293,
          550,
          264,
          3539,
          19261,
          11,
          264,
          3539,
          8186,
          307,
          426,
          1413,
          1451,
          13,
          440,
          497,
          307,
          426,
          1804,
          4018,
          11,
          426,
          1804,
          472,
          11,
          426,
          1804,
          732,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.24430685983577244,
        "compression_ratio": 1.50920245398773,
        "end": 4149.8,
        "id": 600,
        "no_speech_prob": 0.894716739654541,
        "seek": 413280,
        "start": 4132.8,
        "temperature": 0,
        "text": " But I'm not doing an RGB image, so I can just use the R. And now if I console log R, I could just use the map function, but I'll raw date.",
        "tokens": [
          50364,
          583,
          286,
          478,
          406,
          884,
          364,
          31231,
          3256,
          11,
          370,
          286,
          393,
          445,
          764,
          264,
          497,
          13,
          400,
          586,
          498,
          286,
          11076,
          3565,
          497,
          11,
          286,
          727,
          445,
          764,
          264,
          4471,
          2445,
          11,
          457,
          286,
          603,
          8936,
          4002,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.24430685983577244,
        "compression_ratio": 1.50920245398773,
        "end": 4155.8,
        "id": 601,
        "no_speech_prob": 0.894716739654541,
        "seek": 413280,
        "start": 4149.8,
        "temperature": 0,
        "text": " I'm just going to make an array. So I could do some kind of higher order array function to just like do it.",
        "tokens": [
          51214,
          286,
          478,
          445,
          516,
          281,
          652,
          364,
          10225,
          13,
          407,
          286,
          727,
          360,
          512,
          733,
          295,
          2946,
          1668,
          10225,
          2445,
          281,
          445,
          411,
          360,
          309,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.27649725400484526,
        "compression_ratio": 1.2654867256637168,
        "end": 4165.8,
        "id": 602,
        "no_speech_prob": 0.9342918992042542,
        "seek": 415580,
        "start": 4155.8,
        "temperature": 0,
        "text": " I've got, I can basically turn the bitmap into a tensor directly, but since I've got grayscale images, it's probably what I should do actually.",
        "tokens": [
          50364,
          286,
          600,
          658,
          11,
          286,
          393,
          1936,
          1261,
          264,
          857,
          24223,
          666,
          257,
          40863,
          3838,
          11,
          457,
          1670,
          286,
          600,
          658,
          677,
          3772,
          37088,
          5267,
          11,
          309,
          311,
          1391,
          437,
          286,
          820,
          360,
          767,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.22414138399321457,
        "compression_ratio": 1.3424657534246576,
        "end": 4181.8,
        "id": 603,
        "no_speech_prob": 0.4148191511631012,
        "seek": 416580,
        "start": 4165.8,
        "temperature": 0,
        "text": " But I'm just going to say raw data, just for now, raw data N equals R. And then console log raw data.",
        "tokens": [
          50364,
          583,
          286,
          478,
          445,
          516,
          281,
          584,
          8936,
          1412,
          11,
          445,
          337,
          586,
          11,
          8936,
          1412,
          426,
          6915,
          497,
          13,
          400,
          550,
          11076,
          3565,
          8936,
          1412,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.22414138399321457,
        "compression_ratio": 1.3424657534246576,
        "end": 4192.8,
        "id": 604,
        "no_speech_prob": 0.4148191511631012,
        "seek": 416580,
        "start": 4181.8,
        "temperature": 0,
        "text": " Okay, great. So this is all of the raw grayscale values. There we go. We're getting somewhere.",
        "tokens": [
          51164,
          1033,
          11,
          869,
          13,
          407,
          341,
          307,
          439,
          295,
          264,
          8936,
          677,
          3772,
          37088,
          4190,
          13,
          821,
          321,
          352,
          13,
          492,
          434,
          1242,
          4079,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.28645457540239605,
        "compression_ratio": 1.3669064748201438,
        "end": 4202.8,
        "id": 605,
        "no_speech_prob": 0.1801028847694397,
        "seek": 419280,
        "start": 4192.8,
        "temperature": 0,
        "text": " So now, remember when I was doing this before? I, no, these are the X inputs.",
        "tokens": [
          50364,
          407,
          586,
          11,
          1604,
          562,
          286,
          390,
          884,
          341,
          949,
          30,
          286,
          11,
          572,
          11,
          613,
          366,
          264,
          1783,
          15743,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.28645457540239605,
        "compression_ratio": 1.3669064748201438,
        "end": 4218.8,
        "id": 606,
        "no_speech_prob": 0.1801028847694397,
        "seek": 419280,
        "start": 4202.8,
        "temperature": 0,
        "text": " So this generate image, we returned a function. So train model, X train, I'm just sorry, I'm a little lost here.",
        "tokens": [
          50864,
          407,
          341,
          8460,
          3256,
          11,
          321,
          8752,
          257,
          2445,
          13,
          407,
          3847,
          2316,
          11,
          1783,
          3847,
          11,
          286,
          478,
          445,
          2597,
          11,
          286,
          478,
          257,
          707,
          2731,
          510,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.24867083132266998,
        "compression_ratio": 1.1758241758241759,
        "end": 4247.8,
        "id": 607,
        "no_speech_prob": 0.724780261516571,
        "seek": 421880,
        "start": 4218.8,
        "temperature": 0,
        "text": " Okay, so X inputs. So loading all the images, we have X inputs. And then X inputs index I is that raw data.",
        "tokens": [
          50364,
          1033,
          11,
          370,
          1783,
          15743,
          13,
          407,
          15114,
          439,
          264,
          5267,
          11,
          321,
          362,
          1783,
          15743,
          13,
          400,
          550,
          1783,
          15743,
          8186,
          286,
          307,
          300,
          8936,
          1412,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.2604642105102539,
        "compression_ratio": 1.4057971014492754,
        "end": 4256.8,
        "id": 608,
        "no_speech_prob": 0.4532202184200287,
        "seek": 424780,
        "start": 4247.8,
        "temperature": 0,
        "text": " So basically, I'm loading every single image into an array and then putting it in my X inputs array because,",
        "tokens": [
          50364,
          407,
          1936,
          11,
          286,
          478,
          15114,
          633,
          2167,
          3256,
          666,
          364,
          10225,
          293,
          550,
          3372,
          309,
          294,
          452,
          1783,
          15743,
          10225,
          570,
          11,
          50814
        ]
      },
      {
        "avg_logprob": -0.2604642105102539,
        "compression_ratio": 1.4057971014492754,
        "end": 4263.8,
        "id": 609,
        "no_speech_prob": 0.4532202184200287,
        "seek": 424780,
        "start": 4256.8,
        "temperature": 0,
        "text": " and I can take all this other stuff out because, and let's get rid of the random one.",
        "tokens": [
          50814,
          293,
          286,
          393,
          747,
          439,
          341,
          661,
          1507,
          484,
          570,
          11,
          293,
          718,
          311,
          483,
          3973,
          295,
          264,
          4974,
          472,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.23707143465677896,
        "compression_ratio": 1.4206349206349207,
        "end": 4268.8,
        "id": 610,
        "no_speech_prob": 0.7089350819587708,
        "seek": 426380,
        "start": 4264.8,
        "temperature": 0,
        "text": " Because when it's time to train the, get the training data.",
        "tokens": [
          50414,
          1436,
          562,
          309,
          311,
          565,
          281,
          3847,
          264,
          11,
          483,
          264,
          3097,
          1412,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.23707143465677896,
        "compression_ratio": 1.4206349206349207,
        "end": 4285.8,
        "id": 611,
        "no_speech_prob": 0.7089350819587708,
        "seek": 426380,
        "start": 4275.8,
        "temperature": 0,
        "text": " So this, I need a curly bracket there to close this out. Then the training data is a tensor out of all of these images.",
        "tokens": [
          50964,
          407,
          341,
          11,
          286,
          643,
          257,
          32066,
          16904,
          456,
          281,
          1998,
          341,
          484,
          13,
          1396,
          264,
          3097,
          1412,
          307,
          257,
          40863,
          484,
          295,
          439,
          295,
          613,
          5267,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.19754614653410735,
        "compression_ratio": 1.439153439153439,
        "end": 4289.8,
        "id": 612,
        "no_speech_prob": 0.11756565421819687,
        "seek": 428580,
        "start": 4285.8,
        "temperature": 0,
        "text": " And then I'm not going to call train model just yet, but let's sort of see.",
        "tokens": [
          50364,
          400,
          550,
          286,
          478,
          406,
          516,
          281,
          818,
          3847,
          2316,
          445,
          1939,
          11,
          457,
          718,
          311,
          1333,
          295,
          536,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.19754614653410735,
        "compression_ratio": 1.439153439153439,
        "end": 4299.8,
        "id": 613,
        "no_speech_prob": 0.11756565421819687,
        "seek": 428580,
        "start": 4291.8,
        "temperature": 0,
        "text": " I is not found. Why is I not found? Oh, right, because this does need to be in here. There we go.",
        "tokens": [
          50664,
          286,
          307,
          406,
          1352,
          13,
          1545,
          307,
          286,
          406,
          1352,
          30,
          876,
          11,
          558,
          11,
          570,
          341,
          775,
          643,
          281,
          312,
          294,
          510,
          13,
          821,
          321,
          352,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.19754614653410735,
        "compression_ratio": 1.439153439153439,
        "end": 4309.8,
        "id": 614,
        "no_speech_prob": 0.11756565421819687,
        "seek": 428580,
        "start": 4300.8,
        "temperature": 0,
        "text": " Okay, so now that's one image as a tensor. So now I can actually go ahead and load all 100 images.",
        "tokens": [
          51114,
          1033,
          11,
          370,
          586,
          300,
          311,
          472,
          3256,
          382,
          257,
          40863,
          13,
          407,
          586,
          286,
          393,
          767,
          352,
          2286,
          293,
          3677,
          439,
          2319,
          5267,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.19888458695522573,
        "compression_ratio": 1.5570776255707763,
        "end": 4320.8,
        "id": 615,
        "no_speech_prob": 0.10818444192409515,
        "seek": 430980,
        "start": 4309.8,
        "temperature": 0,
        "text": " Okay, I loaded 100 images into those tensors. By the way, the reason why you're seeing 255 everywhere is those images are all white around the edges.",
        "tokens": [
          50364,
          1033,
          11,
          286,
          13210,
          2319,
          5267,
          666,
          729,
          10688,
          830,
          13,
          3146,
          264,
          636,
          11,
          264,
          1778,
          983,
          291,
          434,
          2577,
          3552,
          20,
          5315,
          307,
          729,
          5267,
          366,
          439,
          2418,
          926,
          264,
          8819,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.19888458695522573,
        "compression_ratio": 1.5570776255707763,
        "end": 4327.8,
        "id": 616,
        "no_speech_prob": 0.10818444192409515,
        "seek": 430980,
        "start": 4320.8,
        "temperature": 0,
        "text": " And all of the data that wouldn't be 255 should be dot dot dot. Yeah, I need to refactor this stuff.",
        "tokens": [
          50914,
          400,
          439,
          295,
          264,
          1412,
          300,
          2759,
          380,
          312,
          3552,
          20,
          820,
          312,
          5893,
          5893,
          5893,
          13,
          865,
          11,
          286,
          643,
          281,
          1895,
          15104,
          341,
          1507,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.19888458695522573,
        "compression_ratio": 1.5570776255707763,
        "end": 4331.8,
        "id": 617,
        "no_speech_prob": 0.10818444192409515,
        "seek": 430980,
        "start": 4327.8,
        "temperature": 0,
        "text": " Chris is saying you should make getting the raw data into a separate function. Absolutely.",
        "tokens": [
          51264,
          6688,
          307,
          1566,
          291,
          820,
          652,
          1242,
          264,
          8936,
          1412,
          666,
          257,
          4994,
          2445,
          13,
          7021,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.24148062211048754,
        "compression_ratio": 1.4187192118226601,
        "end": 4338.8,
        "id": 618,
        "no_speech_prob": 0.19435326755046844,
        "seek": 433180,
        "start": 4331.8,
        "temperature": 0,
        "text": " So I will refactor this later. But now I should be able to say await train model.",
        "tokens": [
          50364,
          407,
          286,
          486,
          1895,
          15104,
          341,
          1780,
          13,
          583,
          586,
          286,
          820,
          312,
          1075,
          281,
          584,
          19670,
          3847,
          2316,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.24148062211048754,
        "compression_ratio": 1.4187192118226601,
        "end": 4342.8,
        "id": 619,
        "no_speech_prob": 0.19435326755046844,
        "seek": 433180,
        "start": 4340.8,
        "temperature": 0,
        "text": " And let's see what happens here.",
        "tokens": [
          50814,
          400,
          718,
          311,
          536,
          437,
          2314,
          510,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.24148062211048754,
        "compression_ratio": 1.4187192118226601,
        "end": 4353.8,
        "id": 620,
        "no_speech_prob": 0.19435326755046844,
        "seek": 433180,
        "start": 4345.8,
        "temperature": 0,
        "text": " X train is not defined. Oh, because I made that those global. Okay, well, here.",
        "tokens": [
          51064,
          1783,
          3847,
          307,
          406,
          7642,
          13,
          876,
          11,
          570,
          286,
          1027,
          300,
          729,
          4338,
          13,
          1033,
          11,
          731,
          11,
          510,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.24148062211048754,
        "compression_ratio": 1.4187192118226601,
        "end": 4358.8,
        "id": 621,
        "no_speech_prob": 0.19435326755046844,
        "seek": 433180,
        "start": 4354.8,
        "temperature": 0,
        "text": " I'm going to just be very silly, but I need to rethink how all these functions are organized.",
        "tokens": [
          51514,
          286,
          478,
          516,
          281,
          445,
          312,
          588,
          11774,
          11,
          457,
          286,
          643,
          281,
          34595,
          577,
          439,
          613,
          6828,
          366,
          9983,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.2752568044780213,
        "compression_ratio": 1.6652173913043478,
        "end": 4368.8,
        "id": 622,
        "no_speech_prob": 0.08509616553783417,
        "seek": 436180,
        "start": 4362.8,
        "temperature": 0,
        "text": " Remember, this is something I talked about last time. This is very weird.",
        "tokens": [
          50414,
          5459,
          11,
          341,
          307,
          746,
          286,
          2825,
          466,
          1036,
          565,
          13,
          639,
          307,
          588,
          3657,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.2752568044780213,
        "compression_ratio": 1.6652173913043478,
        "end": 4387.8,
        "id": 623,
        "no_speech_prob": 0.08509616553783417,
        "seek": 436180,
        "start": 4368.8,
        "temperature": 0,
        "text": " Why are my inputs and my outputs the training data? This is unique to this auto encoder problem where instead of like an image classification problem where I would have a whole bunch of images paired with their target labels, those images, the training, the correct output for each image is that image itself.",
        "tokens": [
          50714,
          1545,
          366,
          452,
          15743,
          293,
          452,
          23930,
          264,
          3097,
          1412,
          30,
          639,
          307,
          3845,
          281,
          341,
          8399,
          2058,
          19866,
          1154,
          689,
          2602,
          295,
          411,
          364,
          3256,
          21538,
          1154,
          689,
          286,
          576,
          362,
          257,
          1379,
          3840,
          295,
          5267,
          25699,
          365,
          641,
          3779,
          16949,
          11,
          729,
          5267,
          11,
          264,
          3097,
          11,
          264,
          3006,
          5598,
          337,
          1184,
          3256,
          307,
          300,
          3256,
          2564,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.20034298998244265,
        "compression_ratio": 1.2035398230088497,
        "end": 4393.8,
        "id": 624,
        "no_speech_prob": 0.14413902163505554,
        "seek": 439180,
        "start": 4391.8,
        "temperature": 0,
        "text": " Let me come over here.",
        "tokens": [
          50364,
          961,
          385,
          808,
          670,
          510,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.20034298998244265,
        "compression_ratio": 1.2035398230088497,
        "end": 4395.8,
        "id": 625,
        "no_speech_prob": 0.14413902163505554,
        "seek": 439180,
        "start": 4394.8,
        "temperature": 0,
        "text": " And.",
        "tokens": [
          50514,
          400,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.20034298998244265,
        "compression_ratio": 1.2035398230088497,
        "end": 4404.8,
        "id": 626,
        "no_speech_prob": 0.14413902163505554,
        "seek": 439180,
        "start": 4402.8,
        "temperature": 0,
        "text": " So something happened.",
        "tokens": [
          50914,
          407,
          746,
          2011,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.20034298998244265,
        "compression_ratio": 1.2035398230088497,
        "end": 4407.8,
        "id": 627,
        "no_speech_prob": 0.14413902163505554,
        "seek": 439180,
        "start": 4405.8,
        "temperature": 0,
        "text": " I don't get what this loss is.",
        "tokens": [
          51064,
          286,
          500,
          380,
          483,
          437,
          341,
          4470,
          307,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.20034298998244265,
        "compression_ratio": 1.2035398230088497,
        "end": 4412.8,
        "id": 628,
        "no_speech_prob": 0.14413902163505554,
        "seek": 439180,
        "start": 4409.8,
        "temperature": 0,
        "text": " It's a negative number. I'm a little confused by that.",
        "tokens": [
          51264,
          467,
          311,
          257,
          3671,
          1230,
          13,
          286,
          478,
          257,
          707,
          9019,
          538,
          300,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.17738097054617746,
        "compression_ratio": 1.5706521739130435,
        "end": 4424.8,
        "id": 629,
        "no_speech_prob": 0.5773953795433044,
        "seek": 441280,
        "start": 4413.8,
        "temperature": 0,
        "text": " But this is also so few images, so I think I'm at a good place where now I can just take a short break. I'm going to turn the heat on for a little bit to warm it up in here.",
        "tokens": [
          50414,
          583,
          341,
          307,
          611,
          370,
          1326,
          5267,
          11,
          370,
          286,
          519,
          286,
          478,
          412,
          257,
          665,
          1081,
          689,
          586,
          286,
          393,
          445,
          747,
          257,
          2099,
          1821,
          13,
          286,
          478,
          516,
          281,
          1261,
          264,
          3738,
          322,
          337,
          257,
          707,
          857,
          281,
          4561,
          309,
          493,
          294,
          510,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.17738097054617746,
        "compression_ratio": 1.5706521739130435,
        "end": 4430.8,
        "id": 630,
        "no_speech_prob": 0.5773953795433044,
        "seek": 441280,
        "start": 4426.8,
        "temperature": 0,
        "text": " And so the things that I need to do after I take this short break are.",
        "tokens": [
          51064,
          400,
          370,
          264,
          721,
          300,
          286,
          643,
          281,
          360,
          934,
          286,
          747,
          341,
          2099,
          1821,
          366,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.17738097054617746,
        "compression_ratio": 1.5706521739130435,
        "end": 4433.8,
        "id": 631,
        "no_speech_prob": 0.5773953795433044,
        "seek": 441280,
        "start": 4431.8,
        "temperature": 0,
        "text": " Let me make more images.",
        "tokens": [
          51314,
          961,
          385,
          652,
          544,
          5267,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.17738097054617746,
        "compression_ratio": 1.5706521739130435,
        "end": 4437.8,
        "id": 632,
        "no_speech_prob": 0.5773953795433044,
        "seek": 441280,
        "start": 4435.8,
        "temperature": 0,
        "text": " Let me think about.",
        "tokens": [
          51514,
          961,
          385,
          519,
          466,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.24717914098980784,
        "compression_ratio": 1.543778801843318,
        "end": 4442.8,
        "id": 633,
        "no_speech_prob": 0.15201300382614136,
        "seek": 443780,
        "start": 4438.8,
        "temperature": 0,
        "text": " The hyper parameters and configuration of this network.",
        "tokens": [
          50414,
          440,
          9848,
          9834,
          293,
          11694,
          295,
          341,
          3209,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.24717914098980784,
        "compression_ratio": 1.543778801843318,
        "end": 4449.8,
        "id": 634,
        "no_speech_prob": 0.15201300382614136,
        "seek": 443780,
        "start": 4443.8,
        "temperature": 0,
        "text": " Like if I just like right now, if I just change this to the encoder having 784 units.",
        "tokens": [
          50664,
          1743,
          498,
          286,
          445,
          411,
          558,
          586,
          11,
          498,
          286,
          445,
          1319,
          341,
          281,
          264,
          2058,
          19866,
          1419,
          1614,
          25494,
          6815,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.24717914098980784,
        "compression_ratio": 1.543778801843318,
        "end": 4456.8,
        "id": 635,
        "no_speech_prob": 0.15201300382614136,
        "seek": 443780,
        "start": 4453.8,
        "temperature": 0,
        "text": " Interesting, I wonder I need to think about the learning rate.",
        "tokens": [
          51164,
          14711,
          11,
          286,
          2441,
          286,
          643,
          281,
          519,
          466,
          264,
          2539,
          3314,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.24717914098980784,
        "compression_ratio": 1.543778801843318,
        "end": 4464.8,
        "id": 636,
        "no_speech_prob": 0.15201300382614136,
        "seek": 443780,
        "start": 4457.8,
        "temperature": 0,
        "text": " The loss. I don't know what's going on here. Exactly. I need to rethink the hyper parameters, normalize the data. Thank you, Aman.",
        "tokens": [
          51364,
          440,
          4470,
          13,
          286,
          500,
          380,
          458,
          437,
          311,
          516,
          322,
          510,
          13,
          7587,
          13,
          286,
          643,
          281,
          34595,
          264,
          9848,
          9834,
          11,
          2710,
          1125,
          264,
          1412,
          13,
          1044,
          291,
          11,
          35466,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.2329129507375318,
        "compression_ratio": 1.4615384615384615,
        "end": 4468.8,
        "id": 637,
        "no_speech_prob": 0.0015978122828528285,
        "seek": 446480,
        "start": 4464.8,
        "temperature": 0,
        "text": " Why did I forget? Why did I forget that? Thank you.",
        "tokens": [
          50364,
          1545,
          630,
          286,
          2870,
          30,
          1545,
          630,
          286,
          2870,
          300,
          30,
          1044,
          291,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.2329129507375318,
        "compression_ratio": 1.4615384615384615,
        "end": 4471.8,
        "id": 638,
        "no_speech_prob": 0.0015978122828528285,
        "seek": 446480,
        "start": 4469.8,
        "temperature": 0,
        "text": " Let me do that quickly.",
        "tokens": [
          50614,
          961,
          385,
          360,
          300,
          2661,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.2329129507375318,
        "compression_ratio": 1.4615384615384615,
        "end": 4473.8,
        "id": 639,
        "no_speech_prob": 0.0015978122828528285,
        "seek": 446480,
        "start": 4472.8,
        "temperature": 0,
        "text": " So important.",
        "tokens": [
          50764,
          407,
          1021,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.2329129507375318,
        "compression_ratio": 1.4615384615384615,
        "end": 4480.8,
        "id": 640,
        "no_speech_prob": 0.0015978122828528285,
        "seek": 446480,
        "start": 4476.8,
        "temperature": 0,
        "text": " I forgot to normalize the data. No wonder it's like exploding.",
        "tokens": [
          50964,
          286,
          5298,
          281,
          2710,
          1125,
          264,
          1412,
          13,
          883,
          2441,
          309,
          311,
          411,
          35175,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.2329129507375318,
        "compression_ratio": 1.4615384615384615,
        "end": 4485.8,
        "id": 641,
        "no_speech_prob": 0.0015978122828528285,
        "seek": 446480,
        "start": 4482.8,
        "temperature": 0,
        "text": " There we go. OK, we're getting somewhere.",
        "tokens": [
          51264,
          821,
          321,
          352,
          13,
          2264,
          11,
          321,
          434,
          1242,
          4079,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.2329129507375318,
        "compression_ratio": 1.4615384615384615,
        "end": 4492.8,
        "id": 642,
        "no_speech_prob": 0.0015978122828528285,
        "seek": 446480,
        "start": 4486.8,
        "temperature": 0,
        "text": " The loss is like a number that makes sense. Now it started with.683 went all the way down.",
        "tokens": [
          51464,
          440,
          4470,
          307,
          411,
          257,
          1230,
          300,
          1669,
          2020,
          13,
          823,
          309,
          1409,
          365,
          2411,
          27102,
          18,
          1437,
          439,
          264,
          636,
          760,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.35903751957523933,
        "compression_ratio": 1.548936170212766,
        "end": 4495.8,
        "id": 643,
        "no_speech_prob": 0.039043400436639786,
        "seek": 449280,
        "start": 4492.8,
        "temperature": 0,
        "text": " To.1 I could try more epochs, but I'm going to get more data.",
        "tokens": [
          50364,
          1407,
          2411,
          16,
          286,
          727,
          853,
          544,
          30992,
          28346,
          11,
          457,
          286,
          478,
          516,
          281,
          483,
          544,
          1412,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.35903751957523933,
        "compression_ratio": 1.548936170212766,
        "end": 4497.8,
        "id": 644,
        "no_speech_prob": 0.039043400436639786,
        "seek": 449280,
        "start": 4496.8,
        "temperature": 0,
        "text": " I'm going to.",
        "tokens": [
          50564,
          286,
          478,
          516,
          281,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.35903751957523933,
        "compression_ratio": 1.548936170212766,
        "end": 4500.8,
        "id": 645,
        "no_speech_prob": 0.039043400436639786,
        "seek": 449280,
        "start": 4499.8,
        "temperature": 0,
        "text": " You know.",
        "tokens": [
          50714,
          509,
          458,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.35903751957523933,
        "compression_ratio": 1.548936170212766,
        "end": 4505.8,
        "id": 646,
        "no_speech_prob": 0.039043400436639786,
        "seek": 449280,
        "start": 4501.8,
        "temperature": 0,
        "text": " Just I should be able to get a loss of zero essentially if I have 700.",
        "tokens": [
          50814,
          1449,
          286,
          820,
          312,
          1075,
          281,
          483,
          257,
          4470,
          295,
          4018,
          4476,
          498,
          286,
          362,
          15204,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.35903751957523933,
        "compression_ratio": 1.548936170212766,
        "end": 4514.8,
        "id": 647,
        "no_speech_prob": 0.039043400436639786,
        "seek": 449280,
        "start": 4507.8,
        "temperature": 0,
        "text": " Yeah, look at this. Look at that. Oh, the loss is going to be of course they've defeated the purpose by not actually compressing the data.",
        "tokens": [
          51114,
          865,
          11,
          574,
          412,
          341,
          13,
          2053,
          412,
          300,
          13,
          876,
          11,
          264,
          4470,
          307,
          516,
          281,
          312,
          295,
          1164,
          436,
          600,
          15563,
          264,
          4334,
          538,
          406,
          767,
          14778,
          278,
          264,
          1412,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.35903751957523933,
        "compression_ratio": 1.548936170212766,
        "end": 4517.8,
        "id": 648,
        "no_speech_prob": 0.039043400436639786,
        "seek": 449280,
        "start": 4514.8,
        "temperature": 0,
        "text": " But OK, warming up the hand. That's what I'm about to do. All right.",
        "tokens": [
          51464,
          583,
          2264,
          11,
          17983,
          493,
          264,
          1011,
          13,
          663,
          311,
          437,
          286,
          478,
          466,
          281,
          360,
          13,
          1057,
          558,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.3067179943652863,
        "compression_ratio": 1.5598290598290598,
        "end": 4520.8,
        "id": 649,
        "no_speech_prob": 0.1276426762342453,
        "seek": 451780,
        "start": 4517.8,
        "temperature": 0,
        "text": " OK, everybody. I'm really close now.",
        "tokens": [
          50364,
          2264,
          11,
          2201,
          13,
          286,
          478,
          534,
          1998,
          586,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.3067179943652863,
        "compression_ratio": 1.5598290598290598,
        "end": 4526.8,
        "id": 650,
        "no_speech_prob": 0.1276426762342453,
        "seek": 451780,
        "start": 4521.8,
        "temperature": 0,
        "text": " This was a lot, a lot of time that I spent like trying to just figure out how to load the images.",
        "tokens": [
          50564,
          639,
          390,
          257,
          688,
          11,
          257,
          688,
          295,
          565,
          300,
          286,
          4418,
          411,
          1382,
          281,
          445,
          2573,
          484,
          577,
          281,
          3677,
          264,
          5267,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.3067179943652863,
        "compression_ratio": 1.5598290598290598,
        "end": 4531.8,
        "id": 651,
        "no_speech_prob": 0.1276426762342453,
        "seek": 451780,
        "start": 4526.8,
        "temperature": 0,
        "text": " Sorry for all of those kind of strange tangents and different libraries.",
        "tokens": [
          50814,
          4919,
          337,
          439,
          295,
          729,
          733,
          295,
          5861,
          10266,
          791,
          293,
          819,
          15148,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.3067179943652863,
        "compression_ratio": 1.5598290598290598,
        "end": 4533.8,
        "id": 652,
        "no_speech_prob": 0.1276426762342453,
        "seek": 451780,
        "start": 4531.8,
        "temperature": 0,
        "text": " This is still kind of awkward and weird.",
        "tokens": [
          51064,
          639,
          307,
          920,
          733,
          295,
          11411,
          293,
          3657,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.3067179943652863,
        "compression_ratio": 1.5598290598290598,
        "end": 4541.8,
        "id": 653,
        "no_speech_prob": 0.1276426762342453,
        "seek": 451780,
        "start": 4534.8,
        "temperature": 0,
        "text": " But the fact that the data can be read from the file with Jim and then the actual pixel information is just so cool.",
        "tokens": [
          51214,
          583,
          264,
          1186,
          300,
          264,
          1412,
          393,
          312,
          1401,
          490,
          264,
          3991,
          365,
          6637,
          293,
          550,
          264,
          3539,
          19261,
          1589,
          307,
          445,
          370,
          1627,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.7817030513987822,
        "compression_ratio": 1.5944055944055944,
        "end": 4542.8,
        "id": 654,
        "no_speech_prob": 0.4493061304092407,
        "seek": 454180,
        "start": 4541.8,
        "temperature": 0.2,
        "text": " OK, so.",
        "tokens": [
          50364,
          2264,
          11,
          370,
          13,
          50414
        ]
      },
      {
        "avg_logprob": -0.7817030513987822,
        "compression_ratio": 1.5944055944055944,
        "end": 4550.8,
        "id": 655,
        "no_speech_prob": 0.4493061304092407,
        "seek": 454180,
        "start": 4544.8,
        "temperature": 0.2,
        "text": " I want to take a break for a minute before I take my break. Let me thank today's sponsor.",
        "tokens": [
          50514,
          286,
          528,
          281,
          747,
          257,
          1821,
          337,
          257,
          3456,
          949,
          286,
          747,
          452,
          1821,
          13,
          961,
          385,
          1309,
          965,
          311,
          16198,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.7817030513987822,
        "compression_ratio": 1.5944055944055944,
        "end": 4558.8,
        "id": 656,
        "no_speech_prob": 0.4493061304092407,
        "seek": 454180,
        "start": 4551.8,
        "temperature": 0.2,
        "text": " The sponsor of this is a sponsor is curiosity stream and it's a great way to get your data.",
        "tokens": [
          50864,
          440,
          16198,
          295,
          341,
          307,
          257,
          16198,
          307,
          18769,
          4309,
          293,
          309,
          311,
          257,
          869,
          636,
          281,
          483,
          428,
          1412,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.7817030513987822,
        "compression_ratio": 1.5944055944055944,
        "end": 4560.8,
        "id": 657,
        "no_speech_prob": 0.4493061304092407,
        "seek": 454180,
        "start": 4558.8,
        "temperature": 0.2,
        "text": " And it's a great way to get your data.",
        "tokens": [
          51214,
          400,
          309,
          311,
          257,
          869,
          636,
          281,
          483,
          428,
          1412,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.31989466489016355,
        "compression_ratio": 1.7085201793721974,
        "end": 4566.8,
        "id": 658,
        "no_speech_prob": 0.7928341627120972,
        "seek": 456080,
        "start": 4561.8,
        "temperature": 0.4,
        "text": " And I some of you probably weren't here at the beginning of the live stream where I showed this to you.",
        "tokens": [
          50414,
          400,
          286,
          512,
          295,
          291,
          1391,
          4999,
          380,
          510,
          412,
          264,
          2863,
          295,
          264,
          1621,
          4309,
          689,
          286,
          4712,
          341,
          281,
          291,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.31989466489016355,
        "compression_ratio": 1.7085201793721974,
        "end": 4574.8,
        "id": 659,
        "no_speech_prob": 0.7928341627120972,
        "seek": 456080,
        "start": 4566.8,
        "temperature": 0.4,
        "text": " So curiosity stream. I'm just going to quickly play this brief ad for you from curiosity stream directly so you can learn all about what curiosity stream is.",
        "tokens": [
          50664,
          407,
          18769,
          4309,
          13,
          286,
          478,
          445,
          516,
          281,
          2661,
          862,
          341,
          5353,
          614,
          337,
          291,
          490,
          18769,
          4309,
          3838,
          370,
          291,
          393,
          1466,
          439,
          466,
          437,
          18769,
          4309,
          307,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.31989466489016355,
        "compression_ratio": 1.7085201793721974,
        "end": 4581.8,
        "id": 660,
        "no_speech_prob": 0.7928341627120972,
        "seek": 456080,
        "start": 4574.8,
        "temperature": 0.4,
        "text": " But don't go away. Because after I play this, I'm going to talk to you about why you should sign up through my website.",
        "tokens": [
          51064,
          583,
          500,
          380,
          352,
          1314,
          13,
          1436,
          934,
          286,
          862,
          341,
          11,
          286,
          478,
          516,
          281,
          751,
          281,
          291,
          466,
          983,
          291,
          820,
          1465,
          493,
          807,
          452,
          3144,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.3376178958199241,
        "compression_ratio": 1.077922077922078,
        "end": 4613.8,
        "id": 661,
        "no_speech_prob": 0.9093145132064819,
        "seek": 461180,
        "start": 4611.8,
        "temperature": 0,
        "text": " The award winning original series.",
        "tokens": [
          50364,
          440,
          7130,
          8224,
          3380,
          2638,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.3376178958199241,
        "compression_ratio": 1.077922077922078,
        "end": 4619.8,
        "id": 662,
        "no_speech_prob": 0.9093145132064819,
        "seek": 461180,
        "start": 4618.8,
        "temperature": 0,
        "text": " Follow your curiosity.",
        "tokens": [
          50714,
          9876,
          428,
          18769,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.3376178958199241,
        "compression_ratio": 1.077922077922078,
        "end": 4625.8,
        "id": 663,
        "no_speech_prob": 0.9093145132064819,
        "seek": 461180,
        "start": 4623.8,
        "temperature": 0,
        "text": " This is curiosity stream.",
        "tokens": [
          50964,
          639,
          307,
          18769,
          4309,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.8877235412597656,
        "compression_ratio": 0.3333333333333333,
        "end": 4643.8,
        "id": 664,
        "no_speech_prob": 0.8620855808258057,
        "seek": 464180,
        "start": 4641.8,
        "temperature": 0,
        "text": " You.",
        "tokens": [
          50414,
          509,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.33223779384906477,
        "compression_ratio": 1.5714285714285714,
        "end": 4673.8,
        "id": 665,
        "no_speech_prob": 0.4763196110725403,
        "seek": 467180,
        "start": 4672.8,
        "temperature": 0,
        "text": " Oh, I'm really.",
        "tokens": [
          50414,
          876,
          11,
          286,
          478,
          534,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.33223779384906477,
        "compression_ratio": 1.5714285714285714,
        "end": 4676.8,
        "id": 666,
        "no_speech_prob": 0.4763196110725403,
        "seek": 467180,
        "start": 4674.8,
        "temperature": 0,
        "text": " I'm so getting fired.",
        "tokens": [
          50514,
          286,
          478,
          370,
          1242,
          11777,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.33223779384906477,
        "compression_ratio": 1.5714285714285714,
        "end": 4682.8,
        "id": 667,
        "no_speech_prob": 0.4763196110725403,
        "seek": 467180,
        "start": 4678.8,
        "temperature": 0,
        "text": " I know. OK, so I'm talking to it. So at least that.",
        "tokens": [
          50714,
          286,
          458,
          13,
          2264,
          11,
          370,
          286,
          478,
          1417,
          281,
          309,
          13,
          407,
          412,
          1935,
          300,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.33223779384906477,
        "compression_ratio": 1.5714285714285714,
        "end": 4692.8,
        "id": 668,
        "no_speech_prob": 0.4763196110725403,
        "seek": 467180,
        "start": 4683.8,
        "temperature": 0,
        "text": " Start over. Start over. I'm exit exit stage right. Coming back. Don't make don't make don't don't everybody sign up. So don't get fired. OK.",
        "tokens": [
          50964,
          6481,
          670,
          13,
          6481,
          670,
          13,
          286,
          478,
          11043,
          11043,
          3233,
          558,
          13,
          12473,
          646,
          13,
          1468,
          380,
          652,
          500,
          380,
          652,
          500,
          380,
          500,
          380,
          2201,
          1465,
          493,
          13,
          407,
          500,
          380,
          483,
          11777,
          13,
          2264,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.33223779384906477,
        "compression_ratio": 1.5714285714285714,
        "end": 4700.8,
        "id": 669,
        "no_speech_prob": 0.4763196110725403,
        "seek": 467180,
        "start": 4692.8,
        "temperature": 0,
        "text": " Hello, everyone. You just saw that wonderful 30 second promo about curiosity stream, which is one of my favorite streaming services.",
        "tokens": [
          51414,
          2425,
          11,
          1518,
          13,
          509,
          445,
          1866,
          300,
          3715,
          2217,
          1150,
          26750,
          466,
          18769,
          4309,
          11,
          597,
          307,
          472,
          295,
          452,
          2954,
          11791,
          3328,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.21967962265014648,
        "compression_ratio": 1.590717299578059,
        "end": 4705.8,
        "id": 670,
        "no_speech_prob": 0.18471279740333557,
        "seek": 470080,
        "start": 4700.8,
        "temperature": 0,
        "text": " Because it is chock full of so many wonderful educational documentaries.",
        "tokens": [
          50364,
          1436,
          309,
          307,
          417,
          1560,
          1577,
          295,
          370,
          867,
          3715,
          10189,
          41630,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.21967962265014648,
        "compression_ratio": 1.590717299578059,
        "end": 4708.8,
        "id": 671,
        "no_speech_prob": 0.18471279740333557,
        "seek": 470080,
        "start": 4705.8,
        "temperature": 0,
        "text": " The things that I like to watch the most is all the nature stuff.",
        "tokens": [
          50614,
          440,
          721,
          300,
          286,
          411,
          281,
          1159,
          264,
          881,
          307,
          439,
          264,
          3687,
          1507,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.21967962265014648,
        "compression_ratio": 1.590717299578059,
        "end": 4715.8,
        "id": 672,
        "no_speech_prob": 0.18471279740333557,
        "seek": 470080,
        "start": 4709.8,
        "temperature": 0,
        "text": " So we can see here just realm of the Volga. Whoa. The Volga flows 2000 miles.",
        "tokens": [
          50814,
          407,
          321,
          393,
          536,
          510,
          445,
          15355,
          295,
          264,
          8911,
          3680,
          13,
          7521,
          13,
          440,
          8911,
          3680,
          12867,
          8132,
          6193,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.21967962265014648,
        "compression_ratio": 1.590717299578059,
        "end": 4717.8,
        "id": 673,
        "no_speech_prob": 0.18471279740333557,
        "seek": 470080,
        "start": 4715.8,
        "temperature": 0,
        "text": " Oh, I've got to check this one out.",
        "tokens": [
          51114,
          876,
          11,
          286,
          600,
          658,
          281,
          1520,
          341,
          472,
          484,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.21967962265014648,
        "compression_ratio": 1.590717299578059,
        "end": 4724.8,
        "id": 674,
        "no_speech_prob": 0.18471279740333557,
        "seek": 470080,
        "start": 4718.8,
        "temperature": 0,
        "text": " I was just saying that one of the ones that I have watched with my kids that I really love, which was under here under kids.",
        "tokens": [
          51264,
          286,
          390,
          445,
          1566,
          300,
          472,
          295,
          264,
          2306,
          300,
          286,
          362,
          6337,
          365,
          452,
          2301,
          300,
          286,
          534,
          959,
          11,
          597,
          390,
          833,
          510,
          833,
          2301,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.26802845215529536,
        "compression_ratio": 1.456221198156682,
        "end": 4733.8,
        "id": 675,
        "no_speech_prob": 0.3310494124889374,
        "seek": 472480,
        "start": 4724.8,
        "temperature": 0,
        "text": " It's ancient earth, which is all about life that existed in the Permian, Triassic and Cretaceous periods.",
        "tokens": [
          50364,
          467,
          311,
          7832,
          4120,
          11,
          597,
          307,
          439,
          466,
          993,
          300,
          13135,
          294,
          264,
          41006,
          952,
          11,
          10931,
          35685,
          293,
          383,
          1505,
          617,
          563,
          13804,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.26802845215529536,
        "compression_ratio": 1.456221198156682,
        "end": 4738.8,
        "id": 676,
        "no_speech_prob": 0.3310494124889374,
        "seek": 472480,
        "start": 4733.8,
        "temperature": 0,
        "text": " So right. And who says even without the sound, I want to watch that sea lion show.",
        "tokens": [
          50814,
          407,
          558,
          13,
          400,
          567,
          1619,
          754,
          1553,
          264,
          1626,
          11,
          286,
          528,
          281,
          1159,
          300,
          4158,
          17226,
          855,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.26802845215529536,
        "compression_ratio": 1.456221198156682,
        "end": 4742.8,
        "id": 677,
        "no_speech_prob": 0.3310494124889374,
        "seek": 472480,
        "start": 4738.8,
        "temperature": 0,
        "text": " So just curiosity stream. If you sign up through my link.",
        "tokens": [
          51064,
          407,
          445,
          18769,
          4309,
          13,
          759,
          291,
          1465,
          493,
          807,
          452,
          2113,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.26802845215529536,
        "compression_ratio": 1.456221198156682,
        "end": 4746.8,
        "id": 678,
        "no_speech_prob": 0.3310494124889374,
        "seek": 472480,
        "start": 4742.8,
        "temperature": 0,
        "text": " And I believe if I go slash coding train.",
        "tokens": [
          51264,
          400,
          286,
          1697,
          498,
          286,
          352,
          17330,
          17720,
          3847,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.26802845215529536,
        "compression_ratio": 1.456221198156682,
        "end": 4750.8,
        "id": 679,
        "no_speech_prob": 0.3310494124889374,
        "seek": 472480,
        "start": 4748.8,
        "temperature": 0,
        "text": " It'll sort of show us that.",
        "tokens": [
          51564,
          467,
          603,
          1333,
          295,
          855,
          505,
          300,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.20040989925986843,
        "compression_ratio": 1.5043103448275863,
        "end": 4761.8,
        "id": 680,
        "no_speech_prob": 0.5427643060684204,
        "seek": 475080,
        "start": 4751.8,
        "temperature": 0,
        "text": " Because I'm already logged in. So if I wasn't logged in, it would have a nice little banner at the top that says you get 26% off of the annual subscription.",
        "tokens": [
          50414,
          1436,
          286,
          478,
          1217,
          27231,
          294,
          13,
          407,
          498,
          286,
          2067,
          380,
          27231,
          294,
          11,
          309,
          576,
          362,
          257,
          1481,
          707,
          24348,
          412,
          264,
          1192,
          300,
          1619,
          291,
          483,
          7551,
          4,
          766,
          295,
          264,
          9784,
          17231,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.20040989925986843,
        "compression_ratio": 1.5043103448275863,
        "end": 4771.8,
        "id": 681,
        "no_speech_prob": 0.5427643060684204,
        "seek": 475080,
        "start": 4761.8,
        "temperature": 0,
        "text": " That comes to $14.79. It's barely over a dollar per month at $14.79 for the entire year.",
        "tokens": [
          50914,
          663,
          1487,
          281,
          1848,
          7271,
          13,
          32042,
          13,
          467,
          311,
          10268,
          670,
          257,
          7241,
          680,
          1618,
          412,
          1848,
          7271,
          13,
          32042,
          337,
          264,
          2302,
          1064,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.20040989925986843,
        "compression_ratio": 1.5043103448275863,
        "end": 4777.8,
        "id": 682,
        "no_speech_prob": 0.5427643060684204,
        "seek": 475080,
        "start": 4771.8,
        "temperature": 0,
        "text": " But I think the thing that I really want to tell you that I'm really excited about is this is a bundle.",
        "tokens": [
          51414,
          583,
          286,
          519,
          264,
          551,
          300,
          286,
          534,
          528,
          281,
          980,
          291,
          300,
          286,
          478,
          534,
          2919,
          466,
          307,
          341,
          307,
          257,
          24438,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.22146919930335318,
        "compression_ratio": 1.5813953488372092,
        "end": 4783.8,
        "id": 683,
        "no_speech_prob": 0.01133115217089653,
        "seek": 477780,
        "start": 4777.8,
        "temperature": 0,
        "text": " So if you sign up for curiosity stream bundle through the link, you will also get access to Nebula.",
        "tokens": [
          50364,
          407,
          498,
          291,
          1465,
          493,
          337,
          18769,
          4309,
          24438,
          807,
          264,
          2113,
          11,
          291,
          486,
          611,
          483,
          2105,
          281,
          1734,
          37775,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.22146919930335318,
        "compression_ratio": 1.5813953488372092,
        "end": 4787.8,
        "id": 684,
        "no_speech_prob": 0.01133115217089653,
        "seek": 477780,
        "start": 4783.8,
        "temperature": 0,
        "text": " So Nebula is a streaming service built by YouTube creators.",
        "tokens": [
          50664,
          407,
          1734,
          37775,
          307,
          257,
          11791,
          2643,
          3094,
          538,
          3088,
          16039,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.22146919930335318,
        "compression_ratio": 1.5813953488372092,
        "end": 4792.8,
        "id": 685,
        "no_speech_prob": 0.01133115217089653,
        "seek": 477780,
        "start": 4788.8,
        "temperature": 0,
        "text": " Many of my favorites here. If I go to my library, there's some that I'm following.",
        "tokens": [
          50914,
          5126,
          295,
          452,
          16907,
          510,
          13,
          759,
          286,
          352,
          281,
          452,
          6405,
          11,
          456,
          311,
          512,
          300,
          286,
          478,
          3480,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.22146919930335318,
        "compression_ratio": 1.5813953488372092,
        "end": 4801.8,
        "id": 686,
        "no_speech_prob": 0.01133115217089653,
        "seek": 477780,
        "start": 4792.8,
        "temperature": 0,
        "text": " I'm Renee Ritchie. If you like AI and want machine learning, want to learn more about machine learning, you should definitely be checking out Jordan Harrod's videos.",
        "tokens": [
          51114,
          286,
          478,
          47790,
          497,
          1549,
          414,
          13,
          759,
          291,
          411,
          7318,
          293,
          528,
          3479,
          2539,
          11,
          528,
          281,
          1466,
          544,
          466,
          3479,
          2539,
          11,
          291,
          820,
          2138,
          312,
          8568,
          484,
          10979,
          3653,
          11452,
          311,
          2145,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.25229247840675145,
        "compression_ratio": 1.4945652173913044,
        "end": 4804.8,
        "id": 687,
        "no_speech_prob": 0.2146734893321991,
        "seek": 480180,
        "start": 4802.8,
        "temperature": 0,
        "text": " There's some other ones that are here.",
        "tokens": [
          50414,
          821,
          311,
          512,
          661,
          2306,
          300,
          366,
          510,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.25229247840675145,
        "compression_ratio": 1.4945652173913044,
        "end": 4809.8,
        "id": 688,
        "no_speech_prob": 0.2146734893321991,
        "seek": 480180,
        "start": 4804.8,
        "temperature": 0,
        "text": " And look at this! All of these are Daniel Shiffman coding train videos.",
        "tokens": [
          50514,
          400,
          574,
          412,
          341,
          0,
          1057,
          295,
          613,
          366,
          8033,
          1160,
          3661,
          1601,
          17720,
          3847,
          2145,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.25229247840675145,
        "compression_ratio": 1.4945652173913044,
        "end": 4814.8,
        "id": 689,
        "no_speech_prob": 0.2146734893321991,
        "seek": 480180,
        "start": 4809.8,
        "temperature": 0,
        "text": " And in particular, one of the things that you get with Nebula is early access.",
        "tokens": [
          50764,
          400,
          294,
          1729,
          11,
          472,
          295,
          264,
          721,
          300,
          291,
          483,
          365,
          1734,
          37775,
          307,
          2440,
          2105,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.25229247840675145,
        "compression_ratio": 1.4945652173913044,
        "end": 4819.8,
        "id": 690,
        "no_speech_prob": 0.2146734893321991,
        "seek": 480180,
        "start": 4814.8,
        "temperature": 0,
        "text": " And so this is a video that isn't yet out on the channel. Will be hopefully tomorrow.",
        "tokens": [
          51014,
          400,
          370,
          341,
          307,
          257,
          960,
          300,
          1943,
          380,
          1939,
          484,
          322,
          264,
          2269,
          13,
          3099,
          312,
          4696,
          4153,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.2227372185128634,
        "compression_ratio": 1.4125,
        "end": 4831.8,
        "id": 691,
        "no_speech_prob": 0.5697325468063354,
        "seek": 481980,
        "start": 4819.8,
        "temperature": 0,
        "text": " If you want early access to it, you'll get that through the Nebula bundle.",
        "tokens": [
          50364,
          759,
          291,
          528,
          2440,
          2105,
          281,
          309,
          11,
          291,
          603,
          483,
          300,
          807,
          264,
          1734,
          37775,
          24438,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.2227372185128634,
        "compression_ratio": 1.4125,
        "end": 4839.8,
        "id": 692,
        "no_speech_prob": 0.5697325468063354,
        "seek": 481980,
        "start": 4831.8,
        "temperature": 0,
        "text": " So many wonderful creators. A lot of this stuff is also on YouTube, but it's without ads on Nebula.",
        "tokens": [
          50964,
          407,
          867,
          3715,
          16039,
          13,
          316,
          688,
          295,
          341,
          1507,
          307,
          611,
          322,
          3088,
          11,
          457,
          309,
          311,
          1553,
          10342,
          322,
          1734,
          37775,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.2227372185128634,
        "compression_ratio": 1.4125,
        "end": 4843.8,
        "id": 693,
        "no_speech_prob": 0.5697325468063354,
        "seek": 481980,
        "start": 4839.8,
        "temperature": 0,
        "text": " And there are all these wonderful Nebula originals.",
        "tokens": [
          51364,
          400,
          456,
          366,
          439,
          613,
          3715,
          1734,
          37775,
          4957,
          1124,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.20784570713235875,
        "compression_ratio": 1.5755102040816327,
        "end": 4849.8,
        "id": 694,
        "no_speech_prob": 0.44927504658699036,
        "seek": 484380,
        "start": 4843.8,
        "temperature": 0,
        "text": " So this is a really awesome compilation of different creators.",
        "tokens": [
          50364,
          407,
          341,
          307,
          257,
          534,
          3476,
          40261,
          295,
          819,
          16039,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.20784570713235875,
        "compression_ratio": 1.5755102040816327,
        "end": 4851.8,
        "id": 695,
        "no_speech_prob": 0.44927504658699036,
        "seek": 484380,
        "start": 4849.8,
        "temperature": 0,
        "text": " I wonder if I could make one of these. I don't know.",
        "tokens": [
          50664,
          286,
          2441,
          498,
          286,
          727,
          652,
          472,
          295,
          613,
          13,
          286,
          500,
          380,
          458,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.20784570713235875,
        "compression_ratio": 1.5755102040816327,
        "end": 4860.8,
        "id": 696,
        "no_speech_prob": 0.44927504658699036,
        "seek": 484380,
        "start": 4851.8,
        "temperature": 0,
        "text": " But different creators on YouTube, they're all making videos about the opening title sequences of different television shows.",
        "tokens": [
          50764,
          583,
          819,
          16039,
          322,
          3088,
          11,
          436,
          434,
          439,
          1455,
          2145,
          466,
          264,
          5193,
          4876,
          22978,
          295,
          819,
          8815,
          3110,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.20784570713235875,
        "compression_ratio": 1.5755102040816327,
        "end": 4865.8,
        "id": 697,
        "no_speech_prob": 0.44927504658699036,
        "seek": 484380,
        "start": 4860.8,
        "temperature": 0,
        "text": " So you can see Renee Ritchie did one about Buffy the Vampire Slayer.",
        "tokens": [
          51214,
          407,
          291,
          393,
          536,
          47790,
          497,
          1549,
          414,
          630,
          472,
          466,
          363,
          14297,
          264,
          38796,
          621,
          6187,
          11167,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.20784570713235875,
        "compression_ratio": 1.5755102040816327,
        "end": 4869.8,
        "id": 698,
        "no_speech_prob": 0.44927504658699036,
        "seek": 484380,
        "start": 4865.8,
        "temperature": 0,
        "text": " We've got Soph's Notes, one about Pokemon. Ooh, I've got to check this out.",
        "tokens": [
          51464,
          492,
          600,
          658,
          18921,
          311,
          41360,
          11,
          472,
          466,
          13796,
          13,
          7951,
          11,
          286,
          600,
          658,
          281,
          1520,
          341,
          484,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.28321979572246603,
        "compression_ratio": 1.4583333333333333,
        "end": 4876.8,
        "id": 699,
        "no_speech_prob": 0.28135189414024353,
        "seek": 486980,
        "start": 4869.8,
        "temperature": 0,
        "text": " So these originals are really just wonderful. I'm just poking through to look for some other ones.",
        "tokens": [
          50364,
          407,
          613,
          4957,
          1124,
          366,
          534,
          445,
          3715,
          13,
          286,
          478,
          445,
          42684,
          807,
          281,
          574,
          337,
          512,
          661,
          2306,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.28321979572246603,
        "compression_ratio": 1.4583333333333333,
        "end": 4882.8,
        "id": 700,
        "no_speech_prob": 0.28135189414024353,
        "seek": 486980,
        "start": 4876.8,
        "temperature": 0,
        "text": " I'm a big fan of Legal Eagle. So you've got all of this bad law. Words good.",
        "tokens": [
          50714,
          286,
          478,
          257,
          955,
          3429,
          295,
          33577,
          27926,
          13,
          407,
          291,
          600,
          658,
          439,
          295,
          341,
          1578,
          2101,
          13,
          32857,
          665,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.28321979572246603,
        "compression_ratio": 1.4583333333333333,
        "end": 4889.8,
        "id": 701,
        "no_speech_prob": 0.28135189414024353,
        "seek": 486980,
        "start": 4882.8,
        "temperature": 0,
        "text": " So Mikhail is asking, did he say built by YouTube creators or YouTube's creators?",
        "tokens": [
          51014,
          407,
          16380,
          48909,
          307,
          3365,
          11,
          630,
          415,
          584,
          3094,
          538,
          3088,
          16039,
          420,
          3088,
          311,
          16039,
          30,
          51364
        ]
      },
      {
        "avg_logprob": -0.28321979572246603,
        "compression_ratio": 1.4583333333333333,
        "end": 4892.8,
        "id": 702,
        "no_speech_prob": 0.28135189414024353,
        "seek": 486980,
        "start": 4889.8,
        "temperature": 0,
        "text": " No. Built by creators.",
        "tokens": [
          51364,
          883,
          13,
          49822,
          538,
          16039,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.1841298739115397,
        "compression_ratio": 1.4379084967320261,
        "end": 4898.8,
        "id": 703,
        "no_speech_prob": 0.8975655436515808,
        "seek": 489280,
        "start": 4892.8,
        "temperature": 0,
        "text": " So everyone that you see here on Nebula participated in the making of Nebula itself.",
        "tokens": [
          50364,
          407,
          1518,
          300,
          291,
          536,
          510,
          322,
          1734,
          37775,
          17978,
          294,
          264,
          1455,
          295,
          1734,
          37775,
          2564,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.1841298739115397,
        "compression_ratio": 1.4379084967320261,
        "end": 4910.8,
        "id": 704,
        "no_speech_prob": 0.8975655436515808,
        "seek": 489280,
        "start": 4898.8,
        "temperature": 0,
        "text": " And this isn't really true for me, but I know that one of the benefits for many YouTube creators of Nebula is certain kinds of content.",
        "tokens": [
          50664,
          400,
          341,
          1943,
          380,
          534,
          2074,
          337,
          385,
          11,
          457,
          286,
          458,
          300,
          472,
          295,
          264,
          5311,
          337,
          867,
          3088,
          16039,
          295,
          1734,
          37775,
          307,
          1629,
          3685,
          295,
          2701,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.24973796892769728,
        "compression_ratio": 1.497584541062802,
        "end": 4921.8,
        "id": 705,
        "no_speech_prob": 0.6260292530059814,
        "seek": 491080,
        "start": 4910.8,
        "temperature": 0,
        "text": " A lot of the historical videos, certain kinds of content can't be on YouTube.",
        "tokens": [
          50364,
          316,
          688,
          295,
          264,
          8584,
          2145,
          11,
          1629,
          3685,
          295,
          2701,
          393,
          380,
          312,
          322,
          3088,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.24973796892769728,
        "compression_ratio": 1.497584541062802,
        "end": 4931.8,
        "id": 706,
        "no_speech_prob": 0.6260292530059814,
        "seek": 491080,
        "start": 4921.8,
        "temperature": 0,
        "text": " It will get demonetized or it will get sort of, if it's about a kind of topic like about World War II, for example.",
        "tokens": [
          50914,
          467,
          486,
          483,
          14283,
          302,
          1602,
          420,
          309,
          486,
          483,
          1333,
          295,
          11,
          498,
          309,
          311,
          466,
          257,
          733,
          295,
          4829,
          411,
          466,
          3937,
          3630,
          6351,
          11,
          337,
          1365,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.24973796892769728,
        "compression_ratio": 1.497584541062802,
        "end": 4939.8,
        "id": 707,
        "no_speech_prob": 0.6260292530059814,
        "seek": 491080,
        "start": 4931.8,
        "temperature": 0,
        "text": " So I'm not saying this very eloquently, but creators are free basically to publish certain kinds of videos on Nebula",
        "tokens": [
          51414,
          407,
          286,
          478,
          406,
          1566,
          341,
          588,
          38682,
          47519,
          11,
          457,
          16039,
          366,
          1737,
          1936,
          281,
          11374,
          1629,
          3685,
          295,
          2145,
          322,
          1734,
          37775,
          51814
        ]
      },
      {
        "avg_logprob": -0.21492085930045324,
        "compression_ratio": 1.6797153024911031,
        "end": 4944.8,
        "id": 708,
        "no_speech_prob": 0.3006918430328369,
        "seek": 493980,
        "start": 4939.8,
        "temperature": 0,
        "text": " that might cause them issues on YouTube itself. So that's one of the motivations as well as all these originals,",
        "tokens": [
          50364,
          300,
          1062,
          3082,
          552,
          2663,
          322,
          3088,
          2564,
          13,
          407,
          300,
          311,
          472,
          295,
          264,
          39034,
          382,
          731,
          382,
          439,
          613,
          4957,
          1124,
          11,
          50614
        ]
      },
      {
        "avg_logprob": -0.21492085930045324,
        "compression_ratio": 1.6797153024911031,
        "end": 4949.8,
        "id": 709,
        "no_speech_prob": 0.3006918430328369,
        "seek": 493980,
        "start": 4944.8,
        "temperature": 0,
        "text": " about being able to have no ads. So you can get this for free. Not for free.",
        "tokens": [
          50614,
          466,
          885,
          1075,
          281,
          362,
          572,
          10342,
          13,
          407,
          291,
          393,
          483,
          341,
          337,
          1737,
          13,
          1726,
          337,
          1737,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.21492085930045324,
        "compression_ratio": 1.6797153024911031,
        "end": 4957.8,
        "id": 710,
        "no_speech_prob": 0.3006918430328369,
        "seek": 493980,
        "start": 4949.8,
        "temperature": 0,
        "text": " Well, you do get it for free if you sign up for the, oh, oh, I'm so going to get fired.",
        "tokens": [
          50864,
          1042,
          11,
          291,
          360,
          483,
          309,
          337,
          1737,
          498,
          291,
          1465,
          493,
          337,
          264,
          11,
          1954,
          11,
          1954,
          11,
          286,
          478,
          370,
          516,
          281,
          483,
          11777,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.21492085930045324,
        "compression_ratio": 1.6797153024911031,
        "end": 4963.8,
        "id": 711,
        "no_speech_prob": 0.3006918430328369,
        "seek": 493980,
        "start": 4957.8,
        "temperature": 0,
        "text": " I'm really basically like, I just got a cop to it. Today has been such a mess for me.",
        "tokens": [
          51264,
          286,
          478,
          534,
          1936,
          411,
          11,
          286,
          445,
          658,
          257,
          2971,
          281,
          309,
          13,
          2692,
          575,
          668,
          1270,
          257,
          2082,
          337,
          385,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.21492085930045324,
        "compression_ratio": 1.6797153024911031,
        "end": 4968.8,
        "id": 712,
        "no_speech_prob": 0.3006918430328369,
        "seek": 493980,
        "start": 4963.8,
        "temperature": 0,
        "text": " I had this all planned out this morning. I had everything I knew I wanted to say and do in this live stream.",
        "tokens": [
          51564,
          286,
          632,
          341,
          439,
          8589,
          484,
          341,
          2446,
          13,
          286,
          632,
          1203,
          286,
          2586,
          286,
          1415,
          281,
          584,
          293,
          360,
          294,
          341,
          1621,
          4309,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.18768728256225586,
        "compression_ratio": 1.6403508771929824,
        "end": 4974.8,
        "id": 713,
        "no_speech_prob": 0.10968928039073944,
        "seek": 496880,
        "start": 4968.8,
        "temperature": 0,
        "text": " I really do love this service Nebula. I participated in it. It's meaningful to me.",
        "tokens": [
          50364,
          286,
          534,
          360,
          959,
          341,
          2643,
          1734,
          37775,
          13,
          286,
          17978,
          294,
          309,
          13,
          467,
          311,
          10995,
          281,
          385,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.18768728256225586,
        "compression_ratio": 1.6403508771929824,
        "end": 4981.8,
        "id": 714,
        "no_speech_prob": 0.10968928039073944,
        "seek": 496880,
        "start": 4974.8,
        "temperature": 0,
        "text": " And it's like as I get to become, spend more and more time on Coding Train, I'm really hoping that come this January,",
        "tokens": [
          50664,
          400,
          309,
          311,
          411,
          382,
          286,
          483,
          281,
          1813,
          11,
          3496,
          544,
          293,
          544,
          565,
          322,
          383,
          8616,
          28029,
          11,
          286,
          478,
          534,
          7159,
          300,
          808,
          341,
          7061,
          11,
          51014
        ]
      },
      {
        "avg_logprob": -0.18768728256225586,
        "compression_ratio": 1.6403508771929824,
        "end": 4987.8,
        "id": 715,
        "no_speech_prob": 0.10968928039073944,
        "seek": 496880,
        "start": 4981.8,
        "temperature": 0,
        "text": " I'm going to be able to dive more into Nebula and maybe make a Nebula original myself.",
        "tokens": [
          51014,
          286,
          478,
          516,
          281,
          312,
          1075,
          281,
          9192,
          544,
          666,
          1734,
          37775,
          293,
          1310,
          652,
          257,
          1734,
          37775,
          3380,
          2059,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.18768728256225586,
        "compression_ratio": 1.6403508771929824,
        "end": 4992.8,
        "id": 716,
        "no_speech_prob": 0.10968928039073944,
        "seek": 496880,
        "start": 4987.8,
        "temperature": 0,
        "text": " So if you want to get involved, learn more about it, also support Coding Train itself,",
        "tokens": [
          51314,
          407,
          498,
          291,
          528,
          281,
          483,
          3288,
          11,
          1466,
          544,
          466,
          309,
          11,
          611,
          1406,
          383,
          8616,
          28029,
          2564,
          11,
          51564
        ]
      },
      {
        "avg_logprob": -0.22124535429711437,
        "compression_ratio": 1.8093220338983051,
        "end": 5001.8,
        "id": 717,
        "no_speech_prob": 0.7339663505554199,
        "seek": 499280,
        "start": 4992.8,
        "temperature": 0,
        "text": " get access to this incredible library of documentaries, you can go right now to curiositystream.com slash coding train.",
        "tokens": [
          50364,
          483,
          2105,
          281,
          341,
          4651,
          6405,
          295,
          41630,
          11,
          291,
          393,
          352,
          558,
          586,
          281,
          18769,
          9291,
          13,
          1112,
          17330,
          17720,
          3847,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.22124535429711437,
        "compression_ratio": 1.8093220338983051,
        "end": 5005.8,
        "id": 718,
        "no_speech_prob": 0.7339663505554199,
        "seek": 499280,
        "start": 5001.8,
        "temperature": 0,
        "text": " That's the link right there. Curiositystream.com slash coding train.",
        "tokens": [
          50814,
          663,
          311,
          264,
          2113,
          558,
          456,
          13,
          48998,
          9291,
          13,
          1112,
          17330,
          17720,
          3847,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.22124535429711437,
        "compression_ratio": 1.8093220338983051,
        "end": 5012.8,
        "id": 719,
        "no_speech_prob": 0.7339663505554199,
        "seek": 499280,
        "start": 5005.8,
        "temperature": 0,
        "text": " Thank you everybody for tolerating this like really terrible sponsor read. I'm going to do better next time.",
        "tokens": [
          51014,
          1044,
          291,
          2201,
          337,
          11125,
          990,
          341,
          411,
          534,
          6237,
          16198,
          1401,
          13,
          286,
          478,
          516,
          281,
          360,
          1101,
          958,
          565,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.22124535429711437,
        "compression_ratio": 1.8093220338983051,
        "end": 5018.8,
        "id": 720,
        "no_speech_prob": 0.7339663505554199,
        "seek": 499280,
        "start": 5012.8,
        "temperature": 0,
        "text": " I'm going to take a like a two or three minute break. You can sign up now if you have nothing to do in this two or three minutes.",
        "tokens": [
          51364,
          286,
          478,
          516,
          281,
          747,
          257,
          411,
          257,
          732,
          420,
          1045,
          3456,
          1821,
          13,
          509,
          393,
          1465,
          493,
          586,
          498,
          291,
          362,
          1825,
          281,
          360,
          294,
          341,
          732,
          420,
          1045,
          2077,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.2682497236463759,
        "compression_ratio": 1.2075471698113207,
        "end": 5023.8,
        "id": 721,
        "no_speech_prob": 0.2876434922218323,
        "seek": 501880,
        "start": 5018.8,
        "temperature": 0,
        "text": " I'll be right back to finish off this auto encoder project.",
        "tokens": [
          50364,
          286,
          603,
          312,
          558,
          646,
          281,
          2413,
          766,
          341,
          8399,
          2058,
          19866,
          1716,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.2682497236463759,
        "compression_ratio": 1.2075471698113207,
        "end": 5027.8,
        "id": 722,
        "no_speech_prob": 0.2876434922218323,
        "seek": 501880,
        "start": 5023.8,
        "temperature": 0,
        "text": " I'm going to go feel bad about myself over there now. Be right back.",
        "tokens": [
          50614,
          286,
          478,
          516,
          281,
          352,
          841,
          1578,
          466,
          2059,
          670,
          456,
          586,
          13,
          879,
          558,
          646,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.2939507620675223,
        "compression_ratio": 0.5555555555555556,
        "end": 5134.8,
        "id": 723,
        "no_speech_prob": 0.550060510635376,
        "seek": 510880,
        "start": 5108.8,
        "temperature": 0,
        "text": " All right.",
        "tokens": [
          50364,
          1057,
          558,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.2707687440465708,
        "compression_ratio": 1.367741935483871,
        "end": 5145.8,
        "id": 724,
        "no_speech_prob": 0.06656289100646973,
        "seek": 513480,
        "start": 5134.8,
        "temperature": 0,
        "text": " All right. I have returned. I took some deep breaths, did a very short 20 second meditation.",
        "tokens": [
          50364,
          1057,
          558,
          13,
          286,
          362,
          8752,
          13,
          286,
          1890,
          512,
          2452,
          33769,
          11,
          630,
          257,
          588,
          2099,
          945,
          1150,
          12537,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.2707687440465708,
        "compression_ratio": 1.367741935483871,
        "end": 5155.8,
        "id": 725,
        "no_speech_prob": 0.06656289100646973,
        "seek": 513480,
        "start": 5145.8,
        "temperature": 0,
        "text": " And John says, well, you got me to sign up so you didn't do too badly.",
        "tokens": [
          50914,
          400,
          2619,
          1619,
          11,
          731,
          11,
          291,
          658,
          385,
          281,
          1465,
          493,
          370,
          291,
          994,
          380,
          360,
          886,
          13425,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.2707687440465708,
        "compression_ratio": 1.367741935483871,
        "end": 5161.8,
        "id": 726,
        "no_speech_prob": 0.06656289100646973,
        "seek": 513480,
        "start": 5155.8,
        "temperature": 0,
        "text": " All right. Those pity sign ups. I appreciate it.",
        "tokens": [
          51414,
          1057,
          558,
          13,
          3950,
          21103,
          1465,
          15497,
          13,
          286,
          4449,
          309,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.17327959082099828,
        "compression_ratio": 1.5876777251184835,
        "end": 5169.8,
        "id": 727,
        "no_speech_prob": 0.6075607538223267,
        "seek": 516180,
        "start": 5161.8,
        "temperature": 0,
        "text": " All right. Let me get back into what we're all here for, which is my building of an auto encoder.",
        "tokens": [
          50364,
          1057,
          558,
          13,
          961,
          385,
          483,
          646,
          666,
          437,
          321,
          434,
          439,
          510,
          337,
          11,
          597,
          307,
          452,
          2390,
          295,
          364,
          8399,
          2058,
          19866,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.17327959082099828,
        "compression_ratio": 1.5876777251184835,
        "end": 5178.8,
        "id": 728,
        "no_speech_prob": 0.6075607538223267,
        "seek": 516180,
        "start": 5169.8,
        "temperature": 0,
        "text": " All right. So I think we're really close here to actually seeing some images.",
        "tokens": [
          50764,
          1057,
          558,
          13,
          407,
          286,
          519,
          321,
          434,
          534,
          1998,
          510,
          281,
          767,
          2577,
          512,
          5267,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.17327959082099828,
        "compression_ratio": 1.5876777251184835,
        "end": 5183.8,
        "id": 729,
        "no_speech_prob": 0.6075607538223267,
        "seek": 516180,
        "start": 5178.8,
        "temperature": 0,
        "text": " Generated from the auto encoder. Now, if I wanted to go all the way through with this, I would.",
        "tokens": [
          51214,
          15409,
          770,
          490,
          264,
          8399,
          2058,
          19866,
          13,
          823,
          11,
          498,
          286,
          1415,
          281,
          352,
          439,
          264,
          636,
          807,
          365,
          341,
          11,
          286,
          576,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.17327959082099828,
        "compression_ratio": 1.5876777251184835,
        "end": 5189.8,
        "id": 730,
        "no_speech_prob": 0.6075607538223267,
        "seek": 516180,
        "start": 5183.8,
        "temperature": 0,
        "text": " I want to eventually reconnect this back to the browser itself.",
        "tokens": [
          51464,
          286,
          528,
          281,
          4728,
          30095,
          341,
          646,
          281,
          264,
          11185,
          2564,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.2154769208057817,
        "compression_ratio": 1.6464646464646464,
        "end": 5193.8,
        "id": 731,
        "no_speech_prob": 0.7955595850944519,
        "seek": 518980,
        "start": 5189.8,
        "temperature": 0,
        "text": " I mean, maybe I should just have the model in the browser. I don't really need a node server.",
        "tokens": [
          50364,
          286,
          914,
          11,
          1310,
          286,
          820,
          445,
          362,
          264,
          2316,
          294,
          264,
          11185,
          13,
          286,
          500,
          380,
          534,
          643,
          257,
          9984,
          7154,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.2154769208057817,
        "compression_ratio": 1.6464646464646464,
        "end": 5199.8,
        "id": 732,
        "no_speech_prob": 0.7955595850944519,
        "seek": 518980,
        "start": 5193.8,
        "temperature": 0,
        "text": " So maybe run the training. I'm not really sure where I want to go with this ultimately.",
        "tokens": [
          50564,
          407,
          1310,
          1190,
          264,
          3097,
          13,
          286,
          478,
          406,
          534,
          988,
          689,
          286,
          528,
          281,
          352,
          365,
          341,
          6284,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.2154769208057817,
        "compression_ratio": 1.6464646464646464,
        "end": 5209.8,
        "id": 733,
        "no_speech_prob": 0.7955595850944519,
        "seek": 518980,
        "start": 5199.8,
        "temperature": 0,
        "text": " It so turns out. But I do want to see the results of the auto encoder in the browser and start to understand how to manipulate the latent space.",
        "tokens": [
          50864,
          467,
          370,
          4523,
          484,
          13,
          583,
          286,
          360,
          528,
          281,
          536,
          264,
          3542,
          295,
          264,
          8399,
          2058,
          19866,
          294,
          264,
          11185,
          293,
          722,
          281,
          1223,
          577,
          281,
          20459,
          264,
          48994,
          1901,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.20191835634636157,
        "compression_ratio": 1.3798882681564246,
        "end": 5223.8,
        "id": 734,
        "no_speech_prob": 0.6477096676826477,
        "seek": 520980,
        "start": 5209.8,
        "temperature": 0,
        "text": " But my goal for today, given that I would like to wrap this up in about 20 to 30 minutes, is to simply see an image generated from the auto encoder.",
        "tokens": [
          50364,
          583,
          452,
          3387,
          337,
          965,
          11,
          2212,
          300,
          286,
          576,
          411,
          281,
          7019,
          341,
          493,
          294,
          466,
          945,
          281,
          2217,
          2077,
          11,
          307,
          281,
          2935,
          536,
          364,
          3256,
          10833,
          490,
          264,
          8399,
          2058,
          19866,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.20191835634636157,
        "compression_ratio": 1.3798882681564246,
        "end": 5236.8,
        "id": 735,
        "no_speech_prob": 0.6477096676826477,
        "seek": 520980,
        "start": 5223.8,
        "temperature": 0,
        "text": " Even just one. So I'm trying to decide. I think it would be worth me putting in a few more layers.",
        "tokens": [
          51064,
          2754,
          445,
          472,
          13,
          407,
          286,
          478,
          1382,
          281,
          4536,
          13,
          286,
          519,
          309,
          576,
          312,
          3163,
          385,
          3372,
          294,
          257,
          1326,
          544,
          7914,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.22492301158415964,
        "compression_ratio": 1.4086021505376345,
        "end": 5246.8,
        "id": 736,
        "no_speech_prob": 0.0769529789686203,
        "seek": 523680,
        "start": 5236.8,
        "temperature": 0,
        "text": " So, I mean, I suppose I don't need to worry about improving this so much. And let's just work with what I've got.",
        "tokens": [
          50364,
          407,
          11,
          286,
          914,
          11,
          286,
          7297,
          286,
          500,
          380,
          643,
          281,
          3292,
          466,
          11470,
          341,
          370,
          709,
          13,
          400,
          718,
          311,
          445,
          589,
          365,
          437,
          286,
          600,
          658,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.22492301158415964,
        "compression_ratio": 1.4086021505376345,
        "end": 5254.8,
        "id": 737,
        "no_speech_prob": 0.0769529789686203,
        "seek": 523680,
        "start": 5246.8,
        "temperature": 0,
        "text": " Which is 100 images. Let's see what happens if I give it 100 epochs.",
        "tokens": [
          50864,
          3013,
          307,
          2319,
          5267,
          13,
          961,
          311,
          536,
          437,
          2314,
          498,
          286,
          976,
          309,
          2319,
          30992,
          28346,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.22492301158415964,
        "compression_ratio": 1.4086021505376345,
        "end": 5262.8,
        "id": 738,
        "no_speech_prob": 0.0769529789686203,
        "seek": 523680,
        "start": 5254.8,
        "temperature": 0,
        "text": " And I'm just going to go down. I'm going to compress the 784 pixels down to 64.",
        "tokens": [
          51264,
          400,
          286,
          478,
          445,
          516,
          281,
          352,
          760,
          13,
          286,
          478,
          516,
          281,
          14778,
          264,
          1614,
          25494,
          18668,
          760,
          281,
          12145,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.20487844027005708,
        "compression_ratio": 1.7743055555555556,
        "end": 5265.8,
        "id": 739,
        "no_speech_prob": 0.6222613453865051,
        "seek": 526280,
        "start": 5262.8,
        "temperature": 0,
        "text": " Oh, and Mikhail is asking a great, great question.",
        "tokens": [
          50364,
          876,
          11,
          293,
          16380,
          48909,
          307,
          3365,
          257,
          869,
          11,
          869,
          1168,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.20487844027005708,
        "compression_ratio": 1.7743055555555556,
        "end": 5272.8,
        "id": 740,
        "no_speech_prob": 0.6222613453865051,
        "seek": 526280,
        "start": 5265.8,
        "temperature": 0,
        "text": " In his image loading, he's normalizing the pixels to between 0 and 1, but all the TF tutorials I've seen use negative 1 to 1.",
        "tokens": [
          50514,
          682,
          702,
          3256,
          15114,
          11,
          415,
          311,
          2710,
          3319,
          264,
          18668,
          281,
          1296,
          1958,
          293,
          502,
          11,
          457,
          439,
          264,
          40964,
          17616,
          286,
          600,
          1612,
          764,
          3671,
          502,
          281,
          502,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.20487844027005708,
        "compression_ratio": 1.7743055555555556,
        "end": 5277.8,
        "id": 741,
        "no_speech_prob": 0.6222613453865051,
        "seek": 526280,
        "start": 5272.8,
        "temperature": 0,
        "text": " Is there any practical difference or just personal preference? I would love to know the answer to that question.",
        "tokens": [
          50864,
          1119,
          456,
          604,
          8496,
          2649,
          420,
          445,
          2973,
          17502,
          30,
          286,
          576,
          959,
          281,
          458,
          264,
          1867,
          281,
          300,
          1168,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.20487844027005708,
        "compression_ratio": 1.7743055555555556,
        "end": 5285.8,
        "id": 742,
        "no_speech_prob": 0.6222613453865051,
        "seek": 526280,
        "start": 5277.8,
        "temperature": 0,
        "text": " I think at the moment, because I'm using this output, I'm using the sigmoid function as the output activation function,",
        "tokens": [
          51114,
          286,
          519,
          412,
          264,
          1623,
          11,
          570,
          286,
          478,
          1228,
          341,
          5598,
          11,
          286,
          478,
          1228,
          264,
          4556,
          3280,
          327,
          2445,
          382,
          264,
          5598,
          24433,
          2445,
          11,
          51514
        ]
      },
      {
        "avg_logprob": -0.20487844027005708,
        "compression_ratio": 1.7743055555555556,
        "end": 5291.8,
        "id": 743,
        "no_speech_prob": 0.6222613453865051,
        "seek": 526280,
        "start": 5285.8,
        "temperature": 0,
        "text": " it's got to be between 0 and 1 because the outputs are only going to be between 0 and 1 with sigmoid.",
        "tokens": [
          51514,
          309,
          311,
          658,
          281,
          312,
          1296,
          1958,
          293,
          502,
          570,
          264,
          23930,
          366,
          787,
          516,
          281,
          312,
          1296,
          1958,
          293,
          502,
          365,
          4556,
          3280,
          327,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.2928906374199446,
        "compression_ratio": 1.5233644859813085,
        "end": 5296.8,
        "id": 744,
        "no_speech_prob": 0.01450276467949152,
        "seek": 529180,
        "start": 5291.8,
        "temperature": 0,
        "text": " But if I were using tanh, then I could have outputs between negative 1 and 1.",
        "tokens": [
          50364,
          583,
          498,
          286,
          645,
          1228,
          7603,
          71,
          11,
          550,
          286,
          727,
          362,
          23930,
          1296,
          3671,
          502,
          293,
          502,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.2928906374199446,
        "compression_ratio": 1.5233644859813085,
        "end": 5306.8,
        "id": 745,
        "no_speech_prob": 0.01450276467949152,
        "seek": 529180,
        "start": 5296.8,
        "temperature": 0,
        "text": " It has to do with the... So, but again, I'm kind of flying blind. I'm just sort of like throwing all the spaghetti at the wall.",
        "tokens": [
          50614,
          467,
          575,
          281,
          360,
          365,
          264,
          485,
          407,
          11,
          457,
          797,
          11,
          286,
          478,
          733,
          295,
          7137,
          6865,
          13,
          286,
          478,
          445,
          1333,
          295,
          411,
          10238,
          439,
          264,
          28556,
          412,
          264,
          2929,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.2928906374199446,
        "compression_ratio": 1.5233644859813085,
        "end": 5313.8,
        "id": 746,
        "no_speech_prob": 0.01450276467949152,
        "seek": 529180,
        "start": 5306.8,
        "temperature": 0,
        "text": " And to see what sticks, just trying to get something working that I can go back and kind of fine tune more thoughtfully.",
        "tokens": [
          51114,
          400,
          281,
          536,
          437,
          12518,
          11,
          445,
          1382,
          281,
          483,
          746,
          1364,
          300,
          286,
          393,
          352,
          646,
          293,
          733,
          295,
          2489,
          10864,
          544,
          1194,
          2277,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.22934379577636718,
        "compression_ratio": 1.4540816326530612,
        "end": 5320.8,
        "id": 747,
        "no_speech_prob": 0.426267147064209,
        "seek": 531380,
        "start": 5314.8,
        "temperature": 0,
        "text": " I don't need to print this out anymore. Let's just try training this. Let's see what happens with the loss.",
        "tokens": [
          50414,
          286,
          500,
          380,
          643,
          281,
          4482,
          341,
          484,
          3602,
          13,
          961,
          311,
          445,
          853,
          3097,
          341,
          13,
          961,
          311,
          536,
          437,
          2314,
          365,
          264,
          4470,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.22934379577636718,
        "compression_ratio": 1.4540816326530612,
        "end": 5332.8,
        "id": 748,
        "no_speech_prob": 0.426267147064209,
        "seek": 531380,
        "start": 5324.8,
        "temperature": 0,
        "text": " So, the loss seems to settle at probably around 100 epochs at 0.07. That's great.",
        "tokens": [
          50914,
          407,
          11,
          264,
          4470,
          2544,
          281,
          11852,
          412,
          1391,
          926,
          2319,
          30992,
          28346,
          412,
          1958,
          13,
          16231,
          13,
          663,
          311,
          869,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.22934379577636718,
        "compression_ratio": 1.4540816326530612,
        "end": 5342.8,
        "id": 749,
        "no_speech_prob": 0.426267147064209,
        "seek": 531380,
        "start": 5333.8,
        "temperature": 0,
        "text": " So, could I now... If I wanted to generate an image from this, let's go back to the original...",
        "tokens": [
          51364,
          407,
          11,
          727,
          286,
          586,
          485,
          759,
          286,
          1415,
          281,
          8460,
          364,
          3256,
          490,
          341,
          11,
          718,
          311,
          352,
          646,
          281,
          264,
          3380,
          485,
          51814
        ]
      },
      {
        "avg_logprob": -0.20199853402596932,
        "compression_ratio": 1.6647398843930636,
        "end": 5349.8,
        "id": 750,
        "no_speech_prob": 0.007460467051714659,
        "seek": 534280,
        "start": 5342.8,
        "temperature": 0,
        "text": " So, I'm done with sort of like part two and a half of three parts. This is in three parts.",
        "tokens": [
          50364,
          407,
          11,
          286,
          478,
          1096,
          365,
          1333,
          295,
          411,
          644,
          732,
          293,
          257,
          1922,
          295,
          1045,
          3166,
          13,
          639,
          307,
          294,
          1045,
          3166,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.20199853402596932,
        "compression_ratio": 1.6647398843930636,
        "end": 5354.8,
        "id": 751,
        "no_speech_prob": 0.007460467051714659,
        "seek": 534280,
        "start": 5349.8,
        "temperature": 0,
        "text": " Part one was just building the autoencoder, giving it noisy data.",
        "tokens": [
          50714,
          4100,
          472,
          390,
          445,
          2390,
          264,
          8399,
          22660,
          19866,
          11,
          2902,
          309,
          24518,
          1412,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.20199853402596932,
        "compression_ratio": 1.6647398843930636,
        "end": 5359.8,
        "id": 752,
        "no_speech_prob": 0.007460467051714659,
        "seek": 534280,
        "start": 5354.8,
        "temperature": 0,
        "text": " Part 2A was getting actual data into the autoencoder.",
        "tokens": [
          50964,
          4100,
          568,
          32,
          390,
          1242,
          3539,
          1412,
          666,
          264,
          8399,
          22660,
          19866,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.20199853402596932,
        "compression_ratio": 1.6647398843930636,
        "end": 5365.8,
        "id": 753,
        "no_speech_prob": 0.007460467051714659,
        "seek": 534280,
        "start": 5359.8,
        "temperature": 0,
        "text": " Part 2B is looking at the results of the autoencoder after it's been trained.",
        "tokens": [
          51214,
          4100,
          568,
          33,
          307,
          1237,
          412,
          264,
          3542,
          295,
          264,
          8399,
          22660,
          19866,
          934,
          309,
          311,
          668,
          8895,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.2095226336129104,
        "compression_ratio": 1.3910614525139664,
        "end": 5372.8,
        "id": 754,
        "no_speech_prob": 0.02931179106235504,
        "seek": 536580,
        "start": 5366.8,
        "temperature": 0,
        "text": " So, if I'm coming back to this, what did this tutorial do?",
        "tokens": [
          50414,
          407,
          11,
          498,
          286,
          478,
          1348,
          646,
          281,
          341,
          11,
          437,
          630,
          341,
          7073,
          360,
          30,
          50714
        ]
      },
      {
        "avg_logprob": -0.2095226336129104,
        "compression_ratio": 1.3910614525139664,
        "end": 5378.8,
        "id": 755,
        "no_speech_prob": 0.02931179106235504,
        "seek": 536580,
        "start": 5372.8,
        "temperature": 0,
        "text": " And I'm not having any test data. Yeah, right. This is also, by the way, normalizing between 0 and 1.",
        "tokens": [
          50714,
          400,
          286,
          478,
          406,
          1419,
          604,
          1500,
          1412,
          13,
          865,
          11,
          558,
          13,
          639,
          307,
          611,
          11,
          538,
          264,
          636,
          11,
          2710,
          3319,
          1296,
          1958,
          293,
          502,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.2095226336129104,
        "compression_ratio": 1.3910614525139664,
        "end": 5383.8,
        "id": 756,
        "no_speech_prob": 0.02931179106235504,
        "seek": 536580,
        "start": 5379.8,
        "temperature": 0,
        "text": " Decoded images. Oh, using predict. Okay.",
        "tokens": [
          51064,
          12427,
          12340,
          5267,
          13,
          876,
          11,
          1228,
          6069,
          13,
          1033,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.2095226336129104,
        "compression_ratio": 1.3910614525139664,
        "end": 5391.8,
        "id": 757,
        "no_speech_prob": 0.02931179106235504,
        "seek": 536580,
        "start": 5383.8,
        "temperature": 0,
        "text": " So, if I can use predict to see... Okay, great.",
        "tokens": [
          51264,
          407,
          11,
          498,
          286,
          393,
          764,
          6069,
          281,
          536,
          485,
          1033,
          11,
          869,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.21020745695307014,
        "compression_ratio": 1.560846560846561,
        "end": 5395.8,
        "id": 758,
        "no_speech_prob": 0.010328012518584728,
        "seek": 539180,
        "start": 5391.8,
        "temperature": 0,
        "text": " So, let's do this. Let's follow this. So, I want to use predict.",
        "tokens": [
          50364,
          407,
          11,
          718,
          311,
          360,
          341,
          13,
          961,
          311,
          1524,
          341,
          13,
          407,
          11,
          286,
          528,
          281,
          764,
          6069,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.21020745695307014,
        "compression_ratio": 1.560846560846561,
        "end": 5399.8,
        "id": 759,
        "no_speech_prob": 0.010328012518584728,
        "seek": 539180,
        "start": 5395.8,
        "temperature": 0,
        "text": " Let's refactor this a little bit to make it less weird. Okay?",
        "tokens": [
          50564,
          961,
          311,
          1895,
          15104,
          341,
          257,
          707,
          857,
          281,
          652,
          309,
          1570,
          3657,
          13,
          1033,
          30,
          50764
        ]
      },
      {
        "avg_logprob": -0.21020745695307014,
        "compression_ratio": 1.560846560846561,
        "end": 5404.8,
        "id": 760,
        "no_speech_prob": 0.010328012518584728,
        "seek": 539180,
        "start": 5399.8,
        "temperature": 0,
        "text": " So, also notice the scientific method. Yeah.",
        "tokens": [
          50764,
          407,
          11,
          611,
          3449,
          264,
          8134,
          3170,
          13,
          865,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.21020745695307014,
        "compression_ratio": 1.560846560846561,
        "end": 5408.8,
        "id": 761,
        "no_speech_prob": 0.010328012518584728,
        "seek": 539180,
        "start": 5404.8,
        "temperature": 0,
        "text": " So, let's get a little bit better here.",
        "tokens": [
          51014,
          407,
          11,
          718,
          311,
          483,
          257,
          707,
          857,
          1101,
          510,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.21020745695307014,
        "compression_ratio": 1.560846560846561,
        "end": 5413.8,
        "id": 762,
        "no_speech_prob": 0.010328012518584728,
        "seek": 539180,
        "start": 5408.8,
        "temperature": 0,
        "text": " So, basically I want to have a... I'm going to write a function called like main...",
        "tokens": [
          51214,
          407,
          11,
          1936,
          286,
          528,
          281,
          362,
          257,
          485,
          286,
          478,
          516,
          281,
          2464,
          257,
          2445,
          1219,
          411,
          2135,
          485,
          51464
        ]
      },
      {
        "avg_logprob": -0.2371062755584717,
        "compression_ratio": 1.4960629921259843,
        "end": 5420.8,
        "id": 763,
        "no_speech_prob": 0.010986615903675556,
        "seek": 541380,
        "start": 5414.8,
        "temperature": 0,
        "text": " Which is a little bit silly. Function.",
        "tokens": [
          50414,
          3013,
          307,
          257,
          707,
          857,
          11774,
          13,
          11166,
          882,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.2371062755584717,
        "compression_ratio": 1.4960629921259843,
        "end": 5425.8,
        "id": 764,
        "no_speech_prob": 0.010986615903675556,
        "seek": 541380,
        "start": 5420.8,
        "temperature": 0,
        "text": " Function. And it's going to be an async function.",
        "tokens": [
          50714,
          11166,
          882,
          13,
          400,
          309,
          311,
          516,
          281,
          312,
          364,
          382,
          34015,
          2445,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.2371062755584717,
        "compression_ratio": 1.4960629921259843,
        "end": 5430.8,
        "id": 765,
        "no_speech_prob": 0.010986615903675556,
        "seek": 541380,
        "start": 5425.8,
        "temperature": 0,
        "text": " And the things that I'm going to do in it are...",
        "tokens": [
          50964,
          400,
          264,
          721,
          300,
          286,
          478,
          516,
          281,
          360,
          294,
          309,
          366,
          485,
          51214
        ]
      },
      {
        "avg_logprob": -0.2371062755584717,
        "compression_ratio": 1.4960629921259843,
        "end": 5437.8,
        "id": 766,
        "no_speech_prob": 0.010986615903675556,
        "seek": 541380,
        "start": 5430.8,
        "temperature": 0,
        "text": " Load all image data. Convert image data to a tensor.",
        "tokens": [
          51214,
          48408,
          439,
          3256,
          1412,
          13,
          2656,
          3281,
          3256,
          1412,
          281,
          257,
          40863,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.2349256185384897,
        "compression_ratio": 1.3898305084745763,
        "end": 5442.8,
        "id": 767,
        "no_speech_prob": 0.0212870966643095,
        "seek": 543780,
        "start": 5438.8,
        "temperature": 0,
        "text": " Train the model.",
        "tokens": [
          50414,
          28029,
          264,
          2316,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.2349256185384897,
        "compression_ratio": 1.3898305084745763,
        "end": 5447.8,
        "id": 768,
        "no_speech_prob": 0.0212870966643095,
        "seek": 543780,
        "start": 5442.8,
        "temperature": 0,
        "text": " Test the model.",
        "tokens": [
          50614,
          9279,
          264,
          2316,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.2349256185384897,
        "compression_ratio": 1.3898305084745763,
        "end": 5452.8,
        "id": 769,
        "no_speech_prob": 0.0212870966643095,
        "seek": 543780,
        "start": 5447.8,
        "temperature": 0,
        "text": " So, I've done everything but this last step of test the model.",
        "tokens": [
          50864,
          407,
          11,
          286,
          600,
          1096,
          1203,
          457,
          341,
          1036,
          1823,
          295,
          1500,
          264,
          2316,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.2349256185384897,
        "compression_ratio": 1.3898305084745763,
        "end": 5457.8,
        "id": 770,
        "no_speech_prob": 0.0212870966643095,
        "seek": 543780,
        "start": 5452.8,
        "temperature": 0,
        "text": " So, this async function load images.",
        "tokens": [
          51114,
          407,
          11,
          341,
          382,
          34015,
          2445,
          3677,
          5267,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.2349256185384897,
        "compression_ratio": 1.3898305084745763,
        "end": 5462.8,
        "id": 771,
        "no_speech_prob": 0.0212870966643095,
        "seek": 543780,
        "start": 5457.8,
        "temperature": 0,
        "text": " I can just say return x inputs.",
        "tokens": [
          51364,
          286,
          393,
          445,
          584,
          2736,
          2031,
          15743,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.2626902417438786,
        "compression_ratio": 1.2547169811320755,
        "end": 5469.8,
        "id": 772,
        "no_speech_prob": 0.020332006737589836,
        "seek": 546280,
        "start": 5462.8,
        "temperature": 0,
        "text": " Let's just call this all images.",
        "tokens": [
          50364,
          961,
          311,
          445,
          818,
          341,
          439,
          5267,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.2626902417438786,
        "compression_ratio": 1.2547169811320755,
        "end": 5476.8,
        "id": 773,
        "no_speech_prob": 0.020332006737589836,
        "seek": 546280,
        "start": 5472.8,
        "temperature": 0,
        "text": " And return all images.",
        "tokens": [
          50864,
          400,
          2736,
          439,
          5267,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.2626902417438786,
        "compression_ratio": 1.2547169811320755,
        "end": 5480.8,
        "id": 774,
        "no_speech_prob": 0.020332006737589836,
        "seek": 546280,
        "start": 5476.8,
        "temperature": 0,
        "text": " So, first thing I'm going to say is...",
        "tokens": [
          51064,
          407,
          11,
          700,
          551,
          286,
          478,
          516,
          281,
          584,
          307,
          485,
          51264
        ]
      },
      {
        "avg_logprob": -0.2626902417438786,
        "compression_ratio": 1.2547169811320755,
        "end": 5488.8,
        "id": 775,
        "no_speech_prob": 0.020332006737589836,
        "seek": 546280,
        "start": 5483.8,
        "temperature": 0,
        "text": " Const images equals await load images.",
        "tokens": [
          51414,
          8574,
          5267,
          6915,
          19670,
          3677,
          5267,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.2294607915376362,
        "compression_ratio": 1.4683544303797469,
        "end": 5491.8,
        "id": 776,
        "no_speech_prob": 0.018545787781476974,
        "seek": 548880,
        "start": 5488.8,
        "temperature": 0,
        "text": " Okay? Then...",
        "tokens": [
          50364,
          1033,
          30,
          1396,
          485,
          50514
        ]
      },
      {
        "avg_logprob": -0.2294607915376362,
        "compression_ratio": 1.4683544303797469,
        "end": 5496.8,
        "id": 777,
        "no_speech_prob": 0.018545787781476974,
        "seek": 548880,
        "start": 5493.8,
        "temperature": 0,
        "text": " And there was a question about why this is a 2D tensor.",
        "tokens": [
          50614,
          400,
          456,
          390,
          257,
          1168,
          466,
          983,
          341,
          307,
          257,
          568,
          35,
          40863,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.2294607915376362,
        "compression_ratio": 1.4683544303797469,
        "end": 5499.8,
        "id": 778,
        "no_speech_prob": 0.018545787781476974,
        "seek": 548880,
        "start": 5496.8,
        "temperature": 0,
        "text": " We'll talk about that. If the data is flattened into one dimension.",
        "tokens": [
          50764,
          492,
          603,
          751,
          466,
          300,
          13,
          759,
          264,
          1412,
          307,
          24183,
          292,
          666,
          472,
          10139,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.2294607915376362,
        "compression_ratio": 1.4683544303797469,
        "end": 5502.8,
        "id": 779,
        "no_speech_prob": 0.018545787781476974,
        "seek": 548880,
        "start": 5499.8,
        "temperature": 0,
        "text": " We'll talk about that in a moment.",
        "tokens": [
          50914,
          492,
          603,
          751,
          466,
          300,
          294,
          257,
          1623,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.2294607915376362,
        "compression_ratio": 1.4683544303797469,
        "end": 5505.8,
        "id": 780,
        "no_speech_prob": 0.018545787781476974,
        "seek": 548880,
        "start": 5502.8,
        "temperature": 0,
        "text": " So, let's do this.",
        "tokens": [
          51064,
          407,
          11,
          718,
          311,
          360,
          341,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.2294607915376362,
        "compression_ratio": 1.4683544303797469,
        "end": 5514.8,
        "id": 781,
        "no_speech_prob": 0.018545787781476974,
        "seek": 548880,
        "start": 5510.8,
        "temperature": 0,
        "text": " Does this need an await? No. It doesn't.",
        "tokens": [
          51464,
          4402,
          341,
          643,
          364,
          19670,
          30,
          883,
          13,
          467,
          1177,
          380,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.2367057991027832,
        "compression_ratio": 1.7578947368421052,
        "end": 5516.8,
        "id": 782,
        "no_speech_prob": 0.011868340894579887,
        "seek": 551480,
        "start": 5514.8,
        "temperature": 0,
        "text": " So, that's the training data.",
        "tokens": [
          50364,
          407,
          11,
          300,
          311,
          264,
          3097,
          1412,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.2367057991027832,
        "compression_ratio": 1.7578947368421052,
        "end": 5519.8,
        "id": 783,
        "no_speech_prob": 0.011868340894579887,
        "seek": 551480,
        "start": 5516.8,
        "temperature": 0,
        "text": " I should save some to be testing data.",
        "tokens": [
          50464,
          286,
          820,
          3155,
          512,
          281,
          312,
          4997,
          1412,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.2367057991027832,
        "compression_ratio": 1.7578947368421052,
        "end": 5522.8,
        "id": 784,
        "no_speech_prob": 0.011868340894579887,
        "seek": 551480,
        "start": 5519.8,
        "temperature": 0,
        "text": " But, I'll worry about that later.",
        "tokens": [
          50614,
          583,
          11,
          286,
          603,
          3292,
          466,
          300,
          1780,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.2367057991027832,
        "compression_ratio": 1.7578947368421052,
        "end": 5525.8,
        "id": 785,
        "no_speech_prob": 0.011868340894579887,
        "seek": 551480,
        "start": 5522.8,
        "temperature": 0,
        "text": " I'm just going to reuse. This is a very bad idea.",
        "tokens": [
          50764,
          286,
          478,
          445,
          516,
          281,
          26225,
          13,
          639,
          307,
          257,
          588,
          1578,
          1558,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.2367057991027832,
        "compression_ratio": 1.7578947368421052,
        "end": 5529.8,
        "id": 786,
        "no_speech_prob": 0.011868340894579887,
        "seek": 551480,
        "start": 5525.8,
        "temperature": 0,
        "text": " But, I'm going to reuse some of the training data for my testing of the model.",
        "tokens": [
          50914,
          583,
          11,
          286,
          478,
          516,
          281,
          26225,
          512,
          295,
          264,
          3097,
          1412,
          337,
          452,
          4997,
          295,
          264,
          2316,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.2367057991027832,
        "compression_ratio": 1.7578947368421052,
        "end": 5532.8,
        "id": 787,
        "no_speech_prob": 0.011868340894579887,
        "seek": 551480,
        "start": 5529.8,
        "temperature": 0,
        "text": " We can separate out. We can get new data later. I promise.",
        "tokens": [
          51114,
          492,
          393,
          4994,
          484,
          13,
          492,
          393,
          483,
          777,
          1412,
          1780,
          13,
          286,
          6228,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.2367057991027832,
        "compression_ratio": 1.7578947368421052,
        "end": 5539.8,
        "id": 788,
        "no_speech_prob": 0.011868340894579887,
        "seek": 551480,
        "start": 5535.8,
        "temperature": 0,
        "text": " And then, training the model is as follows.",
        "tokens": [
          51414,
          400,
          550,
          11,
          3097,
          264,
          2316,
          307,
          382,
          10002,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.30761625328842473,
        "compression_ratio": 1.3818181818181818,
        "end": 5548.8,
        "id": 789,
        "no_speech_prob": 0.019717035815119743,
        "seek": 553980,
        "start": 5539.8,
        "temperature": 0,
        "text": " Let's write a function called async train model.",
        "tokens": [
          50364,
          961,
          311,
          2464,
          257,
          2445,
          1219,
          382,
          34015,
          3847,
          2316,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.30761625328842473,
        "compression_ratio": 1.3818181818181818,
        "end": 5554.8,
        "id": 790,
        "no_speech_prob": 0.019717035815119743,
        "seek": 553980,
        "start": 5548.8,
        "temperature": 0,
        "text": " And, we're going to get data in.",
        "tokens": [
          50814,
          400,
          11,
          321,
          434,
          516,
          281,
          483,
          1412,
          294,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.30761625328842473,
        "compression_ratio": 1.3818181818181818,
        "end": 5558.8,
        "id": 791,
        "no_speech_prob": 0.019717035815119743,
        "seek": 553980,
        "start": 5554.8,
        "temperature": 0,
        "text": " I'm going to say await async function.",
        "tokens": [
          51114,
          286,
          478,
          516,
          281,
          584,
          19670,
          382,
          34015,
          2445,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.30761625328842473,
        "compression_ratio": 1.3818181818181818,
        "end": 5563.8,
        "id": 792,
        "no_speech_prob": 0.019717035815119743,
        "seek": 553980,
        "start": 5558.8,
        "temperature": 0,
        "text": " Await train model with x train.",
        "tokens": [
          51314,
          6381,
          1001,
          3847,
          2316,
          365,
          2031,
          3847,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.37847493334514337,
        "compression_ratio": 1.2173913043478262,
        "end": 5570.8,
        "id": 793,
        "no_speech_prob": 0.017985161393880844,
        "seek": 556380,
        "start": 5563.8,
        "temperature": 0,
        "text": " And then, is auto encoder still just a global variable?",
        "tokens": [
          50364,
          400,
          550,
          11,
          307,
          8399,
          2058,
          19866,
          920,
          445,
          257,
          4338,
          7006,
          30,
          50714
        ]
      },
      {
        "avg_logprob": -0.37847493334514337,
        "compression_ratio": 1.2173913043478262,
        "end": 5575.8,
        "id": 794,
        "no_speech_prob": 0.017985161393880844,
        "seek": 556380,
        "start": 5570.8,
        "temperature": 0,
        "text": " Yeah. So, it would make sense for me also to...",
        "tokens": [
          50714,
          865,
          13,
          407,
          11,
          309,
          576,
          652,
          2020,
          337,
          385,
          611,
          281,
          485,
          50964
        ]
      },
      {
        "avg_logprob": -0.37847493334514337,
        "compression_ratio": 1.2173913043478262,
        "end": 5587.8,
        "id": 795,
        "no_speech_prob": 0.017985161393880844,
        "seek": 556380,
        "start": 5581.8,
        "temperature": 0,
        "text": " Have a function that is build model.",
        "tokens": [
          51264,
          3560,
          257,
          2445,
          300,
          307,
          1322,
          2316,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.2877082824707031,
        "compression_ratio": 1.3032786885245902,
        "end": 5599.8,
        "id": 796,
        "no_speech_prob": 0.0005033340421505272,
        "seek": 559380,
        "start": 5593.8,
        "temperature": 0,
        "text": " So, basically...",
        "tokens": [
          50364,
          407,
          11,
          1936,
          485,
          50664
        ]
      },
      {
        "avg_logprob": -0.2877082824707031,
        "compression_ratio": 1.3032786885245902,
        "end": 5604.8,
        "id": 797,
        "no_speech_prob": 0.0005033340421505272,
        "seek": 559380,
        "start": 5599.8,
        "temperature": 0,
        "text": " Auto encoder is a sequential model.",
        "tokens": [
          50664,
          13738,
          2058,
          19866,
          307,
          257,
          42881,
          2316,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.2877082824707031,
        "compression_ratio": 1.3032786885245902,
        "end": 5608.8,
        "id": 798,
        "no_speech_prob": 0.0005033340421505272,
        "seek": 559380,
        "start": 5604.8,
        "temperature": 0,
        "text": " The build model function puts all the stuff into it.",
        "tokens": [
          50914,
          440,
          1322,
          2316,
          2445,
          8137,
          439,
          264,
          1507,
          666,
          309,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.2877082824707031,
        "compression_ratio": 1.3032786885245902,
        "end": 5611.8,
        "id": 799,
        "no_speech_prob": 0.0005033340421505272,
        "seek": 559380,
        "start": 5608.8,
        "temperature": 0,
        "text": " Why I'm...",
        "tokens": [
          51114,
          1545,
          286,
          478,
          485,
          51264
        ]
      },
      {
        "avg_logprob": -0.2877082824707031,
        "compression_ratio": 1.3032786885245902,
        "end": 5616.8,
        "id": 800,
        "no_speech_prob": 0.0005033340421505272,
        "seek": 559380,
        "start": 5611.8,
        "temperature": 0,
        "text": " So, I should be calling build model first.",
        "tokens": [
          51264,
          407,
          11,
          286,
          820,
          312,
          5141,
          1322,
          2316,
          700,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.2699160575866699,
        "compression_ratio": 0.9868421052631579,
        "end": 5626.8,
        "id": 801,
        "no_speech_prob": 0.001133562414906919,
        "seek": 562380,
        "start": 5623.8,
        "temperature": 0,
        "text": " Model.",
        "tokens": [
          50364,
          17105,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.2699160575866699,
        "compression_ratio": 0.9868421052631579,
        "end": 5629.8,
        "id": 802,
        "no_speech_prob": 0.001133562414906919,
        "seek": 562380,
        "start": 5626.8,
        "temperature": 0,
        "text": " What did I do wrong here?",
        "tokens": [
          50514,
          708,
          630,
          286,
          360,
          2085,
          510,
          30,
          50664
        ]
      },
      {
        "avg_logprob": -0.2699160575866699,
        "compression_ratio": 0.9868421052631579,
        "end": 5632.8,
        "id": 803,
        "no_speech_prob": 0.001133562414906919,
        "seek": 562380,
        "start": 5629.8,
        "temperature": 0,
        "text": " There we go.",
        "tokens": [
          50664,
          821,
          321,
          352,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.2699160575866699,
        "compression_ratio": 0.9868421052631579,
        "end": 5644.8,
        "id": 804,
        "no_speech_prob": 0.001133562414906919,
        "seek": 562380,
        "start": 5641.8,
        "temperature": 0,
        "text": " So, let's bring this up here.",
        "tokens": [
          51264,
          407,
          11,
          718,
          311,
          1565,
          341,
          493,
          510,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.3759470525777565,
        "compression_ratio": 1.256198347107438,
        "end": 5649.8,
        "id": 805,
        "no_speech_prob": 0.0006666973349638283,
        "seek": 564480,
        "start": 5645.8,
        "temperature": 0,
        "text": " Build model.",
        "tokens": [
          50414,
          11875,
          2316,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.3759470525777565,
        "compression_ratio": 1.256198347107438,
        "end": 5653.8,
        "id": 806,
        "no_speech_prob": 0.0006666973349638283,
        "seek": 564480,
        "start": 5649.8,
        "temperature": 0,
        "text": " Auto encoder.",
        "tokens": [
          50614,
          13738,
          2058,
          19866,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.3759470525777565,
        "compression_ratio": 1.256198347107438,
        "end": 5659.8,
        "id": 807,
        "no_speech_prob": 0.0006666973349638283,
        "seek": 564480,
        "start": 5653.8,
        "temperature": 0,
        "text": " Again, I'm not so sure this really makes a lot of sense the way I'm doing this.",
        "tokens": [
          50814,
          3764,
          11,
          286,
          478,
          406,
          370,
          988,
          341,
          534,
          1669,
          257,
          688,
          295,
          2020,
          264,
          636,
          286,
          478,
          884,
          341,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.3759470525777565,
        "compression_ratio": 1.256198347107438,
        "end": 5669.8,
        "id": 808,
        "no_speech_prob": 0.0006666973349638283,
        "seek": 564480,
        "start": 5665.8,
        "temperature": 0,
        "text": " So, now, I need...",
        "tokens": [
          51414,
          407,
          11,
          586,
          11,
          286,
          643,
          485,
          51614
        ]
      },
      {
        "avg_logprob": -0.3759470525777565,
        "compression_ratio": 1.256198347107438,
        "end": 5673.8,
        "id": 809,
        "no_speech_prob": 0.0006666973349638283,
        "seek": 564480,
        "start": 5669.8,
        "temperature": 0,
        "text": " To pass this as arguments.",
        "tokens": [
          51614,
          1407,
          1320,
          341,
          382,
          12869,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.2173214488559299,
        "compression_ratio": 1.3,
        "end": 5679.8,
        "id": 810,
        "no_speech_prob": 0.000028857110009994358,
        "seek": 567380,
        "start": 5674.8,
        "temperature": 0,
        "text": " This is pretty arbitrary what I'm doing.",
        "tokens": [
          50414,
          639,
          307,
          1238,
          23211,
          437,
          286,
          478,
          884,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.2173214488559299,
        "compression_ratio": 1.3,
        "end": 5683.8,
        "id": 811,
        "no_speech_prob": 0.000028857110009994358,
        "seek": 567380,
        "start": 5679.8,
        "temperature": 0,
        "text": " But, I'm trying to get rid of sort of global variables.",
        "tokens": [
          50664,
          583,
          11,
          286,
          478,
          1382,
          281,
          483,
          3973,
          295,
          1333,
          295,
          4338,
          9102,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.2173214488559299,
        "compression_ratio": 1.3,
        "end": 5689.8,
        "id": 812,
        "no_speech_prob": 0.000028857110009994358,
        "seek": 567380,
        "start": 5683.8,
        "temperature": 0,
        "text": " And so, now, I've created the sequential model.",
        "tokens": [
          50864,
          400,
          370,
          11,
          586,
          11,
          286,
          600,
          2942,
          264,
          42881,
          2316,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.2173214488559299,
        "compression_ratio": 1.3,
        "end": 5696.8,
        "id": 813,
        "no_speech_prob": 0.000028857110009994358,
        "seek": 567380,
        "start": 5692.8,
        "temperature": 0,
        "text": " I think actually I'd like to do this.",
        "tokens": [
          51314,
          286,
          519,
          767,
          286,
          1116,
          411,
          281,
          360,
          341,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.2644990539550781,
        "compression_ratio": 1.4689655172413794,
        "end": 5707.8,
        "id": 814,
        "no_speech_prob": 0.011867709457874298,
        "seek": 570380,
        "start": 5703.8,
        "temperature": 0,
        "text": " And then, return it.",
        "tokens": [
          50364,
          400,
          550,
          11,
          2736,
          309,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.2644990539550781,
        "compression_ratio": 1.4689655172413794,
        "end": 5711.8,
        "id": 815,
        "no_speech_prob": 0.011867709457874298,
        "seek": 570380,
        "start": 5707.8,
        "temperature": 0,
        "text": " So, what am I doing?",
        "tokens": [
          50564,
          407,
          11,
          437,
          669,
          286,
          884,
          30,
          50764
        ]
      },
      {
        "avg_logprob": -0.2644990539550781,
        "compression_ratio": 1.4689655172413794,
        "end": 5714.8,
        "id": 816,
        "no_speech_prob": 0.011867709457874298,
        "seek": 570380,
        "start": 5711.8,
        "temperature": 0,
        "text": " I am...",
        "tokens": [
          50764,
          286,
          669,
          485,
          50914
        ]
      },
      {
        "avg_logprob": -0.2644990539550781,
        "compression_ratio": 1.4689655172413794,
        "end": 5718.8,
        "id": 817,
        "no_speech_prob": 0.011867709457874298,
        "seek": 570380,
        "start": 5714.8,
        "temperature": 0,
        "text": " Build the model.",
        "tokens": [
          50914,
          11875,
          264,
          2316,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.2644990539550781,
        "compression_ratio": 1.4689655172413794,
        "end": 5721.8,
        "id": 818,
        "no_speech_prob": 0.011867709457874298,
        "seek": 570380,
        "start": 5718.8,
        "temperature": 0,
        "text": " Load the image data.",
        "tokens": [
          51114,
          48408,
          264,
          3256,
          1412,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.2644990539550781,
        "compression_ratio": 1.4689655172413794,
        "end": 5724.8,
        "id": 819,
        "no_speech_prob": 0.011867709457874298,
        "seek": 570380,
        "start": 5721.8,
        "temperature": 0,
        "text": " Convert the image data to a tensor.",
        "tokens": [
          51264,
          2656,
          3281,
          264,
          3256,
          1412,
          281,
          257,
          40863,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.2644990539550781,
        "compression_ratio": 1.4689655172413794,
        "end": 5727.8,
        "id": 820,
        "no_speech_prob": 0.011867709457874298,
        "seek": 570380,
        "start": 5724.8,
        "temperature": 0,
        "text": " So, that I can train the model with that data.",
        "tokens": [
          51414,
          407,
          11,
          300,
          286,
          393,
          3847,
          264,
          2316,
          365,
          300,
          1412,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.2644990539550781,
        "compression_ratio": 1.4689655172413794,
        "end": 5730.8,
        "id": 821,
        "no_speech_prob": 0.011867709457874298,
        "seek": 570380,
        "start": 5727.8,
        "temperature": 0,
        "text": " Then, let's just make sure this all works.",
        "tokens": [
          51564,
          1396,
          11,
          718,
          311,
          445,
          652,
          988,
          341,
          439,
          1985,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.3953169620398319,
        "compression_ratio": 1.6,
        "end": 5734.8,
        "id": 822,
        "no_speech_prob": 0.002934846794232726,
        "seek": 573080,
        "start": 5730.8,
        "temperature": 0,
        "text": " I think I have to call this function.",
        "tokens": [
          50364,
          286,
          519,
          286,
          362,
          281,
          818,
          341,
          2445,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.3953169620398319,
        "compression_ratio": 1.6,
        "end": 5742.8,
        "id": 823,
        "no_speech_prob": 0.002934846794232726,
        "seek": 573080,
        "start": 5738.8,
        "temperature": 0,
        "text": " Alright, so, everything still works.",
        "tokens": [
          50764,
          2798,
          11,
          370,
          11,
          1203,
          920,
          1985,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.3953169620398319,
        "compression_ratio": 1.6,
        "end": 5745.8,
        "id": 824,
        "no_speech_prob": 0.002934846794232726,
        "seek": 573080,
        "start": 5742.8,
        "temperature": 0,
        "text": " Everything still works. Training the model.",
        "tokens": [
          50964,
          5471,
          920,
          1985,
          13,
          20620,
          264,
          2316,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.3953169620398319,
        "compression_ratio": 1.6,
        "end": 5749.8,
        "id": 825,
        "no_speech_prob": 0.002934846794232726,
        "seek": 573080,
        "start": 5745.8,
        "temperature": 0,
        "text": " Then, I would like to test the model.",
        "tokens": [
          51114,
          1396,
          11,
          286,
          576,
          411,
          281,
          1500,
          264,
          2316,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.3953169620398319,
        "compression_ratio": 1.6,
        "end": 5753.8,
        "id": 826,
        "no_speech_prob": 0.002934846794232726,
        "seek": 573080,
        "start": 5749.8,
        "temperature": 0,
        "text": " So, I need one image.",
        "tokens": [
          51314,
          407,
          11,
          286,
          643,
          472,
          3256,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.3953169620398319,
        "compression_ratio": 1.6,
        "end": 5757.8,
        "id": 827,
        "no_speech_prob": 0.002934846794232726,
        "seek": 573080,
        "start": 5753.8,
        "temperature": 0,
        "text": " And, I'm going to call this function.",
        "tokens": [
          51514,
          400,
          11,
          286,
          478,
          516,
          281,
          818,
          341,
          2445,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.21381668195332568,
        "compression_ratio": 1.4350649350649352,
        "end": 5761.8,
        "id": 828,
        "no_speech_prob": 0.0001852254499681294,
        "seek": 575780,
        "start": 5757.8,
        "temperature": 0,
        "text": " So, I need one image.",
        "tokens": [
          50364,
          407,
          11,
          286,
          643,
          472,
          3256,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.21381668195332568,
        "compression_ratio": 1.4350649350649352,
        "end": 5765.8,
        "id": 829,
        "no_speech_prob": 0.0001852254499681294,
        "seek": 575780,
        "start": 5761.8,
        "temperature": 0,
        "text": " So, all the images are here.",
        "tokens": [
          50564,
          407,
          11,
          439,
          264,
          5267,
          366,
          510,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.21381668195332568,
        "compression_ratio": 1.4350649350649352,
        "end": 5771.8,
        "id": 830,
        "no_speech_prob": 0.0001852254499681294,
        "seek": 575780,
        "start": 5769.8,
        "temperature": 0,
        "text": " So, what I could do... Let's do the following.",
        "tokens": [
          50964,
          407,
          11,
          437,
          286,
          727,
          360,
          485,
          961,
          311,
          360,
          264,
          3480,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.21381668195332568,
        "compression_ratio": 1.4350649350649352,
        "end": 5774.8,
        "id": 831,
        "no_speech_prob": 0.0001852254499681294,
        "seek": 575780,
        "start": 5771.8,
        "temperature": 0,
        "text": " Let's be a little more rigorous about this.",
        "tokens": [
          51064,
          961,
          311,
          312,
          257,
          707,
          544,
          29882,
          466,
          341,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.21381668195332568,
        "compression_ratio": 1.4350649350649352,
        "end": 5781.8,
        "id": 832,
        "no_speech_prob": 0.0001852254499681294,
        "seek": 575780,
        "start": 5774.8,
        "temperature": 0,
        "text": " I'm going to rerun my training data creation.",
        "tokens": [
          51214,
          286,
          478,
          516,
          281,
          43819,
          409,
          452,
          3097,
          1412,
          8016,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.21381668195332568,
        "compression_ratio": 1.4350649350649352,
        "end": 5783.8,
        "id": 833,
        "no_speech_prob": 0.0001852254499681294,
        "seek": 575780,
        "start": 5781.8,
        "temperature": 0,
        "text": " And, make 500 images.",
        "tokens": [
          51564,
          400,
          11,
          652,
          5923,
          5267,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.21381668195332568,
        "compression_ratio": 1.4350649350649352,
        "end": 5786.8,
        "id": 834,
        "no_speech_prob": 0.0001852254499681294,
        "seek": 575780,
        "start": 5783.8,
        "temperature": 0,
        "text": " 550 images.",
        "tokens": [
          51664,
          42514,
          5267,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.2516724081600414,
        "compression_ratio": 1.413533834586466,
        "end": 5790.8,
        "id": 835,
        "no_speech_prob": 0.0004173032066319138,
        "seek": 578780,
        "start": 5788.8,
        "temperature": 0,
        "text": " Oops, that's not right.",
        "tokens": [
          50414,
          21726,
          11,
          300,
          311,
          406,
          558,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.2516724081600414,
        "compression_ratio": 1.413533834586466,
        "end": 5794.8,
        "id": 836,
        "no_speech_prob": 0.0004173032066319138,
        "seek": 578780,
        "start": 5790.8,
        "temperature": 0,
        "text": " I'm going to make 550 images.",
        "tokens": [
          50514,
          286,
          478,
          516,
          281,
          652,
          42514,
          5267,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.2516724081600414,
        "compression_ratio": 1.413533834586466,
        "end": 5796.8,
        "id": 837,
        "no_speech_prob": 0.0004173032066319138,
        "seek": 578780,
        "start": 5794.8,
        "temperature": 0,
        "text": " They're all squares.",
        "tokens": [
          50714,
          814,
          434,
          439,
          19368,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.2516724081600414,
        "compression_ratio": 1.413533834586466,
        "end": 5801.8,
        "id": 838,
        "no_speech_prob": 0.0004173032066319138,
        "seek": 578780,
        "start": 5799.8,
        "temperature": 0,
        "text": " Okay, we're almost there.",
        "tokens": [
          50964,
          1033,
          11,
          321,
          434,
          1920,
          456,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.2516724081600414,
        "compression_ratio": 1.413533834586466,
        "end": 5804.8,
        "id": 839,
        "no_speech_prob": 0.0004173032066319138,
        "seek": 578780,
        "start": 5801.8,
        "temperature": 0,
        "text": " Making 550 squares.",
        "tokens": [
          51064,
          14595,
          42514,
          19368,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.2516724081600414,
        "compression_ratio": 1.413533834586466,
        "end": 5806.8,
        "id": 840,
        "no_speech_prob": 0.0004173032066319138,
        "seek": 578780,
        "start": 5804.8,
        "temperature": 0,
        "text": " All done.",
        "tokens": [
          51214,
          1057,
          1096,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.2516724081600414,
        "compression_ratio": 1.413533834586466,
        "end": 5808.8,
        "id": 841,
        "no_speech_prob": 0.0004173032066319138,
        "seek": 578780,
        "start": 5806.8,
        "temperature": 0,
        "text": " I'm going to get this data.",
        "tokens": [
          51314,
          286,
          478,
          516,
          281,
          483,
          341,
          1412,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.2516724081600414,
        "compression_ratio": 1.413533834586466,
        "end": 5812.8,
        "id": 842,
        "no_speech_prob": 0.0004173032066319138,
        "seek": 578780,
        "start": 5808.8,
        "temperature": 0,
        "text": " I'm going to bring it into...",
        "tokens": [
          51414,
          286,
          478,
          516,
          281,
          1565,
          309,
          666,
          485,
          51614
        ]
      },
      {
        "avg_logprob": -0.27396536607008715,
        "compression_ratio": 1.5391304347826087,
        "end": 5817.8,
        "id": 843,
        "no_speech_prob": 0.0020828561391681433,
        "seek": 581280,
        "start": 5813.8,
        "temperature": 0,
        "text": " The autoencoder project.",
        "tokens": [
          50414,
          440,
          8399,
          22660,
          19866,
          1716,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.27396536607008715,
        "compression_ratio": 1.5391304347826087,
        "end": 5820.8,
        "id": 844,
        "no_speech_prob": 0.0020828561391681433,
        "seek": 581280,
        "start": 5817.8,
        "temperature": 0,
        "text": " Going to replace it.",
        "tokens": [
          50614,
          10963,
          281,
          7406,
          309,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.27396536607008715,
        "compression_ratio": 1.5391304347826087,
        "end": 5824.8,
        "id": 845,
        "no_speech_prob": 0.0020828561391681433,
        "seek": 581280,
        "start": 5820.8,
        "temperature": 0,
        "text": " And, I'm going to rerun this sketch.",
        "tokens": [
          50764,
          400,
          11,
          286,
          478,
          516,
          281,
          43819,
          409,
          341,
          12325,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.27396536607008715,
        "compression_ratio": 1.5391304347826087,
        "end": 5825.8,
        "id": 846,
        "no_speech_prob": 0.0020828561391681433,
        "seek": 581280,
        "start": 5824.8,
        "temperature": 0,
        "text": " It's not a sketch.",
        "tokens": [
          50964,
          467,
          311,
          406,
          257,
          12325,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.27396536607008715,
        "compression_ratio": 1.5391304347826087,
        "end": 5827.8,
        "id": 847,
        "no_speech_prob": 0.0020828561391681433,
        "seek": 581280,
        "start": 5825.8,
        "temperature": 0,
        "text": " I'm going to rerun this code.",
        "tokens": [
          51014,
          286,
          478,
          516,
          281,
          43819,
          409,
          341,
          3089,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.27396536607008715,
        "compression_ratio": 1.5391304347826087,
        "end": 5835.8,
        "id": 848,
        "no_speech_prob": 0.0020828561391681433,
        "seek": 581280,
        "start": 5833.8,
        "temperature": 0,
        "text": " With...",
        "tokens": [
          51414,
          2022,
          485,
          51514
        ]
      },
      {
        "avg_logprob": -0.27396536607008715,
        "compression_ratio": 1.5391304347826087,
        "end": 5840.8,
        "id": 849,
        "no_speech_prob": 0.0020828561391681433,
        "seek": 581280,
        "start": 5838.8,
        "temperature": 0,
        "text": " I'm going to put an argument in here.",
        "tokens": [
          51664,
          286,
          478,
          516,
          281,
          829,
          364,
          6770,
          294,
          510,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.2412435091458834,
        "compression_ratio": 1.4252873563218391,
        "end": 5842.8,
        "id": 850,
        "no_speech_prob": 0.014955077320337296,
        "seek": 584080,
        "start": 5840.8,
        "temperature": 0,
        "text": " I'm going to put an argument in here.",
        "tokens": [
          50364,
          286,
          478,
          516,
          281,
          829,
          364,
          6770,
          294,
          510,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.2412435091458834,
        "compression_ratio": 1.4252873563218391,
        "end": 5844.8,
        "id": 851,
        "no_speech_prob": 0.014955077320337296,
        "seek": 584080,
        "start": 5842.8,
        "temperature": 0,
        "text": " For 500 images.",
        "tokens": [
          50464,
          1171,
          5923,
          5267,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.2412435091458834,
        "compression_ratio": 1.4252873563218391,
        "end": 5856.8,
        "id": 852,
        "no_speech_prob": 0.014955077320337296,
        "seek": 584080,
        "start": 5854.8,
        "temperature": 0,
        "text": " Let's just see how this goes.",
        "tokens": [
          51064,
          961,
          311,
          445,
          536,
          577,
          341,
          1709,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.2412435091458834,
        "compression_ratio": 1.4252873563218391,
        "end": 5858.8,
        "id": 853,
        "no_speech_prob": 0.014955077320337296,
        "seek": 584080,
        "start": 5856.8,
        "temperature": 0,
        "text": " Ooh, loss is getting better.",
        "tokens": [
          51164,
          7951,
          11,
          4470,
          307,
          1242,
          1101,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.2412435091458834,
        "compression_ratio": 1.4252873563218391,
        "end": 5862.8,
        "id": 854,
        "no_speech_prob": 0.014955077320337296,
        "seek": 584080,
        "start": 5858.8,
        "temperature": 0,
        "text": " When I've got 500 images, I'm able to get the loss much further down.",
        "tokens": [
          51264,
          1133,
          286,
          600,
          658,
          5923,
          5267,
          11,
          286,
          478,
          1075,
          281,
          483,
          264,
          4470,
          709,
          3052,
          760,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.2412435091458834,
        "compression_ratio": 1.4252873563218391,
        "end": 5867.8,
        "id": 855,
        "no_speech_prob": 0.014955077320337296,
        "seek": 584080,
        "start": 5862.8,
        "temperature": 0,
        "text": " Although, it seems to have settled by the time I'm at 100 epochs.",
        "tokens": [
          51464,
          5780,
          11,
          309,
          2544,
          281,
          362,
          14819,
          538,
          264,
          565,
          286,
          478,
          412,
          2319,
          30992,
          28346,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.21645291192190988,
        "compression_ratio": 1.387878787878788,
        "end": 5876.8,
        "id": 856,
        "no_speech_prob": 0.0012255399487912655,
        "seek": 586780,
        "start": 5868.8,
        "temperature": 0,
        "text": " So, certainly, there's not a huge reason for me to train it for that long.",
        "tokens": [
          50414,
          407,
          11,
          3297,
          11,
          456,
          311,
          406,
          257,
          2603,
          1778,
          337,
          385,
          281,
          3847,
          309,
          337,
          300,
          938,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.21645291192190988,
        "compression_ratio": 1.387878787878788,
        "end": 5879.8,
        "id": 857,
        "no_speech_prob": 0.0012255399487912655,
        "seek": 586780,
        "start": 5876.8,
        "temperature": 0,
        "text": " Let's just say 75 to make things run faster.",
        "tokens": [
          50814,
          961,
          311,
          445,
          584,
          9562,
          281,
          652,
          721,
          1190,
          4663,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.21645291192190988,
        "compression_ratio": 1.387878787878788,
        "end": 5886.8,
        "id": 858,
        "no_speech_prob": 0.0012255399487912655,
        "seek": 586780,
        "start": 5879.8,
        "temperature": 0,
        "text": " And, I think actually what I want to do is load all 550.",
        "tokens": [
          50964,
          400,
          11,
          286,
          519,
          767,
          437,
          286,
          528,
          281,
          360,
          307,
          3677,
          439,
          42514,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.21645291192190988,
        "compression_ratio": 1.387878787878788,
        "end": 5894.8,
        "id": 859,
        "no_speech_prob": 0.0012255399487912655,
        "seek": 586780,
        "start": 5886.8,
        "temperature": 0,
        "text": " But, I want to take out just a slice of them, right?",
        "tokens": [
          51314,
          583,
          11,
          286,
          528,
          281,
          747,
          484,
          445,
          257,
          13153,
          295,
          552,
          11,
          558,
          30,
          51714
        ]
      },
      {
        "avg_logprob": -0.2461936508399853,
        "compression_ratio": 1.4267515923566878,
        "end": 5898.8,
        "id": 860,
        "no_speech_prob": 0.008315595798194408,
        "seek": 589480,
        "start": 5894.8,
        "temperature": 0,
        "text": " So, how do you do a slice JavaScript array?",
        "tokens": [
          50364,
          407,
          11,
          577,
          360,
          291,
          360,
          257,
          13153,
          15778,
          10225,
          30,
          50564
        ]
      },
      {
        "avg_logprob": -0.2461936508399853,
        "compression_ratio": 1.4267515923566878,
        "end": 5906.8,
        "id": 861,
        "no_speech_prob": 0.008315595798194408,
        "seek": 589480,
        "start": 5901.8,
        "temperature": 0,
        "text": " Slice returns a shallow copy of a portion array into a new array object.",
        "tokens": [
          50714,
          6187,
          573,
          11247,
          257,
          20488,
          5055,
          295,
          257,
          8044,
          10225,
          666,
          257,
          777,
          10225,
          2657,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.2461936508399853,
        "compression_ratio": 1.4267515923566878,
        "end": 5911.8,
        "id": 862,
        "no_speech_prob": 0.008315595798194408,
        "seek": 589480,
        "start": 5906.8,
        "temperature": 0,
        "text": " So, if I wanted just 500, I would do this.",
        "tokens": [
          50964,
          407,
          11,
          498,
          286,
          1415,
          445,
          5923,
          11,
          286,
          576,
          360,
          341,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.2461936508399853,
        "compression_ratio": 1.4267515923566878,
        "end": 5920.8,
        "id": 863,
        "no_speech_prob": 0.008315595798194408,
        "seek": 589480,
        "start": 5912.8,
        "temperature": 0,
        "text": " And then, if I want to do test, X test, I could create a tensor.",
        "tokens": [
          51264,
          400,
          550,
          11,
          498,
          286,
          528,
          281,
          360,
          1500,
          11,
          1783,
          1500,
          11,
          286,
          727,
          1884,
          257,
          40863,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.250397703382704,
        "compression_ratio": 1.2260869565217392,
        "end": 5928.8,
        "id": 864,
        "no_speech_prob": 0.0015247755218297243,
        "seek": 592080,
        "start": 5921.8,
        "temperature": 0,
        "text": " Out of those same images, but slice from 500 to 550, right?",
        "tokens": [
          50414,
          5925,
          295,
          729,
          912,
          5267,
          11,
          457,
          13153,
          490,
          5923,
          281,
          42514,
          11,
          558,
          30,
          50764
        ]
      },
      {
        "avg_logprob": -0.250397703382704,
        "compression_ratio": 1.2260869565217392,
        "end": 5941.8,
        "id": 865,
        "no_speech_prob": 0.0015247755218297243,
        "seek": 592080,
        "start": 5934.8,
        "temperature": 0,
        "text": " Let's skip training the model for a second.",
        "tokens": [
          51064,
          961,
          311,
          10023,
          3097,
          264,
          2316,
          337,
          257,
          1150,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.250397703382704,
        "compression_ratio": 1.2260869565217392,
        "end": 5947.8,
        "id": 866,
        "no_speech_prob": 0.0015247755218297243,
        "seek": 592080,
        "start": 5945.8,
        "temperature": 0,
        "text": " Alright, right?",
        "tokens": [
          51614,
          2798,
          11,
          558,
          30,
          51714
        ]
      },
      {
        "avg_logprob": -0.250397703382704,
        "compression_ratio": 1.2260869565217392,
        "end": 5948.8,
        "id": 867,
        "no_speech_prob": 0.0015247755218297243,
        "seek": 592080,
        "start": 5947.8,
        "temperature": 0,
        "text": " So, this makes sense.",
        "tokens": [
          51714,
          407,
          11,
          341,
          1669,
          2020,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.26901674270629883,
        "compression_ratio": 1,
        "end": 5953.8,
        "id": 868,
        "no_speech_prob": 0.006192967761307955,
        "seek": 594880,
        "start": 5948.8,
        "temperature": 0,
        "text": " I've got 500 training images, 50 test images.",
        "tokens": [
          50364,
          286,
          600,
          658,
          5923,
          3097,
          5267,
          11,
          2625,
          1500,
          5267,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.26901674270629883,
        "compression_ratio": 1,
        "end": 5964.8,
        "id": 869,
        "no_speech_prob": 0.006192967761307955,
        "seek": 594880,
        "start": 5956.8,
        "temperature": 0,
        "text": " So, now, I should be able to say,",
        "tokens": [
          50764,
          407,
          11,
          586,
          11,
          286,
          820,
          312,
          1075,
          281,
          584,
          11,
          51164
        ]
      },
      {
        "avg_logprob": -0.301673272076775,
        "compression_ratio": 1.0493827160493827,
        "end": 5977.8,
        "id": 870,
        "no_speech_prob": 0.11436299979686737,
        "seek": 596480,
        "start": 5964.8,
        "temperature": 0,
        "text": " Auto encoder predict X test.",
        "tokens": [
          50364,
          13738,
          2058,
          19866,
          6069,
          1783,
          1500,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.301673272076775,
        "compression_ratio": 1.0493827160493827,
        "end": 5981.8,
        "id": 871,
        "no_speech_prob": 0.11436299979686737,
        "seek": 596480,
        "start": 5980.8,
        "temperature": 0,
        "text": " Let's see.",
        "tokens": [
          51164,
          961,
          311,
          536,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.301673272076775,
        "compression_ratio": 1.0493827160493827,
        "end": 5983.8,
        "id": 872,
        "no_speech_prob": 0.11436299979686737,
        "seek": 596480,
        "start": 5982.8,
        "temperature": 0,
        "text": " After it's trained.",
        "tokens": [
          51264,
          2381,
          309,
          311,
          8895,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.301673272076775,
        "compression_ratio": 1.0493827160493827,
        "end": 5986.8,
        "id": 873,
        "no_speech_prob": 0.11436299979686737,
        "seek": 596480,
        "start": 5983.8,
        "temperature": 0,
        "text": " Is that all I need to do?",
        "tokens": [
          51314,
          1119,
          300,
          439,
          286,
          643,
          281,
          360,
          30,
          51464
        ]
      },
      {
        "avg_logprob": -0.27828209975670126,
        "compression_ratio": 1.4796747967479675,
        "end": 5993.8,
        "id": 874,
        "no_speech_prob": 0.19434644281864166,
        "seek": 598680,
        "start": 5986.8,
        "temperature": 0,
        "text": " Auto predict encoded images.",
        "tokens": [
          50364,
          13738,
          6069,
          2058,
          12340,
          5267,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.27828209975670126,
        "compression_ratio": 1.4796747967479675,
        "end": 6000.8,
        "id": 875,
        "no_speech_prob": 0.19434644281864166,
        "seek": 598680,
        "start": 5994.8,
        "temperature": 0,
        "text": " Oh, it's got the encoder and the decoder as separate things.",
        "tokens": [
          50764,
          876,
          11,
          309,
          311,
          658,
          264,
          2058,
          19866,
          293,
          264,
          979,
          19866,
          382,
          4994,
          721,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.27828209975670126,
        "compression_ratio": 1.4796747967479675,
        "end": 6007.8,
        "id": 876,
        "no_speech_prob": 0.19434644281864166,
        "seek": 598680,
        "start": 6004.8,
        "temperature": 0,
        "text": " Oh, it made two separate, it made an encoder model.",
        "tokens": [
          51264,
          876,
          11,
          309,
          1027,
          732,
          4994,
          11,
          309,
          1027,
          364,
          2058,
          19866,
          2316,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.27828209975670126,
        "compression_ratio": 1.4796747967479675,
        "end": 6010.8,
        "id": 877,
        "no_speech_prob": 0.19434644281864166,
        "seek": 598680,
        "start": 6008.8,
        "temperature": 0,
        "text": " Anyway, I'm going to do this my own way.",
        "tokens": [
          51464,
          5684,
          11,
          286,
          478,
          516,
          281,
          360,
          341,
          452,
          1065,
          636,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.2588279924894634,
        "compression_ratio": 1.4278846153846154,
        "end": 6018.8,
        "id": 878,
        "no_speech_prob": 0.06097065657377243,
        "seek": 601080,
        "start": 6011.8,
        "temperature": 0,
        "text": " Eventually, I want to chop off the encoder and just feed in noise from the middle layer.",
        "tokens": [
          50414,
          17586,
          11,
          286,
          528,
          281,
          7931,
          766,
          264,
          2058,
          19866,
          293,
          445,
          3154,
          294,
          5658,
          490,
          264,
          2808,
          4583,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.2588279924894634,
        "compression_ratio": 1.4278846153846154,
        "end": 6021.8,
        "id": 879,
        "no_speech_prob": 0.06097065657377243,
        "seek": 601080,
        "start": 6018.8,
        "temperature": 0,
        "text": " But, let's just sort of see what happens here.",
        "tokens": [
          50764,
          583,
          11,
          718,
          311,
          445,
          1333,
          295,
          536,
          437,
          2314,
          510,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.2588279924894634,
        "compression_ratio": 1.4278846153846154,
        "end": 6027.8,
        "id": 880,
        "no_speech_prob": 0.06097065657377243,
        "seek": 601080,
        "start": 6025.8,
        "temperature": 0,
        "text": " So, I'm training and then, aha!",
        "tokens": [
          51114,
          407,
          11,
          286,
          478,
          3097,
          293,
          550,
          11,
          47340,
          0,
          51214
        ]
      },
      {
        "avg_logprob": -0.2588279924894634,
        "compression_ratio": 1.4278846153846154,
        "end": 6028.8,
        "id": 881,
        "no_speech_prob": 0.06097065657377243,
        "seek": 601080,
        "start": 6027.8,
        "temperature": 0,
        "text": " Look, look, look!",
        "tokens": [
          51214,
          2053,
          11,
          574,
          11,
          574,
          0,
          51264
        ]
      },
      {
        "avg_logprob": -0.2588279924894634,
        "compression_ratio": 1.4278846153846154,
        "end": 6030.8,
        "id": 882,
        "no_speech_prob": 0.06097065657377243,
        "seek": 601080,
        "start": 6029.8,
        "temperature": 0,
        "text": " We're getting images out.",
        "tokens": [
          51314,
          492,
          434,
          1242,
          5267,
          484,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.2588279924894634,
        "compression_ratio": 1.4278846153846154,
        "end": 6031.8,
        "id": 883,
        "no_speech_prob": 0.06097065657377243,
        "seek": 601080,
        "start": 6030.8,
        "temperature": 0,
        "text": " Yes!",
        "tokens": [
          51364,
          1079,
          0,
          51414
        ]
      },
      {
        "avg_logprob": -0.2588279924894634,
        "compression_ratio": 1.4278846153846154,
        "end": 6037.8,
        "id": 884,
        "no_speech_prob": 0.06097065657377243,
        "seek": 601080,
        "start": 6031.8,
        "temperature": 0,
        "text": " Now, we just need to turn those into images.",
        "tokens": [
          51414,
          823,
          11,
          321,
          445,
          643,
          281,
          1261,
          729,
          666,
          5267,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.2588279924894634,
        "compression_ratio": 1.4278846153846154,
        "end": 6039.8,
        "id": 885,
        "no_speech_prob": 0.06097065657377243,
        "seek": 601080,
        "start": 6037.8,
        "temperature": 0,
        "text": " I bet you Jimp will do that for us.",
        "tokens": [
          51714,
          286,
          778,
          291,
          6637,
          79,
          486,
          360,
          300,
          337,
          505,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.216212763930812,
        "compression_ratio": 1.3656716417910448,
        "end": 6048.8,
        "id": 886,
        "no_speech_prob": 0.0001881392818177119,
        "seek": 604080,
        "start": 6041.8,
        "temperature": 0,
        "text": " So, how do I write a new image?",
        "tokens": [
          50414,
          407,
          11,
          577,
          360,
          286,
          2464,
          257,
          777,
          3256,
          30,
          50764
        ]
      },
      {
        "avg_logprob": -0.216212763930812,
        "compression_ratio": 1.3656716417910448,
        "end": 6050.8,
        "id": 887,
        "no_speech_prob": 0.0001881392818177119,
        "seek": 604080,
        "start": 6048.8,
        "temperature": 0,
        "text": " By the way, it's freezing in here.",
        "tokens": [
          50764,
          3146,
          264,
          636,
          11,
          309,
          311,
          20200,
          294,
          510,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.216212763930812,
        "compression_ratio": 1.3656716417910448,
        "end": 6055.8,
        "id": 888,
        "no_speech_prob": 0.0001881392818177119,
        "seek": 604080,
        "start": 6051.8,
        "temperature": 0,
        "text": " Create an image and write it in a text.",
        "tokens": [
          50914,
          20248,
          364,
          3256,
          293,
          2464,
          309,
          294,
          257,
          2487,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.216212763930812,
        "compression_ratio": 1.3656716417910448,
        "end": 6057.8,
        "id": 889,
        "no_speech_prob": 0.0001881392818177119,
        "seek": 604080,
        "start": 6055.8,
        "temperature": 0,
        "text": " Can I make a new image?",
        "tokens": [
          51114,
          1664,
          286,
          652,
          257,
          777,
          3256,
          30,
          51214
        ]
      },
      {
        "avg_logprob": -0.216212763930812,
        "compression_ratio": 1.3656716417910448,
        "end": 6062.8,
        "id": 890,
        "no_speech_prob": 0.0001881392818177119,
        "seek": 604080,
        "start": 6059.8,
        "temperature": 0,
        "text": " Okay, can I set the pixels?",
        "tokens": [
          51314,
          1033,
          11,
          393,
          286,
          992,
          264,
          18668,
          30,
          51464
        ]
      },
      {
        "avg_logprob": -0.216212763930812,
        "compression_ratio": 1.3656716417910448,
        "end": 6066.8,
        "id": 891,
        "no_speech_prob": 0.0001881392818177119,
        "seek": 604080,
        "start": 6064.8,
        "temperature": 0,
        "text": " We're about to find out.",
        "tokens": [
          51564,
          492,
          434,
          466,
          281,
          915,
          484,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.20548165704786164,
        "compression_ratio": 1.4154589371980677,
        "end": 6067.8,
        "id": 892,
        "no_speech_prob": 0.006289779208600521,
        "seek": 606680,
        "start": 6066.8,
        "temperature": 0,
        "text": " Whew!",
        "tokens": [
          50364,
          46029,
          0,
          50414
        ]
      },
      {
        "avg_logprob": -0.20548165704786164,
        "compression_ratio": 1.4154589371980677,
        "end": 6072.8,
        "id": 893,
        "no_speech_prob": 0.006289779208600521,
        "seek": 606680,
        "start": 6069.8,
        "temperature": 0,
        "text": " This frozen mountain behind me is no joke.",
        "tokens": [
          50514,
          639,
          12496,
          6937,
          2261,
          385,
          307,
          572,
          7647,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.20548165704786164,
        "compression_ratio": 1.4154589371980677,
        "end": 6074.8,
        "id": 894,
        "no_speech_prob": 0.006289779208600521,
        "seek": 606680,
        "start": 6072.8,
        "temperature": 0,
        "text": " I should really just turn the heat on in here.",
        "tokens": [
          50664,
          286,
          820,
          534,
          445,
          1261,
          264,
          3738,
          322,
          294,
          510,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.20548165704786164,
        "compression_ratio": 1.4154589371980677,
        "end": 6078.8,
        "id": 895,
        "no_speech_prob": 0.006289779208600521,
        "seek": 606680,
        "start": 6074.8,
        "temperature": 0,
        "text": " But, normally what I do is I warm it up before I stream.",
        "tokens": [
          50764,
          583,
          11,
          5646,
          437,
          286,
          360,
          307,
          286,
          4561,
          309,
          493,
          949,
          286,
          4309,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.20548165704786164,
        "compression_ratio": 1.4154589371980677,
        "end": 6080.8,
        "id": 896,
        "no_speech_prob": 0.006289779208600521,
        "seek": 606680,
        "start": 6078.8,
        "temperature": 0,
        "text": " But, I thought I wasn't going to.",
        "tokens": [
          50964,
          583,
          11,
          286,
          1194,
          286,
          2067,
          380,
          516,
          281,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.20548165704786164,
        "compression_ratio": 1.4154589371980677,
        "end": 6081.8,
        "id": 897,
        "no_speech_prob": 0.006289779208600521,
        "seek": 606680,
        "start": 6080.8,
        "temperature": 0,
        "text": " I can't believe this is working.",
        "tokens": [
          51064,
          286,
          393,
          380,
          1697,
          341,
          307,
          1364,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.20548165704786164,
        "compression_ratio": 1.4154589371980677,
        "end": 6086.8,
        "id": 898,
        "no_speech_prob": 0.006289779208600521,
        "seek": 606680,
        "start": 6081.8,
        "temperature": 0,
        "text": " Okay, so I need to get the data.",
        "tokens": [
          51114,
          1033,
          11,
          370,
          286,
          643,
          281,
          483,
          264,
          1412,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.20548165704786164,
        "compression_ratio": 1.4154589371980677,
        "end": 6088.8,
        "id": 899,
        "no_speech_prob": 0.006289779208600521,
        "seek": 606680,
        "start": 6086.8,
        "temperature": 0,
        "text": " So, back to TensorFlow.js.",
        "tokens": [
          51364,
          407,
          11,
          646,
          281,
          37624,
          13,
          25530,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.20548165704786164,
        "compression_ratio": 1.4154589371980677,
        "end": 6092.8,
        "id": 900,
        "no_speech_prob": 0.006289779208600521,
        "seek": 606680,
        "start": 6090.8,
        "temperature": 0,
        "text": " Where are we?",
        "tokens": [
          51564,
          2305,
          366,
          321,
          30,
          51664
        ]
      },
      {
        "avg_logprob": -0.26119718746263154,
        "compression_ratio": 1.455128205128205,
        "end": 6094.8,
        "id": 901,
        "no_speech_prob": 0.057489849627017975,
        "seek": 609280,
        "start": 6092.8,
        "temperature": 0,
        "text": " Back to TensorFlow.js.",
        "tokens": [
          50364,
          5833,
          281,
          37624,
          13,
          25530,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.26119718746263154,
        "compression_ratio": 1.455128205128205,
        "end": 6097.8,
        "id": 902,
        "no_speech_prob": 0.057489849627017975,
        "seek": 609280,
        "start": 6094.8,
        "temperature": 0,
        "text": " tf.data.array.",
        "tokens": [
          50464,
          256,
          69,
          13,
          67,
          3274,
          13,
          2284,
          320,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.26119718746263154,
        "compression_ratio": 1.455128205128205,
        "end": 6100.8,
        "id": 903,
        "no_speech_prob": 0.057489849627017975,
        "seek": 609280,
        "start": 6097.8,
        "temperature": 0,
        "text": " No, how do I get the tensor?",
        "tokens": [
          50614,
          883,
          11,
          577,
          360,
          286,
          483,
          264,
          40863,
          30,
          50764
        ]
      },
      {
        "avg_logprob": -0.26119718746263154,
        "compression_ratio": 1.455128205128205,
        "end": 6104.8,
        "id": 904,
        "no_speech_prob": 0.057489849627017975,
        "seek": 609280,
        "start": 6102.8,
        "temperature": 0,
        "text": " tf.tensor.",
        "tokens": [
          50864,
          256,
          69,
          13,
          83,
          23153,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.26119718746263154,
        "compression_ratio": 1.455128205128205,
        "end": 6108.8,
        "id": 905,
        "no_speech_prob": 0.057489849627017975,
        "seek": 609280,
        "start": 6106.8,
        "temperature": 0,
        "text": " tf.image.",
        "tokens": [
          51064,
          256,
          69,
          13,
          26624,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.26119718746263154,
        "compression_ratio": 1.455128205128205,
        "end": 6110.8,
        "id": 906,
        "no_speech_prob": 0.057489849627017975,
        "seek": 609280,
        "start": 6108.8,
        "temperature": 0,
        "text": " One.",
        "tokens": [
          51164,
          1485,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.26119718746263154,
        "compression_ratio": 1.455128205128205,
        "end": 6114.8,
        "id": 907,
        "no_speech_prob": 0.057489849627017975,
        "seek": 609280,
        "start": 6110.8,
        "temperature": 0,
        "text": " Isn't there like, how do I get the data?",
        "tokens": [
          51264,
          6998,
          380,
          456,
          411,
          11,
          577,
          360,
          286,
          483,
          264,
          1412,
          30,
          51464
        ]
      },
      {
        "avg_logprob": -0.26119718746263154,
        "compression_ratio": 1.455128205128205,
        "end": 6115.8,
        "id": 908,
        "no_speech_prob": 0.057489849627017975,
        "seek": 609280,
        "start": 6114.8,
        "temperature": 0,
        "text": " Data, this is what I want.",
        "tokens": [
          51464,
          11888,
          11,
          341,
          307,
          437,
          286,
          528,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.26119718746263154,
        "compression_ratio": 1.455128205128205,
        "end": 6117.8,
        "id": 909,
        "no_speech_prob": 0.057489849627017975,
        "seek": 609280,
        "start": 6116.8,
        "temperature": 0,
        "text": " Gives me the data.",
        "tokens": [
          51564,
          460,
          1539,
          385,
          264,
          1412,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.26119718746263154,
        "compression_ratio": 1.455128205128205,
        "end": 6119.8,
        "id": 910,
        "no_speech_prob": 0.057489849627017975,
        "seek": 609280,
        "start": 6117.8,
        "temperature": 0,
        "text": " Oh, but I can actually just get it as an array.",
        "tokens": [
          51614,
          876,
          11,
          457,
          286,
          393,
          767,
          445,
          483,
          309,
          382,
          364,
          10225,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.3437237820382846,
        "compression_ratio": 1.325925925925926,
        "end": 6122.8,
        "id": 911,
        "no_speech_prob": 0.002672987524420023,
        "seek": 611980,
        "start": 6119.8,
        "temperature": 0,
        "text": " Returns the tensor data as a nested array.",
        "tokens": [
          50364,
          24350,
          82,
          264,
          40863,
          1412,
          382,
          257,
          15646,
          292,
          10225,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.3437237820382846,
        "compression_ratio": 1.325925925925926,
        "end": 6123.8,
        "id": 912,
        "no_speech_prob": 0.002672987524420023,
        "seek": 611980,
        "start": 6122.8,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          50514,
          1033,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.3437237820382846,
        "compression_ratio": 1.325925925925926,
        "end": 6131.8,
        "id": 913,
        "no_speech_prob": 0.002672987524420023,
        "seek": 611980,
        "start": 6125.8,
        "temperature": 0,
        "text": " So, const, did I already use the word images?",
        "tokens": [
          50664,
          407,
          11,
          1817,
          11,
          630,
          286,
          1217,
          764,
          264,
          1349,
          5267,
          30,
          50964
        ]
      },
      {
        "avg_logprob": -0.3437237820382846,
        "compression_ratio": 1.325925925925926,
        "end": 6138.8,
        "id": 914,
        "no_speech_prob": 0.002672987524420023,
        "seek": 611980,
        "start": 6131.8,
        "temperature": 0,
        "text": " Yeah, like new images equals output array.",
        "tokens": [
          50964,
          865,
          11,
          411,
          777,
          5267,
          6915,
          5598,
          10225,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.3437237820382846,
        "compression_ratio": 1.325925925925926,
        "end": 6140.8,
        "id": 915,
        "no_speech_prob": 0.002672987524420023,
        "seek": 611980,
        "start": 6138.8,
        "temperature": 0,
        "text": " Await.",
        "tokens": [
          51314,
          6381,
          1001,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.3437237820382846,
        "compression_ratio": 1.325925925925926,
        "end": 6147.8,
        "id": 916,
        "no_speech_prob": 0.002672987524420023,
        "seek": 611980,
        "start": 6143.8,
        "temperature": 0,
        "text": " Console.log new images index zero.",
        "tokens": [
          51564,
          6923,
          4812,
          13,
          4987,
          777,
          5267,
          8186,
          4018,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.22223614483344845,
        "compression_ratio": 1.381720430107527,
        "end": 6154.8,
        "id": 917,
        "no_speech_prob": 0.004681688733398914,
        "seek": 614980,
        "start": 6150.8,
        "temperature": 0,
        "text": " It's a little silly that I'm training the model every single time.",
        "tokens": [
          50414,
          467,
          311,
          257,
          707,
          11774,
          300,
          286,
          478,
          3097,
          264,
          2316,
          633,
          2167,
          565,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.22223614483344845,
        "compression_ratio": 1.381720430107527,
        "end": 6156.8,
        "id": 918,
        "no_speech_prob": 0.004681688733398914,
        "seek": 614980,
        "start": 6154.8,
        "temperature": 0,
        "text": " But, okay, great.",
        "tokens": [
          50614,
          583,
          11,
          1392,
          11,
          869,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.22223614483344845,
        "compression_ratio": 1.381720430107527,
        "end": 6160.8,
        "id": 919,
        "no_speech_prob": 0.004681688733398914,
        "seek": 614980,
        "start": 6156.8,
        "temperature": 0,
        "text": " So, now I got an array of 784 pixel values.",
        "tokens": [
          50714,
          407,
          11,
          586,
          286,
          658,
          364,
          10225,
          295,
          1614,
          25494,
          19261,
          4190,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.22223614483344845,
        "compression_ratio": 1.381720430107527,
        "end": 6163.8,
        "id": 920,
        "no_speech_prob": 0.004681688733398914,
        "seek": 614980,
        "start": 6160.8,
        "temperature": 0,
        "text": " So, I should be able to say.",
        "tokens": [
          50914,
          407,
          11,
          286,
          820,
          312,
          1075,
          281,
          584,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.22223614483344845,
        "compression_ratio": 1.381720430107527,
        "end": 6176.8,
        "id": 921,
        "no_speech_prob": 0.004681688733398914,
        "seek": 614980,
        "start": 6172.8,
        "temperature": 0,
        "text": " You know, I could use base 64 encoding, probably as a way as writing the images.",
        "tokens": [
          51514,
          509,
          458,
          11,
          286,
          727,
          764,
          3096,
          12145,
          43430,
          11,
          1391,
          382,
          257,
          636,
          382,
          3579,
          264,
          5267,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.22223614483344845,
        "compression_ratio": 1.381720430107527,
        "end": 6178.8,
        "id": 922,
        "no_speech_prob": 0.004681688733398914,
        "seek": 614980,
        "start": 6176.8,
        "temperature": 0,
        "text": " But, this is fine.",
        "tokens": [
          51714,
          583,
          11,
          341,
          307,
          2489,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.3093581106148514,
        "compression_ratio": 1.2644628099173554,
        "end": 6182.8,
        "id": 923,
        "no_speech_prob": 0.000969730201177299,
        "seek": 617880,
        "start": 6179.8,
        "temperature": 0,
        "text": " And let's just do it with just one.",
        "tokens": [
          50414,
          400,
          718,
          311,
          445,
          360,
          309,
          365,
          445,
          472,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.3093581106148514,
        "compression_ratio": 1.2644628099173554,
        "end": 6196.8,
        "id": 924,
        "no_speech_prob": 0.000969730201177299,
        "seek": 617880,
        "start": 6188.8,
        "temperature": 0,
        "text": " So, now what I'm doing is I want to say image equals gimp.",
        "tokens": [
          50864,
          407,
          11,
          586,
          437,
          286,
          478,
          884,
          307,
          286,
          528,
          281,
          584,
          3256,
          6915,
          290,
          8814,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.3093581106148514,
        "compression_ratio": 1.2644628099173554,
        "end": 6198.8,
        "id": 925,
        "no_speech_prob": 0.000969730201177299,
        "seek": 617880,
        "start": 6196.8,
        "temperature": 0,
        "text": " Was it create?",
        "tokens": [
          51264,
          3027,
          309,
          1884,
          30,
          51364
        ]
      },
      {
        "avg_logprob": -0.3093581106148514,
        "compression_ratio": 1.2644628099173554,
        "end": 6206.8,
        "id": 926,
        "no_speech_prob": 0.000969730201177299,
        "seek": 617880,
        "start": 6204.8,
        "temperature": 0,
        "text": " It would really help if I really knew gimp.",
        "tokens": [
          51664,
          467,
          576,
          534,
          854,
          498,
          286,
          534,
          2586,
          290,
          8814,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.4194732348124186,
        "compression_ratio": 0.8297872340425532,
        "end": 6225.8,
        "id": 927,
        "no_speech_prob": 0.0018961919704452157,
        "seek": 620880,
        "start": 6208.8,
        "temperature": 0,
        "text": " Writing text.",
        "tokens": [
          50364,
          32774,
          2487,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.4194732348124186,
        "compression_ratio": 0.8297872340425532,
        "end": 6228.8,
        "id": 928,
        "no_speech_prob": 0.0018961919704452157,
        "seek": 620880,
        "start": 6225.8,
        "temperature": 0,
        "text": " How do I create an image?",
        "tokens": [
          51214,
          1012,
          360,
          286,
          1884,
          364,
          3256,
          30,
          51364
        ]
      },
      {
        "avg_logprob": -0.3331972947761194,
        "compression_ratio": 1.2692307692307692,
        "end": 6239.8,
        "id": 929,
        "no_speech_prob": 0.0021826752927154303,
        "seek": 623880,
        "start": 6238.8,
        "temperature": 0,
        "text": " New gimp.",
        "tokens": [
          50364,
          1873,
          290,
          8814,
          13,
          50414
        ]
      },
      {
        "avg_logprob": -0.3331972947761194,
        "compression_ratio": 1.2692307692307692,
        "end": 6241.8,
        "id": 930,
        "no_speech_prob": 0.0021826752927154303,
        "seek": 623880,
        "start": 6239.8,
        "temperature": 0,
        "text": " Oh, maybe just this.",
        "tokens": [
          50414,
          876,
          11,
          1310,
          445,
          341,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.3331972947761194,
        "compression_ratio": 1.2692307692307692,
        "end": 6242.8,
        "id": 931,
        "no_speech_prob": 0.0021826752927154303,
        "seek": 623880,
        "start": 6241.8,
        "temperature": 0,
        "text": " Oh, okay.",
        "tokens": [
          50514,
          876,
          11,
          1392,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.3331972947761194,
        "compression_ratio": 1.2692307692307692,
        "end": 6243.8,
        "id": 932,
        "no_speech_prob": 0.0021826752927154303,
        "seek": 623880,
        "start": 6242.8,
        "temperature": 0,
        "text": " Creating new images.",
        "tokens": [
          50564,
          40002,
          777,
          5267,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.3331972947761194,
        "compression_ratio": 1.2692307692307692,
        "end": 6244.8,
        "id": 933,
        "no_speech_prob": 0.0021826752927154303,
        "seek": 623880,
        "start": 6243.8,
        "temperature": 0,
        "text": " Here we go.",
        "tokens": [
          50614,
          1692,
          321,
          352,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.3331972947761194,
        "compression_ratio": 1.2692307692307692,
        "end": 6255.8,
        "id": 934,
        "no_speech_prob": 0.0021826752927154303,
        "seek": 623880,
        "start": 6254.8,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          51164,
          1033,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.3331972947761194,
        "compression_ratio": 1.2692307692307692,
        "end": 6257.8,
        "id": 935,
        "no_speech_prob": 0.0021826752927154303,
        "seek": 623880,
        "start": 6255.8,
        "temperature": 0,
        "text": " You can call the gimp constructor.",
        "tokens": [
          51214,
          509,
          393,
          818,
          264,
          290,
          8814,
          47479,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.3331972947761194,
        "compression_ratio": 1.2692307692307692,
        "end": 6261.8,
        "id": 936,
        "no_speech_prob": 0.0021826752927154303,
        "seek": 623880,
        "start": 6257.8,
        "temperature": 0,
        "text": " Can I do this with buffer?",
        "tokens": [
          51314,
          1664,
          286,
          360,
          341,
          365,
          21762,
          30,
          51514
        ]
      },
      {
        "avg_logprob": -0.3331972947761194,
        "compression_ratio": 1.2692307692307692,
        "end": 6262.8,
        "id": 937,
        "no_speech_prob": 0.0021826752927154303,
        "seek": 623880,
        "start": 6261.8,
        "temperature": 0,
        "text": " Data buffer.",
        "tokens": [
          51514,
          11888,
          21762,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.3331972947761194,
        "compression_ratio": 1.2692307692307692,
        "end": 6263.8,
        "id": 938,
        "no_speech_prob": 0.0021826752927154303,
        "seek": 623880,
        "start": 6262.8,
        "temperature": 0,
        "text": " Raw image.",
        "tokens": [
          51564,
          23732,
          3256,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.6098792002751277,
        "compression_ratio": 0.8888888888888888,
        "end": 6266.8,
        "id": 939,
        "no_speech_prob": 0.015188689343631268,
        "seek": 626380,
        "start": 6264.8,
        "temperature": 0,
        "text": " Four channel RGBA image data.",
        "tokens": [
          50414,
          7451,
          2269,
          31231,
          32,
          3256,
          1412,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.6098792002751277,
        "compression_ratio": 0.8888888888888888,
        "end": 6267.8,
        "id": 940,
        "no_speech_prob": 0.015188689343631268,
        "seek": 626380,
        "start": 6266.8,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          50514,
          1033,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.6098792002751277,
        "compression_ratio": 0.8888888888888888,
        "end": 6281.8,
        "id": 941,
        "no_speech_prob": 0.015188689343631268,
        "seek": 626380,
        "start": 6279.8,
        "temperature": 0,
        "text": " Just now, can I do a weight?",
        "tokens": [
          51164,
          1449,
          586,
          11,
          393,
          286,
          360,
          257,
          3364,
          30,
          51264
        ]
      },
      {
        "avg_logprob": -0.7506760954856873,
        "compression_ratio": 1.4137931034482758,
        "end": 6283.8,
        "id": 942,
        "no_speech_prob": 0.046023979783058167,
        "seek": 628180,
        "start": 6282.8,
        "temperature": 0.6000000000000001,
        "text": " So, I'm making it.",
        "tokens": [
          50414,
          407,
          11,
          286,
          478,
          1455,
          309,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.7506760954856873,
        "compression_ratio": 1.4137931034482758,
        "end": 6285.8,
        "id": 943,
        "no_speech_prob": 0.046023979783058167,
        "seek": 628180,
        "start": 6283.8,
        "temperature": 0.6000000000000001,
        "text": " What if I just make the buffer?",
        "tokens": [
          50464,
          708,
          498,
          286,
          445,
          652,
          264,
          21762,
          30,
          50564
        ]
      },
      {
        "avg_logprob": -0.7506760954856873,
        "compression_ratio": 1.4137931034482758,
        "end": 6298.8,
        "id": 944,
        "no_speech_prob": 0.046023979783058167,
        "seek": 628180,
        "start": 6296.8,
        "temperature": 0.6000000000000001,
        "text": " What if I just make the buffer?",
        "tokens": [
          51114,
          343,
          15178,
          498,
          286,
          445,
          652,
          264,
          21762,
          30,
          51214
        ]
      },
      {
        "avg_logprob": -1.6590690612792969,
        "compression_ratio": 1.0705882352941176,
        "end": 6301.8,
        "id": 945,
        "no_speech_prob": 0.08876204490661621,
        "seek": 629880,
        "start": 6299.8,
        "temperature": 1,
        "text": " How do I do that thing where I fill an array?",
        "tokens": [
          50414,
          1012,
          360,
          286,
          360,
          300,
          551,
          689,
          286,
          2836,
          364,
          10225,
          30,
          50514
        ]
      },
      {
        "avg_logprob": -1.6590690612792969,
        "compression_ratio": 1.0705882352941176,
        "end": 6303.8,
        "id": 946,
        "no_speech_prob": 0.08876204490661621,
        "seek": 629880,
        "start": 6301.8,
        "temperature": 1,
        "text": " Okay.",
        "tokens": [
          50514,
          1033,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -1.6590690612792969,
        "compression_ratio": 1.0705882352941176,
        "end": 6307.8,
        "id": 947,
        "no_speech_prob": 0.08876204490661621,
        "seek": 629880,
        "start": 6306.8,
        "temperature": 1,
        "text": " So, figure out how to start here.",
        "tokens": [
          50764,
          407,
          11,
          2573,
          2820,
          83,
          577,
          220,
          1353,
          722,
          720,
          68,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -1.6590690612792969,
        "compression_ratio": 1.0705882352941176,
        "end": 6327.8,
        "id": 948,
        "no_speech_prob": 0.08876204490661621,
        "seek": 629880,
        "start": 6326.8,
        "temperature": 1,
        "text": " Okay.",
        "tokens": [
          51764,
          1033,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.3733955764770508,
        "compression_ratio": 1.278688524590164,
        "end": 6331.8,
        "id": 949,
        "no_speech_prob": 0.0011878714431077242,
        "seek": 632780,
        "start": 6327.8,
        "temperature": 0,
        "text": " So, let's just go ahead and do this.",
        "tokens": [
          50364,
          407,
          11,
          718,
          311,
          445,
          352,
          2286,
          293,
          360,
          341,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.3733955764770508,
        "compression_ratio": 1.278688524590164,
        "end": 6334.8,
        "id": 950,
        "no_speech_prob": 0.0011878714431077242,
        "seek": 632780,
        "start": 6332.8,
        "temperature": 0,
        "text": " Buffer is an array.",
        "tokens": [
          50614,
          20254,
          260,
          307,
          364,
          10225,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.3733955764770508,
        "compression_ratio": 1.278688524590164,
        "end": 6351.8,
        "id": 951,
        "no_speech_prob": 0.0011878714431077242,
        "seek": 632780,
        "start": 6334.8,
        "temperature": 0,
        "text": " And then for n equals 0, n is less than new images index i dot length, n plus plus, buffer index n.",
        "tokens": [
          50714,
          400,
          550,
          337,
          297,
          6915,
          1958,
          11,
          297,
          307,
          1570,
          813,
          777,
          5267,
          8186,
          741,
          5893,
          4641,
          11,
          297,
          1804,
          1804,
          11,
          21762,
          8186,
          297,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.40570153130425346,
        "compression_ratio": 1.1388888888888888,
        "end": 6375.8,
        "id": 952,
        "no_speech_prob": 0.039046745747327805,
        "seek": 635780,
        "start": 6358.8,
        "temperature": 0,
        "text": " n times 4 plus 0, right, is new images in, okay, so current is new images index i.",
        "tokens": [
          50414,
          297,
          1413,
          1017,
          1804,
          1958,
          11,
          558,
          11,
          307,
          777,
          5267,
          294,
          11,
          1392,
          11,
          370,
          2190,
          307,
          777,
          5267,
          8186,
          741,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.23573630939830434,
        "compression_ratio": 1.256578947368421,
        "end": 6393.8,
        "id": 953,
        "no_speech_prob": 0.11595091223716736,
        "seek": 637580,
        "start": 6375.8,
        "temperature": 0,
        "text": " So, if, basically I want to take all of those values and expand them back out by 255.",
        "tokens": [
          50364,
          407,
          11,
          498,
          11,
          1936,
          286,
          528,
          281,
          747,
          439,
          295,
          729,
          4190,
          293,
          5268,
          552,
          646,
          484,
          538,
          3552,
          20,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.23573630939830434,
        "compression_ratio": 1.256578947368421,
        "end": 6401.8,
        "id": 954,
        "no_speech_prob": 0.11595091223716736,
        "seek": 637580,
        "start": 6393.8,
        "temperature": 0,
        "text": " The reason why I'm multiplying by 4 is I took my grayscale image of RGBA and made it just like one value.",
        "tokens": [
          51264,
          440,
          1778,
          983,
          286,
          478,
          30955,
          538,
          1017,
          307,
          286,
          1890,
          452,
          677,
          3772,
          37088,
          3256,
          295,
          31231,
          32,
          293,
          1027,
          309,
          445,
          411,
          472,
          2158,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.19833876869895242,
        "compression_ratio": 1.5240384615384615,
        "end": 6407.8,
        "id": 955,
        "no_speech_prob": 0.03567653149366379,
        "seek": 640180,
        "start": 6402.8,
        "temperature": 0,
        "text": " So, now I'm paying for that because I've got to expand it back out to four values.",
        "tokens": [
          50414,
          407,
          11,
          586,
          286,
          478,
          6229,
          337,
          300,
          570,
          286,
          600,
          658,
          281,
          5268,
          309,
          646,
          484,
          281,
          1451,
          4190,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.19833876869895242,
        "compression_ratio": 1.5240384615384615,
        "end": 6413.8,
        "id": 956,
        "no_speech_prob": 0.03567653149366379,
        "seek": 640180,
        "start": 6407.8,
        "temperature": 0,
        "text": " And this one should always just be 255, so there's no alpha transparency.",
        "tokens": [
          50664,
          400,
          341,
          472,
          820,
          1009,
          445,
          312,
          3552,
          20,
          11,
          370,
          456,
          311,
          572,
          8961,
          17131,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.19833876869895242,
        "compression_ratio": 1.5240384615384615,
        "end": 6420.8,
        "id": 957,
        "no_speech_prob": 0.03567653149366379,
        "seek": 640180,
        "start": 6413.8,
        "temperature": 0,
        "text": " And these are, this is just putting whatever that value is in the RGB channels.",
        "tokens": [
          50964,
          400,
          613,
          366,
          11,
          341,
          307,
          445,
          3372,
          2035,
          300,
          2158,
          307,
          294,
          264,
          31231,
          9235,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.19833876869895242,
        "compression_ratio": 1.5240384615384615,
        "end": 6427.8,
        "id": 958,
        "no_speech_prob": 0.03567653149366379,
        "seek": 640180,
        "start": 6420.8,
        "temperature": 0,
        "text": " And then I should be able to make a new image.",
        "tokens": [
          51314,
          400,
          550,
          286,
          820,
          312,
          1075,
          281,
          652,
          257,
          777,
          3256,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.19833876869895242,
        "compression_ratio": 1.5240384615384615,
        "end": 6429.8,
        "id": 959,
        "no_speech_prob": 0.03567653149366379,
        "seek": 640180,
        "start": 6427.8,
        "temperature": 0,
        "text": " And then how do I write the file?",
        "tokens": [
          51664,
          400,
          550,
          577,
          360,
          286,
          2464,
          264,
          3991,
          30,
          51764
        ]
      },
      {
        "avg_logprob": -0.2543984912690662,
        "compression_ratio": 1.69,
        "end": 6440.8,
        "id": 960,
        "no_speech_prob": 0.018832653760910034,
        "seek": 642980,
        "start": 6429.8,
        "temperature": 0,
        "text": " Write image, right, right, I should be able to say image dot write test dot png.",
        "tokens": [
          50364,
          23499,
          3256,
          11,
          558,
          11,
          558,
          11,
          286,
          820,
          312,
          1075,
          281,
          584,
          3256,
          5893,
          2464,
          1500,
          5893,
          280,
          872,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.2543984912690662,
        "compression_ratio": 1.69,
        "end": 6445.8,
        "id": 961,
        "no_speech_prob": 0.018832653760910034,
        "seek": 642980,
        "start": 6440.8,
        "temperature": 0,
        "text": " Now, that's going to, let's just do it with one, I'm just doing it with one image, so it's fine.",
        "tokens": [
          50914,
          823,
          11,
          300,
          311,
          516,
          281,
          11,
          718,
          311,
          445,
          360,
          309,
          365,
          472,
          11,
          286,
          478,
          445,
          884,
          309,
          365,
          472,
          3256,
          11,
          370,
          309,
          311,
          2489,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.2543984912690662,
        "compression_ratio": 1.69,
        "end": 6448.8,
        "id": 962,
        "no_speech_prob": 0.018832653760910034,
        "seek": 642980,
        "start": 6445.8,
        "temperature": 0,
        "text": " I would say I need to number these, I'll get to that.",
        "tokens": [
          51164,
          286,
          576,
          584,
          286,
          643,
          281,
          1230,
          613,
          11,
          286,
          603,
          483,
          281,
          300,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.2543984912690662,
        "compression_ratio": 1.69,
        "end": 6452.8,
        "id": 963,
        "no_speech_prob": 0.018832653760910034,
        "seek": 642980,
        "start": 6448.8,
        "temperature": 0,
        "text": " And let's just see if output, okay.",
        "tokens": [
          51314,
          400,
          718,
          311,
          445,
          536,
          498,
          5598,
          11,
          1392,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.2543984912690662,
        "compression_ratio": 1.69,
        "end": 6454.8,
        "id": 964,
        "no_speech_prob": 0.018832653760910034,
        "seek": 642980,
        "start": 6452.8,
        "temperature": 0,
        "text": " Let's just see what's happened.",
        "tokens": [
          51514,
          961,
          311,
          445,
          536,
          437,
          311,
          2011,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.2543984912690662,
        "compression_ratio": 1.69,
        "end": 6458.8,
        "id": 965,
        "no_speech_prob": 0.018832653760910034,
        "seek": 642980,
        "start": 6454.8,
        "temperature": 0,
        "text": " I'm sure I missed something important.",
        "tokens": [
          51614,
          286,
          478,
          988,
          286,
          6721,
          746,
          1021,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.2821255703361667,
        "compression_ratio": 1.348148148148148,
        "end": 6467.8,
        "id": 966,
        "no_speech_prob": 0.11756569147109985,
        "seek": 645880,
        "start": 6458.8,
        "temperature": 0,
        "text": " Okay, the first argument must be of type string or instance of buffer, array, buffer, array, array like object received null.",
        "tokens": [
          50364,
          1033,
          11,
          264,
          700,
          6770,
          1633,
          312,
          295,
          2010,
          6798,
          420,
          5197,
          295,
          21762,
          11,
          10225,
          11,
          21762,
          11,
          10225,
          11,
          10225,
          411,
          2657,
          4613,
          18184,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.2821255703361667,
        "compression_ratio": 1.348148148148148,
        "end": 6477.8,
        "id": 967,
        "no_speech_prob": 0.11756569147109985,
        "seek": 645880,
        "start": 6467.8,
        "temperature": 0,
        "text": " Where?",
        "tokens": [
          50814,
          2305,
          30,
          51314
        ]
      },
      {
        "avg_logprob": -0.2821255703361667,
        "compression_ratio": 1.348148148148148,
        "end": 6481.8,
        "id": 968,
        "no_speech_prob": 0.11756569147109985,
        "seek": 645880,
        "start": 6477.8,
        "temperature": 0,
        "text": " So close to having this working, what did I miss?",
        "tokens": [
          51314,
          407,
          1998,
          281,
          1419,
          341,
          1364,
          11,
          437,
          630,
          286,
          1713,
          30,
          51514
        ]
      },
      {
        "avg_logprob": -0.17704293602391294,
        "compression_ratio": 0.875,
        "end": 6500.8,
        "id": 969,
        "no_speech_prob": 0.5389395356178284,
        "seek": 648180,
        "start": 6482.8,
        "temperature": 0,
        "text": " Console log buffer.",
        "tokens": [
          50414,
          44152,
          3565,
          21762,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.17704293602391294,
        "compression_ratio": 0.875,
        "end": 6502.8,
        "id": 970,
        "no_speech_prob": 0.5389395356178284,
        "seek": 648180,
        "start": 6500.8,
        "temperature": 0,
        "text": " Let's just take a look at it.",
        "tokens": [
          51314,
          961,
          311,
          445,
          747,
          257,
          574,
          412,
          309,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.2672957526312934,
        "compression_ratio": 1.219298245614035,
        "end": 6510.8,
        "id": 971,
        "no_speech_prob": 0.7370222806930542,
        "seek": 650280,
        "start": 6503.8,
        "temperature": 0,
        "text": " I'm just going to train the model for, and let's put the number of epochs in here.",
        "tokens": [
          50414,
          286,
          478,
          445,
          516,
          281,
          3847,
          264,
          2316,
          337,
          11,
          293,
          718,
          311,
          829,
          264,
          1230,
          295,
          30992,
          28346,
          294,
          510,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.2672957526312934,
        "compression_ratio": 1.219298245614035,
        "end": 6513.8,
        "id": 972,
        "no_speech_prob": 0.7370222806930542,
        "seek": 650280,
        "start": 6510.8,
        "temperature": 0,
        "text": " Just do 10 epochs.",
        "tokens": [
          50764,
          1449,
          360,
          1266,
          30992,
          28346,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.2672957526312934,
        "compression_ratio": 1.219298245614035,
        "end": 6517.8,
        "id": 973,
        "no_speech_prob": 0.7370222806930542,
        "seek": 650280,
        "start": 6513.8,
        "temperature": 0,
        "text": " So I can like test this more quickly.",
        "tokens": [
          50914,
          407,
          286,
          393,
          411,
          1500,
          341,
          544,
          2661,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.2549226851690383,
        "compression_ratio": 1.2371134020618557,
        "end": 6533.8,
        "id": 974,
        "no_speech_prob": 0.2508919835090637,
        "seek": 651780,
        "start": 6517.8,
        "temperature": 0,
        "text": " Okay, so now I should be able to see the buffer after 10 epochs.",
        "tokens": [
          50364,
          1033,
          11,
          370,
          586,
          286,
          820,
          312,
          1075,
          281,
          536,
          264,
          21762,
          934,
          1266,
          30992,
          28346,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.2549226851690383,
        "compression_ratio": 1.2371134020618557,
        "end": 6535.8,
        "id": 975,
        "no_speech_prob": 0.2508919835090637,
        "seek": 651780,
        "start": 6533.8,
        "temperature": 0,
        "text": " Almost done.",
        "tokens": [
          51164,
          12627,
          1096,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.2549226851690383,
        "compression_ratio": 1.2371134020618557,
        "end": 6537.8,
        "id": 976,
        "no_speech_prob": 0.2508919835090637,
        "seek": 651780,
        "start": 6535.8,
        "temperature": 0,
        "text": " I'm almost done.",
        "tokens": [
          51264,
          286,
          478,
          1920,
          1096,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.2549226851690383,
        "compression_ratio": 1.2371134020618557,
        "end": 6539.8,
        "id": 977,
        "no_speech_prob": 0.2508919835090637,
        "seek": 651780,
        "start": 6537.8,
        "temperature": 0,
        "text": " Okay, this is the buffer.",
        "tokens": [
          51364,
          1033,
          11,
          341,
          307,
          264,
          21762,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.21791667408413357,
        "compression_ratio": 1.125,
        "end": 6547.8,
        "id": 978,
        "no_speech_prob": 0.7057201862335205,
        "seek": 653980,
        "start": 6540.8,
        "temperature": 0,
        "text": " That looks right.",
        "tokens": [
          50414,
          663,
          1542,
          558,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.21791667408413357,
        "compression_ratio": 1.125,
        "end": 6554.8,
        "id": 979,
        "no_speech_prob": 0.7057201862335205,
        "seek": 653980,
        "start": 6547.8,
        "temperature": 0,
        "text": " Oh, maybe I can't use a weight here.",
        "tokens": [
          50764,
          876,
          11,
          1310,
          286,
          393,
          380,
          764,
          257,
          3364,
          510,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.21791667408413357,
        "compression_ratio": 1.125,
        "end": 6555.8,
        "id": 980,
        "no_speech_prob": 0.7057201862335205,
        "seek": 653980,
        "start": 6554.8,
        "temperature": 0,
        "text": " No matching.",
        "tokens": [
          51114,
          883,
          14324,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.21791667408413357,
        "compression_ratio": 1.125,
        "end": 6557.8,
        "id": 981,
        "no_speech_prob": 0.7057201862335205,
        "seek": 653980,
        "start": 6555.8,
        "temperature": 0,
        "text": " So maybe a weight doesn't work.",
        "tokens": [
          51164,
          407,
          1310,
          257,
          3364,
          1177,
          380,
          589,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.2854357560475667,
        "compression_ratio": 0.84,
        "end": 6570.8,
        "id": 982,
        "no_speech_prob": 0.6295294165611267,
        "seek": 655780,
        "start": 6557.8,
        "temperature": 0,
        "text": " I need to follow its callback methodology.",
        "tokens": [
          50364,
          286,
          643,
          281,
          1524,
          1080,
          818,
          3207,
          24850,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.241749267578125,
        "compression_ratio": 1.2543859649122806,
        "end": 6589.8,
        "id": 983,
        "no_speech_prob": 0.5735120177268982,
        "seek": 658780,
        "start": 6588.8,
        "temperature": 0,
        "text": " Let's see what happens here.",
        "tokens": [
          50414,
          961,
          311,
          536,
          437,
          2314,
          510,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.241749267578125,
        "compression_ratio": 1.2543859649122806,
        "end": 6590.8,
        "id": 984,
        "no_speech_prob": 0.5735120177268982,
        "seek": 658780,
        "start": 6589.8,
        "temperature": 0,
        "text": " What is it?",
        "tokens": [
          50464,
          708,
          307,
          309,
          30,
          50514
        ]
      },
      {
        "avg_logprob": -0.241749267578125,
        "compression_ratio": 1.2543859649122806,
        "end": 6602.8,
        "id": 985,
        "no_speech_prob": 0.5735120177268982,
        "seek": 658780,
        "start": 6590.8,
        "temperature": 0,
        "text": " That last argument is error image.",
        "tokens": [
          50514,
          663,
          1036,
          6770,
          307,
          6713,
          3256,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.241749267578125,
        "compression_ratio": 1.2543859649122806,
        "end": 6605.8,
        "id": 986,
        "no_speech_prob": 0.5735120177268982,
        "seek": 658780,
        "start": 6602.8,
        "temperature": 0,
        "text": " Is the function.",
        "tokens": [
          51114,
          1119,
          264,
          2445,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.241749267578125,
        "compression_ratio": 1.2543859649122806,
        "end": 6607.8,
        "id": 987,
        "no_speech_prob": 0.5735120177268982,
        "seek": 658780,
        "start": 6605.8,
        "temperature": 0,
        "text": " I'm a little lost now.",
        "tokens": [
          51264,
          286,
          478,
          257,
          707,
          2731,
          586,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.241749267578125,
        "compression_ratio": 1.2543859649122806,
        "end": 6610.8,
        "id": 988,
        "no_speech_prob": 0.5735120177268982,
        "seek": 658780,
        "start": 6607.8,
        "temperature": 0,
        "text": " A little lost in my syntax.",
        "tokens": [
          51364,
          316,
          707,
          2731,
          294,
          452,
          28431,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.21425433688693576,
        "compression_ratio": 1.48,
        "end": 6616.8,
        "id": 989,
        "no_speech_prob": 0.6957871317863464,
        "seek": 661080,
        "start": 6611.8,
        "temperature": 0,
        "text": " And the arguments are, oh, this is first.",
        "tokens": [
          50414,
          400,
          264,
          12869,
          366,
          11,
          1954,
          11,
          341,
          307,
          700,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.21425433688693576,
        "compression_ratio": 1.48,
        "end": 6618.8,
        "id": 990,
        "no_speech_prob": 0.6957871317863464,
        "seek": 661080,
        "start": 6616.8,
        "temperature": 0,
        "text": " Oh, this is a separate argument.",
        "tokens": [
          50664,
          876,
          11,
          341,
          307,
          257,
          4994,
          6770,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.21425433688693576,
        "compression_ratio": 1.48,
        "end": 6619.8,
        "id": 991,
        "no_speech_prob": 0.6957871317863464,
        "seek": 661080,
        "start": 6618.8,
        "temperature": 0,
        "text": " Doesn't go in there.",
        "tokens": [
          50764,
          12955,
          380,
          352,
          294,
          456,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.21425433688693576,
        "compression_ratio": 1.48,
        "end": 6620.8,
        "id": 992,
        "no_speech_prob": 0.6957871317863464,
        "seek": 661080,
        "start": 6619.8,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          50814,
          1033,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.21425433688693576,
        "compression_ratio": 1.48,
        "end": 6622.8,
        "id": 993,
        "no_speech_prob": 0.6957871317863464,
        "seek": 661080,
        "start": 6620.8,
        "temperature": 0,
        "text": " So it does not go in this object.",
        "tokens": [
          50864,
          407,
          309,
          775,
          406,
          352,
          294,
          341,
          2657,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.21425433688693576,
        "compression_ratio": 1.48,
        "end": 6623.8,
        "id": 994,
        "no_speech_prob": 0.6957871317863464,
        "seek": 661080,
        "start": 6622.8,
        "temperature": 0,
        "text": " There we go.",
        "tokens": [
          50964,
          821,
          321,
          352,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.21425433688693576,
        "compression_ratio": 1.48,
        "end": 6626.8,
        "id": 995,
        "no_speech_prob": 0.6957871317863464,
        "seek": 661080,
        "start": 6623.8,
        "temperature": 0,
        "text": " Okay, image.",
        "tokens": [
          51014,
          1033,
          11,
          3256,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.21425433688693576,
        "compression_ratio": 1.48,
        "end": 6634.8,
        "id": 996,
        "no_speech_prob": 0.6957871317863464,
        "seek": 661080,
        "start": 6626.8,
        "temperature": 0,
        "text": " And what if I actually just did it just as a test?",
        "tokens": [
          51164,
          400,
          437,
          498,
          286,
          767,
          445,
          630,
          309,
          445,
          382,
          257,
          1500,
          30,
          51564
        ]
      },
      {
        "avg_logprob": -0.21425433688693576,
        "compression_ratio": 1.48,
        "end": 6637.8,
        "id": 997,
        "no_speech_prob": 0.6957871317863464,
        "seek": 661080,
        "start": 6634.8,
        "temperature": 0,
        "text": " Well, okay, let's try it with the data buffer.",
        "tokens": [
          51564,
          1042,
          11,
          1392,
          11,
          718,
          311,
          853,
          309,
          365,
          264,
          1412,
          21762,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.18256004651387533,
        "compression_ratio": 1.1,
        "end": 6641.8,
        "id": 998,
        "no_speech_prob": 0.01640279032289982,
        "seek": 663780,
        "start": 6638.8,
        "temperature": 0,
        "text": " Data buffer error image.",
        "tokens": [
          50414,
          11888,
          21762,
          6713,
          3256,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.18256004651387533,
        "compression_ratio": 1.1,
        "end": 6649.8,
        "id": 999,
        "no_speech_prob": 0.01640279032289982,
        "seek": 663780,
        "start": 6641.8,
        "temperature": 0,
        "text": " And then if I said image right.",
        "tokens": [
          50564,
          400,
          550,
          498,
          286,
          848,
          3256,
          558,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.18256004651387533,
        "compression_ratio": 1.1,
        "end": 6653.8,
        "id": 1000,
        "no_speech_prob": 0.01640279032289982,
        "seek": 663780,
        "start": 6649.8,
        "temperature": 0,
        "text": " Let's see if this works.",
        "tokens": [
          50964,
          961,
          311,
          536,
          498,
          341,
          1985,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.18256004651387533,
        "compression_ratio": 1.1,
        "end": 6659.8,
        "id": 1001,
        "no_speech_prob": 0.01640279032289982,
        "seek": 663780,
        "start": 6653.8,
        "temperature": 0,
        "text": " Okay, here we go.",
        "tokens": [
          51164,
          1033,
          11,
          510,
          321,
          352,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.15412214223076315,
        "compression_ratio": 1.1485148514851484,
        "end": 6674.8,
        "id": 1002,
        "no_speech_prob": 0.011508048512041569,
        "seek": 665980,
        "start": 6659.8,
        "temperature": 0,
        "text": " Cannot read properties of undefined.",
        "tokens": [
          50364,
          29866,
          310,
          1401,
          7221,
          295,
          674,
          5666,
          2001,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.15412214223076315,
        "compression_ratio": 1.1485148514851484,
        "end": 6682.8,
        "id": 1003,
        "no_speech_prob": 0.011508048512041569,
        "seek": 665980,
        "start": 6674.8,
        "temperature": 0,
        "text": " We're going to get there, folks.",
        "tokens": [
          51114,
          492,
          434,
          516,
          281,
          483,
          456,
          11,
          4024,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.15412214223076315,
        "compression_ratio": 1.1485148514851484,
        "end": 6687.8,
        "id": 1004,
        "no_speech_prob": 0.011508048512041569,
        "seek": 665980,
        "start": 6682.8,
        "temperature": 0,
        "text": " No matching constructor overloading was found.",
        "tokens": [
          51514,
          883,
          14324,
          47479,
          28777,
          278,
          390,
          1352,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.24623636099008414,
        "compression_ratio": 1.1775700934579438,
        "end": 6690.8,
        "id": 1005,
        "no_speech_prob": 0.28772032260894775,
        "seek": 668780,
        "start": 6687.8,
        "temperature": 0,
        "text": " Do I need to round my output values to integers?",
        "tokens": [
          50364,
          1144,
          286,
          643,
          281,
          3098,
          452,
          5598,
          4190,
          281,
          41674,
          30,
          50514
        ]
      },
      {
        "avg_logprob": -0.24623636099008414,
        "compression_ratio": 1.1775700934579438,
        "end": 6697.8,
        "id": 1006,
        "no_speech_prob": 0.28772032260894775,
        "seek": 668780,
        "start": 6690.8,
        "temperature": 0,
        "text": " I don't think that should matter.",
        "tokens": [
          50514,
          286,
          500,
          380,
          519,
          300,
          820,
          1871,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.24623636099008414,
        "compression_ratio": 1.1775700934579438,
        "end": 6700.8,
        "id": 1007,
        "no_speech_prob": 0.28772032260894775,
        "seek": 668780,
        "start": 6697.8,
        "temperature": 0,
        "text": " But, yeah, I could see how that's an issue.",
        "tokens": [
          50864,
          583,
          11,
          1338,
          11,
          286,
          727,
          536,
          577,
          300,
          311,
          364,
          2734,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.4223859621130902,
        "compression_ratio": 1,
        "end": 6720.8,
        "id": 1008,
        "no_speech_prob": 0.22539466619491577,
        "seek": 671780,
        "start": 6718.8,
        "temperature": 0,
        "text": " Floor is not defined.",
        "tokens": [
          50414,
          15153,
          284,
          307,
          406,
          7642,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.4223859621130902,
        "compression_ratio": 1,
        "end": 6732.8,
        "id": 1009,
        "no_speech_prob": 0.22539466619491577,
        "seek": 671780,
        "start": 6720.8,
        "temperature": 0,
        "text": " Yeah, yeah, yeah.",
        "tokens": [
          50514,
          865,
          11,
          1338,
          11,
          1338,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.4223859621130902,
        "compression_ratio": 1,
        "end": 6734.8,
        "id": 1010,
        "no_speech_prob": 0.22539466619491577,
        "seek": 671780,
        "start": 6732.8,
        "temperature": 0,
        "text": " All right.",
        "tokens": [
          51114,
          1057,
          558,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.2804456778935024,
        "compression_ratio": 0.961038961038961,
        "end": 6737.8,
        "id": 1011,
        "no_speech_prob": 0.4960044026374817,
        "seek": 673480,
        "start": 6735.8,
        "temperature": 0,
        "text": " All right.",
        "tokens": [
          50414,
          1057,
          558,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.2804456778935024,
        "compression_ratio": 0.961038961038961,
        "end": 6746.8,
        "id": 1012,
        "no_speech_prob": 0.4960044026374817,
        "seek": 673480,
        "start": 6737.8,
        "temperature": 0,
        "text": " Let's just try this for a second.",
        "tokens": [
          50514,
          961,
          311,
          445,
          853,
          341,
          337,
          257,
          1150,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.2804456778935024,
        "compression_ratio": 0.961038961038961,
        "end": 6750.8,
        "id": 1013,
        "no_speech_prob": 0.4960044026374817,
        "seek": 673480,
        "start": 6746.8,
        "temperature": 0,
        "text": " See if I can get a red image.",
        "tokens": [
          50964,
          3008,
          498,
          286,
          393,
          483,
          257,
          2182,
          3256,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.2274016832050524,
        "compression_ratio": 1.4210526315789473,
        "end": 6767.8,
        "id": 1014,
        "no_speech_prob": 0.5155728459358215,
        "seek": 676480,
        "start": 6765.8,
        "temperature": 0,
        "text": " Oh, by the way, there's something here.",
        "tokens": [
          50414,
          876,
          11,
          538,
          264,
          636,
          11,
          456,
          311,
          746,
          510,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.2274016832050524,
        "compression_ratio": 1.4210526315789473,
        "end": 6777.8,
        "id": 1015,
        "no_speech_prob": 0.5155728459358215,
        "seek": 676480,
        "start": 6767.8,
        "temperature": 0,
        "text": " Oh, nothing is there.",
        "tokens": [
          50514,
          876,
          11,
          1825,
          307,
          456,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.2274016832050524,
        "compression_ratio": 1.4210526315789473,
        "end": 6781.8,
        "id": 1016,
        "no_speech_prob": 0.5155728459358215,
        "seek": 676480,
        "start": 6777.8,
        "temperature": 0,
        "text": " Just now I'm not trying to use my actual data from the neural network.",
        "tokens": [
          51014,
          1449,
          586,
          286,
          478,
          406,
          1382,
          281,
          764,
          452,
          3539,
          1412,
          490,
          264,
          18161,
          3209,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.2274016832050524,
        "compression_ratio": 1.4210526315789473,
        "end": 6788.8,
        "id": 1017,
        "no_speech_prob": 0.5155728459358215,
        "seek": 676480,
        "start": 6781.8,
        "temperature": 0,
        "text": " I just literally put the GIMP code to draw a red image.",
        "tokens": [
          51214,
          286,
          445,
          3736,
          829,
          264,
          460,
          6324,
          47,
          3089,
          281,
          2642,
          257,
          2182,
          3256,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.2274016832050524,
        "compression_ratio": 1.4210526315789473,
        "end": 6790.8,
        "id": 1018,
        "no_speech_prob": 0.5155728459358215,
        "seek": 676480,
        "start": 6788.8,
        "temperature": 0,
        "text": " That's 256 by 256 there.",
        "tokens": [
          51564,
          663,
          311,
          38882,
          538,
          38882,
          456,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.2274016832050524,
        "compression_ratio": 1.4210526315789473,
        "end": 6793.8,
        "id": 1019,
        "no_speech_prob": 0.5155728459358215,
        "seek": 676480,
        "start": 6790.8,
        "temperature": 0,
        "text": " Just to know that this works.",
        "tokens": [
          51664,
          1449,
          281,
          458,
          300,
          341,
          1985,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.2809685262044271,
        "compression_ratio": 1.4149659863945578,
        "end": 6795.8,
        "id": 1020,
        "no_speech_prob": 0.01883290708065033,
        "seek": 679380,
        "start": 6793.8,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          50364,
          1033,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.2809685262044271,
        "compression_ratio": 1.4149659863945578,
        "end": 6797.8,
        "id": 1021,
        "no_speech_prob": 0.01883290708065033,
        "seek": 679380,
        "start": 6795.8,
        "temperature": 0,
        "text": " Now do we have a red image?",
        "tokens": [
          50464,
          823,
          360,
          321,
          362,
          257,
          2182,
          3256,
          30,
          50564
        ]
      },
      {
        "avg_logprob": -0.2809685262044271,
        "compression_ratio": 1.4149659863945578,
        "end": 6798.8,
        "id": 1022,
        "no_speech_prob": 0.01883290708065033,
        "seek": 679380,
        "start": 6797.8,
        "temperature": 0,
        "text": " Yes.",
        "tokens": [
          50564,
          1079,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.2809685262044271,
        "compression_ratio": 1.4149659863945578,
        "end": 6800.8,
        "id": 1023,
        "no_speech_prob": 0.01883290708065033,
        "seek": 679380,
        "start": 6798.8,
        "temperature": 0,
        "text": " Or pink?",
        "tokens": [
          50614,
          1610,
          7022,
          30,
          50714
        ]
      },
      {
        "avg_logprob": -0.2809685262044271,
        "compression_ratio": 1.4149659863945578,
        "end": 6802.8,
        "id": 1024,
        "no_speech_prob": 0.01883290708065033,
        "seek": 679380,
        "start": 6800.8,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          50714,
          1033,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.2809685262044271,
        "compression_ratio": 1.4149659863945578,
        "end": 6804.8,
        "id": 1025,
        "no_speech_prob": 0.01883290708065033,
        "seek": 679380,
        "start": 6802.8,
        "temperature": 0,
        "text": " So image writing out does work.",
        "tokens": [
          50814,
          407,
          3256,
          3579,
          484,
          775,
          589,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.2809685262044271,
        "compression_ratio": 1.4149659863945578,
        "end": 6809.8,
        "id": 1026,
        "no_speech_prob": 0.01883290708065033,
        "seek": 679380,
        "start": 6804.8,
        "temperature": 0,
        "text": " Now the question is, what if I, how do I create the buffer correctly?",
        "tokens": [
          50914,
          823,
          264,
          1168,
          307,
          11,
          437,
          498,
          286,
          11,
          577,
          360,
          286,
          1884,
          264,
          21762,
          8944,
          30,
          51164
        ]
      },
      {
        "avg_logprob": -0.2809685262044271,
        "compression_ratio": 1.4149659863945578,
        "end": 6816.8,
        "id": 1027,
        "no_speech_prob": 0.01883290708065033,
        "seek": 679380,
        "start": 6809.8,
        "temperature": 0,
        "text": " So if I wanted to follow.",
        "tokens": [
          51164,
          407,
          498,
          286,
          1415,
          281,
          1524,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.2809685262044271,
        "compression_ratio": 1.4149659863945578,
        "end": 6820.8,
        "id": 1028,
        "no_speech_prob": 0.01883290708065033,
        "seek": 679380,
        "start": 6816.8,
        "temperature": 0,
        "text": " So why does this not work?",
        "tokens": [
          51514,
          407,
          983,
          775,
          341,
          406,
          589,
          30,
          51714
        ]
      },
      {
        "avg_logprob": -0.22002180567327537,
        "compression_ratio": 1.2033898305084745,
        "end": 6826.8,
        "id": 1029,
        "no_speech_prob": 0.020023254677653313,
        "seek": 682080,
        "start": 6820.8,
        "temperature": 0,
        "text": " And this does.",
        "tokens": [
          50364,
          400,
          341,
          775,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.22002180567327537,
        "compression_ratio": 1.2033898305084745,
        "end": 6828.8,
        "id": 1030,
        "no_speech_prob": 0.020023254677653313,
        "seek": 682080,
        "start": 6826.8,
        "temperature": 0,
        "text": " Data.",
        "tokens": [
          50664,
          11888,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.22002180567327537,
        "compression_ratio": 1.2033898305084745,
        "end": 6834.8,
        "id": 1031,
        "no_speech_prob": 0.020023254677653313,
        "seek": 682080,
        "start": 6828.8,
        "temperature": 0,
        "text": " I mean, I must not have made the buffer correctly.",
        "tokens": [
          50764,
          286,
          914,
          11,
          286,
          1633,
          406,
          362,
          1027,
          264,
          21762,
          8944,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.22002180567327537,
        "compression_ratio": 1.2033898305084745,
        "end": 6835.8,
        "id": 1032,
        "no_speech_prob": 0.020023254677653313,
        "seek": 682080,
        "start": 6834.8,
        "temperature": 0,
        "text": " Buffer.",
        "tokens": [
          51064,
          20254,
          260,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.22002180567327537,
        "compression_ratio": 1.2033898305084745,
        "end": 6839.8,
        "id": 1033,
        "no_speech_prob": 0.020023254677653313,
        "seek": 682080,
        "start": 6835.8,
        "temperature": 0,
        "text": " Buffer is expected to be a four-channel RGBA image data.",
        "tokens": [
          51114,
          20254,
          260,
          307,
          5176,
          281,
          312,
          257,
          1451,
          12,
          339,
          11444,
          31231,
          32,
          3256,
          1412,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.22002180567327537,
        "compression_ratio": 1.2033898305084745,
        "end": 6840.8,
        "id": 1034,
        "no_speech_prob": 0.020023254677653313,
        "seek": 682080,
        "start": 6839.8,
        "temperature": 0,
        "text": " Yeah?",
        "tokens": [
          51314,
          865,
          30,
          51364
        ]
      },
      {
        "avg_logprob": -0.1789158923285348,
        "compression_ratio": 1,
        "end": 6857.8,
        "id": 1035,
        "no_speech_prob": 0.21465834975242615,
        "seek": 684080,
        "start": 6840.8,
        "temperature": 0,
        "text": " Which is not just a plain array.",
        "tokens": [
          50364,
          3013,
          307,
          406,
          445,
          257,
          11121,
          10225,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.1789158923285348,
        "compression_ratio": 1,
        "end": 6863.8,
        "id": 1036,
        "no_speech_prob": 0.21465834975242615,
        "seek": 684080,
        "start": 6857.8,
        "temperature": 0,
        "text": " Let's see if we can find an example.",
        "tokens": [
          51214,
          961,
          311,
          536,
          498,
          321,
          393,
          915,
          364,
          1365,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.1789158923285348,
        "compression_ratio": 1,
        "end": 6867.8,
        "id": 1037,
        "no_speech_prob": 0.21465834975242615,
        "seek": 684080,
        "start": 6863.8,
        "temperature": 0,
        "text": " Yeah.",
        "tokens": [
          51514,
          865,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.20171293845543495,
        "compression_ratio": 1,
        "end": 6873.8,
        "id": 1038,
        "no_speech_prob": 0.284529447555542,
        "seek": 686780,
        "start": 6867.8,
        "temperature": 0,
        "text": " Yeah, look, here's the error.",
        "tokens": [
          50364,
          865,
          11,
          574,
          11,
          510,
          311,
          264,
          6713,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.20171293845543495,
        "compression_ratio": 1,
        "end": 6874.8,
        "id": 1039,
        "no_speech_prob": 0.284529447555542,
        "seek": 686780,
        "start": 6873.8,
        "temperature": 0,
        "text": " Huh.",
        "tokens": [
          50664,
          8063,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.20171293845543495,
        "compression_ratio": 1,
        "end": 6878.8,
        "id": 1040,
        "no_speech_prob": 0.284529447555542,
        "seek": 686780,
        "start": 6874.8,
        "temperature": 0,
        "text": " Other people are finding this error.",
        "tokens": [
          50714,
          5358,
          561,
          366,
          5006,
          341,
          6713,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.3025428255399068,
        "compression_ratio": 0.7575757575757576,
        "end": 6881.8,
        "id": 1041,
        "no_speech_prob": 0.8251709938049316,
        "seek": 687880,
        "start": 6879.8,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          50414,
          1033,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.3025428255399068,
        "compression_ratio": 0.7575757575757576,
        "end": 6907.8,
        "id": 1042,
        "no_speech_prob": 0.8251709938049316,
        "seek": 687880,
        "start": 6881.8,
        "temperature": 0,
        "text": " That's unfortunate.",
        "tokens": [
          50514,
          663,
          311,
          17843,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.2540503978729248,
        "compression_ratio": 1.197674418604651,
        "end": 6912.8,
        "id": 1043,
        "no_speech_prob": 0.17103780806064606,
        "seek": 690780,
        "start": 6908.8,
        "temperature": 0,
        "text": " Yeah, it doesn't seem to work.",
        "tokens": [
          50414,
          865,
          11,
          309,
          1177,
          380,
          1643,
          281,
          589,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.2540503978729248,
        "compression_ratio": 1.197674418604651,
        "end": 6914.8,
        "id": 1044,
        "no_speech_prob": 0.17103780806064606,
        "seek": 690780,
        "start": 6912.8,
        "temperature": 0,
        "text": " Buffer from array.",
        "tokens": [
          50614,
          20254,
          260,
          490,
          10225,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.2540503978729248,
        "compression_ratio": 1.197674418604651,
        "end": 6915.8,
        "id": 1045,
        "no_speech_prob": 0.17103780806064606,
        "seek": 690780,
        "start": 6914.8,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          50714,
          1033,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.2540503978729248,
        "compression_ratio": 1.197674418604651,
        "end": 6917.8,
        "id": 1046,
        "no_speech_prob": 0.17103780806064606,
        "seek": 690780,
        "start": 6915.8,
        "temperature": 0,
        "text": " Ah, Chris Manning says buffer from array.",
        "tokens": [
          50764,
          2438,
          11,
          6688,
          2458,
          773,
          1619,
          21762,
          490,
          10225,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.2540503978729248,
        "compression_ratio": 1.197674418604651,
        "end": 6931.8,
        "id": 1047,
        "no_speech_prob": 0.17103780806064606,
        "seek": 690780,
        "start": 6917.8,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          50864,
          1033,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.26322744687398275,
        "compression_ratio": 1.4260869565217391,
        "end": 6939.8,
        "id": 1048,
        "no_speech_prob": 0.4532211124897003,
        "seek": 693180,
        "start": 6932.8,
        "temperature": 0,
        "text": " Fingers crossed emoji.",
        "tokens": [
          50414,
          479,
          40180,
          14622,
          31595,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.26322744687398275,
        "compression_ratio": 1.4260869565217391,
        "end": 6941.8,
        "id": 1049,
        "no_speech_prob": 0.4532211124897003,
        "seek": 693180,
        "start": 6939.8,
        "temperature": 0,
        "text": " What?",
        "tokens": [
          50764,
          708,
          30,
          50864
        ]
      },
      {
        "avg_logprob": -0.26322744687398275,
        "compression_ratio": 1.4260869565217391,
        "end": 6946.8,
        "id": 1050,
        "no_speech_prob": 0.4532211124897003,
        "seek": 693180,
        "start": 6941.8,
        "temperature": 0,
        "text": " Oh, I think that worked.",
        "tokens": [
          50864,
          876,
          11,
          286,
          519,
          300,
          2732,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.26322744687398275,
        "compression_ratio": 1.4260869565217391,
        "end": 6947.8,
        "id": 1051,
        "no_speech_prob": 0.4532211124897003,
        "seek": 693180,
        "start": 6946.8,
        "temperature": 0,
        "text": " I mean, oh, but I didn't write the image.",
        "tokens": [
          51114,
          286,
          914,
          11,
          1954,
          11,
          457,
          286,
          994,
          380,
          2464,
          264,
          3256,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.26322744687398275,
        "compression_ratio": 1.4260869565217391,
        "end": 6950.8,
        "id": 1052,
        "no_speech_prob": 0.4532211124897003,
        "seek": 693180,
        "start": 6947.8,
        "temperature": 0,
        "text": " I think that worked.",
        "tokens": [
          51164,
          286,
          519,
          300,
          2732,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.26322744687398275,
        "compression_ratio": 1.4260869565217391,
        "end": 6954.8,
        "id": 1053,
        "no_speech_prob": 0.4532211124897003,
        "seek": 693180,
        "start": 6950.8,
        "temperature": 0,
        "text": " Oh, I think that worked.",
        "tokens": [
          51314,
          876,
          11,
          286,
          519,
          300,
          2732,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.26322744687398275,
        "compression_ratio": 1.4260869565217391,
        "end": 6957.8,
        "id": 1054,
        "no_speech_prob": 0.4532211124897003,
        "seek": 693180,
        "start": 6954.8,
        "temperature": 0,
        "text": " This is very exciting.",
        "tokens": [
          51514,
          639,
          307,
          588,
          4670,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.2901841976024486,
        "compression_ratio": 1.574585635359116,
        "end": 6960.8,
        "id": 1055,
        "no_speech_prob": 0.6653225421905518,
        "seek": 695780,
        "start": 6958.8,
        "temperature": 0,
        "text": " Yes.",
        "tokens": [
          50414,
          1079,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.2901841976024486,
        "compression_ratio": 1.574585635359116,
        "end": 6962.8,
        "id": 1056,
        "no_speech_prob": 0.6653225421905518,
        "seek": 695780,
        "start": 6960.8,
        "temperature": 0,
        "text": " Yes.",
        "tokens": [
          50514,
          1079,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.2901841976024486,
        "compression_ratio": 1.574585635359116,
        "end": 6968.8,
        "id": 1057,
        "no_speech_prob": 0.6653225421905518,
        "seek": 695780,
        "start": 6962.8,
        "temperature": 0,
        "text": " I've never been so excited to see a total, like, noise nonsense image.",
        "tokens": [
          50614,
          286,
          600,
          1128,
          668,
          370,
          2919,
          281,
          536,
          257,
          3217,
          11,
          411,
          11,
          5658,
          14925,
          3256,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.2901841976024486,
        "compression_ratio": 1.574585635359116,
        "end": 6972.8,
        "id": 1058,
        "no_speech_prob": 0.6653225421905518,
        "seek": 695780,
        "start": 6968.8,
        "temperature": 0,
        "text": " Oh, my God, that's amazing.",
        "tokens": [
          50914,
          876,
          11,
          452,
          1265,
          11,
          300,
          311,
          2243,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.2901841976024486,
        "compression_ratio": 1.574585635359116,
        "end": 6973.8,
        "id": 1059,
        "no_speech_prob": 0.6653225421905518,
        "seek": 695780,
        "start": 6972.8,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          51114,
          1033,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.2901841976024486,
        "compression_ratio": 1.574585635359116,
        "end": 6975.8,
        "id": 1060,
        "no_speech_prob": 0.6653225421905518,
        "seek": 695780,
        "start": 6973.8,
        "temperature": 0,
        "text": " Wait, wait, wait, wait, wait, wait.",
        "tokens": [
          51164,
          3802,
          11,
          1699,
          11,
          1699,
          11,
          1699,
          11,
          1699,
          11,
          1699,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.2901841976024486,
        "compression_ratio": 1.574585635359116,
        "end": 6976.8,
        "id": 1061,
        "no_speech_prob": 0.6653225421905518,
        "seek": 695780,
        "start": 6975.8,
        "temperature": 0,
        "text": " All right.",
        "tokens": [
          51264,
          1057,
          558,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.2901841976024486,
        "compression_ratio": 1.574585635359116,
        "end": 6978.8,
        "id": 1062,
        "no_speech_prob": 0.6653225421905518,
        "seek": 695780,
        "start": 6976.8,
        "temperature": 0,
        "text": " So now, hold on, hold on, hold on.",
        "tokens": [
          51314,
          407,
          586,
          11,
          1797,
          322,
          11,
          1797,
          322,
          11,
          1797,
          322,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.2901841976024486,
        "compression_ratio": 1.574585635359116,
        "end": 6980.8,
        "id": 1063,
        "no_speech_prob": 0.6653225421905518,
        "seek": 695780,
        "start": 6978.8,
        "temperature": 0,
        "text": " First of all, I need to train the model better.",
        "tokens": [
          51414,
          2386,
          295,
          439,
          11,
          286,
          643,
          281,
          3847,
          264,
          2316,
          1101,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.2901841976024486,
        "compression_ratio": 1.574585635359116,
        "end": 6982.8,
        "id": 1064,
        "no_speech_prob": 0.6653225421905518,
        "seek": 695780,
        "start": 6980.8,
        "temperature": 0,
        "text": " And then, okay.",
        "tokens": [
          51514,
          400,
          550,
          11,
          1392,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.2901841976024486,
        "compression_ratio": 1.574585635359116,
        "end": 6984.8,
        "id": 1065,
        "no_speech_prob": 0.6653225421905518,
        "seek": 695780,
        "start": 6982.8,
        "temperature": 0,
        "text": " So what do I need to do?",
        "tokens": [
          51614,
          407,
          437,
          360,
          286,
          643,
          281,
          360,
          30,
          51714
        ]
      },
      {
        "avg_logprob": -0.39056954732755333,
        "compression_ratio": 1.4899328859060403,
        "end": 6986.8,
        "id": 1066,
        "no_speech_prob": 0.31066763401031494,
        "seek": 698480,
        "start": 6984.8,
        "temperature": 0,
        "text": " This I can get rid of.",
        "tokens": [
          50364,
          639,
          286,
          393,
          483,
          3973,
          295,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.39056954732755333,
        "compression_ratio": 1.4899328859060403,
        "end": 6990.8,
        "id": 1067,
        "no_speech_prob": 0.31066763401031494,
        "seek": 698480,
        "start": 6986.8,
        "temperature": 0,
        "text": " I need to train the model.",
        "tokens": [
          50464,
          286,
          643,
          281,
          3847,
          264,
          2316,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.39056954732755333,
        "compression_ratio": 1.4899328859060403,
        "end": 6993.8,
        "id": 1068,
        "no_speech_prob": 0.31066763401031494,
        "seek": 698480,
        "start": 6990.8,
        "temperature": 0,
        "text": " With more epochs.",
        "tokens": [
          50664,
          2022,
          544,
          30992,
          28346,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.39056954732755333,
        "compression_ratio": 1.4899328859060403,
        "end": 6996.8,
        "id": 1069,
        "no_speech_prob": 0.31066763401031494,
        "seek": 698480,
        "start": 6993.8,
        "temperature": 0,
        "text": " Let's do 100 epochs.",
        "tokens": [
          50814,
          961,
          311,
          360,
          2319,
          30992,
          28346,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.39056954732755333,
        "compression_ratio": 1.4899328859060403,
        "end": 7001.8,
        "id": 1070,
        "no_speech_prob": 0.31066763401031494,
        "seek": 698480,
        "start": 6996.8,
        "temperature": 0,
        "text": " Then, where was my crazy numeral thing I did?",
        "tokens": [
          50964,
          1396,
          11,
          689,
          390,
          452,
          3219,
          1031,
          2790,
          551,
          286,
          630,
          30,
          51214
        ]
      },
      {
        "avg_logprob": -0.39056954732755333,
        "compression_ratio": 1.4899328859060403,
        "end": 7005.8,
        "id": 1071,
        "no_speech_prob": 0.31066763401031494,
        "seek": 698480,
        "start": 7001.8,
        "temperature": 0,
        "text": " To, let's find that, yeah.",
        "tokens": [
          51214,
          1407,
          11,
          718,
          311,
          915,
          300,
          11,
          1338,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.39056954732755333,
        "compression_ratio": 1.4899328859060403,
        "end": 7008.8,
        "id": 1072,
        "no_speech_prob": 0.31066763401031494,
        "seek": 698480,
        "start": 7005.8,
        "temperature": 0,
        "text": " Then I need to save it.",
        "tokens": [
          51414,
          1396,
          286,
          643,
          281,
          3155,
          309,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.39056954732755333,
        "compression_ratio": 1.4899328859060403,
        "end": 7011.8,
        "id": 1073,
        "no_speech_prob": 0.31066763401031494,
        "seek": 698480,
        "start": 7008.8,
        "temperature": 0,
        "text": " And then, I need to train the model.",
        "tokens": [
          51564,
          400,
          550,
          11,
          286,
          643,
          281,
          3847,
          264,
          2316,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.22214461863040924,
        "compression_ratio": 1.1944444444444444,
        "end": 7013.8,
        "id": 1074,
        "no_speech_prob": 0.0013250160263851285,
        "seek": 701180,
        "start": 7011.8,
        "temperature": 0,
        "text": " Then, I need to save it.",
        "tokens": [
          50364,
          1396,
          11,
          286,
          643,
          281,
          3155,
          309,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.22214461863040924,
        "compression_ratio": 1.1944444444444444,
        "end": 7022.8,
        "id": 1075,
        "no_speech_prob": 0.0013250160263851285,
        "seek": 701180,
        "start": 7021.8,
        "temperature": 0,
        "text": " So, what am I?",
        "tokens": [
          50864,
          407,
          11,
          437,
          669,
          286,
          30,
          50914
        ]
      },
      {
        "avg_logprob": -0.22214461863040924,
        "compression_ratio": 1.1944444444444444,
        "end": 7023.8,
        "id": 1076,
        "no_speech_prob": 0.0013250160263851285,
        "seek": 701180,
        "start": 7022.8,
        "temperature": 0,
        "text": " Am I in N?",
        "tokens": [
          50914,
          2012,
          286,
          294,
          426,
          30,
          50964
        ]
      },
      {
        "avg_logprob": -0.22214461863040924,
        "compression_ratio": 1.1944444444444444,
        "end": 7024.8,
        "id": 1077,
        "no_speech_prob": 0.0013250160263851285,
        "seek": 701180,
        "start": 7023.8,
        "temperature": 0,
        "text": " Am I in I?",
        "tokens": [
          50964,
          2012,
          286,
          294,
          286,
          30,
          51014
        ]
      },
      {
        "avg_logprob": -0.22214461863040924,
        "compression_ratio": 1.1944444444444444,
        "end": 7025.8,
        "id": 1078,
        "no_speech_prob": 0.0013250160263851285,
        "seek": 701180,
        "start": 7024.8,
        "temperature": 0,
        "text": " I don't even remember.",
        "tokens": [
          51014,
          286,
          500,
          380,
          754,
          1604,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.22214461863040924,
        "compression_ratio": 1.1944444444444444,
        "end": 7027.8,
        "id": 1079,
        "no_speech_prob": 0.0013250160263851285,
        "seek": 701180,
        "start": 7025.8,
        "temperature": 0,
        "text": " I'm in I, still.",
        "tokens": [
          51064,
          286,
          478,
          294,
          286,
          11,
          920,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.22214461863040924,
        "compression_ratio": 1.1944444444444444,
        "end": 7040.8,
        "id": 1080,
        "no_speech_prob": 0.0013250160263851285,
        "seek": 701180,
        "start": 7027.8,
        "temperature": 0,
        "text": " I, output, square, num.png.",
        "tokens": [
          51164,
          286,
          11,
          5598,
          11,
          3732,
          11,
          1031,
          13,
          79,
          872,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.22389882405598957,
        "compression_ratio": 1.4217687074829932,
        "end": 7041.8,
        "id": 1081,
        "no_speech_prob": 0.0010162423131987453,
        "seek": 704080,
        "start": 7040.8,
        "temperature": 0,
        "text": " So, this should do.",
        "tokens": [
          50364,
          407,
          11,
          341,
          820,
          360,
          13,
          50414
        ]
      },
      {
        "avg_logprob": -0.22389882405598957,
        "compression_ratio": 1.4217687074829932,
        "end": 7047.8,
        "id": 1082,
        "no_speech_prob": 0.0010162423131987453,
        "seek": 704080,
        "start": 7041.8,
        "temperature": 0,
        "text": " So, now, basically, I am, and I should do all of them.",
        "tokens": [
          50414,
          407,
          11,
          586,
          11,
          1936,
          11,
          286,
          669,
          11,
          293,
          286,
          820,
          360,
          439,
          295,
          552,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.22389882405598957,
        "compression_ratio": 1.4217687074829932,
        "end": 7052.8,
        "id": 1083,
        "no_speech_prob": 0.0010162423131987453,
        "seek": 704080,
        "start": 7047.8,
        "temperature": 0,
        "text": " So, new images dot length.",
        "tokens": [
          50714,
          407,
          11,
          777,
          5267,
          5893,
          4641,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.22389882405598957,
        "compression_ratio": 1.4217687074829932,
        "end": 7059.8,
        "id": 1084,
        "no_speech_prob": 0.0010162423131987453,
        "seek": 704080,
        "start": 7052.8,
        "temperature": 0,
        "text": " And, I've got a lot of, like, these prints here that I don't need.",
        "tokens": [
          50964,
          400,
          11,
          286,
          600,
          658,
          257,
          688,
          295,
          11,
          411,
          11,
          613,
          22305,
          510,
          300,
          286,
          500,
          380,
          643,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.22389882405598957,
        "compression_ratio": 1.4217687074829932,
        "end": 7060.8,
        "id": 1085,
        "no_speech_prob": 0.0010162423131987453,
        "seek": 704080,
        "start": 7059.8,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          51314,
          1033,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.22389882405598957,
        "compression_ratio": 1.4217687074829932,
        "end": 7065.8,
        "id": 1086,
        "no_speech_prob": 0.0010162423131987453,
        "seek": 704080,
        "start": 7060.8,
        "temperature": 0,
        "text": " So, what this should be doing now.",
        "tokens": [
          51364,
          407,
          11,
          437,
          341,
          820,
          312,
          884,
          586,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.16464406898222775,
        "compression_ratio": 1.4939759036144578,
        "end": 7071.8,
        "id": 1087,
        "no_speech_prob": 0.03021427057683468,
        "seek": 706580,
        "start": 7065.8,
        "temperature": 0,
        "text": " And, I should call, I have this main function.",
        "tokens": [
          50364,
          400,
          11,
          286,
          820,
          818,
          11,
          286,
          362,
          341,
          2135,
          2445,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.16464406898222775,
        "compression_ratio": 1.4939759036144578,
        "end": 7073.8,
        "id": 1088,
        "no_speech_prob": 0.03021427057683468,
        "seek": 706580,
        "start": 7071.8,
        "temperature": 0,
        "text": " Let's take this out.",
        "tokens": [
          50664,
          961,
          311,
          747,
          341,
          484,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.16464406898222775,
        "compression_ratio": 1.4939759036144578,
        "end": 7078.8,
        "id": 1089,
        "no_speech_prob": 0.03021427057683468,
        "seek": 706580,
        "start": 7073.8,
        "temperature": 0,
        "text": " Let's do, oh, this should say await.",
        "tokens": [
          50764,
          961,
          311,
          360,
          11,
          1954,
          11,
          341,
          820,
          584,
          19670,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.16464406898222775,
        "compression_ratio": 1.4939759036144578,
        "end": 7079.8,
        "id": 1090,
        "no_speech_prob": 0.03021427057683468,
        "seek": 706580,
        "start": 7078.8,
        "temperature": 0,
        "text": " Oh, no, it doesn't need an await.",
        "tokens": [
          51014,
          876,
          11,
          572,
          11,
          309,
          1177,
          380,
          643,
          364,
          19670,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.16464406898222775,
        "compression_ratio": 1.4939759036144578,
        "end": 7086.8,
        "id": 1091,
        "no_speech_prob": 0.03021427057683468,
        "seek": 706580,
        "start": 7079.8,
        "temperature": 0,
        "text": " It only needs an await if I'm converting it to data that I can actually use.",
        "tokens": [
          51064,
          467,
          787,
          2203,
          364,
          19670,
          498,
          286,
          478,
          29942,
          309,
          281,
          1412,
          300,
          286,
          393,
          767,
          764,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.16464406898222775,
        "compression_ratio": 1.4939759036144578,
        "end": 7087.8,
        "id": 1092,
        "no_speech_prob": 0.03021427057683468,
        "seek": 706580,
        "start": 7086.8,
        "temperature": 0,
        "text": " That's interesting.",
        "tokens": [
          51414,
          663,
          311,
          1880,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.16464406898222775,
        "compression_ratio": 1.4939759036144578,
        "end": 7089.8,
        "id": 1093,
        "no_speech_prob": 0.03021427057683468,
        "seek": 706580,
        "start": 7087.8,
        "temperature": 0,
        "text": " So, hold on.",
        "tokens": [
          51464,
          407,
          11,
          1797,
          322,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.21776615363964136,
        "compression_ratio": 1.509933774834437,
        "end": 7098.8,
        "id": 1094,
        "no_speech_prob": 0.01640286110341549,
        "seek": 708980,
        "start": 7089.8,
        "temperature": 0,
        "text": " So, this is the train data.",
        "tokens": [
          50364,
          407,
          11,
          341,
          307,
          264,
          3847,
          1412,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.21776615363964136,
        "compression_ratio": 1.509933774834437,
        "end": 7103.8,
        "id": 1095,
        "no_speech_prob": 0.01640286110341549,
        "seek": 708980,
        "start": 7098.8,
        "temperature": 0,
        "text": " This is loading all, then I'm taking 500 images to train it with.",
        "tokens": [
          50814,
          639,
          307,
          15114,
          439,
          11,
          550,
          286,
          478,
          1940,
          5923,
          5267,
          281,
          3847,
          309,
          365,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.21776615363964136,
        "compression_ratio": 1.509933774834437,
        "end": 7112.8,
        "id": 1096,
        "no_speech_prob": 0.01640286110341549,
        "seek": 708980,
        "start": 7103.8,
        "temperature": 0,
        "text": " Then, testing the model, I'm going to say, await, generate, generate tests.",
        "tokens": [
          51064,
          1396,
          11,
          4997,
          264,
          2316,
          11,
          286,
          478,
          516,
          281,
          584,
          11,
          19670,
          11,
          8460,
          11,
          8460,
          6921,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.21776615363964136,
        "compression_ratio": 1.509933774834437,
        "end": 7118.8,
        "id": 1097,
        "no_speech_prob": 0.01640286110341549,
        "seek": 708980,
        "start": 7112.8,
        "temperature": 0,
        "text": " And, I want to give it the auto encoder and the test data.",
        "tokens": [
          51514,
          400,
          11,
          286,
          528,
          281,
          976,
          309,
          264,
          8399,
          2058,
          19866,
          293,
          264,
          1500,
          1412,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.19513980320521762,
        "compression_ratio": 1.4217687074829932,
        "end": 7126.8,
        "id": 1098,
        "no_speech_prob": 0.00001618757778487634,
        "seek": 711880,
        "start": 7119.8,
        "temperature": 0,
        "text": " So, this should all be in its own function, which is an async function,",
        "tokens": [
          50414,
          407,
          11,
          341,
          820,
          439,
          312,
          294,
          1080,
          1065,
          2445,
          11,
          597,
          307,
          364,
          382,
          34015,
          2445,
          11,
          50764
        ]
      },
      {
        "avg_logprob": -0.19513980320521762,
        "compression_ratio": 1.4217687074829932,
        "end": 7137.8,
        "id": 1099,
        "no_speech_prob": 0.00001618757778487634,
        "seek": 711880,
        "start": 7126.8,
        "temperature": 0,
        "text": " generate tests, which gets the auto encoder and the test data.",
        "tokens": [
          50764,
          8460,
          6921,
          11,
          597,
          2170,
          264,
          8399,
          2058,
          19866,
          293,
          264,
          1500,
          1412,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.19513980320521762,
        "compression_ratio": 1.4217687074829932,
        "end": 7139.8,
        "id": 1100,
        "no_speech_prob": 0.00001618757778487634,
        "seek": 711880,
        "start": 7137.8,
        "temperature": 0,
        "text": " And, writes it out.",
        "tokens": [
          51314,
          400,
          11,
          13657,
          309,
          484,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.19513980320521762,
        "compression_ratio": 1.4217687074829932,
        "end": 7141.8,
        "id": 1101,
        "no_speech_prob": 0.00001618757778487634,
        "seek": 711880,
        "start": 7139.8,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          51414,
          1033,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.19513980320521762,
        "compression_ratio": 1.4217687074829932,
        "end": 7142.8,
        "id": 1102,
        "no_speech_prob": 0.00001618757778487634,
        "seek": 711880,
        "start": 7141.8,
        "temperature": 0,
        "text": " So, there we go.",
        "tokens": [
          51514,
          407,
          11,
          456,
          321,
          352,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.19513980320521762,
        "compression_ratio": 1.4217687074829932,
        "end": 7144.8,
        "id": 1103,
        "no_speech_prob": 0.00001618757778487634,
        "seek": 711880,
        "start": 7142.8,
        "temperature": 0,
        "text": " These are the steps now.",
        "tokens": [
          51564,
          1981,
          366,
          264,
          4439,
          586,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.19513980320521762,
        "compression_ratio": 1.4217687074829932,
        "end": 7145.8,
        "id": 1104,
        "no_speech_prob": 0.00001618757778487634,
        "seek": 711880,
        "start": 7144.8,
        "temperature": 0,
        "text": " Right.",
        "tokens": [
          51664,
          1779,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.18094401413135314,
        "compression_ratio": 1.6136363636363635,
        "end": 7150.8,
        "id": 1105,
        "no_speech_prob": 0.3702037036418915,
        "seek": 714580,
        "start": 7145.8,
        "temperature": 0,
        "text": " Build the model, load all of the images, train the model, test the model.",
        "tokens": [
          50364,
          11875,
          264,
          2316,
          11,
          3677,
          439,
          295,
          264,
          5267,
          11,
          3847,
          264,
          2316,
          11,
          1500,
          264,
          2316,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.18094401413135314,
        "compression_ratio": 1.6136363636363635,
        "end": 7156.8,
        "id": 1106,
        "no_speech_prob": 0.3702037036418915,
        "seek": 714580,
        "start": 7150.8,
        "temperature": 0,
        "text": " So, train the model with 500 images, test the model with 50 images.",
        "tokens": [
          50614,
          407,
          11,
          3847,
          264,
          2316,
          365,
          5923,
          5267,
          11,
          1500,
          264,
          2316,
          365,
          2625,
          5267,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.18094401413135314,
        "compression_ratio": 1.6136363636363635,
        "end": 7157.8,
        "id": 1107,
        "no_speech_prob": 0.3702037036418915,
        "seek": 714580,
        "start": 7156.8,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          50914,
          1033,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.18094401413135314,
        "compression_ratio": 1.6136363636363635,
        "end": 7159.8,
        "id": 1108,
        "no_speech_prob": 0.3702037036418915,
        "seek": 714580,
        "start": 7157.8,
        "temperature": 0,
        "text": " Ready, everybody?",
        "tokens": [
          50964,
          9944,
          11,
          2201,
          30,
          51064
        ]
      },
      {
        "avg_logprob": -0.18094401413135314,
        "compression_ratio": 1.6136363636363635,
        "end": 7166.8,
        "id": 1109,
        "no_speech_prob": 0.3702037036418915,
        "seek": 714580,
        "start": 7159.8,
        "temperature": 0,
        "text": " This definitely merits a, here we go.",
        "tokens": [
          51064,
          639,
          2138,
          40923,
          257,
          11,
          510,
          321,
          352,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.18094401413135314,
        "compression_ratio": 1.6136363636363635,
        "end": 7169.8,
        "id": 1110,
        "no_speech_prob": 0.3702037036418915,
        "seek": 714580,
        "start": 7166.8,
        "temperature": 0,
        "text": " Oh, by the way, it's funny how this poll is still up.",
        "tokens": [
          51414,
          876,
          11,
          538,
          264,
          636,
          11,
          309,
          311,
          4074,
          577,
          341,
          6418,
          307,
          920,
          493,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.18094401413135314,
        "compression_ratio": 1.6136363636363635,
        "end": 7172.8,
        "id": 1111,
        "no_speech_prob": 0.3702037036418915,
        "seek": 714580,
        "start": 7169.8,
        "temperature": 0,
        "text": " I'm going to hit end poll.",
        "tokens": [
          51564,
          286,
          478,
          516,
          281,
          2045,
          917,
          6418,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.21645773024786086,
        "compression_ratio": 1.3609467455621302,
        "end": 7174.8,
        "id": 1112,
        "no_speech_prob": 0.6260401010513306,
        "seek": 717280,
        "start": 7172.8,
        "temperature": 0,
        "text": " Yes, thank you to Chris Ray.",
        "tokens": [
          50364,
          1079,
          11,
          1309,
          291,
          281,
          6688,
          10883,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.21645773024786086,
        "compression_ratio": 1.3609467455621302,
        "end": 7177.8,
        "id": 1113,
        "no_speech_prob": 0.6260401010513306,
        "seek": 717280,
        "start": 7174.8,
        "temperature": 0,
        "text": " Train whistle for Chris Ray.",
        "tokens": [
          50464,
          28029,
          23470,
          337,
          6688,
          10883,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.21645773024786086,
        "compression_ratio": 1.3609467455621302,
        "end": 7184.8,
        "id": 1114,
        "no_speech_prob": 0.6260401010513306,
        "seek": 717280,
        "start": 7177.8,
        "temperature": 0,
        "text": " Here we go.",
        "tokens": [
          50614,
          1692,
          321,
          352,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.21645773024786086,
        "compression_ratio": 1.3609467455621302,
        "end": 7187.8,
        "id": 1115,
        "no_speech_prob": 0.6260401010513306,
        "seek": 717280,
        "start": 7184.8,
        "temperature": 0,
        "text": " I mean, did it write all those images out that fast?",
        "tokens": [
          50964,
          286,
          914,
          11,
          630,
          309,
          2464,
          439,
          729,
          5267,
          484,
          300,
          2370,
          30,
          51114
        ]
      },
      {
        "avg_logprob": -0.21645773024786086,
        "compression_ratio": 1.3609467455621302,
        "end": 7189.8,
        "id": 1116,
        "no_speech_prob": 0.6260401010513306,
        "seek": 717280,
        "start": 7187.8,
        "temperature": 0,
        "text": " I find that hard to believe.",
        "tokens": [
          51114,
          286,
          915,
          300,
          1152,
          281,
          1697,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.21645773024786086,
        "compression_ratio": 1.3609467455621302,
        "end": 7194.8,
        "id": 1117,
        "no_speech_prob": 0.6260401010513306,
        "seek": 717280,
        "start": 7189.8,
        "temperature": 0,
        "text": " It looks like it, no, that's, what?",
        "tokens": [
          51214,
          467,
          1542,
          411,
          309,
          11,
          572,
          11,
          300,
          311,
          11,
          437,
          30,
          51464
        ]
      },
      {
        "avg_logprob": -0.21645773024786086,
        "compression_ratio": 1.3609467455621302,
        "end": 7195.8,
        "id": 1118,
        "no_speech_prob": 0.6260401010513306,
        "seek": 717280,
        "start": 7194.8,
        "temperature": 0,
        "text": " Oops.",
        "tokens": [
          51464,
          21726,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.21645773024786086,
        "compression_ratio": 1.3609467455621302,
        "end": 7197.8,
        "id": 1119,
        "no_speech_prob": 0.6260401010513306,
        "seek": 717280,
        "start": 7195.8,
        "temperature": 0,
        "text": " I couldn't output.",
        "tokens": [
          51514,
          286,
          2809,
          380,
          5598,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.21645773024786086,
        "compression_ratio": 1.3609467455621302,
        "end": 7201.8,
        "id": 1120,
        "no_speech_prob": 0.6260401010513306,
        "seek": 717280,
        "start": 7197.8,
        "temperature": 0,
        "text": " Oh, yeah, it did.",
        "tokens": [
          51614,
          876,
          11,
          1338,
          11,
          309,
          630,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.19944040591900164,
        "compression_ratio": 1.2440944881889764,
        "end": 7206.8,
        "id": 1121,
        "no_speech_prob": 0.033085260540246964,
        "seek": 720180,
        "start": 7201.8,
        "temperature": 0,
        "text": " But, something is wacky.",
        "tokens": [
          50364,
          583,
          11,
          746,
          307,
          42138,
          88,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.19944040591900164,
        "compression_ratio": 1.2440944881889764,
        "end": 7214.8,
        "id": 1122,
        "no_speech_prob": 0.033085260540246964,
        "seek": 720180,
        "start": 7206.8,
        "temperature": 0,
        "text": " My images don't look anything like what was fed into them.",
        "tokens": [
          50614,
          1222,
          5267,
          500,
          380,
          574,
          1340,
          411,
          437,
          390,
          4636,
          666,
          552,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.19944040591900164,
        "compression_ratio": 1.2440944881889764,
        "end": 7220.8,
        "id": 1123,
        "no_speech_prob": 0.033085260540246964,
        "seek": 720180,
        "start": 7214.8,
        "temperature": 0,
        "text": " Oh, shoot.",
        "tokens": [
          51014,
          876,
          11,
          3076,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.19944040591900164,
        "compression_ratio": 1.2440944881889764,
        "end": 7226.8,
        "id": 1124,
        "no_speech_prob": 0.033085260540246964,
        "seek": 720180,
        "start": 7220.8,
        "temperature": 0,
        "text": " What could I have done wrong?",
        "tokens": [
          51314,
          708,
          727,
          286,
          362,
          1096,
          2085,
          30,
          51614
        ]
      },
      {
        "avg_logprob": -0.19944040591900164,
        "compression_ratio": 1.2440944881889764,
        "end": 7230.8,
        "id": 1125,
        "no_speech_prob": 0.033085260540246964,
        "seek": 720180,
        "start": 7226.8,
        "temperature": 0,
        "text": " Oh, we've got everything to work.",
        "tokens": [
          51614,
          876,
          11,
          321,
          600,
          658,
          1203,
          281,
          589,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.2797918915748596,
        "compression_ratio": 1.2868217054263567,
        "end": 7231.8,
        "id": 1126,
        "no_speech_prob": 0.35932600498199463,
        "seek": 723080,
        "start": 7230.8,
        "temperature": 0,
        "text": " Look at this.",
        "tokens": [
          50364,
          2053,
          412,
          341,
          13,
          50414
        ]
      },
      {
        "avg_logprob": -0.2797918915748596,
        "compression_ratio": 1.2868217054263567,
        "end": 7241.8,
        "id": 1127,
        "no_speech_prob": 0.35932600498199463,
        "seek": 723080,
        "start": 7231.8,
        "temperature": 0,
        "text": " When getting the output, I mean, to be fair, this model is kind of ridiculous.",
        "tokens": [
          50414,
          1133,
          1242,
          264,
          5598,
          11,
          286,
          914,
          11,
          281,
          312,
          3143,
          11,
          341,
          2316,
          307,
          733,
          295,
          11083,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.2797918915748596,
        "compression_ratio": 1.2868217054263567,
        "end": 7251.8,
        "id": 1128,
        "no_speech_prob": 0.35932600498199463,
        "seek": 723080,
        "start": 7241.8,
        "temperature": 0,
        "text": " What if I go back to my just like, let it like literally copy everything?",
        "tokens": [
          50914,
          708,
          498,
          286,
          352,
          646,
          281,
          452,
          445,
          411,
          11,
          718,
          309,
          411,
          3736,
          5055,
          1203,
          30,
          51414
        ]
      },
      {
        "avg_logprob": -0.21401964534412732,
        "compression_ratio": 0.9491525423728814,
        "end": 7271.8,
        "id": 1129,
        "no_speech_prob": 0.18009090423583984,
        "seek": 725180,
        "start": 7252.8,
        "temperature": 0,
        "text": " Oops.",
        "tokens": [
          50414,
          21726,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.21401964534412732,
        "compression_ratio": 0.9491525423728814,
        "end": 7277.8,
        "id": 1130,
        "no_speech_prob": 0.18009090423583984,
        "seek": 725180,
        "start": 7271.8,
        "temperature": 0,
        "text": " Can't tell if it re, did it regenerate the output?",
        "tokens": [
          51364,
          1664,
          380,
          980,
          498,
          309,
          319,
          11,
          630,
          309,
          26358,
          473,
          264,
          5598,
          30,
          51664
        ]
      },
      {
        "avg_logprob": -0.1640466550985972,
        "compression_ratio": 1.2162162162162162,
        "end": 7291.8,
        "id": 1131,
        "no_speech_prob": 0.21732600033283234,
        "seek": 727780,
        "start": 7277.8,
        "temperature": 0,
        "text": " I mean, maybe I need to rethink my model.",
        "tokens": [
          50364,
          286,
          914,
          11,
          1310,
          286,
          643,
          281,
          34595,
          452,
          2316,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.1640466550985972,
        "compression_ratio": 1.2162162162162162,
        "end": 7298.8,
        "id": 1132,
        "no_speech_prob": 0.21732600033283234,
        "seek": 727780,
        "start": 7291.8,
        "temperature": 0,
        "text": " Yeah, no, what is going on?",
        "tokens": [
          51064,
          865,
          11,
          572,
          11,
          437,
          307,
          516,
          322,
          30,
          51414
        ]
      },
      {
        "avg_logprob": -0.1640466550985972,
        "compression_ratio": 1.2162162162162162,
        "end": 7302.8,
        "id": 1133,
        "no_speech_prob": 0.21732600033283234,
        "seek": 727780,
        "start": 7298.8,
        "temperature": 0,
        "text": " I mean, there's images there.",
        "tokens": [
          51414,
          286,
          914,
          11,
          456,
          311,
          5267,
          456,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.1640466550985972,
        "compression_ratio": 1.2162162162162162,
        "end": 7304.8,
        "id": 1134,
        "no_speech_prob": 0.21732600033283234,
        "seek": 727780,
        "start": 7302.8,
        "temperature": 0,
        "text": " It's outputting a zoomed in square.",
        "tokens": [
          51614,
          467,
          311,
          5598,
          783,
          257,
          8863,
          292,
          294,
          3732,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.17177800031808707,
        "compression_ratio": 1.2706766917293233,
        "end": 7308.8,
        "id": 1135,
        "no_speech_prob": 0.4881937801837921,
        "seek": 730480,
        "start": 7304.8,
        "temperature": 0,
        "text": " You've set it to 28 pixels width and height, I think, yeah?",
        "tokens": [
          50364,
          509,
          600,
          992,
          309,
          281,
          7562,
          18668,
          11402,
          293,
          6681,
          11,
          286,
          519,
          11,
          1338,
          30,
          50564
        ]
      },
      {
        "avg_logprob": -0.17177800031808707,
        "compression_ratio": 1.2706766917293233,
        "end": 7311.8,
        "id": 1136,
        "no_speech_prob": 0.4881937801837921,
        "seek": 730480,
        "start": 7308.8,
        "temperature": 0,
        "text": " Did you write the pixels out in the same order you read them in?",
        "tokens": [
          50564,
          2589,
          291,
          2464,
          264,
          18668,
          484,
          294,
          264,
          912,
          1668,
          291,
          1401,
          552,
          294,
          30,
          50714
        ]
      },
      {
        "avg_logprob": -0.17177800031808707,
        "compression_ratio": 1.2706766917293233,
        "end": 7321.8,
        "id": 1137,
        "no_speech_prob": 0.4881937801837921,
        "seek": 730480,
        "start": 7311.8,
        "temperature": 0,
        "text": " Not necessarily.",
        "tokens": [
          50714,
          1726,
          4725,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.17177800031808707,
        "compression_ratio": 1.2706766917293233,
        "end": 7324.8,
        "id": 1138,
        "no_speech_prob": 0.4881937801837921,
        "seek": 730480,
        "start": 7321.8,
        "temperature": 0,
        "text": " So, let's think about this.",
        "tokens": [
          51214,
          407,
          11,
          718,
          311,
          519,
          466,
          341,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.17101327578226724,
        "compression_ratio": 0.9347826086956522,
        "end": 7346.8,
        "id": 1139,
        "no_speech_prob": 0.6368127465248108,
        "seek": 732480,
        "start": 7324.8,
        "temperature": 0,
        "text": " This is me reading the images, the data in.",
        "tokens": [
          50364,
          639,
          307,
          385,
          3760,
          264,
          5267,
          11,
          264,
          1412,
          294,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.22834030498157848,
        "compression_ratio": 1.2962962962962963,
        "end": 7367.8,
        "id": 1140,
        "no_speech_prob": 0.060080986469984055,
        "seek": 734680,
        "start": 7346.8,
        "temperature": 0,
        "text": " And then, it should be 784.",
        "tokens": [
          50364,
          400,
          550,
          11,
          309,
          820,
          312,
          1614,
          25494,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.22834030498157848,
        "compression_ratio": 1.2962962962962963,
        "end": 7370.8,
        "id": 1141,
        "no_speech_prob": 0.060080986469984055,
        "seek": 734680,
        "start": 7367.8,
        "temperature": 0,
        "text": " This is very silly how I have to run through 100 epochs of training this model",
        "tokens": [
          51414,
          639,
          307,
          588,
          11774,
          577,
          286,
          362,
          281,
          1190,
          807,
          2319,
          30992,
          28346,
          295,
          3097,
          341,
          2316,
          51564
        ]
      },
      {
        "avg_logprob": -0.22834030498157848,
        "compression_ratio": 1.2962962962962963,
        "end": 7375.8,
        "id": 1142,
        "no_speech_prob": 0.060080986469984055,
        "seek": 734680,
        "start": 7370.8,
        "temperature": 0,
        "text": " just to, yeah, yeah, yeah, OK, just to see that that number was 784.",
        "tokens": [
          51564,
          445,
          281,
          11,
          1338,
          11,
          1338,
          11,
          1338,
          11,
          2264,
          11,
          445,
          281,
          536,
          300,
          300,
          1230,
          390,
          1614,
          25494,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.19808895523483688,
        "compression_ratio": 1.48125,
        "end": 7379.8,
        "id": 1143,
        "no_speech_prob": 0.03676898032426834,
        "seek": 737580,
        "start": 7375.8,
        "temperature": 0,
        "text": " I am not reading the Discord chat.",
        "tokens": [
          50364,
          286,
          669,
          406,
          3760,
          264,
          32623,
          5081,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.19808895523483688,
        "compression_ratio": 1.48125,
        "end": 7383.8,
        "id": 1144,
        "no_speech_prob": 0.03676898032426834,
        "seek": 737580,
        "start": 7379.8,
        "temperature": 0,
        "text": " Simon is saying, maybe you should add more layers.",
        "tokens": [
          50564,
          13193,
          307,
          1566,
          11,
          1310,
          291,
          820,
          909,
          544,
          7914,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.19808895523483688,
        "compression_ratio": 1.48125,
        "end": 7385.8,
        "id": 1145,
        "no_speech_prob": 0.03676898032426834,
        "seek": 737580,
        "start": 7383.8,
        "temperature": 0,
        "text": " I don't think you did anything wrong.",
        "tokens": [
          50764,
          286,
          500,
          380,
          519,
          291,
          630,
          1340,
          2085,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.19808895523483688,
        "compression_ratio": 1.48125,
        "end": 7387.8,
        "id": 1146,
        "no_speech_prob": 0.03676898032426834,
        "seek": 737580,
        "start": 7385.8,
        "temperature": 0,
        "text": " I think the model is just bad.",
        "tokens": [
          50864,
          286,
          519,
          264,
          2316,
          307,
          445,
          1578,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.19808895523483688,
        "compression_ratio": 1.48125,
        "end": 7389.8,
        "id": 1147,
        "no_speech_prob": 0.03676898032426834,
        "seek": 737580,
        "start": 7387.8,
        "temperature": 0,
        "text": " More layers, OK.",
        "tokens": [
          50964,
          5048,
          7914,
          11,
          2264,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.19808895523483688,
        "compression_ratio": 1.48125,
        "end": 7393.8,
        "id": 1148,
        "no_speech_prob": 0.03676898032426834,
        "seek": 737580,
        "start": 7389.8,
        "temperature": 0,
        "text": " I believe that could be, that is the case.",
        "tokens": [
          51064,
          286,
          1697,
          300,
          727,
          312,
          11,
          300,
          307,
          264,
          1389,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.19808895523483688,
        "compression_ratio": 1.48125,
        "end": 7403.8,
        "id": 1149,
        "no_speech_prob": 0.03676898032426834,
        "seek": 737580,
        "start": 7393.8,
        "temperature": 0,
        "text": " Let's add more layers.",
        "tokens": [
          51264,
          961,
          311,
          909,
          544,
          7914,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.2040376345316569,
        "compression_ratio": 1.2262773722627738,
        "end": 7408.8,
        "id": 1150,
        "no_speech_prob": 0.04336480796337128,
        "seek": 740380,
        "start": 7403.8,
        "temperature": 0,
        "text": " So, let's do it by half.",
        "tokens": [
          50364,
          407,
          11,
          718,
          311,
          360,
          309,
          538,
          1922,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.2040376345316569,
        "compression_ratio": 1.2262773722627738,
        "end": 7415.8,
        "id": 1151,
        "no_speech_prob": 0.04336480796337128,
        "seek": 740380,
        "start": 7408.8,
        "temperature": 0,
        "text": " So, 784 divided by 2 is 392.",
        "tokens": [
          50614,
          407,
          11,
          1614,
          25494,
          6666,
          538,
          568,
          307,
          15238,
          17,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.2040376345316569,
        "compression_ratio": 1.2262773722627738,
        "end": 7417.8,
        "id": 1152,
        "no_speech_prob": 0.04336480796337128,
        "seek": 740380,
        "start": 7415.8,
        "temperature": 0,
        "text": " Let's just use powers of 2.",
        "tokens": [
          50964,
          961,
          311,
          445,
          764,
          8674,
          295,
          568,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.2040376345316569,
        "compression_ratio": 1.2262773722627738,
        "end": 7426.8,
        "id": 1153,
        "no_speech_prob": 0.04336480796337128,
        "seek": 740380,
        "start": 7417.8,
        "temperature": 0,
        "text": " So, let's start with, should I be using ReLU for all the encoder activation functions?",
        "tokens": [
          51064,
          407,
          11,
          718,
          311,
          722,
          365,
          11,
          820,
          286,
          312,
          1228,
          1300,
          43,
          52,
          337,
          439,
          264,
          2058,
          19866,
          24433,
          6828,
          30,
          51514
        ]
      },
      {
        "avg_logprob": -0.1303911526997884,
        "compression_ratio": 1.150943396226415,
        "end": 7433.8,
        "id": 1154,
        "no_speech_prob": 0.341531366109848,
        "seek": 742680,
        "start": 7426.8,
        "temperature": 0,
        "text": " So, let's just do encoder 1.",
        "tokens": [
          50364,
          407,
          11,
          718,
          311,
          445,
          360,
          2058,
          19866,
          502,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.1303911526997884,
        "compression_ratio": 1.150943396226415,
        "end": 7442.8,
        "id": 1155,
        "no_speech_prob": 0.341531366109848,
        "seek": 742680,
        "start": 7433.8,
        "temperature": 0,
        "text": " Encoder 2 is, I don't need the input shape anymore, is 128.",
        "tokens": [
          50714,
          29584,
          19866,
          568,
          307,
          11,
          286,
          500,
          380,
          643,
          264,
          4846,
          3909,
          3602,
          11,
          307,
          29810,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.1303911526997884,
        "compression_ratio": 1.150943396226415,
        "end": 7452.8,
        "id": 1156,
        "no_speech_prob": 0.341531366109848,
        "seek": 742680,
        "start": 7442.8,
        "temperature": 0,
        "text": " And then, decoder 1 would be 256.",
        "tokens": [
          51164,
          400,
          550,
          11,
          979,
          19866,
          502,
          576,
          312,
          38882,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.15839979762122744,
        "compression_ratio": 1.4787878787878788,
        "end": 7457.8,
        "id": 1157,
        "no_speech_prob": 0.025178175419569016,
        "seek": 745280,
        "start": 7452.8,
        "temperature": 0,
        "text": " And, again, this is a little bit silly now.",
        "tokens": [
          50364,
          400,
          11,
          797,
          11,
          341,
          307,
          257,
          707,
          857,
          11774,
          586,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.15839979762122744,
        "compression_ratio": 1.4787878787878788,
        "end": 7459.8,
        "id": 1158,
        "no_speech_prob": 0.025178175419569016,
        "seek": 745280,
        "start": 7457.8,
        "temperature": 0,
        "text": " I don't need to name all of them.",
        "tokens": [
          50614,
          286,
          500,
          380,
          643,
          281,
          1315,
          439,
          295,
          552,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.15839979762122744,
        "compression_ratio": 1.4787878787878788,
        "end": 7469.8,
        "id": 1159,
        "no_speech_prob": 0.025178175419569016,
        "seek": 745280,
        "start": 7459.8,
        "temperature": 0,
        "text": " I could just do decoder 2 is 784.",
        "tokens": [
          50714,
          286,
          727,
          445,
          360,
          979,
          19866,
          568,
          307,
          1614,
          25494,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.15839979762122744,
        "compression_ratio": 1.4787878787878788,
        "end": 7471.8,
        "id": 1160,
        "no_speech_prob": 0.025178175419569016,
        "seek": 745280,
        "start": 7469.8,
        "temperature": 0,
        "text": " OK.",
        "tokens": [
          51214,
          2264,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.15839979762122744,
        "compression_ratio": 1.4787878787878788,
        "end": 7476.8,
        "id": 1161,
        "no_speech_prob": 0.025178175419569016,
        "seek": 745280,
        "start": 7471.8,
        "temperature": 0,
        "text": " So, and let me be a little bit more, I think it will be nicer actually.",
        "tokens": [
          51314,
          407,
          11,
          293,
          718,
          385,
          312,
          257,
          707,
          857,
          544,
          11,
          286,
          519,
          309,
          486,
          312,
          22842,
          767,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.15839979762122744,
        "compression_ratio": 1.4787878787878788,
        "end": 7480.8,
        "id": 1162,
        "no_speech_prob": 0.025178175419569016,
        "seek": 745280,
        "start": 7476.8,
        "temperature": 0,
        "text": " I don't need to, I'm just going to add them in directly.",
        "tokens": [
          51564,
          286,
          500,
          380,
          643,
          281,
          11,
          286,
          478,
          445,
          516,
          281,
          909,
          552,
          294,
          3838,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.2089837881234976,
        "compression_ratio": 1.3644067796610169,
        "end": 7492.8,
        "id": 1163,
        "no_speech_prob": 0.3380451202392578,
        "seek": 748080,
        "start": 7480.8,
        "temperature": 0,
        "text": " So, let's add in, add in this layer.",
        "tokens": [
          50364,
          407,
          11,
          718,
          311,
          909,
          294,
          11,
          909,
          294,
          341,
          4583,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.2089837881234976,
        "compression_ratio": 1.3644067796610169,
        "end": 7500.8,
        "id": 1164,
        "no_speech_prob": 0.3380451202392578,
        "seek": 748080,
        "start": 7492.8,
        "temperature": 0,
        "text": " Then add in another layer.",
        "tokens": [
          50964,
          1396,
          909,
          294,
          1071,
          4583,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.2089837881234976,
        "compression_ratio": 1.3644067796610169,
        "end": 7508.8,
        "id": 1165,
        "no_speech_prob": 0.3380451202392578,
        "seek": 748080,
        "start": 7500.8,
        "temperature": 0,
        "text": " And then, I wonder if there's a nicer way to write this, but I'm just going to do this like this.",
        "tokens": [
          51364,
          400,
          550,
          11,
          286,
          2441,
          498,
          456,
          311,
          257,
          22842,
          636,
          281,
          2464,
          341,
          11,
          457,
          286,
          478,
          445,
          516,
          281,
          360,
          341,
          411,
          341,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.17145409744777038,
        "compression_ratio": 1.402116402116402,
        "end": 7512.8,
        "id": 1166,
        "no_speech_prob": 0.01640266366302967,
        "seek": 750880,
        "start": 7508.8,
        "temperature": 0,
        "text": " Another layer.",
        "tokens": [
          50364,
          3996,
          4583,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.17145409744777038,
        "compression_ratio": 1.402116402116402,
        "end": 7515.8,
        "id": 1167,
        "no_speech_prob": 0.01640266366302967,
        "seek": 750880,
        "start": 7512.8,
        "temperature": 0,
        "text": " And another layer.",
        "tokens": [
          50564,
          400,
          1071,
          4583,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.17145409744777038,
        "compression_ratio": 1.402116402116402,
        "end": 7517.8,
        "id": 1168,
        "no_speech_prob": 0.01640266366302967,
        "seek": 750880,
        "start": 7515.8,
        "temperature": 0,
        "text": " Back to 784.",
        "tokens": [
          50714,
          5833,
          281,
          1614,
          25494,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.17145409744777038,
        "compression_ratio": 1.402116402116402,
        "end": 7518.8,
        "id": 1169,
        "no_speech_prob": 0.01640266366302967,
        "seek": 750880,
        "start": 7517.8,
        "temperature": 0,
        "text": " OK.",
        "tokens": [
          50814,
          2264,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.17145409744777038,
        "compression_ratio": 1.402116402116402,
        "end": 7527.8,
        "id": 1170,
        "no_speech_prob": 0.01640266366302967,
        "seek": 750880,
        "start": 7518.8,
        "temperature": 0,
        "text": " So, we're putting in, you should take one of your input images,",
        "tokens": [
          50864,
          407,
          11,
          321,
          434,
          3372,
          294,
          11,
          291,
          820,
          747,
          472,
          295,
          428,
          4846,
          5267,
          11,
          51314
        ]
      },
      {
        "avg_logprob": -0.17145409744777038,
        "compression_ratio": 1.402116402116402,
        "end": 7530.8,
        "id": 1171,
        "no_speech_prob": 0.01640266366302967,
        "seek": 750880,
        "start": 7527.8,
        "temperature": 0,
        "text": " create the buffer the exact same way you are with the output.",
        "tokens": [
          51314,
          1884,
          264,
          21762,
          264,
          1900,
          912,
          636,
          291,
          366,
          365,
          264,
          5598,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.17145409744777038,
        "compression_ratio": 1.402116402116402,
        "end": 7532.8,
        "id": 1172,
        "no_speech_prob": 0.01640266366302967,
        "seek": 750880,
        "start": 7530.8,
        "temperature": 0,
        "text": " Yeah, that's a very good idea, Chris Manning.",
        "tokens": [
          51464,
          865,
          11,
          300,
          311,
          257,
          588,
          665,
          1558,
          11,
          6688,
          2458,
          773,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.17145409744777038,
        "compression_ratio": 1.402116402116402,
        "end": 7534.8,
        "id": 1173,
        "no_speech_prob": 0.01640266366302967,
        "seek": 750880,
        "start": 7532.8,
        "temperature": 0,
        "text": " I will do that.",
        "tokens": [
          51564,
          286,
          486,
          360,
          300,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.17145409744777038,
        "compression_ratio": 1.402116402116402,
        "end": 7535.8,
        "id": 1174,
        "no_speech_prob": 0.01640266366302967,
        "seek": 750880,
        "start": 7534.8,
        "temperature": 0,
        "text": " I'm also going to do that.",
        "tokens": [
          51664,
          286,
          478,
          611,
          516,
          281,
          360,
          300,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.19653376511165074,
        "compression_ratio": 1.3416666666666666,
        "end": 7537.8,
        "id": 1175,
        "no_speech_prob": 0.23365183174610138,
        "seek": 753580,
        "start": 7535.8,
        "temperature": 0,
        "text": " So, here are my layers.",
        "tokens": [
          50364,
          407,
          11,
          510,
          366,
          452,
          7914,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.19653376511165074,
        "compression_ratio": 1.3416666666666666,
        "end": 7545.8,
        "id": 1176,
        "no_speech_prob": 0.23365183174610138,
        "seek": 753580,
        "start": 7537.8,
        "temperature": 0,
        "text": " The first layer gets 784 down to 256, then down to 128, then back up to 256,",
        "tokens": [
          50464,
          440,
          700,
          4583,
          2170,
          1614,
          25494,
          760,
          281,
          38882,
          11,
          550,
          760,
          281,
          29810,
          11,
          550,
          646,
          493,
          281,
          38882,
          11,
          50864
        ]
      },
      {
        "avg_logprob": -0.19653376511165074,
        "compression_ratio": 1.3416666666666666,
        "end": 7550.8,
        "id": 1177,
        "no_speech_prob": 0.23365183174610138,
        "seek": 753580,
        "start": 7545.8,
        "temperature": 0,
        "text": " then back up to 784, and out.",
        "tokens": [
          50864,
          550,
          646,
          493,
          281,
          1614,
          25494,
          11,
          293,
          484,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.19653376511165074,
        "compression_ratio": 1.3416666666666666,
        "end": 7554.8,
        "id": 1178,
        "no_speech_prob": 0.23365183174610138,
        "seek": 753580,
        "start": 7550.8,
        "temperature": 0,
        "text": " And I don't need this anymore.",
        "tokens": [
          51114,
          400,
          286,
          500,
          380,
          643,
          341,
          3602,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.24161820411682128,
        "compression_ratio": 0.8297872340425532,
        "end": 7575.8,
        "id": 1179,
        "no_speech_prob": 0.31391873955726624,
        "seek": 755480,
        "start": 7554.8,
        "temperature": 0,
        "text": " So, let's see how this does.",
        "tokens": [
          50364,
          407,
          11,
          718,
          311,
          536,
          577,
          341,
          775,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.24161820411682128,
        "compression_ratio": 0.8297872340425532,
        "end": 7578.8,
        "id": 1180,
        "no_speech_prob": 0.31391873955726624,
        "seek": 755480,
        "start": 7575.8,
        "temperature": 0,
        "text": " 351, yeah.",
        "tokens": [
          51414,
          6976,
          16,
          11,
          1338,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.20435701502431738,
        "compression_ratio": 1.6939890710382515,
        "end": 7585.8,
        "id": 1181,
        "no_speech_prob": 0.7216162085533142,
        "seek": 757880,
        "start": 7579.8,
        "temperature": 0,
        "text": " So, let me do, let's do some jim tests.",
        "tokens": [
          50414,
          407,
          11,
          718,
          385,
          360,
          11,
          718,
          311,
          360,
          512,
          361,
          332,
          6921,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.20435701502431738,
        "compression_ratio": 1.6939890710382515,
        "end": 7588.8,
        "id": 1182,
        "no_speech_prob": 0.7216162085533142,
        "seek": 757880,
        "start": 7585.8,
        "temperature": 0,
        "text": " So, I'm going to do test.js.",
        "tokens": [
          50714,
          407,
          11,
          286,
          478,
          516,
          281,
          360,
          1500,
          13,
          25530,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.20435701502431738,
        "compression_ratio": 1.6939890710382515,
        "end": 7592.8,
        "id": 1183,
        "no_speech_prob": 0.7216162085533142,
        "seek": 757880,
        "start": 7588.8,
        "temperature": 0,
        "text": " So, I've got too much stuff going on here to really know what's happening.",
        "tokens": [
          50864,
          407,
          11,
          286,
          600,
          658,
          886,
          709,
          1507,
          516,
          322,
          510,
          281,
          534,
          458,
          437,
          311,
          2737,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.20435701502431738,
        "compression_ratio": 1.6939890710382515,
        "end": 7595.8,
        "id": 1184,
        "no_speech_prob": 0.7216162085533142,
        "seek": 757880,
        "start": 7592.8,
        "temperature": 0,
        "text": " So, let me do the following.",
        "tokens": [
          51064,
          407,
          11,
          718,
          385,
          360,
          264,
          3480,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.20435701502431738,
        "compression_ratio": 1.6939890710382515,
        "end": 7603.8,
        "id": 1185,
        "no_speech_prob": 0.7216162085533142,
        "seek": 757880,
        "start": 7595.8,
        "temperature": 0,
        "text": " I'm going to take, in this test, I'm going to just get rid of everything but jim.",
        "tokens": [
          51214,
          286,
          478,
          516,
          281,
          747,
          11,
          294,
          341,
          1500,
          11,
          286,
          478,
          516,
          281,
          445,
          483,
          3973,
          295,
          1203,
          457,
          361,
          332,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.20435701502431738,
        "compression_ratio": 1.6939890710382515,
        "end": 7607.8,
        "id": 1186,
        "no_speech_prob": 0.7216162085533142,
        "seek": 757880,
        "start": 7603.8,
        "temperature": 0,
        "text": " Get rid of all the TensorFlow stuff, just for a second.",
        "tokens": [
          51614,
          3240,
          3973,
          295,
          439,
          264,
          37624,
          1507,
          11,
          445,
          337,
          257,
          1150,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.1554180651294942,
        "compression_ratio": 1.3932584269662922,
        "end": 7613.8,
        "id": 1187,
        "no_speech_prob": 0.03210027515888214,
        "seek": 760780,
        "start": 7607.8,
        "temperature": 0,
        "text": " So, I want to, oh, I lost some stuff.",
        "tokens": [
          50364,
          407,
          11,
          286,
          528,
          281,
          11,
          1954,
          11,
          286,
          2731,
          512,
          1507,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.1554180651294942,
        "compression_ratio": 1.3932584269662922,
        "end": 7626.8,
        "id": 1188,
        "no_speech_prob": 0.03210027515888214,
        "seek": 760780,
        "start": 7613.8,
        "temperature": 0,
        "text": " So, I want to test images.",
        "tokens": [
          50664,
          407,
          11,
          286,
          528,
          281,
          1500,
          5267,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.1554180651294942,
        "compression_ratio": 1.3932584269662922,
        "end": 7629.8,
        "id": 1189,
        "no_speech_prob": 0.03210027515888214,
        "seek": 760780,
        "start": 7626.8,
        "temperature": 0,
        "text": " So, let's test images one.",
        "tokens": [
          51314,
          407,
          11,
          718,
          311,
          1500,
          5267,
          472,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.1554180651294942,
        "compression_ratio": 1.3932584269662922,
        "end": 7631.8,
        "id": 1190,
        "no_speech_prob": 0.03210027515888214,
        "seek": 760780,
        "start": 7629.8,
        "temperature": 0,
        "text": " So, I'm going to read the image.",
        "tokens": [
          51464,
          407,
          11,
          286,
          478,
          516,
          281,
          1401,
          264,
          3256,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.24184338251749674,
        "compression_ratio": 1.2596153846153846,
        "end": 7640.8,
        "id": 1191,
        "no_speech_prob": 0.5582913756370544,
        "seek": 763180,
        "start": 7631.8,
        "temperature": 0,
        "text": " I'm going to get the raw data.",
        "tokens": [
          50364,
          286,
          478,
          516,
          281,
          483,
          264,
          8936,
          1412,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.24184338251749674,
        "compression_ratio": 1.2596153846153846,
        "end": 7653.8,
        "id": 1192,
        "no_speech_prob": 0.5582913756370544,
        "seek": 763180,
        "start": 7640.8,
        "temperature": 0,
        "text": " Then let's try writing the image back out to make sure that actually works the way I expected it to.",
        "tokens": [
          50814,
          1396,
          718,
          311,
          853,
          3579,
          264,
          3256,
          646,
          484,
          281,
          652,
          988,
          300,
          767,
          1985,
          264,
          636,
          286,
          5176,
          309,
          281,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.1984380086263021,
        "compression_ratio": 1.3181818181818181,
        "end": 7673.8,
        "id": 1193,
        "no_speech_prob": 0.018832866102457047,
        "seek": 766180,
        "start": 7662.8,
        "temperature": 0,
        "text": " So, now that I have the raw data,",
        "tokens": [
          50414,
          407,
          11,
          586,
          300,
          286,
          362,
          264,
          8936,
          1412,
          11,
          50964
        ]
      },
      {
        "avg_logprob": -0.1984380086263021,
        "compression_ratio": 1.3181818181818181,
        "end": 7681.8,
        "id": 1194,
        "no_speech_prob": 0.018832866102457047,
        "seek": 766180,
        "start": 7673.8,
        "temperature": 0,
        "text": " this is the equivalent of raw data to expand it back out and write the image out.",
        "tokens": [
          50964,
          341,
          307,
          264,
          10344,
          295,
          8936,
          1412,
          281,
          5268,
          309,
          646,
          484,
          293,
          2464,
          264,
          3256,
          484,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.1984380086263021,
        "compression_ratio": 1.3181818181818181,
        "end": 7686.8,
        "id": 1195,
        "no_speech_prob": 0.018832866102457047,
        "seek": 766180,
        "start": 7681.8,
        "temperature": 0,
        "text": " So, let us get rid of output.",
        "tokens": [
          51364,
          407,
          11,
          718,
          505,
          483,
          3973,
          295,
          5598,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.29562555232518156,
        "compression_ratio": 1.3975155279503106,
        "end": 7693.8,
        "id": 1196,
        "no_speech_prob": 0.06187405437231064,
        "seek": 768680,
        "start": 7686.8,
        "temperature": 0,
        "text": " So, this should just be a nice little test to read one image in and write it back out,",
        "tokens": [
          50364,
          407,
          11,
          341,
          820,
          445,
          312,
          257,
          1481,
          707,
          1500,
          281,
          1401,
          472,
          3256,
          294,
          293,
          2464,
          309,
          646,
          484,
          11,
          50714
        ]
      },
      {
        "avg_logprob": -0.29562555232518156,
        "compression_ratio": 1.3975155279503106,
        "end": 7695.8,
        "id": 1197,
        "no_speech_prob": 0.06187405437231064,
        "seek": 768680,
        "start": 7693.8,
        "temperature": 0,
        "text": " just to make sure that that actually works.",
        "tokens": [
          50714,
          445,
          281,
          652,
          988,
          300,
          300,
          767,
          1985,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.29562555232518156,
        "compression_ratio": 1.3975155279503106,
        "end": 7698.8,
        "id": 1198,
        "no_speech_prob": 0.06187405437231064,
        "seek": 768680,
        "start": 7695.8,
        "temperature": 0,
        "text": " Probably takes longer to train, says K-Week Man.",
        "tokens": [
          50814,
          9210,
          2516,
          2854,
          281,
          3847,
          11,
          1619,
          591,
          12,
          4360,
          916,
          2458,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.29562555232518156,
        "compression_ratio": 1.3975155279503106,
        "end": 7700.8,
        "id": 1199,
        "no_speech_prob": 0.06187405437231064,
        "seek": 768680,
        "start": 7698.8,
        "temperature": 0,
        "text": " Yeah.",
        "tokens": [
          50964,
          865,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.29562555232518156,
        "compression_ratio": 1.3975155279503106,
        "end": 7703.8,
        "id": 1200,
        "no_speech_prob": 0.06187405437231064,
        "seek": 768680,
        "start": 7700.8,
        "temperature": 0,
        "text": " So, let's just do no test.",
        "tokens": [
          51064,
          407,
          11,
          718,
          311,
          445,
          360,
          572,
          1500,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.29562555232518156,
        "compression_ratio": 1.3975155279503106,
        "end": 7715.8,
        "id": 1201,
        "no_speech_prob": 0.06187405437231064,
        "seek": 768680,
        "start": 7703.8,
        "temperature": 0,
        "text": " Image write.",
        "tokens": [
          51214,
          29903,
          2464,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.17252254486083984,
        "compression_ratio": 1.3398058252427185,
        "end": 7726.8,
        "id": 1202,
        "no_speech_prob": 0.050329919904470444,
        "seek": 771580,
        "start": 7715.8,
        "temperature": 0,
        "text": " What's going on here?",
        "tokens": [
          50364,
          708,
          311,
          516,
          322,
          510,
          30,
          50914
        ]
      },
      {
        "avg_logprob": -0.17252254486083984,
        "compression_ratio": 1.3398058252427185,
        "end": 7731.8,
        "id": 1203,
        "no_speech_prob": 0.050329919904470444,
        "seek": 771580,
        "start": 7726.8,
        "temperature": 0,
        "text": " Oh, there's a mistake here.",
        "tokens": [
          50914,
          876,
          11,
          456,
          311,
          257,
          6146,
          510,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.17252254486083984,
        "compression_ratio": 1.3398058252427185,
        "end": 7734.8,
        "id": 1204,
        "no_speech_prob": 0.050329919904470444,
        "seek": 771580,
        "start": 7731.8,
        "temperature": 0,
        "text": " There's a mistake here.",
        "tokens": [
          51164,
          821,
          311,
          257,
          6146,
          510,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.17252254486083984,
        "compression_ratio": 1.3398058252427185,
        "end": 7741.8,
        "id": 1205,
        "no_speech_prob": 0.050329919904470444,
        "seek": 771580,
        "start": 7734.8,
        "temperature": 0,
        "text": " N times 4, I'm using N to pull the colors.",
        "tokens": [
          51314,
          426,
          1413,
          1017,
          11,
          286,
          478,
          1228,
          426,
          281,
          2235,
          264,
          4577,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.17252254486083984,
        "compression_ratio": 1.3398058252427185,
        "end": 7744.8,
        "id": 1206,
        "no_speech_prob": 0.050329919904470444,
        "seek": 771580,
        "start": 7741.8,
        "temperature": 0,
        "text": " That should be index.",
        "tokens": [
          51664,
          663,
          820,
          312,
          8186,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.18822509251283795,
        "compression_ratio": 1.46448087431694,
        "end": 7747.8,
        "id": 1207,
        "no_speech_prob": 0.03308546543121338,
        "seek": 774480,
        "start": 7744.8,
        "temperature": 0,
        "text": " Whoa.",
        "tokens": [
          50364,
          7521,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.18822509251283795,
        "compression_ratio": 1.46448087431694,
        "end": 7757.8,
        "id": 1208,
        "no_speech_prob": 0.03308546543121338,
        "seek": 774480,
        "start": 7747.8,
        "temperature": 0,
        "text": " Whoa, that's a huge mistake that I've just caught right now.",
        "tokens": [
          50514,
          7521,
          11,
          300,
          311,
          257,
          2603,
          6146,
          300,
          286,
          600,
          445,
          5415,
          558,
          586,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.18822509251283795,
        "compression_ratio": 1.46448087431694,
        "end": 7759.8,
        "id": 1209,
        "no_speech_prob": 0.03308546543121338,
        "seek": 774480,
        "start": 7757.8,
        "temperature": 0,
        "text": " Any idea what the batch size should be?",
        "tokens": [
          51014,
          2639,
          1558,
          437,
          264,
          15245,
          2744,
          820,
          312,
          30,
          51114
        ]
      },
      {
        "avg_logprob": -0.18822509251283795,
        "compression_ratio": 1.46448087431694,
        "end": 7761.8,
        "id": 1210,
        "no_speech_prob": 0.03308546543121338,
        "seek": 774480,
        "start": 7759.8,
        "temperature": 0,
        "text": " Also, this is so arbitrary.",
        "tokens": [
          51114,
          2743,
          11,
          341,
          307,
          370,
          23211,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.18822509251283795,
        "compression_ratio": 1.46448087431694,
        "end": 7762.8,
        "id": 1211,
        "no_speech_prob": 0.03308546543121338,
        "seek": 774480,
        "start": 7761.8,
        "temperature": 0,
        "text": " Let's just say 32.",
        "tokens": [
          51214,
          961,
          311,
          445,
          584,
          8858,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.18822509251283795,
        "compression_ratio": 1.46448087431694,
        "end": 7765.8,
        "id": 1212,
        "no_speech_prob": 0.03308546543121338,
        "seek": 774480,
        "start": 7762.8,
        "temperature": 0,
        "text": " I'm going to make that lower, because I don't have that much data.",
        "tokens": [
          51264,
          286,
          478,
          516,
          281,
          652,
          300,
          3126,
          11,
          570,
          286,
          500,
          380,
          362,
          300,
          709,
          1412,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.18822509251283795,
        "compression_ratio": 1.46448087431694,
        "end": 7768.8,
        "id": 1213,
        "no_speech_prob": 0.03308546543121338,
        "seek": 774480,
        "start": 7765.8,
        "temperature": 0,
        "text": " Look at this.",
        "tokens": [
          51414,
          2053,
          412,
          341,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.18822509251283795,
        "compression_ratio": 1.46448087431694,
        "end": 7770.8,
        "id": 1214,
        "no_speech_prob": 0.03308546543121338,
        "seek": 774480,
        "start": 7768.8,
        "temperature": 0,
        "text": " This is a huge error.",
        "tokens": [
          51564,
          639,
          307,
          257,
          2603,
          6713,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.18822509251283795,
        "compression_ratio": 1.46448087431694,
        "end": 7772.8,
        "id": 1215,
        "no_speech_prob": 0.03308546543121338,
        "seek": 774480,
        "start": 7770.8,
        "temperature": 0,
        "text": " Huge error.",
        "tokens": [
          51664,
          37043,
          6713,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.19664757750755132,
        "compression_ratio": 1.509090909090909,
        "end": 7773.8,
        "id": 1216,
        "no_speech_prob": 0.0061929477378726006,
        "seek": 777280,
        "start": 7772.8,
        "temperature": 0,
        "text": " Huge error.",
        "tokens": [
          50364,
          37043,
          6713,
          13,
          50414
        ]
      },
      {
        "avg_logprob": -0.19664757750755132,
        "compression_ratio": 1.509090909090909,
        "end": 7777.8,
        "id": 1217,
        "no_speech_prob": 0.0061929477378726006,
        "seek": 777280,
        "start": 7773.8,
        "temperature": 0,
        "text": " Huge error.",
        "tokens": [
          50414,
          37043,
          6713,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.19664757750755132,
        "compression_ratio": 1.509090909090909,
        "end": 7785.8,
        "id": 1218,
        "no_speech_prob": 0.0061929477378726006,
        "seek": 777280,
        "start": 7777.8,
        "temperature": 0,
        "text": " I think that might actually be – I might have just found the issue.",
        "tokens": [
          50614,
          286,
          519,
          300,
          1062,
          767,
          312,
          220,
          5815,
          286,
          1062,
          362,
          445,
          1352,
          264,
          2734,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.19664757750755132,
        "compression_ratio": 1.509090909090909,
        "end": 7790.8,
        "id": 1219,
        "no_speech_prob": 0.0061929477378726006,
        "seek": 777280,
        "start": 7785.8,
        "temperature": 0,
        "text": " I feel I need more time to train, but we could actually look at what just came out.",
        "tokens": [
          51014,
          286,
          841,
          286,
          643,
          544,
          565,
          281,
          3847,
          11,
          457,
          321,
          727,
          767,
          574,
          412,
          437,
          445,
          1361,
          484,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.19664757750755132,
        "compression_ratio": 1.509090909090909,
        "end": 7792.8,
        "id": 1220,
        "no_speech_prob": 0.0061929477378726006,
        "seek": 777280,
        "start": 7790.8,
        "temperature": 0,
        "text": " Yeah.",
        "tokens": [
          51264,
          865,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.19664757750755132,
        "compression_ratio": 1.509090909090909,
        "end": 7793.8,
        "id": 1221,
        "no_speech_prob": 0.0061929477378726006,
        "seek": 777280,
        "start": 7792.8,
        "temperature": 0,
        "text": " I did it.",
        "tokens": [
          51364,
          286,
          630,
          309,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.19664757750755132,
        "compression_ratio": 1.509090909090909,
        "end": 7794.8,
        "id": 1222,
        "no_speech_prob": 0.0061929477378726006,
        "seek": 777280,
        "start": 7793.8,
        "temperature": 0,
        "text": " I did it.",
        "tokens": [
          51414,
          286,
          630,
          309,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.19664757750755132,
        "compression_ratio": 1.509090909090909,
        "end": 7797.8,
        "id": 1223,
        "no_speech_prob": 0.0061929477378726006,
        "seek": 777280,
        "start": 7794.8,
        "temperature": 0,
        "text": " It worked.",
        "tokens": [
          51464,
          467,
          2732,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.19664757750755132,
        "compression_ratio": 1.509090909090909,
        "end": 7799.8,
        "id": 1224,
        "no_speech_prob": 0.0061929477378726006,
        "seek": 777280,
        "start": 7797.8,
        "temperature": 0,
        "text": " Look what comes out.",
        "tokens": [
          51614,
          2053,
          437,
          1487,
          484,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.19664757750755132,
        "compression_ratio": 1.509090909090909,
        "end": 7800.8,
        "id": 1225,
        "no_speech_prob": 0.0061929477378726006,
        "seek": 777280,
        "start": 7799.8,
        "temperature": 0,
        "text": " Look at that.",
        "tokens": [
          51714,
          2053,
          412,
          300,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.19943203435880003,
        "compression_ratio": 1.4820512820512821,
        "end": 7801.8,
        "id": 1226,
        "no_speech_prob": 0.5233890414237976,
        "seek": 780080,
        "start": 7800.8,
        "temperature": 0,
        "text": " That is beautiful.",
        "tokens": [
          50364,
          663,
          307,
          2238,
          13,
          50414
        ]
      },
      {
        "avg_logprob": -0.19943203435880003,
        "compression_ratio": 1.4820512820512821,
        "end": 7804.8,
        "id": 1227,
        "no_speech_prob": 0.5233890414237976,
        "seek": 780080,
        "start": 7801.8,
        "temperature": 0,
        "text": " Beautiful.",
        "tokens": [
          50414,
          14724,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.19943203435880003,
        "compression_ratio": 1.4820512820512821,
        "end": 7808.8,
        "id": 1228,
        "no_speech_prob": 0.5233890414237976,
        "seek": 780080,
        "start": 7804.8,
        "temperature": 0,
        "text": " Autoencoder worked.",
        "tokens": [
          50564,
          13738,
          22660,
          19866,
          2732,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.19943203435880003,
        "compression_ratio": 1.4820512820512821,
        "end": 7810.8,
        "id": 1229,
        "no_speech_prob": 0.5233890414237976,
        "seek": 780080,
        "start": 7808.8,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          50764,
          1033,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.19943203435880003,
        "compression_ratio": 1.4820512820512821,
        "end": 7811.8,
        "id": 1230,
        "no_speech_prob": 0.5233890414237976,
        "seek": 780080,
        "start": 7810.8,
        "temperature": 0,
        "text": " This is way too exciting.",
        "tokens": [
          50864,
          639,
          307,
          636,
          886,
          4670,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.19943203435880003,
        "compression_ratio": 1.4820512820512821,
        "end": 7812.8,
        "id": 1231,
        "no_speech_prob": 0.5233890414237976,
        "seek": 780080,
        "start": 7811.8,
        "temperature": 0,
        "text": " Hold on.",
        "tokens": [
          50914,
          6962,
          322,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.19943203435880003,
        "compression_ratio": 1.4820512820512821,
        "end": 7813.8,
        "id": 1232,
        "no_speech_prob": 0.5233890414237976,
        "seek": 780080,
        "start": 7812.8,
        "temperature": 0,
        "text": " Hold on.",
        "tokens": [
          50964,
          6962,
          322,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.19943203435880003,
        "compression_ratio": 1.4820512820512821,
        "end": 7817.8,
        "id": 1233,
        "no_speech_prob": 0.5233890414237976,
        "seek": 780080,
        "start": 7813.8,
        "temperature": 0,
        "text": " Everybody relax.",
        "tokens": [
          51014,
          7646,
          5789,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.19943203435880003,
        "compression_ratio": 1.4820512820512821,
        "end": 7818.8,
        "id": 1234,
        "no_speech_prob": 0.5233890414237976,
        "seek": 780080,
        "start": 7817.8,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          51214,
          1033,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.19943203435880003,
        "compression_ratio": 1.4820512820512821,
        "end": 7819.8,
        "id": 1235,
        "no_speech_prob": 0.5233890414237976,
        "seek": 780080,
        "start": 7818.8,
        "temperature": 0,
        "text": " This is really exciting.",
        "tokens": [
          51264,
          639,
          307,
          534,
          4670,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.19943203435880003,
        "compression_ratio": 1.4820512820512821,
        "end": 7820.8,
        "id": 1236,
        "no_speech_prob": 0.5233890414237976,
        "seek": 780080,
        "start": 7819.8,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          51314,
          1033,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.19943203435880003,
        "compression_ratio": 1.4820512820512821,
        "end": 7821.8,
        "id": 1237,
        "no_speech_prob": 0.5233890414237976,
        "seek": 780080,
        "start": 7820.8,
        "temperature": 0,
        "text": " Now, I have to wrap up.",
        "tokens": [
          51364,
          823,
          11,
          286,
          362,
          281,
          7019,
          493,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.19943203435880003,
        "compression_ratio": 1.4820512820512821,
        "end": 7823.8,
        "id": 1238,
        "no_speech_prob": 0.5233890414237976,
        "seek": 780080,
        "start": 7821.8,
        "temperature": 0,
        "text": " I'm way over time.",
        "tokens": [
          51414,
          286,
          478,
          636,
          670,
          565,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.19943203435880003,
        "compression_ratio": 1.4820512820512821,
        "end": 7825.8,
        "id": 1239,
        "no_speech_prob": 0.5233890414237976,
        "seek": 780080,
        "start": 7823.8,
        "temperature": 0,
        "text": " There's so much more that could be done to this.",
        "tokens": [
          51514,
          821,
          311,
          370,
          709,
          544,
          300,
          727,
          312,
          1096,
          281,
          341,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.19943203435880003,
        "compression_ratio": 1.4820512820512821,
        "end": 7827.8,
        "id": 1240,
        "no_speech_prob": 0.5233890414237976,
        "seek": 780080,
        "start": 7825.8,
        "temperature": 0,
        "text": " Part 3, I believe, will come at some point.",
        "tokens": [
          51614,
          4100,
          805,
          11,
          286,
          1697,
          11,
          486,
          808,
          412,
          512,
          935,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.16386479391178616,
        "compression_ratio": 1.3376623376623376,
        "end": 7830.8,
        "id": 1241,
        "no_speech_prob": 0.39603984355926514,
        "seek": 782780,
        "start": 7827.8,
        "temperature": 0,
        "text": " Maybe this will all get edited into some video, and I'll narrate it.",
        "tokens": [
          50364,
          2704,
          341,
          486,
          439,
          483,
          23016,
          666,
          512,
          960,
          11,
          293,
          286,
          603,
          6397,
          473,
          309,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.16386479391178616,
        "compression_ratio": 1.3376623376623376,
        "end": 7831.8,
        "id": 1242,
        "no_speech_prob": 0.39603984355926514,
        "seek": 782780,
        "start": 7830.8,
        "temperature": 0,
        "text": " Who knows?",
        "tokens": [
          50514,
          2102,
          3255,
          30,
          50564
        ]
      },
      {
        "avg_logprob": -0.16386479391178616,
        "compression_ratio": 1.3376623376623376,
        "end": 7832.8,
        "id": 1243,
        "no_speech_prob": 0.39603984355926514,
        "seek": 782780,
        "start": 7831.8,
        "temperature": 0,
        "text": " I have no idea.",
        "tokens": [
          50564,
          286,
          362,
          572,
          1558,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.16386479391178616,
        "compression_ratio": 1.3376623376623376,
        "end": 7842.8,
        "id": 1244,
        "no_speech_prob": 0.39603984355926514,
        "seek": 782780,
        "start": 7832.8,
        "temperature": 0,
        "text": " But what I want to do is a couple things.",
        "tokens": [
          50614,
          583,
          437,
          286,
          528,
          281,
          360,
          307,
          257,
          1916,
          721,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.16386479391178616,
        "compression_ratio": 1.3376623376623376,
        "end": 7851.8,
        "id": 1245,
        "no_speech_prob": 0.39603984355926514,
        "seek": 782780,
        "start": 7842.8,
        "temperature": 0,
        "text": " One, let's train it for much longer.",
        "tokens": [
          51114,
          1485,
          11,
          718,
          311,
          3847,
          309,
          337,
          709,
          2854,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.16386479391178616,
        "compression_ratio": 1.3376623376623376,
        "end": 7854.8,
        "id": 1246,
        "no_speech_prob": 0.39603984355926514,
        "seek": 782780,
        "start": 7851.8,
        "temperature": 0,
        "text": " Where's the training?",
        "tokens": [
          51564,
          2305,
          311,
          264,
          3097,
          30,
          51714
        ]
      },
      {
        "avg_logprob": -0.16386479391178616,
        "compression_ratio": 1.3376623376623376,
        "end": 7856.8,
        "id": 1247,
        "no_speech_prob": 0.39603984355926514,
        "seek": 782780,
        "start": 7854.8,
        "temperature": 0,
        "text": " Oh, yeah.",
        "tokens": [
          51714,
          876,
          11,
          1338,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.17261181379619397,
        "compression_ratio": 1.5364238410596027,
        "end": 7857.8,
        "id": 1248,
        "no_speech_prob": 0.11919062584638596,
        "seek": 785680,
        "start": 7856.8,
        "temperature": 0,
        "text": " I just want to see.",
        "tokens": [
          50364,
          286,
          445,
          528,
          281,
          536,
          13,
          50414
        ]
      },
      {
        "avg_logprob": -0.17261181379619397,
        "compression_ratio": 1.5364238410596027,
        "end": 7861.8,
        "id": 1249,
        "no_speech_prob": 0.11919062584638596,
        "seek": 785680,
        "start": 7857.8,
        "temperature": 0,
        "text": " Let's give it 200 epochs.",
        "tokens": [
          50414,
          961,
          311,
          976,
          309,
          2331,
          30992,
          28346,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.17261181379619397,
        "compression_ratio": 1.5364238410596027,
        "end": 7868.8,
        "id": 1250,
        "no_speech_prob": 0.11919062584638596,
        "seek": 785680,
        "start": 7861.8,
        "temperature": 0,
        "text": " I just want to see, like, when does the loss stop going down?",
        "tokens": [
          50614,
          286,
          445,
          528,
          281,
          536,
          11,
          411,
          11,
          562,
          775,
          264,
          4470,
          1590,
          516,
          760,
          30,
          50964
        ]
      },
      {
        "avg_logprob": -0.17261181379619397,
        "compression_ratio": 1.5364238410596027,
        "end": 7874.8,
        "id": 1251,
        "no_speech_prob": 0.11919062584638596,
        "seek": 785680,
        "start": 7868.8,
        "temperature": 0,
        "text": " It's still going down.",
        "tokens": [
          50964,
          467,
          311,
          920,
          516,
          760,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.17261181379619397,
        "compression_ratio": 1.5364238410596027,
        "end": 7880.8,
        "id": 1252,
        "no_speech_prob": 0.11919062584638596,
        "seek": 785680,
        "start": 7874.8,
        "temperature": 0,
        "text": " I mean, eventually, I need to just save the model and not do this every time.",
        "tokens": [
          51264,
          286,
          914,
          11,
          4728,
          11,
          286,
          643,
          281,
          445,
          3155,
          264,
          2316,
          293,
          406,
          360,
          341,
          633,
          565,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.17261181379619397,
        "compression_ratio": 1.5364238410596027,
        "end": 7884.8,
        "id": 1253,
        "no_speech_prob": 0.11919062584638596,
        "seek": 785680,
        "start": 7880.8,
        "temperature": 0,
        "text": " But I just want to see.",
        "tokens": [
          51564,
          583,
          286,
          445,
          528,
          281,
          536,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.22838812782650902,
        "compression_ratio": 1.0842105263157895,
        "end": 7893.8,
        "id": 1254,
        "no_speech_prob": 0.0875605046749115,
        "seek": 788480,
        "start": 7884.8,
        "temperature": 0,
        "text": " I want to see if I can denoise some images.",
        "tokens": [
          50364,
          286,
          528,
          281,
          536,
          498,
          286,
          393,
          1441,
          38800,
          512,
          5267,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.22838812782650902,
        "compression_ratio": 1.0842105263157895,
        "end": 7894.8,
        "id": 1255,
        "no_speech_prob": 0.0875605046749115,
        "seek": 788480,
        "start": 7893.8,
        "temperature": 0,
        "text": " So where are we?",
        "tokens": [
          50814,
          407,
          689,
          366,
          321,
          30,
          50864
        ]
      },
      {
        "avg_logprob": -0.22838812782650902,
        "compression_ratio": 1.0842105263157895,
        "end": 7902.8,
        "id": 1256,
        "no_speech_prob": 0.0875605046749115,
        "seek": 788480,
        "start": 7894.8,
        "temperature": 0,
        "text": " Yeah, I mean, so 250.",
        "tokens": [
          50864,
          865,
          11,
          286,
          914,
          11,
          370,
          11650,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.22838812782650902,
        "compression_ratio": 1.0842105263157895,
        "end": 7904.8,
        "id": 1257,
        "no_speech_prob": 0.0875605046749115,
        "seek": 788480,
        "start": 7902.8,
        "temperature": 0,
        "text": " We'll do 250 epochs.",
        "tokens": [
          51264,
          492,
          603,
          360,
          11650,
          30992,
          28346,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.16329955018084982,
        "compression_ratio": 1.25,
        "end": 7911.8,
        "id": 1258,
        "no_speech_prob": 0.4415642023086548,
        "seek": 790480,
        "start": 7904.8,
        "temperature": 0,
        "text": " So what I would like to do, actually, now, just as an experiment,",
        "tokens": [
          50364,
          407,
          437,
          286,
          576,
          411,
          281,
          360,
          11,
          767,
          11,
          586,
          11,
          445,
          382,
          364,
          5120,
          11,
          50714
        ]
      },
      {
        "avg_logprob": -0.16329955018084982,
        "compression_ratio": 1.25,
        "end": 7921.8,
        "id": 1259,
        "no_speech_prob": 0.4415642023086548,
        "seek": 790480,
        "start": 7911.8,
        "temperature": 0,
        "text": " is let me make a bunch of images with a lot of noise in them.",
        "tokens": [
          50714,
          307,
          718,
          385,
          652,
          257,
          3840,
          295,
          5267,
          365,
          257,
          688,
          295,
          5658,
          294,
          552,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.16329955018084982,
        "compression_ratio": 1.25,
        "end": 7923.8,
        "id": 1260,
        "no_speech_prob": 0.4415642023086548,
        "seek": 790480,
        "start": 7921.8,
        "temperature": 0,
        "text": " So let's do this.",
        "tokens": [
          51214,
          407,
          718,
          311,
          360,
          341,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.23488755226135255,
        "compression_ratio": 1.0379746835443038,
        "end": 7936.8,
        "id": 1261,
        "no_speech_prob": 0.16885070502758026,
        "seek": 793480,
        "start": 7935.8,
        "temperature": 0,
        "text": " Point.",
        "tokens": [
          50414,
          12387,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.23488755226135255,
        "compression_ratio": 1.0379746835443038,
        "end": 7956.8,
        "id": 1262,
        "no_speech_prob": 0.16885070502758026,
        "seek": 793480,
        "start": 7953.8,
        "temperature": 0,
        "text": " So I'm just adding a lot of noise into the image.",
        "tokens": [
          51314,
          407,
          286,
          478,
          445,
          5127,
          257,
          688,
          295,
          5658,
          666,
          264,
          3256,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.23488755226135255,
        "compression_ratio": 1.0379746835443038,
        "end": 7962.8,
        "id": 1263,
        "no_speech_prob": 0.16885070502758026,
        "seek": 793480,
        "start": 7961.8,
        "temperature": 0,
        "text": " Maybe I need to add more.",
        "tokens": [
          51714,
          2704,
          286,
          643,
          281,
          909,
          544,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.14555795519959694,
        "compression_ratio": 1.49,
        "end": 7963.8,
        "id": 1264,
        "no_speech_prob": 0.003824377665296197,
        "seek": 796280,
        "start": 7962.8,
        "temperature": 0,
        "text": " Let's add a lot more.",
        "tokens": [
          50364,
          961,
          311,
          909,
          257,
          688,
          544,
          13,
          50414
        ]
      },
      {
        "avg_logprob": -0.14555795519959694,
        "compression_ratio": 1.49,
        "end": 7976.8,
        "id": 1265,
        "no_speech_prob": 0.003824377665296197,
        "seek": 796280,
        "start": 7969.8,
        "temperature": 0,
        "text": " So I'm going to make a whole bunch that are very noisy.",
        "tokens": [
          50714,
          407,
          286,
          478,
          516,
          281,
          652,
          257,
          1379,
          3840,
          300,
          366,
          588,
          24518,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.14555795519959694,
        "compression_ratio": 1.49,
        "end": 7978.8,
        "id": 1266,
        "no_speech_prob": 0.003824377665296197,
        "seek": 796280,
        "start": 7976.8,
        "temperature": 0,
        "text": " I'm just going to take the last 50.",
        "tokens": [
          51064,
          286,
          478,
          445,
          516,
          281,
          747,
          264,
          1036,
          2625,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.14555795519959694,
        "compression_ratio": 1.49,
        "end": 7985.8,
        "id": 1267,
        "no_speech_prob": 0.003824377665296197,
        "seek": 796280,
        "start": 7983.8,
        "temperature": 0,
        "text": " I'm just going to take the last 50.",
        "tokens": [
          51414,
          286,
          478,
          445,
          516,
          281,
          747,
          264,
          1036,
          2625,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.3187375623126363,
        "compression_ratio": 1.3636363636363635,
        "end": 7986.8,
        "id": 1268,
        "no_speech_prob": 0.0005357792251743376,
        "seek": 798580,
        "start": 7985.8,
        "temperature": 0,
        "text": " Where's the processing sketch?",
        "tokens": [
          50364,
          2305,
          311,
          264,
          9007,
          12325,
          30,
          50414
        ]
      },
      {
        "avg_logprob": -0.3187375623126363,
        "compression_ratio": 1.3636363636363635,
        "end": 7987.8,
        "id": 1269,
        "no_speech_prob": 0.0005357792251743376,
        "seek": 798580,
        "start": 7986.8,
        "temperature": 0,
        "text": " That's not right.",
        "tokens": [
          50414,
          663,
          311,
          406,
          558,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.3187375623126363,
        "compression_ratio": 1.3636363636363635,
        "end": 7989.8,
        "id": 1270,
        "no_speech_prob": 0.0005357792251743376,
        "seek": 798580,
        "start": 7987.8,
        "temperature": 0,
        "text": " Here it is.",
        "tokens": [
          50464,
          1692,
          309,
          307,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.3187375623126363,
        "compression_ratio": 1.3636363636363635,
        "end": 7992.8,
        "id": 1271,
        "no_speech_prob": 0.0005357792251743376,
        "seek": 798580,
        "start": 7989.8,
        "temperature": 0,
        "text": " So I just need 500 of 549, right?",
        "tokens": [
          50564,
          407,
          286,
          445,
          643,
          5923,
          295,
          1025,
          14938,
          11,
          558,
          30,
          50714
        ]
      },
      {
        "avg_logprob": -0.3187375623126363,
        "compression_ratio": 1.3636363636363635,
        "end": 7998.8,
        "id": 1272,
        "no_speech_prob": 0.0005357792251743376,
        "seek": 798580,
        "start": 7996.8,
        "temperature": 0,
        "text": " Do these look even noisy?",
        "tokens": [
          50914,
          1144,
          613,
          574,
          754,
          24518,
          30,
          51014
        ]
      },
      {
        "avg_logprob": -0.3187375623126363,
        "compression_ratio": 1.3636363636363635,
        "end": 7999.8,
        "id": 1273,
        "no_speech_prob": 0.0005357792251743376,
        "seek": 798580,
        "start": 7998.8,
        "temperature": 0,
        "text": " Hold on.",
        "tokens": [
          51014,
          6962,
          322,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.3187375623126363,
        "compression_ratio": 1.3636363636363635,
        "end": 8000.8,
        "id": 1274,
        "no_speech_prob": 0.0005357792251743376,
        "seek": 798580,
        "start": 7999.8,
        "temperature": 0,
        "text": " Let's look at some of these.",
        "tokens": [
          51064,
          961,
          311,
          574,
          412,
          512,
          295,
          613,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.3187375623126363,
        "compression_ratio": 1.3636363636363635,
        "end": 8006.8,
        "id": 1275,
        "no_speech_prob": 0.0005357792251743376,
        "seek": 798580,
        "start": 8005.8,
        "temperature": 0,
        "text": " Oh, you know what?",
        "tokens": [
          51364,
          876,
          11,
          291,
          458,
          437,
          30,
          51414
        ]
      },
      {
        "avg_logprob": -0.3187375623126363,
        "compression_ratio": 1.3636363636363635,
        "end": 8011.8,
        "id": 1276,
        "no_speech_prob": 0.0005357792251743376,
        "seek": 798580,
        "start": 8006.8,
        "temperature": 0,
        "text": " In the sampling down of it, I'm going to add a bunch of noise.",
        "tokens": [
          51414,
          682,
          264,
          21179,
          760,
          295,
          309,
          11,
          286,
          478,
          516,
          281,
          909,
          257,
          3840,
          295,
          5658,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.13263033204159494,
        "compression_ratio": 1.302325581395349,
        "end": 8013.8,
        "id": 1277,
        "no_speech_prob": 0.00006502804171759635,
        "seek": 801180,
        "start": 8012.8,
        "temperature": 0,
        "text": " Oh, you know what?",
        "tokens": [
          50414,
          876,
          11,
          291,
          458,
          437,
          30,
          50464
        ]
      },
      {
        "avg_logprob": -0.13263033204159494,
        "compression_ratio": 1.302325581395349,
        "end": 8018.8,
        "id": 1278,
        "no_speech_prob": 0.00006502804171759635,
        "seek": 801180,
        "start": 8013.8,
        "temperature": 0,
        "text": " In the sampling down of it, the noise is really gone.",
        "tokens": [
          50464,
          682,
          264,
          21179,
          760,
          295,
          309,
          11,
          264,
          5658,
          307,
          534,
          2780,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.13263033204159494,
        "compression_ratio": 1.302325581395349,
        "end": 8022.8,
        "id": 1279,
        "no_speech_prob": 0.00006502804171759635,
        "seek": 801180,
        "start": 8018.8,
        "temperature": 0,
        "text": " So let's do this.",
        "tokens": [
          50714,
          407,
          718,
          311,
          360,
          341,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.13263033204159494,
        "compression_ratio": 1.302325581395349,
        "end": 8028.8,
        "id": 1280,
        "no_speech_prob": 0.00006502804171759635,
        "seek": 801180,
        "start": 8027.8,
        "temperature": 0,
        "text": " This will be better, I think.",
        "tokens": [
          51164,
          639,
          486,
          312,
          1101,
          11,
          286,
          519,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.13263033204159494,
        "compression_ratio": 1.302325581395349,
        "end": 8037.8,
        "id": 1281,
        "no_speech_prob": 0.00006502804171759635,
        "seek": 801180,
        "start": 8032.8,
        "temperature": 0,
        "text": " This is so silly what I'm doing, but it's fine.",
        "tokens": [
          51414,
          639,
          307,
          370,
          11774,
          437,
          286,
          478,
          884,
          11,
          457,
          309,
          311,
          2489,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.20431213691586353,
        "compression_ratio": 1.3161764705882353,
        "end": 8040.8,
        "id": 1282,
        "no_speech_prob": 0.00017674401169642806,
        "seek": 803780,
        "start": 8038.8,
        "temperature": 0,
        "text": " All right.",
        "tokens": [
          50414,
          1057,
          558,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.20431213691586353,
        "compression_ratio": 1.3161764705882353,
        "end": 8045.8,
        "id": 1283,
        "no_speech_prob": 0.00017674401169642806,
        "seek": 803780,
        "start": 8040.8,
        "temperature": 0,
        "text": " This might be too noisy, but let's give it a whirl.",
        "tokens": [
          50514,
          639,
          1062,
          312,
          886,
          24518,
          11,
          457,
          718,
          311,
          976,
          309,
          257,
          35706,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.20431213691586353,
        "compression_ratio": 1.3161764705882353,
        "end": 8052.8,
        "id": 1284,
        "no_speech_prob": 0.00017674401169642806,
        "seek": 803780,
        "start": 8045.8,
        "temperature": 0,
        "text": " OK, so I'm going to take these, just these last 49 images,",
        "tokens": [
          50764,
          2264,
          11,
          370,
          286,
          478,
          516,
          281,
          747,
          613,
          11,
          445,
          613,
          1036,
          16513,
          5267,
          11,
          51114
        ]
      },
      {
        "avg_logprob": -0.20431213691586353,
        "compression_ratio": 1.3161764705882353,
        "end": 8055.8,
        "id": 1285,
        "no_speech_prob": 0.00017674401169642806,
        "seek": 803780,
        "start": 8052.8,
        "temperature": 0,
        "text": " and I'm going to put them in here.",
        "tokens": [
          51114,
          293,
          286,
          478,
          516,
          281,
          829,
          552,
          294,
          510,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.20431213691586353,
        "compression_ratio": 1.3161764705882353,
        "end": 8059.8,
        "id": 1286,
        "no_speech_prob": 0.00017674401169642806,
        "seek": 803780,
        "start": 8055.8,
        "temperature": 0,
        "text": " Apply to all, replace.",
        "tokens": [
          51264,
          25264,
          281,
          439,
          11,
          7406,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.2052037643663811,
        "compression_ratio": 1.4183006535947713,
        "end": 8071.8,
        "id": 1287,
        "no_speech_prob": 0.0000337372075591702,
        "seek": 805980,
        "start": 8059.8,
        "temperature": 0,
        "text": " So just so we're clear, the first 499 images, if we were looking at these,",
        "tokens": [
          50364,
          407,
          445,
          370,
          321,
          434,
          1850,
          11,
          264,
          700,
          1017,
          8494,
          5267,
          11,
          498,
          321,
          645,
          1237,
          412,
          613,
          11,
          50964
        ]
      },
      {
        "avg_logprob": -0.2052037643663811,
        "compression_ratio": 1.4183006535947713,
        "end": 8073.8,
        "id": 1288,
        "no_speech_prob": 0.0000337372075591702,
        "seek": 805980,
        "start": 8071.8,
        "temperature": 0,
        "text": " these are just plain squares.",
        "tokens": [
          50964,
          613,
          366,
          445,
          11121,
          19368,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.2052037643663811,
        "compression_ratio": 1.4183006535947713,
        "end": 8075.8,
        "id": 1289,
        "no_speech_prob": 0.0000337372075591702,
        "seek": 805980,
        "start": 8073.8,
        "temperature": 0,
        "text": " But then my test images look like this.",
        "tokens": [
          51064,
          583,
          550,
          452,
          1500,
          5267,
          574,
          411,
          341,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.2052037643663811,
        "compression_ratio": 1.4183006535947713,
        "end": 8080.8,
        "id": 1290,
        "no_speech_prob": 0.0000337372075591702,
        "seek": 805980,
        "start": 8075.8,
        "temperature": 0,
        "text": " Can I denoise these images with my autoencoder?",
        "tokens": [
          51164,
          1664,
          286,
          1441,
          38800,
          613,
          5267,
          365,
          452,
          8399,
          22660,
          19866,
          30,
          51414
        ]
      },
      {
        "avg_logprob": -0.2052037643663811,
        "compression_ratio": 1.4183006535947713,
        "end": 8082.8,
        "id": 1291,
        "no_speech_prob": 0.0000337372075591702,
        "seek": 805980,
        "start": 8080.8,
        "temperature": 0,
        "text": " We're about to find out.",
        "tokens": [
          51414,
          492,
          434,
          466,
          281,
          915,
          484,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.25613995393117267,
        "compression_ratio": 1.2727272727272727,
        "end": 8090.8,
        "id": 1292,
        "no_speech_prob": 0.0006070722592994571,
        "seek": 808280,
        "start": 8083.8,
        "temperature": 0,
        "text": " So I'm now training the model off the first 499 images,",
        "tokens": [
          50414,
          407,
          286,
          478,
          586,
          3097,
          264,
          2316,
          766,
          264,
          700,
          1017,
          8494,
          5267,
          11,
          50764
        ]
      },
      {
        "avg_logprob": -0.25613995393117267,
        "compression_ratio": 1.2727272727272727,
        "end": 8095.8,
        "id": 1293,
        "no_speech_prob": 0.0006070722592994571,
        "seek": 808280,
        "start": 8090.8,
        "temperature": 0,
        "text": " letting it kind of get down as low as I can get it.",
        "tokens": [
          50764,
          8295,
          309,
          733,
          295,
          483,
          760,
          382,
          2295,
          382,
          286,
          393,
          483,
          309,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.25613995393117267,
        "compression_ratio": 1.2727272727272727,
        "end": 8099.8,
        "id": 1294,
        "no_speech_prob": 0.0006070722592994571,
        "seek": 808280,
        "start": 8095.8,
        "temperature": 0,
        "text": " And then we're going to look at what came out.",
        "tokens": [
          51014,
          400,
          550,
          321,
          434,
          516,
          281,
          574,
          412,
          437,
          1361,
          484,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.38498252980849323,
        "compression_ratio": 1.1898734177215189,
        "end": 8104.8,
        "id": 1295,
        "no_speech_prob": 0.008577356114983559,
        "seek": 809980,
        "start": 8099.8,
        "temperature": 0,
        "text": " So the output is, the output has the noise in it.",
        "tokens": [
          50364,
          407,
          264,
          5598,
          307,
          11,
          264,
          5598,
          575,
          264,
          5658,
          294,
          309,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.38498252980849323,
        "compression_ratio": 1.1898734177215189,
        "end": 8107.8,
        "id": 1296,
        "no_speech_prob": 0.008577356114983559,
        "seek": 809980,
        "start": 8104.8,
        "temperature": 0,
        "text": " We need to compare it one to one.",
        "tokens": [
          50614,
          492,
          643,
          281,
          6794,
          309,
          472,
          281,
          472,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.38498252980849323,
        "compression_ratio": 1.1898734177215189,
        "end": 8109.8,
        "id": 1297,
        "no_speech_prob": 0.008577356114983559,
        "seek": 809980,
        "start": 8107.8,
        "temperature": 0,
        "text": " So that's,",
        "tokens": [
          50764,
          407,
          300,
          311,
          11,
          50864
        ]
      },
      {
        "avg_logprob": -2.074721514168432,
        "compression_ratio": 1.3539823008849559,
        "end": 8113.8,
        "id": 1298,
        "no_speech_prob": 0.0053017460741102695,
        "seek": 810980,
        "start": 8109.8,
        "temperature": 1,
        "text": " it's a little less noisy, wouldn't you say?",
        "tokens": [
          50364,
          309,
          311,
          257,
          707,
          1570,
          24518,
          11,
          2759,
          380,
          291,
          584,
          30,
          50564
        ]
      },
      {
        "avg_logprob": -2.074721514168432,
        "compression_ratio": 1.3539823008849559,
        "end": 8119.8,
        "id": 1299,
        "no_speech_prob": 0.0053017460741102695,
        "seek": 810980,
        "start": 8113.8,
        "temperature": 1,
        "text": " These are the two background noise notes,",
        "tokens": [
          50564,
          1981,
          366,
          264,
          732,
          4773,
          547,
          2921,
          5658,
          5570,
          11,
          50864
        ]
      },
      {
        "avg_logprob": -2.074721514168432,
        "compression_ratio": 1.3539823008849559,
        "end": 8122.8,
        "id": 1300,
        "no_speech_prob": 0.0053017460741102695,
        "seek": 810980,
        "start": 8119.8,
        "temperature": 1,
        "text": " these are the two noise notes,",
        "tokens": [
          50864,
          220,
          42678,
          366,
          264,
          732,
          5658,
          220,
          1771,
          7269,
          11,
          51014
        ]
      },
      {
        "avg_logprob": -2.074721514168432,
        "compression_ratio": 1.3539823008849559,
        "end": 8124.8,
        "id": 1301,
        "no_speech_prob": 0.0053017460741102695,
        "seek": 810980,
        "start": 8122.8,
        "temperature": 1,
        "text": " so they're in cost.",
        "tokens": [
          51014,
          370,
          258,
          2030,
          434,
          294,
          2063,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -2.074721514168432,
        "compression_ratio": 1.3539823008849559,
        "end": 8128.56,
        "id": 1302,
        "no_speech_prob": 0.0053017460741102695,
        "seek": 810980,
        "start": 8124.8,
        "temperature": 1,
        "text": " 2.",
        "tokens": [
          51114,
          568,
          13,
          51302
        ]
      },
      {
        "avg_logprob": -2.074721514168432,
        "compression_ratio": 1.3539823008849559,
        "end": 8136.8,
        "id": 1303,
        "no_speech_prob": 0.0053017460741102695,
        "seek": 810980,
        "start": 8132.320000000001,
        "temperature": 1,
        "text": " A bit louder.",
        "tokens": [
          51490,
          316,
          857,
          22717,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.4326577322823661,
        "compression_ratio": 1.0795454545454546,
        "end": 8140.8,
        "id": 1304,
        "no_speech_prob": 0.0009397962712682784,
        "seek": 813680,
        "start": 8136.8,
        "temperature": 0,
        "text": " 3.",
        "tokens": [
          50364,
          805,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.4326577322823661,
        "compression_ratio": 1.0795454545454546,
        "end": 8149.8,
        "id": 1305,
        "no_speech_prob": 0.0009397962712682784,
        "seek": 813680,
        "start": 8145.8,
        "temperature": 0,
        "text": " It's slightly denoised.",
        "tokens": [
          50814,
          467,
          311,
          4748,
          1441,
          78,
          2640,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.4326577322823661,
        "compression_ratio": 1.0795454545454546,
        "end": 8153.8,
        "id": 1306,
        "no_speech_prob": 0.0009397962712682784,
        "seek": 813680,
        "start": 8149.8,
        "temperature": 0,
        "text": " Interesting.",
        "tokens": [
          51014,
          14711,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.4326577322823661,
        "compression_ratio": 1.0795454545454546,
        "end": 8163.8,
        "id": 1307,
        "no_speech_prob": 0.0009397962712682784,
        "seek": 813680,
        "start": 8157.8,
        "temperature": 0,
        "text": " So, this is not the application that I'm looking to do.",
        "tokens": [
          51414,
          407,
          11,
          341,
          307,
          406,
          264,
          3861,
          300,
          286,
          478,
          1237,
          281,
          360,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.24258329318119928,
        "compression_ratio": 1.5404255319148936,
        "end": 8167.8,
        "id": 1308,
        "no_speech_prob": 0.25082725286483765,
        "seek": 816380,
        "start": 8163.8,
        "temperature": 0,
        "text": " What I would like to do, and I think I'll have to wait for part 3,",
        "tokens": [
          50364,
          708,
          286,
          576,
          411,
          281,
          360,
          11,
          293,
          286,
          519,
          286,
          603,
          362,
          281,
          1699,
          337,
          644,
          805,
          11,
          50564
        ]
      },
      {
        "avg_logprob": -0.24258329318119928,
        "compression_ratio": 1.5404255319148936,
        "end": 8171.8,
        "id": 1309,
        "no_speech_prob": 0.25082725286483765,
        "seek": 816380,
        "start": 8167.8,
        "temperature": 0,
        "text": " is I want to, first of all, bump up the resolution a little bit, perhaps.",
        "tokens": [
          50564,
          307,
          286,
          528,
          281,
          11,
          700,
          295,
          439,
          11,
          9961,
          493,
          264,
          8669,
          257,
          707,
          857,
          11,
          4317,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.24258329318119928,
        "compression_ratio": 1.5404255319148936,
        "end": 8176.8,
        "id": 1310,
        "no_speech_prob": 0.25082725286483765,
        "seek": 816380,
        "start": 8171.8,
        "temperature": 0,
        "text": " Then, it looks like it's smoothed the noise, yeah.",
        "tokens": [
          50764,
          1396,
          11,
          309,
          1542,
          411,
          309,
          311,
          5508,
          292,
          264,
          5658,
          11,
          1338,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.24258329318119928,
        "compression_ratio": 1.5404255319148936,
        "end": 8181.8,
        "id": 1311,
        "no_speech_prob": 0.25082725286483765,
        "seek": 816380,
        "start": 8176.8,
        "temperature": 0,
        "text": " No, I didn't train with the...",
        "tokens": [
          51014,
          883,
          11,
          286,
          994,
          380,
          3847,
          365,
          264,
          485,
          51264
        ]
      },
      {
        "avg_logprob": -0.24258329318119928,
        "compression_ratio": 1.5404255319148936,
        "end": 8186.8,
        "id": 1312,
        "no_speech_prob": 0.25082725286483765,
        "seek": 816380,
        "start": 8181.8,
        "temperature": 0,
        "text": " MiniJimmy says the output has the noise because the noisy pictures were trained at the end.",
        "tokens": [
          51264,
          18239,
          36806,
          2226,
          1619,
          264,
          5598,
          575,
          264,
          5658,
          570,
          264,
          24518,
          5242,
          645,
          8895,
          412,
          264,
          917,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.24258329318119928,
        "compression_ratio": 1.5404255319148936,
        "end": 8189.8,
        "id": 1313,
        "no_speech_prob": 0.25082725286483765,
        "seek": 816380,
        "start": 8186.8,
        "temperature": 0,
        "text": " Those shouldn't have been part of the training.",
        "tokens": [
          51514,
          3950,
          4659,
          380,
          362,
          668,
          644,
          295,
          264,
          3097,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.21136627640835073,
        "compression_ratio": 1.528205128205128,
        "end": 8195.8,
        "id": 1314,
        "no_speech_prob": 0.025173235684633255,
        "seek": 818980,
        "start": 8189.8,
        "temperature": 0,
        "text": " The way I've written the code is I'm only training it with the first 500 images.",
        "tokens": [
          50364,
          440,
          636,
          286,
          600,
          3720,
          264,
          3089,
          307,
          286,
          478,
          787,
          3097,
          309,
          365,
          264,
          700,
          5923,
          5267,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.21136627640835073,
        "compression_ratio": 1.528205128205128,
        "end": 8199.8,
        "id": 1315,
        "no_speech_prob": 0.025173235684633255,
        "seek": 818980,
        "start": 8195.8,
        "temperature": 0,
        "text": " So, it shouldn't have any of the... and I just put in the last 50.",
        "tokens": [
          50664,
          407,
          11,
          309,
          4659,
          380,
          362,
          604,
          295,
          264,
          485,
          293,
          286,
          445,
          829,
          294,
          264,
          1036,
          2625,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.21136627640835073,
        "compression_ratio": 1.528205128205128,
        "end": 8206.8,
        "id": 1316,
        "no_speech_prob": 0.025173235684633255,
        "seek": 818980,
        "start": 8199.8,
        "temperature": 0,
        "text": " So, if I manipulated my files correctly, in terms of the input images,",
        "tokens": [
          50864,
          407,
          11,
          498,
          286,
          37161,
          452,
          7098,
          8944,
          11,
          294,
          2115,
          295,
          264,
          4846,
          5267,
          11,
          51214
        ]
      },
      {
        "avg_logprob": -0.21136627640835073,
        "compression_ratio": 1.528205128205128,
        "end": 8213.8,
        "id": 1317,
        "no_speech_prob": 0.025173235684633255,
        "seek": 818980,
        "start": 8206.8,
        "temperature": 0,
        "text": " there should be no noise all the way until 499.",
        "tokens": [
          51214,
          456,
          820,
          312,
          572,
          5658,
          439,
          264,
          636,
          1826,
          1017,
          8494,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.21136627640835073,
        "compression_ratio": 1.528205128205128,
        "end": 8215.8,
        "id": 1318,
        "no_speech_prob": 0.025173235684633255,
        "seek": 818980,
        "start": 8213.8,
        "temperature": 0,
        "text": " And then, they should be noisy.",
        "tokens": [
          51564,
          400,
          550,
          11,
          436,
          820,
          312,
          24518,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.24415276845296224,
        "compression_ratio": 1.4558823529411764,
        "end": 8219.8,
        "id": 1319,
        "no_speech_prob": 0.004829170648008585,
        "seek": 821580,
        "start": 8215.8,
        "temperature": 0,
        "text": " So, these are the training images, and then these are the test images.",
        "tokens": [
          50364,
          407,
          11,
          613,
          366,
          264,
          3097,
          5267,
          11,
          293,
          550,
          613,
          366,
          264,
          1500,
          5267,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.24415276845296224,
        "compression_ratio": 1.4558823529411764,
        "end": 8225.8,
        "id": 1320,
        "no_speech_prob": 0.004829170648008585,
        "seek": 821580,
        "start": 8222.8,
        "temperature": 0,
        "text": " Something happened with the loss and acceleration, yeah.",
        "tokens": [
          50714,
          6595,
          2011,
          365,
          264,
          4470,
          293,
          17162,
          11,
          1338,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.24415276845296224,
        "compression_ratio": 1.4558823529411764,
        "end": 8230.8,
        "id": 1321,
        "no_speech_prob": 0.004829170648008585,
        "seek": 821580,
        "start": 8225.8,
        "temperature": 0,
        "text": " So, let's... let me post this code.",
        "tokens": [
          50864,
          407,
          11,
          718,
          311,
          485,
          718,
          385,
          2183,
          341,
          3089,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.24415276845296224,
        "compression_ratio": 1.4558823529411764,
        "end": 8241.8,
        "id": 1322,
        "no_speech_prob": 0.004829170648008585,
        "seek": 821580,
        "start": 8237.8,
        "temperature": 0,
        "text": " Let's see, I don't want this JPEG.",
        "tokens": [
          51464,
          961,
          311,
          536,
          11,
          286,
          500,
          380,
          528,
          341,
          508,
          5208,
          38,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.2813327251336513,
        "compression_ratio": 1.134020618556701,
        "end": 8245.8,
        "id": 1323,
        "no_speech_prob": 0.0014778942568227649,
        "seek": 824180,
        "start": 8242.8,
        "temperature": 0,
        "text": " I'm going to do a couple of things.",
        "tokens": [
          50414,
          286,
          478,
          516,
          281,
          360,
          257,
          1916,
          295,
          721,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.2813327251336513,
        "compression_ratio": 1.134020618556701,
        "end": 8249.8,
        "id": 1324,
        "no_speech_prob": 0.0014778942568227649,
        "seek": 824180,
        "start": 8245.8,
        "temperature": 0,
        "text": " One is no JPEGs.",
        "tokens": [
          50564,
          1485,
          307,
          572,
          508,
          5208,
          33715,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.2813327251336513,
        "compression_ratio": 1.134020618556701,
        "end": 8256.8,
        "id": 1325,
        "no_speech_prob": 0.0014778942568227649,
        "seek": 824180,
        "start": 8249.8,
        "temperature": 0,
        "text": " Let me also get the training data generator into...",
        "tokens": [
          50764,
          961,
          385,
          611,
          483,
          264,
          3097,
          1412,
          19265,
          666,
          485,
          51114
        ]
      },
      {
        "avg_logprob": -0.2813327251336513,
        "compression_ratio": 1.134020618556701,
        "end": 8263.8,
        "id": 1326,
        "no_speech_prob": 0.0014778942568227649,
        "seek": 824180,
        "start": 8261.8,
        "temperature": 0,
        "text": " here.",
        "tokens": [
          51364,
          510,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.2402619407290504,
        "compression_ratio": 1.4438202247191012,
        "end": 8271.8,
        "id": 1327,
        "no_speech_prob": 0.007576625794172287,
        "seek": 826380,
        "start": 8263.8,
        "temperature": 0,
        "text": " So, this should be...",
        "tokens": [
          50364,
          407,
          11,
          341,
          820,
          312,
          485,
          50764
        ]
      },
      {
        "avg_logprob": -0.2402619407290504,
        "compression_ratio": 1.4438202247191012,
        "end": 8275.8,
        "id": 1328,
        "no_speech_prob": 0.007576625794172287,
        "seek": 826380,
        "start": 8271.8,
        "temperature": 0,
        "text": " So, I'm adding...",
        "tokens": [
          50764,
          407,
          11,
          286,
          478,
          5127,
          485,
          50964
        ]
      },
      {
        "avg_logprob": -0.2402619407290504,
        "compression_ratio": 1.4438202247191012,
        "end": 8279.8,
        "id": 1329,
        "no_speech_prob": 0.007576625794172287,
        "seek": 826380,
        "start": 8275.8,
        "temperature": 0,
        "text": " and that test file I don't need anymore because I just wasn't sure about,",
        "tokens": [
          50964,
          293,
          300,
          1500,
          3991,
          286,
          500,
          380,
          643,
          3602,
          570,
          286,
          445,
          2067,
          380,
          988,
          466,
          11,
          51164
        ]
      },
      {
        "avg_logprob": -0.2402619407290504,
        "compression_ratio": 1.4438202247191012,
        "end": 8281.8,
        "id": 1330,
        "no_speech_prob": 0.007576625794172287,
        "seek": 826380,
        "start": 8279.8,
        "temperature": 0,
        "text": " but I'll leave that in there.",
        "tokens": [
          51164,
          457,
          286,
          603,
          1856,
          300,
          294,
          456,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.2402619407290504,
        "compression_ratio": 1.4438202247191012,
        "end": 8283.8,
        "id": 1331,
        "no_speech_prob": 0.007576625794172287,
        "seek": 826380,
        "start": 8281.8,
        "temperature": 0,
        "text": " So, git ignore index package.",
        "tokens": [
          51264,
          407,
          11,
          18331,
          11200,
          8186,
          7372,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.2402619407290504,
        "compression_ratio": 1.4438202247191012,
        "end": 8285.8,
        "id": 1332,
        "no_speech_prob": 0.007576625794172287,
        "seek": 826380,
        "start": 8283.8,
        "temperature": 0,
        "text": " Could it be pulling in image 500?",
        "tokens": [
          51364,
          7497,
          309,
          312,
          8407,
          294,
          3256,
          5923,
          30,
          51464
        ]
      },
      {
        "avg_logprob": -0.2402619407290504,
        "compression_ratio": 1.4438202247191012,
        "end": 8286.8,
        "id": 1333,
        "no_speech_prob": 0.007576625794172287,
        "seek": 826380,
        "start": 8285.8,
        "temperature": 0,
        "text": " That might be an issue.",
        "tokens": [
          51464,
          663,
          1062,
          312,
          364,
          2734,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.2402619407290504,
        "compression_ratio": 1.4438202247191012,
        "end": 8288.8,
        "id": 1334,
        "no_speech_prob": 0.007576625794172287,
        "seek": 826380,
        "start": 8286.8,
        "temperature": 0,
        "text": " I don't think so, though.",
        "tokens": [
          51514,
          286,
          500,
          380,
          519,
          370,
          11,
          1673,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.2237166924910112,
        "compression_ratio": 1.4143646408839778,
        "end": 8293.8,
        "id": 1335,
        "no_speech_prob": 0.0035379857290536165,
        "seek": 828880,
        "start": 8289.8,
        "temperature": 0,
        "text": " Oh, they should be part of the training versus no noise in the target.",
        "tokens": [
          50414,
          876,
          11,
          436,
          820,
          312,
          644,
          295,
          264,
          3097,
          5717,
          572,
          5658,
          294,
          264,
          3779,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.2237166924910112,
        "compression_ratio": 1.4143646408839778,
        "end": 8295.8,
        "id": 1336,
        "no_speech_prob": 0.0035379857290536165,
        "seek": 828880,
        "start": 8293.8,
        "temperature": 0,
        "text": " Yeah, that's interesting.",
        "tokens": [
          50614,
          865,
          11,
          300,
          311,
          1880,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.2237166924910112,
        "compression_ratio": 1.4143646408839778,
        "end": 8297.8,
        "id": 1337,
        "no_speech_prob": 0.0035379857290536165,
        "seek": 828880,
        "start": 8295.8,
        "temperature": 0,
        "text": " Right, that makes more sense.",
        "tokens": [
          50714,
          1779,
          11,
          300,
          1669,
          544,
          2020,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.2237166924910112,
        "compression_ratio": 1.4143646408839778,
        "end": 8302.8,
        "id": 1338,
        "no_speech_prob": 0.0035379857290536165,
        "seek": 828880,
        "start": 8297.8,
        "temperature": 0,
        "text": " So, yes, and so now...",
        "tokens": [
          50814,
          407,
          11,
          2086,
          11,
          293,
          370,
          586,
          485,
          51064
        ]
      },
      {
        "avg_logprob": -0.2237166924910112,
        "compression_ratio": 1.4143646408839778,
        "end": 8306.8,
        "id": 1339,
        "no_speech_prob": 0.0035379857290536165,
        "seek": 828880,
        "start": 8302.8,
        "temperature": 0,
        "text": " code after part two.",
        "tokens": [
          51064,
          3089,
          934,
          644,
          732,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.2237166924910112,
        "compression_ratio": 1.4143646408839778,
        "end": 8314.8,
        "id": 1340,
        "no_speech_prob": 0.0035379857290536165,
        "seek": 828880,
        "start": 8312.8,
        "temperature": 0,
        "text": " Now, I'm pushing it.",
        "tokens": [
          51564,
          823,
          11,
          286,
          478,
          7380,
          309,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.2237166924910112,
        "compression_ratio": 1.4143646408839778,
        "end": 8315.8,
        "id": 1341,
        "no_speech_prob": 0.0035379857290536165,
        "seek": 828880,
        "start": 8314.8,
        "temperature": 0,
        "text": " I got to go to the grocery store.",
        "tokens": [
          51664,
          286,
          658,
          281,
          352,
          281,
          264,
          14410,
          3531,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.2237166924910112,
        "compression_ratio": 1.4143646408839778,
        "end": 8317.8,
        "id": 1342,
        "no_speech_prob": 0.0035379857290536165,
        "seek": 828880,
        "start": 8315.8,
        "temperature": 0,
        "text": " It's not 5 o'clock yet, is it?",
        "tokens": [
          51714,
          467,
          311,
          406,
          1025,
          277,
          6,
          9023,
          1939,
          11,
          307,
          309,
          30,
          51814
        ]
      },
      {
        "avg_logprob": -0.1892107229317184,
        "compression_ratio": 1.5217391304347827,
        "end": 8318.8,
        "id": 1343,
        "no_speech_prob": 0.003593569854274392,
        "seek": 831780,
        "start": 8317.8,
        "temperature": 0,
        "text": " Oh, it's 4 o'clock.",
        "tokens": [
          50364,
          876,
          11,
          309,
          311,
          1017,
          277,
          6,
          9023,
          13,
          50414
        ]
      },
      {
        "avg_logprob": -0.1892107229317184,
        "compression_ratio": 1.5217391304347827,
        "end": 8320.8,
        "id": 1344,
        "no_speech_prob": 0.003593569854274392,
        "seek": 831780,
        "start": 8318.8,
        "temperature": 0,
        "text": " Okay, I'm way over time here.",
        "tokens": [
          50414,
          1033,
          11,
          286,
          478,
          636,
          670,
          565,
          510,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.1892107229317184,
        "compression_ratio": 1.5217391304347827,
        "end": 8325.8,
        "id": 1345,
        "no_speech_prob": 0.003593569854274392,
        "seek": 831780,
        "start": 8323.8,
        "temperature": 0,
        "text": " Sorry, looking at my...",
        "tokens": [
          50664,
          4919,
          11,
          1237,
          412,
          452,
          485,
          50764
        ]
      },
      {
        "avg_logprob": -0.1892107229317184,
        "compression_ratio": 1.5217391304347827,
        "end": 8329.8,
        "id": 1346,
        "no_speech_prob": 0.003593569854274392,
        "seek": 831780,
        "start": 8328.8,
        "temperature": 0,
        "text": " text messages.",
        "tokens": [
          50914,
          2487,
          7897,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.1892107229317184,
        "compression_ratio": 1.5217391304347827,
        "end": 8330.8,
        "id": 1347,
        "no_speech_prob": 0.003593569854274392,
        "seek": 831780,
        "start": 8329.8,
        "temperature": 0,
        "text": " Okay, more epochs.",
        "tokens": [
          50964,
          1033,
          11,
          544,
          30992,
          28346,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.1892107229317184,
        "compression_ratio": 1.5217391304347827,
        "end": 8334.8,
        "id": 1348,
        "no_speech_prob": 0.003593569854274392,
        "seek": 831780,
        "start": 8330.8,
        "temperature": 0,
        "text": " I don't think it's going to get down below...",
        "tokens": [
          51014,
          286,
          500,
          380,
          519,
          309,
          311,
          516,
          281,
          483,
          760,
          2507,
          485,
          51214
        ]
      },
      {
        "avg_logprob": -0.1892107229317184,
        "compression_ratio": 1.5217391304347827,
        "end": 8336.8,
        "id": 1349,
        "no_speech_prob": 0.003593569854274392,
        "seek": 831780,
        "start": 8334.8,
        "temperature": 0,
        "text": " So, there's so much that could be done to improve this.",
        "tokens": [
          51214,
          407,
          11,
          456,
          311,
          370,
          709,
          300,
          727,
          312,
          1096,
          281,
          3470,
          341,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.1892107229317184,
        "compression_ratio": 1.5217391304347827,
        "end": 8338.8,
        "id": 1350,
        "no_speech_prob": 0.003593569854274392,
        "seek": 831780,
        "start": 8336.8,
        "temperature": 0,
        "text": " This is just a start.",
        "tokens": [
          51314,
          639,
          307,
          445,
          257,
          722,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.1892107229317184,
        "compression_ratio": 1.5217391304347827,
        "end": 8342.8,
        "id": 1351,
        "no_speech_prob": 0.003593569854274392,
        "seek": 831780,
        "start": 8338.8,
        "temperature": 0,
        "text": " Here are some suggestions if anybody wants to pick up and continue this.",
        "tokens": [
          51414,
          1692,
          366,
          512,
          13396,
          498,
          4472,
          2738,
          281,
          1888,
          493,
          293,
          2354,
          341,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.1892107229317184,
        "compression_ratio": 1.5217391304347827,
        "end": 8344.8,
        "id": 1352,
        "no_speech_prob": 0.003593569854274392,
        "seek": 831780,
        "start": 8342.8,
        "temperature": 0,
        "text": " I'll try to come back and do this part three.",
        "tokens": [
          51614,
          286,
          603,
          853,
          281,
          808,
          646,
          293,
          360,
          341,
          644,
          1045,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.20228683948516846,
        "compression_ratio": 1.6150442477876106,
        "end": 8352.8,
        "id": 1353,
        "no_speech_prob": 0.014728058129549026,
        "seek": 834480,
        "start": 8344.8,
        "temperature": 0,
        "text": " Number one is, you know, I kind of haven't been too thoughtful about the layers I'm putting in here",
        "tokens": [
          50364,
          5118,
          472,
          307,
          11,
          291,
          458,
          11,
          286,
          733,
          295,
          2378,
          380,
          668,
          886,
          21566,
          466,
          264,
          7914,
          286,
          478,
          3372,
          294,
          510,
          50764
        ]
      },
      {
        "avg_logprob": -0.20228683948516846,
        "compression_ratio": 1.6150442477876106,
        "end": 8359.8,
        "id": 1354,
        "no_speech_prob": 0.014728058129549026,
        "seek": 834480,
        "start": 8352.8,
        "temperature": 0,
        "text": " in terms of the number of units, what activation functions I'm doing, and this kind of stuff.",
        "tokens": [
          50764,
          294,
          2115,
          295,
          264,
          1230,
          295,
          6815,
          11,
          437,
          24433,
          6828,
          286,
          478,
          884,
          11,
          293,
          341,
          733,
          295,
          1507,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.20228683948516846,
        "compression_ratio": 1.6150442477876106,
        "end": 8363.8,
        "id": 1355,
        "no_speech_prob": 0.014728058129549026,
        "seek": 834480,
        "start": 8359.8,
        "temperature": 0,
        "text": " So, I would love for any of you who's interested to sort of play around with this,",
        "tokens": [
          51114,
          407,
          11,
          286,
          576,
          959,
          337,
          604,
          295,
          291,
          567,
          311,
          3102,
          281,
          1333,
          295,
          862,
          926,
          365,
          341,
          11,
          51314
        ]
      },
      {
        "avg_logprob": -0.20228683948516846,
        "compression_ratio": 1.6150442477876106,
        "end": 8365.8,
        "id": 1356,
        "no_speech_prob": 0.014728058129549026,
        "seek": 834480,
        "start": 8363.8,
        "temperature": 0,
        "text": " see what kind of results you get.",
        "tokens": [
          51314,
          536,
          437,
          733,
          295,
          3542,
          291,
          483,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.20228683948516846,
        "compression_ratio": 1.6150442477876106,
        "end": 8370.8,
        "id": 1357,
        "no_speech_prob": 0.014728058129549026,
        "seek": 834480,
        "start": 8365.8,
        "temperature": 0,
        "text": " Ultimately, what I would like to do is take this model",
        "tokens": [
          51414,
          23921,
          11,
          437,
          286,
          576,
          411,
          281,
          360,
          307,
          747,
          341,
          2316,
          51664
        ]
      },
      {
        "avg_logprob": -0.2680061397267811,
        "compression_ratio": 1.478527607361963,
        "end": 8376.8,
        "id": 1358,
        "no_speech_prob": 0.0488566979765892,
        "seek": 837080,
        "start": 8371.8,
        "temperature": 0,
        "text": " and be able to start feeding in data just from here.",
        "tokens": [
          50414,
          293,
          312,
          1075,
          281,
          722,
          12919,
          294,
          1412,
          445,
          490,
          510,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.2680061397267811,
        "compression_ratio": 1.478527607361963,
        "end": 8382.8,
        "id": 1359,
        "no_speech_prob": 0.0488566979765892,
        "seek": 837080,
        "start": 8376.8,
        "temperature": 0,
        "text": " So, I want to take random data and...",
        "tokens": [
          50664,
          407,
          11,
          286,
          528,
          281,
          747,
          4974,
          1412,
          293,
          485,
          50964
        ]
      },
      {
        "avg_logprob": -0.2680061397267811,
        "compression_ratio": 1.478527607361963,
        "end": 8391.8,
        "id": 1360,
        "no_speech_prob": 0.0488566979765892,
        "seek": 837080,
        "start": 8385.8,
        "temperature": 0,
        "text": " I basically want to start looking at this as a way to browse the latent space.",
        "tokens": [
          51114,
          286,
          1936,
          528,
          281,
          722,
          1237,
          412,
          341,
          382,
          257,
          636,
          281,
          31442,
          264,
          48994,
          1901,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.2680061397267811,
        "compression_ratio": 1.478527607361963,
        "end": 8395.8,
        "id": 1361,
        "no_speech_prob": 0.0488566979765892,
        "seek": 837080,
        "start": 8391.8,
        "temperature": 0,
        "text": " And the other thing is, like, this is just a plain vanilla autoencoder.",
        "tokens": [
          51414,
          400,
          264,
          661,
          551,
          307,
          11,
          411,
          11,
          341,
          307,
          445,
          257,
          11121,
          17528,
          8399,
          22660,
          19866,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.18330511525899423,
        "compression_ratio": 1.7396694214876034,
        "end": 8400.8,
        "id": 1362,
        "no_speech_prob": 0.1365993171930313,
        "seek": 839580,
        "start": 8396.8,
        "temperature": 0,
        "text": " And there is something called a variational autoencoder.",
        "tokens": [
          50414,
          400,
          456,
          307,
          746,
          1219,
          257,
          3034,
          1478,
          8399,
          22660,
          19866,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.18330511525899423,
        "compression_ratio": 1.7396694214876034,
        "end": 8406.8,
        "id": 1363,
        "no_speech_prob": 0.1365993171930313,
        "seek": 839580,
        "start": 8400.8,
        "temperature": 0,
        "text": " So, what would I need to do to this to make it from a just this sort of like beginner starting point autoencoder",
        "tokens": [
          50614,
          407,
          11,
          437,
          576,
          286,
          643,
          281,
          360,
          281,
          341,
          281,
          652,
          309,
          490,
          257,
          445,
          341,
          1333,
          295,
          411,
          22080,
          2891,
          935,
          8399,
          22660,
          19866,
          50914
        ]
      },
      {
        "avg_logprob": -0.18330511525899423,
        "compression_ratio": 1.7396694214876034,
        "end": 8408.8,
        "id": 1364,
        "no_speech_prob": 0.1365993171930313,
        "seek": 839580,
        "start": 8406.8,
        "temperature": 0,
        "text": " and make a variational autoencoder?",
        "tokens": [
          50914,
          293,
          652,
          257,
          3034,
          1478,
          8399,
          22660,
          19866,
          30,
          51014
        ]
      },
      {
        "avg_logprob": -0.18330511525899423,
        "compression_ratio": 1.7396694214876034,
        "end": 8410.8,
        "id": 1365,
        "no_speech_prob": 0.1365993171930313,
        "seek": 839580,
        "start": 8408.8,
        "temperature": 0,
        "text": " I would like to know.",
        "tokens": [
          51014,
          286,
          576,
          411,
          281,
          458,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.18330511525899423,
        "compression_ratio": 1.7396694214876034,
        "end": 8417.8,
        "id": 1366,
        "no_speech_prob": 0.1365993171930313,
        "seek": 839580,
        "start": 8412.8,
        "temperature": 0,
        "text": " Right, and Simon is saying, you didn't get to generating new images with the decoder only.",
        "tokens": [
          51214,
          1779,
          11,
          293,
          13193,
          307,
          1566,
          11,
          291,
          994,
          380,
          483,
          281,
          17746,
          777,
          5267,
          365,
          264,
          979,
          19866,
          787,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.18330511525899423,
        "compression_ratio": 1.7396694214876034,
        "end": 8420.8,
        "id": 1367,
        "no_speech_prob": 0.1365993171930313,
        "seek": 839580,
        "start": 8417.8,
        "temperature": 0,
        "text": " So, that's got to be in part three.",
        "tokens": [
          51464,
          407,
          11,
          300,
          311,
          658,
          281,
          312,
          294,
          644,
          1045,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.18330511525899423,
        "compression_ratio": 1.7396694214876034,
        "end": 8424.8,
        "id": 1368,
        "no_speech_prob": 0.1365993171930313,
        "seek": 839580,
        "start": 8420.8,
        "temperature": 0,
        "text": " So, if you would like to pick this up and run with it on your own,",
        "tokens": [
          51614,
          407,
          11,
          498,
          291,
          576,
          411,
          281,
          1888,
          341,
          493,
          293,
          1190,
          365,
          309,
          322,
          428,
          1065,
          11,
          51814
        ]
      },
      {
        "avg_logprob": -0.18976996926700368,
        "compression_ratio": 1.5844155844155845,
        "end": 8427.8,
        "id": 1369,
        "no_speech_prob": 0.025955930352211,
        "seek": 842480,
        "start": 8424.8,
        "temperature": 0,
        "text": " you can go to github.com slash coding train.",
        "tokens": [
          50364,
          291,
          393,
          352,
          281,
          290,
          355,
          836,
          13,
          1112,
          17330,
          17720,
          3847,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.18976996926700368,
        "compression_ratio": 1.5844155844155845,
        "end": 8432.8,
        "id": 1370,
        "no_speech_prob": 0.025955930352211,
        "seek": 842480,
        "start": 8427.8,
        "temperature": 0,
        "text": " You can come here and check out the autoencoder demo.",
        "tokens": [
          50514,
          509,
          393,
          808,
          510,
          293,
          1520,
          484,
          264,
          8399,
          22660,
          19866,
          10723,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.18976996926700368,
        "compression_ratio": 1.5844155844155845,
        "end": 8435.8,
        "id": 1371,
        "no_speech_prob": 0.025955930352211,
        "seek": 842480,
        "start": 8432.8,
        "temperature": 0,
        "text": " I would take... I probably wouldn't...",
        "tokens": [
          50764,
          286,
          576,
          747,
          485,
          286,
          1391,
          2759,
          380,
          485,
          50914
        ]
      },
      {
        "avg_logprob": -0.18976996926700368,
        "compression_ratio": 1.5844155844155845,
        "end": 8439.8,
        "id": 1372,
        "no_speech_prob": 0.025955930352211,
        "seek": 842480,
        "start": 8435.8,
        "temperature": 0,
        "text": " I'm not looking right now for pull requests that improve this",
        "tokens": [
          50914,
          286,
          478,
          406,
          1237,
          558,
          586,
          337,
          2235,
          12475,
          300,
          3470,
          341,
          51114
        ]
      },
      {
        "avg_logprob": -0.18976996926700368,
        "compression_ratio": 1.5844155844155845,
        "end": 8443.8,
        "id": 1373,
        "no_speech_prob": 0.025955930352211,
        "seek": 842480,
        "start": 8439.8,
        "temperature": 0,
        "text": " because I want to keep improving it on my own.",
        "tokens": [
          51114,
          570,
          286,
          528,
          281,
          1066,
          11470,
          309,
          322,
          452,
          1065,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.18976996926700368,
        "compression_ratio": 1.5844155844155845,
        "end": 8448.8,
        "id": 1374,
        "no_speech_prob": 0.025955930352211,
        "seek": 842480,
        "start": 8443.8,
        "temperature": 0,
        "text": " But I 100% would accept a pull request that adds a readme file",
        "tokens": [
          51314,
          583,
          286,
          2319,
          4,
          576,
          3241,
          257,
          2235,
          5308,
          300,
          10860,
          257,
          1401,
          1398,
          3991,
          51564
        ]
      },
      {
        "avg_logprob": -0.18976996926700368,
        "compression_ratio": 1.5844155844155845,
        "end": 8452.8,
        "id": 1375,
        "no_speech_prob": 0.025955930352211,
        "seek": 842480,
        "start": 8448.8,
        "temperature": 0,
        "text": " that documents all this, links to the live streams, etc.",
        "tokens": [
          51564,
          300,
          8512,
          439,
          341,
          11,
          6123,
          281,
          264,
          1621,
          15842,
          11,
          5183,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.19378648724472314,
        "compression_ratio": 1.6627450980392158,
        "end": 8461.8,
        "id": 1376,
        "no_speech_prob": 0.0021156391594558954,
        "seek": 845280,
        "start": 8453.8,
        "temperature": 0,
        "text": " And I would accept issues that propose improvements or document and link to your own version of it.",
        "tokens": [
          50414,
          400,
          286,
          576,
          3241,
          2663,
          300,
          17421,
          13797,
          420,
          4166,
          293,
          2113,
          281,
          428,
          1065,
          3037,
          295,
          309,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.19378648724472314,
        "compression_ratio": 1.6627450980392158,
        "end": 8464.8,
        "id": 1377,
        "no_speech_prob": 0.0021156391594558954,
        "seek": 845280,
        "start": 8461.8,
        "temperature": 0,
        "text": " So, I'll try to come back at some point.",
        "tokens": [
          50814,
          407,
          11,
          286,
          603,
          853,
          281,
          808,
          646,
          412,
          512,
          935,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.19378648724472314,
        "compression_ratio": 1.6627450980392158,
        "end": 8465.8,
        "id": 1378,
        "no_speech_prob": 0.0021156391594558954,
        "seek": 845280,
        "start": 8464.8,
        "temperature": 0,
        "text": " It's probably going to be December.",
        "tokens": [
          50964,
          467,
          311,
          1391,
          516,
          281,
          312,
          7687,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.19378648724472314,
        "compression_ratio": 1.6627450980392158,
        "end": 8468.8,
        "id": 1379,
        "no_speech_prob": 0.0021156391594558954,
        "seek": 845280,
        "start": 8465.8,
        "temperature": 0,
        "text": " This is probably going to be the last live stream for November.",
        "tokens": [
          51014,
          639,
          307,
          1391,
          516,
          281,
          312,
          264,
          1036,
          1621,
          4309,
          337,
          7674,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.19378648724472314,
        "compression_ratio": 1.6627450980392158,
        "end": 8473.8,
        "id": 1380,
        "no_speech_prob": 0.0021156391594558954,
        "seek": 845280,
        "start": 8469.8,
        "temperature": 0,
        "text": " You know, as I said, if you wanted to watch my newest video...",
        "tokens": [
          51214,
          509,
          458,
          11,
          382,
          286,
          848,
          11,
          498,
          291,
          1415,
          281,
          1159,
          452,
          17569,
          960,
          485,
          51414
        ]
      },
      {
        "avg_logprob": -0.19378648724472314,
        "compression_ratio": 1.6627450980392158,
        "end": 8476.8,
        "id": 1381,
        "no_speech_prob": 0.0021156391594558954,
        "seek": 845280,
        "start": 8474.8,
        "temperature": 0,
        "text": " Right, if you want to watch my newest video,",
        "tokens": [
          51464,
          1779,
          11,
          498,
          291,
          528,
          281,
          1159,
          452,
          17569,
          960,
          11,
          51564
        ]
      },
      {
        "avg_logprob": -0.19378648724472314,
        "compression_ratio": 1.6627450980392158,
        "end": 8480.8,
        "id": 1382,
        "no_speech_prob": 0.0021156391594558954,
        "seek": 845280,
        "start": 8476.8,
        "temperature": 0,
        "text": " all you need to do is go sign up for the CuriosityStream and Nebula bundle.",
        "tokens": [
          51564,
          439,
          291,
          643,
          281,
          360,
          307,
          352,
          1465,
          493,
          337,
          264,
          48998,
          4520,
          1572,
          293,
          1734,
          37775,
          24438,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.21116511027018228,
        "compression_ratio": 1.5127272727272727,
        "end": 8482.8,
        "id": 1383,
        "no_speech_prob": 0.16443084180355072,
        "seek": 848080,
        "start": 8480.8,
        "temperature": 0,
        "text": " CuriosityStream.com slash coding train.",
        "tokens": [
          50364,
          48998,
          4520,
          1572,
          13,
          1112,
          17330,
          17720,
          3847,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.21116511027018228,
        "compression_ratio": 1.5127272727272727,
        "end": 8484.8,
        "id": 1384,
        "no_speech_prob": 0.16443084180355072,
        "seek": 848080,
        "start": 8482.8,
        "temperature": 0,
        "text": " 26% off.",
        "tokens": [
          50464,
          7551,
          4,
          766,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.21116511027018228,
        "compression_ratio": 1.5127272727272727,
        "end": 8486.8,
        "id": 1385,
        "no_speech_prob": 0.16443084180355072,
        "seek": 848080,
        "start": 8484.8,
        "temperature": 0,
        "text": " Yeah, adversarial autoencoder says, Andrea.",
        "tokens": [
          50564,
          865,
          11,
          17641,
          44745,
          8399,
          22660,
          19866,
          1619,
          11,
          24215,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.21116511027018228,
        "compression_ratio": 1.5127272727272727,
        "end": 8488.8,
        "id": 1386,
        "no_speech_prob": 0.16443084180355072,
        "seek": 848080,
        "start": 8486.8,
        "temperature": 0,
        "text": " That's what I should be doing.",
        "tokens": [
          50664,
          663,
          311,
          437,
          286,
          820,
          312,
          884,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.21116511027018228,
        "compression_ratio": 1.5127272727272727,
        "end": 8490.8,
        "id": 1387,
        "no_speech_prob": 0.16443084180355072,
        "seek": 848080,
        "start": 8488.8,
        "temperature": 0,
        "text": " But I'm doing this very slowly.",
        "tokens": [
          50764,
          583,
          286,
          478,
          884,
          341,
          588,
          5692,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.21116511027018228,
        "compression_ratio": 1.5127272727272727,
        "end": 8492.8,
        "id": 1388,
        "no_speech_prob": 0.16443084180355072,
        "seek": 848080,
        "start": 8490.8,
        "temperature": 0,
        "text": " So, one step at a time.",
        "tokens": [
          50864,
          407,
          11,
          472,
          1823,
          412,
          257,
          565,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.21116511027018228,
        "compression_ratio": 1.5127272727272727,
        "end": 8498.8,
        "id": 1389,
        "no_speech_prob": 0.16443084180355072,
        "seek": 848080,
        "start": 8494.8,
        "temperature": 0,
        "text": " But this new video also should be out on YouTube itself tomorrow",
        "tokens": [
          51064,
          583,
          341,
          777,
          960,
          611,
          820,
          312,
          484,
          322,
          3088,
          2564,
          4153,
          51264
        ]
      },
      {
        "avg_logprob": -0.21116511027018228,
        "compression_ratio": 1.5127272727272727,
        "end": 8500.8,
        "id": 1390,
        "no_speech_prob": 0.16443084180355072,
        "seek": 848080,
        "start": 8498.8,
        "temperature": 0,
        "text": " or hopefully at least by Monday.",
        "tokens": [
          51264,
          420,
          4696,
          412,
          1935,
          538,
          8138,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.21116511027018228,
        "compression_ratio": 1.5127272727272727,
        "end": 8501.8,
        "id": 1391,
        "no_speech_prob": 0.16443084180355072,
        "seek": 848080,
        "start": 8500.8,
        "temperature": 0,
        "text": " Sometime very, very soon.",
        "tokens": [
          51364,
          3379,
          1312,
          588,
          11,
          588,
          2321,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.21116511027018228,
        "compression_ratio": 1.5127272727272727,
        "end": 8504.8,
        "id": 1392,
        "no_speech_prob": 0.16443084180355072,
        "seek": 848080,
        "start": 8501.8,
        "temperature": 0,
        "text": " Huge shout out to Tim Rodenbroker",
        "tokens": [
          51414,
          37043,
          8043,
          484,
          281,
          7172,
          11097,
          268,
          9120,
          5767,
          51564
        ]
      },
      {
        "avg_logprob": -0.21116511027018228,
        "compression_ratio": 1.5127272727272727,
        "end": 8507.8,
        "id": 1393,
        "no_speech_prob": 0.16443084180355072,
        "seek": 848080,
        "start": 8504.8,
        "temperature": 0,
        "text": " who donated to the Processing Foundation fundraiser",
        "tokens": [
          51564,
          567,
          23723,
          281,
          264,
          31093,
          278,
          10335,
          24844,
          6694,
          51714
        ]
      },
      {
        "avg_logprob": -0.21116511027018228,
        "compression_ratio": 1.5127272727272727,
        "end": 8509.8,
        "id": 1394,
        "no_speech_prob": 0.16443084180355072,
        "seek": 848080,
        "start": 8507.8,
        "temperature": 0,
        "text": " which inspired this video.",
        "tokens": [
          51714,
          597,
          7547,
          341,
          960,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.1780576457148013,
        "compression_ratio": 1.6861924686192469,
        "end": 8512.8,
        "id": 1395,
        "no_speech_prob": 0.02442004345357418,
        "seek": 850980,
        "start": 8509.8,
        "temperature": 0,
        "text": " Thank you to the sponsor, CuriosityStream.",
        "tokens": [
          50364,
          1044,
          291,
          281,
          264,
          16198,
          11,
          48998,
          4520,
          1572,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.1780576457148013,
        "compression_ratio": 1.6861924686192469,
        "end": 8515.8,
        "id": 1396,
        "no_speech_prob": 0.02442004345357418,
        "seek": 850980,
        "start": 8512.8,
        "temperature": 0,
        "text": " CuriosityStream.com slash coding train.",
        "tokens": [
          50514,
          48998,
          4520,
          1572,
          13,
          1112,
          17330,
          17720,
          3847,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.1780576457148013,
        "compression_ratio": 1.6861924686192469,
        "end": 8517.8,
        "id": 1397,
        "no_speech_prob": 0.02442004345357418,
        "seek": 850980,
        "start": 8515.8,
        "temperature": 0,
        "text": " Tons of wonderful documentaries",
        "tokens": [
          50664,
          314,
          892,
          295,
          3715,
          41630,
          50764
        ]
      },
      {
        "avg_logprob": -0.1780576457148013,
        "compression_ratio": 1.6861924686192469,
        "end": 8521.8,
        "id": 1398,
        "no_speech_prob": 0.02442004345357418,
        "seek": 850980,
        "start": 8517.8,
        "temperature": 0,
        "text": " as well as full access to the Nebula streaming service.",
        "tokens": [
          50764,
          382,
          731,
          382,
          1577,
          2105,
          281,
          264,
          1734,
          37775,
          11791,
          2643,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.1780576457148013,
        "compression_ratio": 1.6861924686192469,
        "end": 8525.8,
        "id": 1399,
        "no_speech_prob": 0.02442004345357418,
        "seek": 850980,
        "start": 8521.8,
        "temperature": 0,
        "text": " Alright, so this wraps up my demonstration,",
        "tokens": [
          50964,
          2798,
          11,
          370,
          341,
          25831,
          493,
          452,
          16520,
          11,
          51164
        ]
      },
      {
        "avg_logprob": -0.1780576457148013,
        "compression_ratio": 1.6861924686192469,
        "end": 8528.8,
        "id": 1400,
        "no_speech_prob": 0.02442004345357418,
        "seek": 850980,
        "start": 8525.8,
        "temperature": 0,
        "text": " explanation, attempts at autoencoder.",
        "tokens": [
          51164,
          10835,
          11,
          15257,
          412,
          8399,
          22660,
          19866,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.1780576457148013,
        "compression_ratio": 1.6861924686192469,
        "end": 8530.8,
        "id": 1401,
        "no_speech_prob": 0.02442004345357418,
        "seek": 850980,
        "start": 8528.8,
        "temperature": 0,
        "text": " We've got autoencoder part two done.",
        "tokens": [
          51314,
          492,
          600,
          658,
          8399,
          22660,
          19866,
          644,
          732,
          1096,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.1780576457148013,
        "compression_ratio": 1.6861924686192469,
        "end": 8533.8,
        "id": 1402,
        "no_speech_prob": 0.02442004345357418,
        "seek": 850980,
        "start": 8531.8,
        "temperature": 0,
        "text": " I'm going to put on a sweater.",
        "tokens": [
          51464,
          286,
          478,
          516,
          281,
          829,
          322,
          257,
          26550,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.1780576457148013,
        "compression_ratio": 1.6861924686192469,
        "end": 8534.8,
        "id": 1403,
        "no_speech_prob": 0.02442004345357418,
        "seek": 850980,
        "start": 8533.8,
        "temperature": 0,
        "text": " I'm going to turn on the heat.",
        "tokens": [
          51564,
          286,
          478,
          516,
          281,
          1261,
          322,
          264,
          3738,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.1780576457148013,
        "compression_ratio": 1.6861924686192469,
        "end": 8537.8,
        "id": 1404,
        "no_speech_prob": 0.02442004345357418,
        "seek": 850980,
        "start": 8534.8,
        "temperature": 0,
        "text": " I'm going to plug the internet back into the house.",
        "tokens": [
          51614,
          286,
          478,
          516,
          281,
          5452,
          264,
          4705,
          646,
          666,
          264,
          1782,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.19362427560906662,
        "compression_ratio": 1.5162790697674418,
        "end": 8541.8,
        "id": 1405,
        "no_speech_prob": 0.0288627278059721,
        "seek": 853780,
        "start": 8537.8,
        "temperature": 0,
        "text": " I'm going to go work on answering my students' emails,",
        "tokens": [
          50364,
          286,
          478,
          516,
          281,
          352,
          589,
          322,
          13430,
          452,
          1731,
          6,
          12524,
          11,
          50564
        ]
      },
      {
        "avg_logprob": -0.19362427560906662,
        "compression_ratio": 1.5162790697674418,
        "end": 8544.8,
        "id": 1406,
        "no_speech_prob": 0.0288627278059721,
        "seek": 853780,
        "start": 8541.8,
        "temperature": 0,
        "text": " make some dinner for my children.",
        "tokens": [
          50564,
          652,
          512,
          6148,
          337,
          452,
          2227,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.19362427560906662,
        "compression_ratio": 1.5162790697674418,
        "end": 8548.8,
        "id": 1407,
        "no_speech_prob": 0.0288627278059721,
        "seek": 853780,
        "start": 8544.8,
        "temperature": 0,
        "text": " And I really appreciate everybody here",
        "tokens": [
          50714,
          400,
          286,
          534,
          4449,
          2201,
          510,
          50914
        ]
      },
      {
        "avg_logprob": -0.19362427560906662,
        "compression_ratio": 1.5162790697674418,
        "end": 8551.8,
        "id": 1408,
        "no_speech_prob": 0.0288627278059721,
        "seek": 853780,
        "start": 8548.8,
        "temperature": 0,
        "text": " participating in this, cheering me on.",
        "tokens": [
          50914,
          13950,
          294,
          341,
          11,
          11060,
          385,
          322,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.19362427560906662,
        "compression_ratio": 1.5162790697674418,
        "end": 8553.8,
        "id": 1409,
        "no_speech_prob": 0.0288627278059721,
        "seek": 853780,
        "start": 8551.8,
        "temperature": 0,
        "text": " I'm very excited that this actually works.",
        "tokens": [
          51064,
          286,
          478,
          588,
          2919,
          300,
          341,
          767,
          1985,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.19362427560906662,
        "compression_ratio": 1.5162790697674418,
        "end": 8556.8,
        "id": 1410,
        "no_speech_prob": 0.0288627278059721,
        "seek": 853780,
        "start": 8554.8,
        "temperature": 0,
        "text": " So, more soon.",
        "tokens": [
          51214,
          407,
          11,
          544,
          2321,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.19362427560906662,
        "compression_ratio": 1.5162790697674418,
        "end": 8557.8,
        "id": 1411,
        "no_speech_prob": 0.0288627278059721,
        "seek": 853780,
        "start": 8556.8,
        "temperature": 0,
        "text": " Alright, goodbye everybody.",
        "tokens": [
          51314,
          2798,
          11,
          12084,
          2201,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.19362427560906662,
        "compression_ratio": 1.5162790697674418,
        "end": 8559.8,
        "id": 1412,
        "no_speech_prob": 0.0288627278059721,
        "seek": 853780,
        "start": 8557.8,
        "temperature": 0,
        "text": " See you next time on the coding train.",
        "tokens": [
          51364,
          3008,
          291,
          958,
          565,
          322,
          264,
          17720,
          3847,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.19362427560906662,
        "compression_ratio": 1.5162790697674418,
        "end": 8562.8,
        "id": 1413,
        "no_speech_prob": 0.0288627278059721,
        "seek": 853780,
        "start": 8560.8,
        "temperature": 0,
        "text": " I can't find my music.",
        "tokens": [
          51514,
          286,
          393,
          380,
          915,
          452,
          1318,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.19362427560906662,
        "compression_ratio": 1.5162790697674418,
        "end": 8564.8,
        "id": 1414,
        "no_speech_prob": 0.0288627278059721,
        "seek": 853780,
        "start": 8563.8,
        "temperature": 0,
        "text": " Here we go.",
        "tokens": [
          51664,
          1692,
          321,
          352,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.255491650622824,
        "compression_ratio": 1.6091954022988506,
        "end": 8627.8,
        "id": 1415,
        "no_speech_prob": 0.479703426361084,
        "seek": 862480,
        "start": 8625.8,
        "temperature": 0,
        "text": " I'm going to do the this dot, this dot, this dot, this dot,",
        "tokens": [
          50414,
          286,
          478,
          516,
          281,
          360,
          264,
          341,
          5893,
          11,
          341,
          5893,
          11,
          341,
          5893,
          11,
          341,
          5893,
          11,
          50514
        ]
      },
      {
        "avg_logprob": -0.255491650622824,
        "compression_ratio": 1.6091954022988506,
        "end": 8628.8,
        "id": 1416,
        "no_speech_prob": 0.479703426361084,
        "seek": 862480,
        "start": 8627.8,
        "temperature": 0,
        "text": " the this dot song.",
        "tokens": [
          50514,
          264,
          341,
          5893,
          2153,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.255491650622824,
        "compression_ratio": 1.6091954022988506,
        "end": 8630.8,
        "id": 1417,
        "no_speech_prob": 0.479703426361084,
        "seek": 862480,
        "start": 8628.8,
        "temperature": 0,
        "text": " Never forget the this dot.",
        "tokens": [
          50564,
          7344,
          2870,
          264,
          341,
          5893,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.255491650622824,
        "compression_ratio": 1.6091954022988506,
        "end": 8632.8,
        "id": 1418,
        "no_speech_prob": 0.479703426361084,
        "seek": 862480,
        "start": 8630.8,
        "temperature": 0,
        "text": " Somebody compose that song for me.",
        "tokens": [
          50664,
          13463,
          35925,
          300,
          2153,
          337,
          385,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.3970305842737998,
        "compression_ratio": 2.0625,
        "end": 8634.8,
        "id": 1419,
        "no_speech_prob": 0.7755516767501831,
        "seek": 863280,
        "start": 8633.8,
        "temperature": 0,
        "text": " I'm going to say it once again.",
        "tokens": [
          50414,
          286,
          478,
          516,
          281,
          584,
          309,
          1564,
          797,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.3970305842737998,
        "compression_ratio": 2.0625,
        "end": 8635.8,
        "id": 1420,
        "no_speech_prob": 0.7755516767501831,
        "seek": 863280,
        "start": 8634.8,
        "temperature": 0,
        "text": " Here we go.",
        "tokens": [
          50464,
          1692,
          321,
          352,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.3970305842737998,
        "compression_ratio": 2.0625,
        "end": 8636.8,
        "id": 1421,
        "no_speech_prob": 0.7755516767501831,
        "seek": 863280,
        "start": 8635.8,
        "temperature": 0,
        "text": " Sing it with me.",
        "tokens": [
          50514,
          7474,
          309,
          365,
          385,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.3970305842737998,
        "compression_ratio": 2.0625,
        "end": 8641.8,
        "id": 1422,
        "no_speech_prob": 0.7755516767501831,
        "seek": 863280,
        "start": 8636.8,
        "temperature": 0,
        "text": " It's the four two Cartesian coordinate songs.",
        "tokens": [
          50564,
          467,
          311,
          264,
          1451,
          732,
          22478,
          42434,
          15670,
          5781,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.3970305842737998,
        "compression_ratio": 2.0625,
        "end": 8650.8,
        "id": 1423,
        "no_speech_prob": 0.7755516767501831,
        "seek": 863280,
        "start": 8645.8,
        "temperature": 0,
        "text": " It's the four two Cartesian coordinate songs.",
        "tokens": [
          51014,
          467,
          311,
          264,
          1451,
          732,
          22478,
          42434,
          15670,
          5781,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.3970305842737998,
        "compression_ratio": 2.0625,
        "end": 8657.8,
        "id": 1424,
        "no_speech_prob": 0.7755516767501831,
        "seek": 863280,
        "start": 8652.8,
        "temperature": 0,
        "text": " It's the four two Cartesian coordinate songs.",
        "tokens": [
          51364,
          467,
          311,
          264,
          1451,
          732,
          22478,
          42434,
          15670,
          5781,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.1724576022889879,
        "compression_ratio": 1.168421052631579,
        "end": 8662.8,
        "id": 1425,
        "no_speech_prob": 0.021499674767255783,
        "seek": 865780,
        "start": 8658.8,
        "temperature": 0,
        "text": " It's the four two Cartesian coordinate songs.",
        "tokens": [
          50414,
          467,
          311,
          264,
          1451,
          732,
          22478,
          42434,
          15670,
          5781,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.1724576022889879,
        "compression_ratio": 1.168421052631579,
        "end": 8679.8,
        "id": 1426,
        "no_speech_prob": 0.021499674767255783,
        "seek": 865780,
        "start": 8676.8,
        "temperature": 0,
        "text": " Auto-tune and the internet will fix that for me.",
        "tokens": [
          51314,
          13738,
          12,
          83,
          2613,
          293,
          264,
          4705,
          486,
          3191,
          300,
          337,
          385,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.1724576022889879,
        "compression_ratio": 1.168421052631579,
        "end": 8685.8,
        "id": 1427,
        "no_speech_prob": 0.021499674767255783,
        "seek": 865780,
        "start": 8684.8,
        "temperature": 0,
        "text": " Sing it with me.",
        "tokens": [
          51714,
          7474,
          309,
          365,
          385,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.4975001637528582,
        "compression_ratio": 2.4035087719298245,
        "end": 8690.8,
        "id": 1428,
        "no_speech_prob": 0.058697398751974106,
        "seek": 868580,
        "start": 8685.8,
        "temperature": 1,
        "text": " It's the four two Cartesian coordinate songs.",
        "tokens": [
          50364,
          467,
          311,
          264,
          1451,
          732,
          22478,
          21181,
          282,
          15670,
          1872,
          21559,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.4975001637528582,
        "compression_ratio": 2.4035087719298245,
        "end": 8699.8,
        "id": 1429,
        "no_speech_prob": 0.058697398751974106,
        "seek": 868580,
        "start": 8694.8,
        "temperature": 1,
        "text": " It's the four two Cartesian coordinate songs.",
        "tokens": [
          50814,
          467,
          311,
          264,
          1451,
          256,
          6120,
          22478,
          42434,
          15670,
          1872,
          21559,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.4975001637528582,
        "compression_ratio": 2.4035087719298245,
        "end": 8706.8,
        "id": 1430,
        "no_speech_prob": 0.058697398751974106,
        "seek": 868580,
        "start": 8699.8,
        "temperature": 1,
        "text": " It's the four two Cartesian coordinate songs.",
        "tokens": [
          51064,
          467,
          311,
          264,
          1451,
          732,
          22478,
          42434,
          15670,
          5781,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.327727904686561,
        "compression_ratio": 0.8490566037735849,
        "end": 8720.8,
        "id": 1431,
        "no_speech_prob": 0.92750084400177,
        "seek": 871580,
        "start": 8715.8,
        "temperature": 0,
        "text": " It's the four two Cartesian coordinate songs.",
        "tokens": [
          50364,
          467,
          311,
          264,
          1451,
          732,
          22478,
          42434,
          15670,
          5781,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.3591151604285607,
        "compression_ratio": 0.8490566037735849,
        "end": 8750.8,
        "id": 1432,
        "no_speech_prob": 0.9572726488113403,
        "seek": 874580,
        "start": 8745.8,
        "temperature": 0,
        "text": " It's the four two Cartesian coordinate songs.",
        "tokens": [
          50364,
          467,
          311,
          264,
          1451,
          732,
          22478,
          42434,
          15670,
          5781,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.33975434914613384,
        "compression_ratio": 2.3425925925925926,
        "end": 8780.8,
        "id": 1433,
        "no_speech_prob": 0.3620705008506775,
        "seek": 877580,
        "start": 8775.8,
        "temperature": 0.8,
        "text": " It's the four two Cartesian coordinate songs.",
        "tokens": [
          50364,
          467,
          311,
          264,
          1451,
          732,
          22478,
          42434,
          15670,
          5781,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.33975434914613384,
        "compression_ratio": 2.3425925925925926,
        "end": 8785.8,
        "id": 1434,
        "no_speech_prob": 0.3620705008506775,
        "seek": 877580,
        "start": 8780.8,
        "temperature": 0.8,
        "text": " It's the four two Cartesian coordinate songs.",
        "tokens": [
          50614,
          467,
          311,
          264,
          1451,
          732,
          22478,
          42434,
          15670,
          220,
          539,
          872,
          82,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.33975434914613384,
        "compression_ratio": 2.3425925925925926,
        "end": 8790.8,
        "id": 1435,
        "no_speech_prob": 0.3620705008506775,
        "seek": 877580,
        "start": 8785.8,
        "temperature": 0.8,
        "text": " It's the four two Cartesian coordinate songs.",
        "tokens": [
          50864,
          467,
          311,
          264,
          1451,
          732,
          22478,
          42434,
          15670,
          5781,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.33975434914613384,
        "compression_ratio": 2.3425925925925926,
        "end": 8797.8,
        "id": 1436,
        "no_speech_prob": 0.3620705008506775,
        "seek": 877580,
        "start": 8790.8,
        "temperature": 0.8,
        "text": " It's the four two Cartesian coordinate songs.",
        "tokens": [
          51114,
          467,
          311,
          264,
          1451,
          256,
          6120,
          22478,
          42434,
          15670,
          5781,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.33975434914613384,
        "compression_ratio": 2.3425925925925926,
        "end": 8800.8,
        "id": 1437,
        "no_speech_prob": 0.3620705008506775,
        "seek": 877580,
        "start": 8797.8,
        "temperature": 0.8,
        "text": " Unicorns and rainbows and cupcakes.",
        "tokens": [
          51464,
          1156,
          23115,
          82,
          293,
          4830,
          21118,
          293,
          44515,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.33975434914613384,
        "compression_ratio": 2.3425925925925926,
        "end": 8802.8,
        "id": 1438,
        "no_speech_prob": 0.3620705008506775,
        "seek": 877580,
        "start": 8800.8,
        "temperature": 0.8,
        "text": " What else is there?",
        "tokens": [
          51614,
          708,
          1646,
          307,
          456,
          30,
          51714
        ]
      },
      {
        "avg_logprob": -0.33975434914613384,
        "compression_ratio": 2.3425925925925926,
        "end": 8804.8,
        "id": 1439,
        "no_speech_prob": 0.3620705008506775,
        "seek": 877580,
        "start": 8802.8,
        "temperature": 0.8,
        "text": " Yes, kittens.",
        "tokens": [
          51714,
          1079,
          11,
          47363,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.18756935444283993,
        "compression_ratio": 1.1754385964912282,
        "end": 8806.8,
        "id": 1440,
        "no_speech_prob": 0.02568393386900425,
        "seek": 880480,
        "start": 8804.8,
        "temperature": 0,
        "text": " Thank you very much.",
        "tokens": [
          50364,
          1044,
          291,
          588,
          709,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.18756935444283993,
        "compression_ratio": 1.1754385964912282,
        "end": 8808.8,
        "id": 1441,
        "no_speech_prob": 0.02568393386900425,
        "seek": 880480,
        "start": 8806.8,
        "temperature": 0,
        "text": " Kittens and rainbows and cupcakes.",
        "tokens": [
          50464,
          591,
          39449,
          293,
          4830,
          21118,
          293,
          44515,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.18756935444283993,
        "compression_ratio": 1.1754385964912282,
        "end": 8810.8,
        "id": 1442,
        "no_speech_prob": 0.02568393386900425,
        "seek": 880480,
        "start": 8808.8,
        "temperature": 0,
        "text": " Notice that and look what I get.",
        "tokens": [
          50564,
          13428,
          300,
          293,
          574,
          437,
          286,
          483,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.18756935444283993,
        "compression_ratio": 1.1754385964912282,
        "end": 8812.8,
        "id": 1443,
        "no_speech_prob": 0.02568393386900425,
        "seek": 880480,
        "start": 8810.8,
        "temperature": 0,
        "text": " I'm really losing my mind.",
        "tokens": [
          50664,
          286,
          478,
          534,
          7027,
          452,
          1575,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.18756935444283993,
        "compression_ratio": 1.1754385964912282,
        "end": 8814.8,
        "id": 1444,
        "no_speech_prob": 0.02568393386900425,
        "seek": 880480,
        "start": 8812.8,
        "temperature": 0,
        "text": " Okay, let's do it.",
        "tokens": [
          50764,
          1033,
          11,
          718,
          311,
          360,
          309,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.6437333027521769,
        "compression_ratio": 0.918918918918919,
        "end": 8824.8,
        "id": 1445,
        "no_speech_prob": 0.9842830300331116,
        "seek": 881480,
        "start": 8814.8,
        "temperature": 0,
        "text": " Kittens and rainbows and cupcakes.",
        "tokens": [
          50364,
          591,
          39449,
          293,
          4830,
          21118,
          293,
          44515,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.34730694510719995,
        "compression_ratio": 1.6428571428571428,
        "end": 8834.8,
        "id": 1446,
        "no_speech_prob": 0.9897687435150146,
        "seek": 882480,
        "start": 8824.8,
        "temperature": 0,
        "text": " Kittens and rainbows and cupcakes.",
        "tokens": [
          50364,
          591,
          39449,
          293,
          4830,
          21118,
          293,
          44515,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.34730694510719995,
        "compression_ratio": 1.6428571428571428,
        "end": 8844.8,
        "id": 1447,
        "no_speech_prob": 0.9897687435150146,
        "seek": 882480,
        "start": 8834.8,
        "temperature": 0,
        "text": " Kittens and rainbows and cupcakes.",
        "tokens": [
          50864,
          591,
          39449,
          293,
          4830,
          21118,
          293,
          44515,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.19017065655101428,
        "compression_ratio": 1.6428571428571428,
        "end": 8854.8,
        "id": 1448,
        "no_speech_prob": 0.991617739200592,
        "seek": 884480,
        "start": 8844.8,
        "temperature": 0,
        "text": " Kittens and rainbows and cupcakes.",
        "tokens": [
          50364,
          591,
          39449,
          293,
          4830,
          21118,
          293,
          44515,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.19017065655101428,
        "compression_ratio": 1.6428571428571428,
        "end": 8864.8,
        "id": 1449,
        "no_speech_prob": 0.991617739200592,
        "seek": 884480,
        "start": 8854.8,
        "temperature": 0,
        "text": " Kittens and rainbows and cupcakes.",
        "tokens": [
          50864,
          591,
          39449,
          293,
          4830,
          21118,
          293,
          44515,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.36700427532196045,
        "compression_ratio": 0.918918918918919,
        "end": 8888.8,
        "id": 1450,
        "no_speech_prob": 0.788352906703949,
        "seek": 886480,
        "start": 8864.8,
        "temperature": 0,
        "text": " Kittens and rainbows and cupcakes.",
        "tokens": [
          50364,
          591,
          39449,
          293,
          4830,
          21118,
          293,
          44515,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.19639522379094904,
        "compression_ratio": 1.4663212435233162,
        "end": 8892.8,
        "id": 1451,
        "no_speech_prob": 0.5349790453910828,
        "seek": 888880,
        "start": 8888.8,
        "temperature": 0,
        "text": " I feel just sort of like a nice feeling of relaxation.",
        "tokens": [
          50364,
          286,
          841,
          445,
          1333,
          295,
          411,
          257,
          1481,
          2633,
          295,
          30315,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.19639522379094904,
        "compression_ratio": 1.4663212435233162,
        "end": 8894.8,
        "id": 1452,
        "no_speech_prob": 0.5349790453910828,
        "seek": 888880,
        "start": 8892.8,
        "temperature": 0,
        "text": " Everything's going to be okay today.",
        "tokens": [
          50564,
          5471,
          311,
          516,
          281,
          312,
          1392,
          965,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.19639522379094904,
        "compression_ratio": 1.4663212435233162,
        "end": 8896.8,
        "id": 1453,
        "no_speech_prob": 0.5349790453910828,
        "seek": 888880,
        "start": 8894.8,
        "temperature": 0,
        "text": " The dream is not broken.",
        "tokens": [
          50664,
          440,
          3055,
          307,
          406,
          5463,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.19639522379094904,
        "compression_ratio": 1.4663212435233162,
        "end": 8897.8,
        "id": 1454,
        "no_speech_prob": 0.5349790453910828,
        "seek": 888880,
        "start": 8896.8,
        "temperature": 0,
        "text": " It has not frozen.",
        "tokens": [
          50764,
          467,
          575,
          406,
          12496,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.19639522379094904,
        "compression_ratio": 1.4663212435233162,
        "end": 8899.8,
        "id": 1455,
        "no_speech_prob": 0.5349790453910828,
        "seek": 888880,
        "start": 8897.8,
        "temperature": 0,
        "text": " This is a wonderful thing.",
        "tokens": [
          50814,
          639,
          307,
          257,
          3715,
          551,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.19639522379094904,
        "compression_ratio": 1.4663212435233162,
        "end": 8901.8,
        "id": 1456,
        "no_speech_prob": 0.5349790453910828,
        "seek": 888880,
        "start": 8899.8,
        "temperature": 0,
        "text": " Okay, we're going to do it.",
        "tokens": [
          50914,
          1033,
          11,
          321,
          434,
          516,
          281,
          360,
          309,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.19639522379094904,
        "compression_ratio": 1.4663212435233162,
        "end": 8902.8,
        "id": 1457,
        "no_speech_prob": 0.5349790453910828,
        "seek": 888880,
        "start": 8901.8,
        "temperature": 0,
        "text": " I'm really getting to something.",
        "tokens": [
          51014,
          286,
          478,
          534,
          1242,
          281,
          746,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.19639522379094904,
        "compression_ratio": 1.4663212435233162,
        "end": 8903.8,
        "id": 1458,
        "no_speech_prob": 0.5349790453910828,
        "seek": 888880,
        "start": 8902.8,
        "temperature": 0,
        "text": " I need my sound effect.",
        "tokens": [
          51064,
          286,
          643,
          452,
          1626,
          1802,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.19639522379094904,
        "compression_ratio": 1.4663212435233162,
        "end": 8916.8,
        "id": 1459,
        "no_speech_prob": 0.5349790453910828,
        "seek": 888880,
        "start": 8903.8,
        "temperature": 0,
        "text": " Unicorns and rainbows and cupcakes.",
        "tokens": [
          51114,
          1156,
          23115,
          82,
          293,
          4830,
          21118,
          293,
          44515,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.2115949876237624,
        "compression_ratio": 1.7574257425742574,
        "end": 8918.8,
        "id": 1460,
        "no_speech_prob": 0.6291753649711609,
        "seek": 891680,
        "start": 8916.8,
        "temperature": 0,
        "text": " What else is there?",
        "tokens": [
          50364,
          708,
          1646,
          307,
          456,
          30,
          50464
        ]
      },
      {
        "avg_logprob": -0.2115949876237624,
        "compression_ratio": 1.7574257425742574,
        "end": 8923.8,
        "id": 1461,
        "no_speech_prob": 0.6291753649711609,
        "seek": 891680,
        "start": 8918.8,
        "temperature": 0,
        "text": " Unicorns and rainbows and cupcakes.",
        "tokens": [
          50464,
          1156,
          23115,
          82,
          293,
          4830,
          21118,
          293,
          44515,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.2115949876237624,
        "compression_ratio": 1.7574257425742574,
        "end": 8924.8,
        "id": 1462,
        "no_speech_prob": 0.6291753649711609,
        "seek": 891680,
        "start": 8923.8,
        "temperature": 0,
        "text": " That was invalid syntax.",
        "tokens": [
          50714,
          663,
          390,
          34702,
          28431,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.2115949876237624,
        "compression_ratio": 1.7574257425742574,
        "end": 8926.8,
        "id": 1463,
        "no_speech_prob": 0.6291753649711609,
        "seek": 891680,
        "start": 8924.8,
        "temperature": 0,
        "text": " I forgot.",
        "tokens": [
          50764,
          286,
          5298,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.2115949876237624,
        "compression_ratio": 1.7574257425742574,
        "end": 8929.8,
        "id": 1464,
        "no_speech_prob": 0.6291753649711609,
        "seek": 891680,
        "start": 8926.8,
        "temperature": 0,
        "text": " There was one other thing here that I think is important.",
        "tokens": [
          50864,
          821,
          390,
          472,
          661,
          551,
          510,
          300,
          286,
          519,
          307,
          1021,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.2115949876237624,
        "compression_ratio": 1.7574257425742574,
        "end": 8932.8,
        "id": 1465,
        "no_speech_prob": 0.6291753649711609,
        "seek": 891680,
        "start": 8929.8,
        "temperature": 0,
        "text": " That I will use continuously over and over again.",
        "tokens": [
          51014,
          663,
          286,
          486,
          764,
          15684,
          670,
          293,
          670,
          797,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.2115949876237624,
        "compression_ratio": 1.7574257425742574,
        "end": 8936.8,
        "id": 1466,
        "no_speech_prob": 0.6291753649711609,
        "seek": 891680,
        "start": 8932.8,
        "temperature": 0,
        "text": " All sorts of text generation analysis things.",
        "tokens": [
          51164,
          1057,
          7527,
          295,
          2487,
          5125,
          5215,
          721,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.2115949876237624,
        "compression_ratio": 1.7574257425742574,
        "end": 8940.8,
        "id": 1467,
        "no_speech_prob": 0.6291753649711609,
        "seek": 891680,
        "start": 8936.8,
        "temperature": 0,
        "text": " That I will use continuously over and over again.",
        "tokens": [
          51364,
          663,
          286,
          486,
          764,
          15684,
          670,
          293,
          670,
          797,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.2115949876237624,
        "compression_ratio": 1.7574257425742574,
        "end": 8943.8,
        "id": 1468,
        "no_speech_prob": 0.6291753649711609,
        "seek": 891680,
        "start": 8940.8,
        "temperature": 0,
        "text": " First thing I need to do is, yes, kittens.",
        "tokens": [
          51564,
          2386,
          551,
          286,
          643,
          281,
          360,
          307,
          11,
          2086,
          11,
          47363,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.2115949876237624,
        "compression_ratio": 1.7574257425742574,
        "end": 8944.8,
        "id": 1469,
        "no_speech_prob": 0.6291753649711609,
        "seek": 891680,
        "start": 8943.8,
        "temperature": 0,
        "text": " Kittens, kittens.",
        "tokens": [
          51714,
          591,
          39449,
          11,
          47363,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.39224820137023925,
        "compression_ratio": 1.3095238095238095,
        "end": 8946.8,
        "id": 1470,
        "no_speech_prob": 0.5070415139198303,
        "seek": 894480,
        "start": 8944.8,
        "temperature": 0,
        "text": " I'm really losing my mind.",
        "tokens": [
          50364,
          286,
          478,
          534,
          7027,
          452,
          1575,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.39224820137023925,
        "compression_ratio": 1.3095238095238095,
        "end": 8948.8,
        "id": 1471,
        "no_speech_prob": 0.5070415139198303,
        "seek": 894480,
        "start": 8946.8,
        "temperature": 0,
        "text": " Okay, we're going to do it.",
        "tokens": [
          50464,
          1033,
          11,
          321,
          434,
          516,
          281,
          360,
          309,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.39224820137023925,
        "compression_ratio": 1.3095238095238095,
        "end": 8961.8,
        "id": 1472,
        "no_speech_prob": 0.5070415139198303,
        "seek": 894480,
        "start": 8948.8,
        "temperature": 0,
        "text": " Kittens and kittens and kittens and kittens.",
        "tokens": [
          50564,
          591,
          39449,
          293,
          47363,
          293,
          47363,
          293,
          47363,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.39224820137023925,
        "compression_ratio": 1.3095238095238095,
        "end": 8963.8,
        "id": 1473,
        "no_speech_prob": 0.5070415139198303,
        "seek": 894480,
        "start": 8961.8,
        "temperature": 0,
        "text": " Dog, yeah.",
        "tokens": [
          51214,
          1144,
          70,
          11,
          1338,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.49188737869262694,
        "compression_ratio": 0.2727272727272727,
        "end": 8965.8,
        "id": 1474,
        "no_speech_prob": 0.9628543853759766,
        "seek": 896380,
        "start": 8963.8,
        "temperature": 0,
        "text": " No.",
        "tokens": [
          50414,
          883,
          13,
          50464
        ]
      }
    ],
    "transcription": " You Do Do Do Do Do Do Hello test one two, I hope my audio is coming through please let me know in the chat Discord in YouTube By carrier pigeon smoke signal however you could possibly reach me, please Let me know apologies for all the stops and starts today I will be beginning in just a few minutes assuming my audio is coming through loud and clear Okay. See you in a moment Hello Moment you both Do Do Do Do Do Do Do Do Do Do Hello happy Saturday Welcome to the coding train with me minor internet personality I am the host of the coding train. I'm coding train. I am coming to you live I know it's some kind of miracle that I'm here right now. I don't know how this is gonna last I Better just very quickly say thank you to Curiosity stream for sponsoring today's live stream You can get access to all the documentaries amazing documentaries on curiosity stream as well as the nebula Everything that's on nebula. Can I tell you about something that's on nebula right now? Let me tell you something that's on nebula right now. Hold on a sec On nebula right now is let's go to my library right here. Look at this This particular video which is going to come out probably hopefully by tomorrow on YouTube still finishing it up But if you want to get some early access to this particular video along with all sorts of other amazing stuff You can get you can sign up the whole year of curiosity stream and nebula At that link 26% off I think that's $14 and 79 cents for the whole year Amazing amazing. You should totally check out all the documentaries and all the YouTube creators that are on nebula. Okay The stream still working so at least I got that out And what am I here to do today? Well, if you might remember a week or so ago and I'm just checking the chat here to see if people are watching I'm not seeing any messages, which is a little bit weird if I'm being perfectly honest so hopefully I'm not just speaking into a vacuum, but I've been working on a project to create an auto encoder using JavaScript with the tensorflow.js library library in node.js and I would like to finish that today So this is part two If you were looking for part one if I come back to here, I really don't see any chat messages very strange Okay code Melanik says hi I'm cars waves, okay people are there you're there. Oh, thank goodness Not very many of you probably because I've totally botched this in the sense that I was supposed to stream this morning at 10 a.m And I had scheduled it. I'm using discord events now So you should sign up for the coding train discord somebody post that link into the chat And then I make an event and you know what time and you can like register your interest you'll get a reminder all the things I've always been wanting for wanting to have and then I was like, no, I can't stream because my internet wasn't working. I Am in a garage, which is a detached garage from my main house Which is where my new studio is and I'm gonna be here all the time every day all day starting in January 2022 lots of plans so I'm working on getting this place wired and powered by solar energy so Disconnected now when I say I am obviously I heard people to do a lot of this work But the electric electrics was disconnected to this building and then a trend we dug a trench To wire electric to the house so they could put solar panels here to power the house and the garage Ran coax and cat5 underground Put it in a splitter so I can have internet in both and for whatever reason I can't get internet and both to work And I discovered that if I just turn off The internet to the house right now. It seems to work here in the garage So that's my temporary solution at least for today to get this live stream in on Saturday November 20th and finish off this project I was trying to fig find where I was I was here to show you Part one so this doesn't say part one, but you can see oh and look at this So this is also by the way available here. I just haven't released it yet. It should be out Tomorrow I'm just got a lot of slowness here, but I'm logged into my account, which is why I see it I'm very excited about this video. Can you please post the discord in the chat or I'm gonna go ahead and do that Since no one else got around to it just yet And I believe that should be oh my god. I posted the wrong link Okay, it's discord.gg slash coding train, okay, so What was I looking for oh, so that's part one if you watch part one great You're in the right place if you didn't watch part one. Well. I'll recap it a little bit as I get into I'm working on the project so I need to find my way back to where I was before We open up processing Because I was using processing to generate the images that I want to Use to train the model and I need to I don't need this And I need to get let me just switch myself back over here While I'm getting various windows set up so Let's see talk amongst yourselves for a minute, please You know normally you would think I would have this all set up before I begin streaming I don't know why I'm hiding this from you. I'm just opening up So I My I term and I think the project is In the auto encoder TF demo Let's open this up in In Visual Studio code all right, okay, let's go back to The auto Encoder Kairos page which is sort of my a model my tutorial that I am following and Hi Bruno hi Adrian hi and Barak hi Cyril I'm seeing some nice message in the chat welcome a bunch of people are joining in that's great So what do I how am I gonna get started here so first let's see if my whiteboard is still working Oh looks like I need to work on the focus there, and wow it's so bright. I think it's brighter in here today The Sun is out So I do get some sunlight in this room so first thing I need to do is focus this camera I think that's better right. I think I just focused it Let me go back and look Here looks better. Yeah, that looks like it's in focus now. Oh, and I need to Okay, hold on everyone. I'm coming back to here I also want to record this session to disk just in case The thought experiment is you know do you really? Later if you're not here live with me right now part of the process of figuring it out together Would you really want to come back and watch four hours of live streaming about building an auto encoder project? Maybe But my thought is if I can get everything recorded to disk Then perhaps I can Succinctly package this in like a 30 to 45 minute video Which skips a lot of the rambling and all that kind of stuff so let me I need to I'm kind of like shocked that I'm doing this because as of this morning I was like I'm just gonna reschedule this to like November 30th, so I just need to check my settings here output streaming recording Distinguishable quality large file size well no wonder high quality medium file size Forgot that I done this start recording, so I recorded last session to disk and I looked at the file afterwards, and it was 57 gigabytes Because I'm recording a 4k Video to disk which has all of the different it has Just the laptop feed it has me actually me just with the green screen And it has the whiteboard if I had the iPad here I have a iPad hookup, but it's not hooked up right now, so this is my new setup I'm obviously still trying to build up momentum. Thank you to everybody's patience Kindness and consideration as I try to figure out I feel like the coding train is going to be born anew in 2022 Yeah, right this which is quite lovely, okay, I've got a little bit of coffee left Got to get back to my children, but I'm giving myself till 330. It's 90 minutes. I'm recording to disk And thank you to all of your Thank You Sorelle you are here with me. I appreciate it alright Little straw poll here, but put a little straw poll into the chat Did you watch part one? Just give me a sense of who watched part one I can't see by the way who's answering so you know it's not like you know did you study for the test? And you don't want to admit it like I would like to know the real information so in the chat now should be a poll asking whether you watched part one or not and as I Kind of get Let's just see if things are still working here. It looks good I'm just sort of checking out my code from before still seems to be running That's fine there, but this I term needs to be a Little bit more over. Ah come on. I term Why do you do me like that? Okay? I think that should be good Processing I don't actually know that I'm even gonna need I actually will want this for sure I just realized okay I also remember K week man Would you like to be referred to I do it all sorts of different ways But I remember you saying that I should reconsider maybe the optimizer or the loss function So again the my my court of working sort the working philosophy here right now is just to get all the pieces plugged in and then I want to add more layers and Sort of think more thoughtfully about the various hyper parameters of the system that I'm building And then also hook it up to p5 so I can see the results in the browser Oh by 330 today no problem. There's probably going to be a part two But I seem to recall you had left some comments in the discord So I let me make sure I come back and revisit that although. Maybe I'm not going to right now I am seeing the poll results that 60% of you 73 people have voted 61% of you have did not watch part one and 39% of you did watch part two and This means this swings the pendulum for me, I'm gonna. Give you a quick recap of kind of everything. I do And let's uh let's put a timer on here, let's timebox this 10 minute timer So I don't want to allow myself to Let the user Look at whats going on to allow myself More than 10 minutes Where oh what I'm using up so much of my time just to put this In the page here, okay Okay, so there's my 10 minute timer I don't want to I want to be starting on the new stuff by the time that hits zero okay, so Quickly I Am very interested in machine learning generative machine learning models models that generate synthetic images Text perhaps sound other kinds of media If you have been following the world of deep learning today the what you probably have heard of is something like oh Again or style Gann or style Gann 2 or style Gann 3 and then there's this like latent space Oh all these images are in the latent space and I can walk through the latent space and look at this AI is dreaming About cats in a style Gann 2 latent space of all cats cats and many more cats If you have no idea what any of that means How could you possibly get started to learn some of the vocabulary feel comfortable with working with these systems even if you're? Ultimately just an end user of pre-trained models You're not designing and training the models yourself for me the process of me trying to Sort out how all this stuff works and understand be able to read the style Gann paper And maybe understand a bit more about it begins with auto encoders an auto encoder is a very simple Well, I know I don't shouldn't say very simple because none of this is particularly simple But it is a good starting point to think about how generative models work and at the last live stream I went through building this whole diagram to talk about how we could build Something called a copying machine out of a neural network So if an image is sent into the neural network if we could just get that same image back out Then somehow the neural network would have learned some type of like Represent internal representation of that image in a way that it can reproduce it So obviously to copy an image is a simple well If this is a simple process with an algorithm I can just say for every pixel make a new image take an existing image for every pixel Put the new pixel in the new image so The auto encoder is not an efficient copying machine, but it does give us this ability to Copy the image while also compressing the data because the idea is if we start if I have a 28 by 28 image with 784 pixels as the data moves through these layers of the neural network We have fewer like I have 784 inputs the first layer might only have Half of that in neurons and then another layer might have half of that and then so these numbers have to somehow be Compressed into a smaller amount of numbers that then get expanded back out to the original image So this is like a copying machine and an image compression engine. It is not an efficient image compression engine Because if we really want to do image compression to save high resolution image with less file space on a on a hard drive We could just use JPEG or other kind of known tried-and-true image compression algorithms But if we are able to take the at these images compress them down and have the neural network the auto encoder learn how to Decode them right we have an encoder and a decoder Then at some point and hopefully I'll get to this part today I can take off after I've trained it I can take out The encoder and just start with the decoder feed in noise and generate new images in the style of the original training data set or I could do certain kinds of operations like image denoising for example What if I sent a noisy image in right if these are all the example? I'm using is I'm just using geometric shapes So if the auto encoder learns the internal and internal representation of what it means to render a square If I send it a noisy square it will then take that and in theory Rerender it back out without the noise. That's the idea so this is what I'm working with I went through this diagram probably in a much longer period of time and then Looked at if I come back over here And I See some comments hold on come back over here now, and I still got five minutes left in my recap of before and If I come back here What was I trying to say? François Chollet yes, okay, so this is a article from 2016 so quite a while ago where I first encountered the idea of an auto encoder This encoder and decoder this original input compressed representation Reconstructed input the output is the reconstructed input and there is sort of a guide here explanation as well as a guide for how to Build these layers using a library called Keras which was a sort of higher level Which is some I should know this maybe somebody in the chat could could kind of explain But like does Keras still exist or is it really just now fully integrated into tensorflow and not called Keras anymore? But when Keras was first developed it was a kind of higher level layer if you will Above lower level machine learning libraries So you could say things like create a neural network with this kind of architecture in Keras in a sort of higher level way And you could plug tensorflow into it to do the actual lower level of intuition or PyTorch or other ones so the way I know and work with Keras is by working in tensorflow.js Which I want to look at the This is I want to I think it's just like js.tensorflow Let's see if this yeah, and I want to go to the API In the tensorflow.js API there is a particular set of functions objects that are part of the layers that are called layers tf.layers layers model sequential layers here we go and this is a net this is essentially the original the modeled after or directly ported from the Keras Python library. Oh, I hear somebody Hello Take a short intermission. I've got I've got a visitor. I'll be right be right back I'm just putting on intermission, and I'll be right back music music music Okay back Okay, I'm back Stretch all right I Disconnected the internet in the house, which is causing some some problems, but we're gonna. We're all we're all gonna get through this together Okay I forgot where I was Well, I was talking about TensorFlow.js, so oh and you don't see that now let me come back here So the code that I began to write is as follows so obviously I went through this in greater detail in the previous stream But I've got a node. I'm eventually gonna turn this into a web server But this is just a node script ultimately right now a little node project where I'm creating a sequential model That is exactly I'm trying to recreate this exact model in code now I'm calling it an auto encoder because that's the application that I'm doing It starts with an encoder which is a dense layer that receives 784 inputs because my images are gonna be 28 by 28. I'm arbitrarily having it be 32 Units then it decodes back to 784 It's just those it's this is like It's just two layers just one layer for the encoder and one layer for the decoder And then I've set up an optimizer a loss function. These are things. I also talked about in the previous I've only got a minute left here in my recap so you know I can touch on those as we go And then I just fed it with a random noise So where I left off is I now would like to and I have this processing sketch Which generates a variety of square images of squares? I have those Hopefully if I could find them here in a folder called data So now I would like to feed the auto encoder these actual images expand the number of layers and I'm reading the chat. Yeah, so my Things are complicated these days for me as they are for everybody my kids are home. I disconnected their internet my wife is out of town so They're having a couple hours of free time but And I wanted to get this out of the way because oh oh my god. What is beeping at me? Oh, it's the timer do you hear that like what's happening? There's a beeper going on okay, okay, okay? I got you. We're gonna get started with the code whoops But I know I've lost track of what I'm saying But I I've got lots of things to do with them tomorrow next week through Thanksgiving And so I was just if I could just do this stream today Then I can kind of figure everything out next week so here I am High computational mama in the chat so Let's see okay, how we are how we all feeling about that any questions about what I've covered so far Before I get started here, and I'm thinking I'm gonna need to read in the images How do I want to read in the images Anybody got a suggestion for a node package that I should use I mean I could use just the file system package to read The files that I need to unpack them into their pixels and turn those into tensors Oh Gloria Pickles Oh You know what now I'm feeling kind of guilty, but she was out all day Earlier today with me as I was going around and we had a nice walk. She's in her sleeping in her crate She's she's crate trained. She loves her crate. She feels very safe in there. There's ever time about my dog by the way Not my daughter My children are free range right now in the house the dog I often have free range My children are free range right now in the house the dog I often have her with me, but she's sleeping in her crate I was about to say like That's her favorite spot like if there's a thunderstorm. She's terrified. She just wants to be in her crate So she sleeps in her crate at night very comfortable there But I don't want to leave her there for more than a couple hours Then I need to let her out after her nap to roam free outside and be here, okay I want to make me some coffee after watching, but don't want to leave this stream, LA new I really think LA noob you should make yourself some coffee. You're not gonna miss anything trust me Couple minutes to make some coffee. I really doubt you're gonna miss anything critical All right Can you restate what you need to do with the files, okay, I Need I have all these images. I want to load them, so I want to write. Let's write some pseudocode I'm gonna do it right here. I'm gonna write a function I will call it load images I am going to Load all image files in the data folder Read the pixels convert the pixels to tensors for TFJS So this is what I need to do I know how to do the last stop because I'm familiar with TensorFlow.js. It's stuff that I've done I know how to load image files in general. I would use the node file system package Okay, the door open you got your phone. You're good. Does it it'll connect automatically right? Okay, okay It's a little chilly in there because I didn't turn the heat on but you can turn the heat on if you want The thermostat on the wall, it's a little thing you just go bring it there you're closing this okay Okay So I could use the file system package and The file system package allows me to load files. Let's just What no no just turn it to like 70 where it says 70. I think it's a good number So let's see so let's see load Read image pixels node.js Get an array of pixels from an image using node.js image pixels get pixels. I just feel like Jimp I could use the jimp package This seems promising JavaScript image manipulation program an image processing library for a node written entirely JavaScript with zero dependencies. This is good Does it support promises Doesn't look like using promises. Yes Okay This looks good No, so Helmer. Yeah, I got to talk about this no internet. No heat. This is a detached garage and it is I'm Trying to get all the stuff in here to make it more Livable, but we don't live in the garage, but to have some more Lounge II relaxing space we have a ping-pong table to have enough like power and internet to power my coding train stuff But you know, I don't run the heat in here all day because we're not in here and that would be very wasteful anyway How do I how do you all feel about this jimp library? I think this is looking good for me So I am going to give it a try until someone tells me not to do it npm install jimp Yep So, let's run that So I'm now loading this package Okay, great, by the way, I'm always curious it always says so some of the packages are looking for funding so Always good to support open source projects. So see there's some of the open source projects that I'm using somehow through these dependencies Maybe I will come back to that later Now up there goes to see the heat's on So now that's the boiler going So hopefully that doesn't mess my audio up too much Aman in the chat on pixel data in oh, I could just use tensorflow.js to load the pixel data. Oh TF image That's a great point Okay, I should probably use that Great point, okay, so this was interesting to explore but let's Let's look at I forgot about that. Thank you for that. That is a great note. So let's go to TF dot image Yeah, look at this You Strap but does it low will it load an image for me? So these are all operations if Hold on what does it expect? Like it expects an image does it expect like like an image HTML image element All right, let's see I From pixels, but this is all stuff happening in the from pixels. Yeah. Okay There is the from pixels function Oh But this is all only in the browser, so I'm not in the browser right now, I mean I could be doing all this in the browser TF image decode, okay image decode. How come I didn't see that? TF image decode I don't see that as a function TF IO decode image Interesting, oh, but this is tensorflow not TF Yeah, so it doesn't look like some of those That like decoding an image file is present here It probably wants to work with images from the browser check this out what I just sent should work says So the thing is like of course we could improve this later Image data. All right. So the parameters are image data. So pixel data image data Image data can I do this in yeah, this is all canvas stuff. So I'm kind of in headless mode right now So I sort of feel like no JS canvas image data So I could use the node canvas module So I could use node canvas and then load an image It's the load image function, okay. Ah, all right. Maybe I should do that. Maybe that makes sense So, all right, this is interesting Let's try this because the other reason to do this is it'll translate nicely to working in p5 but I'm a little bit skeptical of this working in node, but I'll give myself a little bit of time. Let's try installing canvas So Let's comment all this stuff out right now Come back to it So and let's say Import How do I do an import with this Can I do this import Import How do I do this is it like this that possibly be right All right, so let's see Import create can't let's just see. Okay. So now let's try Load image Make this in a sync function Data Data Square zero zero zero Yeah, and then See what happens So I'm just testing this canvas load image function to see if it will load the file Import And see what happens Okay, is it really called canvas it's not called node canvas, but okay Create canvas not found Import Import oh I see Let's try this Okay, look at this Image 28 by 28 data square complete. Huh? Okay. This is interesting Import star as canvas. I don't think my my Import is right. So hold on You Is this This work no, I don't know how to use these es6 imports So For whatever reason This works, but this is not the correct way to do it. I'll have to revisit that later I'm so used to using require. Okay, so first of all, let's Just for a minute here. I just want to know I guess I want to leave TF jazz loaded for right now it Is that what is its console logging there? Yeah, okay So now if I want to load all the images I Mean I could use file system to like figure that out, but I'm just gonna hardcode this I have how many I have a hundred And then let's make this a template literal and So How do I do number formatting in node Is that native oh There's numeral All right, let's try numeral this looks cool And this might be over overkill for what I need to do but Import load image from canvas What if I want to import more than one thing What if I want to import more than one thing Okay, so now let's see how do I use numeral Import If I want to like call it nl for numeral, I don't know And then nl This this might not actually be format, okay Nli format This Is like the format I want is ah so it's That's the format I want so now this I Think this should give me all of the file names I to string pad start Okay, okay Import ABC from X. Yeah Thank you for all these helpful tips in the chat Okay, I'm running out of space here, let's see if I can give myself some more room Okay, so then let's just do console dot log image Let's just do ten images to start See if this works No, no, no, no, so numeral I didn't need because I could just do it with string Let's try did I did I install numeral I did so how come this didn't work Import Numeral from numeral maybe it's that Load image is not a function Didn't like this for I don't know. What did how did I get it working? Okay So I'm doing things in some awkward unnecessary ways like first of all, I don't need this numeral package because I could just use like number to string or something, but it works nicely for me and I Don't understand why I'm doing it this way import Load image That no, I Don't I still don't understand how yes, I should read up on how these Import statements work, but this works Yeah, I tried that import load image from canvas Right look watch I don't want to get stuck on this stuff, but Right, I believe this should work And it's not so you got me As to why that doesn't work, but this is working Okay, so now the question is can I then The point of this was to convert them to tensors The point of this was to convert them to tensors Now from pixels image T no not Wait So I've loaded them I Promise is with browser So I don't have a Browser I Should just have done it the way I was starting to do it Yeah, yes, that's a good So just out of curiosity, I'm going to take Sorrell's I'm probably mispronouncing your name Import And then I could say I mean, it's a little bit more verbose Yeah, I I'm lost But also How do I convert it now to a tensor can I just say Convert it now to a tensor. Can I just say this is what I want to do, but I don't think it's going to let me. It's not a function. Can I get this to work from node? Just add support to tf.fromPixels in node. This is supposed to work. This should work according to this. Am I in the wrong version of tf.js somehow? Do I need a core? fix tf.fromPixels. Why? Supposedly. tf.fromPixels is not a function. It must have changed. Let me just see which version am I using. 3. Is this somehow different? This is the node version. Did that go away? Oh, tf.image. Can I just put the browser in there and it will figure it out? Is it as simple as that? Did I forget? Pixels pass to tf.browser must either be image data in Brower. I should go back to my original solution. tf.fromPixels was deprecated. I should just go back to my original solution. I'm going to go back to my original solution using GIMP. I can make a tensor very easily with this small amount of data. We could come back if there's a more efficient way of doing this. Let's just go back to GIMP. I could probably read the pixels just with node canvas, which might be useful because then if I want to ever just do this in the browser. Let's not do it this way. Actually, can I just read the pixels here? This is what comes up first in my search. Image data. Image data.data. Is it there? Is it there? Do I have the pixels? No. It's such a weird thing for it to console log. Yeah, Sean, this is such a good question. I don't really know why I started doing. I was imagining that at some point I wanted to process huge amounts of data. I don't know. There's not really a good reason. It's just where I started because it was easier for me to work it out. I could just use the file system, like I said. This is silly. I could come back to get image data. I have to draw it as I go. Okay. All right. All right. I've gone far enough with this silly way. Okay. Get array of pixels from an image file. Image pixel color. Okay. Right. This is where I started. Okay. Great. So we're going to use promises and we're going to read. So import Jim. I don't know. Maybe that's right. Okay. And then now we should be able to say let's just try this just real quick. And let's see what happens here. Jim dot read is not a function. I don't know how to import anything. Okay. We got something. Decoders. How do I? Okay. Okay. Instead of using require. There we go. Just as simple as that. Okay. I over complicated it. Okay. Oh, look. It redrew the image. Great. Okay. So this is working. Let's go back. Boy, this stuff takes forever. Okay. So just to figure out where we are for a moment. And I'm going to take a short break in a second. Check on my daughter. And talk about curiosity stream. But this is where we are. Let's see. I am currently just trying to load the image to read the pixels to put it into a tensor. And I'm going to say this now. And the question is, how do I? Where is the Jim documentation? Contained scale, auto crop, crop, blit, composite, mask, convolute, flip, pixelate, displace, clone, resize. Well, I'm looking for like pixels. Okay. No. It's got to be a way to just read the pixels directly to get the pixels as an array. Neighbor pixels. Boy, I'm making this so hard. Let's see if this gives us anything we can use. Data. All right. That's promising. There's a get base 64, get buffer, get pixel color. Well, that's kind of useful. But I don't want to go through and get the pixel colors one at a time. Undefined. Wasn't there something called data? Oh, bitmap. Bitmap. Okay. There's the raw data. Let's see what this looks like. Mine must be a string. I got some weird error there. That didn't work. I can't believe how much trouble I'm having getting the pixels. Am I really going to get the pixels one at a time? All right. Let's just do it. This is so crazy what I'm doing. Get pixel color. J, K. What? Oh, pixels I doesn't even mean anything. Okay. Sorry. This is me reconstructing the pixel array. What are you doing? Automating things for me that I don't want you to do. This actually makes kind of sense. This bit image scan. Hey, wait. Amr is giving me something. Scan? Is that from Jim? Here's a good reference. Your URL probably won't work, Sorel. So, this is giving me probably like the integer. This bitmap data. This is in the Jim documentation. Oh, image.scan. Thank you. Okay. Scan. Ah, scan a region. Image bitmap data. Got it. Got it, got it, got it. Okay, okay. Let's see. Scan. Jim enables low images in memory through the bitmap property of each Jim object. Why is the this so weird? Yeah. R. Jeez. This is so, this is so insane how much this is like driving me crazy. Like how much I'm getting stuck in this. This makes me want to go back to the browser. All right. Let's go for this. This is really weird, but scans a region of the bitmap and calls the function F on every pixel. But couldn't I just do this myself? Is the data, hold on a second. Bitmap data. Okay. Let me just try something. Let R equal image bitmap data zero. Is it just, can I operate the bitmap like an array? Ah, there we go. This was so easy. Ah, I'm such a dummy. Okay, okay. There we go. So now I can do, index equals zero. Index. I'm just going to, I know it's everything's 28 by 28, so I'm just hard coding it in. I'm just going to use N and then the actual pixel, the actual index is N times four. The R is N plus zero, N plus one, N plus two. But I'm not doing an RGB image, so I can just use the R. And now if I console log R, I could just use the map function, but I'll raw date. I'm just going to make an array. So I could do some kind of higher order array function to just like do it. I've got, I can basically turn the bitmap into a tensor directly, but since I've got grayscale images, it's probably what I should do actually. But I'm just going to say raw data, just for now, raw data N equals R. And then console log raw data. Okay, great. So this is all of the raw grayscale values. There we go. We're getting somewhere. So now, remember when I was doing this before? I, no, these are the X inputs. So this generate image, we returned a function. So train model, X train, I'm just sorry, I'm a little lost here. Okay, so X inputs. So loading all the images, we have X inputs. And then X inputs index I is that raw data. So basically, I'm loading every single image into an array and then putting it in my X inputs array because, and I can take all this other stuff out because, and let's get rid of the random one. Because when it's time to train the, get the training data. So this, I need a curly bracket there to close this out. Then the training data is a tensor out of all of these images. And then I'm not going to call train model just yet, but let's sort of see. I is not found. Why is I not found? Oh, right, because this does need to be in here. There we go. Okay, so now that's one image as a tensor. So now I can actually go ahead and load all 100 images. Okay, I loaded 100 images into those tensors. By the way, the reason why you're seeing 255 everywhere is those images are all white around the edges. And all of the data that wouldn't be 255 should be dot dot dot. Yeah, I need to refactor this stuff. Chris is saying you should make getting the raw data into a separate function. Absolutely. So I will refactor this later. But now I should be able to say await train model. And let's see what happens here. X train is not defined. Oh, because I made that those global. Okay, well, here. I'm going to just be very silly, but I need to rethink how all these functions are organized. Remember, this is something I talked about last time. This is very weird. Why are my inputs and my outputs the training data? This is unique to this auto encoder problem where instead of like an image classification problem where I would have a whole bunch of images paired with their target labels, those images, the training, the correct output for each image is that image itself. Let me come over here. And. So something happened. I don't get what this loss is. It's a negative number. I'm a little confused by that. But this is also so few images, so I think I'm at a good place where now I can just take a short break. I'm going to turn the heat on for a little bit to warm it up in here. And so the things that I need to do after I take this short break are. Let me make more images. Let me think about. The hyper parameters and configuration of this network. Like if I just like right now, if I just change this to the encoder having 784 units. Interesting, I wonder I need to think about the learning rate. The loss. I don't know what's going on here. Exactly. I need to rethink the hyper parameters, normalize the data. Thank you, Aman. Why did I forget? Why did I forget that? Thank you. Let me do that quickly. So important. I forgot to normalize the data. No wonder it's like exploding. There we go. OK, we're getting somewhere. The loss is like a number that makes sense. Now it started with.683 went all the way down. To.1 I could try more epochs, but I'm going to get more data. I'm going to. You know. Just I should be able to get a loss of zero essentially if I have 700. Yeah, look at this. Look at that. Oh, the loss is going to be of course they've defeated the purpose by not actually compressing the data. But OK, warming up the hand. That's what I'm about to do. All right. OK, everybody. I'm really close now. This was a lot, a lot of time that I spent like trying to just figure out how to load the images. Sorry for all of those kind of strange tangents and different libraries. This is still kind of awkward and weird. But the fact that the data can be read from the file with Jim and then the actual pixel information is just so cool. OK, so. I want to take a break for a minute before I take my break. Let me thank today's sponsor. The sponsor of this is a sponsor is curiosity stream and it's a great way to get your data. And it's a great way to get your data. And I some of you probably weren't here at the beginning of the live stream where I showed this to you. So curiosity stream. I'm just going to quickly play this brief ad for you from curiosity stream directly so you can learn all about what curiosity stream is. But don't go away. Because after I play this, I'm going to talk to you about why you should sign up through my website. The award winning original series. Follow your curiosity. This is curiosity stream. You. Oh, I'm really. I'm so getting fired. I know. OK, so I'm talking to it. So at least that. Start over. Start over. I'm exit exit stage right. Coming back. Don't make don't make don't don't everybody sign up. So don't get fired. OK. Hello, everyone. You just saw that wonderful 30 second promo about curiosity stream, which is one of my favorite streaming services. Because it is chock full of so many wonderful educational documentaries. The things that I like to watch the most is all the nature stuff. So we can see here just realm of the Volga. Whoa. The Volga flows 2000 miles. Oh, I've got to check this one out. I was just saying that one of the ones that I have watched with my kids that I really love, which was under here under kids. It's ancient earth, which is all about life that existed in the Permian, Triassic and Cretaceous periods. So right. And who says even without the sound, I want to watch that sea lion show. So just curiosity stream. If you sign up through my link. And I believe if I go slash coding train. It'll sort of show us that. Because I'm already logged in. So if I wasn't logged in, it would have a nice little banner at the top that says you get 26% off of the annual subscription. That comes to $14.79. It's barely over a dollar per month at $14.79 for the entire year. But I think the thing that I really want to tell you that I'm really excited about is this is a bundle. So if you sign up for curiosity stream bundle through the link, you will also get access to Nebula. So Nebula is a streaming service built by YouTube creators. Many of my favorites here. If I go to my library, there's some that I'm following. I'm Renee Ritchie. If you like AI and want machine learning, want to learn more about machine learning, you should definitely be checking out Jordan Harrod's videos. There's some other ones that are here. And look at this! All of these are Daniel Shiffman coding train videos. And in particular, one of the things that you get with Nebula is early access. And so this is a video that isn't yet out on the channel. Will be hopefully tomorrow. If you want early access to it, you'll get that through the Nebula bundle. So many wonderful creators. A lot of this stuff is also on YouTube, but it's without ads on Nebula. And there are all these wonderful Nebula originals. So this is a really awesome compilation of different creators. I wonder if I could make one of these. I don't know. But different creators on YouTube, they're all making videos about the opening title sequences of different television shows. So you can see Renee Ritchie did one about Buffy the Vampire Slayer. We've got Soph's Notes, one about Pokemon. Ooh, I've got to check this out. So these originals are really just wonderful. I'm just poking through to look for some other ones. I'm a big fan of Legal Eagle. So you've got all of this bad law. Words good. So Mikhail is asking, did he say built by YouTube creators or YouTube's creators? No. Built by creators. So everyone that you see here on Nebula participated in the making of Nebula itself. And this isn't really true for me, but I know that one of the benefits for many YouTube creators of Nebula is certain kinds of content. A lot of the historical videos, certain kinds of content can't be on YouTube. It will get demonetized or it will get sort of, if it's about a kind of topic like about World War II, for example. So I'm not saying this very eloquently, but creators are free basically to publish certain kinds of videos on Nebula that might cause them issues on YouTube itself. So that's one of the motivations as well as all these originals, about being able to have no ads. So you can get this for free. Not for free. Well, you do get it for free if you sign up for the, oh, oh, I'm so going to get fired. I'm really basically like, I just got a cop to it. Today has been such a mess for me. I had this all planned out this morning. I had everything I knew I wanted to say and do in this live stream. I really do love this service Nebula. I participated in it. It's meaningful to me. And it's like as I get to become, spend more and more time on Coding Train, I'm really hoping that come this January, I'm going to be able to dive more into Nebula and maybe make a Nebula original myself. So if you want to get involved, learn more about it, also support Coding Train itself, get access to this incredible library of documentaries, you can go right now to curiositystream.com slash coding train. That's the link right there. Curiositystream.com slash coding train. Thank you everybody for tolerating this like really terrible sponsor read. I'm going to do better next time. I'm going to take a like a two or three minute break. You can sign up now if you have nothing to do in this two or three minutes. I'll be right back to finish off this auto encoder project. I'm going to go feel bad about myself over there now. Be right back. All right. All right. I have returned. I took some deep breaths, did a very short 20 second meditation. And John says, well, you got me to sign up so you didn't do too badly. All right. Those pity sign ups. I appreciate it. All right. Let me get back into what we're all here for, which is my building of an auto encoder. All right. So I think we're really close here to actually seeing some images. Generated from the auto encoder. Now, if I wanted to go all the way through with this, I would. I want to eventually reconnect this back to the browser itself. I mean, maybe I should just have the model in the browser. I don't really need a node server. So maybe run the training. I'm not really sure where I want to go with this ultimately. It so turns out. But I do want to see the results of the auto encoder in the browser and start to understand how to manipulate the latent space. But my goal for today, given that I would like to wrap this up in about 20 to 30 minutes, is to simply see an image generated from the auto encoder. Even just one. So I'm trying to decide. I think it would be worth me putting in a few more layers. So, I mean, I suppose I don't need to worry about improving this so much. And let's just work with what I've got. Which is 100 images. Let's see what happens if I give it 100 epochs. And I'm just going to go down. I'm going to compress the 784 pixels down to 64. Oh, and Mikhail is asking a great, great question. In his image loading, he's normalizing the pixels to between 0 and 1, but all the TF tutorials I've seen use negative 1 to 1. Is there any practical difference or just personal preference? I would love to know the answer to that question. I think at the moment, because I'm using this output, I'm using the sigmoid function as the output activation function, it's got to be between 0 and 1 because the outputs are only going to be between 0 and 1 with sigmoid. But if I were using tanh, then I could have outputs between negative 1 and 1. It has to do with the... So, but again, I'm kind of flying blind. I'm just sort of like throwing all the spaghetti at the wall. And to see what sticks, just trying to get something working that I can go back and kind of fine tune more thoughtfully. I don't need to print this out anymore. Let's just try training this. Let's see what happens with the loss. So, the loss seems to settle at probably around 100 epochs at 0.07. That's great. So, could I now... If I wanted to generate an image from this, let's go back to the original... So, I'm done with sort of like part two and a half of three parts. This is in three parts. Part one was just building the autoencoder, giving it noisy data. Part 2A was getting actual data into the autoencoder. Part 2B is looking at the results of the autoencoder after it's been trained. So, if I'm coming back to this, what did this tutorial do? And I'm not having any test data. Yeah, right. This is also, by the way, normalizing between 0 and 1. Decoded images. Oh, using predict. Okay. So, if I can use predict to see... Okay, great. So, let's do this. Let's follow this. So, I want to use predict. Let's refactor this a little bit to make it less weird. Okay? So, also notice the scientific method. Yeah. So, let's get a little bit better here. So, basically I want to have a... I'm going to write a function called like main... Which is a little bit silly. Function. Function. And it's going to be an async function. And the things that I'm going to do in it are... Load all image data. Convert image data to a tensor. Train the model. Test the model. So, I've done everything but this last step of test the model. So, this async function load images. I can just say return x inputs. Let's just call this all images. And return all images. So, first thing I'm going to say is... Const images equals await load images. Okay? Then... And there was a question about why this is a 2D tensor. We'll talk about that. If the data is flattened into one dimension. We'll talk about that in a moment. So, let's do this. Does this need an await? No. It doesn't. So, that's the training data. I should save some to be testing data. But, I'll worry about that later. I'm just going to reuse. This is a very bad idea. But, I'm going to reuse some of the training data for my testing of the model. We can separate out. We can get new data later. I promise. And then, training the model is as follows. Let's write a function called async train model. And, we're going to get data in. I'm going to say await async function. Await train model with x train. And then, is auto encoder still just a global variable? Yeah. So, it would make sense for me also to... Have a function that is build model. So, basically... Auto encoder is a sequential model. The build model function puts all the stuff into it. Why I'm... So, I should be calling build model first. Model. What did I do wrong here? There we go. So, let's bring this up here. Build model. Auto encoder. Again, I'm not so sure this really makes a lot of sense the way I'm doing this. So, now, I need... To pass this as arguments. This is pretty arbitrary what I'm doing. But, I'm trying to get rid of sort of global variables. And so, now, I've created the sequential model. I think actually I'd like to do this. And then, return it. So, what am I doing? I am... Build the model. Load the image data. Convert the image data to a tensor. So, that I can train the model with that data. Then, let's just make sure this all works. I think I have to call this function. Alright, so, everything still works. Everything still works. Training the model. Then, I would like to test the model. So, I need one image. And, I'm going to call this function. So, I need one image. So, all the images are here. So, what I could do... Let's do the following. Let's be a little more rigorous about this. I'm going to rerun my training data creation. And, make 500 images. 550 images. Oops, that's not right. I'm going to make 550 images. They're all squares. Okay, we're almost there. Making 550 squares. All done. I'm going to get this data. I'm going to bring it into... The autoencoder project. Going to replace it. And, I'm going to rerun this sketch. It's not a sketch. I'm going to rerun this code. With... I'm going to put an argument in here. I'm going to put an argument in here. For 500 images. Let's just see how this goes. Ooh, loss is getting better. When I've got 500 images, I'm able to get the loss much further down. Although, it seems to have settled by the time I'm at 100 epochs. So, certainly, there's not a huge reason for me to train it for that long. Let's just say 75 to make things run faster. And, I think actually what I want to do is load all 550. But, I want to take out just a slice of them, right? So, how do you do a slice JavaScript array? Slice returns a shallow copy of a portion array into a new array object. So, if I wanted just 500, I would do this. And then, if I want to do test, X test, I could create a tensor. Out of those same images, but slice from 500 to 550, right? Let's skip training the model for a second. Alright, right? So, this makes sense. I've got 500 training images, 50 test images. So, now, I should be able to say, Auto encoder predict X test. Let's see. After it's trained. Is that all I need to do? Auto predict encoded images. Oh, it's got the encoder and the decoder as separate things. Oh, it made two separate, it made an encoder model. Anyway, I'm going to do this my own way. Eventually, I want to chop off the encoder and just feed in noise from the middle layer. But, let's just sort of see what happens here. So, I'm training and then, aha! Look, look, look! We're getting images out. Yes! Now, we just need to turn those into images. I bet you Jimp will do that for us. So, how do I write a new image? By the way, it's freezing in here. Create an image and write it in a text. Can I make a new image? Okay, can I set the pixels? We're about to find out. Whew! This frozen mountain behind me is no joke. I should really just turn the heat on in here. But, normally what I do is I warm it up before I stream. But, I thought I wasn't going to. I can't believe this is working. Okay, so I need to get the data. So, back to TensorFlow.js. Where are we? Back to TensorFlow.js. tf.data.array. No, how do I get the tensor? tf.tensor. tf.image. One. Isn't there like, how do I get the data? Data, this is what I want. Gives me the data. Oh, but I can actually just get it as an array. Returns the tensor data as a nested array. Okay. So, const, did I already use the word images? Yeah, like new images equals output array. Await. Console.log new images index zero. It's a little silly that I'm training the model every single time. But, okay, great. So, now I got an array of 784 pixel values. So, I should be able to say. You know, I could use base 64 encoding, probably as a way as writing the images. But, this is fine. And let's just do it with just one. So, now what I'm doing is I want to say image equals gimp. Was it create? It would really help if I really knew gimp. Writing text. How do I create an image? New gimp. Oh, maybe just this. Oh, okay. Creating new images. Here we go. Okay. You can call the gimp constructor. Can I do this with buffer? Data buffer. Raw image. Four channel RGBA image data. Okay. Just now, can I do a weight? So, I'm making it. What if I just make the buffer? What if I just make the buffer? How do I do that thing where I fill an array? Okay. So, figure out how to start here. Okay. So, let's just go ahead and do this. Buffer is an array. And then for n equals 0, n is less than new images index i dot length, n plus plus, buffer index n. n times 4 plus 0, right, is new images in, okay, so current is new images index i. So, if, basically I want to take all of those values and expand them back out by 255. The reason why I'm multiplying by 4 is I took my grayscale image of RGBA and made it just like one value. So, now I'm paying for that because I've got to expand it back out to four values. And this one should always just be 255, so there's no alpha transparency. And these are, this is just putting whatever that value is in the RGB channels. And then I should be able to make a new image. And then how do I write the file? Write image, right, right, I should be able to say image dot write test dot png. Now, that's going to, let's just do it with one, I'm just doing it with one image, so it's fine. I would say I need to number these, I'll get to that. And let's just see if output, okay. Let's just see what's happened. I'm sure I missed something important. Okay, the first argument must be of type string or instance of buffer, array, buffer, array, array like object received null. Where? So close to having this working, what did I miss? Console log buffer. Let's just take a look at it. I'm just going to train the model for, and let's put the number of epochs in here. Just do 10 epochs. So I can like test this more quickly. Okay, so now I should be able to see the buffer after 10 epochs. Almost done. I'm almost done. Okay, this is the buffer. That looks right. Oh, maybe I can't use a weight here. No matching. So maybe a weight doesn't work. I need to follow its callback methodology. Let's see what happens here. What is it? That last argument is error image. Is the function. I'm a little lost now. A little lost in my syntax. And the arguments are, oh, this is first. Oh, this is a separate argument. Doesn't go in there. Okay. So it does not go in this object. There we go. Okay, image. And what if I actually just did it just as a test? Well, okay, let's try it with the data buffer. Data buffer error image. And then if I said image right. Let's see if this works. Okay, here we go. Cannot read properties of undefined. We're going to get there, folks. No matching constructor overloading was found. Do I need to round my output values to integers? I don't think that should matter. But, yeah, I could see how that's an issue. Floor is not defined. Yeah, yeah, yeah. All right. All right. Let's just try this for a second. See if I can get a red image. Oh, by the way, there's something here. Oh, nothing is there. Just now I'm not trying to use my actual data from the neural network. I just literally put the GIMP code to draw a red image. That's 256 by 256 there. Just to know that this works. Okay. Now do we have a red image? Yes. Or pink? Okay. So image writing out does work. Now the question is, what if I, how do I create the buffer correctly? So if I wanted to follow. So why does this not work? And this does. Data. I mean, I must not have made the buffer correctly. Buffer. Buffer is expected to be a four-channel RGBA image data. Yeah? Which is not just a plain array. Let's see if we can find an example. Yeah. Yeah, look, here's the error. Huh. Other people are finding this error. Okay. That's unfortunate. Yeah, it doesn't seem to work. Buffer from array. Okay. Ah, Chris Manning says buffer from array. Okay. Fingers crossed emoji. What? Oh, I think that worked. I mean, oh, but I didn't write the image. I think that worked. Oh, I think that worked. This is very exciting. Yes. Yes. I've never been so excited to see a total, like, noise nonsense image. Oh, my God, that's amazing. Okay. Wait, wait, wait, wait, wait, wait. All right. So now, hold on, hold on, hold on. First of all, I need to train the model better. And then, okay. So what do I need to do? This I can get rid of. I need to train the model. With more epochs. Let's do 100 epochs. Then, where was my crazy numeral thing I did? To, let's find that, yeah. Then I need to save it. And then, I need to train the model. Then, I need to save it. So, what am I? Am I in N? Am I in I? I don't even remember. I'm in I, still. I, output, square, num.png. So, this should do. So, now, basically, I am, and I should do all of them. So, new images dot length. And, I've got a lot of, like, these prints here that I don't need. Okay. So, what this should be doing now. And, I should call, I have this main function. Let's take this out. Let's do, oh, this should say await. Oh, no, it doesn't need an await. It only needs an await if I'm converting it to data that I can actually use. That's interesting. So, hold on. So, this is the train data. This is loading all, then I'm taking 500 images to train it with. Then, testing the model, I'm going to say, await, generate, generate tests. And, I want to give it the auto encoder and the test data. So, this should all be in its own function, which is an async function, generate tests, which gets the auto encoder and the test data. And, writes it out. Okay. So, there we go. These are the steps now. Right. Build the model, load all of the images, train the model, test the model. So, train the model with 500 images, test the model with 50 images. Okay. Ready, everybody? This definitely merits a, here we go. Oh, by the way, it's funny how this poll is still up. I'm going to hit end poll. Yes, thank you to Chris Ray. Train whistle for Chris Ray. Here we go. I mean, did it write all those images out that fast? I find that hard to believe. It looks like it, no, that's, what? Oops. I couldn't output. Oh, yeah, it did. But, something is wacky. My images don't look anything like what was fed into them. Oh, shoot. What could I have done wrong? Oh, we've got everything to work. Look at this. When getting the output, I mean, to be fair, this model is kind of ridiculous. What if I go back to my just like, let it like literally copy everything? Oops. Can't tell if it re, did it regenerate the output? I mean, maybe I need to rethink my model. Yeah, no, what is going on? I mean, there's images there. It's outputting a zoomed in square. You've set it to 28 pixels width and height, I think, yeah? Did you write the pixels out in the same order you read them in? Not necessarily. So, let's think about this. This is me reading the images, the data in. And then, it should be 784. This is very silly how I have to run through 100 epochs of training this model just to, yeah, yeah, yeah, OK, just to see that that number was 784. I am not reading the Discord chat. Simon is saying, maybe you should add more layers. I don't think you did anything wrong. I think the model is just bad. More layers, OK. I believe that could be, that is the case. Let's add more layers. So, let's do it by half. So, 784 divided by 2 is 392. Let's just use powers of 2. So, let's start with, should I be using ReLU for all the encoder activation functions? So, let's just do encoder 1. Encoder 2 is, I don't need the input shape anymore, is 128. And then, decoder 1 would be 256. And, again, this is a little bit silly now. I don't need to name all of them. I could just do decoder 2 is 784. OK. So, and let me be a little bit more, I think it will be nicer actually. I don't need to, I'm just going to add them in directly. So, let's add in, add in this layer. Then add in another layer. And then, I wonder if there's a nicer way to write this, but I'm just going to do this like this. Another layer. And another layer. Back to 784. OK. So, we're putting in, you should take one of your input images, create the buffer the exact same way you are with the output. Yeah, that's a very good idea, Chris Manning. I will do that. I'm also going to do that. So, here are my layers. The first layer gets 784 down to 256, then down to 128, then back up to 256, then back up to 784, and out. And I don't need this anymore. So, let's see how this does. 351, yeah. So, let me do, let's do some jim tests. So, I'm going to do test.js. So, I've got too much stuff going on here to really know what's happening. So, let me do the following. I'm going to take, in this test, I'm going to just get rid of everything but jim. Get rid of all the TensorFlow stuff, just for a second. So, I want to, oh, I lost some stuff. So, I want to test images. So, let's test images one. So, I'm going to read the image. I'm going to get the raw data. Then let's try writing the image back out to make sure that actually works the way I expected it to. So, now that I have the raw data, this is the equivalent of raw data to expand it back out and write the image out. So, let us get rid of output. So, this should just be a nice little test to read one image in and write it back out, just to make sure that that actually works. Probably takes longer to train, says K-Week Man. Yeah. So, let's just do no test. Image write. What's going on here? Oh, there's a mistake here. There's a mistake here. N times 4, I'm using N to pull the colors. That should be index. Whoa. Whoa, that's a huge mistake that I've just caught right now. Any idea what the batch size should be? Also, this is so arbitrary. Let's just say 32. I'm going to make that lower, because I don't have that much data. Look at this. This is a huge error. Huge error. Huge error. Huge error. I think that might actually be – I might have just found the issue. I feel I need more time to train, but we could actually look at what just came out. Yeah. I did it. I did it. It worked. Look what comes out. Look at that. That is beautiful. Beautiful. Autoencoder worked. Okay. This is way too exciting. Hold on. Hold on. Everybody relax. Okay. This is really exciting. Okay. Now, I have to wrap up. I'm way over time. There's so much more that could be done to this. Part 3, I believe, will come at some point. Maybe this will all get edited into some video, and I'll narrate it. Who knows? I have no idea. But what I want to do is a couple things. One, let's train it for much longer. Where's the training? Oh, yeah. I just want to see. Let's give it 200 epochs. I just want to see, like, when does the loss stop going down? It's still going down. I mean, eventually, I need to just save the model and not do this every time. But I just want to see. I want to see if I can denoise some images. So where are we? Yeah, I mean, so 250. We'll do 250 epochs. So what I would like to do, actually, now, just as an experiment, is let me make a bunch of images with a lot of noise in them. So let's do this. Point. So I'm just adding a lot of noise into the image. Maybe I need to add more. Let's add a lot more. So I'm going to make a whole bunch that are very noisy. I'm just going to take the last 50. I'm just going to take the last 50. Where's the processing sketch? That's not right. Here it is. So I just need 500 of 549, right? Do these look even noisy? Hold on. Let's look at some of these. Oh, you know what? In the sampling down of it, I'm going to add a bunch of noise. Oh, you know what? In the sampling down of it, the noise is really gone. So let's do this. This will be better, I think. This is so silly what I'm doing, but it's fine. All right. This might be too noisy, but let's give it a whirl. OK, so I'm going to take these, just these last 49 images, and I'm going to put them in here. Apply to all, replace. So just so we're clear, the first 499 images, if we were looking at these, these are just plain squares. But then my test images look like this. Can I denoise these images with my autoencoder? We're about to find out. So I'm now training the model off the first 499 images, letting it kind of get down as low as I can get it. And then we're going to look at what came out. So the output is, the output has the noise in it. We need to compare it one to one. So that's, it's a little less noisy, wouldn't you say? These are the two background noise notes, these are the two noise notes, so they're in cost. 2. A bit louder. 3. It's slightly denoised. Interesting. So, this is not the application that I'm looking to do. What I would like to do, and I think I'll have to wait for part 3, is I want to, first of all, bump up the resolution a little bit, perhaps. Then, it looks like it's smoothed the noise, yeah. No, I didn't train with the... MiniJimmy says the output has the noise because the noisy pictures were trained at the end. Those shouldn't have been part of the training. The way I've written the code is I'm only training it with the first 500 images. So, it shouldn't have any of the... and I just put in the last 50. So, if I manipulated my files correctly, in terms of the input images, there should be no noise all the way until 499. And then, they should be noisy. So, these are the training images, and then these are the test images. Something happened with the loss and acceleration, yeah. So, let's... let me post this code. Let's see, I don't want this JPEG. I'm going to do a couple of things. One is no JPEGs. Let me also get the training data generator into... here. So, this should be... So, I'm adding... and that test file I don't need anymore because I just wasn't sure about, but I'll leave that in there. So, git ignore index package. Could it be pulling in image 500? That might be an issue. I don't think so, though. Oh, they should be part of the training versus no noise in the target. Yeah, that's interesting. Right, that makes more sense. So, yes, and so now... code after part two. Now, I'm pushing it. I got to go to the grocery store. It's not 5 o'clock yet, is it? Oh, it's 4 o'clock. Okay, I'm way over time here. Sorry, looking at my... text messages. Okay, more epochs. I don't think it's going to get down below... So, there's so much that could be done to improve this. This is just a start. Here are some suggestions if anybody wants to pick up and continue this. I'll try to come back and do this part three. Number one is, you know, I kind of haven't been too thoughtful about the layers I'm putting in here in terms of the number of units, what activation functions I'm doing, and this kind of stuff. So, I would love for any of you who's interested to sort of play around with this, see what kind of results you get. Ultimately, what I would like to do is take this model and be able to start feeding in data just from here. So, I want to take random data and... I basically want to start looking at this as a way to browse the latent space. And the other thing is, like, this is just a plain vanilla autoencoder. And there is something called a variational autoencoder. So, what would I need to do to this to make it from a just this sort of like beginner starting point autoencoder and make a variational autoencoder? I would like to know. Right, and Simon is saying, you didn't get to generating new images with the decoder only. So, that's got to be in part three. So, if you would like to pick this up and run with it on your own, you can go to github.com slash coding train. You can come here and check out the autoencoder demo. I would take... I probably wouldn't... I'm not looking right now for pull requests that improve this because I want to keep improving it on my own. But I 100% would accept a pull request that adds a readme file that documents all this, links to the live streams, etc. And I would accept issues that propose improvements or document and link to your own version of it. So, I'll try to come back at some point. It's probably going to be December. This is probably going to be the last live stream for November. You know, as I said, if you wanted to watch my newest video... Right, if you want to watch my newest video, all you need to do is go sign up for the CuriosityStream and Nebula bundle. CuriosityStream.com slash coding train. 26% off. Yeah, adversarial autoencoder says, Andrea. That's what I should be doing. But I'm doing this very slowly. So, one step at a time. But this new video also should be out on YouTube itself tomorrow or hopefully at least by Monday. Sometime very, very soon. Huge shout out to Tim Rodenbroker who donated to the Processing Foundation fundraiser which inspired this video. Thank you to the sponsor, CuriosityStream. CuriosityStream.com slash coding train. Tons of wonderful documentaries as well as full access to the Nebula streaming service. Alright, so this wraps up my demonstration, explanation, attempts at autoencoder. We've got autoencoder part two done. I'm going to put on a sweater. I'm going to turn on the heat. I'm going to plug the internet back into the house. I'm going to go work on answering my students' emails, make some dinner for my children. And I really appreciate everybody here participating in this, cheering me on. I'm very excited that this actually works. So, more soon. Alright, goodbye everybody. See you next time on the coding train. I can't find my music. Here we go. I'm going to do the this dot, this dot, this dot, this dot, the this dot song. Never forget the this dot. Somebody compose that song for me. I'm going to say it once again. Here we go. Sing it with me. It's the four two Cartesian coordinate songs. It's the four two Cartesian coordinate songs. It's the four two Cartesian coordinate songs. It's the four two Cartesian coordinate songs. Auto-tune and the internet will fix that for me. Sing it with me. It's the four two Cartesian coordinate songs. It's the four two Cartesian coordinate songs. It's the four two Cartesian coordinate songs. It's the four two Cartesian coordinate songs. It's the four two Cartesian coordinate songs. It's the four two Cartesian coordinate songs. It's the four two Cartesian coordinate songs. It's the four two Cartesian coordinate songs. It's the four two Cartesian coordinate songs. Unicorns and rainbows and cupcakes. What else is there? Yes, kittens. Thank you very much. Kittens and rainbows and cupcakes. Notice that and look what I get. I'm really losing my mind. Okay, let's do it. Kittens and rainbows and cupcakes. Kittens and rainbows and cupcakes. Kittens and rainbows and cupcakes. Kittens and rainbows and cupcakes. Kittens and rainbows and cupcakes. Kittens and rainbows and cupcakes. I feel just sort of like a nice feeling of relaxation. Everything's going to be okay today. The dream is not broken. It has not frozen. This is a wonderful thing. Okay, we're going to do it. I'm really getting to something. I need my sound effect. Unicorns and rainbows and cupcakes. What else is there? Unicorns and rainbows and cupcakes. That was invalid syntax. I forgot. There was one other thing here that I think is important. That I will use continuously over and over again. All sorts of text generation analysis things. That I will use continuously over and over again. First thing I need to do is, yes, kittens. Kittens, kittens. I'm really losing my mind. Okay, we're going to do it. Kittens and kittens and kittens and kittens. Dog, yeah. No.",
    "translation": null
  },
  "error": null,
  "status": "succeeded",
  "created_at": "2023-09-26T21:03:44.224124Z",
  "started_at": "2023-09-26T21:16:29.178156Z",
  "completed_at": "2023-09-26T21:45:01.627285Z",
  "webhook": "https://83ceaa0b612c.ngrok.app/?video_id=SA7W7rlyc3c",
  "webhook_events_filter": [
    "completed"
  ],
  "metrics": {
    "predict_time": 1712.449129
  },
  "urls": {
    "cancel": "https://api.replicate.com/v1/predictions/kjhg4jrbjyz5rgs3dvbxreggxu/cancel",
    "get": "https://api.replicate.com/v1/predictions/kjhg4jrbjyz5rgs3dvbxreggxu"
  }
}