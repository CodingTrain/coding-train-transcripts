{
  "id": "cbcbjxjbk4xnebf7722smmjcu4",
  "version": "91ee9c0c3df30478510ff8c8a3a545add1ad0259ad3a9f78fba57fbc05ee64f7",
  "input": {
    "audio": "https://upcdn.io/FW25b4F/raw/coding-train/Tiot877orkU.m4a"
  },
  "logs": "Transcribe with large-v2 model\nDetected language: English\n  0%|          | 0/96492 [00:00<?, ?frames/s]\n  3%|▎         | 2872/96492 [00:08<04:23, 355.23frames/s]\n  6%|▌         | 5848/96492 [00:19<05:07, 294.81frames/s]\n  9%|▉         | 8812/96492 [00:30<05:14, 278.99frames/s]\n 12%|█▏        | 11376/96492 [00:37<04:37, 307.26frames/s]\n 15%|█▍        | 14320/96492 [00:43<03:50, 356.17frames/s]\n 18%|█▊        | 17020/96492 [00:51<03:46, 351.39frames/s]\n 21%|██        | 20016/96492 [01:01<03:50, 331.15frames/s]\n 24%|██▍       | 22948/96492 [01:11<03:51, 317.69frames/s]\n 27%|██▋       | 25580/96492 [01:20<03:46, 313.38frames/s]\n 29%|██▉       | 28452/96492 [01:26<03:14, 349.60frames/s]\n 32%|███▏      | 31328/96492 [01:31<02:48, 387.68frames/s]\n 35%|███▌      | 34040/96492 [01:38<02:39, 391.71frames/s]\n 38%|███▊      | 36764/96492 [01:45<02:29, 400.38frames/s]\n 41%|████      | 39488/96492 [01:49<02:05, 454.64frames/s]\n 44%|████▎     | 42176/96492 [01:52<01:46, 510.30frames/s]\n 46%|████▌     | 44608/96492 [01:57<01:41, 508.89frames/s]\n 49%|████▉     | 47312/96492 [02:03<01:38, 501.07frames/s]\n 52%|█████▏    | 50192/96492 [02:11<01:42, 449.83frames/s]\n 55%|█████▌    | 53152/96492 [02:16<01:32, 470.10frames/s]\n 58%|█████▊    | 56048/96492 [02:24<01:30, 447.07frames/s]\n 61%|██████    | 59024/96492 [02:31<01:28, 424.18frames/s]\n 64%|██████▍   | 62004/96492 [02:37<01:15, 459.51frames/s]\n 67%|██████▋   | 64900/96492 [02:43<01:09, 455.41frames/s]\n 70%|███████   | 67720/96492 [02:47<00:57, 503.79frames/s]\n 73%|███████▎  | 70472/96492 [02:52<00:48, 535.83frames/s]\n 76%|███████▌  | 73456/96492 [02:56<00:39, 590.16frames/s]\n 79%|███████▉  | 76300/96492 [03:02<00:37, 539.60frames/s]\n 82%|████████▏ | 79272/96492 [03:10<00:37, 464.26frames/s]\n 85%|████████▌ | 82240/96492 [03:18<00:32, 441.99frames/s]\n 88%|████████▊ | 85166/96492 [03:26<00:27, 407.13frames/s]\n 91%|█████████ | 88038/96492 [03:34<00:21, 394.90frames/s]\n 94%|█████████▍| 90694/96492 [03:45<00:17, 340.04frames/s]\n 97%|█████████▋| 93606/96492 [03:54<00:08, 331.91frames/s]\n 99%|█████████▉| 95530/96492 [04:01<00:03, 318.93frames/s]\n99%|█████████▉| 95530/96492 [04:06<00:02, 387.98frames/s]\n",
  "output": {
    "detected_language": "english",
    "segments": [
      {
        "avg_logprob": -0.2559750190147987,
        "compression_ratio": 1.7826086956521738,
        "end": 3.7600000000000002,
        "id": 0,
        "no_speech_prob": 0.00818626955151558,
        "seek": 0,
        "start": 0,
        "temperature": 0,
        "text": " Welcome back to working with data and APIs in JavaScript.",
        "tokens": [
          50364,
          4027,
          646,
          281,
          1364,
          365,
          1412,
          293,
          21445,
          294,
          15778,
          13,
          50552
        ]
      },
      {
        "avg_logprob": -0.2559750190147987,
        "compression_ratio": 1.7826086956521738,
        "end": 6.28,
        "id": 1,
        "no_speech_prob": 0.00818626955151558,
        "seek": 0,
        "start": 3.7600000000000002,
        "temperature": 0,
        "text": " So here I am building this project called the weather",
        "tokens": [
          50552,
          407,
          510,
          286,
          669,
          2390,
          341,
          1716,
          1219,
          264,
          5503,
          50678
        ]
      },
      {
        "avg_logprob": -0.2559750190147987,
        "compression_ratio": 1.7826086956521738,
        "end": 6.8,
        "id": 2,
        "no_speech_prob": 0.00818626955151558,
        "seek": 0,
        "start": 6.28,
        "temperature": 0,
        "text": " here.",
        "tokens": [
          50678,
          510,
          13,
          50704
        ]
      },
      {
        "avg_logprob": -0.2559750190147987,
        "compression_ratio": 1.7826086956521738,
        "end": 10.68,
        "id": 3,
        "no_speech_prob": 0.00818626955151558,
        "seek": 0,
        "start": 6.8,
        "temperature": 0,
        "text": " So far what I have is a web page that geolocates,",
        "tokens": [
          50704,
          407,
          1400,
          437,
          286,
          362,
          307,
          257,
          3670,
          3028,
          300,
          1519,
          401,
          905,
          1024,
          11,
          50898
        ]
      },
      {
        "avg_logprob": -0.2559750190147987,
        "compression_ratio": 1.7826086956521738,
        "end": 14.06,
        "id": 4,
        "no_speech_prob": 0.00818626955151558,
        "seek": 0,
        "start": 10.68,
        "temperature": 0,
        "text": " finds latitude and longitude, sends that to a node server.",
        "tokens": [
          50898,
          10704,
          45436,
          293,
          938,
          4377,
          11,
          14790,
          300,
          281,
          257,
          9984,
          7154,
          13,
          51067
        ]
      },
      {
        "avg_logprob": -0.2559750190147987,
        "compression_ratio": 1.7826086956521738,
        "end": 16.56,
        "id": 5,
        "no_speech_prob": 0.00818626955151558,
        "seek": 0,
        "start": 14.06,
        "temperature": 0,
        "text": " The node server receives it, sends that",
        "tokens": [
          51067,
          440,
          9984,
          7154,
          20717,
          309,
          11,
          14790,
          300,
          51192
        ]
      },
      {
        "avg_logprob": -0.2559750190147987,
        "compression_ratio": 1.7826086956521738,
        "end": 19.88,
        "id": 6,
        "no_speech_prob": 0.00818626955151558,
        "seek": 0,
        "start": 16.56,
        "temperature": 0,
        "text": " to an API called dark sky, which gets the weather information,",
        "tokens": [
          51192,
          281,
          364,
          9362,
          1219,
          2877,
          5443,
          11,
          597,
          2170,
          264,
          5503,
          1589,
          11,
          51358
        ]
      },
      {
        "avg_logprob": -0.2559750190147987,
        "compression_ratio": 1.7826086956521738,
        "end": 22.32,
        "id": 7,
        "no_speech_prob": 0.00818626955151558,
        "seek": 0,
        "start": 19.88,
        "temperature": 0,
        "text": " and then sends that back to the client here.",
        "tokens": [
          51358,
          293,
          550,
          14790,
          300,
          646,
          281,
          264,
          6423,
          510,
          13,
          51480
        ]
      },
      {
        "avg_logprob": -0.2559750190147987,
        "compression_ratio": 1.7826086956521738,
        "end": 23.7,
        "id": 8,
        "no_speech_prob": 0.00818626955151558,
        "seek": 0,
        "start": 22.32,
        "temperature": 0,
        "text": " One other thing I want to show you",
        "tokens": [
          51480,
          1485,
          661,
          551,
          286,
          528,
          281,
          855,
          291,
          51549
        ]
      },
      {
        "avg_logprob": -0.2559750190147987,
        "compression_ratio": 1.7826086956521738,
        "end": 26.84,
        "id": 9,
        "no_speech_prob": 0.00818626955151558,
        "seek": 0,
        "start": 23.7,
        "temperature": 0,
        "text": " is spoofing different latitude and longitudes.",
        "tokens": [
          51549,
          307,
          637,
          29496,
          278,
          819,
          45436,
          293,
          938,
          16451,
          13,
          51706
        ]
      },
      {
        "avg_logprob": -0.2559750190147987,
        "compression_ratio": 1.7826086956521738,
        "end": 28.72,
        "id": 10,
        "no_speech_prob": 0.00818626955151558,
        "seek": 0,
        "start": 26.84,
        "temperature": 0,
        "text": " Because ultimately, this project is",
        "tokens": [
          51706,
          1436,
          6284,
          11,
          341,
          1716,
          307,
          51800
        ]
      },
      {
        "avg_logprob": -0.24168338545833726,
        "compression_ratio": 1.684065934065934,
        "end": 30.96,
        "id": 11,
        "no_speech_prob": 0.002216961933299899,
        "seek": 2872,
        "start": 28.72,
        "temperature": 0,
        "text": " going to become much more interesting if I can manage",
        "tokens": [
          50364,
          516,
          281,
          1813,
          709,
          544,
          1880,
          498,
          286,
          393,
          3067,
          50476
        ]
      },
      {
        "avg_logprob": -0.24168338545833726,
        "compression_ratio": 1.684065934065934,
        "end": 33.72,
        "id": 12,
        "no_speech_prob": 0.002216961933299899,
        "seek": 2872,
        "start": 30.96,
        "temperature": 0,
        "text": " to not just check in at the exact same latitude",
        "tokens": [
          50476,
          281,
          406,
          445,
          1520,
          294,
          412,
          264,
          1900,
          912,
          45436,
          50614
        ]
      },
      {
        "avg_logprob": -0.24168338545833726,
        "compression_ratio": 1.684065934065934,
        "end": 35.68,
        "id": 13,
        "no_speech_prob": 0.002216961933299899,
        "seek": 2872,
        "start": 33.72,
        "temperature": 0,
        "text": " and longitude over and over again.",
        "tokens": [
          50614,
          293,
          938,
          4377,
          670,
          293,
          670,
          797,
          13,
          50712
        ]
      },
      {
        "avg_logprob": -0.24168338545833726,
        "compression_ratio": 1.684065934065934,
        "end": 37.64,
        "id": 14,
        "no_speech_prob": 0.002216961933299899,
        "seek": 2872,
        "start": 35.68,
        "temperature": 0,
        "text": " Presumably I'm not able to pick up this laptop",
        "tokens": [
          50712,
          2718,
          449,
          1188,
          286,
          478,
          406,
          1075,
          281,
          1888,
          493,
          341,
          10732,
          50810
        ]
      },
      {
        "avg_logprob": -0.24168338545833726,
        "compression_ratio": 1.684065934065934,
        "end": 39.12,
        "id": 15,
        "no_speech_prob": 0.002216961933299899,
        "seek": 2872,
        "start": 37.64,
        "temperature": 0,
        "text": " and just carry it around and walk",
        "tokens": [
          50810,
          293,
          445,
          3985,
          309,
          926,
          293,
          1792,
          50884
        ]
      },
      {
        "avg_logprob": -0.24168338545833726,
        "compression_ratio": 1.684065934065934,
        "end": 40.54,
        "id": 16,
        "no_speech_prob": 0.002216961933299899,
        "seek": 2872,
        "start": 39.12,
        "temperature": 0,
        "text": " about the streets of New York City",
        "tokens": [
          50884,
          466,
          264,
          8481,
          295,
          1873,
          3609,
          4392,
          50955
        ]
      },
      {
        "avg_logprob": -0.24168338545833726,
        "compression_ratio": 1.684065934065934,
        "end": 42,
        "id": 17,
        "no_speech_prob": 0.002216961933299899,
        "seek": 2872,
        "start": 40.54,
        "temperature": 0,
        "text": " to get different locations.",
        "tokens": [
          50955,
          281,
          483,
          819,
          9253,
          13,
          51028
        ]
      },
      {
        "avg_logprob": -0.24168338545833726,
        "compression_ratio": 1.684065934065934,
        "end": 44.8,
        "id": 18,
        "no_speech_prob": 0.002216961933299899,
        "seek": 2872,
        "start": 42,
        "temperature": 0,
        "text": " If I'm over here in the console, I can actually click Escape,",
        "tokens": [
          51028,
          759,
          286,
          478,
          670,
          510,
          294,
          264,
          11076,
          11,
          286,
          393,
          767,
          2052,
          42960,
          11,
          51168
        ]
      },
      {
        "avg_logprob": -0.24168338545833726,
        "compression_ratio": 1.684065934065934,
        "end": 47.72,
        "id": 19,
        "no_speech_prob": 0.002216961933299899,
        "seek": 2872,
        "start": 44.8,
        "temperature": 0,
        "text": " which brings up this extra console shelf, drawer,",
        "tokens": [
          51168,
          597,
          5607,
          493,
          341,
          2857,
          11076,
          15222,
          11,
          24039,
          11,
          51314
        ]
      },
      {
        "avg_logprob": -0.24168338545833726,
        "compression_ratio": 1.684065934065934,
        "end": 48.84,
        "id": 20,
        "no_speech_prob": 0.002216961933299899,
        "seek": 2872,
        "start": 47.72,
        "temperature": 0,
        "text": " who knows what it's called.",
        "tokens": [
          51314,
          567,
          3255,
          437,
          309,
          311,
          1219,
          13,
          51370
        ]
      },
      {
        "avg_logprob": -0.24168338545833726,
        "compression_ratio": 1.684065934065934,
        "end": 50.8,
        "id": 21,
        "no_speech_prob": 0.002216961933299899,
        "seek": 2872,
        "start": 48.84,
        "temperature": 0,
        "text": " And I can click over here with these three dots",
        "tokens": [
          51370,
          400,
          286,
          393,
          2052,
          670,
          510,
          365,
          613,
          1045,
          15026,
          51468
        ]
      },
      {
        "avg_logprob": -0.24168338545833726,
        "compression_ratio": 1.684065934065934,
        "end": 52.28,
        "id": 22,
        "no_speech_prob": 0.002216961933299899,
        "seek": 2872,
        "start": 50.8,
        "temperature": 0,
        "text": " and look for sensors.",
        "tokens": [
          51468,
          293,
          574,
          337,
          14840,
          13,
          51542
        ]
      },
      {
        "avg_logprob": -0.24168338545833726,
        "compression_ratio": 1.684065934065934,
        "end": 54.08,
        "id": 23,
        "no_speech_prob": 0.002216961933299899,
        "seek": 2872,
        "start": 52.28,
        "temperature": 0,
        "text": " So by the way, this is also useful",
        "tokens": [
          51542,
          407,
          538,
          264,
          636,
          11,
          341,
          307,
          611,
          4420,
          51632
        ]
      },
      {
        "avg_logprob": -0.24168338545833726,
        "compression_ratio": 1.684065934065934,
        "end": 56,
        "id": 24,
        "no_speech_prob": 0.002216961933299899,
        "seek": 2872,
        "start": 54.08,
        "temperature": 0,
        "text": " if I want to simulate the idea of I'm",
        "tokens": [
          51632,
          498,
          286,
          528,
          281,
          27817,
          264,
          1558,
          295,
          286,
          478,
          51728
        ]
      },
      {
        "avg_logprob": -0.24168338545833726,
        "compression_ratio": 1.684065934065934,
        "end": 58.480000000000004,
        "id": 25,
        "no_speech_prob": 0.002216961933299899,
        "seek": 2872,
        "start": 56,
        "temperature": 0,
        "text": " holding a mobile device that has an accelerometer",
        "tokens": [
          51728,
          5061,
          257,
          6013,
          4302,
          300,
          575,
          364,
          10172,
          13606,
          51852
        ]
      },
      {
        "avg_logprob": -0.22758908005234618,
        "compression_ratio": 1.8712871287128714,
        "end": 59.4,
        "id": 26,
        "no_speech_prob": 0.0002868453157134354,
        "seek": 5848,
        "start": 58.48,
        "temperature": 0,
        "text": " for moving it around.",
        "tokens": [
          50364,
          337,
          2684,
          309,
          926,
          13,
          50410
        ]
      },
      {
        "avg_logprob": -0.22758908005234618,
        "compression_ratio": 1.8712871287128714,
        "end": 60.72,
        "id": 27,
        "no_speech_prob": 0.0002868453157134354,
        "seek": 5848,
        "start": 59.4,
        "temperature": 0,
        "text": " But I'm going to click Sensors.",
        "tokens": [
          50410,
          583,
          286,
          478,
          516,
          281,
          2052,
          40926,
          830,
          13,
          50476
        ]
      },
      {
        "avg_logprob": -0.22758908005234618,
        "compression_ratio": 1.8712871287128714,
        "end": 64.42,
        "id": 28,
        "no_speech_prob": 0.0002868453157134354,
        "seek": 5848,
        "start": 60.72,
        "temperature": 0,
        "text": " And then what I want to look for is geolocation.",
        "tokens": [
          50476,
          400,
          550,
          437,
          286,
          528,
          281,
          574,
          337,
          307,
          1519,
          401,
          27943,
          13,
          50661
        ]
      },
      {
        "avg_logprob": -0.22758908005234618,
        "compression_ratio": 1.8712871287128714,
        "end": 66.96,
        "id": 29,
        "no_speech_prob": 0.0002868453157134354,
        "seek": 5848,
        "start": 64.42,
        "temperature": 0,
        "text": " So you can see there's a bunch of other things I could spoof.",
        "tokens": [
          50661,
          407,
          291,
          393,
          536,
          456,
          311,
          257,
          3840,
          295,
          661,
          721,
          286,
          727,
          637,
          29496,
          13,
          50788
        ]
      },
      {
        "avg_logprob": -0.22758908005234618,
        "compression_ratio": 1.8712871287128714,
        "end": 68.44,
        "id": 30,
        "no_speech_prob": 0.0002868453157134354,
        "seek": 5848,
        "start": 66.96,
        "temperature": 0,
        "text": " But here I want to do geolocation.",
        "tokens": [
          50788,
          583,
          510,
          286,
          528,
          281,
          360,
          1519,
          401,
          27943,
          13,
          50862
        ]
      },
      {
        "avg_logprob": -0.22758908005234618,
        "compression_ratio": 1.8712871287128714,
        "end": 71.2,
        "id": 31,
        "no_speech_prob": 0.0002868453157134354,
        "seek": 5848,
        "start": 68.44,
        "temperature": 0,
        "text": " And in an override, I could say, ah, I want to be in Berlin.",
        "tokens": [
          50862,
          400,
          294,
          364,
          42321,
          11,
          286,
          727,
          584,
          11,
          3716,
          11,
          286,
          528,
          281,
          312,
          294,
          13848,
          13,
          51000
        ]
      },
      {
        "avg_logprob": -0.22758908005234618,
        "compression_ratio": 1.8712871287128714,
        "end": 73.96,
        "id": 32,
        "no_speech_prob": 0.0002868453157134354,
        "seek": 5848,
        "start": 71.2,
        "temperature": 0,
        "text": " So if I put Berlin there and I hit Refresh,",
        "tokens": [
          51000,
          407,
          498,
          286,
          829,
          13848,
          456,
          293,
          286,
          2045,
          16957,
          3644,
          11,
          51138
        ]
      },
      {
        "avg_logprob": -0.22758908005234618,
        "compression_ratio": 1.8712871287128714,
        "end": 76.44,
        "id": 33,
        "no_speech_prob": 0.0002868453157134354,
        "seek": 5848,
        "start": 73.96,
        "temperature": 0,
        "text": " now you can see I have the weather in Berlin.",
        "tokens": [
          51138,
          586,
          291,
          393,
          536,
          286,
          362,
          264,
          5503,
          294,
          13848,
          13,
          51262
        ]
      },
      {
        "avg_logprob": -0.22758908005234618,
        "compression_ratio": 1.8712871287128714,
        "end": 78.96,
        "id": 34,
        "no_speech_prob": 0.0002868453157134354,
        "seek": 5848,
        "start": 76.44,
        "temperature": 0,
        "text": " So I'm going to use this maybe periodically",
        "tokens": [
          51262,
          407,
          286,
          478,
          516,
          281,
          764,
          341,
          1310,
          38916,
          51388
        ]
      },
      {
        "avg_logprob": -0.22758908005234618,
        "compression_ratio": 1.8712871287128714,
        "end": 82.96,
        "id": 35,
        "no_speech_prob": 0.0002868453157134354,
        "seek": 5848,
        "start": 78.96,
        "temperature": 0,
        "text": " and just check in in different locations all over the world",
        "tokens": [
          51388,
          293,
          445,
          1520,
          294,
          294,
          819,
          9253,
          439,
          670,
          264,
          1002,
          51588
        ]
      },
      {
        "avg_logprob": -0.22758908005234618,
        "compression_ratio": 1.8712871287128714,
        "end": 85,
        "id": 36,
        "no_speech_prob": 0.0002868453157134354,
        "seek": 5848,
        "start": 82.96,
        "temperature": 0,
        "text": " to save more interesting information to the database",
        "tokens": [
          51588,
          281,
          3155,
          544,
          1880,
          1589,
          281,
          264,
          8149,
          51690
        ]
      },
      {
        "avg_logprob": -0.22758908005234618,
        "compression_ratio": 1.8712871287128714,
        "end": 85.75999999999999,
        "id": 37,
        "no_speech_prob": 0.0002868453157134354,
        "seek": 5848,
        "start": 85,
        "temperature": 0,
        "text": " itself.",
        "tokens": [
          51690,
          2564,
          13,
          51728
        ]
      },
      {
        "avg_logprob": -0.22758908005234618,
        "compression_ratio": 1.8712871287128714,
        "end": 88.12,
        "id": 38,
        "no_speech_prob": 0.0002868453157134354,
        "seek": 5848,
        "start": 85.75999999999999,
        "temperature": 0,
        "text": " And now let me grab some actual weather information",
        "tokens": [
          51728,
          400,
          586,
          718,
          385,
          4444,
          512,
          3539,
          5503,
          1589,
          51846
        ]
      },
      {
        "avg_logprob": -0.23303627722042122,
        "compression_ratio": 1.6473214285714286,
        "end": 90.48,
        "id": 39,
        "no_speech_prob": 0.000014285466022556648,
        "seek": 8812,
        "start": 88.16000000000001,
        "temperature": 0,
        "text": " and display it here on the web page.",
        "tokens": [
          50366,
          293,
          4674,
          309,
          510,
          322,
          264,
          3670,
          3028,
          13,
          50482
        ]
      },
      {
        "avg_logprob": -0.23303627722042122,
        "compression_ratio": 1.6473214285714286,
        "end": 92.48,
        "id": 40,
        "no_speech_prob": 0.000014285466022556648,
        "seek": 8812,
        "start": 90.48,
        "temperature": 0,
        "text": " I'll create a paragraph element with some spans.",
        "tokens": [
          50482,
          286,
          603,
          1884,
          257,
          18865,
          4478,
          365,
          512,
          44086,
          13,
          50582
        ]
      },
      {
        "avg_logprob": -0.23303627722042122,
        "compression_ratio": 1.6473214285714286,
        "end": 97.92,
        "id": 41,
        "no_speech_prob": 0.000014285466022556648,
        "seek": 8812,
        "start": 96.48,
        "temperature": 0,
        "text": " So now I have a paragraph element",
        "tokens": [
          50782,
          407,
          586,
          286,
          362,
          257,
          18865,
          4478,
          50854
        ]
      },
      {
        "avg_logprob": -0.23303627722042122,
        "compression_ratio": 1.6473214285714286,
        "end": 100.88000000000001,
        "id": 42,
        "no_speech_prob": 0.000014285466022556648,
        "seek": 8812,
        "start": 97.92,
        "temperature": 0,
        "text": " that says the weather here is span ID summary",
        "tokens": [
          50854,
          300,
          1619,
          264,
          5503,
          510,
          307,
          16174,
          7348,
          12691,
          51002
        ]
      },
      {
        "avg_logprob": -0.23303627722042122,
        "compression_ratio": 1.6473214285714286,
        "end": 104.32000000000001,
        "id": 43,
        "no_speech_prob": 0.000014285466022556648,
        "seek": 8812,
        "start": 100.88000000000001,
        "temperature": 0,
        "text": " with a temperature of span ID temperature degrees Fahrenheit,",
        "tokens": [
          51002,
          365,
          257,
          4292,
          295,
          16174,
          7348,
          4292,
          5310,
          31199,
          11,
          51174
        ]
      },
      {
        "avg_logprob": -0.23303627722042122,
        "compression_ratio": 1.6473214285714286,
        "end": 107.24000000000001,
        "id": 44,
        "no_speech_prob": 0.000014285466022556648,
        "seek": 8812,
        "start": 104.32000000000001,
        "temperature": 0,
        "text": " which I'm pretty sure is the measurement that I'm getting",
        "tokens": [
          51174,
          597,
          286,
          478,
          1238,
          988,
          307,
          264,
          13160,
          300,
          286,
          478,
          1242,
          51320
        ]
      },
      {
        "avg_logprob": -0.23303627722042122,
        "compression_ratio": 1.6473214285714286,
        "end": 110.08000000000001,
        "id": 45,
        "no_speech_prob": 0.000014285466022556648,
        "seek": 8812,
        "start": 107.24000000000001,
        "temperature": 0,
        "text": " back from the Dark Sky API itself.",
        "tokens": [
          51320,
          646,
          490,
          264,
          9563,
          9879,
          9362,
          2564,
          13,
          51462
        ]
      },
      {
        "avg_logprob": -0.23303627722042122,
        "compression_ratio": 1.6473214285714286,
        "end": 113.76,
        "id": 46,
        "no_speech_prob": 0.000014285466022556648,
        "seek": 8812,
        "start": 110.08000000000001,
        "temperature": 0,
        "text": " So now I just want to go into my Sketch.js code.",
        "tokens": [
          51462,
          407,
          586,
          286,
          445,
          528,
          281,
          352,
          666,
          452,
          49245,
          13,
          25530,
          3089,
          13,
          51646
        ]
      },
      {
        "avg_logprob": -0.24560769756188552,
        "compression_ratio": 1.5091743119266054,
        "end": 117.16000000000001,
        "id": 47,
        "no_speech_prob": 0.00006014126483933069,
        "seek": 11376,
        "start": 113.76,
        "temperature": 0,
        "text": " Here is where I'm actually console logging",
        "tokens": [
          50364,
          1692,
          307,
          689,
          286,
          478,
          767,
          11076,
          27991,
          50534
        ]
      },
      {
        "avg_logprob": -0.24560769756188552,
        "compression_ratio": 1.5091743119266054,
        "end": 118.56,
        "id": 48,
        "no_speech_prob": 0.00006014126483933069,
        "seek": 11376,
        "start": 117.16000000000001,
        "temperature": 0,
        "text": " that information.",
        "tokens": [
          50534,
          300,
          1589,
          13,
          50604
        ]
      },
      {
        "avg_logprob": -0.24560769756188552,
        "compression_ratio": 1.5091743119266054,
        "end": 121.96000000000001,
        "id": 49,
        "no_speech_prob": 0.00006014126483933069,
        "seek": 11376,
        "start": 118.56,
        "temperature": 0,
        "text": " And if I look in the browser, I can see here",
        "tokens": [
          50604,
          400,
          498,
          286,
          574,
          294,
          264,
          11185,
          11,
          286,
          393,
          536,
          510,
          50774
        ]
      },
      {
        "avg_logprob": -0.24560769756188552,
        "compression_ratio": 1.5091743119266054,
        "end": 126.96000000000001,
        "id": 50,
        "no_speech_prob": 0.00006014126483933069,
        "seek": 11376,
        "start": 121.96000000000001,
        "temperature": 0,
        "text": " that all the data that I want is under currently,",
        "tokens": [
          50774,
          300,
          439,
          264,
          1412,
          300,
          286,
          528,
          307,
          833,
          4362,
          11,
          51024
        ]
      },
      {
        "avg_logprob": -0.24560769756188552,
        "compression_ratio": 1.5091743119266054,
        "end": 128.8,
        "id": 51,
        "no_speech_prob": 0.00006014126483933069,
        "seek": 11376,
        "start": 126.96000000000001,
        "temperature": 0,
        "text": " under temperature, and under summary.",
        "tokens": [
          51024,
          833,
          4292,
          11,
          293,
          833,
          12691,
          13,
          51116
        ]
      },
      {
        "avg_logprob": -0.24560769756188552,
        "compression_ratio": 1.5091743119266054,
        "end": 130.48000000000002,
        "id": 52,
        "no_speech_prob": 0.00006014126483933069,
        "seek": 11376,
        "start": 128.8,
        "temperature": 0,
        "text": " Perfect.",
        "tokens": [
          51116,
          10246,
          13,
          51200
        ]
      },
      {
        "avg_logprob": -0.24560769756188552,
        "compression_ratio": 1.5091743119266054,
        "end": 131.64000000000001,
        "id": 53,
        "no_speech_prob": 0.00006014126483933069,
        "seek": 11376,
        "start": 130.48000000000002,
        "temperature": 0,
        "text": " I planned this correctly.",
        "tokens": [
          51200,
          286,
          8589,
          341,
          8944,
          13,
          51258
        ]
      },
      {
        "avg_logprob": -0.24560769756188552,
        "compression_ratio": 1.5091743119266054,
        "end": 137.88,
        "id": 54,
        "no_speech_prob": 0.00006014126483933069,
        "seek": 11376,
        "start": 131.64000000000001,
        "temperature": 0,
        "text": " So now I should be able to say document.get element by ID",
        "tokens": [
          51258,
          407,
          586,
          286,
          820,
          312,
          1075,
          281,
          584,
          4166,
          13,
          847,
          4478,
          538,
          7348,
          51570
        ]
      },
      {
        "avg_logprob": -0.24560769756188552,
        "compression_ratio": 1.5091743119266054,
        "end": 143.20000000000002,
        "id": 55,
        "no_speech_prob": 0.00006014126483933069,
        "seek": 11376,
        "start": 137.88,
        "temperature": 0,
        "text": " summary equals JSON currently dot summary.",
        "tokens": [
          51570,
          12691,
          6915,
          31828,
          4362,
          5893,
          12691,
          13,
          51836
        ]
      },
      {
        "avg_logprob": -0.20304211399011446,
        "compression_ratio": 1.7037037037037037,
        "end": 144.56,
        "id": 56,
        "no_speech_prob": 0.00005920730109210126,
        "seek": 14320,
        "start": 143.2,
        "temperature": 0,
        "text": " So I just want to take that summary",
        "tokens": [
          50364,
          407,
          286,
          445,
          528,
          281,
          747,
          300,
          12691,
          50432
        ]
      },
      {
        "avg_logprob": -0.20304211399011446,
        "compression_ratio": 1.7037037037037037,
        "end": 148.04,
        "id": 57,
        "no_speech_prob": 0.00005920730109210126,
        "seek": 14320,
        "start": 144.56,
        "temperature": 0,
        "text": " and put it in the text content of that DOM element",
        "tokens": [
          50432,
          293,
          829,
          309,
          294,
          264,
          2487,
          2701,
          295,
          300,
          35727,
          4478,
          50606
        ]
      },
      {
        "avg_logprob": -0.20304211399011446,
        "compression_ratio": 1.7037037037037037,
        "end": 151.67999999999998,
        "id": 58,
        "no_speech_prob": 0.00005920730109210126,
        "seek": 14320,
        "start": 148.04,
        "temperature": 0,
        "text": " and then do the same thing for the temperature element.",
        "tokens": [
          50606,
          293,
          550,
          360,
          264,
          912,
          551,
          337,
          264,
          4292,
          4478,
          13,
          50788
        ]
      },
      {
        "avg_logprob": -0.20304211399011446,
        "compression_ratio": 1.7037037037037037,
        "end": 153.88,
        "id": 59,
        "no_speech_prob": 0.00005920730109210126,
        "seek": 14320,
        "start": 151.67999999999998,
        "temperature": 0,
        "text": " And this is temperature.",
        "tokens": [
          50788,
          400,
          341,
          307,
          4292,
          13,
          50898
        ]
      },
      {
        "avg_logprob": -0.20304211399011446,
        "compression_ratio": 1.7037037037037037,
        "end": 155.79999999999998,
        "id": 60,
        "no_speech_prob": 0.00005920730109210126,
        "seek": 14320,
        "start": 153.88,
        "temperature": 0,
        "text": " And there we go.",
        "tokens": [
          50898,
          400,
          456,
          321,
          352,
          13,
          50994
        ]
      },
      {
        "avg_logprob": -0.20304211399011446,
        "compression_ratio": 1.7037037037037037,
        "end": 158.16,
        "id": 61,
        "no_speech_prob": 0.00005920730109210126,
        "seek": 14320,
        "start": 155.79999999999998,
        "temperature": 0,
        "text": " So now if I hit refresh, we can see,",
        "tokens": [
          50994,
          407,
          586,
          498,
          286,
          2045,
          15134,
          11,
          321,
          393,
          536,
          11,
          51112
        ]
      },
      {
        "avg_logprob": -0.20304211399011446,
        "compression_ratio": 1.7037037037037037,
        "end": 160.39999999999998,
        "id": 62,
        "no_speech_prob": 0.00005920730109210126,
        "seek": 14320,
        "start": 158.16,
        "temperature": 0,
        "text": " aha, the weather here is mostly cloudy",
        "tokens": [
          51112,
          47340,
          11,
          264,
          5503,
          510,
          307,
          5240,
          33060,
          51224
        ]
      },
      {
        "avg_logprob": -0.20304211399011446,
        "compression_ratio": 1.7037037037037037,
        "end": 164.28,
        "id": 63,
        "no_speech_prob": 0.00005920730109210126,
        "seek": 14320,
        "start": 160.39999999999998,
        "temperature": 0,
        "text": " with a temperature of 62.91 degrees Fahrenheit.",
        "tokens": [
          51224,
          365,
          257,
          4292,
          295,
          24536,
          13,
          29925,
          5310,
          31199,
          13,
          51418
        ]
      },
      {
        "avg_logprob": -0.20304211399011446,
        "compression_ratio": 1.7037037037037037,
        "end": 166.72,
        "id": 64,
        "no_speech_prob": 0.00005920730109210126,
        "seek": 14320,
        "start": 164.28,
        "temperature": 0,
        "text": " I'm going to change this to the degree symbol.",
        "tokens": [
          51418,
          286,
          478,
          516,
          281,
          1319,
          341,
          281,
          264,
          4314,
          5986,
          13,
          51540
        ]
      },
      {
        "avg_logprob": -0.20304211399011446,
        "compression_ratio": 1.7037037037037037,
        "end": 170.2,
        "id": 65,
        "no_speech_prob": 0.00005920730109210126,
        "seek": 14320,
        "start": 166.72,
        "temperature": 0,
        "text": " And I'm going to capitalize Fahrenheit, hit refresh again.",
        "tokens": [
          51540,
          400,
          286,
          478,
          516,
          281,
          48114,
          31199,
          11,
          2045,
          15134,
          797,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.19728065544450787,
        "compression_ratio": 1.5876288659793814,
        "end": 174.76,
        "id": 66,
        "no_speech_prob": 0.000025071451091207564,
        "seek": 17020,
        "start": 170.2,
        "temperature": 0,
        "text": " And I can now also travel to Sao Paolo and hit refresh.",
        "tokens": [
          50364,
          400,
          286,
          393,
          586,
          611,
          3147,
          281,
          6299,
          78,
          3426,
          7902,
          293,
          2045,
          15134,
          13,
          50592
        ]
      },
      {
        "avg_logprob": -0.19728065544450787,
        "compression_ratio": 1.5876288659793814,
        "end": 177.39999999999998,
        "id": 67,
        "no_speech_prob": 0.000025071451091207564,
        "seek": 17020,
        "start": 174.76,
        "temperature": 0,
        "text": " And now the weather in Sao Paolo is",
        "tokens": [
          50592,
          400,
          586,
          264,
          5503,
          294,
          6299,
          78,
          3426,
          7902,
          307,
          50724
        ]
      },
      {
        "avg_logprob": -0.19728065544450787,
        "compression_ratio": 1.5876288659793814,
        "end": 181.32,
        "id": 68,
        "no_speech_prob": 0.000025071451091207564,
        "seek": 17020,
        "start": 177.39999999999998,
        "temperature": 0,
        "text": " partly cloudy with a temperature of 73.64 degrees Fahrenheit.",
        "tokens": [
          50724,
          17031,
          33060,
          365,
          257,
          4292,
          295,
          28387,
          13,
          19395,
          5310,
          31199,
          13,
          50920
        ]
      },
      {
        "avg_logprob": -0.19728065544450787,
        "compression_ratio": 1.5876288659793814,
        "end": 183.72,
        "id": 69,
        "no_speech_prob": 0.000025071451091207564,
        "seek": 17020,
        "start": 181.32,
        "temperature": 0,
        "text": " Let me also reorganize this into one paragraph.",
        "tokens": [
          50920,
          961,
          385,
          611,
          41203,
          1125,
          341,
          666,
          472,
          18865,
          13,
          51040
        ]
      },
      {
        "avg_logprob": -0.19728065544450787,
        "compression_ratio": 1.5876288659793814,
        "end": 185.51999999999998,
        "id": 70,
        "no_speech_prob": 0.000025071451091207564,
        "seek": 17020,
        "start": 183.72,
        "temperature": 0,
        "text": " That's, I think, what I meant to do.",
        "tokens": [
          51040,
          663,
          311,
          11,
          286,
          519,
          11,
          437,
          286,
          4140,
          281,
          360,
          13,
          51130
        ]
      },
      {
        "avg_logprob": -0.19728065544450787,
        "compression_ratio": 1.5876288659793814,
        "end": 187.39999999999998,
        "id": 71,
        "no_speech_prob": 0.000025071451091207564,
        "seek": 17020,
        "start": 185.51999999999998,
        "temperature": 0,
        "text": " All right, now I have that in one paragraph.",
        "tokens": [
          51130,
          1057,
          558,
          11,
          586,
          286,
          362,
          300,
          294,
          472,
          18865,
          13,
          51224
        ]
      },
      {
        "avg_logprob": -0.19728065544450787,
        "compression_ratio": 1.5876288659793814,
        "end": 189.32,
        "id": 72,
        "no_speech_prob": 0.000025071451091207564,
        "seek": 17020,
        "start": 187.39999999999998,
        "temperature": 0,
        "text": " I like the way that looks a little bit better.",
        "tokens": [
          51224,
          286,
          411,
          264,
          636,
          300,
          1542,
          257,
          707,
          857,
          1101,
          13,
          51320
        ]
      },
      {
        "avg_logprob": -0.19728065544450787,
        "compression_ratio": 1.5876288659793814,
        "end": 191,
        "id": 73,
        "no_speech_prob": 0.000025071451091207564,
        "seek": 17020,
        "start": 189.32,
        "temperature": 0,
        "text": " And also, I've misspelled Fahrenheit.",
        "tokens": [
          51320,
          400,
          611,
          11,
          286,
          600,
          1713,
          33000,
          31199,
          13,
          51404
        ]
      },
      {
        "avg_logprob": -0.19728065544450787,
        "compression_ratio": 1.5876288659793814,
        "end": 194.44,
        "id": 74,
        "no_speech_prob": 0.000025071451091207564,
        "seek": 17020,
        "start": 191,
        "temperature": 0,
        "text": " It should be F-A-H-R. So I should really fix that.",
        "tokens": [
          51404,
          467,
          820,
          312,
          479,
          12,
          32,
          12,
          39,
          12,
          49,
          13,
          407,
          286,
          820,
          534,
          3191,
          300,
          13,
          51576
        ]
      },
      {
        "avg_logprob": -0.19728065544450787,
        "compression_ratio": 1.5876288659793814,
        "end": 200.16,
        "id": 75,
        "no_speech_prob": 0.000025071451091207564,
        "seek": 17020,
        "start": 194.44,
        "temperature": 0,
        "text": " But I can also lazily just change it to F.",
        "tokens": [
          51576,
          583,
          286,
          393,
          611,
          19320,
          953,
          445,
          1319,
          309,
          281,
          479,
          13,
          51862
        ]
      },
      {
        "avg_logprob": -0.2419530815548367,
        "compression_ratio": 1.6748466257668713,
        "end": 201.32,
        "id": 76,
        "no_speech_prob": 0.00010554563050391153,
        "seek": 20016,
        "start": 200.16,
        "temperature": 0,
        "text": " There we go.",
        "tokens": [
          50364,
          821,
          321,
          352,
          13,
          50422
        ]
      },
      {
        "avg_logprob": -0.2419530815548367,
        "compression_ratio": 1.6748466257668713,
        "end": 202.64,
        "id": 77,
        "no_speech_prob": 0.00010554563050391153,
        "seek": 20016,
        "start": 201.32,
        "temperature": 0,
        "text": " I could be satisfied with this.",
        "tokens": [
          50422,
          286,
          727,
          312,
          11239,
          365,
          341,
          13,
          50488
        ]
      },
      {
        "avg_logprob": -0.2419530815548367,
        "compression_ratio": 1.6748466257668713,
        "end": 204.64,
        "id": 78,
        "no_speech_prob": 0.00010554563050391153,
        "seek": 20016,
        "start": 202.64,
        "temperature": 0,
        "text": " And I'm quite happy with this.",
        "tokens": [
          50488,
          400,
          286,
          478,
          1596,
          2055,
          365,
          341,
          13,
          50588
        ]
      },
      {
        "avg_logprob": -0.2419530815548367,
        "compression_ratio": 1.6748466257668713,
        "end": 206.16,
        "id": 79,
        "no_speech_prob": 0.00010554563050391153,
        "seek": 20016,
        "start": 204.64,
        "temperature": 0,
        "text": " But I want to demonstrate to you what",
        "tokens": [
          50588,
          583,
          286,
          528,
          281,
          11698,
          281,
          291,
          437,
          50664
        ]
      },
      {
        "avg_logprob": -0.2419530815548367,
        "compression_ratio": 1.6748466257668713,
        "end": 208.51999999999998,
        "id": 80,
        "no_speech_prob": 0.00010554563050391153,
        "seek": 20016,
        "start": 206.16,
        "temperature": 0,
        "text": " does it mean to work with multiple APIs",
        "tokens": [
          50664,
          775,
          309,
          914,
          281,
          589,
          365,
          3866,
          21445,
          50782
        ]
      },
      {
        "avg_logprob": -0.2419530815548367,
        "compression_ratio": 1.6748466257668713,
        "end": 210.04,
        "id": 81,
        "no_speech_prob": 0.00010554563050391153,
        "seek": 20016,
        "start": 208.51999999999998,
        "temperature": 0,
        "text": " within one application.",
        "tokens": [
          50782,
          1951,
          472,
          3861,
          13,
          50858
        ]
      },
      {
        "avg_logprob": -0.2419530815548367,
        "compression_ratio": 1.6748466257668713,
        "end": 212.04,
        "id": 82,
        "no_speech_prob": 0.00010554563050391153,
        "seek": 20016,
        "start": 210.04,
        "temperature": 0,
        "text": " So I think it's useful as an exercise",
        "tokens": [
          50858,
          407,
          286,
          519,
          309,
          311,
          4420,
          382,
          364,
          5380,
          50958
        ]
      },
      {
        "avg_logprob": -0.2419530815548367,
        "compression_ratio": 1.6748466257668713,
        "end": 215.2,
        "id": 83,
        "no_speech_prob": 0.00010554563050391153,
        "seek": 20016,
        "start": 212.04,
        "temperature": 0,
        "text": " to go and try to connect to yet another API",
        "tokens": [
          50958,
          281,
          352,
          293,
          853,
          281,
          1745,
          281,
          1939,
          1071,
          9362,
          51116
        ]
      },
      {
        "avg_logprob": -0.2419530815548367,
        "compression_ratio": 1.6748466257668713,
        "end": 219.07999999999998,
        "id": 84,
        "no_speech_prob": 0.00010554563050391153,
        "seek": 20016,
        "start": 215.2,
        "temperature": 0,
        "text": " and get more information to add more context to this web page.",
        "tokens": [
          51116,
          293,
          483,
          544,
          1589,
          281,
          909,
          544,
          4319,
          281,
          341,
          3670,
          3028,
          13,
          51310
        ]
      },
      {
        "avg_logprob": -0.2419530815548367,
        "compression_ratio": 1.6748466257668713,
        "end": 221.6,
        "id": 85,
        "no_speech_prob": 0.00010554563050391153,
        "seek": 20016,
        "start": 219.07999999999998,
        "temperature": 0,
        "text": " OpenAQ is an open data, open source project",
        "tokens": [
          51310,
          7238,
          32,
          48,
          307,
          364,
          1269,
          1412,
          11,
          1269,
          4009,
          1716,
          51436
        ]
      },
      {
        "avg_logprob": -0.2419530815548367,
        "compression_ratio": 1.6748466257668713,
        "end": 224.44,
        "id": 86,
        "no_speech_prob": 0.00010554563050391153,
        "seek": 20016,
        "start": 221.6,
        "temperature": 0,
        "text": " that aggregates a lot of different air quality readings",
        "tokens": [
          51436,
          300,
          16743,
          1024,
          257,
          688,
          295,
          819,
          1988,
          3125,
          27319,
          51578
        ]
      },
      {
        "avg_logprob": -0.2419530815548367,
        "compression_ratio": 1.6748466257668713,
        "end": 225.8,
        "id": 87,
        "no_speech_prob": 0.00010554563050391153,
        "seek": 20016,
        "start": 224.44,
        "temperature": 0,
        "text": " from many different sources.",
        "tokens": [
          51578,
          490,
          867,
          819,
          7139,
          13,
          51646
        ]
      },
      {
        "avg_logprob": -0.2419530815548367,
        "compression_ratio": 1.6748466257668713,
        "end": 227.35999999999999,
        "id": 88,
        "no_speech_prob": 0.00010554563050391153,
        "seek": 20016,
        "start": 225.8,
        "temperature": 0,
        "text": " And you can read about their data sources,",
        "tokens": [
          51646,
          400,
          291,
          393,
          1401,
          466,
          641,
          1412,
          7139,
          11,
          51724
        ]
      },
      {
        "avg_logprob": -0.2419530815548367,
        "compression_ratio": 1.6748466257668713,
        "end": 229.48,
        "id": 89,
        "no_speech_prob": 0.00010554563050391153,
        "seek": 20016,
        "start": 227.35999999999999,
        "temperature": 0,
        "text": " which include government and other kind of research",
        "tokens": [
          51724,
          597,
          4090,
          2463,
          293,
          661,
          733,
          295,
          2132,
          51830
        ]
      },
      {
        "avg_logprob": -0.250522222675261,
        "compression_ratio": 1.735632183908046,
        "end": 230.39999999999998,
        "id": 90,
        "no_speech_prob": 0.0011335491435602307,
        "seek": 22948,
        "start": 229.51999999999998,
        "temperature": 0,
        "text": " institutions.",
        "tokens": [
          50366,
          8142,
          13,
          50410
        ]
      },
      {
        "avg_logprob": -0.250522222675261,
        "compression_ratio": 1.735632183908046,
        "end": 231.92,
        "id": 91,
        "no_speech_prob": 0.0011335491435602307,
        "seek": 22948,
        "start": 230.39999999999998,
        "temperature": 0,
        "text": " And it's important to read the disclaimer",
        "tokens": [
          50410,
          400,
          309,
          311,
          1021,
          281,
          1401,
          264,
          40896,
          50486
        ]
      },
      {
        "avg_logprob": -0.250522222675261,
        "compression_ratio": 1.735632183908046,
        "end": 234.07999999999998,
        "id": 92,
        "no_speech_prob": 0.0011335491435602307,
        "seek": 22948,
        "start": 231.92,
        "temperature": 0,
        "text": " and look at the licensing information about how",
        "tokens": [
          50486,
          293,
          574,
          412,
          264,
          29759,
          1589,
          466,
          577,
          50594
        ]
      },
      {
        "avg_logprob": -0.250522222675261,
        "compression_ratio": 1.735632183908046,
        "end": 236.2,
        "id": 93,
        "no_speech_prob": 0.0011335491435602307,
        "seek": 22948,
        "start": 234.07999999999998,
        "temperature": 0,
        "text": " the data is collected and where it comes from.",
        "tokens": [
          50594,
          264,
          1412,
          307,
          11087,
          293,
          689,
          309,
          1487,
          490,
          13,
          50700
        ]
      },
      {
        "avg_logprob": -0.250522222675261,
        "compression_ratio": 1.735632183908046,
        "end": 239.6,
        "id": 94,
        "no_speech_prob": 0.0011335491435602307,
        "seek": 22948,
        "start": 236.2,
        "temperature": 0,
        "text": " OpenAQ has an API with a variety of different endpoints",
        "tokens": [
          50700,
          7238,
          32,
          48,
          575,
          364,
          9362,
          365,
          257,
          5673,
          295,
          819,
          917,
          20552,
          50870
        ]
      },
      {
        "avg_logprob": -0.250522222675261,
        "compression_ratio": 1.735632183908046,
        "end": 242.95999999999998,
        "id": 95,
        "no_speech_prob": 0.0011335491435602307,
        "seek": 22948,
        "start": 239.6,
        "temperature": 0,
        "text": " for you to request that air quality information.",
        "tokens": [
          50870,
          337,
          291,
          281,
          5308,
          300,
          1988,
          3125,
          1589,
          13,
          51038
        ]
      },
      {
        "avg_logprob": -0.250522222675261,
        "compression_ratio": 1.735632183908046,
        "end": 245.79999999999998,
        "id": 96,
        "no_speech_prob": 0.0011335491435602307,
        "seek": 22948,
        "start": 242.95999999999998,
        "temperature": 0,
        "text": " And the endpoint that I want to look at is the latest endpoint,",
        "tokens": [
          51038,
          400,
          264,
          35795,
          300,
          286,
          528,
          281,
          574,
          412,
          307,
          264,
          6792,
          35795,
          11,
          51180
        ]
      },
      {
        "avg_logprob": -0.250522222675261,
        "compression_ratio": 1.735632183908046,
        "end": 248.16,
        "id": 97,
        "no_speech_prob": 0.0011335491435602307,
        "seek": 22948,
        "start": 245.79999999999998,
        "temperature": 0,
        "text": " which I can pass a latitude and longitude",
        "tokens": [
          51180,
          597,
          286,
          393,
          1320,
          257,
          45436,
          293,
          938,
          4377,
          51298
        ]
      },
      {
        "avg_logprob": -0.250522222675261,
        "compression_ratio": 1.735632183908046,
        "end": 250.35999999999999,
        "id": 98,
        "no_speech_prob": 0.0011335491435602307,
        "seek": 22948,
        "start": 248.16,
        "temperature": 0,
        "text": " as a coordinates parameter.",
        "tokens": [
          51298,
          382,
          257,
          21056,
          13075,
          13,
          51408
        ]
      },
      {
        "avg_logprob": -0.250522222675261,
        "compression_ratio": 1.735632183908046,
        "end": 253.64,
        "id": 99,
        "no_speech_prob": 0.0011335491435602307,
        "seek": 22948,
        "start": 250.35999999999999,
        "temperature": 0,
        "text": " And this is the endpoint, api.openaq.org",
        "tokens": [
          51408,
          400,
          341,
          307,
          264,
          35795,
          11,
          1882,
          72,
          13,
          15752,
          64,
          80,
          13,
          4646,
          51572
        ]
      },
      {
        "avg_logprob": -0.250522222675261,
        "compression_ratio": 1.735632183908046,
        "end": 255.79999999999998,
        "id": 100,
        "no_speech_prob": 0.0011335491435602307,
        "seek": 22948,
        "start": 253.64,
        "temperature": 0,
        "text": " slash v1 slash latest.",
        "tokens": [
          51572,
          17330,
          371,
          16,
          17330,
          6792,
          13,
          51680
        ]
      },
      {
        "avg_logprob": -0.22630899747212727,
        "compression_ratio": 1.751937984496124,
        "end": 260.48,
        "id": 101,
        "no_speech_prob": 0.000041986269934568554,
        "seek": 25580,
        "start": 255.8,
        "temperature": 0,
        "text": " So let's just try copying and pasting that into our browser.",
        "tokens": [
          50364,
          407,
          718,
          311,
          445,
          853,
          27976,
          293,
          1791,
          278,
          300,
          666,
          527,
          11185,
          13,
          50598
        ]
      },
      {
        "avg_logprob": -0.22630899747212727,
        "compression_ratio": 1.751937984496124,
        "end": 263.40000000000003,
        "id": 102,
        "no_speech_prob": 0.000041986269934568554,
        "seek": 25580,
        "start": 260.48,
        "temperature": 0,
        "text": " So we can see it's actually giving us a lot of information.",
        "tokens": [
          50598,
          407,
          321,
          393,
          536,
          309,
          311,
          767,
          2902,
          505,
          257,
          688,
          295,
          1589,
          13,
          50744
        ]
      },
      {
        "avg_logprob": -0.22630899747212727,
        "compression_ratio": 1.751937984496124,
        "end": 266.12,
        "id": 103,
        "no_speech_prob": 0.000041986269934568554,
        "seek": 25580,
        "start": 263.40000000000003,
        "temperature": 0,
        "text": " So I don't want just all the entire database",
        "tokens": [
          50744,
          407,
          286,
          500,
          380,
          528,
          445,
          439,
          264,
          2302,
          8149,
          50880
        ]
      },
      {
        "avg_logprob": -0.22630899747212727,
        "compression_ratio": 1.751937984496124,
        "end": 267.24,
        "id": 104,
        "no_speech_prob": 0.000041986269934568554,
        "seek": 25580,
        "start": 266.12,
        "temperature": 0,
        "text": " of air quality information.",
        "tokens": [
          50880,
          295,
          1988,
          3125,
          1589,
          13,
          50936
        ]
      },
      {
        "avg_logprob": -0.22630899747212727,
        "compression_ratio": 1.751937984496124,
        "end": 269.04,
        "id": 105,
        "no_speech_prob": 0.000041986269934568554,
        "seek": 25580,
        "start": 267.24,
        "temperature": 0,
        "text": " This is a ton of information that comes in.",
        "tokens": [
          50936,
          639,
          307,
          257,
          2952,
          295,
          1589,
          300,
          1487,
          294,
          13,
          51026
        ]
      },
      {
        "avg_logprob": -0.22630899747212727,
        "compression_ratio": 1.751937984496124,
        "end": 271.84000000000003,
        "id": 106,
        "no_speech_prob": 0.000041986269934568554,
        "seek": 25580,
        "start": 269.04,
        "temperature": 0,
        "text": " I want it for a specific latitude and longitude.",
        "tokens": [
          51026,
          286,
          528,
          309,
          337,
          257,
          2685,
          45436,
          293,
          938,
          4377,
          13,
          51166
        ]
      },
      {
        "avg_logprob": -0.22630899747212727,
        "compression_ratio": 1.751937984496124,
        "end": 274.48,
        "id": 107,
        "no_speech_prob": 0.000041986269934568554,
        "seek": 25580,
        "start": 271.84000000000003,
        "temperature": 0,
        "text": " So it looks like, if I go back to the documentation,",
        "tokens": [
          51166,
          407,
          309,
          1542,
          411,
          11,
          498,
          286,
          352,
          646,
          281,
          264,
          14333,
          11,
          51298
        ]
      },
      {
        "avg_logprob": -0.22630899747212727,
        "compression_ratio": 1.751937984496124,
        "end": 277.52,
        "id": 108,
        "no_speech_prob": 0.000041986269934568554,
        "seek": 25580,
        "start": 274.48,
        "temperature": 0,
        "text": " that right here under coordinates,",
        "tokens": [
          51298,
          300,
          558,
          510,
          833,
          21056,
          11,
          51450
        ]
      },
      {
        "avg_logprob": -0.22630899747212727,
        "compression_ratio": 1.751937984496124,
        "end": 281.40000000000003,
        "id": 109,
        "no_speech_prob": 0.000041986269934568554,
        "seek": 25580,
        "start": 277.52,
        "temperature": 0,
        "text": " I can give it a property coordinates",
        "tokens": [
          51450,
          286,
          393,
          976,
          309,
          257,
          4707,
          21056,
          51644
        ]
      },
      {
        "avg_logprob": -0.22630899747212727,
        "compression_ratio": 1.751937984496124,
        "end": 284.52,
        "id": 110,
        "no_speech_prob": 0.000041986269934568554,
        "seek": 25580,
        "start": 281.40000000000003,
        "temperature": 0,
        "text": " equals the latitude comma the longitude.",
        "tokens": [
          51644,
          6915,
          264,
          45436,
          22117,
          264,
          938,
          4377,
          13,
          51800
        ]
      },
      {
        "avg_logprob": -0.2285342046192714,
        "compression_ratio": 1.47265625,
        "end": 287.4,
        "id": 111,
        "no_speech_prob": 0.00010391027171863243,
        "seek": 28452,
        "start": 284.52,
        "temperature": 0,
        "text": " So this should work by doing the following.",
        "tokens": [
          50364,
          407,
          341,
          820,
          589,
          538,
          884,
          264,
          3480,
          13,
          50508
        ]
      },
      {
        "avg_logprob": -0.2285342046192714,
        "compression_ratio": 1.47265625,
        "end": 292.12,
        "id": 112,
        "no_speech_prob": 0.00010391027171863243,
        "seek": 28452,
        "start": 287.4,
        "temperature": 0,
        "text": " So I can go over to this URL and type in what's",
        "tokens": [
          50508,
          407,
          286,
          393,
          352,
          670,
          281,
          341,
          12905,
          293,
          2010,
          294,
          437,
          311,
          50744
        ]
      },
      {
        "avg_logprob": -0.2285342046192714,
        "compression_ratio": 1.47265625,
        "end": 294,
        "id": 113,
        "no_speech_prob": 0.00010391027171863243,
        "seek": 28452,
        "start": 292.12,
        "temperature": 0,
        "text": " known as a URL query string.",
        "tokens": [
          50744,
          2570,
          382,
          257,
          12905,
          14581,
          6798,
          13,
          50838
        ]
      },
      {
        "avg_logprob": -0.2285342046192714,
        "compression_ratio": 1.47265625,
        "end": 296.88,
        "id": 114,
        "no_speech_prob": 0.00010391027171863243,
        "seek": 28452,
        "start": 294,
        "temperature": 0,
        "text": " Question mark, coordinates equals.",
        "tokens": [
          50838,
          14464,
          1491,
          11,
          21056,
          6915,
          13,
          50982
        ]
      },
      {
        "avg_logprob": -0.2285342046192714,
        "compression_ratio": 1.47265625,
        "end": 299.44,
        "id": 115,
        "no_speech_prob": 0.00010391027171863243,
        "seek": 28452,
        "start": 296.88,
        "temperature": 0,
        "text": " Now I need to give it some latitude and longitude.",
        "tokens": [
          50982,
          823,
          286,
          643,
          281,
          976,
          309,
          512,
          45436,
          293,
          938,
          4377,
          13,
          51110
        ]
      },
      {
        "avg_logprob": -0.2285342046192714,
        "compression_ratio": 1.47265625,
        "end": 305.88,
        "id": 116,
        "no_speech_prob": 0.00010391027171863243,
        "seek": 28452,
        "start": 299.44,
        "temperature": 0,
        "text": " I am at 40.73 comma negative 73.99.",
        "tokens": [
          51110,
          286,
          669,
          412,
          3356,
          13,
          33396,
          22117,
          3671,
          28387,
          13,
          8494,
          13,
          51432
        ]
      },
      {
        "avg_logprob": -0.2285342046192714,
        "compression_ratio": 1.47265625,
        "end": 307.35999999999996,
        "id": 117,
        "no_speech_prob": 0.00010391027171863243,
        "seek": 28452,
        "start": 305.88,
        "temperature": 0,
        "text": " So I can put that in.",
        "tokens": [
          51432,
          407,
          286,
          393,
          829,
          300,
          294,
          13,
          51506
        ]
      },
      {
        "avg_logprob": -0.2285342046192714,
        "compression_ratio": 1.47265625,
        "end": 307.84,
        "id": 118,
        "no_speech_prob": 0.00010391027171863243,
        "seek": 28452,
        "start": 307.35999999999996,
        "temperature": 0,
        "text": " All right.",
        "tokens": [
          51506,
          1057,
          558,
          13,
          51530
        ]
      },
      {
        "avg_logprob": -0.2285342046192714,
        "compression_ratio": 1.47265625,
        "end": 310.64,
        "id": 119,
        "no_speech_prob": 0.00010391027171863243,
        "seek": 28452,
        "start": 307.84,
        "temperature": 0,
        "text": " Ah, so it looks like I'm getting an air quality measurement",
        "tokens": [
          51530,
          2438,
          11,
          370,
          309,
          1542,
          411,
          286,
          478,
          1242,
          364,
          1988,
          3125,
          13160,
          51670
        ]
      },
      {
        "avg_logprob": -0.2285342046192714,
        "compression_ratio": 1.47265625,
        "end": 313.28,
        "id": 120,
        "no_speech_prob": 0.00010391027171863243,
        "seek": 28452,
        "start": 310.64,
        "temperature": 0,
        "text": " from a location at Division Street, which",
        "tokens": [
          51670,
          490,
          257,
          4914,
          412,
          17183,
          7638,
          11,
          597,
          51802
        ]
      },
      {
        "avg_logprob": -0.24018732706705728,
        "compression_ratio": 1.7964912280701755,
        "end": 316.59999999999997,
        "id": 121,
        "no_speech_prob": 0.00004757637361763045,
        "seek": 31328,
        "start": 313.32,
        "temperature": 0,
        "text": " is this distance, probably in meters for me.",
        "tokens": [
          50366,
          307,
          341,
          4560,
          11,
          1391,
          294,
          8146,
          337,
          385,
          13,
          50530
        ]
      },
      {
        "avg_logprob": -0.24018732706705728,
        "compression_ratio": 1.7964912280701755,
        "end": 319.52,
        "id": 122,
        "no_speech_prob": 0.00004757637361763045,
        "seek": 31328,
        "start": 316.59999999999997,
        "temperature": 0,
        "text": " And this is the particulates probably in the air,",
        "tokens": [
          50530,
          400,
          341,
          307,
          264,
          21861,
          1024,
          1391,
          294,
          264,
          1988,
          11,
          50676
        ]
      },
      {
        "avg_logprob": -0.24018732706705728,
        "compression_ratio": 1.7964912280701755,
        "end": 321.84,
        "id": 123,
        "no_speech_prob": 0.00004757637361763045,
        "seek": 31328,
        "start": 319.52,
        "temperature": 0,
        "text": " the micrograms per meters cubed.",
        "tokens": [
          50676,
          264,
          4532,
          1342,
          82,
          680,
          8146,
          36510,
          13,
          50792
        ]
      },
      {
        "avg_logprob": -0.24018732706705728,
        "compression_ratio": 1.7964912280701755,
        "end": 324.26,
        "id": 124,
        "no_speech_prob": 0.00004757637361763045,
        "seek": 31328,
        "start": 321.84,
        "temperature": 0,
        "text": " And obviously, I want to read through the documentation",
        "tokens": [
          50792,
          400,
          2745,
          11,
          286,
          528,
          281,
          1401,
          807,
          264,
          14333,
          50913
        ]
      },
      {
        "avg_logprob": -0.24018732706705728,
        "compression_ratio": 1.7964912280701755,
        "end": 326.84,
        "id": 125,
        "no_speech_prob": 0.00004757637361763045,
        "seek": 31328,
        "start": 324.26,
        "temperature": 0,
        "text": " to be a bit more clear about what these measurements exactly",
        "tokens": [
          50913,
          281,
          312,
          257,
          857,
          544,
          1850,
          466,
          437,
          613,
          15383,
          2293,
          51042
        ]
      },
      {
        "avg_logprob": -0.24018732706705728,
        "compression_ratio": 1.7964912280701755,
        "end": 326.96,
        "id": 126,
        "no_speech_prob": 0.00004757637361763045,
        "seek": 31328,
        "start": 326.84,
        "temperature": 0,
        "text": " are.",
        "tokens": [
          51042,
          366,
          13,
          51048
        ]
      },
      {
        "avg_logprob": -0.24018732706705728,
        "compression_ratio": 1.7964912280701755,
        "end": 329.32,
        "id": 127,
        "no_speech_prob": 0.00004757637361763045,
        "seek": 31328,
        "start": 326.96,
        "temperature": 0,
        "text": " And I'll try to do that before I put in any information",
        "tokens": [
          51048,
          400,
          286,
          603,
          853,
          281,
          360,
          300,
          949,
          286,
          829,
          294,
          604,
          1589,
          51166
        ]
      },
      {
        "avg_logprob": -0.24018732706705728,
        "compression_ratio": 1.7964912280701755,
        "end": 330.55999999999995,
        "id": 128,
        "no_speech_prob": 0.00004757637361763045,
        "seek": 31328,
        "start": 329.32,
        "temperature": 0,
        "text": " on the web page itself.",
        "tokens": [
          51166,
          322,
          264,
          3670,
          3028,
          2564,
          13,
          51228
        ]
      },
      {
        "avg_logprob": -0.24018732706705728,
        "compression_ratio": 1.7964912280701755,
        "end": 333.28,
        "id": 129,
        "no_speech_prob": 0.00004757637361763045,
        "seek": 31328,
        "start": 330.55999999999995,
        "temperature": 0,
        "text": " If I wanted to, I could also limit, say,",
        "tokens": [
          51228,
          759,
          286,
          1415,
          281,
          11,
          286,
          727,
          611,
          4948,
          11,
          584,
          11,
          51364
        ]
      },
      {
        "avg_logprob": -0.24018732706705728,
        "compression_ratio": 1.7964912280701755,
        "end": 335.2,
        "id": 130,
        "no_speech_prob": 0.00004757637361763045,
        "seek": 31328,
        "start": 333.28,
        "temperature": 0,
        "text": " like limit only to get measurements",
        "tokens": [
          51364,
          411,
          4948,
          787,
          281,
          483,
          15383,
          51460
        ]
      },
      {
        "avg_logprob": -0.24018732706705728,
        "compression_ratio": 1.7964912280701755,
        "end": 338.32,
        "id": 131,
        "no_speech_prob": 0.00004757637361763045,
        "seek": 31328,
        "start": 335.2,
        "temperature": 0,
        "text": " within a certain area, within a certain radius by meters.",
        "tokens": [
          51460,
          1951,
          257,
          1629,
          1859,
          11,
          1951,
          257,
          1629,
          15845,
          538,
          8146,
          13,
          51616
        ]
      },
      {
        "avg_logprob": -0.24018732706705728,
        "compression_ratio": 1.7964912280701755,
        "end": 340.4,
        "id": 132,
        "no_speech_prob": 0.00004757637361763045,
        "seek": 31328,
        "start": 338.32,
        "temperature": 0,
        "text": " And you can see there are a bunch of other ways",
        "tokens": [
          51616,
          400,
          291,
          393,
          536,
          456,
          366,
          257,
          3840,
          295,
          661,
          2098,
          51720
        ]
      },
      {
        "avg_logprob": -0.23073657109187198,
        "compression_ratio": 1.701818181818182,
        "end": 344.32,
        "id": 133,
        "no_speech_prob": 0.00015356161748059094,
        "seek": 34040,
        "start": 340.4,
        "temperature": 0,
        "text": " that I can sort or limit the number of data points",
        "tokens": [
          50364,
          300,
          286,
          393,
          1333,
          420,
          4948,
          264,
          1230,
          295,
          1412,
          2793,
          50560
        ]
      },
      {
        "avg_logprob": -0.23073657109187198,
        "compression_ratio": 1.701818181818182,
        "end": 345.44,
        "id": 134,
        "no_speech_prob": 0.00015356161748059094,
        "seek": 34040,
        "start": 344.32,
        "temperature": 0,
        "text": " that I get back.",
        "tokens": [
          50560,
          300,
          286,
          483,
          646,
          13,
          50616
        ]
      },
      {
        "avg_logprob": -0.23073657109187198,
        "compression_ratio": 1.701818181818182,
        "end": 348.28,
        "id": 135,
        "no_speech_prob": 0.00015356161748059094,
        "seek": 34040,
        "start": 345.44,
        "temperature": 0,
        "text": " You might also notice here that this is not an API key here.",
        "tokens": [
          50616,
          509,
          1062,
          611,
          3449,
          510,
          300,
          341,
          307,
          406,
          364,
          9362,
          2141,
          510,
          13,
          50758
        ]
      },
      {
        "avg_logprob": -0.23073657109187198,
        "compression_ratio": 1.701818181818182,
        "end": 349.84,
        "id": 136,
        "no_speech_prob": 0.00015356161748059094,
        "seek": 34040,
        "start": 348.28,
        "temperature": 0,
        "text": " I didn't have to authenticate, log in.",
        "tokens": [
          50758,
          286,
          994,
          380,
          362,
          281,
          9214,
          8700,
          11,
          3565,
          294,
          13,
          50836
        ]
      },
      {
        "avg_logprob": -0.23073657109187198,
        "compression_ratio": 1.701818181818182,
        "end": 351.56,
        "id": 137,
        "no_speech_prob": 0.00015356161748059094,
        "seek": 34040,
        "start": 349.84,
        "temperature": 0,
        "text": " I don't have any secret key.",
        "tokens": [
          50836,
          286,
          500,
          380,
          362,
          604,
          4054,
          2141,
          13,
          50922
        ]
      },
      {
        "avg_logprob": -0.23073657109187198,
        "compression_ratio": 1.701818181818182,
        "end": 355.23999999999995,
        "id": 138,
        "no_speech_prob": 0.00015356161748059094,
        "seek": 34040,
        "start": 351.56,
        "temperature": 0,
        "text": " And so in essence, I could just make a fetch request,",
        "tokens": [
          50922,
          400,
          370,
          294,
          12801,
          11,
          286,
          727,
          445,
          652,
          257,
          23673,
          5308,
          11,
          51106
        ]
      },
      {
        "avg_logprob": -0.23073657109187198,
        "compression_ratio": 1.701818181818182,
        "end": 358.35999999999996,
        "id": 139,
        "no_speech_prob": 0.00015356161748059094,
        "seek": 34040,
        "start": 355.23999999999995,
        "temperature": 0,
        "text": " a get request to this endpoint right from the client side",
        "tokens": [
          51106,
          257,
          483,
          5308,
          281,
          341,
          35795,
          558,
          490,
          264,
          6423,
          1252,
          51262
        ]
      },
      {
        "avg_logprob": -0.23073657109187198,
        "compression_ratio": 1.701818181818182,
        "end": 359.15999999999997,
        "id": 140,
        "no_speech_prob": 0.00015356161748059094,
        "seek": 34040,
        "start": 358.35999999999996,
        "temperature": 0,
        "text": " code itself.",
        "tokens": [
          51262,
          3089,
          2564,
          13,
          51302
        ]
      },
      {
        "avg_logprob": -0.23073657109187198,
        "compression_ratio": 1.701818181818182,
        "end": 362.03999999999996,
        "id": 141,
        "no_speech_prob": 0.00015356161748059094,
        "seek": 34040,
        "start": 359.15999999999997,
        "temperature": 0,
        "text": " But since I'm already requesting the weather information",
        "tokens": [
          51302,
          583,
          1670,
          286,
          478,
          1217,
          31937,
          264,
          5503,
          1589,
          51446
        ]
      },
      {
        "avg_logprob": -0.23073657109187198,
        "compression_ratio": 1.701818181818182,
        "end": 364.47999999999996,
        "id": 142,
        "no_speech_prob": 0.00015356161748059094,
        "seek": 34040,
        "start": 362.03999999999996,
        "temperature": 0,
        "text": " from Dark Sky from the server, let's also",
        "tokens": [
          51446,
          490,
          9563,
          9879,
          490,
          264,
          7154,
          11,
          718,
          311,
          611,
          51568
        ]
      },
      {
        "avg_logprob": -0.23073657109187198,
        "compression_ratio": 1.701818181818182,
        "end": 367.64,
        "id": 143,
        "no_speech_prob": 0.00015356161748059094,
        "seek": 34040,
        "start": 364.47999999999996,
        "temperature": 0,
        "text": " make a request to here from the server as well.",
        "tokens": [
          51568,
          652,
          257,
          5308,
          281,
          510,
          490,
          264,
          7154,
          382,
          731,
          13,
          51726
        ]
      },
      {
        "avg_logprob": -0.19180644000018085,
        "compression_ratio": 1.521505376344086,
        "end": 370.47999999999996,
        "id": 144,
        "no_speech_prob": 0.000006854309958725935,
        "seek": 36764,
        "start": 367.64,
        "temperature": 0,
        "text": " Let's grab this URL.",
        "tokens": [
          50364,
          961,
          311,
          4444,
          341,
          12905,
          13,
          50506
        ]
      },
      {
        "avg_logprob": -0.19180644000018085,
        "compression_ratio": 1.521505376344086,
        "end": 372.47999999999996,
        "id": 145,
        "no_speech_prob": 0.000006854309958725935,
        "seek": 36764,
        "start": 370.47999999999996,
        "temperature": 0,
        "text": " I'm going to go to the server code.",
        "tokens": [
          50506,
          286,
          478,
          516,
          281,
          352,
          281,
          264,
          7154,
          3089,
          13,
          50606
        ]
      },
      {
        "avg_logprob": -0.19180644000018085,
        "compression_ratio": 1.521505376344086,
        "end": 376.15999999999997,
        "id": 146,
        "no_speech_prob": 0.000006854309958725935,
        "seek": 36764,
        "start": 372.47999999999996,
        "temperature": 0,
        "text": " And the wonderful thing about using async and await",
        "tokens": [
          50606,
          400,
          264,
          3715,
          551,
          466,
          1228,
          382,
          34015,
          293,
          19670,
          50790
        ]
      },
      {
        "avg_logprob": -0.19180644000018085,
        "compression_ratio": 1.521505376344086,
        "end": 380.64,
        "id": 147,
        "no_speech_prob": 0.000006854309958725935,
        "seek": 36764,
        "start": 376.15999999999997,
        "temperature": 0,
        "text": " is I could just do another call to fetch right here.",
        "tokens": [
          50790,
          307,
          286,
          727,
          445,
          360,
          1071,
          818,
          281,
          23673,
          558,
          510,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.19180644000018085,
        "compression_ratio": 1.521505376344086,
        "end": 387.52,
        "id": 148,
        "no_speech_prob": 0.000006854309958725935,
        "seek": 36764,
        "start": 380.64,
        "temperature": 0,
        "text": " So let's change this to weather URL,",
        "tokens": [
          51014,
          407,
          718,
          311,
          1319,
          341,
          281,
          5503,
          12905,
          11,
          51358
        ]
      },
      {
        "avg_logprob": -0.19180644000018085,
        "compression_ratio": 1.521505376344086,
        "end": 393.36,
        "id": 149,
        "no_speech_prob": 0.000006854309958725935,
        "seek": 36764,
        "start": 387.52,
        "temperature": 0,
        "text": " call this weather response, and weather data.",
        "tokens": [
          51358,
          818,
          341,
          5503,
          4134,
          11,
          293,
          5503,
          1412,
          13,
          51650
        ]
      },
      {
        "avg_logprob": -0.19180644000018085,
        "compression_ratio": 1.521505376344086,
        "end": 394.88,
        "id": 150,
        "no_speech_prob": 0.000006854309958725935,
        "seek": 36764,
        "start": 393.36,
        "temperature": 0,
        "text": " The reason I'm doing that is because I",
        "tokens": [
          51650,
          440,
          1778,
          286,
          478,
          884,
          300,
          307,
          570,
          286,
          51726
        ]
      },
      {
        "avg_logprob": -0.22324522336324057,
        "compression_ratio": 1.691358024691358,
        "end": 400.4,
        "id": 151,
        "no_speech_prob": 0.0046095456928014755,
        "seek": 39488,
        "start": 394.88,
        "temperature": 0,
        "text": " want to then do exactly the same sequence with an air quality",
        "tokens": [
          50364,
          528,
          281,
          550,
          360,
          2293,
          264,
          912,
          8310,
          365,
          364,
          1988,
          3125,
          50640
        ]
      },
      {
        "avg_logprob": -0.22324522336324057,
        "compression_ratio": 1.691358024691358,
        "end": 404.68,
        "id": 152,
        "no_speech_prob": 0.0046095456928014755,
        "seek": 39488,
        "start": 400.4,
        "temperature": 0,
        "text": " URL, an air quality response, and air quality data.",
        "tokens": [
          50640,
          12905,
          11,
          364,
          1988,
          3125,
          4134,
          11,
          293,
          1988,
          3125,
          1412,
          13,
          50854
        ]
      },
      {
        "avg_logprob": -0.22324522336324057,
        "compression_ratio": 1.691358024691358,
        "end": 413,
        "id": 153,
        "no_speech_prob": 0.0046095456928014755,
        "seek": 39488,
        "start": 404.68,
        "temperature": 0,
        "text": " So let's put in the air quality URL, which is this,",
        "tokens": [
          50854,
          407,
          718,
          311,
          829,
          294,
          264,
          1988,
          3125,
          12905,
          11,
          597,
          307,
          341,
          11,
          51270
        ]
      },
      {
        "avg_logprob": -0.22324522336324057,
        "compression_ratio": 1.691358024691358,
        "end": 417.8,
        "id": 154,
        "no_speech_prob": 0.0046095456928014755,
        "seek": 39488,
        "start": 413,
        "temperature": 0,
        "text": " but with coordinates equals the latitude and longitude.",
        "tokens": [
          51270,
          457,
          365,
          21056,
          6915,
          264,
          45436,
          293,
          938,
          4377,
          13,
          51510
        ]
      },
      {
        "avg_logprob": -0.22324522336324057,
        "compression_ratio": 1.691358024691358,
        "end": 421.76,
        "id": 155,
        "no_speech_prob": 0.0046095456928014755,
        "seek": 39488,
        "start": 417.8,
        "temperature": 0,
        "text": " Then we're going to say a fetch that air quality URL",
        "tokens": [
          51510,
          1396,
          321,
          434,
          516,
          281,
          584,
          257,
          23673,
          300,
          1988,
          3125,
          12905,
          51708
        ]
      },
      {
        "avg_logprob": -0.2313918670018514,
        "compression_ratio": 1.7281553398058251,
        "end": 425.36,
        "id": 156,
        "no_speech_prob": 0.0000019638032426883,
        "seek": 42176,
        "start": 421.76,
        "temperature": 0,
        "text": " and then convert that response into a data.",
        "tokens": [
          50364,
          293,
          550,
          7620,
          300,
          4134,
          666,
          257,
          1412,
          13,
          50544
        ]
      },
      {
        "avg_logprob": -0.2313918670018514,
        "compression_ratio": 1.7281553398058251,
        "end": 428.71999999999997,
        "id": 157,
        "no_speech_prob": 0.0000019638032426883,
        "seek": 42176,
        "start": 425.36,
        "temperature": 0,
        "text": " And I also need to change this to weather URL",
        "tokens": [
          50544,
          400,
          286,
          611,
          643,
          281,
          1319,
          341,
          281,
          5503,
          12905,
          50712
        ]
      },
      {
        "avg_logprob": -0.2313918670018514,
        "compression_ratio": 1.7281553398058251,
        "end": 431.84,
        "id": 158,
        "no_speech_prob": 0.0000019638032426883,
        "seek": 42176,
        "start": 428.71999999999997,
        "temperature": 0,
        "text": " and change this to weather response.",
        "tokens": [
          50712,
          293,
          1319,
          341,
          281,
          5503,
          4134,
          13,
          50868
        ]
      },
      {
        "avg_logprob": -0.2313918670018514,
        "compression_ratio": 1.7281553398058251,
        "end": 435.88,
        "id": 159,
        "no_speech_prob": 0.0000019638032426883,
        "seek": 42176,
        "start": 431.84,
        "temperature": 0,
        "text": " So now I have weather data and air quality data.",
        "tokens": [
          50868,
          407,
          586,
          286,
          362,
          5503,
          1412,
          293,
          1988,
          3125,
          1412,
          13,
          51070
        ]
      },
      {
        "avg_logprob": -0.2313918670018514,
        "compression_ratio": 1.7281553398058251,
        "end": 437.59999999999997,
        "id": 160,
        "no_speech_prob": 0.0000019638032426883,
        "seek": 42176,
        "start": 435.88,
        "temperature": 0,
        "text": " So I have both of those data sources.",
        "tokens": [
          51070,
          407,
          286,
          362,
          1293,
          295,
          729,
          1412,
          7139,
          13,
          51156
        ]
      },
      {
        "avg_logprob": -0.2313918670018514,
        "compression_ratio": 1.7281553398058251,
        "end": 439.12,
        "id": 161,
        "no_speech_prob": 0.0000019638032426883,
        "seek": 42176,
        "start": 437.59999999999997,
        "temperature": 0,
        "text": " All I need to do is just put them,",
        "tokens": [
          51156,
          1057,
          286,
          643,
          281,
          360,
          307,
          445,
          829,
          552,
          11,
          51232
        ]
      },
      {
        "avg_logprob": -0.2313918670018514,
        "compression_ratio": 1.7281553398058251,
        "end": 441.15999999999997,
        "id": 162,
        "no_speech_prob": 0.0000019638032426883,
        "seek": 42176,
        "start": 439.12,
        "temperature": 0,
        "text": " I'm going to put them together in another object.",
        "tokens": [
          51232,
          286,
          478,
          516,
          281,
          829,
          552,
          1214,
          294,
          1071,
          2657,
          13,
          51334
        ]
      },
      {
        "avg_logprob": -0.2313918670018514,
        "compression_ratio": 1.7281553398058251,
        "end": 446.08,
        "id": 163,
        "no_speech_prob": 0.0000019638032426883,
        "seek": 42176,
        "start": 441.15999999999997,
        "temperature": 0,
        "text": " I'll say constant data equals weather colon weather data,",
        "tokens": [
          51334,
          286,
          603,
          584,
          5754,
          1412,
          6915,
          5503,
          8255,
          5503,
          1412,
          11,
          51580
        ]
      },
      {
        "avg_logprob": -0.21583161530671297,
        "compression_ratio": 1.6382113821138211,
        "end": 452.32,
        "id": 164,
        "no_speech_prob": 0.000003905482572008623,
        "seek": 44608,
        "start": 446.08,
        "temperature": 0,
        "text": " and then air quality colon AQ data.",
        "tokens": [
          50364,
          293,
          550,
          1988,
          3125,
          8255,
          316,
          48,
          1412,
          13,
          50676
        ]
      },
      {
        "avg_logprob": -0.21583161530671297,
        "compression_ratio": 1.6382113821138211,
        "end": 455.8,
        "id": 165,
        "no_speech_prob": 0.000003905482572008623,
        "seek": 44608,
        "start": 452.32,
        "temperature": 0,
        "text": " And that is what I'm going to send back to the client.",
        "tokens": [
          50676,
          400,
          300,
          307,
          437,
          286,
          478,
          516,
          281,
          2845,
          646,
          281,
          264,
          6423,
          13,
          50850
        ]
      },
      {
        "avg_logprob": -0.21583161530671297,
        "compression_ratio": 1.6382113821138211,
        "end": 458.84,
        "id": 166,
        "no_speech_prob": 0.000003905482572008623,
        "seek": 44608,
        "start": 455.8,
        "temperature": 0,
        "text": " Now I'm getting data from multiple APIs.",
        "tokens": [
          50850,
          823,
          286,
          478,
          1242,
          1412,
          490,
          3866,
          21445,
          13,
          51002
        ]
      },
      {
        "avg_logprob": -0.21583161530671297,
        "compression_ratio": 1.6382113821138211,
        "end": 460.91999999999996,
        "id": 167,
        "no_speech_prob": 0.000003905482572008623,
        "seek": 44608,
        "start": 458.84,
        "temperature": 0,
        "text": " I'm getting weather information from Dark Sky",
        "tokens": [
          51002,
          286,
          478,
          1242,
          5503,
          1589,
          490,
          9563,
          9879,
          51106
        ]
      },
      {
        "avg_logprob": -0.21583161530671297,
        "compression_ratio": 1.6382113821138211,
        "end": 463.36,
        "id": 168,
        "no_speech_prob": 0.000003905482572008623,
        "seek": 44608,
        "start": 460.91999999999996,
        "temperature": 0,
        "text": " and air quality information from OpenAQ.",
        "tokens": [
          51106,
          293,
          1988,
          3125,
          1589,
          490,
          7238,
          32,
          48,
          13,
          51228
        ]
      },
      {
        "avg_logprob": -0.21583161530671297,
        "compression_ratio": 1.6382113821138211,
        "end": 465.24,
        "id": 169,
        "no_speech_prob": 0.000003905482572008623,
        "seek": 44608,
        "start": 463.36,
        "temperature": 0,
        "text": " I should point out that I don't have",
        "tokens": [
          51228,
          286,
          820,
          935,
          484,
          300,
          286,
          500,
          380,
          362,
          51322
        ]
      },
      {
        "avg_logprob": -0.21583161530671297,
        "compression_ratio": 1.6382113821138211,
        "end": 467.08,
        "id": 170,
        "no_speech_prob": 0.000003905482572008623,
        "seek": 44608,
        "start": 465.24,
        "temperature": 0,
        "text": " to sequence one after the other.",
        "tokens": [
          51322,
          281,
          8310,
          472,
          934,
          264,
          661,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.21583161530671297,
        "compression_ratio": 1.6382113821138211,
        "end": 469.03999999999996,
        "id": 171,
        "no_speech_prob": 0.000003905482572008623,
        "seek": 44608,
        "start": 467.08,
        "temperature": 0,
        "text": " Because they're asynchronous calls,",
        "tokens": [
          51414,
          1436,
          436,
          434,
          49174,
          5498,
          11,
          51512
        ]
      },
      {
        "avg_logprob": -0.21583161530671297,
        "compression_ratio": 1.6382113821138211,
        "end": 471.15999999999997,
        "id": 172,
        "no_speech_prob": 0.000003905482572008623,
        "seek": 44608,
        "start": 469.03999999999996,
        "temperature": 0,
        "text": " they can happen somewhat in parallel.",
        "tokens": [
          51512,
          436,
          393,
          1051,
          8344,
          294,
          8952,
          13,
          51618
        ]
      },
      {
        "avg_logprob": -0.21583161530671297,
        "compression_ratio": 1.6382113821138211,
        "end": 473.12,
        "id": 173,
        "no_speech_prob": 0.000003905482572008623,
        "seek": 44608,
        "start": 471.15999999999997,
        "temperature": 0,
        "text": " I could use something called promise.all",
        "tokens": [
          51618,
          286,
          727,
          764,
          746,
          1219,
          6228,
          13,
          336,
          51716
        ]
      },
      {
        "avg_logprob": -0.24289791584014891,
        "compression_ratio": 1.629737609329446,
        "end": 476.16,
        "id": 174,
        "no_speech_prob": 0.00020027259597554803,
        "seek": 47312,
        "start": 473.12,
        "temperature": 0,
        "text": " to wait for a whole bunch of different asynchronous events",
        "tokens": [
          50364,
          281,
          1699,
          337,
          257,
          1379,
          3840,
          295,
          819,
          49174,
          3931,
          50516
        ]
      },
      {
        "avg_logprob": -0.24289791584014891,
        "compression_ratio": 1.629737609329446,
        "end": 477.36,
        "id": 175,
        "no_speech_prob": 0.00020027259597554803,
        "seek": 47312,
        "start": 476.16,
        "temperature": 0,
        "text": " to all complete.",
        "tokens": [
          50516,
          281,
          439,
          3566,
          13,
          50576
        ]
      },
      {
        "avg_logprob": -0.24289791584014891,
        "compression_ratio": 1.629737609329446,
        "end": 479.44,
        "id": 176,
        "no_speech_prob": 0.00020027259597554803,
        "seek": 47312,
        "start": 477.36,
        "temperature": 0,
        "text": " And I've actually covered this in a separate video.",
        "tokens": [
          50576,
          400,
          286,
          600,
          767,
          5343,
          341,
          294,
          257,
          4994,
          960,
          13,
          50680
        ]
      },
      {
        "avg_logprob": -0.24289791584014891,
        "compression_ratio": 1.629737609329446,
        "end": 481.1,
        "id": 177,
        "no_speech_prob": 0.00020027259597554803,
        "seek": 47312,
        "start": 479.44,
        "temperature": 0,
        "text": " You could think of this as a little exercise to yourself.",
        "tokens": [
          50680,
          509,
          727,
          519,
          295,
          341,
          382,
          257,
          707,
          5380,
          281,
          1803,
          13,
          50763
        ]
      },
      {
        "avg_logprob": -0.24289791584014891,
        "compression_ratio": 1.629737609329446,
        "end": 483.44,
        "id": 178,
        "no_speech_prob": 0.00020027259597554803,
        "seek": 47312,
        "start": 481.1,
        "temperature": 0,
        "text": " Maybe change this to use promise.all.",
        "tokens": [
          50763,
          2704,
          1319,
          341,
          281,
          764,
          6228,
          13,
          336,
          13,
          50880
        ]
      },
      {
        "avg_logprob": -0.24289791584014891,
        "compression_ratio": 1.629737609329446,
        "end": 486.08,
        "id": 179,
        "no_speech_prob": 0.00020027259597554803,
        "seek": 47312,
        "start": 483.44,
        "temperature": 0,
        "text": " But with just two APIs here, I'm happy to just do this",
        "tokens": [
          50880,
          583,
          365,
          445,
          732,
          21445,
          510,
          11,
          286,
          478,
          2055,
          281,
          445,
          360,
          341,
          51012
        ]
      },
      {
        "avg_logprob": -0.24289791584014891,
        "compression_ratio": 1.629737609329446,
        "end": 487.4,
        "id": 180,
        "no_speech_prob": 0.00020027259597554803,
        "seek": 47312,
        "start": 486.08,
        "temperature": 0,
        "text": " in sequence.",
        "tokens": [
          51012,
          294,
          8310,
          13,
          51078
        ]
      },
      {
        "avg_logprob": -0.24289791584014891,
        "compression_ratio": 1.629737609329446,
        "end": 488.96,
        "id": 181,
        "no_speech_prob": 0.00020027259597554803,
        "seek": 47312,
        "start": 487.4,
        "temperature": 0,
        "text": " Let's check to see if this works.",
        "tokens": [
          51078,
          961,
          311,
          1520,
          281,
          536,
          498,
          341,
          1985,
          13,
          51156
        ]
      },
      {
        "avg_logprob": -0.24289791584014891,
        "compression_ratio": 1.629737609329446,
        "end": 490.64,
        "id": 182,
        "no_speech_prob": 0.00020027259597554803,
        "seek": 47312,
        "start": 488.96,
        "temperature": 0,
        "text": " I'm actually running NodeMon right now.",
        "tokens": [
          51156,
          286,
          478,
          767,
          2614,
          38640,
          32498,
          558,
          586,
          13,
          51240
        ]
      },
      {
        "avg_logprob": -0.24289791584014891,
        "compression_ratio": 1.629737609329446,
        "end": 493.2,
        "id": 183,
        "no_speech_prob": 0.00020027259597554803,
        "seek": 47312,
        "start": 490.64,
        "temperature": 0,
        "text": " So the server has been restarted for me automatically.",
        "tokens": [
          51240,
          407,
          264,
          7154,
          575,
          668,
          21022,
          292,
          337,
          385,
          6772,
          13,
          51368
        ]
      },
      {
        "avg_logprob": -0.24289791584014891,
        "compression_ratio": 1.629737609329446,
        "end": 495,
        "id": 184,
        "no_speech_prob": 0.00020027259597554803,
        "seek": 47312,
        "start": 493.2,
        "temperature": 0,
        "text": " Let's move to Shanghai.",
        "tokens": [
          51368,
          961,
          311,
          1286,
          281,
          26135,
          13,
          51458
        ]
      },
      {
        "avg_logprob": -0.24289791584014891,
        "compression_ratio": 1.629737609329446,
        "end": 496.6,
        "id": 185,
        "no_speech_prob": 0.00020027259597554803,
        "seek": 47312,
        "start": 495,
        "temperature": 0,
        "text": " And let's hit refresh.",
        "tokens": [
          51458,
          400,
          718,
          311,
          2045,
          15134,
          13,
          51538
        ]
      },
      {
        "avg_logprob": -0.24289791584014891,
        "compression_ratio": 1.629737609329446,
        "end": 499.66,
        "id": 186,
        "no_speech_prob": 0.00020027259597554803,
        "seek": 47312,
        "start": 496.6,
        "temperature": 0,
        "text": " And let's see, ah, uncaught, cannot read property summary",
        "tokens": [
          51538,
          400,
          718,
          311,
          536,
          11,
          3716,
          11,
          517,
          496,
          1599,
          11,
          2644,
          1401,
          4707,
          12691,
          51691
        ]
      },
      {
        "avg_logprob": -0.24289791584014891,
        "compression_ratio": 1.629737609329446,
        "end": 500.76,
        "id": 187,
        "no_speech_prob": 0.00020027259597554803,
        "seek": 47312,
        "start": 499.66,
        "temperature": 0,
        "text": " of undefined.",
        "tokens": [
          51691,
          295,
          674,
          5666,
          2001,
          13,
          51746
        ]
      },
      {
        "avg_logprob": -0.24289791584014891,
        "compression_ratio": 1.629737609329446,
        "end": 501.92,
        "id": 188,
        "no_speech_prob": 0.00020027259597554803,
        "seek": 47312,
        "start": 500.76,
        "temperature": 0,
        "text": " What just happened?",
        "tokens": [
          51746,
          708,
          445,
          2011,
          30,
          51804
        ]
      },
      {
        "avg_logprob": -0.25282410212925505,
        "compression_ratio": 1.6888888888888889,
        "end": 503.96000000000004,
        "id": 189,
        "no_speech_prob": 0.000050644564907997847,
        "seek": 50192,
        "start": 501.92,
        "temperature": 0,
        "text": " Sketch.js line 14.",
        "tokens": [
          50364,
          49245,
          13,
          25530,
          1622,
          3499,
          13,
          50466
        ]
      },
      {
        "avg_logprob": -0.25282410212925505,
        "compression_ratio": 1.6888888888888889,
        "end": 504.46000000000004,
        "id": 190,
        "no_speech_prob": 0.000050644564907997847,
        "seek": 50192,
        "start": 503.96000000000004,
        "temperature": 0,
        "text": " Ah.",
        "tokens": [
          50466,
          2438,
          13,
          50491
        ]
      },
      {
        "avg_logprob": -0.25282410212925505,
        "compression_ratio": 1.6888888888888889,
        "end": 510.6,
        "id": 191,
        "no_speech_prob": 0.000050644564907997847,
        "seek": 50192,
        "start": 507.26,
        "temperature": 0,
        "text": " So I changed the way the data comes in.",
        "tokens": [
          50631,
          407,
          286,
          3105,
          264,
          636,
          264,
          1412,
          1487,
          294,
          13,
          50798
        ]
      },
      {
        "avg_logprob": -0.25282410212925505,
        "compression_ratio": 1.6888888888888889,
        "end": 514.72,
        "id": 192,
        "no_speech_prob": 0.000050644564907997847,
        "seek": 50192,
        "start": 510.6,
        "temperature": 0,
        "text": " The data came in before as just the actual information",
        "tokens": [
          50798,
          440,
          1412,
          1361,
          294,
          949,
          382,
          445,
          264,
          3539,
          1589,
          51004
        ]
      },
      {
        "avg_logprob": -0.25282410212925505,
        "compression_ratio": 1.6888888888888889,
        "end": 515.5600000000001,
        "id": 193,
        "no_speech_prob": 0.000050644564907997847,
        "seek": 50192,
        "start": 514.72,
        "temperature": 0,
        "text": " from Dark Sky.",
        "tokens": [
          51004,
          490,
          9563,
          9879,
          13,
          51046
        ]
      },
      {
        "avg_logprob": -0.25282410212925505,
        "compression_ratio": 1.6888888888888889,
        "end": 520.72,
        "id": 194,
        "no_speech_prob": 0.000050644564907997847,
        "seek": 50192,
        "start": 515.5600000000001,
        "temperature": 0,
        "text": " But now I put everything in a property called weather.",
        "tokens": [
          51046,
          583,
          586,
          286,
          829,
          1203,
          294,
          257,
          4707,
          1219,
          5503,
          13,
          51304
        ]
      },
      {
        "avg_logprob": -0.25282410212925505,
        "compression_ratio": 1.6888888888888889,
        "end": 522.28,
        "id": 195,
        "no_speech_prob": 0.000050644564907997847,
        "seek": 50192,
        "start": 520.72,
        "temperature": 0,
        "text": " So did it console log?",
        "tokens": [
          51304,
          407,
          630,
          309,
          11076,
          3565,
          30,
          51382
        ]
      },
      {
        "avg_logprob": -0.25282410212925505,
        "compression_ratio": 1.6888888888888889,
        "end": 522.76,
        "id": 196,
        "no_speech_prob": 0.000050644564907997847,
        "seek": 50192,
        "start": 522.28,
        "temperature": 0,
        "text": " Yeah.",
        "tokens": [
          51382,
          865,
          13,
          51406
        ]
      },
      {
        "avg_logprob": -0.25282410212925505,
        "compression_ratio": 1.6888888888888889,
        "end": 524.28,
        "id": 197,
        "no_speech_prob": 0.000050644564907997847,
        "seek": 50192,
        "start": 522.76,
        "temperature": 0,
        "text": " So you can see here I have air quality",
        "tokens": [
          51406,
          407,
          291,
          393,
          536,
          510,
          286,
          362,
          1988,
          3125,
          51482
        ]
      },
      {
        "avg_logprob": -0.25282410212925505,
        "compression_ratio": 1.6888888888888889,
        "end": 525.78,
        "id": 198,
        "no_speech_prob": 0.000050644564907997847,
        "seek": 50192,
        "start": 524.28,
        "temperature": 0,
        "text": " with all the air quality information",
        "tokens": [
          51482,
          365,
          439,
          264,
          1988,
          3125,
          1589,
          51557
        ]
      },
      {
        "avg_logprob": -0.25282410212925505,
        "compression_ratio": 1.6888888888888889,
        "end": 527.8000000000001,
        "id": 199,
        "no_speech_prob": 0.000050644564907997847,
        "seek": 50192,
        "start": 525.78,
        "temperature": 0,
        "text": " and weather with all the weather information.",
        "tokens": [
          51557,
          293,
          5503,
          365,
          439,
          264,
          5503,
          1589,
          13,
          51658
        ]
      },
      {
        "avg_logprob": -0.25282410212925505,
        "compression_ratio": 1.6888888888888889,
        "end": 531.52,
        "id": 200,
        "no_speech_prob": 0.000050644564907997847,
        "seek": 50192,
        "start": 527.8000000000001,
        "temperature": 0,
        "text": " So I need to change this to weather.json.",
        "tokens": [
          51658,
          407,
          286,
          643,
          281,
          1319,
          341,
          281,
          5503,
          13,
          73,
          3015,
          13,
          51844
        ]
      },
      {
        "avg_logprob": -0.21539742979284834,
        "compression_ratio": 1.9388646288209608,
        "end": 533.1999999999999,
        "id": 201,
        "no_speech_prob": 0.0005112512153573334,
        "seek": 53152,
        "start": 531.52,
        "temperature": 0,
        "text": " And I don't love the way I'm doing this.",
        "tokens": [
          50364,
          400,
          286,
          500,
          380,
          959,
          264,
          636,
          286,
          478,
          884,
          341,
          13,
          50448
        ]
      },
      {
        "avg_logprob": -0.21539742979284834,
        "compression_ratio": 1.9388646288209608,
        "end": 534.62,
        "id": 202,
        "no_speech_prob": 0.0005112512153573334,
        "seek": 53152,
        "start": 533.1999999999999,
        "temperature": 0,
        "text": " I think what I'm going to do is I'm",
        "tokens": [
          50448,
          286,
          519,
          437,
          286,
          478,
          516,
          281,
          360,
          307,
          286,
          478,
          50519
        ]
      },
      {
        "avg_logprob": -0.21539742979284834,
        "compression_ratio": 1.9388646288209608,
        "end": 537.96,
        "id": 203,
        "no_speech_prob": 0.0005112512153573334,
        "seek": 53152,
        "start": 534.62,
        "temperature": 0,
        "text": " going to say const weather equals, sorry,",
        "tokens": [
          50519,
          516,
          281,
          584,
          1817,
          5503,
          6915,
          11,
          2597,
          11,
          50686
        ]
      },
      {
        "avg_logprob": -0.21539742979284834,
        "compression_ratio": 1.9388646288209608,
        "end": 541.0799999999999,
        "id": 204,
        "no_speech_prob": 0.0005112512153573334,
        "seek": 53152,
        "start": 537.96,
        "temperature": 0,
        "text": " it's json.weather.currently.",
        "tokens": [
          50686,
          309,
          311,
          361,
          3015,
          13,
          826,
          1172,
          13,
          49827,
          356,
          13,
          50842
        ]
      },
      {
        "avg_logprob": -0.21539742979284834,
        "compression_ratio": 1.9388646288209608,
        "end": 542.1999999999999,
        "id": 205,
        "no_speech_prob": 0.0005112512153573334,
        "seek": 53152,
        "start": 541.0799999999999,
        "temperature": 0,
        "text": " I'm just going to do that.",
        "tokens": [
          50842,
          286,
          478,
          445,
          516,
          281,
          360,
          300,
          13,
          50898
        ]
      },
      {
        "avg_logprob": -0.21539742979284834,
        "compression_ratio": 1.9388646288209608,
        "end": 543.6999999999999,
        "id": 206,
        "no_speech_prob": 0.0005112512153573334,
        "seek": 53152,
        "start": 542.1999999999999,
        "temperature": 0,
        "text": " And I'm going to say, for right now,",
        "tokens": [
          50898,
          400,
          286,
          478,
          516,
          281,
          584,
          11,
          337,
          558,
          586,
          11,
          50973
        ]
      },
      {
        "avg_logprob": -0.21539742979284834,
        "compression_ratio": 1.9388646288209608,
        "end": 547.36,
        "id": 207,
        "no_speech_prob": 0.0005112512153573334,
        "seek": 53152,
        "start": 543.6999999999999,
        "temperature": 0,
        "text": " I'm just going to say air equals json.air.quality.",
        "tokens": [
          50973,
          286,
          478,
          445,
          516,
          281,
          584,
          1988,
          6915,
          361,
          3015,
          13,
          1246,
          13,
          11286,
          13,
          51156
        ]
      },
      {
        "avg_logprob": -0.21539742979284834,
        "compression_ratio": 1.9388646288209608,
        "end": 549.4,
        "id": 208,
        "no_speech_prob": 0.0005112512153573334,
        "seek": 53152,
        "start": 547.36,
        "temperature": 0,
        "text": " I'll have to look at what I'm looking for in there",
        "tokens": [
          51156,
          286,
          603,
          362,
          281,
          574,
          412,
          437,
          286,
          478,
          1237,
          337,
          294,
          456,
          51258
        ]
      },
      {
        "avg_logprob": -0.21539742979284834,
        "compression_ratio": 1.9388646288209608,
        "end": 550.12,
        "id": 209,
        "no_speech_prob": 0.0005112512153573334,
        "seek": 53152,
        "start": 549.4,
        "temperature": 0,
        "text": " in a second.",
        "tokens": [
          51258,
          294,
          257,
          1150,
          13,
          51294
        ]
      },
      {
        "avg_logprob": -0.21539742979284834,
        "compression_ratio": 1.9388646288209608,
        "end": 556.74,
        "id": 210,
        "no_speech_prob": 0.0005112512153573334,
        "seek": 53152,
        "start": 550.12,
        "temperature": 0,
        "text": " So now the text content here should be weather.summary.",
        "tokens": [
          51294,
          407,
          586,
          264,
          2487,
          2701,
          510,
          820,
          312,
          5503,
          13,
          82,
          40879,
          822,
          13,
          51625
        ]
      },
      {
        "avg_logprob": -0.21539742979284834,
        "compression_ratio": 1.9388646288209608,
        "end": 560.48,
        "id": 211,
        "no_speech_prob": 0.0005112512153573334,
        "seek": 53152,
        "start": 556.74,
        "temperature": 0,
        "text": " And the text content here should just be weather.temperature.",
        "tokens": [
          51625,
          400,
          264,
          2487,
          2701,
          510,
          820,
          445,
          312,
          5503,
          13,
          18275,
          610,
          1503,
          13,
          51812
        ]
      },
      {
        "avg_logprob": -0.21092079022179352,
        "compression_ratio": 1.8366666666666667,
        "end": 562.6800000000001,
        "id": 212,
        "no_speech_prob": 0.00004611240728991106,
        "seek": 56048,
        "start": 560.48,
        "temperature": 0,
        "text": " Let's see if that works.",
        "tokens": [
          50364,
          961,
          311,
          536,
          498,
          300,
          1985,
          13,
          50474
        ]
      },
      {
        "avg_logprob": -0.21092079022179352,
        "compression_ratio": 1.8366666666666667,
        "end": 564.76,
        "id": 213,
        "no_speech_prob": 0.00004611240728991106,
        "seek": 56048,
        "start": 562.6800000000001,
        "temperature": 0,
        "text": " And hit Refresh.",
        "tokens": [
          50474,
          400,
          2045,
          16957,
          3644,
          13,
          50578
        ]
      },
      {
        "avg_logprob": -0.21092079022179352,
        "compression_ratio": 1.8366666666666667,
        "end": 565.48,
        "id": 214,
        "no_speech_prob": 0.00004611240728991106,
        "seek": 56048,
        "start": 564.76,
        "temperature": 0,
        "text": " And there we go.",
        "tokens": [
          50578,
          400,
          456,
          321,
          352,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.21092079022179352,
        "compression_ratio": 1.8366666666666667,
        "end": 568.16,
        "id": 215,
        "no_speech_prob": 0.00004611240728991106,
        "seek": 56048,
        "start": 565.48,
        "temperature": 0,
        "text": " We now have the latitude and longitude and the weather",
        "tokens": [
          50614,
          492,
          586,
          362,
          264,
          45436,
          293,
          938,
          4377,
          293,
          264,
          5503,
          50748
        ]
      },
      {
        "avg_logprob": -0.21092079022179352,
        "compression_ratio": 1.8366666666666667,
        "end": 569.8000000000001,
        "id": 216,
        "no_speech_prob": 0.00004611240728991106,
        "seek": 56048,
        "start": 568.16,
        "temperature": 0,
        "text": " information from Shanghai.",
        "tokens": [
          50748,
          1589,
          490,
          26135,
          13,
          50830
        ]
      },
      {
        "avg_logprob": -0.21092079022179352,
        "compression_ratio": 1.8366666666666667,
        "end": 572.12,
        "id": 217,
        "no_speech_prob": 0.00004611240728991106,
        "seek": 56048,
        "start": 569.8000000000001,
        "temperature": 0,
        "text": " And let's put some information about air quality.",
        "tokens": [
          50830,
          400,
          718,
          311,
          829,
          512,
          1589,
          466,
          1988,
          3125,
          13,
          50946
        ]
      },
      {
        "avg_logprob": -0.21092079022179352,
        "compression_ratio": 1.8366666666666667,
        "end": 575.2,
        "id": 218,
        "no_speech_prob": 0.00004611240728991106,
        "seek": 56048,
        "start": 572.12,
        "temperature": 0,
        "text": " So in here under air quality, under results,",
        "tokens": [
          50946,
          407,
          294,
          510,
          833,
          1988,
          3125,
          11,
          833,
          3542,
          11,
          51100
        ]
      },
      {
        "avg_logprob": -0.21092079022179352,
        "compression_ratio": 1.8366666666666667,
        "end": 578.88,
        "id": 219,
        "no_speech_prob": 0.00004611240728991106,
        "seek": 56048,
        "start": 575.2,
        "temperature": 0,
        "text": " I think what I'll do, oh, there are no results.",
        "tokens": [
          51100,
          286,
          519,
          437,
          286,
          603,
          360,
          11,
          1954,
          11,
          456,
          366,
          572,
          3542,
          13,
          51284
        ]
      },
      {
        "avg_logprob": -0.21092079022179352,
        "compression_ratio": 1.8366666666666667,
        "end": 581.08,
        "id": 220,
        "no_speech_prob": 0.00004611240728991106,
        "seek": 56048,
        "start": 578.88,
        "temperature": 0,
        "text": " So I suppose OpenAQ just doesn't have",
        "tokens": [
          51284,
          407,
          286,
          7297,
          7238,
          32,
          48,
          445,
          1177,
          380,
          362,
          51394
        ]
      },
      {
        "avg_logprob": -0.21092079022179352,
        "compression_ratio": 1.8366666666666667,
        "end": 582.32,
        "id": 221,
        "no_speech_prob": 0.00004611240728991106,
        "seek": 56048,
        "start": 581.08,
        "temperature": 0,
        "text": " any information for Shanghai.",
        "tokens": [
          51394,
          604,
          1589,
          337,
          26135,
          13,
          51456
        ]
      },
      {
        "avg_logprob": -0.21092079022179352,
        "compression_ratio": 1.8366666666666667,
        "end": 583.7,
        "id": 222,
        "no_speech_prob": 0.00004611240728991106,
        "seek": 56048,
        "start": 582.32,
        "temperature": 0,
        "text": " Let's go back to New York because I know",
        "tokens": [
          51456,
          961,
          311,
          352,
          646,
          281,
          1873,
          3609,
          570,
          286,
          458,
          51525
        ]
      },
      {
        "avg_logprob": -0.21092079022179352,
        "compression_ratio": 1.8366666666666667,
        "end": 585.2,
        "id": 223,
        "no_speech_prob": 0.00004611240728991106,
        "seek": 56048,
        "start": 583.7,
        "temperature": 0,
        "text": " there's information in New York.",
        "tokens": [
          51525,
          456,
          311,
          1589,
          294,
          1873,
          3609,
          13,
          51600
        ]
      },
      {
        "avg_logprob": -0.21092079022179352,
        "compression_ratio": 1.8366666666666667,
        "end": 586.6800000000001,
        "id": 224,
        "no_speech_prob": 0.00004611240728991106,
        "seek": 56048,
        "start": 585.2,
        "temperature": 0,
        "text": " I guess I could do no override.",
        "tokens": [
          51600,
          286,
          2041,
          286,
          727,
          360,
          572,
          42321,
          13,
          51674
        ]
      },
      {
        "avg_logprob": -0.21092079022179352,
        "compression_ratio": 1.8366666666666667,
        "end": 588.2,
        "id": 225,
        "no_speech_prob": 0.00004611240728991106,
        "seek": 56048,
        "start": 586.6800000000001,
        "temperature": 0,
        "text": " And that'll get me back to New York.",
        "tokens": [
          51674,
          400,
          300,
          603,
          483,
          385,
          646,
          281,
          1873,
          3609,
          13,
          51750
        ]
      },
      {
        "avg_logprob": -0.21092079022179352,
        "compression_ratio": 1.8366666666666667,
        "end": 590.24,
        "id": 226,
        "no_speech_prob": 0.00004611240728991106,
        "seek": 56048,
        "start": 588.2,
        "temperature": 0,
        "text": " So now I've got the weather in New York, which is clear.",
        "tokens": [
          51750,
          407,
          586,
          286,
          600,
          658,
          264,
          5503,
          294,
          1873,
          3609,
          11,
          597,
          307,
          1850,
          13,
          51852
        ]
      },
      {
        "avg_logprob": -0.22930728264574735,
        "compression_ratio": 1.590717299578059,
        "end": 591.72,
        "id": 227,
        "no_speech_prob": 0.000017231550373253413,
        "seek": 59024,
        "start": 591,
        "temperature": 0,
        "text": " 65 degrees.",
        "tokens": [
          50402,
          11624,
          5310,
          13,
          50438
        ]
      },
      {
        "avg_logprob": -0.22930728264574735,
        "compression_ratio": 1.590717299578059,
        "end": 594.64,
        "id": 228,
        "no_speech_prob": 0.000017231550373253413,
        "seek": 59024,
        "start": 591.72,
        "temperature": 0,
        "text": " And I can go down here and look at air quality under results.",
        "tokens": [
          50438,
          400,
          286,
          393,
          352,
          760,
          510,
          293,
          574,
          412,
          1988,
          3125,
          833,
          3542,
          13,
          50584
        ]
      },
      {
        "avg_logprob": -0.22930728264574735,
        "compression_ratio": 1.590717299578059,
        "end": 600.24,
        "id": 229,
        "no_speech_prob": 0.000017231550373253413,
        "seek": 59024,
        "start": 594.64,
        "temperature": 0,
        "text": " We can see here are my two sensor readings under zero,",
        "tokens": [
          50584,
          492,
          393,
          536,
          510,
          366,
          452,
          732,
          10200,
          27319,
          833,
          4018,
          11,
          50864
        ]
      },
      {
        "avg_logprob": -0.22930728264574735,
        "compression_ratio": 1.590717299578059,
        "end": 603.48,
        "id": 230,
        "no_speech_prob": 0.000017231550373253413,
        "seek": 59024,
        "start": 600.24,
        "temperature": 0,
        "text": " under measurements, under zero.",
        "tokens": [
          50864,
          833,
          15383,
          11,
          833,
          4018,
          13,
          51026
        ]
      },
      {
        "avg_logprob": -0.22930728264574735,
        "compression_ratio": 1.590717299578059,
        "end": 606.16,
        "id": 231,
        "no_speech_prob": 0.000017231550373253413,
        "seek": 59024,
        "start": 603.48,
        "temperature": 0,
        "text": " So maybe this is what I want to report.",
        "tokens": [
          51026,
          407,
          1310,
          341,
          307,
          437,
          286,
          528,
          281,
          2275,
          13,
          51160
        ]
      },
      {
        "avg_logprob": -0.22930728264574735,
        "compression_ratio": 1.590717299578059,
        "end": 609.84,
        "id": 232,
        "no_speech_prob": 0.000017231550373253413,
        "seek": 59024,
        "start": 606.16,
        "temperature": 0,
        "text": " This data is PM data, or particulate matter data.",
        "tokens": [
          51160,
          639,
          1412,
          307,
          12499,
          1412,
          11,
          420,
          1276,
          5256,
          1871,
          1412,
          13,
          51344
        ]
      },
      {
        "avg_logprob": -0.22930728264574735,
        "compression_ratio": 1.590717299578059,
        "end": 613.24,
        "id": 233,
        "no_speech_prob": 0.000017231550373253413,
        "seek": 59024,
        "start": 609.84,
        "temperature": 0,
        "text": " And PM 2.5 refers to fine particles",
        "tokens": [
          51344,
          400,
          12499,
          568,
          13,
          20,
          14942,
          281,
          2489,
          10007,
          51514
        ]
      },
      {
        "avg_logprob": -0.22930728264574735,
        "compression_ratio": 1.590717299578059,
        "end": 616.92,
        "id": 234,
        "no_speech_prob": 0.000017231550373253413,
        "seek": 59024,
        "start": 613.24,
        "temperature": 0,
        "text": " are 2.5 micrometers in diameter or smaller.",
        "tokens": [
          51514,
          366,
          568,
          13,
          20,
          3123,
          81,
          34675,
          294,
          14196,
          420,
          4356,
          13,
          51698
        ]
      },
      {
        "avg_logprob": -0.22930728264574735,
        "compression_ratio": 1.590717299578059,
        "end": 620.04,
        "id": 235,
        "no_speech_prob": 0.000017231550373253413,
        "seek": 59024,
        "start": 616.92,
        "temperature": 0,
        "text": " So that's the concentration of those particles",
        "tokens": [
          51698,
          407,
          300,
          311,
          264,
          9856,
          295,
          729,
          10007,
          51854
        ]
      },
      {
        "avg_logprob": -0.2528071476862981,
        "compression_ratio": 1.606896551724138,
        "end": 624,
        "id": 236,
        "no_speech_prob": 0.00000685430768498918,
        "seek": 62004,
        "start": 620.8399999999999,
        "temperature": 0,
        "text": " within a cubic meter or meters cubed,",
        "tokens": [
          50404,
          1951,
          257,
          28733,
          9255,
          420,
          8146,
          36510,
          11,
          50562
        ]
      },
      {
        "avg_logprob": -0.2528071476862981,
        "compression_ratio": 1.606896551724138,
        "end": 626.16,
        "id": 237,
        "no_speech_prob": 0.00000685430768498918,
        "seek": 62004,
        "start": 624,
        "temperature": 0,
        "text": " micrograms per meters cubed.",
        "tokens": [
          50562,
          4532,
          1342,
          82,
          680,
          8146,
          36510,
          13,
          50670
        ]
      },
      {
        "avg_logprob": -0.2528071476862981,
        "compression_ratio": 1.606896551724138,
        "end": 627.6999999999999,
        "id": 238,
        "no_speech_prob": 0.00000685430768498918,
        "seek": 62004,
        "start": 626.16,
        "temperature": 0,
        "text": " Now, it's also important to be aware,",
        "tokens": [
          50670,
          823,
          11,
          309,
          311,
          611,
          1021,
          281,
          312,
          3650,
          11,
          50747
        ]
      },
      {
        "avg_logprob": -0.2528071476862981,
        "compression_ratio": 1.606896551724138,
        "end": 631.12,
        "id": 239,
        "no_speech_prob": 0.00000685430768498918,
        "seek": 62004,
        "start": 627.6999999999999,
        "temperature": 0,
        "text": " I'm recording this on Tuesday, May 21, 2019.",
        "tokens": [
          50747,
          286,
          478,
          6613,
          341,
          322,
          10017,
          11,
          1891,
          5080,
          11,
          6071,
          13,
          50918
        ]
      },
      {
        "avg_logprob": -0.2528071476862981,
        "compression_ratio": 1.606896551724138,
        "end": 633,
        "id": 240,
        "no_speech_prob": 0.00000685430768498918,
        "seek": 62004,
        "start": 631.12,
        "temperature": 0,
        "text": " And the last time this reading was updated",
        "tokens": [
          50918,
          400,
          264,
          1036,
          565,
          341,
          3760,
          390,
          10588,
          51012
        ]
      },
      {
        "avg_logprob": -0.2528071476862981,
        "compression_ratio": 1.606896551724138,
        "end": 635.04,
        "id": 241,
        "no_speech_prob": 0.00000685430768498918,
        "seek": 62004,
        "start": 633,
        "temperature": 0,
        "text": " was February 4, 2019.",
        "tokens": [
          51012,
          390,
          8711,
          1017,
          11,
          6071,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.2528071476862981,
        "compression_ratio": 1.606896551724138,
        "end": 637.9599999999999,
        "id": 242,
        "no_speech_prob": 0.00000685430768498918,
        "seek": 62004,
        "start": 635.04,
        "temperature": 0,
        "text": " So this isn't necessarily real-time data.",
        "tokens": [
          51114,
          407,
          341,
          1943,
          380,
          4725,
          957,
          12,
          3766,
          1412,
          13,
          51260
        ]
      },
      {
        "avg_logprob": -0.2528071476862981,
        "compression_ratio": 1.606896551724138,
        "end": 641.64,
        "id": 243,
        "no_speech_prob": 0.00000685430768498918,
        "seek": 62004,
        "start": 637.9599999999999,
        "temperature": 0,
        "text": " And I assume, looking through all the different data sources",
        "tokens": [
          51260,
          400,
          286,
          6552,
          11,
          1237,
          807,
          439,
          264,
          819,
          1412,
          7139,
          51444
        ]
      },
      {
        "avg_logprob": -0.2528071476862981,
        "compression_ratio": 1.606896551724138,
        "end": 643.48,
        "id": 244,
        "no_speech_prob": 0.00000685430768498918,
        "seek": 62004,
        "start": 641.64,
        "temperature": 0,
        "text": " that they're aggregating, some are",
        "tokens": [
          51444,
          300,
          436,
          434,
          16743,
          990,
          11,
          512,
          366,
          51536
        ]
      },
      {
        "avg_logprob": -0.2528071476862981,
        "compression_ratio": 1.606896551724138,
        "end": 645.48,
        "id": 245,
        "no_speech_prob": 0.00000685430768498918,
        "seek": 62004,
        "start": 643.48,
        "temperature": 0,
        "text": " updated in much more real time than others.",
        "tokens": [
          51536,
          10588,
          294,
          709,
          544,
          957,
          565,
          813,
          2357,
          13,
          51636
        ]
      },
      {
        "avg_logprob": -0.2528071476862981,
        "compression_ratio": 1.606896551724138,
        "end": 647.0799999999999,
        "id": 246,
        "no_speech_prob": 0.00000685430768498918,
        "seek": 62004,
        "start": 645.48,
        "temperature": 0,
        "text": " But for now, I'm just going to grab",
        "tokens": [
          51636,
          583,
          337,
          586,
          11,
          286,
          478,
          445,
          516,
          281,
          4444,
          51716
        ]
      },
      {
        "avg_logprob": -0.2528071476862981,
        "compression_ratio": 1.606896551724138,
        "end": 649,
        "id": 247,
        "no_speech_prob": 0.00000685430768498918,
        "seek": 62004,
        "start": 647.0799999999999,
        "temperature": 0,
        "text": " whatever the first measurement is",
        "tokens": [
          51716,
          2035,
          264,
          700,
          13160,
          307,
          51812
        ]
      },
      {
        "avg_logprob": -0.24862340780404898,
        "compression_ratio": 1.7701863354037266,
        "end": 654.4,
        "id": 248,
        "no_speech_prob": 0.0000028573151666932972,
        "seek": 64900,
        "start": 649,
        "temperature": 0,
        "text": " and try to get the value, 24.9, and the units",
        "tokens": [
          50364,
          293,
          853,
          281,
          483,
          264,
          2158,
          11,
          4022,
          13,
          24,
          11,
          293,
          264,
          6815,
          50634
        ]
      },
      {
        "avg_logprob": -0.24862340780404898,
        "compression_ratio": 1.7701863354037266,
        "end": 657.2,
        "id": 249,
        "no_speech_prob": 0.0000028573151666932972,
        "seek": 64900,
        "start": 654.4,
        "temperature": 0,
        "text": " and display that on the page itself.",
        "tokens": [
          50634,
          293,
          4674,
          300,
          322,
          264,
          3028,
          2564,
          13,
          50774
        ]
      },
      {
        "avg_logprob": -0.24862340780404898,
        "compression_ratio": 1.7701863354037266,
        "end": 660.48,
        "id": 250,
        "no_speech_prob": 0.0000028573151666932972,
        "seek": 64900,
        "start": 657.2,
        "temperature": 0,
        "text": " So what I want is air quality dot results index",
        "tokens": [
          50774,
          407,
          437,
          286,
          528,
          307,
          1988,
          3125,
          5893,
          3542,
          8186,
          50938
        ]
      },
      {
        "avg_logprob": -0.24862340780404898,
        "compression_ratio": 1.7701863354037266,
        "end": 664.96,
        "id": 251,
        "no_speech_prob": 0.0000028573151666932972,
        "seek": 64900,
        "start": 660.48,
        "temperature": 0,
        "text": " zero dot measurements index zero.",
        "tokens": [
          50938,
          4018,
          5893,
          15383,
          8186,
          4018,
          13,
          51162
        ]
      },
      {
        "avg_logprob": -0.24862340780404898,
        "compression_ratio": 1.7701863354037266,
        "end": 672.04,
        "id": 252,
        "no_speech_prob": 0.0000028573151666932972,
        "seek": 64900,
        "start": 664.96,
        "temperature": 0,
        "text": " Air quality dot results index zero dot measurements index",
        "tokens": [
          51162,
          5774,
          3125,
          5893,
          3542,
          8186,
          4018,
          5893,
          15383,
          8186,
          51516
        ]
      },
      {
        "avg_logprob": -0.24862340780404898,
        "compression_ratio": 1.7701863354037266,
        "end": 672.88,
        "id": 253,
        "no_speech_prob": 0.0000028573151666932972,
        "seek": 64900,
        "start": 672.04,
        "temperature": 0,
        "text": " zero.",
        "tokens": [
          51516,
          4018,
          13,
          51558
        ]
      },
      {
        "avg_logprob": -0.24862340780404898,
        "compression_ratio": 1.7701863354037266,
        "end": 677.2,
        "id": 254,
        "no_speech_prob": 0.0000028573151666932972,
        "seek": 64900,
        "start": 672.88,
        "temperature": 0,
        "text": " And then I need to add another sentence to my HTML page.",
        "tokens": [
          51558,
          400,
          550,
          286,
          643,
          281,
          909,
          1071,
          8174,
          281,
          452,
          17995,
          3028,
          13,
          51774
        ]
      },
      {
        "avg_logprob": -0.386018461339614,
        "compression_ratio": 1.5916230366492146,
        "end": 678.2,
        "id": 255,
        "no_speech_prob": 0.000022125601390143856,
        "seek": 67720,
        "start": 677.2,
        "temperature": 0,
        "text": " OK.",
        "tokens": [
          50364,
          2264,
          13,
          50414
        ]
      },
      {
        "avg_logprob": -0.386018461339614,
        "compression_ratio": 1.5916230366492146,
        "end": 685.48,
        "id": 256,
        "no_speech_prob": 0.000022125601390143856,
        "seek": 67720,
        "start": 678.2,
        "temperature": 0,
        "text": " I have the concentration of particulate matter",
        "tokens": [
          50414,
          286,
          362,
          264,
          9856,
          295,
          1276,
          5256,
          1871,
          50778
        ]
      },
      {
        "avg_logprob": -0.386018461339614,
        "compression_ratio": 1.5916230366492146,
        "end": 691.1600000000001,
        "id": 257,
        "no_speech_prob": 0.000022125601390143856,
        "seek": 67720,
        "start": 685.48,
        "temperature": 0,
        "text": " with a span is another span in the units last read on date.",
        "tokens": [
          50778,
          365,
          257,
          16174,
          307,
          1071,
          16174,
          294,
          264,
          6815,
          1036,
          1401,
          322,
          4002,
          13,
          51062
        ]
      },
      {
        "avg_logprob": -0.386018461339614,
        "compression_ratio": 1.5916230366492146,
        "end": 693.32,
        "id": 258,
        "no_speech_prob": 0.000022125601390143856,
        "seek": 67720,
        "start": 691.1600000000001,
        "temperature": 0,
        "text": " So I want to take that stuff from the database",
        "tokens": [
          51062,
          407,
          286,
          528,
          281,
          747,
          300,
          1507,
          490,
          264,
          8149,
          51170
        ]
      },
      {
        "avg_logprob": -0.386018461339614,
        "compression_ratio": 1.5916230366492146,
        "end": 695.96,
        "id": 259,
        "no_speech_prob": 0.000022125601390143856,
        "seek": 67720,
        "start": 693.32,
        "temperature": 0,
        "text": " and fill it in on all these spans.",
        "tokens": [
          51170,
          293,
          2836,
          309,
          294,
          322,
          439,
          613,
          44086,
          13,
          51302
        ]
      },
      {
        "avg_logprob": -0.386018461339614,
        "compression_ratio": 1.5916230366492146,
        "end": 698.6800000000001,
        "id": 260,
        "no_speech_prob": 0.000022125601390143856,
        "seek": 67720,
        "start": 695.96,
        "temperature": 0,
        "text": " So let me add a bunch more document dot get element ID",
        "tokens": [
          51302,
          407,
          718,
          385,
          909,
          257,
          3840,
          544,
          4166,
          5893,
          483,
          4478,
          7348,
          51438
        ]
      },
      {
        "avg_logprob": -0.386018461339614,
        "compression_ratio": 1.5916230366492146,
        "end": 699.2,
        "id": 261,
        "no_speech_prob": 0.000022125601390143856,
        "seek": 67720,
        "start": 698.6800000000001,
        "temperature": 0,
        "text": " calls.",
        "tokens": [
          51438,
          5498,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.386018461339614,
        "compression_ratio": 1.5916230366492146,
        "end": 704.72,
        "id": 262,
        "no_speech_prob": 0.000022125601390143856,
        "seek": 67720,
        "start": 699.2,
        "temperature": 0,
        "text": " And then I want to send all these particular span",
        "tokens": [
          51464,
          400,
          550,
          286,
          528,
          281,
          2845,
          439,
          613,
          1729,
          16174,
          51740
        ]
      },
      {
        "avg_logprob": -0.26185335795084635,
        "compression_ratio": 1.588235294117647,
        "end": 706.32,
        "id": 263,
        "no_speech_prob": 0.000985006452538073,
        "seek": 70472,
        "start": 704.72,
        "temperature": 0,
        "text": " elements to the correct piece of data",
        "tokens": [
          50364,
          4959,
          281,
          264,
          3006,
          2522,
          295,
          1412,
          50444
        ]
      },
      {
        "avg_logprob": -0.26185335795084635,
        "compression_ratio": 1.588235294117647,
        "end": 708.12,
        "id": 264,
        "no_speech_prob": 0.000985006452538073,
        "seek": 70472,
        "start": 706.32,
        "temperature": 0,
        "text": " from this air variable up here.",
        "tokens": [
          50444,
          490,
          341,
          1988,
          7006,
          493,
          510,
          13,
          50534
        ]
      },
      {
        "avg_logprob": -0.26185335795084635,
        "compression_ratio": 1.588235294117647,
        "end": 721.72,
        "id": 265,
        "no_speech_prob": 0.000985006452538073,
        "seek": 70472,
        "start": 708.12,
        "temperature": 0,
        "text": " So it'll be air dot parameter, air dot value, air dot units.",
        "tokens": [
          50534,
          407,
          309,
          603,
          312,
          1988,
          5893,
          13075,
          11,
          1988,
          5893,
          2158,
          11,
          1988,
          5893,
          6815,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.26185335795084635,
        "compression_ratio": 1.588235294117647,
        "end": 723.9200000000001,
        "id": 266,
        "no_speech_prob": 0.000985006452538073,
        "seek": 70472,
        "start": 721.72,
        "temperature": 0,
        "text": " And I think this one is called air dot last updated.",
        "tokens": [
          51214,
          400,
          286,
          519,
          341,
          472,
          307,
          1219,
          1988,
          5893,
          1036,
          10588,
          13,
          51324
        ]
      },
      {
        "avg_logprob": -0.26185335795084635,
        "compression_ratio": 1.588235294117647,
        "end": 731.28,
        "id": 267,
        "no_speech_prob": 0.000985006452538073,
        "seek": 70472,
        "start": 729,
        "temperature": 0,
        "text": " We can confirm that by seeing them all in here.",
        "tokens": [
          51578,
          492,
          393,
          9064,
          300,
          538,
          2577,
          552,
          439,
          294,
          510,
          13,
          51692
        ]
      },
      {
        "avg_logprob": -0.26185335795084635,
        "compression_ratio": 1.588235294117647,
        "end": 734.5600000000001,
        "id": 268,
        "no_speech_prob": 0.000985006452538073,
        "seek": 70472,
        "start": 731.28,
        "temperature": 0,
        "text": " Parameter unit value and last updated.",
        "tokens": [
          51692,
          34882,
          2398,
          4985,
          2158,
          293,
          1036,
          10588,
          13,
          51856
        ]
      },
      {
        "avg_logprob": -0.2394093340776098,
        "compression_ratio": 1.672340425531915,
        "end": 736.1999999999999,
        "id": 269,
        "no_speech_prob": 0.0000018738733160716947,
        "seek": 73456,
        "start": 735.4,
        "temperature": 0,
        "text": " So it's not units.",
        "tokens": [
          50406,
          407,
          309,
          311,
          406,
          6815,
          13,
          50446
        ]
      },
      {
        "avg_logprob": -0.2394093340776098,
        "compression_ratio": 1.672340425531915,
        "end": 737.28,
        "id": 270,
        "no_speech_prob": 0.0000018738733160716947,
        "seek": 73456,
        "start": 736.1999999999999,
        "temperature": 0,
        "text": " It's unit.",
        "tokens": [
          50446,
          467,
          311,
          4985,
          13,
          50500
        ]
      },
      {
        "avg_logprob": -0.2394093340776098,
        "compression_ratio": 1.672340425531915,
        "end": 738.04,
        "id": 271,
        "no_speech_prob": 0.0000018738733160716947,
        "seek": 73456,
        "start": 737.28,
        "temperature": 0,
        "text": " OK.",
        "tokens": [
          50500,
          2264,
          13,
          50538
        ]
      },
      {
        "avg_logprob": -0.2394093340776098,
        "compression_ratio": 1.672340425531915,
        "end": 741.1199999999999,
        "id": 272,
        "no_speech_prob": 0.0000018738733160716947,
        "seek": 73456,
        "start": 738.04,
        "temperature": 0,
        "text": " Let's try refreshing this.",
        "tokens": [
          50538,
          961,
          311,
          853,
          19772,
          341,
          13,
          50692
        ]
      },
      {
        "avg_logprob": -0.2394093340776098,
        "compression_ratio": 1.672340425531915,
        "end": 741.5999999999999,
        "id": 273,
        "no_speech_prob": 0.0000018738733160716947,
        "seek": 73456,
        "start": 741.1199999999999,
        "temperature": 0,
        "text": " Great.",
        "tokens": [
          50692,
          3769,
          13,
          50716
        ]
      },
      {
        "avg_logprob": -0.2394093340776098,
        "compression_ratio": 1.672340425531915,
        "end": 742.1999999999999,
        "id": 274,
        "no_speech_prob": 0.0000018738733160716947,
        "seek": 73456,
        "start": 741.5999999999999,
        "temperature": 0,
        "text": " There it is.",
        "tokens": [
          50716,
          821,
          309,
          307,
          13,
          50746
        ]
      },
      {
        "avg_logprob": -0.2394093340776098,
        "compression_ratio": 1.672340425531915,
        "end": 744.7199999999999,
        "id": 275,
        "no_speech_prob": 0.0000018738733160716947,
        "seek": 73456,
        "start": 742.1999999999999,
        "temperature": 0,
        "text": " Now we have the particulate matter reading",
        "tokens": [
          50746,
          823,
          321,
          362,
          264,
          1276,
          5256,
          1871,
          3760,
          50872
        ]
      },
      {
        "avg_logprob": -0.2394093340776098,
        "compression_ratio": 1.672340425531915,
        "end": 746.52,
        "id": 276,
        "no_speech_prob": 0.0000018738733160716947,
        "seek": 73456,
        "start": 744.7199999999999,
        "temperature": 0,
        "text": " in this paragraph as well.",
        "tokens": [
          50872,
          294,
          341,
          18865,
          382,
          731,
          13,
          50962
        ]
      },
      {
        "avg_logprob": -0.2394093340776098,
        "compression_ratio": 1.672340425531915,
        "end": 748.4,
        "id": 277,
        "no_speech_prob": 0.0000018738733160716947,
        "seek": 73456,
        "start": 746.52,
        "temperature": 0,
        "text": " Let's go to another location.",
        "tokens": [
          50962,
          961,
          311,
          352,
          281,
          1071,
          4914,
          13,
          51056
        ]
      },
      {
        "avg_logprob": -0.2394093340776098,
        "compression_ratio": 1.672340425531915,
        "end": 750.78,
        "id": 278,
        "no_speech_prob": 0.0000018738733160716947,
        "seek": 73456,
        "start": 748.4,
        "temperature": 0,
        "text": " Let's go to Mumbai.",
        "tokens": [
          51056,
          961,
          311,
          352,
          281,
          34309,
          13,
          51175
        ]
      },
      {
        "avg_logprob": -0.2394093340776098,
        "compression_ratio": 1.672340425531915,
        "end": 753.4399999999999,
        "id": 279,
        "no_speech_prob": 0.0000018738733160716947,
        "seek": 73456,
        "start": 750.78,
        "temperature": 0,
        "text": " And let's hit refresh.",
        "tokens": [
          51175,
          400,
          718,
          311,
          2045,
          15134,
          13,
          51308
        ]
      },
      {
        "avg_logprob": -0.2394093340776098,
        "compression_ratio": 1.672340425531915,
        "end": 756,
        "id": 280,
        "no_speech_prob": 0.0000018738733160716947,
        "seek": 73456,
        "start": 753.4399999999999,
        "temperature": 0,
        "text": " And there's our reading in Mumbai.",
        "tokens": [
          51308,
          400,
          456,
          311,
          527,
          3760,
          294,
          34309,
          13,
          51436
        ]
      },
      {
        "avg_logprob": -0.2394093340776098,
        "compression_ratio": 1.672340425531915,
        "end": 758.26,
        "id": 281,
        "no_speech_prob": 0.0000018738733160716947,
        "seek": 73456,
        "start": 756,
        "temperature": 0,
        "text": " So this wraps up this piece of the project.",
        "tokens": [
          51436,
          407,
          341,
          25831,
          493,
          341,
          2522,
          295,
          264,
          1716,
          13,
          51549
        ]
      },
      {
        "avg_logprob": -0.2394093340776098,
        "compression_ratio": 1.672340425531915,
        "end": 761.02,
        "id": 282,
        "no_speech_prob": 0.0000018738733160716947,
        "seek": 73456,
        "start": 758.26,
        "temperature": 0,
        "text": " I now connect to two different APIs on the server.",
        "tokens": [
          51549,
          286,
          586,
          1745,
          281,
          732,
          819,
          21445,
          322,
          264,
          7154,
          13,
          51687
        ]
      },
      {
        "avg_logprob": -0.2394093340776098,
        "compression_ratio": 1.672340425531915,
        "end": 763,
        "id": 283,
        "no_speech_prob": 0.0000018738733160716947,
        "seek": 73456,
        "start": 761.02,
        "temperature": 0,
        "text": " I get the information, both those APIs,",
        "tokens": [
          51687,
          286,
          483,
          264,
          1589,
          11,
          1293,
          729,
          21445,
          11,
          51786
        ]
      },
      {
        "avg_logprob": -0.28368050711495535,
        "compression_ratio": 1.7472527472527473,
        "end": 765.36,
        "id": 284,
        "no_speech_prob": 0.000779347843490541,
        "seek": 76300,
        "start": 763,
        "temperature": 0,
        "text": " pass them to the client, display it here on the web page.",
        "tokens": [
          50364,
          1320,
          552,
          281,
          264,
          6423,
          11,
          4674,
          309,
          510,
          322,
          264,
          3670,
          3028,
          13,
          50482
        ]
      },
      {
        "avg_logprob": -0.28368050711495535,
        "compression_ratio": 1.7472527472527473,
        "end": 767.48,
        "id": 285,
        "no_speech_prob": 0.000779347843490541,
        "seek": 76300,
        "start": 765.36,
        "temperature": 0,
        "text": " Before I go into the next video, I probably",
        "tokens": [
          50482,
          4546,
          286,
          352,
          666,
          264,
          958,
          960,
          11,
          286,
          1391,
          50588
        ]
      },
      {
        "avg_logprob": -0.28368050711495535,
        "compression_ratio": 1.7472527472527473,
        "end": 769.68,
        "id": 286,
        "no_speech_prob": 0.000779347843490541,
        "seek": 76300,
        "start": 767.48,
        "temperature": 0,
        "text": " should add some form of error handling.",
        "tokens": [
          50588,
          820,
          909,
          512,
          1254,
          295,
          6713,
          13175,
          13,
          50698
        ]
      },
      {
        "avg_logprob": -0.28368050711495535,
        "compression_ratio": 1.7472527472527473,
        "end": 771.68,
        "id": 287,
        "no_speech_prob": 0.000779347843490541,
        "seek": 76300,
        "start": 769.68,
        "temperature": 0,
        "text": " There's so many things that could go wrong here.",
        "tokens": [
          50698,
          821,
          311,
          370,
          867,
          721,
          300,
          727,
          352,
          2085,
          510,
          13,
          50798
        ]
      },
      {
        "avg_logprob": -0.28368050711495535,
        "compression_ratio": 1.7472527472527473,
        "end": 774.44,
        "id": 288,
        "no_speech_prob": 0.000779347843490541,
        "seek": 76300,
        "start": 771.68,
        "temperature": 0,
        "text": " And I'm not going to do comprehensive error handling",
        "tokens": [
          50798,
          400,
          286,
          478,
          406,
          516,
          281,
          360,
          13914,
          6713,
          13175,
          50936
        ]
      },
      {
        "avg_logprob": -0.28368050711495535,
        "compression_ratio": 1.7472527472527473,
        "end": 776.28,
        "id": 289,
        "no_speech_prob": 0.000779347843490541,
        "seek": 76300,
        "start": 774.44,
        "temperature": 0,
        "text": " in every possible scenario by any means.",
        "tokens": [
          50936,
          294,
          633,
          1944,
          9005,
          538,
          604,
          1355,
          13,
          51028
        ]
      },
      {
        "avg_logprob": -0.28368050711495535,
        "compression_ratio": 1.7472527472527473,
        "end": 779.16,
        "id": 290,
        "no_speech_prob": 0.000779347843490541,
        "seek": 76300,
        "start": 776.28,
        "temperature": 0,
        "text": " But it's something interesting to try to break this project",
        "tokens": [
          51028,
          583,
          309,
          311,
          746,
          1880,
          281,
          853,
          281,
          1821,
          341,
          1716,
          51172
        ]
      },
      {
        "avg_logprob": -0.28368050711495535,
        "compression_ratio": 1.7472527472527473,
        "end": 781.2,
        "id": 291,
        "no_speech_prob": 0.000779347843490541,
        "seek": 76300,
        "start": 779.16,
        "temperature": 0,
        "text": " as much as you can and keep writing code to account for",
        "tokens": [
          51172,
          382,
          709,
          382,
          291,
          393,
          293,
          1066,
          3579,
          3089,
          281,
          2696,
          337,
          51274
        ]
      },
      {
        "avg_logprob": -0.28368050711495535,
        "compression_ratio": 1.7472527472527473,
        "end": 781.56,
        "id": 292,
        "no_speech_prob": 0.000779347843490541,
        "seek": 76300,
        "start": 781.2,
        "temperature": 0,
        "text": " that.",
        "tokens": [
          51274,
          300,
          13,
          51292
        ]
      },
      {
        "avg_logprob": -0.28368050711495535,
        "compression_ratio": 1.7472527472527473,
        "end": 784.24,
        "id": 293,
        "no_speech_prob": 0.000779347843490541,
        "seek": 76300,
        "start": 781.56,
        "temperature": 0,
        "text": " But one thing I know I could do, because I discovered it earlier,",
        "tokens": [
          51292,
          583,
          472,
          551,
          286,
          458,
          286,
          727,
          360,
          11,
          570,
          286,
          6941,
          309,
          3071,
          11,
          51426
        ]
      },
      {
        "avg_logprob": -0.28368050711495535,
        "compression_ratio": 1.7472527472527473,
        "end": 786.82,
        "id": 294,
        "no_speech_prob": 0.000779347843490541,
        "seek": 76300,
        "start": 784.24,
        "temperature": 0,
        "text": " is I could go to Shanghai, where there are no air quality",
        "tokens": [
          51426,
          307,
          286,
          727,
          352,
          281,
          26135,
          11,
          689,
          456,
          366,
          572,
          1988,
          3125,
          51555
        ]
      },
      {
        "avg_logprob": -0.28368050711495535,
        "compression_ratio": 1.7472527472527473,
        "end": 787.48,
        "id": 295,
        "no_speech_prob": 0.000779347843490541,
        "seek": 76300,
        "start": 786.82,
        "temperature": 0,
        "text": " readings.",
        "tokens": [
          51555,
          27319,
          13,
          51588
        ]
      },
      {
        "avg_logprob": -0.28368050711495535,
        "compression_ratio": 1.7472527472527473,
        "end": 788.48,
        "id": 296,
        "no_speech_prob": 0.000779347843490541,
        "seek": 76300,
        "start": 787.48,
        "temperature": 0,
        "text": " And I could hit refresh.",
        "tokens": [
          51588,
          400,
          286,
          727,
          2045,
          15134,
          13,
          51638
        ]
      },
      {
        "avg_logprob": -0.28368050711495535,
        "compression_ratio": 1.7472527472527473,
        "end": 790.08,
        "id": 297,
        "no_speech_prob": 0.000779347843490541,
        "seek": 76300,
        "start": 788.48,
        "temperature": 0,
        "text": " And we'll see I get an error here.",
        "tokens": [
          51638,
          400,
          321,
          603,
          536,
          286,
          483,
          364,
          6713,
          510,
          13,
          51718
        ]
      },
      {
        "avg_logprob": -0.28368050711495535,
        "compression_ratio": 1.7472527472527473,
        "end": 792.72,
        "id": 298,
        "no_speech_prob": 0.000779347843490541,
        "seek": 76300,
        "start": 790.08,
        "temperature": 0,
        "text": " On the one hand, as an end user, is",
        "tokens": [
          51718,
          1282,
          264,
          472,
          1011,
          11,
          382,
          364,
          917,
          4195,
          11,
          307,
          51850
        ]
      },
      {
        "avg_logprob": -0.2379884158863741,
        "compression_ratio": 1.711111111111111,
        "end": 793.76,
        "id": 299,
        "no_speech_prob": 0.000019525843526935205,
        "seek": 79272,
        "start": 792.9200000000001,
        "temperature": 0,
        "text": " experience OK?",
        "tokens": [
          50374,
          1752,
          2264,
          30,
          50416
        ]
      },
      {
        "avg_logprob": -0.2379884158863741,
        "compression_ratio": 1.711111111111111,
        "end": 794.8000000000001,
        "id": 300,
        "no_speech_prob": 0.000019525843526935205,
        "seek": 79272,
        "start": 793.76,
        "temperature": 0,
        "text": " I mean, you have to ask yourself,",
        "tokens": [
          50416,
          286,
          914,
          11,
          291,
          362,
          281,
          1029,
          1803,
          11,
          50468
        ]
      },
      {
        "avg_logprob": -0.2379884158863741,
        "compression_ratio": 1.711111111111111,
        "end": 796.8000000000001,
        "id": 301,
        "no_speech_prob": 0.000019525843526935205,
        "seek": 79272,
        "start": 794.8000000000001,
        "temperature": 0,
        "text": " why am I making this project in the first place?",
        "tokens": [
          50468,
          983,
          669,
          286,
          1455,
          341,
          1716,
          294,
          264,
          700,
          1081,
          30,
          50568
        ]
      },
      {
        "avg_logprob": -0.2379884158863741,
        "compression_ratio": 1.711111111111111,
        "end": 799.32,
        "id": 302,
        "no_speech_prob": 0.000019525843526935205,
        "seek": 79272,
        "start": 796.8000000000001,
        "temperature": 0,
        "text": " But at a minimum, I could be able to handle",
        "tokens": [
          50568,
          583,
          412,
          257,
          7285,
          11,
          286,
          727,
          312,
          1075,
          281,
          4813,
          50694
        ]
      },
      {
        "avg_logprob": -0.2379884158863741,
        "compression_ratio": 1.711111111111111,
        "end": 800.6800000000001,
        "id": 303,
        "no_speech_prob": 0.000019525843526935205,
        "seek": 79272,
        "start": 799.32,
        "temperature": 0,
        "text": " this a bit more elegantly.",
        "tokens": [
          50694,
          341,
          257,
          857,
          544,
          14459,
          3627,
          13,
          50762
        ]
      },
      {
        "avg_logprob": -0.2379884158863741,
        "compression_ratio": 1.711111111111111,
        "end": 803.08,
        "id": 304,
        "no_speech_prob": 0.000019525843526935205,
        "seek": 79272,
        "start": 800.6800000000001,
        "temperature": 0,
        "text": " And so this is cannot read property measurements",
        "tokens": [
          50762,
          400,
          370,
          341,
          307,
          2644,
          1401,
          4707,
          15383,
          50882
        ]
      },
      {
        "avg_logprob": -0.2379884158863741,
        "compression_ratio": 1.711111111111111,
        "end": 804.1800000000001,
        "id": 305,
        "no_speech_prob": 0.000019525843526935205,
        "seek": 79272,
        "start": 803.08,
        "temperature": 0,
        "text": " of undefined.",
        "tokens": [
          50882,
          295,
          674,
          5666,
          2001,
          13,
          50937
        ]
      },
      {
        "avg_logprob": -0.2379884158863741,
        "compression_ratio": 1.711111111111111,
        "end": 809.5600000000001,
        "id": 306,
        "no_speech_prob": 0.000019525843526935205,
        "seek": 79272,
        "start": 804.1800000000001,
        "temperature": 0,
        "text": " That's because here, there is no measurements property,",
        "tokens": [
          50937,
          663,
          311,
          570,
          510,
          11,
          456,
          307,
          572,
          15383,
          4707,
          11,
          51206
        ]
      },
      {
        "avg_logprob": -0.2379884158863741,
        "compression_ratio": 1.711111111111111,
        "end": 811.6,
        "id": 307,
        "no_speech_prob": 0.000019525843526935205,
        "seek": 79272,
        "start": 809.5600000000001,
        "temperature": 0,
        "text": " because there were no results.",
        "tokens": [
          51206,
          570,
          456,
          645,
          572,
          3542,
          13,
          51308
        ]
      },
      {
        "avg_logprob": -0.2379884158863741,
        "compression_ratio": 1.711111111111111,
        "end": 813.28,
        "id": 308,
        "no_speech_prob": 0.000019525843526935205,
        "seek": 79272,
        "start": 811.6,
        "temperature": 0,
        "text": " Now, what I often do in error handling",
        "tokens": [
          51308,
          823,
          11,
          437,
          286,
          2049,
          360,
          294,
          6713,
          13175,
          51392
        ]
      },
      {
        "avg_logprob": -0.2379884158863741,
        "compression_ratio": 1.711111111111111,
        "end": 814.5600000000001,
        "id": 309,
        "no_speech_prob": 0.000019525843526935205,
        "seek": 79272,
        "start": 813.28,
        "temperature": 0,
        "text": " is I start to add some if statements.",
        "tokens": [
          51392,
          307,
          286,
          722,
          281,
          909,
          512,
          498,
          12363,
          13,
          51456
        ]
      },
      {
        "avg_logprob": -0.2379884158863741,
        "compression_ratio": 1.711111111111111,
        "end": 816.44,
        "id": 310,
        "no_speech_prob": 0.000019525843526935205,
        "seek": 79272,
        "start": 814.5600000000001,
        "temperature": 0,
        "text": " OK, well, if there are no measurements,",
        "tokens": [
          51456,
          2264,
          11,
          731,
          11,
          498,
          456,
          366,
          572,
          15383,
          11,
          51550
        ]
      },
      {
        "avg_logprob": -0.2379884158863741,
        "compression_ratio": 1.711111111111111,
        "end": 818.5600000000001,
        "id": 311,
        "no_speech_prob": 0.000019525843526935205,
        "seek": 79272,
        "start": 816.44,
        "temperature": 0,
        "text": " if the length of the array is less than this.",
        "tokens": [
          51550,
          498,
          264,
          4641,
          295,
          264,
          10225,
          307,
          1570,
          813,
          341,
          13,
          51656
        ]
      },
      {
        "avg_logprob": -0.2379884158863741,
        "compression_ratio": 1.711111111111111,
        "end": 822.4,
        "id": 312,
        "no_speech_prob": 0.000019525843526935205,
        "seek": 79272,
        "start": 818.5600000000001,
        "temperature": 0,
        "text": " But one way that I can account for a variety of any error",
        "tokens": [
          51656,
          583,
          472,
          636,
          300,
          286,
          393,
          2696,
          337,
          257,
          5673,
          295,
          604,
          6713,
          51848
        ]
      },
      {
        "avg_logprob": -0.2431621661765038,
        "compression_ratio": 1.7836257309941521,
        "end": 825.48,
        "id": 313,
        "no_speech_prob": 0.00009314544877270237,
        "seek": 82240,
        "start": 822.4,
        "temperature": 0,
        "text": " or specific errors is by using try catch.",
        "tokens": [
          50364,
          420,
          2685,
          13603,
          307,
          538,
          1228,
          853,
          3745,
          13,
          50518
        ]
      },
      {
        "avg_logprob": -0.2431621661765038,
        "compression_ratio": 1.7836257309941521,
        "end": 827.9599999999999,
        "id": 314,
        "no_speech_prob": 0.00009314544877270237,
        "seek": 82240,
        "start": 825.48,
        "temperature": 0,
        "text": " A try catch statement is a block of code.",
        "tokens": [
          50518,
          316,
          853,
          3745,
          5629,
          307,
          257,
          3461,
          295,
          3089,
          13,
          50642
        ]
      },
      {
        "avg_logprob": -0.2431621661765038,
        "compression_ratio": 1.7836257309941521,
        "end": 829.28,
        "id": 315,
        "no_speech_prob": 0.00009314544877270237,
        "seek": 82240,
        "start": 827.9599999999999,
        "temperature": 0,
        "text": " It's code that you want to try.",
        "tokens": [
          50642,
          467,
          311,
          3089,
          300,
          291,
          528,
          281,
          853,
          13,
          50708
        ]
      },
      {
        "avg_logprob": -0.2431621661765038,
        "compression_ratio": 1.7836257309941521,
        "end": 831.92,
        "id": 316,
        "no_speech_prob": 0.00009314544877270237,
        "seek": 82240,
        "start": 829.28,
        "temperature": 0,
        "text": " And if anything goes wrong while you're trying that code out,",
        "tokens": [
          50708,
          400,
          498,
          1340,
          1709,
          2085,
          1339,
          291,
          434,
          1382,
          300,
          3089,
          484,
          11,
          50840
        ]
      },
      {
        "avg_logprob": -0.2431621661765038,
        "compression_ratio": 1.7836257309941521,
        "end": 835.3199999999999,
        "id": 317,
        "no_speech_prob": 0.00009314544877270237,
        "seek": 82240,
        "start": 831.92,
        "temperature": 0,
        "text": " you could then catch the error and execute a different code",
        "tokens": [
          50840,
          291,
          727,
          550,
          3745,
          264,
          6713,
          293,
          14483,
          257,
          819,
          3089,
          51010
        ]
      },
      {
        "avg_logprob": -0.2431621661765038,
        "compression_ratio": 1.7836257309941521,
        "end": 836.4399999999999,
        "id": 318,
        "no_speech_prob": 0.00009314544877270237,
        "seek": 82240,
        "start": 835.3199999999999,
        "temperature": 0,
        "text": " based on what that area is.",
        "tokens": [
          51010,
          2361,
          322,
          437,
          300,
          1859,
          307,
          13,
          51066
        ]
      },
      {
        "avg_logprob": -0.2431621661765038,
        "compression_ratio": 1.7836257309941521,
        "end": 838.68,
        "id": 319,
        "no_speech_prob": 0.00009314544877270237,
        "seek": 82240,
        "start": 836.4399999999999,
        "temperature": 0,
        "text": " And you can handle different errors in different ways,",
        "tokens": [
          51066,
          400,
          291,
          393,
          4813,
          819,
          13603,
          294,
          819,
          2098,
          11,
          51178
        ]
      },
      {
        "avg_logprob": -0.2431621661765038,
        "compression_ratio": 1.7836257309941521,
        "end": 840.28,
        "id": 320,
        "no_speech_prob": 0.00009314544877270237,
        "seek": 82240,
        "start": 838.68,
        "temperature": 0,
        "text": " or any error in the same way.",
        "tokens": [
          51178,
          420,
          604,
          6713,
          294,
          264,
          912,
          636,
          13,
          51258
        ]
      },
      {
        "avg_logprob": -0.2431621661765038,
        "compression_ratio": 1.7836257309941521,
        "end": 841.52,
        "id": 321,
        "no_speech_prob": 0.00009314544877270237,
        "seek": 82240,
        "start": 840.28,
        "temperature": 0,
        "text": " I'm going to use it in the simplest way.",
        "tokens": [
          51258,
          286,
          478,
          516,
          281,
          764,
          309,
          294,
          264,
          22811,
          636,
          13,
          51320
        ]
      },
      {
        "avg_logprob": -0.2431621661765038,
        "compression_ratio": 1.7836257309941521,
        "end": 844.1999999999999,
        "id": 322,
        "no_speech_prob": 0.00009314544877270237,
        "seek": 82240,
        "start": 841.52,
        "temperature": 0,
        "text": " And I'll refer you to the MDM web docs to read more about it.",
        "tokens": [
          51320,
          400,
          286,
          603,
          2864,
          291,
          281,
          264,
          22521,
          44,
          3670,
          45623,
          281,
          1401,
          544,
          466,
          309,
          13,
          51454
        ]
      },
      {
        "avg_logprob": -0.2431621661765038,
        "compression_ratio": 1.7836257309941521,
        "end": 845.6999999999999,
        "id": 323,
        "no_speech_prob": 0.00009314544877270237,
        "seek": 82240,
        "start": 844.1999999999999,
        "temperature": 0,
        "text": " And I also have another video where",
        "tokens": [
          51454,
          400,
          286,
          611,
          362,
          1071,
          960,
          689,
          51529
        ]
      },
      {
        "avg_logprob": -0.2431621661765038,
        "compression_ratio": 1.7836257309941521,
        "end": 847.78,
        "id": 324,
        "no_speech_prob": 0.00009314544877270237,
        "seek": 82240,
        "start": 845.6999999999999,
        "temperature": 0,
        "text": " I cover it a little bit as part of my series",
        "tokens": [
          51529,
          286,
          2060,
          309,
          257,
          707,
          857,
          382,
          644,
          295,
          452,
          2638,
          51633
        ]
      },
      {
        "avg_logprob": -0.2431621661765038,
        "compression_ratio": 1.7836257309941521,
        "end": 849.76,
        "id": 325,
        "no_speech_prob": 0.00009314544877270237,
        "seek": 82240,
        "start": 847.78,
        "temperature": 0,
        "text": " on async await and promises.",
        "tokens": [
          51633,
          322,
          382,
          34015,
          19670,
          293,
          16403,
          13,
          51732
        ]
      },
      {
        "avg_logprob": -0.2431621661765038,
        "compression_ratio": 1.7836257309941521,
        "end": 851.66,
        "id": 326,
        "no_speech_prob": 0.00009314544877270237,
        "seek": 82240,
        "start": 849.76,
        "temperature": 0,
        "text": " So for right here, right now, all I want to do",
        "tokens": [
          51732,
          407,
          337,
          558,
          510,
          11,
          558,
          586,
          11,
          439,
          286,
          528,
          281,
          360,
          51827
        ]
      },
      {
        "avg_logprob": -0.2798652103969029,
        "compression_ratio": 1.795275590551181,
        "end": 855.02,
        "id": 327,
        "no_speech_prob": 0.000013631328329211101,
        "seek": 85166,
        "start": 851.7199999999999,
        "temperature": 0,
        "text": " is I just want to try all this code.",
        "tokens": [
          50367,
          307,
          286,
          445,
          528,
          281,
          853,
          439,
          341,
          3089,
          13,
          50532
        ]
      },
      {
        "avg_logprob": -0.2798652103969029,
        "compression_ratio": 1.795275590551181,
        "end": 857.38,
        "id": 328,
        "no_speech_prob": 0.000013631328329211101,
        "seek": 85166,
        "start": 855.02,
        "temperature": 0,
        "text": " I'm going to say try.",
        "tokens": [
          50532,
          286,
          478,
          516,
          281,
          584,
          853,
          13,
          50650
        ]
      },
      {
        "avg_logprob": -0.2798652103969029,
        "compression_ratio": 1.795275590551181,
        "end": 860.3,
        "id": 329,
        "no_speech_prob": 0.000013631328329211101,
        "seek": 85166,
        "start": 857.38,
        "temperature": 0,
        "text": " And then I'll put the closed curly brackets at the end.",
        "tokens": [
          50650,
          400,
          550,
          286,
          603,
          829,
          264,
          5395,
          32066,
          26179,
          412,
          264,
          917,
          13,
          50796
        ]
      },
      {
        "avg_logprob": -0.2798652103969029,
        "compression_ratio": 1.795275590551181,
        "end": 861.86,
        "id": 330,
        "no_speech_prob": 0.000013631328329211101,
        "seek": 85166,
        "start": 860.3,
        "temperature": 0,
        "text": " And then I'm going to say catch.",
        "tokens": [
          50796,
          400,
          550,
          286,
          478,
          516,
          281,
          584,
          3745,
          13,
          50874
        ]
      },
      {
        "avg_logprob": -0.2798652103969029,
        "compression_ratio": 1.795275590551181,
        "end": 864.3399999999999,
        "id": 331,
        "no_speech_prob": 0.000013631328329211101,
        "seek": 85166,
        "start": 861.86,
        "temperature": 0,
        "text": " And then I'm going to give an argument like error.",
        "tokens": [
          50874,
          400,
          550,
          286,
          478,
          516,
          281,
          976,
          364,
          6770,
          411,
          6713,
          13,
          50998
        ]
      },
      {
        "avg_logprob": -0.2798652103969029,
        "compression_ratio": 1.795275590551181,
        "end": 866.98,
        "id": 332,
        "no_speech_prob": 0.000013631328329211101,
        "seek": 85166,
        "start": 864.3399999999999,
        "temperature": 0,
        "text": " And then basically, I can say I'm just",
        "tokens": [
          50998,
          400,
          550,
          1936,
          11,
          286,
          393,
          584,
          286,
          478,
          445,
          51130
        ]
      },
      {
        "avg_logprob": -0.2798652103969029,
        "compression_ratio": 1.795275590551181,
        "end": 873.06,
        "id": 333,
        "no_speech_prob": 0.000013631328329211101,
        "seek": 85166,
        "start": 866.98,
        "temperature": 0,
        "text": " going to add right now console.log something went wrong.",
        "tokens": [
          51130,
          516,
          281,
          909,
          558,
          586,
          11076,
          13,
          4987,
          746,
          1437,
          2085,
          13,
          51434
        ]
      },
      {
        "avg_logprob": -0.2798652103969029,
        "compression_ratio": 1.795275590551181,
        "end": 874.5799999999999,
        "id": 334,
        "no_speech_prob": 0.000013631328329211101,
        "seek": 85166,
        "start": 873.06,
        "temperature": 0,
        "text": " Now, this is not good error handling.",
        "tokens": [
          51434,
          823,
          11,
          341,
          307,
          406,
          665,
          6713,
          13175,
          13,
          51510
        ]
      },
      {
        "avg_logprob": -0.2798652103969029,
        "compression_ratio": 1.795275590551181,
        "end": 875.66,
        "id": 335,
        "no_speech_prob": 0.000013631328329211101,
        "seek": 85166,
        "start": 874.5799999999999,
        "temperature": 0,
        "text": " But you can see the idea.",
        "tokens": [
          51510,
          583,
          291,
          393,
          536,
          264,
          1558,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.2798652103969029,
        "compression_ratio": 1.795275590551181,
        "end": 876.6999999999999,
        "id": 336,
        "no_speech_prob": 0.000013631328329211101,
        "seek": 85166,
        "start": 875.66,
        "temperature": 0,
        "text": " Try all this code.",
        "tokens": [
          51564,
          6526,
          439,
          341,
          3089,
          13,
          51616
        ]
      },
      {
        "avg_logprob": -0.2798652103969029,
        "compression_ratio": 1.795275590551181,
        "end": 878.62,
        "id": 337,
        "no_speech_prob": 0.000013631328329211101,
        "seek": 85166,
        "start": 876.6999999999999,
        "temperature": 0,
        "text": " Anything goes wrong, spit that out.",
        "tokens": [
          51616,
          11998,
          1709,
          2085,
          11,
          22127,
          300,
          484,
          13,
          51712
        ]
      },
      {
        "avg_logprob": -0.2798652103969029,
        "compression_ratio": 1.795275590551181,
        "end": 880.38,
        "id": 338,
        "no_speech_prob": 0.000013631328329211101,
        "seek": 85166,
        "start": 878.62,
        "temperature": 0,
        "text": " I'll go back to the web page, hit refresh.",
        "tokens": [
          51712,
          286,
          603,
          352,
          646,
          281,
          264,
          3670,
          3028,
          11,
          2045,
          15134,
          13,
          51800
        ]
      },
      {
        "avg_logprob": -0.2344556933771955,
        "compression_ratio": 1.7118055555555556,
        "end": 882.82,
        "id": 339,
        "no_speech_prob": 0.00008092724601738155,
        "seek": 88038,
        "start": 880.38,
        "temperature": 0,
        "text": " And we can see, ah, something went wrong.",
        "tokens": [
          50364,
          400,
          321,
          393,
          536,
          11,
          3716,
          11,
          746,
          1437,
          2085,
          13,
          50486
        ]
      },
      {
        "avg_logprob": -0.2344556933771955,
        "compression_ratio": 1.7118055555555556,
        "end": 885.66,
        "id": 340,
        "no_speech_prob": 0.00008092724601738155,
        "seek": 88038,
        "start": 882.82,
        "temperature": 0,
        "text": " Now, this isn't really doing excellent error handling.",
        "tokens": [
          50486,
          823,
          11,
          341,
          1943,
          380,
          534,
          884,
          7103,
          6713,
          13175,
          13,
          50628
        ]
      },
      {
        "avg_logprob": -0.2344556933771955,
        "compression_ratio": 1.7118055555555556,
        "end": 888.7,
        "id": 341,
        "no_speech_prob": 0.00008092724601738155,
        "seek": 88038,
        "start": 885.66,
        "temperature": 0,
        "text": " In fact, all I'm really doing is exactly what it would do by",
        "tokens": [
          50628,
          682,
          1186,
          11,
          439,
          286,
          478,
          534,
          884,
          307,
          2293,
          437,
          309,
          576,
          360,
          538,
          50780
        ]
      },
      {
        "avg_logprob": -0.2344556933771955,
        "compression_ratio": 1.7118055555555556,
        "end": 889.66,
        "id": 342,
        "no_speech_prob": 0.00008092724601738155,
        "seek": 88038,
        "start": 888.7,
        "temperature": 0,
        "text": " default anyway.",
        "tokens": [
          50780,
          7576,
          4033,
          13,
          50828
        ]
      },
      {
        "avg_logprob": -0.2344556933771955,
        "compression_ratio": 1.7118055555555556,
        "end": 891.82,
        "id": 343,
        "no_speech_prob": 0.00008092724601738155,
        "seek": 88038,
        "start": 889.66,
        "temperature": 0,
        "text": " Because I could just say console.error,",
        "tokens": [
          50828,
          1436,
          286,
          727,
          445,
          584,
          11076,
          13,
          260,
          2874,
          11,
          50936
        ]
      },
      {
        "avg_logprob": -0.2344556933771955,
        "compression_ratio": 1.7118055555555556,
        "end": 894.26,
        "id": 344,
        "no_speech_prob": 0.00008092724601738155,
        "seek": 88038,
        "start": 891.82,
        "temperature": 0,
        "text": " which will just log something but in red.",
        "tokens": [
          50936,
          597,
          486,
          445,
          3565,
          746,
          457,
          294,
          2182,
          13,
          51058
        ]
      },
      {
        "avg_logprob": -0.2344556933771955,
        "compression_ratio": 1.7118055555555556,
        "end": 896.08,
        "id": 345,
        "no_speech_prob": 0.00008092724601738155,
        "seek": 88038,
        "start": 894.26,
        "temperature": 0,
        "text": " And I could log that error itself.",
        "tokens": [
          51058,
          400,
          286,
          727,
          3565,
          300,
          6713,
          2564,
          13,
          51149
        ]
      },
      {
        "avg_logprob": -0.2344556933771955,
        "compression_ratio": 1.7118055555555556,
        "end": 897.58,
        "id": 346,
        "no_speech_prob": 0.00008092724601738155,
        "seek": 88038,
        "start": 896.08,
        "temperature": 0,
        "text": " So now if I hit refresh, you can see",
        "tokens": [
          51149,
          407,
          586,
          498,
          286,
          2045,
          15134,
          11,
          291,
          393,
          536,
          51224
        ]
      },
      {
        "avg_logprob": -0.2344556933771955,
        "compression_ratio": 1.7118055555555556,
        "end": 899.5,
        "id": 347,
        "no_speech_prob": 0.00008092724601738155,
        "seek": 88038,
        "start": 897.58,
        "temperature": 0,
        "text": " this is basically what it was before.",
        "tokens": [
          51224,
          341,
          307,
          1936,
          437,
          309,
          390,
          949,
          13,
          51320
        ]
      },
      {
        "avg_logprob": -0.2344556933771955,
        "compression_ratio": 1.7118055555555556,
        "end": 902.54,
        "id": 348,
        "no_speech_prob": 0.00008092724601738155,
        "seek": 88038,
        "start": 899.5,
        "temperature": 0,
        "text": " But I could do something more specific here.",
        "tokens": [
          51320,
          583,
          286,
          727,
          360,
          746,
          544,
          2685,
          510,
          13,
          51472
        ]
      },
      {
        "avg_logprob": -0.2344556933771955,
        "compression_ratio": 1.7118055555555556,
        "end": 905.26,
        "id": 349,
        "no_speech_prob": 0.00008092724601738155,
        "seek": 88038,
        "start": 902.54,
        "temperature": 0,
        "text": " Like I could create, I could fill in these DOM elements",
        "tokens": [
          51472,
          1743,
          286,
          727,
          1884,
          11,
          286,
          727,
          2836,
          294,
          613,
          35727,
          4959,
          51608
        ]
      },
      {
        "avg_logprob": -0.2344556933771955,
        "compression_ratio": 1.7118055555555556,
        "end": 906.94,
        "id": 350,
        "no_speech_prob": 0.00008092724601738155,
        "seek": 88038,
        "start": 905.26,
        "temperature": 0,
        "text": " like no reading available.",
        "tokens": [
          51608,
          411,
          572,
          3760,
          2435,
          13,
          51692
        ]
      },
      {
        "avg_logprob": -0.2137926287121243,
        "compression_ratio": 1.7692307692307692,
        "end": 908.6600000000001,
        "id": 351,
        "no_speech_prob": 0.00023782075732015073,
        "seek": 90694,
        "start": 906.94,
        "temperature": 0,
        "text": " I could take this right here.",
        "tokens": [
          50364,
          286,
          727,
          747,
          341,
          558,
          510,
          13,
          50450
        ]
      },
      {
        "avg_logprob": -0.2137926287121243,
        "compression_ratio": 1.7692307692307692,
        "end": 911.86,
        "id": 352,
        "no_speech_prob": 0.00023782075732015073,
        "seek": 90694,
        "start": 908.6600000000001,
        "temperature": 0,
        "text": " And I could put this down here.",
        "tokens": [
          50450,
          400,
          286,
          727,
          829,
          341,
          760,
          510,
          13,
          50610
        ]
      },
      {
        "avg_logprob": -0.2137926287121243,
        "compression_ratio": 1.7692307692307692,
        "end": 914.22,
        "id": 353,
        "no_speech_prob": 0.00023782075732015073,
        "seek": 90694,
        "start": 911.86,
        "temperature": 0,
        "text": " And I could say no reading.",
        "tokens": [
          50610,
          400,
          286,
          727,
          584,
          572,
          3760,
          13,
          50728
        ]
      },
      {
        "avg_logprob": -0.2137926287121243,
        "compression_ratio": 1.7692307692307692,
        "end": 916.1400000000001,
        "id": 354,
        "no_speech_prob": 0.00023782075732015073,
        "seek": 90694,
        "start": 914.22,
        "temperature": 0,
        "text": " So now if I go back to the page and refresh,",
        "tokens": [
          50728,
          407,
          586,
          498,
          286,
          352,
          646,
          281,
          264,
          3028,
          293,
          15134,
          11,
          50824
        ]
      },
      {
        "avg_logprob": -0.2137926287121243,
        "compression_ratio": 1.7692307692307692,
        "end": 919.7800000000001,
        "id": 355,
        "no_speech_prob": 0.00023782075732015073,
        "seek": 90694,
        "start": 916.1400000000001,
        "temperature": 0,
        "text": " we can see, well, at least it says no reading there.",
        "tokens": [
          50824,
          321,
          393,
          536,
          11,
          731,
          11,
          412,
          1935,
          309,
          1619,
          572,
          3760,
          456,
          13,
          51006
        ]
      },
      {
        "avg_logprob": -0.2137926287121243,
        "compression_ratio": 1.7692307692307692,
        "end": 921.5,
        "id": 356,
        "no_speech_prob": 0.00023782075732015073,
        "seek": 90694,
        "start": 919.7800000000001,
        "temperature": 0,
        "text": " So as an exercise to you, I might",
        "tokens": [
          51006,
          407,
          382,
          364,
          5380,
          281,
          291,
          11,
          286,
          1062,
          51092
        ]
      },
      {
        "avg_logprob": -0.2137926287121243,
        "compression_ratio": 1.7692307692307692,
        "end": 924.3000000000001,
        "id": 357,
        "no_speech_prob": 0.00023782075732015073,
        "seek": 90694,
        "start": 921.5,
        "temperature": 0,
        "text": " suggest that you handle the errors more thoughtfully.",
        "tokens": [
          51092,
          3402,
          300,
          291,
          4813,
          264,
          13603,
          544,
          1194,
          2277,
          13,
          51232
        ]
      },
      {
        "avg_logprob": -0.2137926287121243,
        "compression_ratio": 1.7692307692307692,
        "end": 926.7800000000001,
        "id": 358,
        "no_speech_prob": 0.00023782075732015073,
        "seek": 90694,
        "start": 924.3000000000001,
        "temperature": 0,
        "text": " Maybe you completely change what this sentence says.",
        "tokens": [
          51232,
          2704,
          291,
          2584,
          1319,
          437,
          341,
          8174,
          1619,
          13,
          51356
        ]
      },
      {
        "avg_logprob": -0.2137926287121243,
        "compression_ratio": 1.7692307692307692,
        "end": 928.1400000000001,
        "id": 359,
        "no_speech_prob": 0.00023782075732015073,
        "seek": 90694,
        "start": 926.7800000000001,
        "temperature": 0,
        "text": " And ultimately, really, something",
        "tokens": [
          51356,
          400,
          6284,
          11,
          534,
          11,
          746,
          51424
        ]
      },
      {
        "avg_logprob": -0.2137926287121243,
        "compression_ratio": 1.7692307692307692,
        "end": 930.74,
        "id": 360,
        "no_speech_prob": 0.00023782075732015073,
        "seek": 90694,
        "start": 928.1400000000001,
        "temperature": 0,
        "text": " that you might want to do before you move on to the next video",
        "tokens": [
          51424,
          300,
          291,
          1062,
          528,
          281,
          360,
          949,
          291,
          1286,
          322,
          281,
          264,
          958,
          960,
          51554
        ]
      },
      {
        "avg_logprob": -0.2137926287121243,
        "compression_ratio": 1.7692307692307692,
        "end": 932.9000000000001,
        "id": 361,
        "no_speech_prob": 0.00023782075732015073,
        "seek": 90694,
        "start": 930.74,
        "temperature": 0,
        "text": " is design this or rewrite the narrative in a more",
        "tokens": [
          51554,
          307,
          1715,
          341,
          420,
          28132,
          264,
          9977,
          294,
          257,
          544,
          51662
        ]
      },
      {
        "avg_logprob": -0.2137926287121243,
        "compression_ratio": 1.7692307692307692,
        "end": 933.9200000000001,
        "id": 362,
        "no_speech_prob": 0.00023782075732015073,
        "seek": 90694,
        "start": 932.9000000000001,
        "temperature": 0,
        "text": " thoughtful way.",
        "tokens": [
          51662,
          21566,
          636,
          13,
          51713
        ]
      },
      {
        "avg_logprob": -0.2137926287121243,
        "compression_ratio": 1.7692307692307692,
        "end": 936.0600000000001,
        "id": 363,
        "no_speech_prob": 0.00023782075732015073,
        "seek": 90694,
        "start": 933.9200000000001,
        "temperature": 0,
        "text": " Or try pulling other elements of data",
        "tokens": [
          51713,
          1610,
          853,
          8407,
          661,
          4959,
          295,
          1412,
          51820
        ]
      },
      {
        "avg_logprob": -0.20841972115113563,
        "compression_ratio": 1.5631067961165048,
        "end": 938.66,
        "id": 364,
        "no_speech_prob": 0.00002977301483042538,
        "seek": 93606,
        "start": 936.14,
        "temperature": 0,
        "text": " from the air quality API or the weather API",
        "tokens": [
          50368,
          490,
          264,
          1988,
          3125,
          9362,
          420,
          264,
          5503,
          9362,
          50494
        ]
      },
      {
        "avg_logprob": -0.20841972115113563,
        "compression_ratio": 1.5631067961165048,
        "end": 940.8199999999999,
        "id": 365,
        "no_speech_prob": 0.00002977301483042538,
        "seek": 93606,
        "start": 938.66,
        "temperature": 0,
        "text": " itself to display on this page.",
        "tokens": [
          50494,
          2564,
          281,
          4674,
          322,
          341,
          3028,
          13,
          50602
        ]
      },
      {
        "avg_logprob": -0.20841972115113563,
        "compression_ratio": 1.5631067961165048,
        "end": 943.26,
        "id": 366,
        "no_speech_prob": 0.00002977301483042538,
        "seek": 93606,
        "start": 940.8199999999999,
        "temperature": 0,
        "text": " In the next video, I'm going to move on and work",
        "tokens": [
          50602,
          682,
          264,
          958,
          960,
          11,
          286,
          478,
          516,
          281,
          1286,
          322,
          293,
          589,
          50724
        ]
      },
      {
        "avg_logprob": -0.20841972115113563,
        "compression_ratio": 1.5631067961165048,
        "end": 944.6199999999999,
        "id": 367,
        "no_speech_prob": 0.00002977301483042538,
        "seek": 93606,
        "start": 943.26,
        "temperature": 0,
        "text": " on this check-in button.",
        "tokens": [
          50724,
          322,
          341,
          1520,
          12,
          259,
          2960,
          13,
          50792
        ]
      },
      {
        "avg_logprob": -0.20841972115113563,
        "compression_ratio": 1.5631067961165048,
        "end": 946.54,
        "id": 368,
        "no_speech_prob": 0.00002977301483042538,
        "seek": 93606,
        "start": 944.6199999999999,
        "temperature": 0,
        "text": " So when I click check-in, I'm now",
        "tokens": [
          50792,
          407,
          562,
          286,
          2052,
          1520,
          12,
          259,
          11,
          286,
          478,
          586,
          50888
        ]
      },
      {
        "avg_logprob": -0.20841972115113563,
        "compression_ratio": 1.5631067961165048,
        "end": 950.02,
        "id": 369,
        "no_speech_prob": 0.00002977301483042538,
        "seek": 93606,
        "start": 946.54,
        "temperature": 0,
        "text": " going to save a snapshot of all of this to the database.",
        "tokens": [
          50888,
          516,
          281,
          3155,
          257,
          30163,
          295,
          439,
          295,
          341,
          281,
          264,
          8149,
          13,
          51062
        ]
      },
      {
        "avg_logprob": -0.20841972115113563,
        "compression_ratio": 1.5631067961165048,
        "end": 951.9,
        "id": 370,
        "no_speech_prob": 0.00002977301483042538,
        "seek": 93606,
        "start": 950.02,
        "temperature": 0,
        "text": " Because ultimately, what I want to do",
        "tokens": [
          51062,
          1436,
          6284,
          11,
          437,
          286,
          528,
          281,
          360,
          51156
        ]
      },
      {
        "avg_logprob": -0.20841972115113563,
        "compression_ratio": 1.5631067961165048,
        "end": 955.3,
        "id": 371,
        "no_speech_prob": 0.00002977301483042538,
        "seek": 93606,
        "start": 951.9,
        "temperature": 0,
        "text": " is view all of those logs plotted on a map.",
        "tokens": [
          51156,
          307,
          1910,
          439,
          295,
          729,
          20820,
          43288,
          322,
          257,
          4471,
          13,
          51326
        ]
      }
    ],
    "transcription": " Welcome back to working with data and APIs in JavaScript. So here I am building this project called the weather here. So far what I have is a web page that geolocates, finds latitude and longitude, sends that to a node server. The node server receives it, sends that to an API called dark sky, which gets the weather information, and then sends that back to the client here. One other thing I want to show you is spoofing different latitude and longitudes. Because ultimately, this project is going to become much more interesting if I can manage to not just check in at the exact same latitude and longitude over and over again. Presumably I'm not able to pick up this laptop and just carry it around and walk about the streets of New York City to get different locations. If I'm over here in the console, I can actually click Escape, which brings up this extra console shelf, drawer, who knows what it's called. And I can click over here with these three dots and look for sensors. So by the way, this is also useful if I want to simulate the idea of I'm holding a mobile device that has an accelerometer for moving it around. But I'm going to click Sensors. And then what I want to look for is geolocation. So you can see there's a bunch of other things I could spoof. But here I want to do geolocation. And in an override, I could say, ah, I want to be in Berlin. So if I put Berlin there and I hit Refresh, now you can see I have the weather in Berlin. So I'm going to use this maybe periodically and just check in in different locations all over the world to save more interesting information to the database itself. And now let me grab some actual weather information and display it here on the web page. I'll create a paragraph element with some spans. So now I have a paragraph element that says the weather here is span ID summary with a temperature of span ID temperature degrees Fahrenheit, which I'm pretty sure is the measurement that I'm getting back from the Dark Sky API itself. So now I just want to go into my Sketch.js code. Here is where I'm actually console logging that information. And if I look in the browser, I can see here that all the data that I want is under currently, under temperature, and under summary. Perfect. I planned this correctly. So now I should be able to say document.get element by ID summary equals JSON currently dot summary. So I just want to take that summary and put it in the text content of that DOM element and then do the same thing for the temperature element. And this is temperature. And there we go. So now if I hit refresh, we can see, aha, the weather here is mostly cloudy with a temperature of 62.91 degrees Fahrenheit. I'm going to change this to the degree symbol. And I'm going to capitalize Fahrenheit, hit refresh again. And I can now also travel to Sao Paolo and hit refresh. And now the weather in Sao Paolo is partly cloudy with a temperature of 73.64 degrees Fahrenheit. Let me also reorganize this into one paragraph. That's, I think, what I meant to do. All right, now I have that in one paragraph. I like the way that looks a little bit better. And also, I've misspelled Fahrenheit. It should be F-A-H-R. So I should really fix that. But I can also lazily just change it to F. There we go. I could be satisfied with this. And I'm quite happy with this. But I want to demonstrate to you what does it mean to work with multiple APIs within one application. So I think it's useful as an exercise to go and try to connect to yet another API and get more information to add more context to this web page. OpenAQ is an open data, open source project that aggregates a lot of different air quality readings from many different sources. And you can read about their data sources, which include government and other kind of research institutions. And it's important to read the disclaimer and look at the licensing information about how the data is collected and where it comes from. OpenAQ has an API with a variety of different endpoints for you to request that air quality information. And the endpoint that I want to look at is the latest endpoint, which I can pass a latitude and longitude as a coordinates parameter. And this is the endpoint, api.openaq.org slash v1 slash latest. So let's just try copying and pasting that into our browser. So we can see it's actually giving us a lot of information. So I don't want just all the entire database of air quality information. This is a ton of information that comes in. I want it for a specific latitude and longitude. So it looks like, if I go back to the documentation, that right here under coordinates, I can give it a property coordinates equals the latitude comma the longitude. So this should work by doing the following. So I can go over to this URL and type in what's known as a URL query string. Question mark, coordinates equals. Now I need to give it some latitude and longitude. I am at 40.73 comma negative 73.99. So I can put that in. All right. Ah, so it looks like I'm getting an air quality measurement from a location at Division Street, which is this distance, probably in meters for me. And this is the particulates probably in the air, the micrograms per meters cubed. And obviously, I want to read through the documentation to be a bit more clear about what these measurements exactly are. And I'll try to do that before I put in any information on the web page itself. If I wanted to, I could also limit, say, like limit only to get measurements within a certain area, within a certain radius by meters. And you can see there are a bunch of other ways that I can sort or limit the number of data points that I get back. You might also notice here that this is not an API key here. I didn't have to authenticate, log in. I don't have any secret key. And so in essence, I could just make a fetch request, a get request to this endpoint right from the client side code itself. But since I'm already requesting the weather information from Dark Sky from the server, let's also make a request to here from the server as well. Let's grab this URL. I'm going to go to the server code. And the wonderful thing about using async and await is I could just do another call to fetch right here. So let's change this to weather URL, call this weather response, and weather data. The reason I'm doing that is because I want to then do exactly the same sequence with an air quality URL, an air quality response, and air quality data. So let's put in the air quality URL, which is this, but with coordinates equals the latitude and longitude. Then we're going to say a fetch that air quality URL and then convert that response into a data. And I also need to change this to weather URL and change this to weather response. So now I have weather data and air quality data. So I have both of those data sources. All I need to do is just put them, I'm going to put them together in another object. I'll say constant data equals weather colon weather data, and then air quality colon AQ data. And that is what I'm going to send back to the client. Now I'm getting data from multiple APIs. I'm getting weather information from Dark Sky and air quality information from OpenAQ. I should point out that I don't have to sequence one after the other. Because they're asynchronous calls, they can happen somewhat in parallel. I could use something called promise.all to wait for a whole bunch of different asynchronous events to all complete. And I've actually covered this in a separate video. You could think of this as a little exercise to yourself. Maybe change this to use promise.all. But with just two APIs here, I'm happy to just do this in sequence. Let's check to see if this works. I'm actually running NodeMon right now. So the server has been restarted for me automatically. Let's move to Shanghai. And let's hit refresh. And let's see, ah, uncaught, cannot read property summary of undefined. What just happened? Sketch.js line 14. Ah. So I changed the way the data comes in. The data came in before as just the actual information from Dark Sky. But now I put everything in a property called weather. So did it console log? Yeah. So you can see here I have air quality with all the air quality information and weather with all the weather information. So I need to change this to weather.json. And I don't love the way I'm doing this. I think what I'm going to do is I'm going to say const weather equals, sorry, it's json.weather.currently. I'm just going to do that. And I'm going to say, for right now, I'm just going to say air equals json.air.quality. I'll have to look at what I'm looking for in there in a second. So now the text content here should be weather.summary. And the text content here should just be weather.temperature. Let's see if that works. And hit Refresh. And there we go. We now have the latitude and longitude and the weather information from Shanghai. And let's put some information about air quality. So in here under air quality, under results, I think what I'll do, oh, there are no results. So I suppose OpenAQ just doesn't have any information for Shanghai. Let's go back to New York because I know there's information in New York. I guess I could do no override. And that'll get me back to New York. So now I've got the weather in New York, which is clear. 65 degrees. And I can go down here and look at air quality under results. We can see here are my two sensor readings under zero, under measurements, under zero. So maybe this is what I want to report. This data is PM data, or particulate matter data. And PM 2.5 refers to fine particles are 2.5 micrometers in diameter or smaller. So that's the concentration of those particles within a cubic meter or meters cubed, micrograms per meters cubed. Now, it's also important to be aware, I'm recording this on Tuesday, May 21, 2019. And the last time this reading was updated was February 4, 2019. So this isn't necessarily real-time data. And I assume, looking through all the different data sources that they're aggregating, some are updated in much more real time than others. But for now, I'm just going to grab whatever the first measurement is and try to get the value, 24.9, and the units and display that on the page itself. So what I want is air quality dot results index zero dot measurements index zero. Air quality dot results index zero dot measurements index zero. And then I need to add another sentence to my HTML page. OK. I have the concentration of particulate matter with a span is another span in the units last read on date. So I want to take that stuff from the database and fill it in on all these spans. So let me add a bunch more document dot get element ID calls. And then I want to send all these particular span elements to the correct piece of data from this air variable up here. So it'll be air dot parameter, air dot value, air dot units. And I think this one is called air dot last updated. We can confirm that by seeing them all in here. Parameter unit value and last updated. So it's not units. It's unit. OK. Let's try refreshing this. Great. There it is. Now we have the particulate matter reading in this paragraph as well. Let's go to another location. Let's go to Mumbai. And let's hit refresh. And there's our reading in Mumbai. So this wraps up this piece of the project. I now connect to two different APIs on the server. I get the information, both those APIs, pass them to the client, display it here on the web page. Before I go into the next video, I probably should add some form of error handling. There's so many things that could go wrong here. And I'm not going to do comprehensive error handling in every possible scenario by any means. But it's something interesting to try to break this project as much as you can and keep writing code to account for that. But one thing I know I could do, because I discovered it earlier, is I could go to Shanghai, where there are no air quality readings. And I could hit refresh. And we'll see I get an error here. On the one hand, as an end user, is experience OK? I mean, you have to ask yourself, why am I making this project in the first place? But at a minimum, I could be able to handle this a bit more elegantly. And so this is cannot read property measurements of undefined. That's because here, there is no measurements property, because there were no results. Now, what I often do in error handling is I start to add some if statements. OK, well, if there are no measurements, if the length of the array is less than this. But one way that I can account for a variety of any error or specific errors is by using try catch. A try catch statement is a block of code. It's code that you want to try. And if anything goes wrong while you're trying that code out, you could then catch the error and execute a different code based on what that area is. And you can handle different errors in different ways, or any error in the same way. I'm going to use it in the simplest way. And I'll refer you to the MDM web docs to read more about it. And I also have another video where I cover it a little bit as part of my series on async await and promises. So for right here, right now, all I want to do is I just want to try all this code. I'm going to say try. And then I'll put the closed curly brackets at the end. And then I'm going to say catch. And then I'm going to give an argument like error. And then basically, I can say I'm just going to add right now console.log something went wrong. Now, this is not good error handling. But you can see the idea. Try all this code. Anything goes wrong, spit that out. I'll go back to the web page, hit refresh. And we can see, ah, something went wrong. Now, this isn't really doing excellent error handling. In fact, all I'm really doing is exactly what it would do by default anyway. Because I could just say console.error, which will just log something but in red. And I could log that error itself. So now if I hit refresh, you can see this is basically what it was before. But I could do something more specific here. Like I could create, I could fill in these DOM elements like no reading available. I could take this right here. And I could put this down here. And I could say no reading. So now if I go back to the page and refresh, we can see, well, at least it says no reading there. So as an exercise to you, I might suggest that you handle the errors more thoughtfully. Maybe you completely change what this sentence says. And ultimately, really, something that you might want to do before you move on to the next video is design this or rewrite the narrative in a more thoughtful way. Or try pulling other elements of data from the air quality API or the weather API itself to display on this page. In the next video, I'm going to move on and work on this check-in button. So when I click check-in, I'm now going to save a snapshot of all of this to the database. Because ultimately, what I want to do is view all of those logs plotted on a map.",
    "translation": null
  },
  "error": null,
  "status": "succeeded",
  "created_at": "2023-09-26T21:03:56.018555Z",
  "started_at": "2023-09-26T21:22:14.925875Z",
  "completed_at": "2023-09-26T21:26:26.260986Z",
  "webhook": "https://83ceaa0b612c.ngrok.app/?video_id=Tiot877orkU",
  "webhook_events_filter": [
    "completed"
  ],
  "metrics": {
    "predict_time": 251.335111
  },
  "urls": {
    "cancel": "https://api.replicate.com/v1/predictions/cbcbjxjbk4xnebf7722smmjcu4/cancel",
    "get": "https://api.replicate.com/v1/predictions/cbcbjxjbk4xnebf7722smmjcu4"
  }
}