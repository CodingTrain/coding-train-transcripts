{
  "id": "httujtjb6hcqn4vcb7px62a5ne",
  "version": "91ee9c0c3df30478510ff8c8a3a545add1ad0259ad3a9f78fba57fbc05ee64f7",
  "input": {
    "audio": "https://upcdn.io/FW25b4F/raw/coding-train/eU7gIy3xV30.m4a"
  },
  "logs": "Transcribe with large-v2 model\nDetected language: English\n  0%|          | 0/72736 [00:00<?, ?frames/s]\n  4%|▎         | 2704/72736 [00:09<04:03, 287.56frames/s]\n  8%|▊         | 5488/72736 [00:17<03:32, 316.22frames/s]\n 11%|█         | 7850/72736 [00:25<03:29, 309.76frames/s]\n 15%|█▍        | 10766/72736 [00:34<03:17, 313.87frames/s]\n 19%|█▊        | 13630/72736 [00:42<02:59, 328.40frames/s]\n 23%|██▎       | 16506/72736 [00:53<03:04, 304.78frames/s]\n 27%|██▋       | 19454/72736 [01:02<02:53, 307.87frames/s]\n 31%|███       | 22238/72736 [01:10<02:38, 318.53frames/s]\n 34%|███▍      | 25010/72736 [01:18<02:26, 324.73frames/s]\n 38%|███▊      | 27838/72736 [01:28<02:21, 316.93frames/s]\n 42%|████▏     | 30742/72736 [01:35<02:04, 338.43frames/s]\n 46%|████▌     | 33306/72736 [01:43<01:59, 329.88frames/s]\n 49%|████▉     | 35906/72736 [01:51<01:50, 334.11frames/s]\n 53%|█████▎    | 38812/72736 [02:01<01:47, 315.71frames/s]\n 57%|█████▋    | 41712/72736 [02:12<01:44, 296.76frames/s]\n 61%|██████    | 44508/72736 [02:24<01:42, 276.64frames/s]\n 65%|██████▌   | 47384/72736 [02:33<01:28, 286.76frames/s]\n 69%|██████▉   | 50314/72736 [02:43<01:17, 290.10frames/s]\n 73%|███████▎  | 53254/72736 [02:53<01:06, 292.39frames/s]\n 77%|███████▋  | 56254/72736 [03:01<00:53, 309.19frames/s]\n 81%|████████▏ | 59130/72736 [03:12<00:45, 299.99frames/s]\n 85%|████████▍ | 61774/72736 [03:20<00:36, 301.13frames/s]\n 89%|████████▊ | 64450/72736 [03:27<00:25, 327.31frames/s]\n 93%|█████████▎| 67450/72736 [03:34<00:15, 346.08frames/s]\n 97%|█████████▋| 70302/72736 [03:46<00:07, 309.76frames/s]\n100%|██████████| 72736/72736 [03:57<00:00, 282.00frames/s]\n100%|██████████| 72736/72736 [03:57<00:00, 306.81frames/s]\n",
  "output": {
    "detected_language": "english",
    "segments": [
      {
        "avg_logprob": -0.2214286097773799,
        "compression_ratio": 1.6714801444043321,
        "end": 3.88,
        "id": 0,
        "no_speech_prob": 0.008442813530564308,
        "seek": 0,
        "start": 0,
        "temperature": 0,
        "text": " Hello and welcome to another beginner's guide",
        "tokens": [
          50364,
          2425,
          293,
          2928,
          281,
          1071,
          22080,
          311,
          5934,
          50558
        ]
      },
      {
        "avg_logprob": -0.2214286097773799,
        "compression_ratio": 1.6714801444043321,
        "end": 5.68,
        "id": 1,
        "no_speech_prob": 0.008442813530564308,
        "seek": 0,
        "start": 3.88,
        "temperature": 0,
        "text": " to machine learning with ml5.js video.",
        "tokens": [
          50558,
          281,
          3479,
          2539,
          365,
          23271,
          20,
          13,
          25530,
          960,
          13,
          50648
        ]
      },
      {
        "avg_logprob": -0.2214286097773799,
        "compression_ratio": 1.6714801444043321,
        "end": 9.96,
        "id": 2,
        "no_speech_prob": 0.008442813530564308,
        "seek": 0,
        "start": 5.68,
        "temperature": 0,
        "text": " Now, in this video, I am going to unlock something for you.",
        "tokens": [
          50648,
          823,
          11,
          294,
          341,
          960,
          11,
          286,
          669,
          516,
          281,
          11634,
          746,
          337,
          291,
          13,
          50862
        ]
      },
      {
        "avg_logprob": -0.2214286097773799,
        "compression_ratio": 1.6714801444043321,
        "end": 10.88,
        "id": 3,
        "no_speech_prob": 0.008442813530564308,
        "seek": 0,
        "start": 9.96,
        "temperature": 0,
        "text": " It's already unlocked for you,",
        "tokens": [
          50862,
          467,
          311,
          1217,
          30180,
          337,
          291,
          11,
          50908
        ]
      },
      {
        "avg_logprob": -0.2214286097773799,
        "compression_ratio": 1.6714801444043321,
        "end": 11.96,
        "id": 4,
        "no_speech_prob": 0.008442813530564308,
        "seek": 0,
        "start": 10.88,
        "temperature": 0,
        "text": " but I'm going to show it to you",
        "tokens": [
          50908,
          457,
          286,
          478,
          516,
          281,
          855,
          309,
          281,
          291,
          50962
        ]
      },
      {
        "avg_logprob": -0.2214286097773799,
        "compression_ratio": 1.6714801444043321,
        "end": 14.38,
        "id": 5,
        "no_speech_prob": 0.008442813530564308,
        "seek": 0,
        "start": 11.96,
        "temperature": 0,
        "text": " that is incredibly powerful for what you can do now",
        "tokens": [
          50962,
          300,
          307,
          6252,
          4005,
          337,
          437,
          291,
          393,
          360,
          586,
          51083
        ]
      },
      {
        "avg_logprob": -0.2214286097773799,
        "compression_ratio": 1.6714801444043321,
        "end": 16.14,
        "id": 6,
        "no_speech_prob": 0.008442813530564308,
        "seek": 0,
        "start": 14.38,
        "temperature": 0,
        "text": " with ml5 that you couldn't do before,",
        "tokens": [
          51083,
          365,
          23271,
          20,
          300,
          291,
          2809,
          380,
          360,
          949,
          11,
          51171
        ]
      },
      {
        "avg_logprob": -0.2214286097773799,
        "compression_ratio": 1.6714801444043321,
        "end": 17.78,
        "id": 7,
        "no_speech_prob": 0.008442813530564308,
        "seek": 0,
        "start": 16.14,
        "temperature": 0,
        "text": " but many of you asked about in the comments.",
        "tokens": [
          51171,
          457,
          867,
          295,
          291,
          2351,
          466,
          294,
          264,
          3053,
          13,
          51253
        ]
      },
      {
        "avg_logprob": -0.2214286097773799,
        "compression_ratio": 1.6714801444043321,
        "end": 18.88,
        "id": 8,
        "no_speech_prob": 0.008442813530564308,
        "seek": 0,
        "start": 17.78,
        "temperature": 0,
        "text": " And what is that?",
        "tokens": [
          51253,
          400,
          437,
          307,
          300,
          30,
          51308
        ]
      },
      {
        "avg_logprob": -0.2214286097773799,
        "compression_ratio": 1.6714801444043321,
        "end": 22.26,
        "id": 9,
        "no_speech_prob": 0.008442813530564308,
        "seek": 0,
        "start": 18.88,
        "temperature": 0,
        "text": " It is the save load feature extractor.",
        "tokens": [
          51308,
          467,
          307,
          264,
          3155,
          3677,
          4111,
          8947,
          284,
          13,
          51477
        ]
      },
      {
        "avg_logprob": -0.2214286097773799,
        "compression_ratio": 1.6714801444043321,
        "end": 25.080000000000002,
        "id": 10,
        "no_speech_prob": 0.008442813530564308,
        "seek": 0,
        "start": 22.26,
        "temperature": 0,
        "text": " This is a new feature that was added to ml5",
        "tokens": [
          51477,
          639,
          307,
          257,
          777,
          4111,
          300,
          390,
          3869,
          281,
          23271,
          20,
          51618
        ]
      },
      {
        "avg_logprob": -0.2214286097773799,
        "compression_ratio": 1.6714801444043321,
        "end": 27.04,
        "id": 11,
        "no_speech_prob": 0.008442813530564308,
        "seek": 0,
        "start": 25.080000000000002,
        "temperature": 0,
        "text": " just five days ago.",
        "tokens": [
          51618,
          445,
          1732,
          1708,
          2057,
          13,
          51716
        ]
      },
      {
        "avg_logprob": -0.22782956875436675,
        "compression_ratio": 1.6333333333333333,
        "end": 32.04,
        "id": 12,
        "no_speech_prob": 0.0004955336335115135,
        "seek": 2704,
        "start": 27.04,
        "temperature": 0,
        "text": " You need to make sure that you are using ml5 0.1.3",
        "tokens": [
          50364,
          509,
          643,
          281,
          652,
          988,
          300,
          291,
          366,
          1228,
          23271,
          20,
          1958,
          13,
          16,
          13,
          18,
          50614
        ]
      },
      {
        "avg_logprob": -0.22782956875436675,
        "compression_ratio": 1.6333333333333333,
        "end": 35.8,
        "id": 13,
        "no_speech_prob": 0.0004955336335115135,
        "seek": 2704,
        "start": 32.28,
        "temperature": 0,
        "text": " or whatever number in the future past that,",
        "tokens": [
          50626,
          420,
          2035,
          1230,
          294,
          264,
          2027,
          1791,
          300,
          11,
          50802
        ]
      },
      {
        "avg_logprob": -0.22782956875436675,
        "compression_ratio": 1.6333333333333333,
        "end": 37.64,
        "id": 14,
        "no_speech_prob": 0.0004955336335115135,
        "seek": 2704,
        "start": 35.8,
        "temperature": 0,
        "text": " but certainly this is the version of the library",
        "tokens": [
          50802,
          457,
          3297,
          341,
          307,
          264,
          3037,
          295,
          264,
          6405,
          50894
        ]
      },
      {
        "avg_logprob": -0.22782956875436675,
        "compression_ratio": 1.6333333333333333,
        "end": 39.12,
        "id": 15,
        "no_speech_prob": 0.0004955336335115135,
        "seek": 2704,
        "start": 37.64,
        "temperature": 0,
        "text": " that I'm using in this video.",
        "tokens": [
          50894,
          300,
          286,
          478,
          1228,
          294,
          341,
          960,
          13,
          50968
        ]
      },
      {
        "avg_logprob": -0.22782956875436675,
        "compression_ratio": 1.6333333333333333,
        "end": 40.72,
        "id": 16,
        "no_speech_prob": 0.0004955336335115135,
        "seek": 2704,
        "start": 39.12,
        "temperature": 0,
        "text": " Now, what does it do?",
        "tokens": [
          50968,
          823,
          11,
          437,
          775,
          309,
          360,
          30,
          51048
        ]
      },
      {
        "avg_logprob": -0.22782956875436675,
        "compression_ratio": 1.6333333333333333,
        "end": 43,
        "id": 17,
        "no_speech_prob": 0.0004955336335115135,
        "seek": 2704,
        "start": 40.72,
        "temperature": 0,
        "text": " So the last example, if you've been watching",
        "tokens": [
          51048,
          407,
          264,
          1036,
          1365,
          11,
          498,
          291,
          600,
          668,
          1976,
          51162
        ]
      },
      {
        "avg_logprob": -0.22782956875436675,
        "compression_ratio": 1.6333333333333333,
        "end": 46.94,
        "id": 18,
        "no_speech_prob": 0.0004955336335115135,
        "seek": 2704,
        "start": 43,
        "temperature": 0,
        "text": " these video series in order, was this example.",
        "tokens": [
          51162,
          613,
          960,
          2638,
          294,
          1668,
          11,
          390,
          341,
          1365,
          13,
          51359
        ]
      },
      {
        "avg_logprob": -0.22782956875436675,
        "compression_ratio": 1.6333333333333333,
        "end": 48.480000000000004,
        "id": 19,
        "no_speech_prob": 0.0004955336335115135,
        "seek": 2704,
        "start": 46.94,
        "temperature": 0,
        "text": " What this example does is it loads",
        "tokens": [
          51359,
          708,
          341,
          1365,
          775,
          307,
          309,
          12668,
          51436
        ]
      },
      {
        "avg_logprob": -0.22782956875436675,
        "compression_ratio": 1.6333333333333333,
        "end": 52.56,
        "id": 20,
        "no_speech_prob": 0.0004955336335115135,
        "seek": 2704,
        "start": 48.480000000000004,
        "temperature": 0,
        "text": " a pre-trained image classification model called MobileNet.",
        "tokens": [
          51436,
          257,
          659,
          12,
          17227,
          2001,
          3256,
          21538,
          2316,
          1219,
          22625,
          31890,
          13,
          51640
        ]
      },
      {
        "avg_logprob": -0.22782956875436675,
        "compression_ratio": 1.6333333333333333,
        "end": 54.879999999999995,
        "id": 21,
        "no_speech_prob": 0.0004955336335115135,
        "seek": 2704,
        "start": 52.56,
        "temperature": 0,
        "text": " And MobileNet is trained on 1,000 different kinds of things",
        "tokens": [
          51640,
          400,
          22625,
          31890,
          307,
          8895,
          322,
          502,
          11,
          1360,
          819,
          3685,
          295,
          721,
          51756
        ]
      },
      {
        "avg_logprob": -0.2563982832020727,
        "compression_ratio": 1.6455223880597014,
        "end": 57.32,
        "id": 22,
        "no_speech_prob": 0.00001805847932700999,
        "seek": 5488,
        "start": 54.96,
        "temperature": 0,
        "text": " and recognizes puppies and dogs and birds",
        "tokens": [
          50368,
          293,
          26564,
          33734,
          293,
          7197,
          293,
          9009,
          50486
        ]
      },
      {
        "avg_logprob": -0.2563982832020727,
        "compression_ratio": 1.6455223880597014,
        "end": 59,
        "id": 23,
        "no_speech_prob": 0.00001805847932700999,
        "seek": 5488,
        "start": 57.32,
        "temperature": 0,
        "text": " and different kinds of objects.",
        "tokens": [
          50486,
          293,
          819,
          3685,
          295,
          6565,
          13,
          50570
        ]
      },
      {
        "avg_logprob": -0.2563982832020727,
        "compression_ratio": 1.6455223880597014,
        "end": 61.86,
        "id": 24,
        "no_speech_prob": 0.00001805847932700999,
        "seek": 5488,
        "start": 59,
        "temperature": 0,
        "text": " Transfer learning is the process by which",
        "tokens": [
          50570,
          35025,
          2539,
          307,
          264,
          1399,
          538,
          597,
          50713
        ]
      },
      {
        "avg_logprob": -0.2563982832020727,
        "compression_ratio": 1.6455223880597014,
        "end": 64.08,
        "id": 25,
        "no_speech_prob": 0.00001805847932700999,
        "seek": 5488,
        "start": 61.86,
        "temperature": 0,
        "text": " we take that pre-trained MobileNet model",
        "tokens": [
          50713,
          321,
          747,
          300,
          659,
          12,
          17227,
          2001,
          22625,
          31890,
          2316,
          50824
        ]
      },
      {
        "avg_logprob": -0.2563982832020727,
        "compression_ratio": 1.6455223880597014,
        "end": 66.8,
        "id": 26,
        "no_speech_prob": 0.00001805847932700999,
        "seek": 5488,
        "start": 64.08,
        "temperature": 0,
        "text": " and basically disconnect it from all of those labels",
        "tokens": [
          50824,
          293,
          1936,
          14299,
          309,
          490,
          439,
          295,
          729,
          16949,
          50960
        ]
      },
      {
        "avg_logprob": -0.2563982832020727,
        "compression_ratio": 1.6455223880597014,
        "end": 68.68,
        "id": 27,
        "no_speech_prob": 0.00001805847932700999,
        "seek": 5488,
        "start": 66.8,
        "temperature": 0,
        "text": " and reconnect it to our own labels.",
        "tokens": [
          50960,
          293,
          30095,
          309,
          281,
          527,
          1065,
          16949,
          13,
          51054
        ]
      },
      {
        "avg_logprob": -0.2563982832020727,
        "compression_ratio": 1.6455223880597014,
        "end": 71,
        "id": 28,
        "no_speech_prob": 0.00001805847932700999,
        "seek": 5488,
        "start": 68.68,
        "temperature": 0,
        "text": " For example, I'm going to make up a label called happy",
        "tokens": [
          51054,
          1171,
          1365,
          11,
          286,
          478,
          516,
          281,
          652,
          493,
          257,
          7645,
          1219,
          2055,
          51170
        ]
      },
      {
        "avg_logprob": -0.2563982832020727,
        "compression_ratio": 1.6455223880597014,
        "end": 72.24000000000001,
        "id": 29,
        "no_speech_prob": 0.00001805847932700999,
        "seek": 5488,
        "start": 71,
        "temperature": 0,
        "text": " and a label called sad.",
        "tokens": [
          51170,
          293,
          257,
          7645,
          1219,
          4227,
          13,
          51232
        ]
      },
      {
        "avg_logprob": -0.2563982832020727,
        "compression_ratio": 1.6455223880597014,
        "end": 73.96000000000001,
        "id": 30,
        "no_speech_prob": 0.00001805847932700999,
        "seek": 5488,
        "start": 72.24000000000001,
        "temperature": 0,
        "text": " I could certainly have more than just two.",
        "tokens": [
          51232,
          286,
          727,
          3297,
          362,
          544,
          813,
          445,
          732,
          13,
          51318
        ]
      },
      {
        "avg_logprob": -0.2563982832020727,
        "compression_ratio": 1.6455223880597014,
        "end": 76.12,
        "id": 31,
        "no_speech_prob": 0.00001805847932700999,
        "seek": 5488,
        "start": 73.96000000000001,
        "temperature": 0,
        "text": " And I'm going to show it things like",
        "tokens": [
          51318,
          400,
          286,
          478,
          516,
          281,
          855,
          309,
          721,
          411,
          51426
        ]
      },
      {
        "avg_logprob": -0.2563982832020727,
        "compression_ratio": 1.6455223880597014,
        "end": 78.5,
        "id": 32,
        "no_speech_prob": 0.00001805847932700999,
        "seek": 5488,
        "start": 76.12,
        "temperature": 0,
        "text": " the train whistle is me being happy.",
        "tokens": [
          51426,
          264,
          3847,
          23470,
          307,
          385,
          885,
          2055,
          13,
          51545
        ]
      },
      {
        "avg_logprob": -0.2994358228600543,
        "compression_ratio": 1.99009900990099,
        "end": 82.34,
        "id": 33,
        "no_speech_prob": 0.00022341091244015843,
        "seek": 7850,
        "start": 79.42,
        "temperature": 0,
        "text": " Oh, oh, oh, oh, oh, oh, oh, oh, oh.",
        "tokens": [
          50410,
          876,
          11,
          1954,
          11,
          1954,
          11,
          1954,
          11,
          1954,
          11,
          1954,
          11,
          1954,
          11,
          1954,
          11,
          1954,
          13,
          50556
        ]
      },
      {
        "avg_logprob": -0.2994358228600543,
        "compression_ratio": 1.99009900990099,
        "end": 86.58,
        "id": 34,
        "no_speech_prob": 0.00022341091244015843,
        "seek": 7850,
        "start": 84.34,
        "temperature": 0,
        "text": " I'm going to show it that train whistle a bunch of times.",
        "tokens": [
          50656,
          286,
          478,
          516,
          281,
          855,
          309,
          300,
          3847,
          23470,
          257,
          3840,
          295,
          1413,
          13,
          50768
        ]
      },
      {
        "avg_logprob": -0.2994358228600543,
        "compression_ratio": 1.99009900990099,
        "end": 87.98,
        "id": 35,
        "no_speech_prob": 0.00022341091244015843,
        "seek": 7850,
        "start": 86.58,
        "temperature": 0,
        "text": " Say happy, happy, happy, happy, happy.",
        "tokens": [
          50768,
          6463,
          2055,
          11,
          2055,
          11,
          2055,
          11,
          2055,
          11,
          2055,
          13,
          50838
        ]
      },
      {
        "avg_logprob": -0.2994358228600543,
        "compression_ratio": 1.99009900990099,
        "end": 91.22,
        "id": 36,
        "no_speech_prob": 0.00022341091244015843,
        "seek": 7850,
        "start": 87.98,
        "temperature": 0,
        "text": " Now, no train whistle is very sad.",
        "tokens": [
          50838,
          823,
          11,
          572,
          3847,
          23470,
          307,
          588,
          4227,
          13,
          51000
        ]
      },
      {
        "avg_logprob": -0.2994358228600543,
        "compression_ratio": 1.99009900990099,
        "end": 93.38,
        "id": 37,
        "no_speech_prob": 0.00022341091244015843,
        "seek": 7850,
        "start": 91.22,
        "temperature": 0,
        "text": " I'm sad, no train whistle is sad.",
        "tokens": [
          51000,
          286,
          478,
          4227,
          11,
          572,
          3847,
          23470,
          307,
          4227,
          13,
          51108
        ]
      },
      {
        "avg_logprob": -0.2994358228600543,
        "compression_ratio": 1.99009900990099,
        "end": 95.12,
        "id": 38,
        "no_speech_prob": 0.00022341091244015843,
        "seek": 7850,
        "start": 93.38,
        "temperature": 0,
        "text": " Oh, I'm spending way too much time on this",
        "tokens": [
          51108,
          876,
          11,
          286,
          478,
          6434,
          636,
          886,
          709,
          565,
          322,
          341,
          51195
        ]
      },
      {
        "avg_logprob": -0.2994358228600543,
        "compression_ratio": 1.99009900990099,
        "end": 96.34,
        "id": 39,
        "no_speech_prob": 0.00022341091244015843,
        "seek": 7850,
        "start": 95.12,
        "temperature": 0,
        "text": " because I haven't implemented the thing",
        "tokens": [
          51195,
          570,
          286,
          2378,
          380,
          12270,
          264,
          551,
          51256
        ]
      },
      {
        "avg_logprob": -0.2994358228600543,
        "compression_ratio": 1.99009900990099,
        "end": 97.26,
        "id": 40,
        "no_speech_prob": 0.00022341091244015843,
        "seek": 7850,
        "start": 96.34,
        "temperature": 0,
        "text": " that I want to implement.",
        "tokens": [
          51256,
          300,
          286,
          528,
          281,
          4445,
          13,
          51302
        ]
      },
      {
        "avg_logprob": -0.2994358228600543,
        "compression_ratio": 1.99009900990099,
        "end": 99.7,
        "id": 41,
        "no_speech_prob": 0.00022341091244015843,
        "seek": 7850,
        "start": 97.26,
        "temperature": 0,
        "text": " Now I'm going to say train and it's going to train",
        "tokens": [
          51302,
          823,
          286,
          478,
          516,
          281,
          584,
          3847,
          293,
          309,
          311,
          516,
          281,
          3847,
          51424
        ]
      },
      {
        "avg_logprob": -0.2994358228600543,
        "compression_ratio": 1.99009900990099,
        "end": 101.58,
        "id": 42,
        "no_speech_prob": 0.00022341091244015843,
        "seek": 7850,
        "start": 99.7,
        "temperature": 0,
        "text": " and then once it's done, ah!",
        "tokens": [
          51424,
          293,
          550,
          1564,
          309,
          311,
          1096,
          11,
          3716,
          0,
          51518
        ]
      },
      {
        "avg_logprob": -0.2994358228600543,
        "compression_ratio": 1.99009900990099,
        "end": 104.86,
        "id": 43,
        "no_speech_prob": 0.00022341091244015843,
        "seek": 7850,
        "start": 103.94,
        "temperature": 0,
        "text": " Happy.",
        "tokens": [
          51636,
          8277,
          13,
          51682
        ]
      },
      {
        "avg_logprob": -0.2994358228600543,
        "compression_ratio": 1.99009900990099,
        "end": 107.66,
        "id": 44,
        "no_speech_prob": 0.00022341091244015843,
        "seek": 7850,
        "start": 106.18,
        "temperature": 0,
        "text": " Sad.",
        "tokens": [
          51748,
          12269,
          13,
          51822
        ]
      },
      {
        "avg_logprob": -0.2190464630126953,
        "compression_ratio": 1.6356877323420074,
        "end": 109.53999999999999,
        "id": 45,
        "no_speech_prob": 0.000015689523934270255,
        "seek": 10766,
        "start": 107.66,
        "temperature": 0,
        "text": " Happy train whistle.",
        "tokens": [
          50364,
          8277,
          3847,
          23470,
          13,
          50458
        ]
      },
      {
        "avg_logprob": -0.2190464630126953,
        "compression_ratio": 1.6356877323420074,
        "end": 110.38,
        "id": 46,
        "no_speech_prob": 0.000015689523934270255,
        "seek": 10766,
        "start": 109.53999999999999,
        "temperature": 0,
        "text": " Sad.",
        "tokens": [
          50458,
          12269,
          13,
          50500
        ]
      },
      {
        "avg_logprob": -0.2190464630126953,
        "compression_ratio": 1.6356877323420074,
        "end": 111.2,
        "id": 47,
        "no_speech_prob": 0.000015689523934270255,
        "seek": 10766,
        "start": 110.38,
        "temperature": 0,
        "text": " Okay, so it works.",
        "tokens": [
          50500,
          1033,
          11,
          370,
          309,
          1985,
          13,
          50541
        ]
      },
      {
        "avg_logprob": -0.2190464630126953,
        "compression_ratio": 1.6356877323420074,
        "end": 113.53999999999999,
        "id": 48,
        "no_speech_prob": 0.000015689523934270255,
        "seek": 10766,
        "start": 111.2,
        "temperature": 0,
        "text": " It is now learning to classify images in real time",
        "tokens": [
          50541,
          467,
          307,
          586,
          2539,
          281,
          33872,
          5267,
          294,
          957,
          565,
          50658
        ]
      },
      {
        "avg_logprob": -0.2190464630126953,
        "compression_ratio": 1.6356877323420074,
        "end": 115.24,
        "id": 49,
        "no_speech_prob": 0.000015689523934270255,
        "seek": 10766,
        "start": 113.53999999999999,
        "temperature": 0,
        "text": " according to those two categories.",
        "tokens": [
          50658,
          4650,
          281,
          729,
          732,
          10479,
          13,
          50743
        ]
      },
      {
        "avg_logprob": -0.2190464630126953,
        "compression_ratio": 1.6356877323420074,
        "end": 119.46,
        "id": 50,
        "no_speech_prob": 0.000015689523934270255,
        "seek": 10766,
        "start": 115.24,
        "temperature": 0,
        "text": " But I'm a big spaz and I'm going to just be over here",
        "tokens": [
          50743,
          583,
          286,
          478,
          257,
          955,
          637,
          921,
          293,
          286,
          478,
          516,
          281,
          445,
          312,
          670,
          510,
          50954
        ]
      },
      {
        "avg_logprob": -0.2190464630126953,
        "compression_ratio": 1.6356877323420074,
        "end": 122.66,
        "id": 51,
        "no_speech_prob": 0.000015689523934270255,
        "seek": 10766,
        "start": 119.46,
        "temperature": 0,
        "text": " doing refresh and I have now lost that forever.",
        "tokens": [
          50954,
          884,
          15134,
          293,
          286,
          362,
          586,
          2731,
          300,
          5680,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.2190464630126953,
        "compression_ratio": 1.6356877323420074,
        "end": 125.46,
        "id": 52,
        "no_speech_prob": 0.000015689523934270255,
        "seek": 10766,
        "start": 122.66,
        "temperature": 0,
        "text": " I no longer have that model, it's gone.",
        "tokens": [
          51114,
          286,
          572,
          2854,
          362,
          300,
          2316,
          11,
          309,
          311,
          2780,
          13,
          51254
        ]
      },
      {
        "avg_logprob": -0.2190464630126953,
        "compression_ratio": 1.6356877323420074,
        "end": 128.74,
        "id": 53,
        "no_speech_prob": 0.000015689523934270255,
        "seek": 10766,
        "start": 125.46,
        "temperature": 0,
        "text": " The new feature is ability to save",
        "tokens": [
          51254,
          440,
          777,
          4111,
          307,
          3485,
          281,
          3155,
          51418
        ]
      },
      {
        "avg_logprob": -0.2190464630126953,
        "compression_ratio": 1.6356877323420074,
        "end": 131.3,
        "id": 54,
        "no_speech_prob": 0.000015689523934270255,
        "seek": 10766,
        "start": 128.74,
        "temperature": 0,
        "text": " that custom trained model and then reload it.",
        "tokens": [
          51418,
          300,
          2375,
          8895,
          2316,
          293,
          550,
          25628,
          309,
          13,
          51546
        ]
      },
      {
        "avg_logprob": -0.2190464630126953,
        "compression_ratio": 1.6356877323420074,
        "end": 133.85999999999999,
        "id": 55,
        "no_speech_prob": 0.000015689523934270255,
        "seek": 10766,
        "start": 131.3,
        "temperature": 0,
        "text": " So if you're using this for an installation",
        "tokens": [
          51546,
          407,
          498,
          291,
          434,
          1228,
          341,
          337,
          364,
          13260,
          51674
        ]
      },
      {
        "avg_logprob": -0.2190464630126953,
        "compression_ratio": 1.6356877323420074,
        "end": 136.3,
        "id": 56,
        "no_speech_prob": 0.000015689523934270255,
        "seek": 10766,
        "start": 133.85999999999999,
        "temperature": 0,
        "text": " and you're going to take down the computer",
        "tokens": [
          51674,
          293,
          291,
          434,
          516,
          281,
          747,
          760,
          264,
          3820,
          51796
        ]
      },
      {
        "avg_logprob": -0.23514911427217372,
        "compression_ratio": 2.0299625468164795,
        "end": 138.9,
        "id": 57,
        "no_speech_prob": 0.000044693944801110774,
        "seek": 13630,
        "start": 136.3,
        "temperature": 0,
        "text": " and set it up every day, you can save that model.",
        "tokens": [
          50364,
          293,
          992,
          309,
          493,
          633,
          786,
          11,
          291,
          393,
          3155,
          300,
          2316,
          13,
          50494
        ]
      },
      {
        "avg_logprob": -0.23514911427217372,
        "compression_ratio": 2.0299625468164795,
        "end": 140.68,
        "id": 58,
        "no_speech_prob": 0.000044693944801110774,
        "seek": 13630,
        "start": 138.9,
        "temperature": 0,
        "text": " You can imagine, there's lots of possibilities here.",
        "tokens": [
          50494,
          509,
          393,
          3811,
          11,
          456,
          311,
          3195,
          295,
          12178,
          510,
          13,
          50583
        ]
      },
      {
        "avg_logprob": -0.23514911427217372,
        "compression_ratio": 2.0299625468164795,
        "end": 142.86,
        "id": 59,
        "no_speech_prob": 0.000044693944801110774,
        "seek": 13630,
        "start": 140.68,
        "temperature": 0,
        "text": " So there's only two things that I really need",
        "tokens": [
          50583,
          407,
          456,
          311,
          787,
          732,
          721,
          300,
          286,
          534,
          643,
          50692
        ]
      },
      {
        "avg_logprob": -0.23514911427217372,
        "compression_ratio": 2.0299625468164795,
        "end": 143.82000000000002,
        "id": 60,
        "no_speech_prob": 0.000044693944801110774,
        "seek": 13630,
        "start": 142.86,
        "temperature": 0,
        "text": " to add to the code.",
        "tokens": [
          50692,
          281,
          909,
          281,
          264,
          3089,
          13,
          50740
        ]
      },
      {
        "avg_logprob": -0.23514911427217372,
        "compression_ratio": 2.0299625468164795,
        "end": 145.62,
        "id": 61,
        "no_speech_prob": 0.000044693944801110774,
        "seek": 13630,
        "start": 143.82000000000002,
        "temperature": 0,
        "text": " There's a save function and a load function.",
        "tokens": [
          50740,
          821,
          311,
          257,
          3155,
          2445,
          293,
          257,
          3677,
          2445,
          13,
          50830
        ]
      },
      {
        "avg_logprob": -0.23514911427217372,
        "compression_ratio": 2.0299625468164795,
        "end": 146.58,
        "id": 62,
        "no_speech_prob": 0.000044693944801110774,
        "seek": 13630,
        "start": 145.62,
        "temperature": 0,
        "text": " There's a bunch of pieces there",
        "tokens": [
          50830,
          821,
          311,
          257,
          3840,
          295,
          3755,
          456,
          50878
        ]
      },
      {
        "avg_logprob": -0.23514911427217372,
        "compression_ratio": 2.0299625468164795,
        "end": 148.02,
        "id": 63,
        "no_speech_prob": 0.000044693944801110774,
        "seek": 13630,
        "start": 146.58,
        "temperature": 0,
        "text": " but that's what I'm going to do right now.",
        "tokens": [
          50878,
          457,
          300,
          311,
          437,
          286,
          478,
          516,
          281,
          360,
          558,
          586,
          13,
          50950
        ]
      },
      {
        "avg_logprob": -0.23514911427217372,
        "compression_ratio": 2.0299625468164795,
        "end": 150.78,
        "id": 64,
        "no_speech_prob": 0.000044693944801110774,
        "seek": 13630,
        "start": 148.02,
        "temperature": 0,
        "text": " So I'm going to go here into the code",
        "tokens": [
          50950,
          407,
          286,
          478,
          516,
          281,
          352,
          510,
          666,
          264,
          3089,
          51088
        ]
      },
      {
        "avg_logprob": -0.23514911427217372,
        "compression_ratio": 2.0299625468164795,
        "end": 153.10000000000002,
        "id": 65,
        "no_speech_prob": 0.000044693944801110774,
        "seek": 13630,
        "start": 150.78,
        "temperature": 0,
        "text": " and I'm going to just add another button.",
        "tokens": [
          51088,
          293,
          286,
          478,
          516,
          281,
          445,
          909,
          1071,
          2960,
          13,
          51204
        ]
      },
      {
        "avg_logprob": -0.23514911427217372,
        "compression_ratio": 2.0299625468164795,
        "end": 154.94,
        "id": 66,
        "no_speech_prob": 0.000044693944801110774,
        "seek": 13630,
        "start": 153.10000000000002,
        "temperature": 0,
        "text": " Like I have a happy button, a sad button,",
        "tokens": [
          51204,
          1743,
          286,
          362,
          257,
          2055,
          2960,
          11,
          257,
          4227,
          2960,
          11,
          51296
        ]
      },
      {
        "avg_logprob": -0.23514911427217372,
        "compression_ratio": 2.0299625468164795,
        "end": 156.82000000000002,
        "id": 67,
        "no_speech_prob": 0.000044693944801110774,
        "seek": 13630,
        "start": 154.94,
        "temperature": 0,
        "text": " and a train button.",
        "tokens": [
          51296,
          293,
          257,
          3847,
          2960,
          13,
          51390
        ]
      },
      {
        "avg_logprob": -0.23514911427217372,
        "compression_ratio": 2.0299625468164795,
        "end": 157.64000000000001,
        "id": 68,
        "no_speech_prob": 0.000044693944801110774,
        "seek": 13630,
        "start": 156.82000000000002,
        "temperature": 0,
        "text": " Choo choo.",
        "tokens": [
          51390,
          761,
          1986,
          1586,
          78,
          13,
          51431
        ]
      },
      {
        "avg_logprob": -0.23514911427217372,
        "compression_ratio": 2.0299625468164795,
        "end": 159.70000000000002,
        "id": 69,
        "no_speech_prob": 0.000044693944801110774,
        "seek": 13630,
        "start": 157.64000000000001,
        "temperature": 0,
        "text": " I'm going to add a sad button.",
        "tokens": [
          51431,
          286,
          478,
          516,
          281,
          909,
          257,
          4227,
          2960,
          13,
          51534
        ]
      },
      {
        "avg_logprob": -0.23514911427217372,
        "compression_ratio": 2.0299625468164795,
        "end": 162.78,
        "id": 70,
        "no_speech_prob": 0.000044693944801110774,
        "seek": 13630,
        "start": 159.70000000000002,
        "temperature": 0,
        "text": " No, not sad, a save button.",
        "tokens": [
          51534,
          883,
          11,
          406,
          4227,
          11,
          257,
          3155,
          2960,
          13,
          51688
        ]
      },
      {
        "avg_logprob": -0.23514911427217372,
        "compression_ratio": 2.0299625468164795,
        "end": 165.06,
        "id": 71,
        "no_speech_prob": 0.000044693944801110774,
        "seek": 13630,
        "start": 162.78,
        "temperature": 0,
        "text": " I'm going to call it save and save button",
        "tokens": [
          51688,
          286,
          478,
          516,
          281,
          818,
          309,
          3155,
          293,
          3155,
          2960,
          51802
        ]
      },
      {
        "avg_logprob": -0.29007709317091035,
        "compression_ratio": 1.9404761904761905,
        "end": 166.42000000000002,
        "id": 72,
        "no_speech_prob": 0.000018631733837537467,
        "seek": 16506,
        "start": 165.06,
        "temperature": 0,
        "text": " and when the mouse is pressed,",
        "tokens": [
          50364,
          293,
          562,
          264,
          9719,
          307,
          17355,
          11,
          50432
        ]
      },
      {
        "avg_logprob": -0.29007709317091035,
        "compression_ratio": 1.9404761904761905,
        "end": 168.86,
        "id": 73,
        "no_speech_prob": 0.000018631733837537467,
        "seek": 16506,
        "start": 166.42000000000002,
        "temperature": 0,
        "text": " I'm just going to say classifier.save.",
        "tokens": [
          50432,
          286,
          478,
          445,
          516,
          281,
          584,
          1508,
          9902,
          13,
          82,
          946,
          13,
          50554
        ]
      },
      {
        "avg_logprob": -0.29007709317091035,
        "compression_ratio": 1.9404761904761905,
        "end": 169.7,
        "id": 74,
        "no_speech_prob": 0.000018631733837537467,
        "seek": 16506,
        "start": 168.86,
        "temperature": 0,
        "text": " That's it.",
        "tokens": [
          50554,
          663,
          311,
          309,
          13,
          50596
        ]
      },
      {
        "avg_logprob": -0.29007709317091035,
        "compression_ratio": 1.9404761904761905,
        "end": 171.66,
        "id": 75,
        "no_speech_prob": 0.000018631733837537467,
        "seek": 16506,
        "start": 169.7,
        "temperature": 0,
        "text": " All I have to do is say classifier.save.",
        "tokens": [
          50596,
          1057,
          286,
          362,
          281,
          360,
          307,
          584,
          1508,
          9902,
          13,
          82,
          946,
          13,
          50694
        ]
      },
      {
        "avg_logprob": -0.29007709317091035,
        "compression_ratio": 1.9404761904761905,
        "end": 174.26,
        "id": 76,
        "no_speech_prob": 0.000018631733837537467,
        "seek": 16506,
        "start": 173.3,
        "temperature": 0,
        "text": " Let's see what happens.",
        "tokens": [
          50776,
          961,
          311,
          536,
          437,
          2314,
          13,
          50824
        ]
      },
      {
        "avg_logprob": -0.29007709317091035,
        "compression_ratio": 1.9404761904761905,
        "end": 175.94,
        "id": 77,
        "no_speech_prob": 0.000018631733837537467,
        "seek": 16506,
        "start": 174.26,
        "temperature": 0,
        "text": " So I'm not going to train it very,",
        "tokens": [
          50824,
          407,
          286,
          478,
          406,
          516,
          281,
          3847,
          309,
          588,
          11,
          50908
        ]
      },
      {
        "avg_logprob": -0.29007709317091035,
        "compression_ratio": 1.9404761904761905,
        "end": 179.1,
        "id": 78,
        "no_speech_prob": 0.000018631733837537467,
        "seek": 16506,
        "start": 177.38,
        "temperature": 0,
        "text": " actually no, I am going to train.",
        "tokens": [
          50980,
          767,
          572,
          11,
          286,
          669,
          516,
          281,
          3847,
          13,
          51066
        ]
      },
      {
        "avg_logprob": -0.29007709317091035,
        "compression_ratio": 1.9404761904761905,
        "end": 181.14000000000001,
        "id": 79,
        "no_speech_prob": 0.000018631733837537467,
        "seek": 16506,
        "start": 179.1,
        "temperature": 0,
        "text": " I'm going to let's do a really good solid training this time",
        "tokens": [
          51066,
          286,
          478,
          516,
          281,
          718,
          311,
          360,
          257,
          534,
          665,
          5100,
          3097,
          341,
          565,
          51168
        ]
      },
      {
        "avg_logprob": -0.29007709317091035,
        "compression_ratio": 1.9404761904761905,
        "end": 182.7,
        "id": 80,
        "no_speech_prob": 0.000018631733837537467,
        "seek": 16506,
        "start": 181.14000000000001,
        "temperature": 0,
        "text": " because this is the one we're going to save",
        "tokens": [
          51168,
          570,
          341,
          307,
          264,
          472,
          321,
          434,
          516,
          281,
          3155,
          51246
        ]
      },
      {
        "avg_logprob": -0.29007709317091035,
        "compression_ratio": 1.9404761904761905,
        "end": 183.66,
        "id": 81,
        "no_speech_prob": 0.000018631733837537467,
        "seek": 16506,
        "start": 182.7,
        "temperature": 0,
        "text": " as long as it works.",
        "tokens": [
          51246,
          382,
          938,
          382,
          309,
          1985,
          13,
          51294
        ]
      },
      {
        "avg_logprob": -0.29007709317091035,
        "compression_ratio": 1.9404761904761905,
        "end": 185.74,
        "id": 82,
        "no_speech_prob": 0.000018631733837537467,
        "seek": 16506,
        "start": 183.66,
        "temperature": 0,
        "text": " All right, so let's do the same thing.",
        "tokens": [
          51294,
          1057,
          558,
          11,
          370,
          718,
          311,
          360,
          264,
          912,
          551,
          13,
          51398
        ]
      },
      {
        "avg_logprob": -0.29007709317091035,
        "compression_ratio": 1.9404761904761905,
        "end": 187.82,
        "id": 83,
        "no_speech_prob": 0.000018631733837537467,
        "seek": 16506,
        "start": 185.74,
        "temperature": 0,
        "text": " Happy, happy, happy, happy.",
        "tokens": [
          51398,
          8277,
          11,
          2055,
          11,
          2055,
          11,
          2055,
          13,
          51502
        ]
      },
      {
        "avg_logprob": -0.29007709317091035,
        "compression_ratio": 1.9404761904761905,
        "end": 190.64000000000001,
        "id": 84,
        "no_speech_prob": 0.000018631733837537467,
        "seek": 16506,
        "start": 187.82,
        "temperature": 0,
        "text": " Train whistle is a happy thing.",
        "tokens": [
          51502,
          314,
          7146,
          23470,
          307,
          257,
          2055,
          551,
          13,
          51643
        ]
      },
      {
        "avg_logprob": -0.29007709317091035,
        "compression_ratio": 1.9404761904761905,
        "end": 192.86,
        "id": 85,
        "no_speech_prob": 0.000018631733837537467,
        "seek": 16506,
        "start": 190.64000000000001,
        "temperature": 0,
        "text": " A happy, happy, happy thing.",
        "tokens": [
          51643,
          316,
          2055,
          11,
          2055,
          11,
          2055,
          551,
          13,
          51754
        ]
      },
      {
        "avg_logprob": -0.29007709317091035,
        "compression_ratio": 1.9404761904761905,
        "end": 194.54,
        "id": 86,
        "no_speech_prob": 0.000018631733837537467,
        "seek": 16506,
        "start": 192.86,
        "temperature": 0,
        "text": " Just me is very sad.",
        "tokens": [
          51754,
          1449,
          385,
          307,
          588,
          4227,
          13,
          51838
        ]
      },
      {
        "avg_logprob": -0.23688933685535693,
        "compression_ratio": 1.7063829787234042,
        "end": 195.85999999999999,
        "id": 87,
        "no_speech_prob": 0.000006962252427911153,
        "seek": 19454,
        "start": 195.01999999999998,
        "temperature": 0,
        "text": " There's no train whistle.",
        "tokens": [
          50388,
          821,
          311,
          572,
          3847,
          23470,
          13,
          50430
        ]
      },
      {
        "avg_logprob": -0.23688933685535693,
        "compression_ratio": 1.7063829787234042,
        "end": 197.45999999999998,
        "id": 88,
        "no_speech_prob": 0.000006962252427911153,
        "seek": 19454,
        "start": 195.85999999999999,
        "temperature": 0,
        "text": " I'm so sad, I'm very sad, I'm very sad",
        "tokens": [
          50430,
          286,
          478,
          370,
          4227,
          11,
          286,
          478,
          588,
          4227,
          11,
          286,
          478,
          588,
          4227,
          50510
        ]
      },
      {
        "avg_logprob": -0.23688933685535693,
        "compression_ratio": 1.7063829787234042,
        "end": 199.06,
        "id": 89,
        "no_speech_prob": 0.000006962252427911153,
        "seek": 19454,
        "start": 197.45999999999998,
        "temperature": 0,
        "text": " and now I'm going to train this.",
        "tokens": [
          50510,
          293,
          586,
          286,
          478,
          516,
          281,
          3847,
          341,
          13,
          50590
        ]
      },
      {
        "avg_logprob": -0.23688933685535693,
        "compression_ratio": 1.7063829787234042,
        "end": 202.26,
        "id": 90,
        "no_speech_prob": 0.000006962252427911153,
        "seek": 19454,
        "start": 200.7,
        "temperature": 0,
        "text": " Weird how the loss is zero.",
        "tokens": [
          50672,
          32033,
          577,
          264,
          4470,
          307,
          4018,
          13,
          50750
        ]
      },
      {
        "avg_logprob": -0.23688933685535693,
        "compression_ratio": 1.7063829787234042,
        "end": 204.34,
        "id": 91,
        "no_speech_prob": 0.000006962252427911153,
        "seek": 19454,
        "start": 202.26,
        "temperature": 0,
        "text": " I'm just going to not worry about that too much.",
        "tokens": [
          50750,
          286,
          478,
          445,
          516,
          281,
          406,
          3292,
          466,
          300,
          886,
          709,
          13,
          50854
        ]
      },
      {
        "avg_logprob": -0.23688933685535693,
        "compression_ratio": 1.7063829787234042,
        "end": 205.98,
        "id": 92,
        "no_speech_prob": 0.000006962252427911153,
        "seek": 19454,
        "start": 204.34,
        "temperature": 0,
        "text": " I'm going to hit save.",
        "tokens": [
          50854,
          286,
          478,
          516,
          281,
          2045,
          3155,
          13,
          50936
        ]
      },
      {
        "avg_logprob": -0.23688933685535693,
        "compression_ratio": 1.7063829787234042,
        "end": 209.48,
        "id": 93,
        "no_speech_prob": 0.000006962252427911153,
        "seek": 19454,
        "start": 207.54,
        "temperature": 0,
        "text": " And now, you can see that down here by the way",
        "tokens": [
          51014,
          400,
          586,
          11,
          291,
          393,
          536,
          300,
          760,
          510,
          538,
          264,
          636,
          51111
        ]
      },
      {
        "avg_logprob": -0.23688933685535693,
        "compression_ratio": 1.7063829787234042,
        "end": 211.5,
        "id": 94,
        "no_speech_prob": 0.000006962252427911153,
        "seek": 19454,
        "start": 209.48,
        "temperature": 0,
        "text": " that I did this a couple times practicing.",
        "tokens": [
          51111,
          300,
          286,
          630,
          341,
          257,
          1916,
          1413,
          11350,
          13,
          51212
        ]
      },
      {
        "avg_logprob": -0.23688933685535693,
        "compression_ratio": 1.7063829787234042,
        "end": 215.62,
        "id": 95,
        "no_speech_prob": 0.000006962252427911153,
        "seek": 19454,
        "start": 211.5,
        "temperature": 0,
        "text": " Now, what it did is it downloaded, come on,",
        "tokens": [
          51212,
          823,
          11,
          437,
          309,
          630,
          307,
          309,
          21748,
          11,
          808,
          322,
          11,
          51418
        ]
      },
      {
        "avg_logprob": -0.23688933685535693,
        "compression_ratio": 1.7063829787234042,
        "end": 219.07999999999998,
        "id": 96,
        "no_speech_prob": 0.000006962252427911153,
        "seek": 19454,
        "start": 215.62,
        "temperature": 0,
        "text": " to my download directory two files,",
        "tokens": [
          51418,
          281,
          452,
          5484,
          21120,
          732,
          7098,
          11,
          51591
        ]
      },
      {
        "avg_logprob": -0.23688933685535693,
        "compression_ratio": 1.7063829787234042,
        "end": 222.38,
        "id": 97,
        "no_speech_prob": 0.000006962252427911153,
        "seek": 19454,
        "start": 219.07999999999998,
        "temperature": 0,
        "text": " model.json and model.weights.bin.",
        "tokens": [
          51591,
          2316,
          13,
          73,
          3015,
          293,
          2316,
          13,
          826,
          5761,
          13,
          13496,
          13,
          51756
        ]
      },
      {
        "avg_logprob": -0.2604997040795498,
        "compression_ratio": 1.6790123456790123,
        "end": 225.18,
        "id": 98,
        "no_speech_prob": 0.000002406101657470572,
        "seek": 22238,
        "start": 222.38,
        "temperature": 0,
        "text": " So those files will end up wherever the default",
        "tokens": [
          50364,
          407,
          729,
          7098,
          486,
          917,
          493,
          8660,
          264,
          7576,
          50504
        ]
      },
      {
        "avg_logprob": -0.2604997040795498,
        "compression_ratio": 1.6790123456790123,
        "end": 227.5,
        "id": 99,
        "no_speech_prob": 0.000002406101657470572,
        "seek": 22238,
        "start": 225.18,
        "temperature": 0,
        "text": " downloads directory of your browser is",
        "tokens": [
          50504,
          36553,
          21120,
          295,
          428,
          11185,
          307,
          50620
        ]
      },
      {
        "avg_logprob": -0.2604997040795498,
        "compression_ratio": 1.6790123456790123,
        "end": 230.18,
        "id": 100,
        "no_speech_prob": 0.000002406101657470572,
        "seek": 22238,
        "start": 227.5,
        "temperature": 0,
        "text": " and the next step is just to load those files in.",
        "tokens": [
          50620,
          293,
          264,
          958,
          1823,
          307,
          445,
          281,
          3677,
          729,
          7098,
          294,
          13,
          50754
        ]
      },
      {
        "avg_logprob": -0.2604997040795498,
        "compression_ratio": 1.6790123456790123,
        "end": 231.66,
        "id": 101,
        "no_speech_prob": 0.000002406101657470572,
        "seek": 22238,
        "start": 230.18,
        "temperature": 0,
        "text": " But before we load them, let's talk about",
        "tokens": [
          50754,
          583,
          949,
          321,
          3677,
          552,
          11,
          718,
          311,
          751,
          466,
          50828
        ]
      },
      {
        "avg_logprob": -0.2604997040795498,
        "compression_ratio": 1.6790123456790123,
        "end": 233.46,
        "id": 102,
        "no_speech_prob": 0.000002406101657470572,
        "seek": 22238,
        "start": 231.66,
        "temperature": 0,
        "text": " what's in those files.",
        "tokens": [
          50828,
          437,
          311,
          294,
          729,
          7098,
          13,
          50918
        ]
      },
      {
        "avg_logprob": -0.2604997040795498,
        "compression_ratio": 1.6790123456790123,
        "end": 234.29999999999998,
        "id": 103,
        "no_speech_prob": 0.000002406101657470572,
        "seek": 22238,
        "start": 233.46,
        "temperature": 0,
        "text": " So there's two files.",
        "tokens": [
          50918,
          407,
          456,
          311,
          732,
          7098,
          13,
          50960
        ]
      },
      {
        "avg_logprob": -0.2604997040795498,
        "compression_ratio": 1.6790123456790123,
        "end": 239.3,
        "id": 104,
        "no_speech_prob": 0.000002406101657470572,
        "seek": 22238,
        "start": 234.29999999999998,
        "temperature": 0,
        "text": " I said model.json, model.weights.bin.",
        "tokens": [
          50960,
          286,
          848,
          2316,
          13,
          73,
          3015,
          11,
          2316,
          13,
          826,
          5761,
          13,
          13496,
          13,
          51210
        ]
      },
      {
        "avg_logprob": -0.2604997040795498,
        "compression_ratio": 1.6790123456790123,
        "end": 245.78,
        "id": 105,
        "no_speech_prob": 0.000002406101657470572,
        "seek": 22238,
        "start": 241.74,
        "temperature": 0,
        "text": " Okay, so what is a neural network?",
        "tokens": [
          51332,
          1033,
          11,
          370,
          437,
          307,
          257,
          18161,
          3209,
          30,
          51534
        ]
      },
      {
        "avg_logprob": -0.2604997040795498,
        "compression_ratio": 1.6790123456790123,
        "end": 246.94,
        "id": 106,
        "no_speech_prob": 0.000002406101657470572,
        "seek": 22238,
        "start": 245.78,
        "temperature": 0,
        "text": " What is a machine learning model?",
        "tokens": [
          51534,
          708,
          307,
          257,
          3479,
          2539,
          2316,
          30,
          51592
        ]
      },
      {
        "avg_logprob": -0.2604997040795498,
        "compression_ratio": 1.6790123456790123,
        "end": 247.9,
        "id": 107,
        "no_speech_prob": 0.000002406101657470572,
        "seek": 22238,
        "start": 246.94,
        "temperature": 0,
        "text": " What is the thing that we're saving?",
        "tokens": [
          51592,
          708,
          307,
          264,
          551,
          300,
          321,
          434,
          6816,
          30,
          51640
        ]
      },
      {
        "avg_logprob": -0.2604997040795498,
        "compression_ratio": 1.6790123456790123,
        "end": 250.1,
        "id": 108,
        "no_speech_prob": 0.000002406101657470572,
        "seek": 22238,
        "start": 247.9,
        "temperature": 0,
        "text": " Well, in this case, it's actually saving",
        "tokens": [
          51640,
          1042,
          11,
          294,
          341,
          1389,
          11,
          309,
          311,
          767,
          6816,
          51750
        ]
      },
      {
        "avg_logprob": -0.20749975575341117,
        "compression_ratio": 1.7647058823529411,
        "end": 252.94,
        "id": 109,
        "no_speech_prob": 0.0000065404346969444305,
        "seek": 25010,
        "start": 250.1,
        "temperature": 0,
        "text": " the configuration of a neural network.",
        "tokens": [
          50364,
          264,
          11694,
          295,
          257,
          18161,
          3209,
          13,
          50506
        ]
      },
      {
        "avg_logprob": -0.20749975575341117,
        "compression_ratio": 1.7647058823529411,
        "end": 254.92,
        "id": 110,
        "no_speech_prob": 0.0000065404346969444305,
        "seek": 25010,
        "start": 252.94,
        "temperature": 0,
        "text": " Now, if you want to know what a neural network is,",
        "tokens": [
          50506,
          823,
          11,
          498,
          291,
          528,
          281,
          458,
          437,
          257,
          18161,
          3209,
          307,
          11,
          50605
        ]
      },
      {
        "avg_logprob": -0.20749975575341117,
        "compression_ratio": 1.7647058823529411,
        "end": 257.65999999999997,
        "id": 111,
        "no_speech_prob": 0.0000065404346969444305,
        "seek": 25010,
        "start": 254.92,
        "temperature": 0,
        "text": " I have some videos about that but I would refer you",
        "tokens": [
          50605,
          286,
          362,
          512,
          2145,
          466,
          300,
          457,
          286,
          576,
          2864,
          291,
          50742
        ]
      },
      {
        "avg_logprob": -0.20749975575341117,
        "compression_ratio": 1.7647058823529411,
        "end": 260.54,
        "id": 112,
        "no_speech_prob": 0.0000065404346969444305,
        "seek": 25010,
        "start": 257.65999999999997,
        "temperature": 0,
        "text": " to the three blue, one brown video,",
        "tokens": [
          50742,
          281,
          264,
          1045,
          3344,
          11,
          472,
          6292,
          960,
          11,
          50886
        ]
      },
      {
        "avg_logprob": -0.20749975575341117,
        "compression_ratio": 1.7647058823529411,
        "end": 261.54,
        "id": 113,
        "no_speech_prob": 0.0000065404346969444305,
        "seek": 25010,
        "start": 260.54,
        "temperature": 0,
        "text": " what is a neural network?",
        "tokens": [
          50886,
          437,
          307,
          257,
          18161,
          3209,
          30,
          50936
        ]
      },
      {
        "avg_logprob": -0.20749975575341117,
        "compression_ratio": 1.7647058823529411,
        "end": 262.98,
        "id": 114,
        "no_speech_prob": 0.0000065404346969444305,
        "seek": 25010,
        "start": 261.54,
        "temperature": 0,
        "text": " I will link to that in this video's description.",
        "tokens": [
          50936,
          286,
          486,
          2113,
          281,
          300,
          294,
          341,
          960,
          311,
          3855,
          13,
          51008
        ]
      },
      {
        "avg_logprob": -0.20749975575341117,
        "compression_ratio": 1.7647058823529411,
        "end": 265.34,
        "id": 115,
        "no_speech_prob": 0.0000065404346969444305,
        "seek": 25010,
        "start": 262.98,
        "temperature": 0,
        "text": " That will give you a much bigger deep dive",
        "tokens": [
          51008,
          663,
          486,
          976,
          291,
          257,
          709,
          3801,
          2452,
          9192,
          51126
        ]
      },
      {
        "avg_logprob": -0.20749975575341117,
        "compression_ratio": 1.7647058823529411,
        "end": 267.34,
        "id": 116,
        "no_speech_prob": 0.0000065404346969444305,
        "seek": 25010,
        "start": 265.34,
        "temperature": 0,
        "text": " into those details.",
        "tokens": [
          51126,
          666,
          729,
          4365,
          13,
          51226
        ]
      },
      {
        "avg_logprob": -0.20749975575341117,
        "compression_ratio": 1.7647058823529411,
        "end": 269.18,
        "id": 117,
        "no_speech_prob": 0.0000065404346969444305,
        "seek": 25010,
        "start": 267.34,
        "temperature": 0,
        "text": " But if you look at that video, what you'll see",
        "tokens": [
          51226,
          583,
          498,
          291,
          574,
          412,
          300,
          960,
          11,
          437,
          291,
          603,
          536,
          51318
        ]
      },
      {
        "avg_logprob": -0.20749975575341117,
        "compression_ratio": 1.7647058823529411,
        "end": 271.58,
        "id": 118,
        "no_speech_prob": 0.0000065404346969444305,
        "seek": 25010,
        "start": 269.18,
        "temperature": 0,
        "text": " is there's basically like a big diagram",
        "tokens": [
          51318,
          307,
          456,
          311,
          1936,
          411,
          257,
          955,
          10686,
          51438
        ]
      },
      {
        "avg_logprob": -0.20749975575341117,
        "compression_ratio": 1.7647058823529411,
        "end": 274.98,
        "id": 119,
        "no_speech_prob": 0.0000065404346969444305,
        "seek": 25010,
        "start": 271.58,
        "temperature": 0,
        "text": " and the diagram has a bunch of inputs.",
        "tokens": [
          51438,
          293,
          264,
          10686,
          575,
          257,
          3840,
          295,
          15743,
          13,
          51608
        ]
      },
      {
        "avg_logprob": -0.20749975575341117,
        "compression_ratio": 1.7647058823529411,
        "end": 276.94,
        "id": 120,
        "no_speech_prob": 0.0000065404346969444305,
        "seek": 25010,
        "start": 274.98,
        "temperature": 0,
        "text": " It has some outputs.",
        "tokens": [
          51608,
          467,
          575,
          512,
          23930,
          13,
          51706
        ]
      },
      {
        "avg_logprob": -0.20749975575341117,
        "compression_ratio": 1.7647058823529411,
        "end": 278.38,
        "id": 121,
        "no_speech_prob": 0.0000065404346969444305,
        "seek": 25010,
        "start": 276.94,
        "temperature": 0,
        "text": " By the way, in this case, we could actually say",
        "tokens": [
          51706,
          3146,
          264,
          636,
          11,
          294,
          341,
          1389,
          11,
          321,
          727,
          767,
          584,
          51778
        ]
      },
      {
        "avg_logprob": -0.23047692926080376,
        "compression_ratio": 1.7705627705627707,
        "end": 283.38,
        "id": 122,
        "no_speech_prob": 0.0000014593756532121915,
        "seek": 27838,
        "start": 278.38,
        "temperature": 0,
        "text": " the outputs are just two, a happy and a sad.",
        "tokens": [
          50364,
          264,
          23930,
          366,
          445,
          732,
          11,
          257,
          2055,
          293,
          257,
          4227,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.23047692926080376,
        "compression_ratio": 1.7705627705627707,
        "end": 285.86,
        "id": 123,
        "no_speech_prob": 0.0000014593756532121915,
        "seek": 27838,
        "start": 283.9,
        "temperature": 0,
        "text": " And what the neural network, what the machine learning",
        "tokens": [
          50640,
          400,
          437,
          264,
          18161,
          3209,
          11,
          437,
          264,
          3479,
          2539,
          50738
        ]
      },
      {
        "avg_logprob": -0.23047692926080376,
        "compression_ratio": 1.7705627705627707,
        "end": 290.86,
        "id": 124,
        "no_speech_prob": 0.0000014593756532121915,
        "seek": 27838,
        "start": 285.86,
        "temperature": 0,
        "text": " model outputs is a probability, maybe like 80%",
        "tokens": [
          50738,
          2316,
          23930,
          307,
          257,
          8482,
          11,
          1310,
          411,
          4688,
          4,
          50988
        ]
      },
      {
        "avg_logprob": -0.23047692926080376,
        "compression_ratio": 1.7705627705627707,
        "end": 293.9,
        "id": 125,
        "no_speech_prob": 0.0000014593756532121915,
        "seek": 27838,
        "start": 291.3,
        "temperature": 0,
        "text": " of it being happy, of that image being happy",
        "tokens": [
          51010,
          295,
          309,
          885,
          2055,
          11,
          295,
          300,
          3256,
          885,
          2055,
          51140
        ]
      },
      {
        "avg_logprob": -0.23047692926080376,
        "compression_ratio": 1.7705627705627707,
        "end": 296.34,
        "id": 126,
        "no_speech_prob": 0.0000014593756532121915,
        "seek": 27838,
        "start": 293.9,
        "temperature": 0,
        "text": " and 20% that image is sad.",
        "tokens": [
          51140,
          293,
          945,
          4,
          300,
          3256,
          307,
          4227,
          13,
          51262
        ]
      },
      {
        "avg_logprob": -0.23047692926080376,
        "compression_ratio": 1.7705627705627707,
        "end": 299.58,
        "id": 127,
        "no_speech_prob": 0.0000014593756532121915,
        "seek": 27838,
        "start": 296.34,
        "temperature": 0,
        "text": " So the whole point of this is to feed in an image, right?",
        "tokens": [
          51262,
          407,
          264,
          1379,
          935,
          295,
          341,
          307,
          281,
          3154,
          294,
          364,
          3256,
          11,
          558,
          30,
          51424
        ]
      },
      {
        "avg_logprob": -0.23047692926080376,
        "compression_ratio": 1.7705627705627707,
        "end": 303.86,
        "id": 128,
        "no_speech_prob": 0.0000014593756532121915,
        "seek": 27838,
        "start": 299.58,
        "temperature": 0,
        "text": " It's the image and maybe all the pixels of the image",
        "tokens": [
          51424,
          467,
          311,
          264,
          3256,
          293,
          1310,
          439,
          264,
          18668,
          295,
          264,
          3256,
          51638
        ]
      },
      {
        "avg_logprob": -0.23047692926080376,
        "compression_ratio": 1.7705627705627707,
        "end": 305.26,
        "id": 129,
        "no_speech_prob": 0.0000014593756532121915,
        "seek": 27838,
        "start": 303.86,
        "temperature": 0,
        "text": " that are actually these inputs.",
        "tokens": [
          51638,
          300,
          366,
          767,
          613,
          15743,
          13,
          51708
        ]
      },
      {
        "avg_logprob": -0.23047692926080376,
        "compression_ratio": 1.7705627705627707,
        "end": 307.42,
        "id": 130,
        "no_speech_prob": 0.0000014593756532121915,
        "seek": 27838,
        "start": 305.26,
        "temperature": 0,
        "text": " It goes through this magic neural network thing",
        "tokens": [
          51708,
          467,
          1709,
          807,
          341,
          5585,
          18161,
          3209,
          551,
          51816
        ]
      },
      {
        "avg_logprob": -0.2359735071659088,
        "compression_ratio": 1.6821428571428572,
        "end": 308.74,
        "id": 131,
        "no_speech_prob": 5.804996590086375e-7,
        "seek": 30742,
        "start": 307.42,
        "temperature": 0,
        "text": " which isn't really magic, it's a thing",
        "tokens": [
          50364,
          597,
          1943,
          380,
          534,
          5585,
          11,
          309,
          311,
          257,
          551,
          50430
        ]
      },
      {
        "avg_logprob": -0.2359735071659088,
        "compression_ratio": 1.6821428571428572,
        "end": 310.22,
        "id": 132,
        "no_speech_prob": 5.804996590086375e-7,
        "seek": 30742,
        "start": 308.74,
        "temperature": 0,
        "text": " that you can learn about.",
        "tokens": [
          50430,
          300,
          291,
          393,
          1466,
          466,
          13,
          50504
        ]
      },
      {
        "avg_logprob": -0.2359735071659088,
        "compression_ratio": 1.6821428571428572,
        "end": 312.90000000000003,
        "id": 133,
        "no_speech_prob": 5.804996590086375e-7,
        "seek": 30742,
        "start": 310.22,
        "temperature": 0,
        "text": " And then out the other end comes a guess",
        "tokens": [
          50504,
          400,
          550,
          484,
          264,
          661,
          917,
          1487,
          257,
          2041,
          50638
        ]
      },
      {
        "avg_logprob": -0.2359735071659088,
        "compression_ratio": 1.6821428571428572,
        "end": 314.38,
        "id": 134,
        "no_speech_prob": 5.804996590086375e-7,
        "seek": 30742,
        "start": 312.90000000000003,
        "temperature": 0,
        "text": " as to whether it's happy or sad.",
        "tokens": [
          50638,
          382,
          281,
          1968,
          309,
          311,
          2055,
          420,
          4227,
          13,
          50712
        ]
      },
      {
        "avg_logprob": -0.2359735071659088,
        "compression_ratio": 1.6821428571428572,
        "end": 316.90000000000003,
        "id": 135,
        "no_speech_prob": 5.804996590086375e-7,
        "seek": 30742,
        "start": 314.38,
        "temperature": 0,
        "text": " Now what is all this stuff in the middle?",
        "tokens": [
          50712,
          823,
          437,
          307,
          439,
          341,
          1507,
          294,
          264,
          2808,
          30,
          50838
        ]
      },
      {
        "avg_logprob": -0.2359735071659088,
        "compression_ratio": 1.6821428571428572,
        "end": 319.18,
        "id": 136,
        "no_speech_prob": 5.804996590086375e-7,
        "seek": 30742,
        "start": 316.90000000000003,
        "temperature": 0,
        "text": " The stuff in the middle is typically referred to",
        "tokens": [
          50838,
          440,
          1507,
          294,
          264,
          2808,
          307,
          5850,
          10839,
          281,
          50952
        ]
      },
      {
        "avg_logprob": -0.2359735071659088,
        "compression_ratio": 1.6821428571428572,
        "end": 321.14000000000004,
        "id": 137,
        "no_speech_prob": 5.804996590086375e-7,
        "seek": 30742,
        "start": 319.18,
        "temperature": 0,
        "text": " and there are many different styles and flavors",
        "tokens": [
          50952,
          293,
          456,
          366,
          867,
          819,
          13273,
          293,
          16303,
          51050
        ]
      },
      {
        "avg_logprob": -0.2359735071659088,
        "compression_ratio": 1.6821428571428572,
        "end": 324.02000000000004,
        "id": 138,
        "no_speech_prob": 5.804996590086375e-7,
        "seek": 30742,
        "start": 321.14000000000004,
        "temperature": 0,
        "text": " and kinds of neural network but in the sort of zoomed out",
        "tokens": [
          51050,
          293,
          3685,
          295,
          18161,
          3209,
          457,
          294,
          264,
          1333,
          295,
          8863,
          292,
          484,
          51194
        ]
      },
      {
        "avg_logprob": -0.2359735071659088,
        "compression_ratio": 1.6821428571428572,
        "end": 326.82,
        "id": 139,
        "no_speech_prob": 5.804996590086375e-7,
        "seek": 30742,
        "start": 324.02000000000004,
        "temperature": 0,
        "text": " view, in general terms, is what's known as a hidden layer",
        "tokens": [
          51194,
          1910,
          11,
          294,
          2674,
          2115,
          11,
          307,
          437,
          311,
          2570,
          382,
          257,
          7633,
          4583,
          51334
        ]
      },
      {
        "avg_logprob": -0.2359735071659088,
        "compression_ratio": 1.6821428571428572,
        "end": 328.5,
        "id": 140,
        "no_speech_prob": 5.804996590086375e-7,
        "seek": 30742,
        "start": 326.82,
        "temperature": 0,
        "text": " or hidden layers.",
        "tokens": [
          51334,
          420,
          7633,
          7914,
          13,
          51418
        ]
      },
      {
        "avg_logprob": -0.2359735071659088,
        "compression_ratio": 1.6821428571428572,
        "end": 333.06,
        "id": 141,
        "no_speech_prob": 5.804996590086375e-7,
        "seek": 30742,
        "start": 328.5,
        "temperature": 0,
        "text": " So every input is connected to the output but not directly.",
        "tokens": [
          51418,
          407,
          633,
          4846,
          307,
          4582,
          281,
          264,
          5598,
          457,
          406,
          3838,
          13,
          51646
        ]
      },
      {
        "avg_logprob": -0.2250159103258521,
        "compression_ratio": 1.951111111111111,
        "end": 337.58,
        "id": 142,
        "no_speech_prob": 0.000018925145923276432,
        "seek": 33306,
        "start": 333.06,
        "temperature": 0,
        "text": " There are some amount of nodes, maybe two hidden layers",
        "tokens": [
          50364,
          821,
          366,
          512,
          2372,
          295,
          13891,
          11,
          1310,
          732,
          7633,
          7914,
          50590
        ]
      },
      {
        "avg_logprob": -0.2250159103258521,
        "compression_ratio": 1.951111111111111,
        "end": 341.32,
        "id": 143,
        "no_speech_prob": 0.000018925145923276432,
        "seek": 33306,
        "start": 337.58,
        "temperature": 0,
        "text": " each with four nodes and every input is connected",
        "tokens": [
          50590,
          1184,
          365,
          1451,
          13891,
          293,
          633,
          4846,
          307,
          4582,
          50777
        ]
      },
      {
        "avg_logprob": -0.2250159103258521,
        "compression_ratio": 1.951111111111111,
        "end": 343.54,
        "id": 144,
        "no_speech_prob": 0.000018925145923276432,
        "seek": 33306,
        "start": 341.32,
        "temperature": 0,
        "text": " to every node and then every node is connected",
        "tokens": [
          50777,
          281,
          633,
          9984,
          293,
          550,
          633,
          9984,
          307,
          4582,
          50888
        ]
      },
      {
        "avg_logprob": -0.2250159103258521,
        "compression_ratio": 1.951111111111111,
        "end": 345.42,
        "id": 145,
        "no_speech_prob": 0.000018925145923276432,
        "seek": 33306,
        "start": 343.54,
        "temperature": 0,
        "text": " to every node and then every node is connected",
        "tokens": [
          50888,
          281,
          633,
          9984,
          293,
          550,
          633,
          9984,
          307,
          4582,
          50982
        ]
      },
      {
        "avg_logprob": -0.2250159103258521,
        "compression_ratio": 1.951111111111111,
        "end": 347.14,
        "id": 146,
        "no_speech_prob": 0.000018925145923276432,
        "seek": 33306,
        "start": 345.42,
        "temperature": 0,
        "text": " to every output and so on and so forth.",
        "tokens": [
          50982,
          281,
          633,
          5598,
          293,
          370,
          322,
          293,
          370,
          5220,
          13,
          51068
        ]
      },
      {
        "avg_logprob": -0.2250159103258521,
        "compression_ratio": 1.951111111111111,
        "end": 349.66,
        "id": 147,
        "no_speech_prob": 0.000018925145923276432,
        "seek": 33306,
        "start": 347.14,
        "temperature": 0,
        "text": " So I could be here all day trying to do this diagram",
        "tokens": [
          51068,
          407,
          286,
          727,
          312,
          510,
          439,
          786,
          1382,
          281,
          360,
          341,
          10686,
          51194
        ]
      },
      {
        "avg_logprob": -0.2250159103258521,
        "compression_ratio": 1.951111111111111,
        "end": 351.72,
        "id": 148,
        "no_speech_prob": 0.000018925145923276432,
        "seek": 33306,
        "start": 349.66,
        "temperature": 0,
        "text": " and draw every connection between everything.",
        "tokens": [
          51194,
          293,
          2642,
          633,
          4984,
          1296,
          1203,
          13,
          51297
        ]
      },
      {
        "avg_logprob": -0.2250159103258521,
        "compression_ratio": 1.951111111111111,
        "end": 353.02,
        "id": 149,
        "no_speech_prob": 0.000018925145923276432,
        "seek": 33306,
        "start": 351.72,
        "temperature": 0,
        "text": " I'm not going to do that.",
        "tokens": [
          51297,
          286,
          478,
          406,
          516,
          281,
          360,
          300,
          13,
          51362
        ]
      },
      {
        "avg_logprob": -0.2250159103258521,
        "compression_ratio": 1.951111111111111,
        "end": 357.66,
        "id": 150,
        "no_speech_prob": 0.000018925145923276432,
        "seek": 33306,
        "start": 353.02,
        "temperature": 0,
        "text": " But all of the information about here is what is saved",
        "tokens": [
          51362,
          583,
          439,
          295,
          264,
          1589,
          466,
          510,
          307,
          437,
          307,
          6624,
          51594
        ]
      },
      {
        "avg_logprob": -0.2250159103258521,
        "compression_ratio": 1.951111111111111,
        "end": 359.06,
        "id": 151,
        "no_speech_prob": 0.000018925145923276432,
        "seek": 33306,
        "start": 357.66,
        "temperature": 0,
        "text": " in these two files.",
        "tokens": [
          51594,
          294,
          613,
          732,
          7098,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.2110544921486241,
        "compression_ratio": 1.7953020134228188,
        "end": 363.82,
        "id": 152,
        "no_speech_prob": 0.00001593660817889031,
        "seek": 35906,
        "start": 359.06,
        "temperature": 0,
        "text": " Model.json is a file that just explains all of these pieces.",
        "tokens": [
          50364,
          17105,
          13,
          73,
          3015,
          307,
          257,
          3991,
          300,
          445,
          13948,
          439,
          295,
          613,
          3755,
          13,
          50602
        ]
      },
      {
        "avg_logprob": -0.2110544921486241,
        "compression_ratio": 1.7953020134228188,
        "end": 367.56,
        "id": 153,
        "no_speech_prob": 0.00001593660817889031,
        "seek": 35906,
        "start": 363.82,
        "temperature": 0,
        "text": " The layers, the outputs, the inputs, all of that stuff.",
        "tokens": [
          50602,
          440,
          7914,
          11,
          264,
          23930,
          11,
          264,
          15743,
          11,
          439,
          295,
          300,
          1507,
          13,
          50789
        ]
      },
      {
        "avg_logprob": -0.2110544921486241,
        "compression_ratio": 1.7953020134228188,
        "end": 370.42,
        "id": 154,
        "no_speech_prob": 0.00001593660817889031,
        "seek": 35906,
        "start": 367.56,
        "temperature": 0,
        "text": " That is what is in model.json.",
        "tokens": [
          50789,
          663,
          307,
          437,
          307,
          294,
          2316,
          13,
          73,
          3015,
          13,
          50932
        ]
      },
      {
        "avg_logprob": -0.2110544921486241,
        "compression_ratio": 1.7953020134228188,
        "end": 372.74,
        "id": 155,
        "no_speech_prob": 0.00001593660817889031,
        "seek": 35906,
        "start": 370.42,
        "temperature": 0,
        "text": " In a moment I'll just open up that file and look at it.",
        "tokens": [
          50932,
          682,
          257,
          1623,
          286,
          603,
          445,
          1269,
          493,
          300,
          3991,
          293,
          574,
          412,
          309,
          13,
          51048
        ]
      },
      {
        "avg_logprob": -0.2110544921486241,
        "compression_ratio": 1.7953020134228188,
        "end": 374.82,
        "id": 156,
        "no_speech_prob": 0.00001593660817889031,
        "seek": 35906,
        "start": 372.74,
        "temperature": 0,
        "text": " Model.weights is an interesting thing.",
        "tokens": [
          51048,
          17105,
          13,
          826,
          5761,
          307,
          364,
          1880,
          551,
          13,
          51152
        ]
      },
      {
        "avg_logprob": -0.2110544921486241,
        "compression_ratio": 1.7953020134228188,
        "end": 376.58,
        "id": 157,
        "no_speech_prob": 0.00001593660817889031,
        "seek": 35906,
        "start": 374.82,
        "temperature": 0,
        "text": " So the magic of a neural network,",
        "tokens": [
          51152,
          407,
          264,
          5585,
          295,
          257,
          18161,
          3209,
          11,
          51240
        ]
      },
      {
        "avg_logprob": -0.2110544921486241,
        "compression_ratio": 1.7953020134228188,
        "end": 379.46,
        "id": 158,
        "no_speech_prob": 0.00001593660817889031,
        "seek": 35906,
        "start": 376.58,
        "temperature": 0,
        "text": " what makes a neural network work is a number",
        "tokens": [
          51240,
          437,
          1669,
          257,
          18161,
          3209,
          589,
          307,
          257,
          1230,
          51384
        ]
      },
      {
        "avg_logprob": -0.2110544921486241,
        "compression_ratio": 1.7953020134228188,
        "end": 381.02,
        "id": 159,
        "no_speech_prob": 0.00001593660817889031,
        "seek": 35906,
        "start": 379.46,
        "temperature": 0,
        "text": " that's associated with every single one",
        "tokens": [
          51384,
          300,
          311,
          6615,
          365,
          633,
          2167,
          472,
          51462
        ]
      },
      {
        "avg_logprob": -0.2110544921486241,
        "compression_ratio": 1.7953020134228188,
        "end": 382.56,
        "id": 160,
        "no_speech_prob": 0.00001593660817889031,
        "seek": 35906,
        "start": 381.02,
        "temperature": 0,
        "text": " of these connections known as a weight.",
        "tokens": [
          51462,
          295,
          613,
          9271,
          2570,
          382,
          257,
          3364,
          13,
          51539
        ]
      },
      {
        "avg_logprob": -0.2110544921486241,
        "compression_ratio": 1.7953020134228188,
        "end": 385.12,
        "id": 161,
        "no_speech_prob": 0.00001593660817889031,
        "seek": 35906,
        "start": 382.56,
        "temperature": 0,
        "text": " You can think of it as like a whole bunch of dials.",
        "tokens": [
          51539,
          509,
          393,
          519,
          295,
          309,
          382,
          411,
          257,
          1379,
          3840,
          295,
          5502,
          82,
          13,
          51667
        ]
      },
      {
        "avg_logprob": -0.2110544921486241,
        "compression_ratio": 1.7953020134228188,
        "end": 386.46,
        "id": 162,
        "no_speech_prob": 0.00001593660817889031,
        "seek": 35906,
        "start": 385.12,
        "temperature": 0,
        "text": " So I'm tuning the dials, right?",
        "tokens": [
          51667,
          407,
          286,
          478,
          15164,
          264,
          5502,
          82,
          11,
          558,
          30,
          51734
        ]
      },
      {
        "avg_logprob": -0.2110544921486241,
        "compression_ratio": 1.7953020134228188,
        "end": 388.12,
        "id": 163,
        "no_speech_prob": 0.00001593660817889031,
        "seek": 35906,
        "start": 386.46,
        "temperature": 0,
        "text": " I'm trying to get the dials in the right position",
        "tokens": [
          51734,
          286,
          478,
          1382,
          281,
          483,
          264,
          5502,
          82,
          294,
          264,
          558,
          2535,
          51817
        ]
      },
      {
        "avg_logprob": -0.2118864174348762,
        "compression_ratio": 1.8112094395280236,
        "end": 391.28000000000003,
        "id": 164,
        "no_speech_prob": 0.000013211950317781884,
        "seek": 38812,
        "start": 388.12,
        "temperature": 0,
        "text": " so that it really makes good guesses about happy versus sad.",
        "tokens": [
          50364,
          370,
          300,
          309,
          534,
          1669,
          665,
          42703,
          466,
          2055,
          5717,
          4227,
          13,
          50522
        ]
      },
      {
        "avg_logprob": -0.2118864174348762,
        "compression_ratio": 1.8112094395280236,
        "end": 392.76,
        "id": 165,
        "no_speech_prob": 0.000013211950317781884,
        "seek": 38812,
        "start": 391.28000000000003,
        "temperature": 0,
        "text": " That's the training process.",
        "tokens": [
          50522,
          663,
          311,
          264,
          3097,
          1399,
          13,
          50596
        ]
      },
      {
        "avg_logprob": -0.2118864174348762,
        "compression_ratio": 1.8112094395280236,
        "end": 394.32,
        "id": 166,
        "no_speech_prob": 0.000013211950317781884,
        "seek": 38812,
        "start": 392.76,
        "temperature": 0,
        "text": " Once that training process is done,",
        "tokens": [
          50596,
          3443,
          300,
          3097,
          1399,
          307,
          1096,
          11,
          50674
        ]
      },
      {
        "avg_logprob": -0.2118864174348762,
        "compression_ratio": 1.8112094395280236,
        "end": 396.32,
        "id": 167,
        "no_speech_prob": 0.000013211950317781884,
        "seek": 38812,
        "start": 394.32,
        "temperature": 0,
        "text": " I want to save where all those dials are.",
        "tokens": [
          50674,
          286,
          528,
          281,
          3155,
          689,
          439,
          729,
          5502,
          82,
          366,
          13,
          50774
        ]
      },
      {
        "avg_logprob": -0.2118864174348762,
        "compression_ratio": 1.8112094395280236,
        "end": 398.28000000000003,
        "id": 168,
        "no_speech_prob": 0.000013211950317781884,
        "seek": 38812,
        "start": 396.32,
        "temperature": 0,
        "text": " All of those numbers are in this file.",
        "tokens": [
          50774,
          1057,
          295,
          729,
          3547,
          366,
          294,
          341,
          3991,
          13,
          50872
        ]
      },
      {
        "avg_logprob": -0.2118864174348762,
        "compression_ratio": 1.8112094395280236,
        "end": 399.92,
        "id": 169,
        "no_speech_prob": 0.000013211950317781884,
        "seek": 38812,
        "start": 398.28000000000003,
        "temperature": 0,
        "text": " This is a binary format file",
        "tokens": [
          50872,
          639,
          307,
          257,
          17434,
          7877,
          3991,
          50954
        ]
      },
      {
        "avg_logprob": -0.2118864174348762,
        "compression_ratio": 1.8112094395280236,
        "end": 401.52,
        "id": 170,
        "no_speech_prob": 0.000013211950317781884,
        "seek": 38812,
        "start": 399.92,
        "temperature": 0,
        "text": " because there's a lot of numbers.",
        "tokens": [
          50954,
          570,
          456,
          311,
          257,
          688,
          295,
          3547,
          13,
          51034
        ]
      },
      {
        "avg_logprob": -0.2118864174348762,
        "compression_ratio": 1.8112094395280236,
        "end": 403.96,
        "id": 171,
        "no_speech_prob": 0.000013211950317781884,
        "seek": 38812,
        "start": 401.52,
        "temperature": 0,
        "text": " Millions upon millions of connections potentially",
        "tokens": [
          51034,
          7190,
          626,
          3564,
          6803,
          295,
          9271,
          7263,
          51156
        ]
      },
      {
        "avg_logprob": -0.2118864174348762,
        "compression_ratio": 1.8112094395280236,
        "end": 405.84000000000003,
        "id": 172,
        "no_speech_prob": 0.000013211950317781884,
        "seek": 38812,
        "start": 403.96,
        "temperature": 0,
        "text": " between a lot of pixels and a lot of labels,",
        "tokens": [
          51156,
          1296,
          257,
          688,
          295,
          18668,
          293,
          257,
          688,
          295,
          16949,
          11,
          51250
        ]
      },
      {
        "avg_logprob": -0.2118864174348762,
        "compression_ratio": 1.8112094395280236,
        "end": 406.88,
        "id": 173,
        "no_speech_prob": 0.000013211950317781884,
        "seek": 38812,
        "start": 405.84000000000003,
        "temperature": 0,
        "text": " a lot of hidden layers.",
        "tokens": [
          51250,
          257,
          688,
          295,
          7633,
          7914,
          13,
          51302
        ]
      },
      {
        "avg_logprob": -0.2118864174348762,
        "compression_ratio": 1.8112094395280236,
        "end": 409.08,
        "id": 174,
        "no_speech_prob": 0.000013211950317781884,
        "seek": 38812,
        "start": 406.88,
        "temperature": 0,
        "text": " So this, you'll notice like the file that we saved",
        "tokens": [
          51302,
          407,
          341,
          11,
          291,
          603,
          3449,
          411,
          264,
          3991,
          300,
          321,
          6624,
          51412
        ]
      },
      {
        "avg_logprob": -0.2118864174348762,
        "compression_ratio": 1.8112094395280236,
        "end": 411.72,
        "id": 175,
        "no_speech_prob": 0.000013211950317781884,
        "seek": 38812,
        "start": 409.08,
        "temperature": 0,
        "text": " is five megabytes because it's tons and tons of numbers.",
        "tokens": [
          51412,
          307,
          1732,
          10816,
          24538,
          570,
          309,
          311,
          9131,
          293,
          9131,
          295,
          3547,
          13,
          51544
        ]
      },
      {
        "avg_logprob": -0.2118864174348762,
        "compression_ratio": 1.8112094395280236,
        "end": 414.56,
        "id": 176,
        "no_speech_prob": 0.000013211950317781884,
        "seek": 38812,
        "start": 411.72,
        "temperature": 0,
        "text": " So it ends up, but this is just a very small file",
        "tokens": [
          51544,
          407,
          309,
          5314,
          493,
          11,
          457,
          341,
          307,
          445,
          257,
          588,
          1359,
          3991,
          51686
        ]
      },
      {
        "avg_logprob": -0.2118864174348762,
        "compression_ratio": 1.8112094395280236,
        "end": 415.88,
        "id": 177,
        "no_speech_prob": 0.000013211950317781884,
        "seek": 38812,
        "start": 414.56,
        "temperature": 0,
        "text": " with a little bit of text information",
        "tokens": [
          51686,
          365,
          257,
          707,
          857,
          295,
          2487,
          1589,
          51752
        ]
      },
      {
        "avg_logprob": -0.2118864174348762,
        "compression_ratio": 1.8112094395280236,
        "end": 417.12,
        "id": 178,
        "no_speech_prob": 0.000013211950317781884,
        "seek": 38812,
        "start": 415.88,
        "temperature": 0,
        "text": " about how this is configured.",
        "tokens": [
          51752,
          466,
          577,
          341,
          307,
          30538,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.2059934355995872,
        "compression_ratio": 1.7492260061919505,
        "end": 418.8,
        "id": 179,
        "no_speech_prob": 0.000015936502677504905,
        "seek": 41712,
        "start": 417.12,
        "temperature": 0,
        "text": " Okay, I spent a lot of time on that.",
        "tokens": [
          50364,
          1033,
          11,
          286,
          4418,
          257,
          688,
          295,
          565,
          322,
          300,
          13,
          50448
        ]
      },
      {
        "avg_logprob": -0.2059934355995872,
        "compression_ratio": 1.7492260061919505,
        "end": 420.48,
        "id": 180,
        "no_speech_prob": 0.000015936502677504905,
        "seek": 41712,
        "start": 418.8,
        "temperature": 0,
        "text": " Hopefully that's some helpful background to you.",
        "tokens": [
          50448,
          10429,
          300,
          311,
          512,
          4961,
          3678,
          281,
          291,
          13,
          50532
        ]
      },
      {
        "avg_logprob": -0.2059934355995872,
        "compression_ratio": 1.7492260061919505,
        "end": 423.52,
        "id": 181,
        "no_speech_prob": 0.000015936502677504905,
        "seek": 41712,
        "start": 420.48,
        "temperature": 0,
        "text": " Let's go back and actually look at those files.",
        "tokens": [
          50532,
          961,
          311,
          352,
          646,
          293,
          767,
          574,
          412,
          729,
          7098,
          13,
          50684
        ]
      },
      {
        "avg_logprob": -0.2059934355995872,
        "compression_ratio": 1.7492260061919505,
        "end": 425.24,
        "id": 182,
        "no_speech_prob": 0.000015936502677504905,
        "seek": 41712,
        "start": 423.52,
        "temperature": 0,
        "text": " So now I've got those files.",
        "tokens": [
          50684,
          407,
          586,
          286,
          600,
          658,
          729,
          7098,
          13,
          50770
        ]
      },
      {
        "avg_logprob": -0.2059934355995872,
        "compression_ratio": 1.7492260061919505,
        "end": 427.44,
        "id": 183,
        "no_speech_prob": 0.000015936502677504905,
        "seek": 41712,
        "start": 425.24,
        "temperature": 0,
        "text": " What I'm going to do is I'm just going to drag them",
        "tokens": [
          50770,
          708,
          286,
          478,
          516,
          281,
          360,
          307,
          286,
          478,
          445,
          516,
          281,
          5286,
          552,
          50880
        ]
      },
      {
        "avg_logprob": -0.2059934355995872,
        "compression_ratio": 1.7492260061919505,
        "end": 429.36,
        "id": 184,
        "no_speech_prob": 0.000015936502677504905,
        "seek": 41712,
        "start": 427.44,
        "temperature": 0,
        "text": " into Visual Studio Code,",
        "tokens": [
          50880,
          666,
          23187,
          13500,
          15549,
          11,
          50976
        ]
      },
      {
        "avg_logprob": -0.2059934355995872,
        "compression_ratio": 1.7492260061919505,
        "end": 431.76,
        "id": 185,
        "no_speech_prob": 0.000015936502677504905,
        "seek": 41712,
        "start": 429.36,
        "temperature": 0,
        "text": " which is what I'm using to code this right now,",
        "tokens": [
          50976,
          597,
          307,
          437,
          286,
          478,
          1228,
          281,
          3089,
          341,
          558,
          586,
          11,
          51096
        ]
      },
      {
        "avg_logprob": -0.2059934355995872,
        "compression_ratio": 1.7492260061919505,
        "end": 433.8,
        "id": 186,
        "no_speech_prob": 0.000015936502677504905,
        "seek": 41712,
        "start": 431.76,
        "temperature": 0,
        "text": " but you could be using any environment.",
        "tokens": [
          51096,
          457,
          291,
          727,
          312,
          1228,
          604,
          2823,
          13,
          51198
        ]
      },
      {
        "avg_logprob": -0.2059934355995872,
        "compression_ratio": 1.7492260061919505,
        "end": 436.28000000000003,
        "id": 187,
        "no_speech_prob": 0.000015936502677504905,
        "seek": 41712,
        "start": 433.8,
        "temperature": 0,
        "text": " Oops, they didn't make it into the right place.",
        "tokens": [
          51198,
          21726,
          11,
          436,
          994,
          380,
          652,
          309,
          666,
          264,
          558,
          1081,
          13,
          51322
        ]
      },
      {
        "avg_logprob": -0.2059934355995872,
        "compression_ratio": 1.7492260061919505,
        "end": 437.64,
        "id": 188,
        "no_speech_prob": 0.000015936502677504905,
        "seek": 41712,
        "start": 436.28000000000003,
        "temperature": 0,
        "text": " Let me try that again.",
        "tokens": [
          51322,
          961,
          385,
          853,
          300,
          797,
          13,
          51390
        ]
      },
      {
        "avg_logprob": -0.2059934355995872,
        "compression_ratio": 1.7492260061919505,
        "end": 438.52,
        "id": 189,
        "no_speech_prob": 0.000015936502677504905,
        "seek": 41712,
        "start": 437.64,
        "temperature": 0,
        "text": " I'll clean this up later,",
        "tokens": [
          51390,
          286,
          603,
          2541,
          341,
          493,
          1780,
          11,
          51434
        ]
      },
      {
        "avg_logprob": -0.2059934355995872,
        "compression_ratio": 1.7492260061919505,
        "end": 439.94,
        "id": 190,
        "no_speech_prob": 0.000015936502677504905,
        "seek": 41712,
        "start": 438.52,
        "temperature": 0,
        "text": " but I want them in this directory, great.",
        "tokens": [
          51434,
          457,
          286,
          528,
          552,
          294,
          341,
          21120,
          11,
          869,
          13,
          51505
        ]
      },
      {
        "avg_logprob": -0.2059934355995872,
        "compression_ratio": 1.7492260061919505,
        "end": 441.08,
        "id": 191,
        "no_speech_prob": 0.000015936502677504905,
        "seek": 41712,
        "start": 439.94,
        "temperature": 0,
        "text": " So you can see that they're there,",
        "tokens": [
          51505,
          407,
          291,
          393,
          536,
          300,
          436,
          434,
          456,
          11,
          51562
        ]
      },
      {
        "avg_logprob": -0.2059934355995872,
        "compression_ratio": 1.7492260061919505,
        "end": 443.52,
        "id": 192,
        "no_speech_prob": 0.000015936502677504905,
        "seek": 41712,
        "start": 441.08,
        "temperature": 0,
        "text": " model.json, model.weights.bin.",
        "tokens": [
          51562,
          2316,
          13,
          73,
          3015,
          11,
          2316,
          13,
          826,
          5761,
          13,
          13496,
          13,
          51684
        ]
      },
      {
        "avg_logprob": -0.2059934355995872,
        "compression_ratio": 1.7492260061919505,
        "end": 445.08,
        "id": 193,
        "no_speech_prob": 0.000015936502677504905,
        "seek": 41712,
        "start": 443.52,
        "temperature": 0,
        "text": " If I click on this, you can see,",
        "tokens": [
          51684,
          759,
          286,
          2052,
          322,
          341,
          11,
          291,
          393,
          536,
          11,
          51762
        ]
      },
      {
        "avg_logprob": -0.2356602061878551,
        "compression_ratio": 1.6990595611285266,
        "end": 448.08,
        "id": 194,
        "no_speech_prob": 0.000026274730771547183,
        "seek": 44508,
        "start": 445.08,
        "temperature": 0,
        "text": " you can start to see all the stuff in it.",
        "tokens": [
          50364,
          291,
          393,
          722,
          281,
          536,
          439,
          264,
          1507,
          294,
          309,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.2356602061878551,
        "compression_ratio": 1.6990595611285266,
        "end": 450.47999999999996,
        "id": 195,
        "no_speech_prob": 0.000026274730771547183,
        "seek": 44508,
        "start": 448.08,
        "temperature": 0,
        "text": " There's information about the input shape",
        "tokens": [
          50514,
          821,
          311,
          1589,
          466,
          264,
          4846,
          3909,
          50634
        ]
      },
      {
        "avg_logprob": -0.2356602061878551,
        "compression_ratio": 1.6990595611285266,
        "end": 453.12,
        "id": 196,
        "no_speech_prob": 0.000026274730771547183,
        "seek": 44508,
        "start": 450.47999999999996,
        "temperature": 0,
        "text": " and is it a sequential model",
        "tokens": [
          50634,
          293,
          307,
          309,
          257,
          42881,
          2316,
          50766
        ]
      },
      {
        "avg_logprob": -0.2356602061878551,
        "compression_ratio": 1.6990595611285266,
        "end": 455,
        "id": 197,
        "no_speech_prob": 0.000026274730771547183,
        "seek": 44508,
        "start": 453.12,
        "temperature": 0,
        "text": " and what kind of algorithm are you using",
        "tokens": [
          50766,
          293,
          437,
          733,
          295,
          9284,
          366,
          291,
          1228,
          50860
        ]
      },
      {
        "avg_logprob": -0.2356602061878551,
        "compression_ratio": 1.6990595611285266,
        "end": 456.24,
        "id": 198,
        "no_speech_prob": 0.000026274730771547183,
        "seek": 44508,
        "start": 455,
        "temperature": 0,
        "text": " and oh, is it dense?",
        "tokens": [
          50860,
          293,
          1954,
          11,
          307,
          309,
          18011,
          30,
          50922
        ]
      },
      {
        "avg_logprob": -0.2356602061878551,
        "compression_ratio": 1.6990595611285266,
        "end": 458.28,
        "id": 199,
        "no_speech_prob": 0.000026274730771547183,
        "seek": 44508,
        "start": 456.24,
        "temperature": 0,
        "text": " And it uses something called softmat, all this stuff.",
        "tokens": [
          50922,
          400,
          309,
          4960,
          746,
          1219,
          2787,
          15677,
          11,
          439,
          341,
          1507,
          13,
          51024
        ]
      },
      {
        "avg_logprob": -0.2356602061878551,
        "compression_ratio": 1.6990595611285266,
        "end": 460.5,
        "id": 200,
        "no_speech_prob": 0.000026274730771547183,
        "seek": 44508,
        "start": 458.28,
        "temperature": 0,
        "text": " So this is way beyond the scope",
        "tokens": [
          51024,
          407,
          341,
          307,
          636,
          4399,
          264,
          11923,
          51135
        ]
      },
      {
        "avg_logprob": -0.2356602061878551,
        "compression_ratio": 1.6990595611285266,
        "end": 461.88,
        "id": 201,
        "no_speech_prob": 0.000026274730771547183,
        "seek": 44508,
        "start": 460.5,
        "temperature": 0,
        "text": " of what I'm doing in these videos,",
        "tokens": [
          51135,
          295,
          437,
          286,
          478,
          884,
          294,
          613,
          2145,
          11,
          51204
        ]
      },
      {
        "avg_logprob": -0.2356602061878551,
        "compression_ratio": 1.6990595611285266,
        "end": 464.36,
        "id": 202,
        "no_speech_prob": 0.000026274730771547183,
        "seek": 44508,
        "start": 461.88,
        "temperature": 0,
        "text": " but if you're interested in more about these details,",
        "tokens": [
          51204,
          457,
          498,
          291,
          434,
          3102,
          294,
          544,
          466,
          613,
          4365,
          11,
          51328
        ]
      },
      {
        "avg_logprob": -0.2356602061878551,
        "compression_ratio": 1.6990595611285266,
        "end": 465.52,
        "id": 203,
        "no_speech_prob": 0.000026274730771547183,
        "seek": 44508,
        "start": 464.36,
        "temperature": 0,
        "text": " you could look at some of my videos",
        "tokens": [
          51328,
          291,
          727,
          574,
          412,
          512,
          295,
          452,
          2145,
          51386
        ]
      },
      {
        "avg_logprob": -0.2356602061878551,
        "compression_ratio": 1.6990595611285266,
        "end": 467.4,
        "id": 204,
        "no_speech_prob": 0.000026274730771547183,
        "seek": 44508,
        "start": 465.52,
        "temperature": 0,
        "text": " that use TensorFlow.js natively",
        "tokens": [
          51386,
          300,
          764,
          37624,
          13,
          25530,
          8470,
          356,
          51480
        ]
      },
      {
        "avg_logprob": -0.2356602061878551,
        "compression_ratio": 1.6990595611285266,
        "end": 469,
        "id": 205,
        "no_speech_prob": 0.000026274730771547183,
        "seek": 44508,
        "start": 467.4,
        "temperature": 0,
        "text": " to understand more pieces here.",
        "tokens": [
          51480,
          281,
          1223,
          544,
          3755,
          510,
          13,
          51560
        ]
      },
      {
        "avg_logprob": -0.2356602061878551,
        "compression_ratio": 1.6990595611285266,
        "end": 470.29999999999995,
        "id": 206,
        "no_speech_prob": 0.000026274730771547183,
        "seek": 44508,
        "start": 469,
        "temperature": 0,
        "text": " But you can see here,",
        "tokens": [
          51560,
          583,
          291,
          393,
          536,
          510,
          11,
          51625
        ]
      },
      {
        "avg_logprob": -0.2356602061878551,
        "compression_ratio": 1.6990595611285266,
        "end": 472.96,
        "id": 207,
        "no_speech_prob": 0.000026274730771547183,
        "seek": 44508,
        "start": 470.29999999999995,
        "temperature": 0,
        "text": " this is where it's looking for the weights file,",
        "tokens": [
          51625,
          341,
          307,
          689,
          309,
          311,
          1237,
          337,
          264,
          17443,
          3991,
          11,
          51758
        ]
      },
      {
        "avg_logprob": -0.2356602061878551,
        "compression_ratio": 1.6990595611285266,
        "end": 473.84,
        "id": 208,
        "no_speech_prob": 0.000026274730771547183,
        "seek": 44508,
        "start": 472.96,
        "temperature": 0,
        "text": " et cetera, et cetera.",
        "tokens": [
          51758,
          1030,
          11458,
          11,
          1030,
          11458,
          13,
          51802
        ]
      },
      {
        "avg_logprob": -0.23801587079022382,
        "compression_ratio": 1.768421052631579,
        "end": 475.2,
        "id": 209,
        "no_speech_prob": 0.000009080472409550566,
        "seek": 47384,
        "start": 473.84,
        "temperature": 0,
        "text": " And this is really important.",
        "tokens": [
          50364,
          400,
          341,
          307,
          534,
          1021,
          13,
          50432
        ]
      },
      {
        "avg_logprob": -0.23801587079022382,
        "compression_ratio": 1.768421052631579,
        "end": 477.71999999999997,
        "id": 210,
        "no_speech_prob": 0.000009080472409550566,
        "seek": 47384,
        "start": 475.2,
        "temperature": 0,
        "text": " This is something, this is really just the TensorFlow,",
        "tokens": [
          50432,
          639,
          307,
          746,
          11,
          341,
          307,
          534,
          445,
          264,
          37624,
          11,
          50558
        ]
      },
      {
        "avg_logprob": -0.23801587079022382,
        "compression_ratio": 1.768421052631579,
        "end": 480.67999999999995,
        "id": 211,
        "no_speech_prob": 0.000009080472409550566,
        "seek": 47384,
        "start": 477.71999999999997,
        "temperature": 0,
        "text": " what TensorFlow.js would do natively,",
        "tokens": [
          50558,
          437,
          37624,
          13,
          25530,
          576,
          360,
          8470,
          356,
          11,
          50706
        ]
      },
      {
        "avg_logprob": -0.23801587079022382,
        "compression_ratio": 1.768421052631579,
        "end": 483.23999999999995,
        "id": 212,
        "no_speech_prob": 0.000009080472409550566,
        "seek": 47384,
        "start": 480.67999999999995,
        "temperature": 0,
        "text": " but ml5 is helping with a little bit on top of it",
        "tokens": [
          50706,
          457,
          23271,
          20,
          307,
          4315,
          365,
          257,
          707,
          857,
          322,
          1192,
          295,
          309,
          50834
        ]
      },
      {
        "avg_logprob": -0.23801587079022382,
        "compression_ratio": 1.768421052631579,
        "end": 485.11999999999995,
        "id": 213,
        "no_speech_prob": 0.000009080472409550566,
        "seek": 47384,
        "start": 483.23999999999995,
        "temperature": 0,
        "text": " by adding these happy and sad labels.",
        "tokens": [
          50834,
          538,
          5127,
          613,
          2055,
          293,
          4227,
          16949,
          13,
          50928
        ]
      },
      {
        "avg_logprob": -0.23801587079022382,
        "compression_ratio": 1.768421052631579,
        "end": 486.67999999999995,
        "id": 214,
        "no_speech_prob": 0.000009080472409550566,
        "seek": 47384,
        "start": 485.11999999999995,
        "temperature": 0,
        "text": " Okay.",
        "tokens": [
          50928,
          1033,
          13,
          51006
        ]
      },
      {
        "avg_logprob": -0.23801587079022382,
        "compression_ratio": 1.768421052631579,
        "end": 489.7,
        "id": 215,
        "no_speech_prob": 0.000009080472409550566,
        "seek": 47384,
        "start": 486.67999999999995,
        "temperature": 0,
        "text": " So now, all we have to do is load the model now.",
        "tokens": [
          51006,
          407,
          586,
          11,
          439,
          321,
          362,
          281,
          360,
          307,
          3677,
          264,
          2316,
          586,
          13,
          51157
        ]
      },
      {
        "avg_logprob": -0.23801587079022382,
        "compression_ratio": 1.768421052631579,
        "end": 492.15999999999997,
        "id": 216,
        "no_speech_prob": 0.000009080472409550566,
        "seek": 47384,
        "start": 489.7,
        "temperature": 0,
        "text": " Okay, so we're going to go, we save that model",
        "tokens": [
          51157,
          1033,
          11,
          370,
          321,
          434,
          516,
          281,
          352,
          11,
          321,
          3155,
          300,
          2316,
          51280
        ]
      },
      {
        "avg_logprob": -0.23801587079022382,
        "compression_ratio": 1.768421052631579,
        "end": 494.03999999999996,
        "id": 217,
        "no_speech_prob": 0.000009080472409550566,
        "seek": 47384,
        "start": 492.15999999999997,
        "temperature": 0,
        "text": " and so the steps are,",
        "tokens": [
          51280,
          293,
          370,
          264,
          4439,
          366,
          11,
          51374
        ]
      },
      {
        "avg_logprob": -0.23801587079022382,
        "compression_ratio": 1.768421052631579,
        "end": 497.55999999999995,
        "id": 218,
        "no_speech_prob": 0.000009080472409550566,
        "seek": 47384,
        "start": 494.03999999999996,
        "temperature": 0,
        "text": " the first thing we have to do is load the MobileNet model.",
        "tokens": [
          51374,
          264,
          700,
          551,
          321,
          362,
          281,
          360,
          307,
          3677,
          264,
          22625,
          31890,
          2316,
          13,
          51550
        ]
      },
      {
        "avg_logprob": -0.23801587079022382,
        "compression_ratio": 1.768421052631579,
        "end": 498.84,
        "id": 219,
        "no_speech_prob": 0.000009080472409550566,
        "seek": 47384,
        "start": 497.55999999999995,
        "temperature": 0,
        "text": " So we're not actually saving",
        "tokens": [
          51550,
          407,
          321,
          434,
          406,
          767,
          6816,
          51614
        ]
      },
      {
        "avg_logprob": -0.23801587079022382,
        "compression_ratio": 1.768421052631579,
        "end": 501.35999999999996,
        "id": 220,
        "no_speech_prob": 0.000009080472409550566,
        "seek": 47384,
        "start": 498.84,
        "temperature": 0,
        "text": " that original pre-trained image classifier.",
        "tokens": [
          51614,
          300,
          3380,
          659,
          12,
          17227,
          2001,
          3256,
          1508,
          9902,
          13,
          51740
        ]
      },
      {
        "avg_logprob": -0.23801587079022382,
        "compression_ratio": 1.768421052631579,
        "end": 503.14,
        "id": 221,
        "no_speech_prob": 0.000009080472409550566,
        "seek": 47384,
        "start": 501.35999999999996,
        "temperature": 0,
        "text": " We're just saving the bits and pieces",
        "tokens": [
          51740,
          492,
          434,
          445,
          6816,
          264,
          9239,
          293,
          3755,
          51829
        ]
      },
      {
        "avg_logprob": -0.23747783548691692,
        "compression_ratio": 1.7540322580645162,
        "end": 505.09999999999997,
        "id": 222,
        "no_speech_prob": 0.00002078514989989344,
        "seek": 50314,
        "start": 503.14,
        "temperature": 0,
        "text": " that are like hooked into it.",
        "tokens": [
          50364,
          300,
          366,
          411,
          20410,
          666,
          309,
          13,
          50462
        ]
      },
      {
        "avg_logprob": -0.23747783548691692,
        "compression_ratio": 1.7540322580645162,
        "end": 508.65999999999997,
        "id": 223,
        "no_speech_prob": 0.00002078514989989344,
        "seek": 50314,
        "start": 505.09999999999997,
        "temperature": 0,
        "text": " So we can't hook into it until MobileNet is ready.",
        "tokens": [
          50462,
          407,
          321,
          393,
          380,
          6328,
          666,
          309,
          1826,
          22625,
          31890,
          307,
          1919,
          13,
          50640
        ]
      },
      {
        "avg_logprob": -0.23747783548691692,
        "compression_ratio": 1.7540322580645162,
        "end": 512.06,
        "id": 224,
        "no_speech_prob": 0.00002078514989989344,
        "seek": 50314,
        "start": 508.65999999999997,
        "temperature": 0,
        "text": " So once we've hooked into, once MobileNet is ready,",
        "tokens": [
          50640,
          407,
          1564,
          321,
          600,
          20410,
          666,
          11,
          1564,
          22625,
          31890,
          307,
          1919,
          11,
          50810
        ]
      },
      {
        "avg_logprob": -0.23747783548691692,
        "compression_ratio": 1.7540322580645162,
        "end": 517.06,
        "id": 225,
        "no_speech_prob": 0.00002078514989989344,
        "seek": 50314,
        "start": 512.06,
        "temperature": 0,
        "text": " we can then say classifier.load model.json.",
        "tokens": [
          50810,
          321,
          393,
          550,
          584,
          1508,
          9902,
          13,
          2907,
          2316,
          13,
          73,
          3015,
          13,
          51060
        ]
      },
      {
        "avg_logprob": -0.23747783548691692,
        "compression_ratio": 1.7540322580645162,
        "end": 520.18,
        "id": 226,
        "no_speech_prob": 0.00002078514989989344,
        "seek": 50314,
        "start": 517.9,
        "temperature": 0,
        "text": " Now, there are two files, model.json",
        "tokens": [
          51102,
          823,
          11,
          456,
          366,
          732,
          7098,
          11,
          2316,
          13,
          73,
          3015,
          51216
        ]
      },
      {
        "avg_logprob": -0.23747783548691692,
        "compression_ratio": 1.7540322580645162,
        "end": 524.54,
        "id": 227,
        "no_speech_prob": 0.00002078514989989344,
        "seek": 50314,
        "start": 520.18,
        "temperature": 0,
        "text": " and model.weights.bin, but if you,",
        "tokens": [
          51216,
          293,
          2316,
          13,
          826,
          5761,
          13,
          13496,
          11,
          457,
          498,
          291,
          11,
          51434
        ]
      },
      {
        "avg_logprob": -0.23747783548691692,
        "compression_ratio": 1.7540322580645162,
        "end": 526.54,
        "id": 228,
        "no_speech_prob": 0.00002078514989989344,
        "seek": 50314,
        "start": 524.54,
        "temperature": 0,
        "text": " ml5 is set up that if you just give it one file,",
        "tokens": [
          51434,
          23271,
          20,
          307,
          992,
          493,
          300,
          498,
          291,
          445,
          976,
          309,
          472,
          3991,
          11,
          51534
        ]
      },
      {
        "avg_logprob": -0.23747783548691692,
        "compression_ratio": 1.7540322580645162,
        "end": 528.46,
        "id": 229,
        "no_speech_prob": 0.00002078514989989344,
        "seek": 50314,
        "start": 526.54,
        "temperature": 0,
        "text": " it'll look automatically for the other file",
        "tokens": [
          51534,
          309,
          603,
          574,
          6772,
          337,
          264,
          661,
          3991,
          51630
        ]
      },
      {
        "avg_logprob": -0.23747783548691692,
        "compression_ratio": 1.7540322580645162,
        "end": 529.5,
        "id": 230,
        "no_speech_prob": 0.00002078514989989344,
        "seek": 50314,
        "start": 528.46,
        "temperature": 0,
        "text": " in the same place.",
        "tokens": [
          51630,
          294,
          264,
          912,
          1081,
          13,
          51682
        ]
      },
      {
        "avg_logprob": -0.23747783548691692,
        "compression_ratio": 1.7540322580645162,
        "end": 531.54,
        "id": 231,
        "no_speech_prob": 0.00002078514989989344,
        "seek": 50314,
        "start": 529.5,
        "temperature": 0,
        "text": " There are ways of customizing the file names",
        "tokens": [
          51682,
          821,
          366,
          2098,
          295,
          2375,
          3319,
          264,
          3991,
          5288,
          51784
        ]
      },
      {
        "avg_logprob": -0.23747783548691692,
        "compression_ratio": 1.7540322580645162,
        "end": 532.54,
        "id": 232,
        "no_speech_prob": 0.00002078514989989344,
        "seek": 50314,
        "start": 531.54,
        "temperature": 0,
        "text": " and their paths and all that,",
        "tokens": [
          51784,
          293,
          641,
          14518,
          293,
          439,
          300,
          11,
          51834
        ]
      },
      {
        "avg_logprob": -0.2549821402280385,
        "compression_ratio": 1.8695652173913044,
        "end": 535.5,
        "id": 233,
        "no_speech_prob": 0.000003844932052743388,
        "seek": 53254,
        "start": 533.5,
        "temperature": 0,
        "text": " that you can sort of look into in the documentation.",
        "tokens": [
          50412,
          300,
          291,
          393,
          1333,
          295,
          574,
          666,
          294,
          264,
          14333,
          13,
          50512
        ]
      },
      {
        "avg_logprob": -0.2549821402280385,
        "compression_ratio": 1.8695652173913044,
        "end": 537.2199999999999,
        "id": 234,
        "no_speech_prob": 0.000003844932052743388,
        "seek": 53254,
        "start": 535.5,
        "temperature": 0,
        "text": " But the easiest thing for just to do this,",
        "tokens": [
          50512,
          583,
          264,
          12889,
          551,
          337,
          445,
          281,
          360,
          341,
          11,
          50598
        ]
      },
      {
        "avg_logprob": -0.2549821402280385,
        "compression_ratio": 1.8695652173913044,
        "end": 540.54,
        "id": 235,
        "no_speech_prob": 0.000003844932052743388,
        "seek": 53254,
        "start": 537.2199999999999,
        "temperature": 0,
        "text": " and then I'm going to say custom model ready.",
        "tokens": [
          50598,
          293,
          550,
          286,
          478,
          516,
          281,
          584,
          2375,
          2316,
          1919,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.2549821402280385,
        "compression_ratio": 1.8695652173913044,
        "end": 542.8399999999999,
        "id": 236,
        "no_speech_prob": 0.000003844932052743388,
        "seek": 53254,
        "start": 540.54,
        "temperature": 0,
        "text": " So I'm going to write another event function.",
        "tokens": [
          50764,
          407,
          286,
          478,
          516,
          281,
          2464,
          1071,
          2280,
          2445,
          13,
          50879
        ]
      },
      {
        "avg_logprob": -0.2549821402280385,
        "compression_ratio": 1.8695652173913044,
        "end": 546.3399999999999,
        "id": 237,
        "no_speech_prob": 0.000003844932052743388,
        "seek": 53254,
        "start": 544.06,
        "temperature": 0,
        "text": " A custom model ready.",
        "tokens": [
          50940,
          316,
          2375,
          2316,
          1919,
          13,
          51054
        ]
      },
      {
        "avg_logprob": -0.2549821402280385,
        "compression_ratio": 1.8695652173913044,
        "end": 548.0999999999999,
        "id": 238,
        "no_speech_prob": 0.000003844932052743388,
        "seek": 53254,
        "start": 546.3399999999999,
        "temperature": 0,
        "text": " And there, I'm going to say,",
        "tokens": [
          51054,
          400,
          456,
          11,
          286,
          478,
          516,
          281,
          584,
          11,
          51142
        ]
      },
      {
        "avg_logprob": -0.2549821402280385,
        "compression_ratio": 1.8695652173913044,
        "end": 551.4599999999999,
        "id": 239,
        "no_speech_prob": 0.000003844932052743388,
        "seek": 53254,
        "start": 549.98,
        "temperature": 0,
        "text": " custom model is ready.",
        "tokens": [
          51236,
          2375,
          2316,
          307,
          1919,
          13,
          51310
        ]
      },
      {
        "avg_logprob": -0.2549821402280385,
        "compression_ratio": 1.8695652173913044,
        "end": 552.9399999999999,
        "id": 240,
        "no_speech_prob": 0.000003844932052743388,
        "seek": 53254,
        "start": 551.4599999999999,
        "temperature": 0,
        "text": " So it's a two-step process.",
        "tokens": [
          51310,
          407,
          309,
          311,
          257,
          732,
          12,
          16792,
          1399,
          13,
          51384
        ]
      },
      {
        "avg_logprob": -0.2549821402280385,
        "compression_ratio": 1.8695652173913044,
        "end": 555.74,
        "id": 241,
        "no_speech_prob": 0.000003844932052743388,
        "seek": 53254,
        "start": 552.9399999999999,
        "temperature": 0,
        "text": " We have to load MobileNet, MobileNet is ready.",
        "tokens": [
          51384,
          492,
          362,
          281,
          3677,
          22625,
          31890,
          11,
          22625,
          31890,
          307,
          1919,
          13,
          51524
        ]
      },
      {
        "avg_logprob": -0.2549821402280385,
        "compression_ratio": 1.8695652173913044,
        "end": 558.5,
        "id": 242,
        "no_speech_prob": 0.000003844932052743388,
        "seek": 53254,
        "start": 555.74,
        "temperature": 0,
        "text": " Then load model.json with the weights,",
        "tokens": [
          51524,
          1396,
          3677,
          2316,
          13,
          73,
          3015,
          365,
          264,
          17443,
          11,
          51662
        ]
      },
      {
        "avg_logprob": -0.2549821402280385,
        "compression_ratio": 1.8695652173913044,
        "end": 560.14,
        "id": 243,
        "no_speech_prob": 0.000003844932052743388,
        "seek": 53254,
        "start": 558.5,
        "temperature": 0,
        "text": " custom model is ready.",
        "tokens": [
          51662,
          2375,
          2316,
          307,
          1919,
          13,
          51744
        ]
      },
      {
        "avg_logprob": -0.2549821402280385,
        "compression_ratio": 1.8695652173913044,
        "end": 561.6999999999999,
        "id": 244,
        "no_speech_prob": 0.000003844932052743388,
        "seek": 53254,
        "start": 560.14,
        "temperature": 0,
        "text": " All right, let's just run this.",
        "tokens": [
          51744,
          1057,
          558,
          11,
          718,
          311,
          445,
          1190,
          341,
          13,
          51822
        ]
      },
      {
        "avg_logprob": -0.2405975487581484,
        "compression_ratio": 1.7552447552447552,
        "end": 564.62,
        "id": 245,
        "no_speech_prob": 0.000032699230359867215,
        "seek": 56254,
        "start": 563.4599999999999,
        "temperature": 0,
        "text": " Zoom back out.",
        "tokens": [
          50410,
          13453,
          646,
          484,
          13,
          50468
        ]
      },
      {
        "avg_logprob": -0.2405975487581484,
        "compression_ratio": 1.7552447552447552,
        "end": 567.06,
        "id": 246,
        "no_speech_prob": 0.000032699230359867215,
        "seek": 56254,
        "start": 565.54,
        "temperature": 0,
        "text": " And there we go.",
        "tokens": [
          50514,
          400,
          456,
          321,
          352,
          13,
          50590
        ]
      },
      {
        "avg_logprob": -0.2405975487581484,
        "compression_ratio": 1.7552447552447552,
        "end": 569.4599999999999,
        "id": 247,
        "no_speech_prob": 0.000032699230359867215,
        "seek": 56254,
        "start": 567.06,
        "temperature": 0,
        "text": " Everything's loaded, but I don't see any results.",
        "tokens": [
          50590,
          5471,
          311,
          13210,
          11,
          457,
          286,
          500,
          380,
          536,
          604,
          3542,
          13,
          50710
        ]
      },
      {
        "avg_logprob": -0.2405975487581484,
        "compression_ratio": 1.7552447552447552,
        "end": 571.06,
        "id": 248,
        "no_speech_prob": 0.000032699230359867215,
        "seek": 56254,
        "start": 569.4599999999999,
        "temperature": 0,
        "text": " Hmm, I don't see any results.",
        "tokens": [
          50710,
          8239,
          11,
          286,
          500,
          380,
          536,
          604,
          3542,
          13,
          50790
        ]
      },
      {
        "avg_logprob": -0.2405975487581484,
        "compression_ratio": 1.7552447552447552,
        "end": 571.9,
        "id": 249,
        "no_speech_prob": 0.000032699230359867215,
        "seek": 56254,
        "start": 571.06,
        "temperature": 0,
        "text": " Why?",
        "tokens": [
          50790,
          1545,
          30,
          50832
        ]
      },
      {
        "avg_logprob": -0.2405975487581484,
        "compression_ratio": 1.7552447552447552,
        "end": 574.26,
        "id": 250,
        "no_speech_prob": 0.000032699230359867215,
        "seek": 56254,
        "start": 571.9,
        "temperature": 0,
        "text": " Well, this sketch was written with,",
        "tokens": [
          50832,
          1042,
          11,
          341,
          12325,
          390,
          3720,
          365,
          11,
          50950
        ]
      },
      {
        "avg_logprob": -0.2405975487581484,
        "compression_ratio": 1.7552447552447552,
        "end": 576.74,
        "id": 251,
        "no_speech_prob": 0.000032699230359867215,
        "seek": 56254,
        "start": 574.26,
        "temperature": 0,
        "text": " originally, with code to train.",
        "tokens": [
          50950,
          7993,
          11,
          365,
          3089,
          281,
          3847,
          13,
          51074
        ]
      },
      {
        "avg_logprob": -0.2405975487581484,
        "compression_ratio": 1.7552447552447552,
        "end": 578.0999999999999,
        "id": 252,
        "no_speech_prob": 0.000032699230359867215,
        "seek": 56254,
        "start": 576.74,
        "temperature": 0,
        "text": " So I'm supposed to press the buttons and it'd train,",
        "tokens": [
          51074,
          407,
          286,
          478,
          3442,
          281,
          1886,
          264,
          9905,
          293,
          309,
          1116,
          3847,
          11,
          51142
        ]
      },
      {
        "avg_logprob": -0.2405975487581484,
        "compression_ratio": 1.7552447552447552,
        "end": 579.3399999999999,
        "id": 253,
        "no_speech_prob": 0.000032699230359867215,
        "seek": 56254,
        "start": 578.0999999999999,
        "temperature": 0,
        "text": " but now I don't need to train,",
        "tokens": [
          51142,
          457,
          586,
          286,
          500,
          380,
          643,
          281,
          3847,
          11,
          51204
        ]
      },
      {
        "avg_logprob": -0.2405975487581484,
        "compression_ratio": 1.7552447552447552,
        "end": 580.18,
        "id": 254,
        "no_speech_prob": 0.000032699230359867215,
        "seek": 56254,
        "start": 579.3399999999999,
        "temperature": 0,
        "text": " because I loaded the model.",
        "tokens": [
          51204,
          570,
          286,
          13210,
          264,
          2316,
          13,
          51246
        ]
      },
      {
        "avg_logprob": -0.2405975487581484,
        "compression_ratio": 1.7552447552447552,
        "end": 582.62,
        "id": 255,
        "no_speech_prob": 0.000032699230359867215,
        "seek": 56254,
        "start": 580.18,
        "temperature": 0,
        "text": " So this is where I kind of like,",
        "tokens": [
          51246,
          407,
          341,
          307,
          689,
          286,
          733,
          295,
          411,
          11,
          51368
        ]
      },
      {
        "avg_logprob": -0.2405975487581484,
        "compression_ratio": 1.7552447552447552,
        "end": 584.3399999999999,
        "id": 256,
        "no_speech_prob": 0.000032699230359867215,
        "seek": 56254,
        "start": 582.62,
        "temperature": 0,
        "text": " I don't know what you should do next.",
        "tokens": [
          51368,
          286,
          500,
          380,
          458,
          437,
          291,
          820,
          360,
          958,
          13,
          51454
        ]
      },
      {
        "avg_logprob": -0.2405975487581484,
        "compression_ratio": 1.7552447552447552,
        "end": 586.8199999999999,
        "id": 257,
        "no_speech_prob": 0.000032699230359867215,
        "seek": 56254,
        "start": 584.3399999999999,
        "temperature": 0,
        "text": " Maybe you want to keep two separate webpages,",
        "tokens": [
          51454,
          2704,
          291,
          528,
          281,
          1066,
          732,
          4994,
          3670,
          79,
          1660,
          11,
          51578
        ]
      },
      {
        "avg_logprob": -0.2405975487581484,
        "compression_ratio": 1.7552447552447552,
        "end": 589.8199999999999,
        "id": 258,
        "no_speech_prob": 0.000032699230359867215,
        "seek": 56254,
        "start": 586.8199999999999,
        "temperature": 0,
        "text": " two separate sketches, one for training and one for loading.",
        "tokens": [
          51578,
          732,
          4994,
          34547,
          11,
          472,
          337,
          3097,
          293,
          472,
          337,
          15114,
          13,
          51728
        ]
      },
      {
        "avg_logprob": -0.2405975487581484,
        "compression_ratio": 1.7552447552447552,
        "end": 591.3,
        "id": 259,
        "no_speech_prob": 0.000032699230359867215,
        "seek": 56254,
        "start": 589.8199999999999,
        "temperature": 0,
        "text": " Maybe you do it all in one.",
        "tokens": [
          51728,
          2704,
          291,
          360,
          309,
          439,
          294,
          472,
          13,
          51802
        ]
      },
      {
        "avg_logprob": -0.2151967696561158,
        "compression_ratio": 1.686131386861314,
        "end": 593.8199999999999,
        "id": 260,
        "no_speech_prob": 0.000012219062227813993,
        "seek": 59130,
        "start": 591.3,
        "temperature": 0,
        "text": " You'll actually see, if you go to the ml5 examples,",
        "tokens": [
          50364,
          509,
          603,
          767,
          536,
          11,
          498,
          291,
          352,
          281,
          264,
          23271,
          20,
          5110,
          11,
          50490
        ]
      },
      {
        "avg_logprob": -0.2151967696561158,
        "compression_ratio": 1.686131386861314,
        "end": 597.02,
        "id": 261,
        "no_speech_prob": 0.000012219062227813993,
        "seek": 59130,
        "start": 593.8199999999999,
        "temperature": 0,
        "text": " there's one that has a button that you can drag and drop.",
        "tokens": [
          50490,
          456,
          311,
          472,
          300,
          575,
          257,
          2960,
          300,
          291,
          393,
          5286,
          293,
          3270,
          13,
          50650
        ]
      },
      {
        "avg_logprob": -0.2151967696561158,
        "compression_ratio": 1.686131386861314,
        "end": 598.8399999999999,
        "id": 262,
        "no_speech_prob": 0.000012219062227813993,
        "seek": 59130,
        "start": 597.02,
        "temperature": 0,
        "text": " You can actually select files and load them",
        "tokens": [
          50650,
          509,
          393,
          767,
          3048,
          7098,
          293,
          3677,
          552,
          50741
        ]
      },
      {
        "avg_logprob": -0.2151967696561158,
        "compression_ratio": 1.686131386861314,
        "end": 600.4599999999999,
        "id": 263,
        "no_speech_prob": 0.000012219062227813993,
        "seek": 59130,
        "start": 598.8399999999999,
        "temperature": 0,
        "text": " and save them all in the same sketch.",
        "tokens": [
          50741,
          293,
          3155,
          552,
          439,
          294,
          264,
          912,
          12325,
          13,
          50822
        ]
      },
      {
        "avg_logprob": -0.2151967696561158,
        "compression_ratio": 1.686131386861314,
        "end": 603.26,
        "id": 264,
        "no_speech_prob": 0.000012219062227813993,
        "seek": 59130,
        "start": 600.4599999999999,
        "temperature": 0,
        "text": " But what I want to do now is basically a workflow for,",
        "tokens": [
          50822,
          583,
          437,
          286,
          528,
          281,
          360,
          586,
          307,
          1936,
          257,
          20993,
          337,
          11,
          50962
        ]
      },
      {
        "avg_logprob": -0.2151967696561158,
        "compression_ratio": 1.686131386861314,
        "end": 604.6999999999999,
        "id": 265,
        "no_speech_prob": 0.000012219062227813993,
        "seek": 59130,
        "start": 603.26,
        "temperature": 0,
        "text": " I'm done with the training,",
        "tokens": [
          50962,
          286,
          478,
          1096,
          365,
          264,
          3097,
          11,
          51034
        ]
      },
      {
        "avg_logprob": -0.2151967696561158,
        "compression_ratio": 1.686131386861314,
        "end": 606.62,
        "id": 266,
        "no_speech_prob": 0.000012219062227813993,
        "seek": 59130,
        "start": 604.6999999999999,
        "temperature": 0,
        "text": " so I'm not going to ever train again.",
        "tokens": [
          51034,
          370,
          286,
          478,
          406,
          516,
          281,
          1562,
          3847,
          797,
          13,
          51130
        ]
      },
      {
        "avg_logprob": -0.2151967696561158,
        "compression_ratio": 1.686131386861314,
        "end": 609.74,
        "id": 267,
        "no_speech_prob": 0.000012219062227813993,
        "seek": 59130,
        "start": 606.62,
        "temperature": 0,
        "text": " So I can actually remove all of these buttons.",
        "tokens": [
          51130,
          407,
          286,
          393,
          767,
          4159,
          439,
          295,
          613,
          9905,
          13,
          51286
        ]
      },
      {
        "avg_logprob": -0.2151967696561158,
        "compression_ratio": 1.686131386861314,
        "end": 611.56,
        "id": 268,
        "no_speech_prob": 0.000012219062227813993,
        "seek": 59130,
        "start": 609.74,
        "temperature": 0,
        "text": " They're no longer relevant to me.",
        "tokens": [
          51286,
          814,
          434,
          572,
          2854,
          7340,
          281,
          385,
          13,
          51377
        ]
      },
      {
        "avg_logprob": -0.2151967696561158,
        "compression_ratio": 1.686131386861314,
        "end": 615.3399999999999,
        "id": 269,
        "no_speech_prob": 0.000012219062227813993,
        "seek": 59130,
        "start": 612.78,
        "temperature": 0,
        "text": " The text that should show up at the beginning",
        "tokens": [
          51438,
          440,
          2487,
          300,
          820,
          855,
          493,
          412,
          264,
          2863,
          51566
        ]
      },
      {
        "avg_logprob": -0.2151967696561158,
        "compression_ratio": 1.686131386861314,
        "end": 617.74,
        "id": 270,
        "no_speech_prob": 0.000012219062227813993,
        "seek": 59130,
        "start": 615.3399999999999,
        "temperature": 0,
        "text": " is just loading model.",
        "tokens": [
          51566,
          307,
          445,
          15114,
          2316,
          13,
          51686
        ]
      },
      {
        "avg_logprob": -0.2103899286148396,
        "compression_ratio": 1.770949720670391,
        "end": 623.0600000000001,
        "id": 271,
        "no_speech_prob": 0.000002443991661493783,
        "seek": 61774,
        "start": 618.62,
        "temperature": 0,
        "text": " And then when the model is ready,",
        "tokens": [
          50408,
          400,
          550,
          562,
          264,
          2316,
          307,
          1919,
          11,
          50630
        ]
      },
      {
        "avg_logprob": -0.2103899286148396,
        "compression_ratio": 1.770949720670391,
        "end": 628.0600000000001,
        "id": 272,
        "no_speech_prob": 0.000002443991661493783,
        "seek": 61774,
        "start": 623.0600000000001,
        "temperature": 0,
        "text": " I would say label equals model ready.",
        "tokens": [
          50630,
          286,
          576,
          584,
          7645,
          6915,
          2316,
          1919,
          13,
          50880
        ]
      },
      {
        "avg_logprob": -0.2103899286148396,
        "compression_ratio": 1.770949720670391,
        "end": 631.58,
        "id": 273,
        "no_speech_prob": 0.000002443991661493783,
        "seek": 61774,
        "start": 629.9,
        "temperature": 0,
        "text": " So let's run this now.",
        "tokens": [
          50972,
          407,
          718,
          311,
          1190,
          341,
          586,
          13,
          51056
        ]
      },
      {
        "avg_logprob": -0.2103899286148396,
        "compression_ratio": 1.770949720670391,
        "end": 634.1800000000001,
        "id": 274,
        "no_speech_prob": 0.000002443991661493783,
        "seek": 61774,
        "start": 631.58,
        "temperature": 0,
        "text": " So now it's loading model, loading model, model ready.",
        "tokens": [
          51056,
          407,
          586,
          309,
          311,
          15114,
          2316,
          11,
          15114,
          2316,
          11,
          2316,
          1919,
          13,
          51186
        ]
      },
      {
        "avg_logprob": -0.2103899286148396,
        "compression_ratio": 1.770949720670391,
        "end": 635.58,
        "id": 275,
        "no_speech_prob": 0.000002443991661493783,
        "seek": 61774,
        "start": 634.1800000000001,
        "temperature": 0,
        "text": " And now, once the model is ready,",
        "tokens": [
          51186,
          400,
          586,
          11,
          1564,
          264,
          2316,
          307,
          1919,
          11,
          51256
        ]
      },
      {
        "avg_logprob": -0.2103899286148396,
        "compression_ratio": 1.770949720670391,
        "end": 637.5,
        "id": 276,
        "no_speech_prob": 0.000002443991661493783,
        "seek": 61774,
        "start": 635.58,
        "temperature": 0,
        "text": " all I need to do is start classifying.",
        "tokens": [
          51256,
          439,
          286,
          643,
          281,
          360,
          307,
          722,
          1508,
          5489,
          13,
          51352
        ]
      },
      {
        "avg_logprob": -0.2103899286148396,
        "compression_ratio": 1.770949720670391,
        "end": 640.1800000000001,
        "id": 277,
        "no_speech_prob": 0.000002443991661493783,
        "seek": 61774,
        "start": 637.5,
        "temperature": 0,
        "text": " And before, I didn't classify",
        "tokens": [
          51352,
          400,
          949,
          11,
          286,
          994,
          380,
          33872,
          51486
        ]
      },
      {
        "avg_logprob": -0.2103899286148396,
        "compression_ratio": 1.770949720670391,
        "end": 643.02,
        "id": 278,
        "no_speech_prob": 0.000002443991661493783,
        "seek": 61774,
        "start": 640.1800000000001,
        "temperature": 0,
        "text": " until the training was finished.",
        "tokens": [
          51486,
          1826,
          264,
          3097,
          390,
          4335,
          13,
          51628
        ]
      },
      {
        "avg_logprob": -0.2103899286148396,
        "compression_ratio": 1.770949720670391,
        "end": 644.5,
        "id": 279,
        "no_speech_prob": 0.000002443991661493783,
        "seek": 61774,
        "start": 643.02,
        "temperature": 0,
        "text": " The training is now irrelevant.",
        "tokens": [
          51628,
          440,
          3097,
          307,
          586,
          28682,
          13,
          51702
        ]
      },
      {
        "avg_logprob": -0.2579486227443076,
        "compression_ratio": 1.8,
        "end": 648.22,
        "id": 280,
        "no_speech_prob": 0.000022125661416794173,
        "seek": 64450,
        "start": 644.5,
        "temperature": 0,
        "text": " I could actually completely comment this out as well.",
        "tokens": [
          50364,
          286,
          727,
          767,
          2584,
          2871,
          341,
          484,
          382,
          731,
          13,
          50550
        ]
      },
      {
        "avg_logprob": -0.2579486227443076,
        "compression_ratio": 1.8,
        "end": 650.34,
        "id": 281,
        "no_speech_prob": 0.000022125661416794173,
        "seek": 64450,
        "start": 648.22,
        "temperature": 0,
        "text": " And basically, I want to start training",
        "tokens": [
          50550,
          400,
          1936,
          11,
          286,
          528,
          281,
          722,
          3097,
          50656
        ]
      },
      {
        "avg_logprob": -0.2579486227443076,
        "compression_ratio": 1.8,
        "end": 651.82,
        "id": 282,
        "no_speech_prob": 0.000022125661416794173,
        "seek": 64450,
        "start": 650.34,
        "temperature": 0,
        "text": " when the model is ready.",
        "tokens": [
          50656,
          562,
          264,
          2316,
          307,
          1919,
          13,
          50730
        ]
      },
      {
        "avg_logprob": -0.2579486227443076,
        "compression_ratio": 1.8,
        "end": 652.78,
        "id": 283,
        "no_speech_prob": 0.000022125661416794173,
        "seek": 64450,
        "start": 651.82,
        "temperature": 0,
        "text": " Not training, sorry.",
        "tokens": [
          50730,
          1726,
          3097,
          11,
          2597,
          13,
          50778
        ]
      },
      {
        "avg_logprob": -0.2579486227443076,
        "compression_ratio": 1.8,
        "end": 654.98,
        "id": 284,
        "no_speech_prob": 0.000022125661416794173,
        "seek": 64450,
        "start": 652.78,
        "temperature": 0,
        "text": " I want to start guessing when the model is ready",
        "tokens": [
          50778,
          286,
          528,
          281,
          722,
          17939,
          562,
          264,
          2316,
          307,
          1919,
          50888
        ]
      },
      {
        "avg_logprob": -0.2579486227443076,
        "compression_ratio": 1.8,
        "end": 657.02,
        "id": 285,
        "no_speech_prob": 0.000022125661416794173,
        "seek": 64450,
        "start": 654.98,
        "temperature": 0,
        "text": " by saying classifier to classify.",
        "tokens": [
          50888,
          538,
          1566,
          1508,
          9902,
          281,
          33872,
          13,
          50990
        ]
      },
      {
        "avg_logprob": -0.2579486227443076,
        "compression_ratio": 1.8,
        "end": 657.86,
        "id": 286,
        "no_speech_prob": 0.000022125661416794173,
        "seek": 64450,
        "start": 657.02,
        "temperature": 0,
        "text": " Got results.",
        "tokens": [
          50990,
          5803,
          3542,
          13,
          51032
        ]
      },
      {
        "avg_logprob": -0.2579486227443076,
        "compression_ratio": 1.8,
        "end": 660.42,
        "id": 287,
        "no_speech_prob": 0.000022125661416794173,
        "seek": 64450,
        "start": 657.86,
        "temperature": 0,
        "text": " And now, here we go.",
        "tokens": [
          51032,
          400,
          586,
          11,
          510,
          321,
          352,
          13,
          51160
        ]
      },
      {
        "avg_logprob": -0.2579486227443076,
        "compression_ratio": 1.8,
        "end": 661.74,
        "id": 288,
        "no_speech_prob": 0.000022125661416794173,
        "seek": 64450,
        "start": 660.42,
        "temperature": 0,
        "text": " Loading the model.",
        "tokens": [
          51160,
          6130,
          8166,
          264,
          2316,
          13,
          51226
        ]
      },
      {
        "avg_logprob": -0.2579486227443076,
        "compression_ratio": 1.8,
        "end": 662.86,
        "id": 289,
        "no_speech_prob": 0.000022125661416794173,
        "seek": 64450,
        "start": 661.74,
        "temperature": 0,
        "text": " Model is ready.",
        "tokens": [
          51226,
          17105,
          307,
          1919,
          13,
          51282
        ]
      },
      {
        "avg_logprob": -0.2579486227443076,
        "compression_ratio": 1.8,
        "end": 664.78,
        "id": 290,
        "no_speech_prob": 0.000022125661416794173,
        "seek": 64450,
        "start": 662.86,
        "temperature": 0,
        "text": " Happy.",
        "tokens": [
          51282,
          8277,
          13,
          51378
        ]
      },
      {
        "avg_logprob": -0.2579486227443076,
        "compression_ratio": 1.8,
        "end": 666.1,
        "id": 291,
        "no_speech_prob": 0.000022125661416794173,
        "seek": 64450,
        "start": 664.78,
        "temperature": 0,
        "text": " Sad.",
        "tokens": [
          51378,
          12269,
          13,
          51444
        ]
      },
      {
        "avg_logprob": -0.2579486227443076,
        "compression_ratio": 1.8,
        "end": 666.94,
        "id": 292,
        "no_speech_prob": 0.000022125661416794173,
        "seek": 64450,
        "start": 666.1,
        "temperature": 0,
        "text": " Happy.",
        "tokens": [
          51444,
          8277,
          13,
          51486
        ]
      },
      {
        "avg_logprob": -0.2579486227443076,
        "compression_ratio": 1.8,
        "end": 668.78,
        "id": 293,
        "no_speech_prob": 0.000022125661416794173,
        "seek": 64450,
        "start": 666.94,
        "temperature": 0,
        "text": " Sad.",
        "tokens": [
          51486,
          12269,
          13,
          51578
        ]
      },
      {
        "avg_logprob": -0.2579486227443076,
        "compression_ratio": 1.8,
        "end": 671.12,
        "id": 294,
        "no_speech_prob": 0.000022125661416794173,
        "seek": 64450,
        "start": 668.78,
        "temperature": 0,
        "text": " And I can refresh the page again.",
        "tokens": [
          51578,
          400,
          286,
          393,
          15134,
          264,
          3028,
          797,
          13,
          51695
        ]
      },
      {
        "avg_logprob": -0.2579486227443076,
        "compression_ratio": 1.8,
        "end": 671.96,
        "id": 295,
        "no_speech_prob": 0.000022125661416794173,
        "seek": 64450,
        "start": 671.12,
        "temperature": 0,
        "text": " And happy.",
        "tokens": [
          51695,
          400,
          2055,
          13,
          51737
        ]
      },
      {
        "avg_logprob": -0.27270057927007263,
        "compression_ratio": 1.78125,
        "end": 675.94,
        "id": 296,
        "no_speech_prob": 0.0008693576673977077,
        "seek": 67450,
        "start": 675.1,
        "temperature": 0,
        "text": " Sad.",
        "tokens": [
          50394,
          12269,
          13,
          50436
        ]
      },
      {
        "avg_logprob": -0.27270057927007263,
        "compression_ratio": 1.78125,
        "end": 677.66,
        "id": 297,
        "no_speech_prob": 0.0008693576673977077,
        "seek": 67450,
        "start": 676.78,
        "temperature": 0,
        "text": " Happy.",
        "tokens": [
          50478,
          8277,
          13,
          50522
        ]
      },
      {
        "avg_logprob": -0.27270057927007263,
        "compression_ratio": 1.78125,
        "end": 678.5,
        "id": 298,
        "no_speech_prob": 0.0008693576673977077,
        "seek": 67450,
        "start": 677.66,
        "temperature": 0,
        "text": " Sad.",
        "tokens": [
          50522,
          12269,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.27270057927007263,
        "compression_ratio": 1.78125,
        "end": 679.34,
        "id": 299,
        "no_speech_prob": 0.0008693576673977077,
        "seek": 67450,
        "start": 678.5,
        "temperature": 0,
        "text": " All right, so it works.",
        "tokens": [
          50564,
          1057,
          558,
          11,
          370,
          309,
          1985,
          13,
          50606
        ]
      },
      {
        "avg_logprob": -0.27270057927007263,
        "compression_ratio": 1.78125,
        "end": 680.18,
        "id": 300,
        "no_speech_prob": 0.0008693576673977077,
        "seek": 67450,
        "start": 679.34,
        "temperature": 0,
        "text": " We're done.",
        "tokens": [
          50606,
          492,
          434,
          1096,
          13,
          50648
        ]
      },
      {
        "avg_logprob": -0.27270057927007263,
        "compression_ratio": 1.78125,
        "end": 681,
        "id": 301,
        "no_speech_prob": 0.0008693576673977077,
        "seek": 67450,
        "start": 680.18,
        "temperature": 0,
        "text": " Yay!",
        "tokens": [
          50648,
          13268,
          0,
          50689
        ]
      },
      {
        "avg_logprob": -0.27270057927007263,
        "compression_ratio": 1.78125,
        "end": 682.22,
        "id": 302,
        "no_speech_prob": 0.0008693576673977077,
        "seek": 67450,
        "start": 681,
        "temperature": 0,
        "text": " Okay, this is a thing you can do now.",
        "tokens": [
          50689,
          1033,
          11,
          341,
          307,
          257,
          551,
          291,
          393,
          360,
          586,
          13,
          50750
        ]
      },
      {
        "avg_logprob": -0.27270057927007263,
        "compression_ratio": 1.78125,
        "end": 684.46,
        "id": 303,
        "no_speech_prob": 0.0008693576673977077,
        "seek": 67450,
        "start": 682.22,
        "temperature": 0,
        "text": " You can train your own transfer learning model.",
        "tokens": [
          50750,
          509,
          393,
          3847,
          428,
          1065,
          5003,
          2539,
          2316,
          13,
          50862
        ]
      },
      {
        "avg_logprob": -0.27270057927007263,
        "compression_ratio": 1.78125,
        "end": 686.14,
        "id": 304,
        "no_speech_prob": 0.0008693576673977077,
        "seek": 67450,
        "start": 684.46,
        "temperature": 0,
        "text": " You can do this with the regression example too",
        "tokens": [
          50862,
          509,
          393,
          360,
          341,
          365,
          264,
          24590,
          1365,
          886,
          50946
        ]
      },
      {
        "avg_logprob": -0.27270057927007263,
        "compression_ratio": 1.78125,
        "end": 687.34,
        "id": 305,
        "no_speech_prob": 0.0008693576673977077,
        "seek": 67450,
        "start": 686.14,
        "temperature": 0,
        "text": " if you watched that video.",
        "tokens": [
          50946,
          498,
          291,
          6337,
          300,
          960,
          13,
          51006
        ]
      },
      {
        "avg_logprob": -0.27270057927007263,
        "compression_ratio": 1.78125,
        "end": 688.18,
        "id": 306,
        "no_speech_prob": 0.0008693576673977077,
        "seek": 67450,
        "start": 687.34,
        "temperature": 0,
        "text": " You can save it.",
        "tokens": [
          51006,
          509,
          393,
          3155,
          309,
          13,
          51048
        ]
      },
      {
        "avg_logprob": -0.27270057927007263,
        "compression_ratio": 1.78125,
        "end": 689.42,
        "id": 307,
        "no_speech_prob": 0.0008693576673977077,
        "seek": 67450,
        "start": 688.18,
        "temperature": 0,
        "text": " So, I don't know, share.",
        "tokens": [
          51048,
          407,
          11,
          286,
          500,
          380,
          458,
          11,
          2073,
          13,
          51110
        ]
      },
      {
        "avg_logprob": -0.27270057927007263,
        "compression_ratio": 1.78125,
        "end": 690.52,
        "id": 308,
        "no_speech_prob": 0.0008693576673977077,
        "seek": 67450,
        "start": 689.42,
        "temperature": 0,
        "text": " You can share models.",
        "tokens": [
          51110,
          509,
          393,
          2073,
          5245,
          13,
          51165
        ]
      },
      {
        "avg_logprob": -0.27270057927007263,
        "compression_ratio": 1.78125,
        "end": 691.7,
        "id": 309,
        "no_speech_prob": 0.0008693576673977077,
        "seek": 67450,
        "start": 690.52,
        "temperature": 0,
        "text": " Let's all share models with each other.",
        "tokens": [
          51165,
          961,
          311,
          439,
          2073,
          5245,
          365,
          1184,
          661,
          13,
          51224
        ]
      },
      {
        "avg_logprob": -0.27270057927007263,
        "compression_ratio": 1.78125,
        "end": 694.1,
        "id": 310,
        "no_speech_prob": 0.0008693576673977077,
        "seek": 67450,
        "start": 691.7,
        "temperature": 0,
        "text": " Share your model with me.",
        "tokens": [
          51224,
          14945,
          428,
          2316,
          365,
          385,
          13,
          51344
        ]
      },
      {
        "avg_logprob": -0.27270057927007263,
        "compression_ratio": 1.78125,
        "end": 695.22,
        "id": 311,
        "no_speech_prob": 0.0008693576673977077,
        "seek": 67450,
        "start": 694.1,
        "temperature": 0,
        "text": " Let's see what happens.",
        "tokens": [
          51344,
          961,
          311,
          536,
          437,
          2314,
          13,
          51400
        ]
      },
      {
        "avg_logprob": -0.27270057927007263,
        "compression_ratio": 1.78125,
        "end": 696.38,
        "id": 312,
        "no_speech_prob": 0.0008693576673977077,
        "seek": 67450,
        "start": 695.22,
        "temperature": 0,
        "text": " All right, I'm curious to see",
        "tokens": [
          51400,
          1057,
          558,
          11,
          286,
          478,
          6369,
          281,
          536,
          51458
        ]
      },
      {
        "avg_logprob": -0.27270057927007263,
        "compression_ratio": 1.78125,
        "end": 698.34,
        "id": 313,
        "no_speech_prob": 0.0008693576673977077,
        "seek": 67450,
        "start": 696.38,
        "temperature": 0,
        "text": " what kind of creative stuff you come up with.",
        "tokens": [
          51458,
          437,
          733,
          295,
          5880,
          1507,
          291,
          808,
          493,
          365,
          13,
          51556
        ]
      },
      {
        "avg_logprob": -0.27270057927007263,
        "compression_ratio": 1.78125,
        "end": 700.5,
        "id": 314,
        "no_speech_prob": 0.0008693576673977077,
        "seek": 67450,
        "start": 698.34,
        "temperature": 0,
        "text": " What kind of, the interaction that I've done here",
        "tokens": [
          51556,
          708,
          733,
          295,
          11,
          264,
          9285,
          300,
          286,
          600,
          1096,
          510,
          51664
        ]
      },
      {
        "avg_logprob": -0.27270057927007263,
        "compression_ratio": 1.78125,
        "end": 701.38,
        "id": 315,
        "no_speech_prob": 0.0008693576673977077,
        "seek": 67450,
        "start": 700.5,
        "temperature": 0,
        "text": " is like super awkward.",
        "tokens": [
          51664,
          307,
          411,
          1687,
          11411,
          13,
          51708
        ]
      },
      {
        "avg_logprob": -0.27270057927007263,
        "compression_ratio": 1.78125,
        "end": 703.02,
        "id": 316,
        "no_speech_prob": 0.0008693576673977077,
        "seek": 67450,
        "start": 701.38,
        "temperature": 0,
        "text": " Like I'm going to press the button all the time.",
        "tokens": [
          51708,
          1743,
          286,
          478,
          516,
          281,
          1886,
          264,
          2960,
          439,
          264,
          565,
          13,
          51790
        ]
      },
      {
        "avg_logprob": -0.20206562776743256,
        "compression_ratio": 1.975,
        "end": 705.1,
        "id": 317,
        "no_speech_prob": 0.00019716417591553181,
        "seek": 70302,
        "start": 703.54,
        "temperature": 0,
        "text": " You don't actually have to train with just video.",
        "tokens": [
          50390,
          509,
          500,
          380,
          767,
          362,
          281,
          3847,
          365,
          445,
          960,
          13,
          50468
        ]
      },
      {
        "avg_logprob": -0.20206562776743256,
        "compression_ratio": 1.975,
        "end": 706.74,
        "id": 318,
        "no_speech_prob": 0.00019716417591553181,
        "seek": 70302,
        "start": 705.1,
        "temperature": 0,
        "text": " You could load a bunch of images.",
        "tokens": [
          50468,
          509,
          727,
          3677,
          257,
          3840,
          295,
          5267,
          13,
          50550
        ]
      },
      {
        "avg_logprob": -0.20206562776743256,
        "compression_ratio": 1.975,
        "end": 708.22,
        "id": 319,
        "no_speech_prob": 0.00019716417591553181,
        "seek": 70302,
        "start": 706.74,
        "temperature": 0,
        "text": " So, there's so many possibilities here",
        "tokens": [
          50550,
          407,
          11,
          456,
          311,
          370,
          867,
          12178,
          510,
          50624
        ]
      },
      {
        "avg_logprob": -0.20206562776743256,
        "compression_ratio": 1.975,
        "end": 710.5,
        "id": 320,
        "no_speech_prob": 0.00019716417591553181,
        "seek": 70302,
        "start": 708.22,
        "temperature": 0,
        "text": " and I look forward to seeing what you make",
        "tokens": [
          50624,
          293,
          286,
          574,
          2128,
          281,
          2577,
          437,
          291,
          652,
          50738
        ]
      },
      {
        "avg_logprob": -0.20206562776743256,
        "compression_ratio": 1.975,
        "end": 713.38,
        "id": 321,
        "no_speech_prob": 0.00019716417591553181,
        "seek": 70302,
        "start": 710.5,
        "temperature": 0,
        "text": " and stay tuned for more ml5 videos.",
        "tokens": [
          50738,
          293,
          1754,
          10870,
          337,
          544,
          23271,
          20,
          2145,
          13,
          50882
        ]
      },
      {
        "avg_logprob": -0.20206562776743256,
        "compression_ratio": 1.975,
        "end": 714.54,
        "id": 322,
        "no_speech_prob": 0.00019716417591553181,
        "seek": 70302,
        "start": 713.38,
        "temperature": 0,
        "text": " More stuff is coming.",
        "tokens": [
          50882,
          5048,
          1507,
          307,
          1348,
          13,
          50940
        ]
      },
      {
        "avg_logprob": -0.20206562776743256,
        "compression_ratio": 1.975,
        "end": 716.14,
        "id": 323,
        "no_speech_prob": 0.00019716417591553181,
        "seek": 70302,
        "start": 714.54,
        "temperature": 0,
        "text": " I don't know yet what, but more stuff is coming.",
        "tokens": [
          50940,
          286,
          500,
          380,
          458,
          1939,
          437,
          11,
          457,
          544,
          1507,
          307,
          1348,
          13,
          51020
        ]
      },
      {
        "avg_logprob": -0.20206562776743256,
        "compression_ratio": 1.975,
        "end": 716.98,
        "id": 324,
        "no_speech_prob": 0.00019716417591553181,
        "seek": 70302,
        "start": 716.14,
        "temperature": 0,
        "text": " Goodbye.",
        "tokens": [
          51020,
          15528,
          13,
          51062
        ]
      },
      {
        "avg_logprob": -0.20206562776743256,
        "compression_ratio": 1.975,
        "end": 717.8199999999999,
        "id": 325,
        "no_speech_prob": 0.00019716417591553181,
        "seek": 70302,
        "start": 716.98,
        "temperature": 0,
        "text": " Ding!",
        "tokens": [
          51062,
          20558,
          0,
          51104
        ]
      },
      {
        "avg_logprob": -0.20206562776743256,
        "compression_ratio": 1.975,
        "end": 718.64,
        "id": 326,
        "no_speech_prob": 0.00019716417591553181,
        "seek": 70302,
        "start": 717.8199999999999,
        "temperature": 0,
        "text": " Ding!",
        "tokens": [
          51104,
          220,
          35,
          278,
          0,
          51145
        ]
      },
      {
        "avg_logprob": -0.20206562776743256,
        "compression_ratio": 1.975,
        "end": 719.48,
        "id": 327,
        "no_speech_prob": 0.00019716417591553181,
        "seek": 70302,
        "start": 718.64,
        "temperature": 0,
        "text": " Ding!",
        "tokens": [
          51145,
          20558,
          0,
          51187
        ]
      },
      {
        "avg_logprob": -0.20206562776743256,
        "compression_ratio": 1.975,
        "end": 720.3,
        "id": 328,
        "no_speech_prob": 0.00019716417591553181,
        "seek": 70302,
        "start": 719.48,
        "temperature": 0,
        "text": " Ding!",
        "tokens": [
          51187,
          20558,
          0,
          51228
        ]
      },
      {
        "avg_logprob": -0.20206562776743256,
        "compression_ratio": 1.975,
        "end": 721.14,
        "id": 329,
        "no_speech_prob": 0.00019716417591553181,
        "seek": 70302,
        "start": 720.3,
        "temperature": 0,
        "text": " Ding!",
        "tokens": [
          51228,
          20558,
          0,
          51270
        ]
      },
      {
        "avg_logprob": -0.20206562776743256,
        "compression_ratio": 1.975,
        "end": 721.98,
        "id": 330,
        "no_speech_prob": 0.00019716417591553181,
        "seek": 70302,
        "start": 721.14,
        "temperature": 0,
        "text": " Ding!",
        "tokens": [
          51270,
          20558,
          0,
          51312
        ]
      },
      {
        "avg_logprob": -0.20206562776743256,
        "compression_ratio": 1.975,
        "end": 722.8,
        "id": 331,
        "no_speech_prob": 0.00019716417591553181,
        "seek": 70302,
        "start": 721.98,
        "temperature": 0,
        "text": " Ding!",
        "tokens": [
          51312,
          20558,
          0,
          51353
        ]
      },
      {
        "avg_logprob": -0.20206562776743256,
        "compression_ratio": 1.975,
        "end": 723.64,
        "id": 332,
        "no_speech_prob": 0.00019716417591553181,
        "seek": 70302,
        "start": 722.8,
        "temperature": 0,
        "text": " Ding!",
        "tokens": [
          51353,
          20558,
          0,
          51395
        ]
      },
      {
        "avg_logprob": -0.20206562776743256,
        "compression_ratio": 1.975,
        "end": 724.48,
        "id": 333,
        "no_speech_prob": 0.00019716417591553181,
        "seek": 70302,
        "start": 723.64,
        "temperature": 0,
        "text": " Ding!",
        "tokens": [
          51395,
          20558,
          0,
          51437
        ]
      },
      {
        "avg_logprob": -0.20206562776743256,
        "compression_ratio": 1.975,
        "end": 725.3,
        "id": 334,
        "no_speech_prob": 0.00019716417591553181,
        "seek": 70302,
        "start": 724.48,
        "temperature": 0,
        "text": " Ding!",
        "tokens": [
          51437,
          20558,
          0,
          51478
        ]
      },
      {
        "avg_logprob": -0.20206562776743256,
        "compression_ratio": 1.975,
        "end": 726.14,
        "id": 335,
        "no_speech_prob": 0.00019716417591553181,
        "seek": 70302,
        "start": 725.3,
        "temperature": 0,
        "text": " Ding!",
        "tokens": [
          51478,
          20558,
          0,
          51520
        ]
      },
      {
        "avg_logprob": -0.20206562776743256,
        "compression_ratio": 1.975,
        "end": 726.98,
        "id": 336,
        "no_speech_prob": 0.00019716417591553181,
        "seek": 70302,
        "start": 726.14,
        "temperature": 0,
        "text": " Ding!",
        "tokens": [
          51520,
          20558,
          0,
          51562
        ]
      },
      {
        "avg_logprob": -0.20206562776743256,
        "compression_ratio": 1.975,
        "end": 727.8,
        "id": 337,
        "no_speech_prob": 0.00019716417591553181,
        "seek": 70302,
        "start": 726.98,
        "temperature": 0,
        "text": " Ding!",
        "tokens": [
          51562,
          20558,
          0,
          51603
        ]
      },
      {
        "avg_logprob": -0.20206562776743256,
        "compression_ratio": 1.975,
        "end": 728.64,
        "id": 338,
        "no_speech_prob": 0.00019716417591553181,
        "seek": 70302,
        "start": 727.8,
        "temperature": 0,
        "text": " Ding!",
        "tokens": [
          51603,
          20558,
          0,
          51645
        ]
      },
      {
        "avg_logprob": -0.20206562776743256,
        "compression_ratio": 1.975,
        "end": 729.48,
        "id": 339,
        "no_speech_prob": 0.00019716417591553181,
        "seek": 70302,
        "start": 728.64,
        "temperature": 0,
        "text": " Ding!",
        "tokens": [
          51645,
          20558,
          0,
          51687
        ]
      },
      {
        "avg_logprob": -0.20206562776743256,
        "compression_ratio": 1.975,
        "end": 730.3,
        "id": 340,
        "no_speech_prob": 0.00019716417591553181,
        "seek": 70302,
        "start": 729.48,
        "temperature": 0,
        "text": " Ding!",
        "tokens": [
          51687,
          20558,
          0,
          51728
        ]
      },
      {
        "avg_logprob": -0.20206562776743256,
        "compression_ratio": 1.975,
        "end": 731.14,
        "id": 341,
        "no_speech_prob": 0.00019716417591553181,
        "seek": 70302,
        "start": 730.3,
        "temperature": 0,
        "text": " Ding!",
        "tokens": [
          51728,
          20558,
          0,
          51770
        ]
      },
      {
        "avg_logprob": -0.20206562776743256,
        "compression_ratio": 1.975,
        "end": 731.98,
        "id": 342,
        "no_speech_prob": 0.00019716417591553181,
        "seek": 70302,
        "start": 731.14,
        "temperature": 0,
        "text": " Ding!",
        "tokens": [
          51770,
          20558,
          0,
          51812
        ]
      },
      {
        "avg_logprob": -0.20206562776743256,
        "compression_ratio": 1.975,
        "end": 732.8,
        "id": 343,
        "no_speech_prob": 0.00019716417591553181,
        "seek": 70302,
        "start": 731.98,
        "temperature": 0,
        "text": " Ding!",
        "tokens": [
          51812,
          20558,
          0,
          51853
        ]
      }
    ],
    "transcription": " Hello and welcome to another beginner's guide to machine learning with ml5.js video. Now, in this video, I am going to unlock something for you. It's already unlocked for you, but I'm going to show it to you that is incredibly powerful for what you can do now with ml5 that you couldn't do before, but many of you asked about in the comments. And what is that? It is the save load feature extractor. This is a new feature that was added to ml5 just five days ago. You need to make sure that you are using ml5 0.1.3 or whatever number in the future past that, but certainly this is the version of the library that I'm using in this video. Now, what does it do? So the last example, if you've been watching these video series in order, was this example. What this example does is it loads a pre-trained image classification model called MobileNet. And MobileNet is trained on 1,000 different kinds of things and recognizes puppies and dogs and birds and different kinds of objects. Transfer learning is the process by which we take that pre-trained MobileNet model and basically disconnect it from all of those labels and reconnect it to our own labels. For example, I'm going to make up a label called happy and a label called sad. I could certainly have more than just two. And I'm going to show it things like the train whistle is me being happy. Oh, oh, oh, oh, oh, oh, oh, oh, oh. I'm going to show it that train whistle a bunch of times. Say happy, happy, happy, happy, happy. Now, no train whistle is very sad. I'm sad, no train whistle is sad. Oh, I'm spending way too much time on this because I haven't implemented the thing that I want to implement. Now I'm going to say train and it's going to train and then once it's done, ah! Happy. Sad. Happy train whistle. Sad. Okay, so it works. It is now learning to classify images in real time according to those two categories. But I'm a big spaz and I'm going to just be over here doing refresh and I have now lost that forever. I no longer have that model, it's gone. The new feature is ability to save that custom trained model and then reload it. So if you're using this for an installation and you're going to take down the computer and set it up every day, you can save that model. You can imagine, there's lots of possibilities here. So there's only two things that I really need to add to the code. There's a save function and a load function. There's a bunch of pieces there but that's what I'm going to do right now. So I'm going to go here into the code and I'm going to just add another button. Like I have a happy button, a sad button, and a train button. Choo choo. I'm going to add a sad button. No, not sad, a save button. I'm going to call it save and save button and when the mouse is pressed, I'm just going to say classifier.save. That's it. All I have to do is say classifier.save. Let's see what happens. So I'm not going to train it very, actually no, I am going to train. I'm going to let's do a really good solid training this time because this is the one we're going to save as long as it works. All right, so let's do the same thing. Happy, happy, happy, happy. Train whistle is a happy thing. A happy, happy, happy thing. Just me is very sad. There's no train whistle. I'm so sad, I'm very sad, I'm very sad and now I'm going to train this. Weird how the loss is zero. I'm just going to not worry about that too much. I'm going to hit save. And now, you can see that down here by the way that I did this a couple times practicing. Now, what it did is it downloaded, come on, to my download directory two files, model.json and model.weights.bin. So those files will end up wherever the default downloads directory of your browser is and the next step is just to load those files in. But before we load them, let's talk about what's in those files. So there's two files. I said model.json, model.weights.bin. Okay, so what is a neural network? What is a machine learning model? What is the thing that we're saving? Well, in this case, it's actually saving the configuration of a neural network. Now, if you want to know what a neural network is, I have some videos about that but I would refer you to the three blue, one brown video, what is a neural network? I will link to that in this video's description. That will give you a much bigger deep dive into those details. But if you look at that video, what you'll see is there's basically like a big diagram and the diagram has a bunch of inputs. It has some outputs. By the way, in this case, we could actually say the outputs are just two, a happy and a sad. And what the neural network, what the machine learning model outputs is a probability, maybe like 80% of it being happy, of that image being happy and 20% that image is sad. So the whole point of this is to feed in an image, right? It's the image and maybe all the pixels of the image that are actually these inputs. It goes through this magic neural network thing which isn't really magic, it's a thing that you can learn about. And then out the other end comes a guess as to whether it's happy or sad. Now what is all this stuff in the middle? The stuff in the middle is typically referred to and there are many different styles and flavors and kinds of neural network but in the sort of zoomed out view, in general terms, is what's known as a hidden layer or hidden layers. So every input is connected to the output but not directly. There are some amount of nodes, maybe two hidden layers each with four nodes and every input is connected to every node and then every node is connected to every node and then every node is connected to every output and so on and so forth. So I could be here all day trying to do this diagram and draw every connection between everything. I'm not going to do that. But all of the information about here is what is saved in these two files. Model.json is a file that just explains all of these pieces. The layers, the outputs, the inputs, all of that stuff. That is what is in model.json. In a moment I'll just open up that file and look at it. Model.weights is an interesting thing. So the magic of a neural network, what makes a neural network work is a number that's associated with every single one of these connections known as a weight. You can think of it as like a whole bunch of dials. So I'm tuning the dials, right? I'm trying to get the dials in the right position so that it really makes good guesses about happy versus sad. That's the training process. Once that training process is done, I want to save where all those dials are. All of those numbers are in this file. This is a binary format file because there's a lot of numbers. Millions upon millions of connections potentially between a lot of pixels and a lot of labels, a lot of hidden layers. So this, you'll notice like the file that we saved is five megabytes because it's tons and tons of numbers. So it ends up, but this is just a very small file with a little bit of text information about how this is configured. Okay, I spent a lot of time on that. Hopefully that's some helpful background to you. Let's go back and actually look at those files. So now I've got those files. What I'm going to do is I'm just going to drag them into Visual Studio Code, which is what I'm using to code this right now, but you could be using any environment. Oops, they didn't make it into the right place. Let me try that again. I'll clean this up later, but I want them in this directory, great. So you can see that they're there, model.json, model.weights.bin. If I click on this, you can see, you can start to see all the stuff in it. There's information about the input shape and is it a sequential model and what kind of algorithm are you using and oh, is it dense? And it uses something called softmat, all this stuff. So this is way beyond the scope of what I'm doing in these videos, but if you're interested in more about these details, you could look at some of my videos that use TensorFlow.js natively to understand more pieces here. But you can see here, this is where it's looking for the weights file, et cetera, et cetera. And this is really important. This is something, this is really just the TensorFlow, what TensorFlow.js would do natively, but ml5 is helping with a little bit on top of it by adding these happy and sad labels. Okay. So now, all we have to do is load the model now. Okay, so we're going to go, we save that model and so the steps are, the first thing we have to do is load the MobileNet model. So we're not actually saving that original pre-trained image classifier. We're just saving the bits and pieces that are like hooked into it. So we can't hook into it until MobileNet is ready. So once we've hooked into, once MobileNet is ready, we can then say classifier.load model.json. Now, there are two files, model.json and model.weights.bin, but if you, ml5 is set up that if you just give it one file, it'll look automatically for the other file in the same place. There are ways of customizing the file names and their paths and all that, that you can sort of look into in the documentation. But the easiest thing for just to do this, and then I'm going to say custom model ready. So I'm going to write another event function. A custom model ready. And there, I'm going to say, custom model is ready. So it's a two-step process. We have to load MobileNet, MobileNet is ready. Then load model.json with the weights, custom model is ready. All right, let's just run this. Zoom back out. And there we go. Everything's loaded, but I don't see any results. Hmm, I don't see any results. Why? Well, this sketch was written with, originally, with code to train. So I'm supposed to press the buttons and it'd train, but now I don't need to train, because I loaded the model. So this is where I kind of like, I don't know what you should do next. Maybe you want to keep two separate webpages, two separate sketches, one for training and one for loading. Maybe you do it all in one. You'll actually see, if you go to the ml5 examples, there's one that has a button that you can drag and drop. You can actually select files and load them and save them all in the same sketch. But what I want to do now is basically a workflow for, I'm done with the training, so I'm not going to ever train again. So I can actually remove all of these buttons. They're no longer relevant to me. The text that should show up at the beginning is just loading model. And then when the model is ready, I would say label equals model ready. So let's run this now. So now it's loading model, loading model, model ready. And now, once the model is ready, all I need to do is start classifying. And before, I didn't classify until the training was finished. The training is now irrelevant. I could actually completely comment this out as well. And basically, I want to start training when the model is ready. Not training, sorry. I want to start guessing when the model is ready by saying classifier to classify. Got results. And now, here we go. Loading the model. Model is ready. Happy. Sad. Happy. Sad. And I can refresh the page again. And happy. Sad. Happy. Sad. All right, so it works. We're done. Yay! Okay, this is a thing you can do now. You can train your own transfer learning model. You can do this with the regression example too if you watched that video. You can save it. So, I don't know, share. You can share models. Let's all share models with each other. Share your model with me. Let's see what happens. All right, I'm curious to see what kind of creative stuff you come up with. What kind of, the interaction that I've done here is like super awkward. Like I'm going to press the button all the time. You don't actually have to train with just video. You could load a bunch of images. So, there's so many possibilities here and I look forward to seeing what you make and stay tuned for more ml5 videos. More stuff is coming. I don't know yet what, but more stuff is coming. Goodbye. Ding! Ding! Ding! Ding! Ding! Ding! Ding! Ding! Ding! Ding! Ding! Ding! Ding! Ding! Ding! Ding! Ding! Ding! Ding!",
    "translation": null
  },
  "error": null,
  "status": "succeeded",
  "created_at": "2023-09-26T21:03:44.065247Z",
  "started_at": "2023-09-26T21:16:27.163049Z",
  "completed_at": "2023-09-26T21:20:29.800119Z",
  "webhook": "https://83ceaa0b612c.ngrok.app/?video_id=eU7gIy3xV30",
  "webhook_events_filter": [
    "completed"
  ],
  "metrics": {
    "predict_time": 242.63707
  },
  "urls": {
    "cancel": "https://api.replicate.com/v1/predictions/httujtjb6hcqn4vcb7px62a5ne/cancel",
    "get": "https://api.replicate.com/v1/predictions/httujtjb6hcqn4vcb7px62a5ne"
  }
}