{
  "id": "powxk5bbbiywm55rp3j4nvk524",
  "version": "91ee9c0c3df30478510ff8c8a3a545add1ad0259ad3a9f78fba57fbc05ee64f7",
  "input": {
    "audio": "https://upcdn.io/FW25b4F/raw/coding-train/fFzvwdkzr_c.m4a"
  },
  "logs": "Transcribe with large-v2 model\nDetected language: English\n  0%|          | 0/59032 [00:00<?, ?frames/s]\n  5%|▍         | 2756/59032 [00:07<02:42, 346.06frames/s]\n  9%|▉         | 5600/59032 [00:14<02:11, 407.48frames/s]\n 14%|█▍        | 8508/59032 [00:21<02:02, 411.53frames/s]\n 19%|█▉        | 11104/59032 [00:27<01:55, 416.24frames/s]\n 24%|██▎       | 13948/59032 [00:32<01:38, 458.25frames/s]\n 28%|██▊       | 16640/59032 [00:39<01:37, 434.11frames/s]\n 33%|███▎      | 19392/59032 [00:46<01:33, 421.86frames/s]\n 38%|███▊      | 22340/59032 [00:52<01:25, 431.02frames/s]\n 43%|████▎     | 25340/59032 [00:58<01:15, 448.41frames/s]\n 48%|████▊     | 28260/59032 [01:07<01:16, 402.32frames/s]\n 53%|█████▎    | 31032/59032 [01:17<01:17, 361.32frames/s]\n 57%|█████▋    | 33896/59032 [01:25<01:09, 360.03frames/s]\n 62%|██████▏   | 36768/59032 [01:33<01:02, 354.92frames/s]\n 67%|██████▋   | 39768/59032 [01:42<00:54, 354.50frames/s]\n 72%|███████▏  | 42768/59032 [01:49<00:43, 375.01frames/s]\n 77%|███████▋  | 45576/59032 [01:57<00:36, 364.87frames/s]\n 82%|████████▏ | 48408/59032 [02:04<00:29, 364.71frames/s]\n 87%|████████▋ | 51240/59032 [02:13<00:22, 349.98frames/s]\n 92%|█████████▏| 54132/59032 [02:21<00:13, 359.48frames/s]\n 96%|█████████▋| 56956/59032 [02:27<00:05, 387.74frames/s]\n 98%|█████████▊| 58026/59032 [02:30<00:02, 371.19frames/s]\n100%|██████████| 59032/59032 [02:34<00:00, 356.37frames/s]\n100%|██████████| 59032/59032 [02:34<00:00, 382.34frames/s]\n",
  "output": {
    "detected_language": "english",
    "segments": [
      {
        "avg_logprob": -0.23143315906367026,
        "compression_ratio": 1.7374517374517375,
        "end": 2.04,
        "id": 0,
        "no_speech_prob": 0.002018833300098777,
        "seek": 0,
        "start": 0,
        "temperature": 0,
        "text": " I don't know where you arrived from.",
        "tokens": [
          50364,
          286,
          500,
          380,
          458,
          689,
          291,
          6678,
          490,
          13,
          50466
        ]
      },
      {
        "avg_logprob": -0.23143315906367026,
        "compression_ratio": 1.7374517374517375,
        "end": 5.22,
        "id": 1,
        "no_speech_prob": 0.002018833300098777,
        "seek": 0,
        "start": 2.04,
        "temperature": 0,
        "text": " But if you didn't arrive from the previous videos",
        "tokens": [
          50466,
          583,
          498,
          291,
          994,
          380,
          8881,
          490,
          264,
          3894,
          2145,
          50625
        ]
      },
      {
        "avg_logprob": -0.23143315906367026,
        "compression_ratio": 1.7374517374517375,
        "end": 6.8,
        "id": 2,
        "no_speech_prob": 0.002018833300098777,
        "seek": 0,
        "start": 5.22,
        "temperature": 0,
        "text": " about training your own neural network,",
        "tokens": [
          50625,
          466,
          3097,
          428,
          1065,
          18161,
          3209,
          11,
          50704
        ]
      },
      {
        "avg_logprob": -0.23143315906367026,
        "compression_ratio": 1.7374517374517375,
        "end": 8.36,
        "id": 3,
        "no_speech_prob": 0.002018833300098777,
        "seek": 0,
        "start": 6.8,
        "temperature": 0,
        "text": " you might feel a little bit lost.",
        "tokens": [
          50704,
          291,
          1062,
          841,
          257,
          707,
          857,
          2731,
          13,
          50782
        ]
      },
      {
        "avg_logprob": -0.23143315906367026,
        "compression_ratio": 1.7374517374517375,
        "end": 10.14,
        "id": 4,
        "no_speech_prob": 0.002018833300098777,
        "seek": 0,
        "start": 8.36,
        "temperature": 0,
        "text": " Because what I'm going to do here entirely",
        "tokens": [
          50782,
          1436,
          437,
          286,
          478,
          516,
          281,
          360,
          510,
          7696,
          50871
        ]
      },
      {
        "avg_logprob": -0.23143315906367026,
        "compression_ratio": 1.7374517374517375,
        "end": 12.94,
        "id": 5,
        "no_speech_prob": 0.002018833300098777,
        "seek": 0,
        "start": 10.14,
        "temperature": 0,
        "text": " depends on the previous few videos",
        "tokens": [
          50871,
          5946,
          322,
          264,
          3894,
          1326,
          2145,
          51011
        ]
      },
      {
        "avg_logprob": -0.23143315906367026,
        "compression_ratio": 1.7374517374517375,
        "end": 17.36,
        "id": 6,
        "no_speech_prob": 0.002018833300098777,
        "seek": 0,
        "start": 12.94,
        "temperature": 0,
        "text": " where I trained a model to classify musical notes based",
        "tokens": [
          51011,
          689,
          286,
          8895,
          257,
          2316,
          281,
          33872,
          9165,
          5570,
          2361,
          51232
        ]
      },
      {
        "avg_logprob": -0.23143315906367026,
        "compression_ratio": 1.7374517374517375,
        "end": 20.080000000000002,
        "id": 7,
        "no_speech_prob": 0.002018833300098777,
        "seek": 0,
        "start": 17.36,
        "temperature": 0,
        "text": " on mouse clicks in a P5 canvas.",
        "tokens": [
          51232,
          322,
          9719,
          18521,
          294,
          257,
          430,
          20,
          16267,
          13,
          51368
        ]
      },
      {
        "avg_logprob": -0.23143315906367026,
        "compression_ratio": 1.7374517374517375,
        "end": 21.62,
        "id": 8,
        "no_speech_prob": 0.002018833300098777,
        "seek": 0,
        "start": 20.080000000000002,
        "temperature": 0,
        "text": " So what I'm going to do in this video",
        "tokens": [
          51368,
          407,
          437,
          286,
          478,
          516,
          281,
          360,
          294,
          341,
          960,
          51445
        ]
      },
      {
        "avg_logprob": -0.23143315906367026,
        "compression_ratio": 1.7374517374517375,
        "end": 24.36,
        "id": 9,
        "no_speech_prob": 0.002018833300098777,
        "seek": 0,
        "start": 21.62,
        "temperature": 0,
        "text": " is change this word from classification,",
        "tokens": [
          51445,
          307,
          1319,
          341,
          1349,
          490,
          21538,
          11,
          51582
        ]
      },
      {
        "avg_logprob": -0.23143315906367026,
        "compression_ratio": 1.7374517374517375,
        "end": 27.560000000000002,
        "id": 10,
        "no_speech_prob": 0.002018833300098777,
        "seek": 0,
        "start": 24.36,
        "temperature": 0,
        "text": " I'm going to do it right now, to regression.",
        "tokens": [
          51582,
          286,
          478,
          516,
          281,
          360,
          309,
          558,
          586,
          11,
          281,
          24590,
          13,
          51742
        ]
      },
      {
        "avg_logprob": -0.21433958715322066,
        "compression_ratio": 1.694915254237288,
        "end": 29.84,
        "id": 11,
        "no_speech_prob": 0.000016442418200313114,
        "seek": 2756,
        "start": 27.56,
        "temperature": 0,
        "text": " And this is going to drastically change",
        "tokens": [
          50364,
          400,
          341,
          307,
          516,
          281,
          29673,
          1319,
          50478
        ]
      },
      {
        "avg_logprob": -0.21433958715322066,
        "compression_ratio": 1.694915254237288,
        "end": 34.64,
        "id": 12,
        "no_speech_prob": 0.000016442418200313114,
        "seek": 2756,
        "start": 29.84,
        "temperature": 0,
        "text": " what the neural network outputs and how I use that output.",
        "tokens": [
          50478,
          437,
          264,
          18161,
          3209,
          23930,
          293,
          577,
          286,
          764,
          300,
          5598,
          13,
          50718
        ]
      },
      {
        "avg_logprob": -0.21433958715322066,
        "compression_ratio": 1.694915254237288,
        "end": 37.7,
        "id": 13,
        "no_speech_prob": 0.000016442418200313114,
        "seek": 2756,
        "start": 34.64,
        "temperature": 0,
        "text": " But before I start changing anything else in the code,",
        "tokens": [
          50718,
          583,
          949,
          286,
          722,
          4473,
          1340,
          1646,
          294,
          264,
          3089,
          11,
          50871
        ]
      },
      {
        "avg_logprob": -0.21433958715322066,
        "compression_ratio": 1.694915254237288,
        "end": 42.32,
        "id": 14,
        "no_speech_prob": 0.000016442418200313114,
        "seek": 2756,
        "start": 37.7,
        "temperature": 0,
        "text": " let me talk about what I mean by regression in the context",
        "tokens": [
          50871,
          718,
          385,
          751,
          466,
          437,
          286,
          914,
          538,
          24590,
          294,
          264,
          4319,
          51102
        ]
      },
      {
        "avg_logprob": -0.21433958715322066,
        "compression_ratio": 1.694915254237288,
        "end": 43.879999999999995,
        "id": 15,
        "no_speech_prob": 0.000016442418200313114,
        "seek": 2756,
        "start": 42.32,
        "temperature": 0,
        "text": " of machine learning.",
        "tokens": [
          51102,
          295,
          3479,
          2539,
          13,
          51180
        ]
      },
      {
        "avg_logprob": -0.21433958715322066,
        "compression_ratio": 1.694915254237288,
        "end": 48.4,
        "id": 16,
        "no_speech_prob": 0.000016442418200313114,
        "seek": 2756,
        "start": 43.879999999999995,
        "temperature": 0,
        "text": " First, let's recap classification.",
        "tokens": [
          51180,
          2386,
          11,
          718,
          311,
          20928,
          21538,
          13,
          51406
        ]
      },
      {
        "avg_logprob": -0.21433958715322066,
        "compression_ratio": 1.694915254237288,
        "end": 50.56,
        "id": 17,
        "no_speech_prob": 0.000016442418200313114,
        "seek": 2756,
        "start": 48.4,
        "temperature": 0,
        "text": " The idea of classification is that the neural network",
        "tokens": [
          51406,
          440,
          1558,
          295,
          21538,
          307,
          300,
          264,
          18161,
          3209,
          51514
        ]
      },
      {
        "avg_logprob": -0.21433958715322066,
        "compression_ratio": 1.694915254237288,
        "end": 53.44,
        "id": 18,
        "no_speech_prob": 0.000016442418200313114,
        "seek": 2756,
        "start": 50.56,
        "temperature": 0,
        "text": " is going to receive some input and end up",
        "tokens": [
          51514,
          307,
          516,
          281,
          4774,
          512,
          4846,
          293,
          917,
          493,
          51658
        ]
      },
      {
        "avg_logprob": -0.21433958715322066,
        "compression_ratio": 1.694915254237288,
        "end": 56,
        "id": 19,
        "no_speech_prob": 0.000016442418200313114,
        "seek": 2756,
        "start": 53.44,
        "temperature": 0,
        "text": " with a discrete categorical output,",
        "tokens": [
          51658,
          365,
          257,
          27706,
          19250,
          804,
          5598,
          11,
          51786
        ]
      },
      {
        "avg_logprob": -0.22337297712053572,
        "compression_ratio": 1.6779661016949152,
        "end": 61.64,
        "id": 20,
        "no_speech_prob": 0.000005682421488018008,
        "seek": 5600,
        "start": 56,
        "temperature": 0,
        "text": " meaning it's going to assign a label, C, D, or E.",
        "tokens": [
          50364,
          3620,
          309,
          311,
          516,
          281,
          6269,
          257,
          7645,
          11,
          383,
          11,
          413,
          11,
          420,
          462,
          13,
          50646
        ]
      },
      {
        "avg_logprob": -0.22337297712053572,
        "compression_ratio": 1.6779661016949152,
        "end": 63.88,
        "id": 21,
        "no_speech_prob": 0.000005682421488018008,
        "seek": 5600,
        "start": 61.64,
        "temperature": 0,
        "text": " We can think of that as there's three light bulbs.",
        "tokens": [
          50646,
          492,
          393,
          519,
          295,
          300,
          382,
          456,
          311,
          1045,
          1442,
          32871,
          13,
          50758
        ]
      },
      {
        "avg_logprob": -0.22337297712053572,
        "compression_ratio": 1.6779661016949152,
        "end": 70.52,
        "id": 22,
        "no_speech_prob": 0.000005682421488018008,
        "seek": 5600,
        "start": 67.48,
        "temperature": 0,
        "text": " Are those like little drawings of light bulbs?",
        "tokens": [
          50938,
          2014,
          729,
          411,
          707,
          18618,
          295,
          1442,
          32871,
          30,
          51090
        ]
      },
      {
        "avg_logprob": -0.22337297712053572,
        "compression_ratio": 1.6779661016949152,
        "end": 73.16,
        "id": 23,
        "no_speech_prob": 0.000005682421488018008,
        "seek": 5600,
        "start": 70.52,
        "temperature": 0,
        "text": " Each light bulb is associated with one",
        "tokens": [
          51090,
          6947,
          1442,
          21122,
          307,
          6615,
          365,
          472,
          51222
        ]
      },
      {
        "avg_logprob": -0.22337297712053572,
        "compression_ratio": 1.6779661016949152,
        "end": 76.76,
        "id": 24,
        "no_speech_prob": 0.000005682421488018008,
        "seek": 5600,
        "start": 73.16,
        "temperature": 0,
        "text": " of the possible labels or categories, classifications.",
        "tokens": [
          51222,
          295,
          264,
          1944,
          16949,
          420,
          10479,
          11,
          1508,
          7833,
          13,
          51402
        ]
      },
      {
        "avg_logprob": -0.22337297712053572,
        "compression_ratio": 1.6779661016949152,
        "end": 78.28,
        "id": 25,
        "no_speech_prob": 0.000005682421488018008,
        "seek": 5600,
        "start": 76.76,
        "temperature": 0,
        "text": " And if the neural network decides",
        "tokens": [
          51402,
          400,
          498,
          264,
          18161,
          3209,
          14898,
          51478
        ]
      },
      {
        "avg_logprob": -0.22337297712053572,
        "compression_ratio": 1.6779661016949152,
        "end": 81.68,
        "id": 26,
        "no_speech_prob": 0.000005682421488018008,
        "seek": 5600,
        "start": 78.28,
        "temperature": 0,
        "text": " that this particular input corresponds to the label E,",
        "tokens": [
          51478,
          300,
          341,
          1729,
          4846,
          23249,
          281,
          264,
          7645,
          462,
          11,
          51648
        ]
      },
      {
        "avg_logprob": -0.22337297712053572,
        "compression_ratio": 1.6779661016949152,
        "end": 84.08,
        "id": 27,
        "no_speech_prob": 0.000005682421488018008,
        "seek": 5600,
        "start": 81.68,
        "temperature": 0,
        "text": " then maybe this light bulb would light up.",
        "tokens": [
          51648,
          550,
          1310,
          341,
          1442,
          21122,
          576,
          1442,
          493,
          13,
          51768
        ]
      },
      {
        "avg_logprob": -0.22337297712053572,
        "compression_ratio": 1.6779661016949152,
        "end": 85.08,
        "id": 28,
        "no_speech_prob": 0.000005682421488018008,
        "seek": 5600,
        "start": 84.08,
        "temperature": 0,
        "text": " And you could do this.",
        "tokens": [
          51768,
          400,
          291,
          727,
          360,
          341,
          13,
          51818
        ]
      },
      {
        "avg_logprob": -0.2088084654374556,
        "compression_ratio": 1.5669642857142858,
        "end": 87.12,
        "id": 29,
        "no_speech_prob": 0.00001922315095725935,
        "seek": 8508,
        "start": 85.08,
        "temperature": 0,
        "text": " You could build an Arduino with some LEDs",
        "tokens": [
          50364,
          509,
          727,
          1322,
          364,
          39539,
          365,
          512,
          33366,
          50466
        ]
      },
      {
        "avg_logprob": -0.2088084654374556,
        "compression_ratio": 1.5669642857142858,
        "end": 90.75999999999999,
        "id": 30,
        "no_speech_prob": 0.00001922315095725935,
        "seek": 8508,
        "start": 87.12,
        "temperature": 0,
        "text": " and have the results of machine learning classification",
        "tokens": [
          50466,
          293,
          362,
          264,
          3542,
          295,
          3479,
          2539,
          21538,
          50648
        ]
      },
      {
        "avg_logprob": -0.2088084654374556,
        "compression_ratio": 1.5669642857142858,
        "end": 93.16,
        "id": 31,
        "no_speech_prob": 0.00001922315095725935,
        "seek": 8508,
        "start": 90.75999999999999,
        "temperature": 0,
        "text": " light up a particular LED.",
        "tokens": [
          50648,
          1442,
          493,
          257,
          1729,
          11261,
          13,
          50768
        ]
      },
      {
        "avg_logprob": -0.2088084654374556,
        "compression_ratio": 1.5669642857142858,
        "end": 95.28,
        "id": 32,
        "no_speech_prob": 0.00001922315095725935,
        "seek": 8508,
        "start": 93.16,
        "temperature": 0,
        "text": " A regression, you could think of the output",
        "tokens": [
          50768,
          316,
          24590,
          11,
          291,
          727,
          519,
          295,
          264,
          5598,
          50874
        ]
      },
      {
        "avg_logprob": -0.2088084654374556,
        "compression_ratio": 1.5669642857142858,
        "end": 97.28,
        "id": 33,
        "no_speech_prob": 0.00001922315095725935,
        "seek": 8508,
        "start": 95.28,
        "temperature": 0,
        "text": " being a slider or maybe a dial.",
        "tokens": [
          50874,
          885,
          257,
          26046,
          420,
          1310,
          257,
          5502,
          13,
          50974
        ]
      },
      {
        "avg_logprob": -0.2088084654374556,
        "compression_ratio": 1.5669642857142858,
        "end": 102.08,
        "id": 34,
        "no_speech_prob": 0.00001922315095725935,
        "seek": 8508,
        "start": 99.82,
        "temperature": 0,
        "text": " As the data comes into the neural network,",
        "tokens": [
          51101,
          1018,
          264,
          1412,
          1487,
          666,
          264,
          18161,
          3209,
          11,
          51214
        ]
      },
      {
        "avg_logprob": -0.2088084654374556,
        "compression_ratio": 1.5669642857142858,
        "end": 106.48,
        "id": 35,
        "no_speech_prob": 0.00001922315095725935,
        "seek": 8508,
        "start": 102.08,
        "temperature": 0,
        "text": " the dial ends up at some value between some minimum",
        "tokens": [
          51214,
          264,
          5502,
          5314,
          493,
          412,
          512,
          2158,
          1296,
          512,
          7285,
          51434
        ]
      },
      {
        "avg_logprob": -0.2088084654374556,
        "compression_ratio": 1.5669642857142858,
        "end": 107.68,
        "id": 36,
        "no_speech_prob": 0.00001922315095725935,
        "seek": 8508,
        "start": 106.48,
        "temperature": 0,
        "text": " and maximum.",
        "tokens": [
          51434,
          293,
          6674,
          13,
          51494
        ]
      },
      {
        "avg_logprob": -0.2088084654374556,
        "compression_ratio": 1.5669642857142858,
        "end": 111.03999999999999,
        "id": 37,
        "no_speech_prob": 0.00001922315095725935,
        "seek": 8508,
        "start": 107.68,
        "temperature": 0,
        "text": " The output is numerical continuous output.",
        "tokens": [
          51494,
          440,
          5598,
          307,
          29054,
          10957,
          5598,
          13,
          51662
        ]
      },
      {
        "avg_logprob": -0.17822944724952783,
        "compression_ratio": 1.695852534562212,
        "end": 117.12,
        "id": 38,
        "no_speech_prob": 0.000053075029427418485,
        "seek": 11104,
        "start": 111.04,
        "temperature": 0,
        "text": " So classification is one of a discrete set of possibilities.",
        "tokens": [
          50364,
          407,
          21538,
          307,
          472,
          295,
          257,
          27706,
          992,
          295,
          12178,
          13,
          50668
        ]
      },
      {
        "avg_logprob": -0.17822944724952783,
        "compression_ratio": 1.695852534562212,
        "end": 122.16000000000001,
        "id": 39,
        "no_speech_prob": 0.000053075029427418485,
        "seek": 11104,
        "start": 117.12,
        "temperature": 0,
        "text": " And regression is any value between a given range.",
        "tokens": [
          50668,
          400,
          24590,
          307,
          604,
          2158,
          1296,
          257,
          2212,
          3613,
          13,
          50920
        ]
      },
      {
        "avg_logprob": -0.17822944724952783,
        "compression_ratio": 1.695852534562212,
        "end": 124.88000000000001,
        "id": 40,
        "no_speech_prob": 0.000053075029427418485,
        "seek": 11104,
        "start": 122.16000000000001,
        "temperature": 0,
        "text": " Now, you can still have multiple outputs in a regression",
        "tokens": [
          50920,
          823,
          11,
          291,
          393,
          920,
          362,
          3866,
          23930,
          294,
          257,
          24590,
          51056
        ]
      },
      {
        "avg_logprob": -0.17822944724952783,
        "compression_ratio": 1.695852534562212,
        "end": 128.12,
        "id": 41,
        "no_speech_prob": 0.000053075029427418485,
        "seek": 11104,
        "start": 124.88000000000001,
        "temperature": 0,
        "text": " because you can have multiple continuous values.",
        "tokens": [
          51056,
          570,
          291,
          393,
          362,
          3866,
          10957,
          4190,
          13,
          51218
        ]
      },
      {
        "avg_logprob": -0.17822944724952783,
        "compression_ratio": 1.695852534562212,
        "end": 131.8,
        "id": 42,
        "no_speech_prob": 0.000053075029427418485,
        "seek": 11104,
        "start": 128.12,
        "temperature": 0,
        "text": " But in this case, I want to redo this example",
        "tokens": [
          51218,
          583,
          294,
          341,
          1389,
          11,
          286,
          528,
          281,
          29956,
          341,
          1365,
          51402
        ]
      },
      {
        "avg_logprob": -0.17822944724952783,
        "compression_ratio": 1.695852534562212,
        "end": 134.56,
        "id": 43,
        "no_speech_prob": 0.000053075029427418485,
        "seek": 11104,
        "start": 131.8,
        "temperature": 0,
        "text": " by having a single output and that output",
        "tokens": [
          51402,
          538,
          1419,
          257,
          2167,
          5598,
          293,
          300,
          5598,
          51540
        ]
      },
      {
        "avg_logprob": -0.17822944724952783,
        "compression_ratio": 1.695852534562212,
        "end": 136.56,
        "id": 44,
        "no_speech_prob": 0.000053075029427418485,
        "seek": 11104,
        "start": 134.56,
        "temperature": 0,
        "text": " be the frequency value.",
        "tokens": [
          51540,
          312,
          264,
          7893,
          2158,
          13,
          51640
        ]
      },
      {
        "avg_logprob": -0.17822944724952783,
        "compression_ratio": 1.695852534562212,
        "end": 139.48000000000002,
        "id": 45,
        "no_speech_prob": 0.000053075029427418485,
        "seek": 11104,
        "start": 136.56,
        "temperature": 0,
        "text": " So if I change the task to regression,",
        "tokens": [
          51640,
          407,
          498,
          286,
          1319,
          264,
          5633,
          281,
          24590,
          11,
          51786
        ]
      },
      {
        "avg_logprob": -0.19441531499226888,
        "compression_ratio": 1.774468085106383,
        "end": 143.16,
        "id": 46,
        "no_speech_prob": 0.00008481085387757048,
        "seek": 13948,
        "start": 139.48,
        "temperature": 0,
        "text": " now I want my output to be tied to a frequency.",
        "tokens": [
          50364,
          586,
          286,
          528,
          452,
          5598,
          281,
          312,
          9601,
          281,
          257,
          7893,
          13,
          50548
        ]
      },
      {
        "avg_logprob": -0.19441531499226888,
        "compression_ratio": 1.774468085106383,
        "end": 145.51999999999998,
        "id": 47,
        "no_speech_prob": 0.00008481085387757048,
        "seek": 13948,
        "start": 143.16,
        "temperature": 0,
        "text": " No longer do I want during the training process",
        "tokens": [
          50548,
          883,
          2854,
          360,
          286,
          528,
          1830,
          264,
          3097,
          1399,
          50666
        ]
      },
      {
        "avg_logprob": -0.19441531499226888,
        "compression_ratio": 1.774468085106383,
        "end": 146.95999999999998,
        "id": 48,
        "no_speech_prob": 0.00008481085387757048,
        "seek": 13948,
        "start": 145.51999999999998,
        "temperature": 0,
        "text": " to give target labels.",
        "tokens": [
          50666,
          281,
          976,
          3779,
          16949,
          13,
          50738
        ]
      },
      {
        "avg_logprob": -0.19441531499226888,
        "compression_ratio": 1.774468085106383,
        "end": 148.95999999999998,
        "id": 49,
        "no_speech_prob": 0.00008481085387757048,
        "seek": 13948,
        "start": 146.95999999999998,
        "temperature": 0,
        "text": " I want to give target numbers so that it",
        "tokens": [
          50738,
          286,
          528,
          281,
          976,
          3779,
          3547,
          370,
          300,
          309,
          50838
        ]
      },
      {
        "avg_logprob": -0.19441531499226888,
        "compression_ratio": 1.774468085106383,
        "end": 152.39999999999998,
        "id": 50,
        "no_speech_prob": 0.00008481085387757048,
        "seek": 13948,
        "start": 148.95999999999998,
        "temperature": 0,
        "text": " will guess a number as part of the regression output.",
        "tokens": [
          50838,
          486,
          2041,
          257,
          1230,
          382,
          644,
          295,
          264,
          24590,
          5598,
          13,
          51010
        ]
      },
      {
        "avg_logprob": -0.19441531499226888,
        "compression_ratio": 1.774468085106383,
        "end": 154.51999999999998,
        "id": 51,
        "no_speech_prob": 0.00008481085387757048,
        "seek": 13948,
        "start": 152.39999999999998,
        "temperature": 0,
        "text": " So this is my code for data collection.",
        "tokens": [
          51010,
          407,
          341,
          307,
          452,
          3089,
          337,
          1412,
          5765,
          13,
          51116
        ]
      },
      {
        "avg_logprob": -0.19441531499226888,
        "compression_ratio": 1.774468085106383,
        "end": 157.35999999999999,
        "id": 52,
        "no_speech_prob": 0.00008481085387757048,
        "seek": 13948,
        "start": 154.51999999999998,
        "temperature": 0,
        "text": " When I click the mouse, the inputs are an x and y.",
        "tokens": [
          51116,
          1133,
          286,
          2052,
          264,
          9719,
          11,
          264,
          15743,
          366,
          364,
          2031,
          293,
          288,
          13,
          51258
        ]
      },
      {
        "avg_logprob": -0.19441531499226888,
        "compression_ratio": 1.774468085106383,
        "end": 161,
        "id": 53,
        "no_speech_prob": 0.00008481085387757048,
        "seek": 13948,
        "start": 157.35999999999999,
        "temperature": 0,
        "text": " And the target is a target label.",
        "tokens": [
          51258,
          400,
          264,
          3779,
          307,
          257,
          3779,
          7645,
          13,
          51440
        ]
      },
      {
        "avg_logprob": -0.19441531499226888,
        "compression_ratio": 1.774468085106383,
        "end": 163.88,
        "id": 54,
        "no_speech_prob": 0.00008481085387757048,
        "seek": 13948,
        "start": 161,
        "temperature": 0,
        "text": " But I don't want it to be a target label anymore.",
        "tokens": [
          51440,
          583,
          286,
          500,
          380,
          528,
          309,
          281,
          312,
          257,
          3779,
          7645,
          3602,
          13,
          51584
        ]
      },
      {
        "avg_logprob": -0.19441531499226888,
        "compression_ratio": 1.774468085106383,
        "end": 166.39999999999998,
        "id": 55,
        "no_speech_prob": 0.00008481085387757048,
        "seek": 13948,
        "start": 163.88,
        "temperature": 0,
        "text": " I want it to be a frequency.",
        "tokens": [
          51584,
          286,
          528,
          309,
          281,
          312,
          257,
          7893,
          13,
          51710
        ]
      },
      {
        "avg_logprob": -0.23080584324827982,
        "compression_ratio": 1.6692607003891051,
        "end": 171.28,
        "id": 56,
        "no_speech_prob": 0.000060141355788800865,
        "seek": 16640,
        "start": 167.16,
        "temperature": 0,
        "text": " And I can figure out what that target frequency is",
        "tokens": [
          50402,
          400,
          286,
          393,
          2573,
          484,
          437,
          300,
          3779,
          7893,
          307,
          50608
        ]
      },
      {
        "avg_logprob": -0.23080584324827982,
        "compression_ratio": 1.6692607003891051,
        "end": 175.20000000000002,
        "id": 57,
        "no_speech_prob": 0.000060141355788800865,
        "seek": 16640,
        "start": 171.28,
        "temperature": 0,
        "text": " by looking it up in this particular JavaScript object.",
        "tokens": [
          50608,
          538,
          1237,
          309,
          493,
          294,
          341,
          1729,
          15778,
          2657,
          13,
          50804
        ]
      },
      {
        "avg_logprob": -0.23080584324827982,
        "compression_ratio": 1.6692607003891051,
        "end": 177.24,
        "id": 58,
        "no_speech_prob": 0.000060141355788800865,
        "seek": 16640,
        "start": 175.20000000000002,
        "temperature": 0,
        "text": " So I can say let target frequency",
        "tokens": [
          50804,
          407,
          286,
          393,
          584,
          718,
          3779,
          7893,
          50906
        ]
      },
      {
        "avg_logprob": -0.23080584324827982,
        "compression_ratio": 1.6692607003891051,
        "end": 180.48000000000002,
        "id": 59,
        "no_speech_prob": 0.000060141355788800865,
        "seek": 16640,
        "start": 177.24,
        "temperature": 0,
        "text": " equal notes target label.",
        "tokens": [
          50906,
          2681,
          5570,
          3779,
          7645,
          13,
          51068
        ]
      },
      {
        "avg_logprob": -0.23080584324827982,
        "compression_ratio": 1.6692607003891051,
        "end": 182.28,
        "id": 60,
        "no_speech_prob": 0.000060141355788800865,
        "seek": 16640,
        "start": 180.48000000000002,
        "temperature": 0,
        "text": " And in fact, that's something that I'm already",
        "tokens": [
          51068,
          400,
          294,
          1186,
          11,
          300,
          311,
          746,
          300,
          286,
          478,
          1217,
          51158
        ]
      },
      {
        "avg_logprob": -0.23080584324827982,
        "compression_ratio": 1.6692607003891051,
        "end": 183.44,
        "id": 61,
        "no_speech_prob": 0.000060141355788800865,
        "seek": 16640,
        "start": 182.28,
        "temperature": 0,
        "text": " doing down here.",
        "tokens": [
          51158,
          884,
          760,
          510,
          13,
          51216
        ]
      },
      {
        "avg_logprob": -0.23080584324827982,
        "compression_ratio": 1.6692607003891051,
        "end": 187.16,
        "id": 62,
        "no_speech_prob": 0.000060141355788800865,
        "seek": 16640,
        "start": 183.44,
        "temperature": 0,
        "text": " So let's replace this with target frequency.",
        "tokens": [
          51216,
          407,
          718,
          311,
          7406,
          341,
          365,
          3779,
          7893,
          13,
          51402
        ]
      },
      {
        "avg_logprob": -0.23080584324827982,
        "compression_ratio": 1.6692607003891051,
        "end": 189.8,
        "id": 63,
        "no_speech_prob": 0.000060141355788800865,
        "seek": 16640,
        "start": 187.16,
        "temperature": 0,
        "text": " Now, ordinarily, I might remove target label completely",
        "tokens": [
          51402,
          823,
          11,
          25376,
          3289,
          11,
          286,
          1062,
          4159,
          3779,
          7645,
          2584,
          51534
        ]
      },
      {
        "avg_logprob": -0.23080584324827982,
        "compression_ratio": 1.6692607003891051,
        "end": 191.32,
        "id": 64,
        "no_speech_prob": 0.000060141355788800865,
        "seek": 16640,
        "start": 189.8,
        "temperature": 0,
        "text": " as a variable in the system because I",
        "tokens": [
          51534,
          382,
          257,
          7006,
          294,
          264,
          1185,
          570,
          286,
          51610
        ]
      },
      {
        "avg_logprob": -0.23080584324827982,
        "compression_ratio": 1.6692607003891051,
        "end": 193.92000000000002,
        "id": 65,
        "no_speech_prob": 0.000060141355788800865,
        "seek": 16640,
        "start": 191.32,
        "temperature": 0,
        "text": " don't need the label anymore for the machine learning model.",
        "tokens": [
          51610,
          500,
          380,
          643,
          264,
          7645,
          3602,
          337,
          264,
          3479,
          2539,
          2316,
          13,
          51740
        ]
      },
      {
        "avg_logprob": -0.23450437273297992,
        "compression_ratio": 1.6930232558139535,
        "end": 195.67999999999998,
        "id": 66,
        "no_speech_prob": 0.00010889629629673436,
        "seek": 19392,
        "start": 193.92,
        "temperature": 0,
        "text": " I'm not using CDE.",
        "tokens": [
          50364,
          286,
          478,
          406,
          1228,
          6743,
          36,
          13,
          50452
        ]
      },
      {
        "avg_logprob": -0.23450437273297992,
        "compression_ratio": 1.6930232558139535,
        "end": 199.39999999999998,
        "id": 67,
        "no_speech_prob": 0.00010889629629673436,
        "seek": 19392,
        "start": 195.67999999999998,
        "temperature": 0,
        "text": " I'm not using the note name for training the model.",
        "tokens": [
          50452,
          286,
          478,
          406,
          1228,
          264,
          3637,
          1315,
          337,
          3097,
          264,
          2316,
          13,
          50638
        ]
      },
      {
        "avg_logprob": -0.23450437273297992,
        "compression_ratio": 1.6930232558139535,
        "end": 202.56,
        "id": 68,
        "no_speech_prob": 0.00010889629629673436,
        "seek": 19392,
        "start": 199.39999999999998,
        "temperature": 0,
        "text": " But while I'm collecting the data,",
        "tokens": [
          50638,
          583,
          1339,
          286,
          478,
          12510,
          264,
          1412,
          11,
          50796
        ]
      },
      {
        "avg_logprob": -0.23450437273297992,
        "compression_ratio": 1.6930232558139535,
        "end": 207.48,
        "id": 69,
        "no_speech_prob": 0.00010889629629673436,
        "seek": 19392,
        "start": 202.56,
        "temperature": 0,
        "text": " I still would like to see the note C or A or G",
        "tokens": [
          50796,
          286,
          920,
          576,
          411,
          281,
          536,
          264,
          3637,
          383,
          420,
          316,
          420,
          460,
          51042
        ]
      },
      {
        "avg_logprob": -0.23450437273297992,
        "compression_ratio": 1.6930232558139535,
        "end": 209.39999999999998,
        "id": 70,
        "no_speech_prob": 0.00010889629629673436,
        "seek": 19392,
        "start": 207.48,
        "temperature": 0,
        "text": " because I think that's less awkward than drawing",
        "tokens": [
          51042,
          570,
          286,
          519,
          300,
          311,
          1570,
          11411,
          813,
          6316,
          51138
        ]
      },
      {
        "avg_logprob": -0.23450437273297992,
        "compression_ratio": 1.6930232558139535,
        "end": 212.16,
        "id": 71,
        "no_speech_prob": 0.00010889629629673436,
        "seek": 19392,
        "start": 209.39999999999998,
        "temperature": 0,
        "text": " the frequency number in the window.",
        "tokens": [
          51138,
          264,
          7893,
          1230,
          294,
          264,
          4910,
          13,
          51276
        ]
      },
      {
        "avg_logprob": -0.23450437273297992,
        "compression_ratio": 1.6930232558139535,
        "end": 216.51999999999998,
        "id": 72,
        "no_speech_prob": 0.00010889629629673436,
        "seek": 19392,
        "start": 212.16,
        "temperature": 0,
        "text": " So crazily, I think I'm actually done with all",
        "tokens": [
          51276,
          407,
          46348,
          953,
          11,
          286,
          519,
          286,
          478,
          767,
          1096,
          365,
          439,
          51494
        ]
      },
      {
        "avg_logprob": -0.23450437273297992,
        "compression_ratio": 1.6930232558139535,
        "end": 218.44,
        "id": 73,
        "no_speech_prob": 0.00010889629629673436,
        "seek": 19392,
        "start": 216.51999999999998,
        "temperature": 0,
        "text": " that I need for the first two steps.",
        "tokens": [
          51494,
          300,
          286,
          643,
          337,
          264,
          700,
          732,
          4439,
          13,
          51590
        ]
      },
      {
        "avg_logprob": -0.23450437273297992,
        "compression_ratio": 1.6930232558139535,
        "end": 223.39999999999998,
        "id": 74,
        "no_speech_prob": 0.00010889629629673436,
        "seek": 19392,
        "start": 221.39999999999998,
        "temperature": 0,
        "text": " The first two steps being collect the data",
        "tokens": [
          51738,
          440,
          700,
          732,
          4439,
          885,
          2500,
          264,
          1412,
          51838
        ]
      },
      {
        "avg_logprob": -0.26144282671870017,
        "compression_ratio": 1.6875,
        "end": 224.28,
        "id": 75,
        "no_speech_prob": 0.00007141877722460777,
        "seek": 22340,
        "start": 223.4,
        "temperature": 0,
        "text": " and train the model.",
        "tokens": [
          50364,
          293,
          3847,
          264,
          2316,
          13,
          50408
        ]
      },
      {
        "avg_logprob": -0.26144282671870017,
        "compression_ratio": 1.6875,
        "end": 226.20000000000002,
        "id": 76,
        "no_speech_prob": 0.00007141877722460777,
        "seek": 22340,
        "start": 224.28,
        "temperature": 0,
        "text": " I've changed the task to regression.",
        "tokens": [
          50408,
          286,
          600,
          3105,
          264,
          5633,
          281,
          24590,
          13,
          50504
        ]
      },
      {
        "avg_logprob": -0.26144282671870017,
        "compression_ratio": 1.6875,
        "end": 234.52,
        "id": 77,
        "no_speech_prob": 0.00007141877722460777,
        "seek": 22340,
        "start": 226.20000000000002,
        "temperature": 0,
        "text": " And now I've changed the output to a single output node that",
        "tokens": [
          50504,
          400,
          586,
          286,
          600,
          3105,
          264,
          5598,
          281,
          257,
          2167,
          5598,
          9984,
          300,
          50920
        ]
      },
      {
        "avg_logprob": -0.26144282671870017,
        "compression_ratio": 1.6875,
        "end": 236.64000000000001,
        "id": 78,
        "no_speech_prob": 0.00007141877722460777,
        "seek": 22340,
        "start": 234.52,
        "temperature": 0,
        "text": " just has a frequency value.",
        "tokens": [
          50920,
          445,
          575,
          257,
          7893,
          2158,
          13,
          51026
        ]
      },
      {
        "avg_logprob": -0.26144282671870017,
        "compression_ratio": 1.6875,
        "end": 239.68,
        "id": 79,
        "no_speech_prob": 0.00007141877722460777,
        "seek": 22340,
        "start": 236.64000000000001,
        "temperature": 0,
        "text": " So I should be able to run all of the bits of code",
        "tokens": [
          51026,
          407,
          286,
          820,
          312,
          1075,
          281,
          1190,
          439,
          295,
          264,
          9239,
          295,
          3089,
          51178
        ]
      },
      {
        "avg_logprob": -0.26144282671870017,
        "compression_ratio": 1.6875,
        "end": 241.88,
        "id": 80,
        "no_speech_prob": 0.00007141877722460777,
        "seek": 22340,
        "start": 239.68,
        "temperature": 0,
        "text": " that I did before and have it train the model.",
        "tokens": [
          51178,
          300,
          286,
          630,
          949,
          293,
          362,
          309,
          3847,
          264,
          2316,
          13,
          51288
        ]
      },
      {
        "avg_logprob": -0.26144282671870017,
        "compression_ratio": 1.6875,
        "end": 242.84,
        "id": 81,
        "no_speech_prob": 0.00007141877722460777,
        "seek": 22340,
        "start": 241.88,
        "temperature": 0,
        "text": " Let's see if that works.",
        "tokens": [
          51288,
          961,
          311,
          536,
          498,
          300,
          1985,
          13,
          51336
        ]
      },
      {
        "avg_logprob": -0.26144282671870017,
        "compression_ratio": 1.6875,
        "end": 248.6,
        "id": 82,
        "no_speech_prob": 0.00007141877722460777,
        "seek": 22340,
        "start": 242.84,
        "temperature": 0,
        "text": " All right.",
        "tokens": [
          51336,
          1057,
          558,
          13,
          51624
        ]
      },
      {
        "avg_logprob": -0.26144282671870017,
        "compression_ratio": 1.6875,
        "end": 249.44,
        "id": 83,
        "no_speech_prob": 0.00007141877722460777,
        "seek": 22340,
        "start": 248.6,
        "temperature": 0,
        "text": " Collected some data.",
        "tokens": [
          51624,
          31896,
          292,
          512,
          1412,
          13,
          51666
        ]
      },
      {
        "avg_logprob": -0.26144282671870017,
        "compression_ratio": 1.6875,
        "end": 250.36,
        "id": 84,
        "no_speech_prob": 0.00007141877722460777,
        "seek": 22340,
        "start": 249.44,
        "temperature": 0,
        "text": " Let's train the model.",
        "tokens": [
          51666,
          961,
          311,
          3847,
          264,
          2316,
          13,
          51712
        ]
      },
      {
        "avg_logprob": -0.22085626157995772,
        "compression_ratio": 1.7025316455696202,
        "end": 254.24,
        "id": 85,
        "no_speech_prob": 0.00006302742258412763,
        "seek": 25340,
        "start": 253.52,
        "temperature": 0,
        "text": " And it worked.",
        "tokens": [
          50370,
          400,
          309,
          2732,
          13,
          50406
        ]
      },
      {
        "avg_logprob": -0.22085626157995772,
        "compression_ratio": 1.7025316455696202,
        "end": 255.84,
        "id": 86,
        "no_speech_prob": 0.00006302742258412763,
        "seek": 25340,
        "start": 254.24,
        "temperature": 0,
        "text": " I mean, it worked in the sense that I",
        "tokens": [
          50406,
          286,
          914,
          11,
          309,
          2732,
          294,
          264,
          2020,
          300,
          286,
          50486
        ]
      },
      {
        "avg_logprob": -0.22085626157995772,
        "compression_ratio": 1.7025316455696202,
        "end": 257.6,
        "id": 87,
        "no_speech_prob": 0.00006302742258412763,
        "seek": 25340,
        "start": 255.84,
        "temperature": 0,
        "text": " don't see any errors in the console.",
        "tokens": [
          50486,
          500,
          380,
          536,
          604,
          13603,
          294,
          264,
          11076,
          13,
          50574
        ]
      },
      {
        "avg_logprob": -0.22085626157995772,
        "compression_ratio": 1.7025316455696202,
        "end": 260.12,
        "id": 88,
        "no_speech_prob": 0.00006302742258412763,
        "seek": 25340,
        "start": 257.6,
        "temperature": 0,
        "text": " And I see a nice graph with the loss going all the way down.",
        "tokens": [
          50574,
          400,
          286,
          536,
          257,
          1481,
          4295,
          365,
          264,
          4470,
          516,
          439,
          264,
          636,
          760,
          13,
          50700
        ]
      },
      {
        "avg_logprob": -0.22085626157995772,
        "compression_ratio": 1.7025316455696202,
        "end": 263.24,
        "id": 89,
        "no_speech_prob": 0.00006302742258412763,
        "seek": 25340,
        "start": 260.12,
        "temperature": 0,
        "text": " Incidentally, the loss went way down very, very quickly.",
        "tokens": [
          50700,
          7779,
          36578,
          11,
          264,
          4470,
          1437,
          636,
          760,
          588,
          11,
          588,
          2661,
          13,
          50856
        ]
      },
      {
        "avg_logprob": -0.22085626157995772,
        "compression_ratio": 1.7025316455696202,
        "end": 265.2,
        "id": 90,
        "no_speech_prob": 0.00006302742258412763,
        "seek": 25340,
        "start": 263.24,
        "temperature": 0,
        "text": " So I probably don't need 200 epochs.",
        "tokens": [
          50856,
          407,
          286,
          1391,
          500,
          380,
          643,
          2331,
          30992,
          28346,
          13,
          50954
        ]
      },
      {
        "avg_logprob": -0.22085626157995772,
        "compression_ratio": 1.7025316455696202,
        "end": 267.64,
        "id": 91,
        "no_speech_prob": 0.00006302742258412763,
        "seek": 25340,
        "start": 265.2,
        "temperature": 0,
        "text": " Maybe this regression problem was a little bit easier",
        "tokens": [
          50954,
          2704,
          341,
          24590,
          1154,
          390,
          257,
          707,
          857,
          3571,
          51076
        ]
      },
      {
        "avg_logprob": -0.22085626157995772,
        "compression_ratio": 1.7025316455696202,
        "end": 269,
        "id": 92,
        "no_speech_prob": 0.00006302742258412763,
        "seek": 25340,
        "start": 267.64,
        "temperature": 0,
        "text": " for it to learn more accurately.",
        "tokens": [
          51076,
          337,
          309,
          281,
          1466,
          544,
          20095,
          13,
          51144
        ]
      },
      {
        "avg_logprob": -0.22085626157995772,
        "compression_ratio": 1.7025316455696202,
        "end": 269.52,
        "id": 93,
        "no_speech_prob": 0.00006302742258412763,
        "seek": 25340,
        "start": 269,
        "temperature": 0,
        "text": " Who knows?",
        "tokens": [
          51144,
          2102,
          3255,
          30,
          51170
        ]
      },
      {
        "avg_logprob": -0.22085626157995772,
        "compression_ratio": 1.7025316455696202,
        "end": 271.44,
        "id": 94,
        "no_speech_prob": 0.00006302742258412763,
        "seek": 25340,
        "start": 269.52,
        "temperature": 0,
        "text": " But it optimized very quickly.",
        "tokens": [
          51170,
          583,
          309,
          26941,
          588,
          2661,
          13,
          51266
        ]
      },
      {
        "avg_logprob": -0.22085626157995772,
        "compression_ratio": 1.7025316455696202,
        "end": 275.2,
        "id": 95,
        "no_speech_prob": 0.00006302742258412763,
        "seek": 25340,
        "start": 271.44,
        "temperature": 0,
        "text": " So now that collecting data and training the model is done,",
        "tokens": [
          51266,
          407,
          586,
          300,
          12510,
          1412,
          293,
          3097,
          264,
          2316,
          307,
          1096,
          11,
          51454
        ]
      },
      {
        "avg_logprob": -0.22085626157995772,
        "compression_ratio": 1.7025316455696202,
        "end": 278.64,
        "id": 96,
        "no_speech_prob": 0.00006302742258412763,
        "seek": 25340,
        "start": 275.2,
        "temperature": 0,
        "text": " I need to just do that last stage of basically deploying",
        "tokens": [
          51454,
          286,
          643,
          281,
          445,
          360,
          300,
          1036,
          3233,
          295,
          1936,
          34198,
          51626
        ]
      },
      {
        "avg_logprob": -0.22085626157995772,
        "compression_ratio": 1.7025316455696202,
        "end": 282.6,
        "id": 97,
        "no_speech_prob": 0.00006302742258412763,
        "seek": 25340,
        "start": 278.64,
        "temperature": 0,
        "text": " the model and making predictions with new data.",
        "tokens": [
          51626,
          264,
          2316,
          293,
          1455,
          21264,
          365,
          777,
          1412,
          13,
          51824
        ]
      },
      {
        "avg_logprob": -0.24463232902631368,
        "compression_ratio": 1.702970297029703,
        "end": 284.52000000000004,
        "id": 98,
        "no_speech_prob": 0.00004539775909506716,
        "seek": 28260,
        "start": 282.6,
        "temperature": 0,
        "text": " And I don't think this is going to work.",
        "tokens": [
          50364,
          400,
          286,
          500,
          380,
          519,
          341,
          307,
          516,
          281,
          589,
          13,
          50460
        ]
      },
      {
        "avg_logprob": -0.24463232902631368,
        "compression_ratio": 1.702970297029703,
        "end": 285.68,
        "id": 99,
        "no_speech_prob": 0.00004539775909506716,
        "seek": 28260,
        "start": 284.52000000000004,
        "temperature": 0,
        "text": " I haven't adjusted the code at all.",
        "tokens": [
          50460,
          286,
          2378,
          380,
          19871,
          264,
          3089,
          412,
          439,
          13,
          50518
        ]
      },
      {
        "avg_logprob": -0.24463232902631368,
        "compression_ratio": 1.702970297029703,
        "end": 287.6,
        "id": 100,
        "no_speech_prob": 0.00004539775909506716,
        "seek": 28260,
        "start": 285.68,
        "temperature": 0,
        "text": " It's still looking for a label and all of that.",
        "tokens": [
          50518,
          467,
          311,
          920,
          1237,
          337,
          257,
          7645,
          293,
          439,
          295,
          300,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.24463232902631368,
        "compression_ratio": 1.702970297029703,
        "end": 288.84000000000003,
        "id": 101,
        "no_speech_prob": 0.00004539775909506716,
        "seek": 28260,
        "start": 287.6,
        "temperature": 0,
        "text": " So who knows what will happen?",
        "tokens": [
          50614,
          407,
          567,
          3255,
          437,
          486,
          1051,
          30,
          50676
        ]
      },
      {
        "avg_logprob": -0.24463232902631368,
        "compression_ratio": 1.702970297029703,
        "end": 292.8,
        "id": 102,
        "no_speech_prob": 0.00004539775909506716,
        "seek": 28260,
        "start": 288.84000000000003,
        "temperature": 0,
        "text": " You Yeah, it's just it's first of all,",
        "tokens": [
          50676,
          509,
          865,
          11,
          309,
          311,
          445,
          309,
          311,
          700,
          295,
          439,
          11,
          50874
        ]
      },
      {
        "avg_logprob": -0.24463232902631368,
        "compression_ratio": 1.702970297029703,
        "end": 295.04,
        "id": 103,
        "no_speech_prob": 0.00004539775909506716,
        "seek": 28260,
        "start": 292.8,
        "temperature": 0,
        "text": " it's writing the word frequency here and just",
        "tokens": [
          50874,
          309,
          311,
          3579,
          264,
          1349,
          7893,
          510,
          293,
          445,
          50986
        ]
      },
      {
        "avg_logprob": -0.24463232902631368,
        "compression_ratio": 1.702970297029703,
        "end": 296.52000000000004,
        "id": 104,
        "no_speech_prob": 0.00004539775909506716,
        "seek": 28260,
        "start": 295.04,
        "temperature": 0,
        "text": " playing one particular note.",
        "tokens": [
          50986,
          2433,
          472,
          1729,
          3637,
          13,
          51060
        ]
      },
      {
        "avg_logprob": -0.24463232902631368,
        "compression_ratio": 1.702970297029703,
        "end": 298.20000000000005,
        "id": 105,
        "no_speech_prob": 0.00004539775909506716,
        "seek": 28260,
        "start": 296.52000000000004,
        "temperature": 0,
        "text": " So let's go look at the prediction code",
        "tokens": [
          51060,
          407,
          718,
          311,
          352,
          574,
          412,
          264,
          17630,
          3089,
          51144
        ]
      },
      {
        "avg_logprob": -0.24463232902631368,
        "compression_ratio": 1.702970297029703,
        "end": 300.64000000000004,
        "id": 106,
        "no_speech_prob": 0.00004539775909506716,
        "seek": 28260,
        "start": 298.20000000000005,
        "temperature": 0,
        "text": " and see what we need to adjust for a regression.",
        "tokens": [
          51144,
          293,
          536,
          437,
          321,
          643,
          281,
          4369,
          337,
          257,
          24590,
          13,
          51266
        ]
      },
      {
        "avg_logprob": -0.24463232902631368,
        "compression_ratio": 1.702970297029703,
        "end": 304.36,
        "id": 107,
        "no_speech_prob": 0.00004539775909506716,
        "seek": 28260,
        "start": 300.64000000000004,
        "temperature": 0,
        "text": " First thing is because we're no longer doing classification,",
        "tokens": [
          51266,
          2386,
          551,
          307,
          570,
          321,
          434,
          572,
          2854,
          884,
          21538,
          11,
          51452
        ]
      },
      {
        "avg_logprob": -0.24463232902631368,
        "compression_ratio": 1.702970297029703,
        "end": 307.8,
        "id": 108,
        "no_speech_prob": 0.00004539775909506716,
        "seek": 28260,
        "start": 304.36,
        "temperature": 0,
        "text": " we shouldn't call model.classify with the given inputs.",
        "tokens": [
          51452,
          321,
          4659,
          380,
          818,
          2316,
          13,
          11665,
          2505,
          365,
          264,
          2212,
          15743,
          13,
          51624
        ]
      },
      {
        "avg_logprob": -0.24463232902631368,
        "compression_ratio": 1.702970297029703,
        "end": 310.32000000000005,
        "id": 109,
        "no_speech_prob": 0.00004539775909506716,
        "seek": 28260,
        "start": 307.8,
        "temperature": 0,
        "text": " We want to change this to model.predict.",
        "tokens": [
          51624,
          492,
          528,
          281,
          1319,
          341,
          281,
          2316,
          13,
          79,
          24945,
          13,
          51750
        ]
      },
      {
        "avg_logprob": -0.20481346067318246,
        "compression_ratio": 1.7416666666666667,
        "end": 312.68,
        "id": 110,
        "no_speech_prob": 0.0000039054798435245175,
        "seek": 31032,
        "start": 310.32,
        "temperature": 0,
        "text": " So predict is the function name for a regression,",
        "tokens": [
          50364,
          407,
          6069,
          307,
          264,
          2445,
          1315,
          337,
          257,
          24590,
          11,
          50482
        ]
      },
      {
        "avg_logprob": -0.20481346067318246,
        "compression_ratio": 1.7416666666666667,
        "end": 315.36,
        "id": 111,
        "no_speech_prob": 0.0000039054798435245175,
        "seek": 31032,
        "start": 312.68,
        "temperature": 0,
        "text": " classifies the function name for a classification.",
        "tokens": [
          50482,
          1508,
          11221,
          264,
          2445,
          1315,
          337,
          257,
          21538,
          13,
          50616
        ]
      },
      {
        "avg_logprob": -0.20481346067318246,
        "compression_ratio": 1.7416666666666667,
        "end": 317.71999999999997,
        "id": 112,
        "no_speech_prob": 0.0000039054798435245175,
        "seek": 31032,
        "start": 315.36,
        "temperature": 0,
        "text": " Let's collect data again and retrain the model.",
        "tokens": [
          50616,
          961,
          311,
          2500,
          1412,
          797,
          293,
          1533,
          7146,
          264,
          2316,
          13,
          50734
        ]
      },
      {
        "avg_logprob": -0.20481346067318246,
        "compression_ratio": 1.7416666666666667,
        "end": 322.64,
        "id": 113,
        "no_speech_prob": 0.0000039054798435245175,
        "seek": 31032,
        "start": 317.71999999999997,
        "temperature": 0,
        "text": " OK, it's trained.",
        "tokens": [
          50734,
          2264,
          11,
          309,
          311,
          8895,
          13,
          50980
        ]
      },
      {
        "avg_logprob": -0.20481346067318246,
        "compression_ratio": 1.7416666666666667,
        "end": 325.15999999999997,
        "id": 114,
        "no_speech_prob": 0.0000039054798435245175,
        "seek": 31032,
        "start": 322.64,
        "temperature": 0,
        "text": " Let me click into the canvas.",
        "tokens": [
          50980,
          961,
          385,
          2052,
          666,
          264,
          16267,
          13,
          51106
        ]
      },
      {
        "avg_logprob": -0.20481346067318246,
        "compression_ratio": 1.7416666666666667,
        "end": 329.12,
        "id": 115,
        "no_speech_prob": 0.0000039054798435245175,
        "seek": 31032,
        "start": 325.15999999999997,
        "temperature": 0,
        "text": " And let's look and see what came out here.",
        "tokens": [
          51106,
          400,
          718,
          311,
          574,
          293,
          536,
          437,
          1361,
          484,
          510,
          13,
          51304
        ]
      },
      {
        "avg_logprob": -0.20481346067318246,
        "compression_ratio": 1.7416666666666667,
        "end": 330.24,
        "id": 116,
        "no_speech_prob": 0.0000039054798435245175,
        "seek": 31032,
        "start": 329.12,
        "temperature": 0,
        "text": " So this is what I get back.",
        "tokens": [
          51304,
          407,
          341,
          307,
          437,
          286,
          483,
          646,
          13,
          51360
        ]
      },
      {
        "avg_logprob": -0.20481346067318246,
        "compression_ratio": 1.7416666666666667,
        "end": 331.56,
        "id": 117,
        "no_speech_prob": 0.0000039054798435245175,
        "seek": 31032,
        "start": 330.24,
        "temperature": 0,
        "text": " I get back an array.",
        "tokens": [
          51360,
          286,
          483,
          646,
          364,
          10225,
          13,
          51426
        ]
      },
      {
        "avg_logprob": -0.20481346067318246,
        "compression_ratio": 1.7416666666666667,
        "end": 334.84,
        "id": 118,
        "no_speech_prob": 0.0000039054798435245175,
        "seek": 31032,
        "start": 331.56,
        "temperature": 0,
        "text": " I only have one output in this particular model.",
        "tokens": [
          51426,
          286,
          787,
          362,
          472,
          5598,
          294,
          341,
          1729,
          2316,
          13,
          51590
        ]
      },
      {
        "avg_logprob": -0.20481346067318246,
        "compression_ratio": 1.7416666666666667,
        "end": 337.64,
        "id": 119,
        "no_speech_prob": 0.0000039054798435245175,
        "seek": 31032,
        "start": 334.84,
        "temperature": 0,
        "text": " And so I look at the zero element of that array.",
        "tokens": [
          51590,
          400,
          370,
          286,
          574,
          412,
          264,
          4018,
          4478,
          295,
          300,
          10225,
          13,
          51730
        ]
      },
      {
        "avg_logprob": -0.20481346067318246,
        "compression_ratio": 1.7416666666666667,
        "end": 338.96,
        "id": 120,
        "no_speech_prob": 0.0000039054798435245175,
        "seek": 31032,
        "start": 337.64,
        "temperature": 0,
        "text": " This is the value it predicted.",
        "tokens": [
          51730,
          639,
          307,
          264,
          2158,
          309,
          19147,
          13,
          51796
        ]
      },
      {
        "avg_logprob": -0.1991516675135886,
        "compression_ratio": 1.630188679245283,
        "end": 341.52,
        "id": 121,
        "no_speech_prob": 0.000033214164432138205,
        "seek": 33896,
        "start": 338.96,
        "temperature": 0,
        "text": " And I have a label that in case I had multiple things,",
        "tokens": [
          50364,
          400,
          286,
          362,
          257,
          7645,
          300,
          294,
          1389,
          286,
          632,
          3866,
          721,
          11,
          50492
        ]
      },
      {
        "avg_logprob": -0.1991516675135886,
        "compression_ratio": 1.630188679245283,
        "end": 343.68,
        "id": 122,
        "no_speech_prob": 0.000033214164432138205,
        "seek": 33896,
        "start": 341.52,
        "temperature": 0,
        "text": " I could know which goes with which.",
        "tokens": [
          50492,
          286,
          727,
          458,
          597,
          1709,
          365,
          597,
          13,
          50600
        ]
      },
      {
        "avg_logprob": -0.1991516675135886,
        "compression_ratio": 1.630188679245283,
        "end": 347.35999999999996,
        "id": 123,
        "no_speech_prob": 0.000033214164432138205,
        "seek": 33896,
        "start": 343.68,
        "temperature": 0,
        "text": " So based on what's here, I want to change this to results,",
        "tokens": [
          50600,
          407,
          2361,
          322,
          437,
          311,
          510,
          11,
          286,
          528,
          281,
          1319,
          341,
          281,
          3542,
          11,
          50784
        ]
      },
      {
        "avg_logprob": -0.1991516675135886,
        "compression_ratio": 1.630188679245283,
        "end": 350.2,
        "id": 124,
        "no_speech_prob": 0.000033214164432138205,
        "seek": 33896,
        "start": 347.35999999999996,
        "temperature": 0,
        "text": " index0.value.",
        "tokens": [
          50784,
          8186,
          15,
          13,
          29155,
          13,
          50926
        ]
      },
      {
        "avg_logprob": -0.1991516675135886,
        "compression_ratio": 1.630188679245283,
        "end": 352.35999999999996,
        "id": 125,
        "no_speech_prob": 0.000033214164432138205,
        "seek": 33896,
        "start": 350.2,
        "temperature": 0,
        "text": " That's the frequency that I want to play.",
        "tokens": [
          50926,
          663,
          311,
          264,
          7893,
          300,
          286,
          528,
          281,
          862,
          13,
          51034
        ]
      },
      {
        "avg_logprob": -0.1991516675135886,
        "compression_ratio": 1.630188679245283,
        "end": 354.4,
        "id": 126,
        "no_speech_prob": 0.000033214164432138205,
        "seek": 33896,
        "start": 352.35999999999996,
        "temperature": 0,
        "text": " Now, what do I want to draw?",
        "tokens": [
          51034,
          823,
          11,
          437,
          360,
          286,
          528,
          281,
          2642,
          30,
          51136
        ]
      },
      {
        "avg_logprob": -0.1991516675135886,
        "compression_ratio": 1.630188679245283,
        "end": 356.52,
        "id": 127,
        "no_speech_prob": 0.000033214164432138205,
        "seek": 33896,
        "start": 354.4,
        "temperature": 0,
        "text": " Maybe I'll actually look at the number.",
        "tokens": [
          51136,
          2704,
          286,
          603,
          767,
          574,
          412,
          264,
          1230,
          13,
          51242
        ]
      },
      {
        "avg_logprob": -0.1991516675135886,
        "compression_ratio": 1.630188679245283,
        "end": 359.56,
        "id": 128,
        "no_speech_prob": 0.000033214164432138205,
        "seek": 33896,
        "start": 356.52,
        "temperature": 0,
        "text": " So let's actually also draw that.",
        "tokens": [
          51242,
          407,
          718,
          311,
          767,
          611,
          2642,
          300,
          13,
          51394
        ]
      },
      {
        "avg_logprob": -0.1991516675135886,
        "compression_ratio": 1.630188679245283,
        "end": 362.44,
        "id": 129,
        "no_speech_prob": 0.000033214164432138205,
        "seek": 33896,
        "start": 359.56,
        "temperature": 0,
        "text": " But maybe we'll take away the decimal place",
        "tokens": [
          51394,
          583,
          1310,
          321,
          603,
          747,
          1314,
          264,
          26601,
          1081,
          51538
        ]
      },
      {
        "avg_logprob": -0.1991516675135886,
        "compression_ratio": 1.630188679245283,
        "end": 365.03999999999996,
        "id": 130,
        "no_speech_prob": 0.000033214164432138205,
        "seek": 33896,
        "start": 362.44,
        "temperature": 0,
        "text": " by using floor just so it's less busy,",
        "tokens": [
          51538,
          538,
          1228,
          4123,
          445,
          370,
          309,
          311,
          1570,
          5856,
          11,
          51668
        ]
      },
      {
        "avg_logprob": -0.1991516675135886,
        "compression_ratio": 1.630188679245283,
        "end": 367.67999999999995,
        "id": 131,
        "no_speech_prob": 0.000033214164432138205,
        "seek": 33896,
        "start": 365.03999999999996,
        "temperature": 0,
        "text": " takes up less room in the canvas itself.",
        "tokens": [
          51668,
          2516,
          493,
          1570,
          1808,
          294,
          264,
          16267,
          2564,
          13,
          51800
        ]
      },
      {
        "avg_logprob": -0.2727608607365535,
        "compression_ratio": 1.6704545454545454,
        "end": 371.64,
        "id": 132,
        "no_speech_prob": 0.000007646526682947297,
        "seek": 36768,
        "start": 368.68,
        "temperature": 0,
        "text": " All right, let me add the save data feature.",
        "tokens": [
          50414,
          1057,
          558,
          11,
          718,
          385,
          909,
          264,
          3155,
          1412,
          4111,
          13,
          50562
        ]
      },
      {
        "avg_logprob": -0.2727608607365535,
        "compression_ratio": 1.6704545454545454,
        "end": 374,
        "id": 133,
        "no_speech_prob": 0.000007646526682947297,
        "seek": 36768,
        "start": 371.64,
        "temperature": 0,
        "text": " Before I collect the data, let me just change the number",
        "tokens": [
          50562,
          4546,
          286,
          2500,
          264,
          1412,
          11,
          718,
          385,
          445,
          1319,
          264,
          1230,
          50680
        ]
      },
      {
        "avg_logprob": -0.2727608607365535,
        "compression_ratio": 1.6704545454545454,
        "end": 377.12,
        "id": 134,
        "no_speech_prob": 0.000007646526682947297,
        "seek": 36768,
        "start": 374,
        "temperature": 0,
        "text": " of epochs to 50 because I clearly don't need 200 epochs.",
        "tokens": [
          50680,
          295,
          30992,
          28346,
          281,
          2625,
          570,
          286,
          4448,
          500,
          380,
          643,
          2331,
          30992,
          28346,
          13,
          50836
        ]
      },
      {
        "avg_logprob": -0.2727608607365535,
        "compression_ratio": 1.6704545454545454,
        "end": 378.88,
        "id": 135,
        "no_speech_prob": 0.000007646526682947297,
        "seek": 36768,
        "start": 377.12,
        "temperature": 0,
        "text": " Now I'm going to collect a bunch of data.",
        "tokens": [
          50836,
          823,
          286,
          478,
          516,
          281,
          2500,
          257,
          3840,
          295,
          1412,
          13,
          50924
        ]
      },
      {
        "avg_logprob": -0.2727608607365535,
        "compression_ratio": 1.6704545454545454,
        "end": 380.12,
        "id": 136,
        "no_speech_prob": 0.000007646526682947297,
        "seek": 36768,
        "start": 378.88,
        "temperature": 0,
        "text": " So let me make a bunch of Cs.",
        "tokens": [
          50924,
          407,
          718,
          385,
          652,
          257,
          3840,
          295,
          383,
          82,
          13,
          50986
        ]
      },
      {
        "avg_logprob": -0.2727608607365535,
        "compression_ratio": 1.6704545454545454,
        "end": 387.04,
        "id": 137,
        "no_speech_prob": 0.000007646526682947297,
        "seek": 36768,
        "start": 385.12,
        "temperature": 0,
        "text": " I clicked around somewhat arbitrarily.",
        "tokens": [
          51236,
          286,
          23370,
          926,
          8344,
          19071,
          3289,
          13,
          51332
        ]
      },
      {
        "avg_logprob": -0.2727608607365535,
        "compression_ratio": 1.6704545454545454,
        "end": 388.72,
        "id": 138,
        "no_speech_prob": 0.000007646526682947297,
        "seek": 36768,
        "start": 387.04,
        "temperature": 0,
        "text": " But let me now actually save this",
        "tokens": [
          51332,
          583,
          718,
          385,
          586,
          767,
          3155,
          341,
          51416
        ]
      },
      {
        "avg_logprob": -0.2727608607365535,
        "compression_ratio": 1.6704545454545454,
        "end": 390.64,
        "id": 139,
        "no_speech_prob": 0.000007646526682947297,
        "seek": 36768,
        "start": 388.72,
        "temperature": 0,
        "text": " so I don't have to always collect the data again",
        "tokens": [
          51416,
          370,
          286,
          500,
          380,
          362,
          281,
          1009,
          2500,
          264,
          1412,
          797,
          51512
        ]
      },
      {
        "avg_logprob": -0.2727608607365535,
        "compression_ratio": 1.6704545454545454,
        "end": 392.6,
        "id": 140,
        "no_speech_prob": 0.000007646526682947297,
        "seek": 36768,
        "start": 390.64,
        "temperature": 0,
        "text": " every single time.",
        "tokens": [
          51512,
          633,
          2167,
          565,
          13,
          51610
        ]
      },
      {
        "avg_logprob": -0.2727608607365535,
        "compression_ratio": 1.6704545454545454,
        "end": 394.56,
        "id": 141,
        "no_speech_prob": 0.000007646526682947297,
        "seek": 36768,
        "start": 392.6,
        "temperature": 0,
        "text": " So I've saved that to a JSON file.",
        "tokens": [
          51610,
          407,
          286,
          600,
          6624,
          300,
          281,
          257,
          31828,
          3991,
          13,
          51708
        ]
      },
      {
        "avg_logprob": -0.2727608607365535,
        "compression_ratio": 1.6704545454545454,
        "end": 396.08,
        "id": 142,
        "no_speech_prob": 0.000007646526682947297,
        "seek": 36768,
        "start": 394.56,
        "temperature": 0,
        "text": " I am now going to train the model.",
        "tokens": [
          51708,
          286,
          669,
          586,
          516,
          281,
          3847,
          264,
          2316,
          13,
          51784
        ]
      },
      {
        "avg_logprob": -0.29465936457069175,
        "compression_ratio": 1.5829383886255923,
        "end": 401.40000000000003,
        "id": 143,
        "no_speech_prob": 0.00005307456012815237,
        "seek": 39768,
        "start": 398.68,
        "temperature": 0,
        "text": " What do I expect to happen?",
        "tokens": [
          50414,
          708,
          360,
          286,
          2066,
          281,
          1051,
          30,
          50550
        ]
      },
      {
        "avg_logprob": -0.29465936457069175,
        "compression_ratio": 1.5829383886255923,
        "end": 403.36,
        "id": 144,
        "no_speech_prob": 0.00005307456012815237,
        "seek": 39768,
        "start": 401.40000000000003,
        "temperature": 0,
        "text": " Before, when I was doing classification,",
        "tokens": [
          50550,
          4546,
          11,
          562,
          286,
          390,
          884,
          21538,
          11,
          50648
        ]
      },
      {
        "avg_logprob": -0.29465936457069175,
        "compression_ratio": 1.5829383886255923,
        "end": 406.68,
        "id": 145,
        "no_speech_prob": 0.00005307456012815237,
        "seek": 39768,
        "start": 403.36,
        "temperature": 0,
        "text": " I would expect to hear a C when I click near the Cs,",
        "tokens": [
          50648,
          286,
          576,
          2066,
          281,
          1568,
          257,
          383,
          562,
          286,
          2052,
          2651,
          264,
          383,
          82,
          11,
          50814
        ]
      },
      {
        "avg_logprob": -0.29465936457069175,
        "compression_ratio": 1.5829383886255923,
        "end": 408.36,
        "id": 146,
        "no_speech_prob": 0.00005307456012815237,
        "seek": 39768,
        "start": 406.68,
        "temperature": 0,
        "text": " an F when I click near the Fs.",
        "tokens": [
          50814,
          364,
          479,
          562,
          286,
          2052,
          2651,
          264,
          479,
          82,
          13,
          50898
        ]
      },
      {
        "avg_logprob": -0.29465936457069175,
        "compression_ratio": 1.5829383886255923,
        "end": 410.52,
        "id": 147,
        "no_speech_prob": 0.00005307456012815237,
        "seek": 39768,
        "start": 408.36,
        "temperature": 0,
        "text": " And I would hopefully get something similar to that.",
        "tokens": [
          50898,
          400,
          286,
          576,
          4696,
          483,
          746,
          2531,
          281,
          300,
          13,
          51006
        ]
      },
      {
        "avg_logprob": -0.29465936457069175,
        "compression_ratio": 1.5829383886255923,
        "end": 412.16,
        "id": 148,
        "no_speech_prob": 0.00005307456012815237,
        "seek": 39768,
        "start": 410.52,
        "temperature": 0,
        "text": " Like, does this sound like a C to you?",
        "tokens": [
          51006,
          1743,
          11,
          775,
          341,
          1626,
          411,
          257,
          383,
          281,
          291,
          30,
          51088
        ]
      },
      {
        "avg_logprob": -0.29465936457069175,
        "compression_ratio": 1.5829383886255923,
        "end": 416,
        "id": 149,
        "no_speech_prob": 0.00005307456012815237,
        "seek": 39768,
        "start": 412.16,
        "temperature": 0,
        "text": " You can hear it's changing, though.",
        "tokens": [
          51088,
          509,
          393,
          1568,
          309,
          311,
          4473,
          11,
          1673,
          13,
          51280
        ]
      },
      {
        "avg_logprob": -0.29465936457069175,
        "compression_ratio": 1.5829383886255923,
        "end": 418.44,
        "id": 150,
        "no_speech_prob": 0.00005307456012815237,
        "seek": 39768,
        "start": 416,
        "temperature": 0,
        "text": " F?",
        "tokens": [
          51280,
          479,
          30,
          51402
        ]
      },
      {
        "avg_logprob": -0.29465936457069175,
        "compression_ratio": 1.5829383886255923,
        "end": 421.48,
        "id": 151,
        "no_speech_prob": 0.00005307456012815237,
        "seek": 39768,
        "start": 418.44,
        "temperature": 0,
        "text": " But look, I'm getting a different note every time.",
        "tokens": [
          51402,
          583,
          574,
          11,
          286,
          478,
          1242,
          257,
          819,
          3637,
          633,
          565,
          13,
          51554
        ]
      },
      {
        "avg_logprob": -0.3464389308806389,
        "compression_ratio": 1.8368200836820083,
        "end": 432.16,
        "id": 152,
        "no_speech_prob": 0.00007254351658048108,
        "seek": 42768,
        "start": 428.56,
        "temperature": 0,
        "text": " Because the regression, once again, remember, is like a dial.",
        "tokens": [
          50408,
          1436,
          264,
          24590,
          11,
          1564,
          797,
          11,
          1604,
          11,
          307,
          411,
          257,
          5502,
          13,
          50588
        ]
      },
      {
        "avg_logprob": -0.3464389308806389,
        "compression_ratio": 1.8368200836820083,
        "end": 434.84000000000003,
        "id": 153,
        "no_speech_prob": 0.00007254351658048108,
        "seek": 42768,
        "start": 432.16,
        "temperature": 0,
        "text": " So if I have the note C over here",
        "tokens": [
          50588,
          407,
          498,
          286,
          362,
          264,
          3637,
          383,
          670,
          510,
          50722
        ]
      },
      {
        "avg_logprob": -0.3464389308806389,
        "compression_ratio": 1.8368200836820083,
        "end": 440,
        "id": 154,
        "no_speech_prob": 0.00007254351658048108,
        "seek": 42768,
        "start": 434.84000000000003,
        "temperature": 0,
        "text": " and I have the note E over here, ideally, when I click here,",
        "tokens": [
          50722,
          293,
          286,
          362,
          264,
          3637,
          462,
          670,
          510,
          11,
          22915,
          11,
          562,
          286,
          2052,
          510,
          11,
          50980
        ]
      },
      {
        "avg_logprob": -0.3464389308806389,
        "compression_ratio": 1.8368200836820083,
        "end": 442.88,
        "id": 155,
        "no_speech_prob": 0.00007254351658048108,
        "seek": 42768,
        "start": 440,
        "temperature": 0,
        "text": " I'm going to get a note that's in between, like D.",
        "tokens": [
          50980,
          286,
          478,
          516,
          281,
          483,
          257,
          3637,
          300,
          311,
          294,
          1296,
          11,
          411,
          413,
          13,
          51124
        ]
      },
      {
        "avg_logprob": -0.3464389308806389,
        "compression_ratio": 1.8368200836820083,
        "end": 444.8,
        "id": 156,
        "no_speech_prob": 0.00007254351658048108,
        "seek": 42768,
        "start": 442.88,
        "temperature": 0,
        "text": " But the notes are completely irrelevant here.",
        "tokens": [
          51124,
          583,
          264,
          5570,
          366,
          2584,
          28682,
          510,
          13,
          51220
        ]
      },
      {
        "avg_logprob": -0.3464389308806389,
        "compression_ratio": 1.8368200836820083,
        "end": 446.64,
        "id": 157,
        "no_speech_prob": 0.00007254351658048108,
        "seek": 42768,
        "start": 444.8,
        "temperature": 0,
        "text": " It's really all about the numbers.",
        "tokens": [
          51220,
          467,
          311,
          534,
          439,
          466,
          264,
          3547,
          13,
          51312
        ]
      },
      {
        "avg_logprob": -0.3464389308806389,
        "compression_ratio": 1.8368200836820083,
        "end": 449.76,
        "id": 158,
        "no_speech_prob": 0.00007254351658048108,
        "seek": 42768,
        "start": 446.64,
        "temperature": 0,
        "text": " The idea being that if I have the number 200 here",
        "tokens": [
          51312,
          440,
          1558,
          885,
          300,
          498,
          286,
          362,
          264,
          1230,
          2331,
          510,
          51468
        ]
      },
      {
        "avg_logprob": -0.3464389308806389,
        "compression_ratio": 1.8368200836820083,
        "end": 452.72,
        "id": 159,
        "no_speech_prob": 0.00007254351658048108,
        "seek": 42768,
        "start": 449.76,
        "temperature": 0,
        "text": " and I have the number 300 here, clicking in between",
        "tokens": [
          51468,
          293,
          286,
          362,
          264,
          1230,
          6641,
          510,
          11,
          9697,
          294,
          1296,
          51616
        ]
      },
      {
        "avg_logprob": -0.3464389308806389,
        "compression_ratio": 1.8368200836820083,
        "end": 455.76,
        "id": 160,
        "no_speech_prob": 0.00007254351658048108,
        "seek": 42768,
        "start": 452.72,
        "temperature": 0,
        "text": " is like having a slider or a dial on the screen.",
        "tokens": [
          51616,
          307,
          411,
          1419,
          257,
          26046,
          420,
          257,
          5502,
          322,
          264,
          2568,
          13,
          51768
        ]
      },
      {
        "avg_logprob": -0.21470186787266884,
        "compression_ratio": 1.5958188153310104,
        "end": 459.48,
        "id": 161,
        "no_speech_prob": 0.0022518287878483534,
        "seek": 45576,
        "start": 455.76,
        "temperature": 0,
        "text": " It's like having a slider or a dial going between 200",
        "tokens": [
          50364,
          467,
          311,
          411,
          1419,
          257,
          26046,
          420,
          257,
          5502,
          516,
          1296,
          2331,
          50550
        ]
      },
      {
        "avg_logprob": -0.21470186787266884,
        "compression_ratio": 1.5958188153310104,
        "end": 461.4,
        "id": 162,
        "no_speech_prob": 0.0022518287878483534,
        "seek": 45576,
        "start": 459.48,
        "temperature": 0,
        "text": " all the way up to 300.",
        "tokens": [
          50550,
          439,
          264,
          636,
          493,
          281,
          6641,
          13,
          50646
        ]
      },
      {
        "avg_logprob": -0.21470186787266884,
        "compression_ratio": 1.5958188153310104,
        "end": 464.03999999999996,
        "id": 163,
        "no_speech_prob": 0.0022518287878483534,
        "seek": 45576,
        "start": 461.4,
        "temperature": 0,
        "text": " And while this works in a somewhat obvious way",
        "tokens": [
          50646,
          400,
          1339,
          341,
          1985,
          294,
          257,
          8344,
          6322,
          636,
          50778
        ]
      },
      {
        "avg_logprob": -0.21470186787266884,
        "compression_ratio": 1.5958188153310104,
        "end": 466.52,
        "id": 164,
        "no_speech_prob": 0.0022518287878483534,
        "seek": 45576,
        "start": 464.03999999999996,
        "temperature": 0,
        "text": " in this two-dimensional space with me putting",
        "tokens": [
          50778,
          294,
          341,
          732,
          12,
          18759,
          1901,
          365,
          385,
          3372,
          50902
        ]
      },
      {
        "avg_logprob": -0.21470186787266884,
        "compression_ratio": 1.5958188153310104,
        "end": 468.8,
        "id": 165,
        "no_speech_prob": 0.0022518287878483534,
        "seek": 45576,
        "start": 466.52,
        "temperature": 0,
        "text": " a lot of Cs over here and a lot of Gs over there,",
        "tokens": [
          50902,
          257,
          688,
          295,
          383,
          82,
          670,
          510,
          293,
          257,
          688,
          295,
          460,
          82,
          670,
          456,
          11,
          51016
        ]
      },
      {
        "avg_logprob": -0.21470186787266884,
        "compression_ratio": 1.5958188153310104,
        "end": 471.44,
        "id": 166,
        "no_speech_prob": 0.0022518287878483534,
        "seek": 45576,
        "start": 468.8,
        "temperature": 0,
        "text": " you could imagine how this could become a much more",
        "tokens": [
          51016,
          291,
          727,
          3811,
          577,
          341,
          727,
          1813,
          257,
          709,
          544,
          51148
        ]
      },
      {
        "avg_logprob": -0.21470186787266884,
        "compression_ratio": 1.5958188153310104,
        "end": 473.71999999999997,
        "id": 167,
        "no_speech_prob": 0.0022518287878483534,
        "seek": 45576,
        "start": 471.44,
        "temperature": 0,
        "text": " sophisticated musical instrument.",
        "tokens": [
          51148,
          16950,
          9165,
          7198,
          13,
          51262
        ]
      },
      {
        "avg_logprob": -0.21470186787266884,
        "compression_ratio": 1.5958188153310104,
        "end": 475.8,
        "id": 168,
        "no_speech_prob": 0.0022518287878483534,
        "seek": 45576,
        "start": 473.71999999999997,
        "temperature": 0,
        "text": " Or the output doesn't even have to be tied",
        "tokens": [
          51262,
          1610,
          264,
          5598,
          1177,
          380,
          754,
          362,
          281,
          312,
          9601,
          51366
        ]
      },
      {
        "avg_logprob": -0.21470186787266884,
        "compression_ratio": 1.5958188153310104,
        "end": 478.59999999999997,
        "id": 169,
        "no_speech_prob": 0.0022518287878483534,
        "seek": 45576,
        "start": 475.8,
        "temperature": 0,
        "text": " to a musical frequency, a sound frequency.",
        "tokens": [
          51366,
          281,
          257,
          9165,
          7893,
          11,
          257,
          1626,
          7893,
          13,
          51506
        ]
      },
      {
        "avg_logprob": -0.21470186787266884,
        "compression_ratio": 1.5958188153310104,
        "end": 480.36,
        "id": 170,
        "no_speech_prob": 0.0022518287878483534,
        "seek": 45576,
        "start": 478.59999999999997,
        "temperature": 0,
        "text": " There's so many possibilities.",
        "tokens": [
          51506,
          821,
          311,
          370,
          867,
          12178,
          13,
          51594
        ]
      },
      {
        "avg_logprob": -0.21470186787266884,
        "compression_ratio": 1.5958188153310104,
        "end": 484.08,
        "id": 171,
        "no_speech_prob": 0.0022518287878483534,
        "seek": 45576,
        "start": 480.36,
        "temperature": 0,
        "text": " But now we've seen that in addition",
        "tokens": [
          51594,
          583,
          586,
          321,
          600,
          1612,
          300,
          294,
          4500,
          51780
        ]
      },
      {
        "avg_logprob": -0.2292994635445731,
        "compression_ratio": 1.664516129032258,
        "end": 488.24,
        "id": 172,
        "no_speech_prob": 0.0003459899453446269,
        "seek": 48408,
        "start": 484.12,
        "temperature": 0,
        "text": " to using the ML5 neural network for classification,",
        "tokens": [
          50366,
          281,
          1228,
          264,
          21601,
          20,
          18161,
          3209,
          337,
          21538,
          11,
          50572
        ]
      },
      {
        "avg_logprob": -0.2292994635445731,
        "compression_ratio": 1.664516129032258,
        "end": 490.88,
        "id": 173,
        "no_speech_prob": 0.0003459899453446269,
        "seek": 48408,
        "start": 488.24,
        "temperature": 0,
        "text": " you can also use it for regression.",
        "tokens": [
          50572,
          291,
          393,
          611,
          764,
          309,
          337,
          24590,
          13,
          50704
        ]
      },
      {
        "avg_logprob": -0.2292994635445731,
        "compression_ratio": 1.664516129032258,
        "end": 492.03999999999996,
        "id": 174,
        "no_speech_prob": 0.0003459899453446269,
        "seek": 48408,
        "start": 490.88,
        "temperature": 0,
        "text": " So what's next?",
        "tokens": [
          50704,
          407,
          437,
          311,
          958,
          30,
          50762
        ]
      },
      {
        "avg_logprob": -0.2292994635445731,
        "compression_ratio": 1.664516129032258,
        "end": 494.03999999999996,
        "id": 175,
        "no_speech_prob": 0.0003459899453446269,
        "seek": 48408,
        "start": 492.03999999999996,
        "temperature": 0,
        "text": " Let's think of some exercises for you to do.",
        "tokens": [
          50762,
          961,
          311,
          519,
          295,
          512,
          11900,
          337,
          291,
          281,
          360,
          13,
          50862
        ]
      },
      {
        "avg_logprob": -0.2292994635445731,
        "compression_ratio": 1.664516129032258,
        "end": 495.59999999999997,
        "id": 176,
        "no_speech_prob": 0.0003459899453446269,
        "seek": 48408,
        "start": 494.03999999999996,
        "temperature": 0,
        "text": " So first of all, right now I have",
        "tokens": [
          50862,
          407,
          700,
          295,
          439,
          11,
          558,
          586,
          286,
          362,
          50940
        ]
      },
      {
        "avg_logprob": -0.2292994635445731,
        "compression_ratio": 1.664516129032258,
        "end": 497.36,
        "id": 177,
        "no_speech_prob": 0.0003459899453446269,
        "seek": 48408,
        "start": 495.59999999999997,
        "temperature": 0,
        "text": " to click around to hear the note.",
        "tokens": [
          50940,
          281,
          2052,
          926,
          281,
          1568,
          264,
          3637,
          13,
          51028
        ]
      },
      {
        "avg_logprob": -0.2292994635445731,
        "compression_ratio": 1.664516129032258,
        "end": 499.56,
        "id": 178,
        "no_speech_prob": 0.0003459899453446269,
        "seek": 48408,
        "start": 497.36,
        "temperature": 0,
        "text": " But there's no reason why in this particular example",
        "tokens": [
          51028,
          583,
          456,
          311,
          572,
          1778,
          983,
          294,
          341,
          1729,
          1365,
          51138
        ]
      },
      {
        "avg_logprob": -0.2292994635445731,
        "compression_ratio": 1.664516129032258,
        "end": 502.68,
        "id": 179,
        "no_speech_prob": 0.0003459899453446269,
        "seek": 48408,
        "start": 499.56,
        "temperature": 0,
        "text": " I couldn't move the mouse around and have that frequency adjust.",
        "tokens": [
          51138,
          286,
          2809,
          380,
          1286,
          264,
          9719,
          926,
          293,
          362,
          300,
          7893,
          4369,
          13,
          51294
        ]
      },
      {
        "avg_logprob": -0.2292994635445731,
        "compression_ratio": 1.664516129032258,
        "end": 505.76,
        "id": 180,
        "no_speech_prob": 0.0003459899453446269,
        "seek": 48408,
        "start": 502.68,
        "temperature": 0,
        "text": " So I don't need an envelope anymore.",
        "tokens": [
          51294,
          407,
          286,
          500,
          380,
          643,
          364,
          19989,
          3602,
          13,
          51448
        ]
      },
      {
        "avg_logprob": -0.2292994635445731,
        "compression_ratio": 1.664516129032258,
        "end": 507.71999999999997,
        "id": 181,
        "no_speech_prob": 0.0003459899453446269,
        "seek": 48408,
        "start": 505.76,
        "temperature": 0,
        "text": " Maybe I'm just continuously playing a note.",
        "tokens": [
          51448,
          2704,
          286,
          478,
          445,
          15684,
          2433,
          257,
          3637,
          13,
          51546
        ]
      },
      {
        "avg_logprob": -0.2292994635445731,
        "compression_ratio": 1.664516129032258,
        "end": 509.38,
        "id": 182,
        "no_speech_prob": 0.0003459899453446269,
        "seek": 48408,
        "start": 507.71999999999997,
        "temperature": 0,
        "text": " So that might be something that you try.",
        "tokens": [
          51546,
          407,
          300,
          1062,
          312,
          746,
          300,
          291,
          853,
          13,
          51629
        ]
      },
      {
        "avg_logprob": -0.2292994635445731,
        "compression_ratio": 1.664516129032258,
        "end": 512.4,
        "id": 183,
        "no_speech_prob": 0.0003459899453446269,
        "seek": 48408,
        "start": 509.38,
        "temperature": 0,
        "text": " You can play around with saving the model, saving the data,",
        "tokens": [
          51629,
          509,
          393,
          862,
          926,
          365,
          6816,
          264,
          2316,
          11,
          6816,
          264,
          1412,
          11,
          51780
        ]
      },
      {
        "avg_logprob": -0.24101026179426807,
        "compression_ratio": 1.6840148698884758,
        "end": 514.88,
        "id": 184,
        "no_speech_prob": 0.0001686522737145424,
        "seek": 51240,
        "start": 512.4,
        "temperature": 0,
        "text": " all that stuff that I showed you in the previous two videos",
        "tokens": [
          50364,
          439,
          300,
          1507,
          300,
          286,
          4712,
          291,
          294,
          264,
          3894,
          732,
          2145,
          50488
        ]
      },
      {
        "avg_logprob": -0.24101026179426807,
        "compression_ratio": 1.6840148698884758,
        "end": 516.8,
        "id": 185,
        "no_speech_prob": 0.0001686522737145424,
        "seek": 51240,
        "start": 514.88,
        "temperature": 0,
        "text": " with this regression example as well.",
        "tokens": [
          50488,
          365,
          341,
          24590,
          1365,
          382,
          731,
          13,
          50584
        ]
      },
      {
        "avg_logprob": -0.24101026179426807,
        "compression_ratio": 1.6840148698884758,
        "end": 519.28,
        "id": 186,
        "no_speech_prob": 0.0001686522737145424,
        "seek": 51240,
        "start": 516.8,
        "temperature": 0,
        "text": " But ultimately, I think what I want to look at here,",
        "tokens": [
          50584,
          583,
          6284,
          11,
          286,
          519,
          437,
          286,
          528,
          281,
          574,
          412,
          510,
          11,
          50708
        ]
      },
      {
        "avg_logprob": -0.24101026179426807,
        "compression_ratio": 1.6840148698884758,
        "end": 523.68,
        "id": 187,
        "no_speech_prob": 0.0001686522737145424,
        "seek": 51240,
        "start": 519.28,
        "temperature": 0,
        "text": " and I will come back and do another video, is what",
        "tokens": [
          50708,
          293,
          286,
          486,
          808,
          646,
          293,
          360,
          1071,
          960,
          11,
          307,
          437,
          50928
        ]
      },
      {
        "avg_logprob": -0.24101026179426807,
        "compression_ratio": 1.6840148698884758,
        "end": 525.9599999999999,
        "id": 188,
        "no_speech_prob": 0.0001686522737145424,
        "seek": 51240,
        "start": 523.68,
        "temperature": 0,
        "text": " are some ideas for inputs that allow",
        "tokens": [
          50928,
          366,
          512,
          3487,
          337,
          15743,
          300,
          2089,
          51042
        ]
      },
      {
        "avg_logprob": -0.24101026179426807,
        "compression_ratio": 1.6840148698884758,
        "end": 530.64,
        "id": 189,
        "no_speech_prob": 0.0001686522737145424,
        "seek": 51240,
        "start": 525.9599999999999,
        "temperature": 0,
        "text": " for more creative or surprising results than just mouse clicks?",
        "tokens": [
          51042,
          337,
          544,
          5880,
          420,
          8830,
          3542,
          813,
          445,
          9719,
          596,
          72,
          2761,
          30,
          51276
        ]
      },
      {
        "avg_logprob": -0.24101026179426807,
        "compression_ratio": 1.6840148698884758,
        "end": 533.92,
        "id": 190,
        "no_speech_prob": 0.0001686522737145424,
        "seek": 51240,
        "start": 530.64,
        "temperature": 0,
        "text": " And I think the one that I want to show you is using PoseNet.",
        "tokens": [
          51276,
          400,
          286,
          519,
          264,
          472,
          300,
          286,
          528,
          281,
          855,
          291,
          307,
          1228,
          40174,
          31890,
          13,
          51440
        ]
      },
      {
        "avg_logprob": -0.24101026179426807,
        "compression_ratio": 1.6840148698884758,
        "end": 536.36,
        "id": 191,
        "no_speech_prob": 0.0001686522737145424,
        "seek": 51240,
        "start": 533.92,
        "temperature": 0,
        "text": " So PoseNet is also a machine learning model",
        "tokens": [
          51440,
          407,
          40174,
          31890,
          307,
          611,
          257,
          3479,
          2539,
          2316,
          51562
        ]
      },
      {
        "avg_logprob": -0.24101026179426807,
        "compression_ratio": 1.6840148698884758,
        "end": 541.3199999999999,
        "id": 192,
        "no_speech_prob": 0.0001686522737145424,
        "seek": 51240,
        "start": 536.36,
        "temperature": 0,
        "text": " that takes an image as the input and guesses",
        "tokens": [
          51562,
          300,
          2516,
          364,
          3256,
          382,
          264,
          4846,
          293,
          42703,
          51810
        ]
      },
      {
        "avg_logprob": -0.19906231588568568,
        "compression_ratio": 1.6768060836501901,
        "end": 543.48,
        "id": 193,
        "no_speech_prob": 0.0000321922852890566,
        "seek": 54132,
        "start": 541.32,
        "temperature": 0,
        "text": " where parts of your body are.",
        "tokens": [
          50364,
          689,
          3166,
          295,
          428,
          1772,
          366,
          13,
          50472
        ]
      },
      {
        "avg_logprob": -0.19906231588568568,
        "compression_ratio": 1.6768060836501901,
        "end": 545.2800000000001,
        "id": 194,
        "no_speech_prob": 0.0000321922852890566,
        "seek": 54132,
        "start": 543.48,
        "temperature": 0,
        "text": " So it can find your nose, and your eyes,",
        "tokens": [
          50472,
          407,
          309,
          393,
          915,
          428,
          6690,
          11,
          293,
          428,
          2575,
          11,
          50562
        ]
      },
      {
        "avg_logprob": -0.19906231588568568,
        "compression_ratio": 1.6768060836501901,
        "end": 547.24,
        "id": 195,
        "no_speech_prob": 0.0000321922852890566,
        "seek": 54132,
        "start": 545.2800000000001,
        "temperature": 0,
        "text": " and your hands, and your elbows, a whole set",
        "tokens": [
          50562,
          293,
          428,
          2377,
          11,
          293,
          428,
          26620,
          11,
          257,
          1379,
          992,
          50660
        ]
      },
      {
        "avg_logprob": -0.19906231588568568,
        "compression_ratio": 1.6768060836501901,
        "end": 549.44,
        "id": 196,
        "no_speech_prob": 0.0000321922852890566,
        "seek": 54132,
        "start": 547.24,
        "temperature": 0,
        "text": " of key points on a human body.",
        "tokens": [
          50660,
          295,
          2141,
          2793,
          322,
          257,
          1952,
          1772,
          13,
          50770
        ]
      },
      {
        "avg_logprob": -0.19906231588568568,
        "compression_ratio": 1.6768060836501901,
        "end": 552.36,
        "id": 197,
        "no_speech_prob": 0.0000321922852890566,
        "seek": 54132,
        "start": 549.44,
        "temperature": 0,
        "text": " Why not train a model to recognize",
        "tokens": [
          50770,
          1545,
          406,
          3847,
          257,
          2316,
          281,
          5521,
          50916
        ]
      },
      {
        "avg_logprob": -0.19906231588568568,
        "compression_ratio": 1.6768060836501901,
        "end": 554.96,
        "id": 198,
        "no_speech_prob": 0.0000321922852890566,
        "seek": 54132,
        "start": 552.36,
        "temperature": 0,
        "text": " as the inputs certain poses and then",
        "tokens": [
          50916,
          382,
          264,
          15743,
          1629,
          26059,
          293,
          550,
          51046
        ]
      },
      {
        "avg_logprob": -0.19906231588568568,
        "compression_ratio": 1.6768060836501901,
        "end": 557.6800000000001,
        "id": 199,
        "no_speech_prob": 0.0000321922852890566,
        "seek": 54132,
        "start": 554.96,
        "temperature": 0,
        "text": " have a particular output associated with that?",
        "tokens": [
          51046,
          362,
          257,
          1729,
          5598,
          6615,
          365,
          300,
          30,
          51182
        ]
      },
      {
        "avg_logprob": -0.19906231588568568,
        "compression_ratio": 1.6768060836501901,
        "end": 561.12,
        "id": 200,
        "no_speech_prob": 0.0000321922852890566,
        "seek": 54132,
        "start": 557.6800000000001,
        "temperature": 0,
        "text": " So I'm going to build a project using all of this stuff.",
        "tokens": [
          51182,
          407,
          286,
          478,
          516,
          281,
          1322,
          257,
          1716,
          1228,
          439,
          295,
          341,
          1507,
          13,
          51354
        ]
      },
      {
        "avg_logprob": -0.19906231588568568,
        "compression_ratio": 1.6768060836501901,
        "end": 564.8000000000001,
        "id": 201,
        "no_speech_prob": 0.0000321922852890566,
        "seek": 54132,
        "start": 561.12,
        "temperature": 0,
        "text": " In the next video, I think I'll make it a coding challenge,",
        "tokens": [
          51354,
          682,
          264,
          958,
          960,
          11,
          286,
          519,
          286,
          603,
          652,
          309,
          257,
          17720,
          3430,
          11,
          51538
        ]
      },
      {
        "avg_logprob": -0.19906231588568568,
        "compression_ratio": 1.6768060836501901,
        "end": 569.5600000000001,
        "id": 202,
        "no_speech_prob": 0.0000321922852890566,
        "seek": 54132,
        "start": 564.8000000000001,
        "temperature": 0,
        "text": " build a project that does pose classification with the ml5",
        "tokens": [
          51538,
          1322,
          257,
          1716,
          300,
          775,
          10774,
          21538,
          365,
          264,
          23271,
          20,
          51776
        ]
      },
      {
        "avg_logprob": -0.25954876207325556,
        "compression_ratio": 1.3865030674846626,
        "end": 571,
        "id": 203,
        "no_speech_prob": 0.0006986677180975676,
        "seek": 56956,
        "start": 569.56,
        "temperature": 0,
        "text": " neural network library.",
        "tokens": [
          50364,
          18161,
          3209,
          6405,
          13,
          50436
        ]
      },
      {
        "avg_logprob": -0.25954876207325556,
        "compression_ratio": 1.3865030674846626,
        "end": 572.56,
        "id": 204,
        "no_speech_prob": 0.0006986677180975676,
        "seek": 56956,
        "start": 571,
        "temperature": 0,
        "text": " Or maybe it'll be pose regression.",
        "tokens": [
          50436,
          1610,
          1310,
          309,
          603,
          312,
          10774,
          24590,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.25954876207325556,
        "compression_ratio": 1.3865030674846626,
        "end": 573.2399999999999,
        "id": 205,
        "no_speech_prob": 0.0006986677180975676,
        "seek": 56956,
        "start": 572.56,
        "temperature": 0,
        "text": " I don't know.",
        "tokens": [
          50514,
          286,
          500,
          380,
          458,
          13,
          50548
        ]
      },
      {
        "avg_logprob": -0.25954876207325556,
        "compression_ratio": 1.3865030674846626,
        "end": 574.1999999999999,
        "id": 206,
        "no_speech_prob": 0.0006986677180975676,
        "seek": 56956,
        "start": 573.2399999999999,
        "temperature": 0,
        "text": " We'll see.",
        "tokens": [
          50548,
          492,
          603,
          536,
          13,
          50596
        ]
      },
      {
        "avg_logprob": -0.25954876207325556,
        "compression_ratio": 1.3865030674846626,
        "end": 575.5999999999999,
        "id": 207,
        "no_speech_prob": 0.0006986677180975676,
        "seek": 56956,
        "start": 574.1999999999999,
        "temperature": 0,
        "text": " It'll be in the next video.",
        "tokens": [
          50596,
          467,
          603,
          312,
          294,
          264,
          958,
          960,
          13,
          50666
        ]
      },
      {
        "avg_logprob": -0.25954876207325556,
        "compression_ratio": 1.3865030674846626,
        "end": 577.0799999999999,
        "id": 208,
        "no_speech_prob": 0.0006986677180975676,
        "seek": 56956,
        "start": 575.5999999999999,
        "temperature": 0,
        "text": " Thanks for watching, and I look forward",
        "tokens": [
          50666,
          2561,
          337,
          1976,
          11,
          293,
          286,
          574,
          2128,
          50740
        ]
      },
      {
        "avg_logprob": -0.25954876207325556,
        "compression_ratio": 1.3865030674846626,
        "end": 578.64,
        "id": 209,
        "no_speech_prob": 0.0006986677180975676,
        "seek": 56956,
        "start": 577.0799999999999,
        "temperature": 0,
        "text": " to all of your questions and comments",
        "tokens": [
          50740,
          281,
          439,
          295,
          428,
          1651,
          293,
          3053,
          50818
        ]
      },
      {
        "avg_logprob": -0.25954876207325556,
        "compression_ratio": 1.3865030674846626,
        "end": 579.76,
        "id": 210,
        "no_speech_prob": 0.0006986677180975676,
        "seek": 56956,
        "start": 578.64,
        "temperature": 0,
        "text": " and all that sort of stuff.",
        "tokens": [
          50818,
          293,
          439,
          300,
          1333,
          295,
          1507,
          13,
          50874
        ]
      },
      {
        "avg_logprob": -0.25954876207325556,
        "compression_ratio": 1.3865030674846626,
        "end": 580.26,
        "id": 211,
        "no_speech_prob": 0.0006986677180975676,
        "seek": 56956,
        "start": 579.76,
        "temperature": 0,
        "text": " Goodbye.",
        "tokens": [
          50874,
          15528,
          13,
          50899
        ]
      },
      {
        "avg_logprob": -0.9009979688204252,
        "compression_ratio": 0.6875,
        "end": 580.86,
        "id": 212,
        "no_speech_prob": 0.18836760520935059,
        "seek": 58026,
        "start": 580.36,
        "temperature": 0.6000000000000001,
        "text": " Ding.",
        "tokens": [
          50369,
          220,
          35,
          278,
          13,
          50394
        ]
      },
      {
        "avg_logprob": -0.9009979688204252,
        "compression_ratio": 0.6875,
        "end": 582.4,
        "id": 213,
        "no_speech_prob": 0.18836760520935059,
        "seek": 58026,
        "start": 580.86,
        "temperature": 0.6000000000000001,
        "text": " Ding.",
        "tokens": [
          50394,
          220,
          35,
          278,
          13,
          50471
        ]
      }
    ],
    "transcription": " I don't know where you arrived from. But if you didn't arrive from the previous videos about training your own neural network, you might feel a little bit lost. Because what I'm going to do here entirely depends on the previous few videos where I trained a model to classify musical notes based on mouse clicks in a P5 canvas. So what I'm going to do in this video is change this word from classification, I'm going to do it right now, to regression. And this is going to drastically change what the neural network outputs and how I use that output. But before I start changing anything else in the code, let me talk about what I mean by regression in the context of machine learning. First, let's recap classification. The idea of classification is that the neural network is going to receive some input and end up with a discrete categorical output, meaning it's going to assign a label, C, D, or E. We can think of that as there's three light bulbs. Are those like little drawings of light bulbs? Each light bulb is associated with one of the possible labels or categories, classifications. And if the neural network decides that this particular input corresponds to the label E, then maybe this light bulb would light up. And you could do this. You could build an Arduino with some LEDs and have the results of machine learning classification light up a particular LED. A regression, you could think of the output being a slider or maybe a dial. As the data comes into the neural network, the dial ends up at some value between some minimum and maximum. The output is numerical continuous output. So classification is one of a discrete set of possibilities. And regression is any value between a given range. Now, you can still have multiple outputs in a regression because you can have multiple continuous values. But in this case, I want to redo this example by having a single output and that output be the frequency value. So if I change the task to regression, now I want my output to be tied to a frequency. No longer do I want during the training process to give target labels. I want to give target numbers so that it will guess a number as part of the regression output. So this is my code for data collection. When I click the mouse, the inputs are an x and y. And the target is a target label. But I don't want it to be a target label anymore. I want it to be a frequency. And I can figure out what that target frequency is by looking it up in this particular JavaScript object. So I can say let target frequency equal notes target label. And in fact, that's something that I'm already doing down here. So let's replace this with target frequency. Now, ordinarily, I might remove target label completely as a variable in the system because I don't need the label anymore for the machine learning model. I'm not using CDE. I'm not using the note name for training the model. But while I'm collecting the data, I still would like to see the note C or A or G because I think that's less awkward than drawing the frequency number in the window. So crazily, I think I'm actually done with all that I need for the first two steps. The first two steps being collect the data and train the model. I've changed the task to regression. And now I've changed the output to a single output node that just has a frequency value. So I should be able to run all of the bits of code that I did before and have it train the model. Let's see if that works. All right. Collected some data. Let's train the model. And it worked. I mean, it worked in the sense that I don't see any errors in the console. And I see a nice graph with the loss going all the way down. Incidentally, the loss went way down very, very quickly. So I probably don't need 200 epochs. Maybe this regression problem was a little bit easier for it to learn more accurately. Who knows? But it optimized very quickly. So now that collecting data and training the model is done, I need to just do that last stage of basically deploying the model and making predictions with new data. And I don't think this is going to work. I haven't adjusted the code at all. It's still looking for a label and all of that. So who knows what will happen? You Yeah, it's just it's first of all, it's writing the word frequency here and just playing one particular note. So let's go look at the prediction code and see what we need to adjust for a regression. First thing is because we're no longer doing classification, we shouldn't call model.classify with the given inputs. We want to change this to model.predict. So predict is the function name for a regression, classifies the function name for a classification. Let's collect data again and retrain the model. OK, it's trained. Let me click into the canvas. And let's look and see what came out here. So this is what I get back. I get back an array. I only have one output in this particular model. And so I look at the zero element of that array. This is the value it predicted. And I have a label that in case I had multiple things, I could know which goes with which. So based on what's here, I want to change this to results, index0.value. That's the frequency that I want to play. Now, what do I want to draw? Maybe I'll actually look at the number. So let's actually also draw that. But maybe we'll take away the decimal place by using floor just so it's less busy, takes up less room in the canvas itself. All right, let me add the save data feature. Before I collect the data, let me just change the number of epochs to 50 because I clearly don't need 200 epochs. Now I'm going to collect a bunch of data. So let me make a bunch of Cs. I clicked around somewhat arbitrarily. But let me now actually save this so I don't have to always collect the data again every single time. So I've saved that to a JSON file. I am now going to train the model. What do I expect to happen? Before, when I was doing classification, I would expect to hear a C when I click near the Cs, an F when I click near the Fs. And I would hopefully get something similar to that. Like, does this sound like a C to you? You can hear it's changing, though. F? But look, I'm getting a different note every time. Because the regression, once again, remember, is like a dial. So if I have the note C over here and I have the note E over here, ideally, when I click here, I'm going to get a note that's in between, like D. But the notes are completely irrelevant here. It's really all about the numbers. The idea being that if I have the number 200 here and I have the number 300 here, clicking in between is like having a slider or a dial on the screen. It's like having a slider or a dial going between 200 all the way up to 300. And while this works in a somewhat obvious way in this two-dimensional space with me putting a lot of Cs over here and a lot of Gs over there, you could imagine how this could become a much more sophisticated musical instrument. Or the output doesn't even have to be tied to a musical frequency, a sound frequency. There's so many possibilities. But now we've seen that in addition to using the ML5 neural network for classification, you can also use it for regression. So what's next? Let's think of some exercises for you to do. So first of all, right now I have to click around to hear the note. But there's no reason why in this particular example I couldn't move the mouse around and have that frequency adjust. So I don't need an envelope anymore. Maybe I'm just continuously playing a note. So that might be something that you try. You can play around with saving the model, saving the data, all that stuff that I showed you in the previous two videos with this regression example as well. But ultimately, I think what I want to look at here, and I will come back and do another video, is what are some ideas for inputs that allow for more creative or surprising results than just mouse clicks? And I think the one that I want to show you is using PoseNet. So PoseNet is also a machine learning model that takes an image as the input and guesses where parts of your body are. So it can find your nose, and your eyes, and your hands, and your elbows, a whole set of key points on a human body. Why not train a model to recognize as the inputs certain poses and then have a particular output associated with that? So I'm going to build a project using all of this stuff. In the next video, I think I'll make it a coding challenge, build a project that does pose classification with the ml5 neural network library. Or maybe it'll be pose regression. I don't know. We'll see. It'll be in the next video. Thanks for watching, and I look forward to all of your questions and comments and all that sort of stuff. Goodbye. Ding. Ding.",
    "translation": null
  },
  "error": null,
  "status": "succeeded",
  "created_at": "2023-09-26T21:03:42.625293Z",
  "started_at": "2023-09-26T21:16:18.945287Z",
  "completed_at": "2023-09-26T21:18:58.374064Z",
  "webhook": "https://83ceaa0b612c.ngrok.app/?video_id=fFzvwdkzr_c",
  "webhook_events_filter": [
    "completed"
  ],
  "metrics": {
    "predict_time": 159.428777
  },
  "urls": {
    "cancel": "https://api.replicate.com/v1/predictions/powxk5bbbiywm55rp3j4nvk524/cancel",
    "get": "https://api.replicate.com/v1/predictions/powxk5bbbiywm55rp3j4nvk524"
  }
}