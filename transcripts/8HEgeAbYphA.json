{
  "id": "gmoiynzb7wcu4kb67uwgydvfe4",
  "version": "91ee9c0c3df30478510ff8c8a3a545add1ad0259ad3a9f78fba57fbc05ee64f7",
  "input": {
    "audio": "https://upcdn.io/FW25b4F/raw/coding-train/8HEgeAbYphA.m4a"
  },
  "logs": "Transcribe with large-v2 model\nDetected language: English\n  0%|          | 0/208807 [00:00<?, ?frames/s]\n  1%|▏         | 2992/208807 [00:07<08:12, 417.56frames/s]\n  3%|▎         | 5572/208807 [00:12<07:24, 456.95frames/s]\n  4%|▍         | 8436/208807 [00:18<07:28, 446.31frames/s]\n  5%|▌         | 11210/208807 [00:24<07:16, 452.23frames/s]\n  7%|▋         | 14160/208807 [00:30<06:38, 488.51frames/s]\n  8%|▊         | 16964/208807 [00:36<06:53, 464.25frames/s]\n 10%|▉         | 19882/208807 [00:43<07:01, 448.52frames/s]\n 11%|█         | 22874/208807 [00:50<06:57, 445.47frames/s]\n 12%|█▏        | 25810/208807 [00:55<06:24, 475.68frames/s]\n 14%|█▎        | 28626/208807 [01:02<06:41, 449.18frames/s]\n 15%|█▌        | 31618/208807 [01:10<06:46, 435.72frames/s]\n 17%|█▋        | 34558/208807 [01:15<06:06, 475.26frames/s]\n 18%|█▊        | 37378/208807 [01:20<05:46, 494.73frames/s]\n 19%|█▉        | 40066/208807 [01:25<05:42, 492.33frames/s]\n 20%|██        | 42538/208807 [01:30<05:32, 499.72frames/s]\n 22%|██▏       | 45262/208807 [01:36<05:27, 499.89frames/s]\n 23%|██▎       | 48258/208807 [01:42<05:25, 492.55frames/s]\n 24%|██▍       | 51030/208807 [01:48<05:32, 473.87frames/s]\n 26%|██▌       | 53898/208807 [01:55<05:32, 465.66frames/s]\n 27%|██▋       | 56850/208807 [02:03<06:00, 421.88frames/s]\n 29%|██▊       | 59838/208807 [02:10<05:54, 420.37frames/s]\n 30%|███       | 62670/208807 [02:16<05:35, 435.94frames/s]\n 31%|███▏      | 65370/208807 [02:23<05:34, 428.98frames/s]\n 33%|███▎      | 68226/208807 [02:30<05:44, 407.56frames/s]\n 34%|███▍      | 71114/208807 [02:37<05:36, 409.78frames/s]\n 35%|███▌      | 73938/208807 [02:43<05:13, 430.45frames/s]\n 37%|███▋      | 76630/208807 [02:51<05:23, 408.17frames/s]\n 38%|███▊      | 79608/208807 [02:57<05:04, 424.87frames/s]\n 39%|███▉      | 82468/208807 [03:03<04:48, 437.75frames/s]\n 41%|████      | 85196/208807 [03:10<04:44, 433.77frames/s]\n 42%|████▏     | 87874/208807 [03:17<04:50, 416.39frames/s]\n 43%|████▎     | 90666/208807 [03:22<04:33, 432.59frames/s]\n 45%|████▍     | 93594/208807 [03:29<04:28, 429.63frames/s]\n 46%|████▌     | 96486/208807 [03:35<04:13, 443.82frames/s]\n 48%|████▊     | 99430/208807 [03:43<04:21, 417.62frames/s]\n 49%|████▉     | 102412/208807 [03:49<04:02, 438.12frames/s]\n 50%|█████     | 105334/208807 [03:57<04:01, 429.09frames/s]\n 52%|█████▏    | 108028/208807 [04:05<04:15, 393.78frames/s]\n 53%|█████▎    | 110908/208807 [04:12<04:05, 399.04frames/s]\n 55%|█████▍    | 113894/208807 [04:19<03:55, 403.88frames/s]\n 56%|█████▌    | 116828/208807 [04:25<03:35, 427.81frames/s]\n 57%|█████▋    | 119734/208807 [04:31<03:18, 447.86frames/s]\n 59%|█████▉    | 122680/208807 [04:37<03:08, 456.10frames/s]\n 60%|██████    | 125590/208807 [04:44<03:04, 451.23frames/s]\n 62%|██████▏   | 128480/208807 [04:50<02:55, 457.26frames/s]\n 63%|██████▎   | 131310/208807 [04:56<02:48, 460.94frames/s]\n 64%|██████▍   | 134196/208807 [05:02<02:44, 453.17frames/s]\n 66%|██████▌   | 136930/208807 [05:08<02:36, 458.66frames/s]\n 67%|██████▋   | 139796/208807 [05:16<02:39, 432.53frames/s]\n 68%|██████▊   | 142550/208807 [05:22<02:33, 432.41frames/s]\n 70%|██████▉   | 145528/208807 [05:29<02:30, 420.99frames/s]\n 71%|███████   | 148350/208807 [05:37<02:29, 405.13frames/s]\n 72%|███████▏  | 151220/208807 [05:45<02:27, 389.63frames/s]\n 74%|███████▍  | 154094/208807 [05:51<02:11, 417.06frames/s]\n 75%|███████▌  | 156936/208807 [05:59<02:11, 394.12frames/s]\n 75%|███████▌  | 156936/208807 [06:16<02:11, 394.12frames/s]\n 77%|███████▋  | 159882/208807 [06:17<02:55, 278.61frames/s]\n 78%|███████▊  | 162712/208807 [06:22<02:22, 323.24frames/s]\n 79%|███████▉  | 165646/208807 [06:30<02:07, 337.66frames/s]\n 81%|████████  | 168412/208807 [06:36<01:51, 362.13frames/s]\n 82%|████████▏ | 171362/208807 [06:43<01:38, 379.93frames/s]\n 83%|████████▎ | 174336/208807 [06:48<01:22, 418.97frames/s]\n 85%|████████▍ | 176650/208807 [06:55<01:20, 398.66frames/s]\n 86%|████████▌ | 179620/208807 [07:02<01:11, 409.28frames/s]\n 87%|████████▋ | 182606/208807 [07:10<01:06, 393.57frames/s]\n 89%|████████▉ | 185384/208807 [07:18<01:00, 384.31frames/s]\n 90%|█████████ | 188086/208807 [07:23<00:49, 415.08frames/s]\n 92%|█████████▏| 191072/208807 [07:31<00:44, 398.17frames/s]\n 93%|█████████▎| 194022/208807 [07:36<00:32, 455.64frames/s]\n 94%|█████████▍| 196956/208807 [07:43<00:27, 438.31frames/s]\n 96%|█████████▌| 199956/208807 [07:45<00:16, 549.90frames/s]\n 97%|█████████▋| 202662/208807 [07:52<00:12, 489.26frames/s]\n 98%|█████████▊| 205648/208807 [08:00<00:07, 441.78frames/s]\n100%|█████████▉| 207846/208807 [08:06<00:02, 438.56frames/s]\n100%|██████████| 208807/208807 [08:06<00:00, 482.33frames/s]\n100%|██████████| 208807/208807 [08:06<00:00, 429.00frames/s]\n",
  "output": {
    "detected_language": "english",
    "segments": [
      {
        "avg_logprob": -0.2505563279272805,
        "compression_ratio": 1.7903780068728523,
        "end": 3.48,
        "id": 0,
        "no_speech_prob": 0.04466048628091812,
        "seek": 0,
        "start": 0,
        "temperature": 0,
        "text": " Hello, and welcome to another beginner's guide",
        "tokens": [
          50364,
          2425,
          11,
          293,
          2928,
          281,
          1071,
          22080,
          311,
          5934,
          50538
        ]
      },
      {
        "avg_logprob": -0.2505563279272805,
        "compression_ratio": 1.7903780068728523,
        "end": 7.2,
        "id": 1,
        "no_speech_prob": 0.04466048628091812,
        "seek": 0,
        "start": 3.48,
        "temperature": 0,
        "text": " to machine learning video tutorial with ml5.js.",
        "tokens": [
          50538,
          281,
          3479,
          2539,
          960,
          7073,
          365,
          23271,
          20,
          13,
          25530,
          13,
          50724
        ]
      },
      {
        "avg_logprob": -0.2505563279272805,
        "compression_ratio": 1.7903780068728523,
        "end": 8.4,
        "id": 2,
        "no_speech_prob": 0.04466048628091812,
        "seek": 0,
        "start": 7.2,
        "temperature": 0,
        "text": " Very excited about this one.",
        "tokens": [
          50724,
          4372,
          2919,
          466,
          341,
          472,
          13,
          50784
        ]
      },
      {
        "avg_logprob": -0.2505563279272805,
        "compression_ratio": 1.7903780068728523,
        "end": 10.76,
        "id": 3,
        "no_speech_prob": 0.04466048628091812,
        "seek": 0,
        "start": 8.4,
        "temperature": 0,
        "text": " I'm typically excited about the video tutorials I make,",
        "tokens": [
          50784,
          286,
          478,
          5850,
          2919,
          466,
          264,
          960,
          17616,
          286,
          652,
          11,
          50902
        ]
      },
      {
        "avg_logprob": -0.2505563279272805,
        "compression_ratio": 1.7903780068728523,
        "end": 12.88,
        "id": 4,
        "no_speech_prob": 0.04466048628091812,
        "seek": 0,
        "start": 10.76,
        "temperature": 0,
        "text": " but this one I'm particularly excited about,",
        "tokens": [
          50902,
          457,
          341,
          472,
          286,
          478,
          4098,
          2919,
          466,
          11,
          51008
        ]
      },
      {
        "avg_logprob": -0.2505563279272805,
        "compression_ratio": 1.7903780068728523,
        "end": 14.48,
        "id": 5,
        "no_speech_prob": 0.04466048628091812,
        "seek": 0,
        "start": 12.88,
        "temperature": 0,
        "text": " because I'm going to look at something",
        "tokens": [
          51008,
          570,
          286,
          478,
          516,
          281,
          574,
          412,
          746,
          51088
        ]
      },
      {
        "avg_logprob": -0.2505563279272805,
        "compression_ratio": 1.7903780068728523,
        "end": 17.64,
        "id": 6,
        "no_speech_prob": 0.04466048628091812,
        "seek": 0,
        "start": 14.48,
        "temperature": 0,
        "text": " that has recently arrived in the ml5.js library.",
        "tokens": [
          51088,
          300,
          575,
          3938,
          6678,
          294,
          264,
          23271,
          20,
          13,
          25530,
          6405,
          13,
          51246
        ]
      },
      {
        "avg_logprob": -0.2505563279272805,
        "compression_ratio": 1.7903780068728523,
        "end": 21.080000000000002,
        "id": 7,
        "no_speech_prob": 0.04466048628091812,
        "seek": 0,
        "start": 17.64,
        "temperature": 0,
        "text": " So first of all, use version 0.4.2, or a more recent version",
        "tokens": [
          51246,
          407,
          700,
          295,
          439,
          11,
          764,
          3037,
          1958,
          13,
          19,
          13,
          17,
          11,
          420,
          257,
          544,
          5162,
          3037,
          51418
        ]
      },
      {
        "avg_logprob": -0.2505563279272805,
        "compression_ratio": 1.7903780068728523,
        "end": 24.04,
        "id": 8,
        "no_speech_prob": 0.04466048628091812,
        "seek": 0,
        "start": 21.080000000000002,
        "temperature": 0,
        "text": " perhaps, but that's the version I'll be using in this video.",
        "tokens": [
          51418,
          4317,
          11,
          457,
          300,
          311,
          264,
          3037,
          286,
          603,
          312,
          1228,
          294,
          341,
          960,
          13,
          51566
        ]
      },
      {
        "avg_logprob": -0.2505563279272805,
        "compression_ratio": 1.7903780068728523,
        "end": 26.88,
        "id": 9,
        "no_speech_prob": 0.04466048628091812,
        "seek": 0,
        "start": 24.04,
        "temperature": 0,
        "text": " And I want to look at this functionality in the ml5",
        "tokens": [
          51566,
          400,
          286,
          528,
          281,
          574,
          412,
          341,
          14980,
          294,
          264,
          23271,
          20,
          51708
        ]
      },
      {
        "avg_logprob": -0.2505563279272805,
        "compression_ratio": 1.7903780068728523,
        "end": 29.92,
        "id": 10,
        "no_speech_prob": 0.04466048628091812,
        "seek": 0,
        "start": 26.88,
        "temperature": 0,
        "text": " library called ml5 neural network.",
        "tokens": [
          51708,
          6405,
          1219,
          23271,
          20,
          18161,
          3209,
          13,
          51860
        ]
      },
      {
        "avg_logprob": -0.22210247039794923,
        "compression_ratio": 1.6233183856502242,
        "end": 34.72,
        "id": 11,
        "no_speech_prob": 0.00012148063979111612,
        "seek": 2992,
        "start": 29.92,
        "temperature": 0,
        "text": " It is a function in ml5 that creates a empty, or blank,",
        "tokens": [
          50364,
          467,
          307,
          257,
          2445,
          294,
          23271,
          20,
          300,
          7829,
          257,
          6707,
          11,
          420,
          8247,
          11,
          50604
        ]
      },
      {
        "avg_logprob": -0.22210247039794923,
        "compression_ratio": 1.6233183856502242,
        "end": 36.96,
        "id": 12,
        "no_speech_prob": 0.00012148063979111612,
        "seek": 2992,
        "start": 34.72,
        "temperature": 0,
        "text": " so to speak, neural network.",
        "tokens": [
          50604,
          370,
          281,
          1710,
          11,
          18161,
          3209,
          13,
          50716
        ]
      },
      {
        "avg_logprob": -0.22210247039794923,
        "compression_ratio": 1.6233183856502242,
        "end": 40.6,
        "id": 13,
        "no_speech_prob": 0.00012148063979111612,
        "seek": 2992,
        "start": 36.96,
        "temperature": 0,
        "text": " Everything that I've showed you in this video series so far",
        "tokens": [
          50716,
          5471,
          300,
          286,
          600,
          4712,
          291,
          294,
          341,
          960,
          2638,
          370,
          1400,
          50898
        ]
      },
      {
        "avg_logprob": -0.22210247039794923,
        "compression_ratio": 1.6233183856502242,
        "end": 43.160000000000004,
        "id": 14,
        "no_speech_prob": 0.00012148063979111612,
        "seek": 2992,
        "start": 40.6,
        "temperature": 0,
        "text": " has involved loading a pre-trained model.",
        "tokens": [
          50898,
          575,
          3288,
          15114,
          257,
          659,
          12,
          17227,
          2001,
          2316,
          13,
          51026
        ]
      },
      {
        "avg_logprob": -0.22210247039794923,
        "compression_ratio": 1.6233183856502242,
        "end": 46.480000000000004,
        "id": 15,
        "no_speech_prob": 0.00012148063979111612,
        "seek": 2992,
        "start": 43.160000000000004,
        "temperature": 0,
        "text": " So a neural network architecture that's already",
        "tokens": [
          51026,
          407,
          257,
          18161,
          3209,
          9482,
          300,
          311,
          1217,
          51192
        ]
      },
      {
        "avg_logprob": -0.22210247039794923,
        "compression_ratio": 1.6233183856502242,
        "end": 48.24,
        "id": 16,
        "no_speech_prob": 0.00012148063979111612,
        "seek": 2992,
        "start": 46.480000000000004,
        "temperature": 0,
        "text": " been trained with some data.",
        "tokens": [
          51192,
          668,
          8895,
          365,
          512,
          1412,
          13,
          51280
        ]
      },
      {
        "avg_logprob": -0.22210247039794923,
        "compression_ratio": 1.6233183856502242,
        "end": 52.72,
        "id": 17,
        "no_speech_prob": 0.00012148063979111612,
        "seek": 2992,
        "start": 48.24,
        "temperature": 0,
        "text": " And in this video, I want to look at making an empty,",
        "tokens": [
          51280,
          400,
          294,
          341,
          960,
          11,
          286,
          528,
          281,
          574,
          412,
          1455,
          364,
          6707,
          11,
          51504
        ]
      },
      {
        "avg_logprob": -0.22210247039794923,
        "compression_ratio": 1.6233183856502242,
        "end": 55.72,
        "id": 18,
        "no_speech_prob": 0.00012148063979111612,
        "seek": 2992,
        "start": 52.72,
        "temperature": 0,
        "text": " a blank slate, configuring a neural network,",
        "tokens": [
          51504,
          257,
          8247,
          39118,
          11,
          6662,
          1345,
          257,
          18161,
          3209,
          11,
          51654
        ]
      },
      {
        "avg_logprob": -0.2033145991900495,
        "compression_ratio": 1.7142857142857142,
        "end": 60.16,
        "id": 19,
        "no_speech_prob": 0.0005703120259568095,
        "seek": 5572,
        "start": 55.72,
        "temperature": 0,
        "text": " collecting data, training the model, and doing inference.",
        "tokens": [
          50364,
          12510,
          1412,
          11,
          3097,
          264,
          2316,
          11,
          293,
          884,
          38253,
          13,
          50586
        ]
      },
      {
        "avg_logprob": -0.2033145991900495,
        "compression_ratio": 1.7142857142857142,
        "end": 62.44,
        "id": 20,
        "no_speech_prob": 0.0005703120259568095,
        "seek": 5572,
        "start": 60.16,
        "temperature": 0,
        "text": " And the context that I want to look at that",
        "tokens": [
          50586,
          400,
          264,
          4319,
          300,
          286,
          528,
          281,
          574,
          412,
          300,
          50700
        ]
      },
      {
        "avg_logprob": -0.2033145991900495,
        "compression_ratio": 1.7142857142857142,
        "end": 64.68,
        "id": 21,
        "no_speech_prob": 0.0005703120259568095,
        "seek": 5572,
        "start": 62.44,
        "temperature": 0,
        "text": " is with real-time interactive data.",
        "tokens": [
          50700,
          307,
          365,
          957,
          12,
          3766,
          15141,
          1412,
          13,
          50812
        ]
      },
      {
        "avg_logprob": -0.2033145991900495,
        "compression_ratio": 1.7142857142857142,
        "end": 66.3,
        "id": 22,
        "no_speech_prob": 0.0005703120259568095,
        "seek": 5572,
        "start": 64.68,
        "temperature": 0,
        "text": " So I'm going to come back and maybe use",
        "tokens": [
          50812,
          407,
          286,
          478,
          516,
          281,
          808,
          646,
          293,
          1310,
          764,
          50893
        ]
      },
      {
        "avg_logprob": -0.2033145991900495,
        "compression_ratio": 1.7142857142857142,
        "end": 68.84,
        "id": 23,
        "no_speech_prob": 0.0005703120259568095,
        "seek": 5572,
        "start": 66.3,
        "temperature": 0,
        "text": " some more traditional data sets.",
        "tokens": [
          50893,
          512,
          544,
          5164,
          1412,
          6352,
          13,
          51020
        ]
      },
      {
        "avg_logprob": -0.2033145991900495,
        "compression_ratio": 1.7142857142857142,
        "end": 72.12,
        "id": 24,
        "no_speech_prob": 0.0005703120259568095,
        "seek": 5572,
        "start": 68.84,
        "temperature": 0,
        "text": " There's a data set that's on the ml5 examples",
        "tokens": [
          51020,
          821,
          311,
          257,
          1412,
          992,
          300,
          311,
          322,
          264,
          23271,
          20,
          5110,
          51184
        ]
      },
      {
        "avg_logprob": -0.2033145991900495,
        "compression_ratio": 1.7142857142857142,
        "end": 74.03999999999999,
        "id": 25,
        "no_speech_prob": 0.0005703120259568095,
        "seek": 5572,
        "start": 72.12,
        "temperature": 0,
        "text": " with the Titanic survival data set.",
        "tokens": [
          51184,
          365,
          264,
          42183,
          12559,
          1412,
          992,
          13,
          51280
        ]
      },
      {
        "avg_logprob": -0.2033145991900495,
        "compression_ratio": 1.7142857142857142,
        "end": 76.68,
        "id": 26,
        "no_speech_prob": 0.0005703120259568095,
        "seek": 5572,
        "start": 74.03999999999999,
        "temperature": 0,
        "text": " I have the data set for my color classifier series.",
        "tokens": [
          51280,
          286,
          362,
          264,
          1412,
          992,
          337,
          452,
          2017,
          1508,
          9902,
          2638,
          13,
          51412
        ]
      },
      {
        "avg_logprob": -0.2033145991900495,
        "compression_ratio": 1.7142857142857142,
        "end": 80.56,
        "id": 27,
        "no_speech_prob": 0.0005703120259568095,
        "seek": 5572,
        "start": 76.68,
        "temperature": 0,
        "text": " So I'll come back and show you some examples of those as well.",
        "tokens": [
          51412,
          407,
          286,
          603,
          808,
          646,
          293,
          855,
          291,
          512,
          5110,
          295,
          729,
          382,
          731,
          13,
          51606
        ]
      },
      {
        "avg_logprob": -0.2033145991900495,
        "compression_ratio": 1.7142857142857142,
        "end": 82.52,
        "id": 28,
        "no_speech_prob": 0.0005703120259568095,
        "seek": 5572,
        "start": 80.56,
        "temperature": 0,
        "text": " But in this first video, I just want",
        "tokens": [
          51606,
          583,
          294,
          341,
          700,
          960,
          11,
          286,
          445,
          528,
          51704
        ]
      },
      {
        "avg_logprob": -0.2033145991900495,
        "compression_ratio": 1.7142857142857142,
        "end": 84.36,
        "id": 29,
        "no_speech_prob": 0.0005703120259568095,
        "seek": 5572,
        "start": 82.52,
        "temperature": 0,
        "text": " to do something very generic, which",
        "tokens": [
          51704,
          281,
          360,
          746,
          588,
          19577,
          11,
          597,
          51796
        ]
      },
      {
        "avg_logprob": -0.2569645152372472,
        "compression_ratio": 1.6236559139784945,
        "end": 86.28,
        "id": 30,
        "no_speech_prob": 0.0011878962395712733,
        "seek": 8436,
        "start": 84.36,
        "temperature": 0,
        "text": " is create a blank neural network,",
        "tokens": [
          50364,
          307,
          1884,
          257,
          8247,
          18161,
          3209,
          11,
          50460
        ]
      },
      {
        "avg_logprob": -0.2569645152372472,
        "compression_ratio": 1.6236559139784945,
        "end": 91.8,
        "id": 31,
        "no_speech_prob": 0.0011878962395712733,
        "seek": 8436,
        "start": 86.28,
        "temperature": 0,
        "text": " use mouse clicks to train it, and then move the mouse around",
        "tokens": [
          50460,
          764,
          9719,
          18521,
          281,
          3847,
          309,
          11,
          293,
          550,
          1286,
          264,
          9719,
          926,
          50736
        ]
      },
      {
        "avg_logprob": -0.2569645152372472,
        "compression_ratio": 1.6236559139784945,
        "end": 94,
        "id": 32,
        "no_speech_prob": 0.0011878962395712733,
        "seek": 8436,
        "start": 91.8,
        "temperature": 0,
        "text": " for it to make guesses or predictions.",
        "tokens": [
          50736,
          337,
          309,
          281,
          652,
          42703,
          420,
          21264,
          13,
          50846
        ]
      },
      {
        "avg_logprob": -0.2569645152372472,
        "compression_ratio": 1.6236559139784945,
        "end": 95.92,
        "id": 33,
        "no_speech_prob": 0.0011878962395712733,
        "seek": 8436,
        "start": 94,
        "temperature": 0,
        "text": " And that might sound like a weird thing to do.",
        "tokens": [
          50846,
          400,
          300,
          1062,
          1626,
          411,
          257,
          3657,
          551,
          281,
          360,
          13,
          50942
        ]
      },
      {
        "avg_logprob": -0.2569645152372472,
        "compression_ratio": 1.6236559139784945,
        "end": 97.72,
        "id": 34,
        "no_speech_prob": 0.0011878962395712733,
        "seek": 8436,
        "start": 95.92,
        "temperature": 0,
        "text": " And hopefully, it'll start to make sense",
        "tokens": [
          50942,
          400,
          4696,
          11,
          309,
          603,
          722,
          281,
          652,
          2020,
          51032
        ]
      },
      {
        "avg_logprob": -0.2569645152372472,
        "compression_ratio": 1.6236559139784945,
        "end": 101.2,
        "id": 35,
        "no_speech_prob": 0.0011878962395712733,
        "seek": 8436,
        "start": 97.72,
        "temperature": 0,
        "text": " as I build the code and step through all the processes.",
        "tokens": [
          51032,
          382,
          286,
          1322,
          264,
          3089,
          293,
          1823,
          807,
          439,
          264,
          7555,
          13,
          51206
        ]
      },
      {
        "avg_logprob": -0.2569645152372472,
        "compression_ratio": 1.6236559139784945,
        "end": 104.53999999999999,
        "id": 36,
        "no_speech_prob": 0.0011878962395712733,
        "seek": 8436,
        "start": 101.2,
        "temperature": 0,
        "text": " I also want to highlight for you the Wekinator project, which",
        "tokens": [
          51206,
          286,
          611,
          528,
          281,
          5078,
          337,
          291,
          264,
          492,
          5843,
          1639,
          1716,
          11,
          597,
          51373
        ]
      },
      {
        "avg_logprob": -0.2569645152372472,
        "compression_ratio": 1.6236559139784945,
        "end": 106.88,
        "id": 37,
        "no_speech_prob": 0.0011878962395712733,
        "seek": 8436,
        "start": 104.53999999999999,
        "temperature": 0,
        "text": " is a free open source piece of software created",
        "tokens": [
          51373,
          307,
          257,
          1737,
          1269,
          4009,
          2522,
          295,
          4722,
          2942,
          51490
        ]
      },
      {
        "avg_logprob": -0.2569645152372472,
        "compression_ratio": 1.6236559139784945,
        "end": 111.2,
        "id": 38,
        "no_speech_prob": 0.0011878962395712733,
        "seek": 8436,
        "start": 106.88,
        "temperature": 0,
        "text": " by Rebecca Fribrich in 2009 for training machine learning",
        "tokens": [
          51490,
          538,
          19381,
          479,
          470,
          1443,
          480,
          294,
          11453,
          337,
          3097,
          3479,
          2539,
          51706
        ]
      },
      {
        "avg_logprob": -0.2569645152372472,
        "compression_ratio": 1.6236559139784945,
        "end": 112.1,
        "id": 39,
        "no_speech_prob": 0.0011878962395712733,
        "seek": 8436,
        "start": 111.2,
        "temperature": 0,
        "text": " models.",
        "tokens": [
          51706,
          5245,
          13,
          51751
        ]
      },
      {
        "avg_logprob": -0.2308307685474358,
        "compression_ratio": 1.5852713178294573,
        "end": 114.5,
        "id": 40,
        "no_speech_prob": 0.00011959766561631113,
        "seek": 11210,
        "start": 112.1,
        "temperature": 0,
        "text": " And I would especially encourage you",
        "tokens": [
          50364,
          400,
          286,
          576,
          2318,
          5373,
          291,
          50484
        ]
      },
      {
        "avg_logprob": -0.2308307685474358,
        "compression_ratio": 1.5852713178294573,
        "end": 118.25999999999999,
        "id": 41,
        "no_speech_prob": 0.00011959766561631113,
        "seek": 11210,
        "start": 114.5,
        "temperature": 0,
        "text": " to watch Rebecca Fribrich's talk from the I-O conference",
        "tokens": [
          50484,
          281,
          1159,
          19381,
          479,
          470,
          1443,
          480,
          311,
          751,
          490,
          264,
          286,
          12,
          46,
          7586,
          50672
        ]
      },
      {
        "avg_logprob": -0.2308307685474358,
        "compression_ratio": 1.5852713178294573,
        "end": 122.1,
        "id": 42,
        "no_speech_prob": 0.00011959766561631113,
        "seek": 11210,
        "start": 118.25999999999999,
        "temperature": 0,
        "text": " in 2018, where she talks about creativity and inclusion",
        "tokens": [
          50672,
          294,
          6096,
          11,
          689,
          750,
          6686,
          466,
          12915,
          293,
          15874,
          50864
        ]
      },
      {
        "avg_logprob": -0.2308307685474358,
        "compression_ratio": 1.5852713178294573,
        "end": 125.33999999999999,
        "id": 43,
        "no_speech_prob": 0.00011959766561631113,
        "seek": 11210,
        "start": 122.1,
        "temperature": 0,
        "text": " in machine learning and goes through some demonstrations",
        "tokens": [
          50864,
          294,
          3479,
          2539,
          293,
          1709,
          807,
          512,
          34714,
          51026
        ]
      },
      {
        "avg_logprob": -0.2308307685474358,
        "compression_ratio": 1.5852713178294573,
        "end": 128.29999999999998,
        "id": 44,
        "no_speech_prob": 0.00011959766561631113,
        "seek": 11210,
        "start": 125.33999999999999,
        "temperature": 0,
        "text": " with Wekinator and processing and other pieces of software.",
        "tokens": [
          51026,
          365,
          492,
          5843,
          1639,
          293,
          9007,
          293,
          661,
          3755,
          295,
          4722,
          13,
          51174
        ]
      },
      {
        "avg_logprob": -0.2308307685474358,
        "compression_ratio": 1.5852713178294573,
        "end": 132.29999999999998,
        "id": 45,
        "no_speech_prob": 0.00011959766561631113,
        "seek": 11210,
        "start": 128.29999999999998,
        "temperature": 0,
        "text": " So a lot of the work that I'm doing with ml5",
        "tokens": [
          51174,
          407,
          257,
          688,
          295,
          264,
          589,
          300,
          286,
          478,
          884,
          365,
          23271,
          20,
          51374
        ]
      },
      {
        "avg_logprob": -0.2308307685474358,
        "compression_ratio": 1.5852713178294573,
        "end": 138.82,
        "id": 46,
        "no_speech_prob": 0.00011959766561631113,
        "seek": 11210,
        "start": 132.29999999999998,
        "temperature": 0,
        "text": " is entirely based on recreations of many of the example",
        "tokens": [
          51374,
          307,
          7696,
          2361,
          322,
          14261,
          763,
          295,
          867,
          295,
          264,
          1365,
          51700
        ]
      },
      {
        "avg_logprob": -0.2308307685474358,
        "compression_ratio": 1.5852713178294573,
        "end": 141.6,
        "id": 47,
        "no_speech_prob": 0.00011959766561631113,
        "seek": 11210,
        "start": 138.82,
        "temperature": 0,
        "text": " demonstrations that Rebecca Fribrich made",
        "tokens": [
          51700,
          34714,
          300,
          19381,
          479,
          470,
          1443,
          480,
          1027,
          51839
        ]
      },
      {
        "avg_logprob": -0.19528569673237048,
        "compression_ratio": 1.6576271186440679,
        "end": 144.12,
        "id": 48,
        "no_speech_prob": 0.00011412177991587669,
        "seek": 14160,
        "start": 141.6,
        "temperature": 0,
        "text": " and has done research about for years and years",
        "tokens": [
          50364,
          293,
          575,
          1096,
          2132,
          466,
          337,
          924,
          293,
          924,
          50490
        ]
      },
      {
        "avg_logprob": -0.19528569673237048,
        "compression_ratio": 1.6576271186440679,
        "end": 145.4,
        "id": 49,
        "no_speech_prob": 0.00011412177991587669,
        "seek": 14160,
        "start": 144.12,
        "temperature": 0,
        "text": " with the Wekinator project.",
        "tokens": [
          50490,
          365,
          264,
          492,
          5843,
          1639,
          1716,
          13,
          50554
        ]
      },
      {
        "avg_logprob": -0.19528569673237048,
        "compression_ratio": 1.6576271186440679,
        "end": 147.35999999999999,
        "id": 50,
        "no_speech_prob": 0.00011412177991587669,
        "seek": 14160,
        "start": 145.4,
        "temperature": 0,
        "text": " So in fact, the examples that I'm",
        "tokens": [
          50554,
          407,
          294,
          1186,
          11,
          264,
          5110,
          300,
          286,
          478,
          50652
        ]
      },
      {
        "avg_logprob": -0.19528569673237048,
        "compression_ratio": 1.6576271186440679,
        "end": 149.16,
        "id": 51,
        "no_speech_prob": 0.00011412177991587669,
        "seek": 14160,
        "start": 147.35999999999999,
        "temperature": 0,
        "text": " going to make in this video and the next one",
        "tokens": [
          50652,
          516,
          281,
          652,
          294,
          341,
          960,
          293,
          264,
          958,
          472,
          50742
        ]
      },
      {
        "avg_logprob": -0.19528569673237048,
        "compression_ratio": 1.6576271186440679,
        "end": 151.64,
        "id": 52,
        "no_speech_prob": 0.00011412177991587669,
        "seek": 14160,
        "start": 149.16,
        "temperature": 0,
        "text": " and the next follow-ups are direct ports,",
        "tokens": [
          50742,
          293,
          264,
          958,
          1524,
          12,
          7528,
          366,
          2047,
          18160,
          11,
          50866
        ]
      },
      {
        "avg_logprob": -0.19528569673237048,
        "compression_ratio": 1.6576271186440679,
        "end": 154.12,
        "id": 53,
        "no_speech_prob": 0.00011412177991587669,
        "seek": 14160,
        "start": 151.64,
        "temperature": 0,
        "text": " in a way, of some of the original Wekinator",
        "tokens": [
          50866,
          294,
          257,
          636,
          11,
          295,
          512,
          295,
          264,
          3380,
          492,
          5843,
          1639,
          50990
        ]
      },
      {
        "avg_logprob": -0.19528569673237048,
        "compression_ratio": 1.6576271186440679,
        "end": 155.6,
        "id": 54,
        "no_speech_prob": 0.00011412177991587669,
        "seek": 14160,
        "start": 154.12,
        "temperature": 0,
        "text": " and processing examples.",
        "tokens": [
          50990,
          293,
          9007,
          5110,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.19528569673237048,
        "compression_ratio": 1.6576271186440679,
        "end": 158.16,
        "id": 55,
        "no_speech_prob": 0.00011412177991587669,
        "seek": 14160,
        "start": 155.6,
        "temperature": 0,
        "text": " But I'm going to do it all in JavaScript in the browser",
        "tokens": [
          51064,
          583,
          286,
          478,
          516,
          281,
          360,
          309,
          439,
          294,
          15778,
          294,
          264,
          11185,
          51192
        ]
      },
      {
        "avg_logprob": -0.19528569673237048,
        "compression_ratio": 1.6576271186440679,
        "end": 161.2,
        "id": 56,
        "no_speech_prob": 0.00011412177991587669,
        "seek": 14160,
        "start": 158.16,
        "temperature": 0,
        "text": " with p5 and the ml5.js library.",
        "tokens": [
          51192,
          365,
          280,
          20,
          293,
          264,
          23271,
          20,
          13,
          25530,
          6405,
          13,
          51344
        ]
      },
      {
        "avg_logprob": -0.19528569673237048,
        "compression_ratio": 1.6576271186440679,
        "end": 163.2,
        "id": 57,
        "no_speech_prob": 0.00011412177991587669,
        "seek": 14160,
        "start": 161.2,
        "temperature": 0,
        "text": " There's also a fairly lengthy history",
        "tokens": [
          51344,
          821,
          311,
          611,
          257,
          6457,
          35374,
          2503,
          51444
        ]
      },
      {
        "avg_logprob": -0.19528569673237048,
        "compression_ratio": 1.6576271186440679,
        "end": 165.72,
        "id": 58,
        "no_speech_prob": 0.00011412177991587669,
        "seek": 14160,
        "start": 163.2,
        "temperature": 0,
        "text": " of creative artists training machine learning",
        "tokens": [
          51444,
          295,
          5880,
          6910,
          3097,
          3479,
          2539,
          51570
        ]
      },
      {
        "avg_logprob": -0.19528569673237048,
        "compression_ratio": 1.6576271186440679,
        "end": 169.64,
        "id": 59,
        "no_speech_prob": 0.00011412177991587669,
        "seek": 14160,
        "start": 165.72,
        "temperature": 0,
        "text": " models in real time to control musical instruments,",
        "tokens": [
          51570,
          5245,
          294,
          957,
          565,
          281,
          1969,
          9165,
          12190,
          11,
          51766
        ]
      },
      {
        "avg_logprob": -0.218859631082286,
        "compression_ratio": 1.7304964539007093,
        "end": 172.35999999999999,
        "id": 60,
        "no_speech_prob": 0.009267698042094707,
        "seek": 16964,
        "start": 169.64,
        "temperature": 0,
        "text": " a performance, a visual art piece.",
        "tokens": [
          50364,
          257,
          3389,
          11,
          257,
          5056,
          1523,
          2522,
          13,
          50500
        ]
      },
      {
        "avg_logprob": -0.218859631082286,
        "compression_ratio": 1.7304964539007093,
        "end": 174.16,
        "id": 61,
        "no_speech_prob": 0.009267698042094707,
        "seek": 16964,
        "start": 172.35999999999999,
        "temperature": 0,
        "text": " And I would encourage you to check out some of these",
        "tokens": [
          50500,
          400,
          286,
          576,
          5373,
          291,
          281,
          1520,
          484,
          512,
          295,
          613,
          50590
        ]
      },
      {
        "avg_logprob": -0.218859631082286,
        "compression_ratio": 1.7304964539007093,
        "end": 174.95999999999998,
        "id": 62,
        "no_speech_prob": 0.009267698042094707,
        "seek": 16964,
        "start": 174.16,
        "temperature": 0,
        "text": " projects.",
        "tokens": [
          50590,
          4455,
          13,
          50630
        ]
      },
      {
        "avg_logprob": -0.218859631082286,
        "compression_ratio": 1.7304964539007093,
        "end": 177.83999999999997,
        "id": 63,
        "no_speech_prob": 0.009267698042094707,
        "seek": 16964,
        "start": 174.95999999999998,
        "temperature": 0,
        "text": " Our guide for figuring out how to write the code",
        "tokens": [
          50630,
          2621,
          5934,
          337,
          15213,
          484,
          577,
          281,
          2464,
          264,
          3089,
          50774
        ]
      },
      {
        "avg_logprob": -0.218859631082286,
        "compression_ratio": 1.7304964539007093,
        "end": 179.76,
        "id": 64,
        "no_speech_prob": 0.009267698042094707,
        "seek": 16964,
        "start": 177.83999999999997,
        "temperature": 0,
        "text": " is going to be the ml5 website.",
        "tokens": [
          50774,
          307,
          516,
          281,
          312,
          264,
          23271,
          20,
          3144,
          13,
          50870
        ]
      },
      {
        "avg_logprob": -0.218859631082286,
        "compression_ratio": 1.7304964539007093,
        "end": 183.44,
        "id": 65,
        "no_speech_prob": 0.009267698042094707,
        "seek": 16964,
        "start": 179.76,
        "temperature": 0,
        "text": " And there's a page on the ml5 website for the neural network",
        "tokens": [
          50870,
          400,
          456,
          311,
          257,
          3028,
          322,
          264,
          23271,
          20,
          3144,
          337,
          264,
          18161,
          3209,
          51054
        ]
      },
      {
        "avg_logprob": -0.218859631082286,
        "compression_ratio": 1.7304964539007093,
        "end": 183.92,
        "id": 66,
        "no_speech_prob": 0.009267698042094707,
        "seek": 16964,
        "start": 183.44,
        "temperature": 0,
        "text": " function.",
        "tokens": [
          51054,
          2445,
          13,
          51078
        ]
      },
      {
        "avg_logprob": -0.218859631082286,
        "compression_ratio": 1.7304964539007093,
        "end": 186.6,
        "id": 67,
        "no_speech_prob": 0.009267698042094707,
        "seek": 16964,
        "start": 183.92,
        "temperature": 0,
        "text": " But before I start diving into the code,",
        "tokens": [
          51078,
          583,
          949,
          286,
          722,
          20241,
          666,
          264,
          3089,
          11,
          51212
        ]
      },
      {
        "avg_logprob": -0.218859631082286,
        "compression_ratio": 1.7304964539007093,
        "end": 190.95999999999998,
        "id": 68,
        "no_speech_prob": 0.009267698042094707,
        "seek": 16964,
        "start": 186.6,
        "temperature": 0,
        "text": " let's take a minute to talk about what a neural network is.",
        "tokens": [
          51212,
          718,
          311,
          747,
          257,
          3456,
          281,
          751,
          466,
          437,
          257,
          18161,
          3209,
          307,
          13,
          51430
        ]
      },
      {
        "avg_logprob": -0.218859631082286,
        "compression_ratio": 1.7304964539007093,
        "end": 192.79999999999998,
        "id": 69,
        "no_speech_prob": 0.009267698042094707,
        "seek": 16964,
        "start": 190.95999999999998,
        "temperature": 0,
        "text": " Now, by no means in this video am",
        "tokens": [
          51430,
          823,
          11,
          538,
          572,
          1355,
          294,
          341,
          960,
          669,
          51522
        ]
      },
      {
        "avg_logprob": -0.218859631082286,
        "compression_ratio": 1.7304964539007093,
        "end": 195.26,
        "id": 70,
        "no_speech_prob": 0.009267698042094707,
        "seek": 16964,
        "start": 192.79999999999998,
        "temperature": 0,
        "text": " I going to do a comprehensive deep dive",
        "tokens": [
          51522,
          286,
          516,
          281,
          360,
          257,
          13914,
          2452,
          9192,
          51645
        ]
      },
      {
        "avg_logprob": -0.218859631082286,
        "compression_ratio": 1.7304964539007093,
        "end": 197,
        "id": 71,
        "no_speech_prob": 0.009267698042094707,
        "seek": 16964,
        "start": 195.26,
        "temperature": 0,
        "text": " into what a neural network is and how",
        "tokens": [
          51645,
          666,
          437,
          257,
          18161,
          3209,
          307,
          293,
          577,
          51732
        ]
      },
      {
        "avg_logprob": -0.218859631082286,
        "compression_ratio": 1.7304964539007093,
        "end": 198.82,
        "id": 72,
        "no_speech_prob": 0.009267698042094707,
        "seek": 16964,
        "start": 197,
        "temperature": 0,
        "text": " to code one from scratch.",
        "tokens": [
          51732,
          281,
          3089,
          472,
          490,
          8459,
          13,
          51823
        ]
      },
      {
        "avg_logprob": -0.23131896124945747,
        "compression_ratio": 1.669811320754717,
        "end": 201.94,
        "id": 73,
        "no_speech_prob": 0.0003514351265039295,
        "seek": 19882,
        "start": 198.82,
        "temperature": 0,
        "text": " I will refer you to many other wonderful resources",
        "tokens": [
          50364,
          286,
          486,
          2864,
          291,
          281,
          867,
          661,
          3715,
          3593,
          50520
        ]
      },
      {
        "avg_logprob": -0.23131896124945747,
        "compression_ratio": 1.669811320754717,
        "end": 203.4,
        "id": 74,
        "no_speech_prob": 0.0003514351265039295,
        "seek": 19882,
        "start": 201.94,
        "temperature": 0,
        "text": " where you could do that deep dive,",
        "tokens": [
          50520,
          689,
          291,
          727,
          360,
          300,
          2452,
          9192,
          11,
          50593
        ]
      },
      {
        "avg_logprob": -0.23131896124945747,
        "compression_ratio": 1.669811320754717,
        "end": 205.94,
        "id": 75,
        "no_speech_prob": 0.0003514351265039295,
        "seek": 19882,
        "start": 203.4,
        "temperature": 0,
        "text": " starting with the 3Blue1Brown video,",
        "tokens": [
          50593,
          2891,
          365,
          264,
          805,
          45231,
          16,
          22170,
          648,
          960,
          11,
          50720
        ]
      },
      {
        "avg_logprob": -0.23131896124945747,
        "compression_ratio": 1.669811320754717,
        "end": 208.7,
        "id": 76,
        "no_speech_prob": 0.0003514351265039295,
        "seek": 19882,
        "start": 205.94,
        "temperature": 0,
        "text": " what is a neural network, and some of the subsequent ones.",
        "tokens": [
          50720,
          437,
          307,
          257,
          18161,
          3209,
          11,
          293,
          512,
          295,
          264,
          19962,
          2306,
          13,
          50858
        ]
      },
      {
        "avg_logprob": -0.23131896124945747,
        "compression_ratio": 1.669811320754717,
        "end": 212.01999999999998,
        "id": 77,
        "no_speech_prob": 0.0003514351265039295,
        "seek": 19882,
        "start": 208.7,
        "temperature": 0,
        "text": " I have also a 10 to 15 part video series",
        "tokens": [
          50858,
          286,
          362,
          611,
          257,
          1266,
          281,
          2119,
          644,
          960,
          2638,
          51024
        ]
      },
      {
        "avg_logprob": -0.23131896124945747,
        "compression_ratio": 1.669811320754717,
        "end": 215.14,
        "id": 78,
        "no_speech_prob": 0.0003514351265039295,
        "seek": 19882,
        "start": 212.01999999999998,
        "temperature": 0,
        "text": " where I build a neural network from scratch in JavaScript",
        "tokens": [
          51024,
          689,
          286,
          1322,
          257,
          18161,
          3209,
          490,
          8459,
          294,
          15778,
          51180
        ]
      },
      {
        "avg_logprob": -0.23131896124945747,
        "compression_ratio": 1.669811320754717,
        "end": 217.7,
        "id": 79,
        "no_speech_prob": 0.0003514351265039295,
        "seek": 19882,
        "start": 215.14,
        "temperature": 0,
        "text": " based on a particular book called Make Your Own Neural",
        "tokens": [
          51180,
          2361,
          322,
          257,
          1729,
          1446,
          1219,
          4387,
          2260,
          25964,
          1734,
          1807,
          51308
        ]
      },
      {
        "avg_logprob": -0.23131896124945747,
        "compression_ratio": 1.669811320754717,
        "end": 219.82,
        "id": 80,
        "no_speech_prob": 0.0003514351265039295,
        "seek": 19882,
        "start": 217.7,
        "temperature": 0,
        "text": " Network that is in Python.",
        "tokens": [
          51308,
          12640,
          300,
          307,
          294,
          15329,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.23131896124945747,
        "compression_ratio": 1.669811320754717,
        "end": 223.51999999999998,
        "id": 81,
        "no_speech_prob": 0.0003514351265039295,
        "seek": 19882,
        "start": 219.82,
        "temperature": 0,
        "text": " I have other videos that are guides around machine learning",
        "tokens": [
          51414,
          286,
          362,
          661,
          2145,
          300,
          366,
          17007,
          926,
          3479,
          2539,
          51599
        ]
      },
      {
        "avg_logprob": -0.23131896124945747,
        "compression_ratio": 1.669811320754717,
        "end": 225.35999999999999,
        "id": 82,
        "no_speech_prob": 0.0003514351265039295,
        "seek": 19882,
        "start": 223.51999999999998,
        "temperature": 0,
        "text": " concepts where I talk about different kinds",
        "tokens": [
          51599,
          10392,
          689,
          286,
          751,
          466,
          819,
          3685,
          51691
        ]
      },
      {
        "avg_logprob": -0.23131896124945747,
        "compression_ratio": 1.669811320754717,
        "end": 226.45999999999998,
        "id": 83,
        "no_speech_prob": 0.0003514351265039295,
        "seek": 19882,
        "start": 225.35999999999999,
        "temperature": 0,
        "text": " of neural networks.",
        "tokens": [
          51691,
          295,
          18161,
          9590,
          13,
          51746
        ]
      },
      {
        "avg_logprob": -0.23131896124945747,
        "compression_ratio": 1.669811320754717,
        "end": 228.74,
        "id": 84,
        "no_speech_prob": 0.0003514351265039295,
        "seek": 19882,
        "start": 226.45999999999998,
        "temperature": 0,
        "text": " So I will link to all of those in this video",
        "tokens": [
          51746,
          407,
          286,
          486,
          2113,
          281,
          439,
          295,
          729,
          294,
          341,
          960,
          51860
        ]
      },
      {
        "avg_logprob": -0.22789087295532226,
        "compression_ratio": 1.608294930875576,
        "end": 229.54000000000002,
        "id": 85,
        "no_speech_prob": 0.00017674415721558034,
        "seek": 22874,
        "start": 228.74,
        "temperature": 0,
        "text": " description.",
        "tokens": [
          50364,
          3855,
          13,
          50404
        ]
      },
      {
        "avg_logprob": -0.22789087295532226,
        "compression_ratio": 1.608294930875576,
        "end": 232.78,
        "id": 86,
        "no_speech_prob": 0.00017674415721558034,
        "seek": 22874,
        "start": 229.54000000000002,
        "temperature": 0,
        "text": " But here, I'm going to use the whiteboard over here just",
        "tokens": [
          50404,
          583,
          510,
          11,
          286,
          478,
          516,
          281,
          764,
          264,
          2418,
          3787,
          670,
          510,
          445,
          50566
        ]
      },
      {
        "avg_logprob": -0.22789087295532226,
        "compression_ratio": 1.608294930875576,
        "end": 236.9,
        "id": 87,
        "no_speech_prob": 0.00017674415721558034,
        "seek": 22874,
        "start": 232.78,
        "temperature": 0,
        "text": " to give you a very zoomed out, high level overview of what",
        "tokens": [
          50566,
          281,
          976,
          291,
          257,
          588,
          8863,
          292,
          484,
          11,
          1090,
          1496,
          12492,
          295,
          437,
          50772
        ]
      },
      {
        "avg_logprob": -0.22789087295532226,
        "compression_ratio": 1.608294930875576,
        "end": 238.06,
        "id": 88,
        "no_speech_prob": 0.00017674415721558034,
        "seek": 22874,
        "start": 236.9,
        "temperature": 0,
        "text": " I'm talking about.",
        "tokens": [
          50772,
          286,
          478,
          1417,
          466,
          13,
          50830
        ]
      },
      {
        "avg_logprob": -0.22789087295532226,
        "compression_ratio": 1.608294930875576,
        "end": 241.38,
        "id": 89,
        "no_speech_prob": 0.00017674415721558034,
        "seek": 22874,
        "start": 238.06,
        "temperature": 0,
        "text": " So a machine learning system, in the most basic sense,",
        "tokens": [
          50830,
          407,
          257,
          3479,
          2539,
          1185,
          11,
          294,
          264,
          881,
          3875,
          2020,
          11,
          50996
        ]
      },
      {
        "avg_logprob": -0.22789087295532226,
        "compression_ratio": 1.608294930875576,
        "end": 247.5,
        "id": 90,
        "no_speech_prob": 0.00017674415721558034,
        "seek": 22874,
        "start": 241.38,
        "temperature": 0,
        "text": " involves inputs and outputs.",
        "tokens": [
          50996,
          11626,
          15743,
          293,
          23930,
          13,
          51302
        ]
      },
      {
        "avg_logprob": -0.22789087295532226,
        "compression_ratio": 1.608294930875576,
        "end": 251.62,
        "id": 91,
        "no_speech_prob": 0.00017674415721558034,
        "seek": 22874,
        "start": 247.5,
        "temperature": 0,
        "text": " So let's say for a moment that the goal that I have",
        "tokens": [
          51302,
          407,
          718,
          311,
          584,
          337,
          257,
          1623,
          300,
          264,
          3387,
          300,
          286,
          362,
          51508
        ]
      },
      {
        "avg_logprob": -0.22789087295532226,
        "compression_ratio": 1.608294930875576,
        "end": 254.78,
        "id": 92,
        "no_speech_prob": 0.00017674415721558034,
        "seek": 22874,
        "start": 251.62,
        "temperature": 0,
        "text": " is to train a machine learning model",
        "tokens": [
          51508,
          307,
          281,
          3847,
          257,
          3479,
          2539,
          2316,
          51666
        ]
      },
      {
        "avg_logprob": -0.22789087295532226,
        "compression_ratio": 1.608294930875576,
        "end": 258.1,
        "id": 93,
        "no_speech_prob": 0.00017674415721558034,
        "seek": 22874,
        "start": 254.78,
        "temperature": 0,
        "text": " to use my body as the input.",
        "tokens": [
          51666,
          281,
          764,
          452,
          1772,
          382,
          264,
          4846,
          13,
          51832
        ]
      },
      {
        "avg_logprob": -0.21448049683501755,
        "compression_ratio": 1.5798045602605864,
        "end": 261.14000000000004,
        "id": 94,
        "no_speech_prob": 0.000016701367712812498,
        "seek": 25810,
        "start": 258.1,
        "temperature": 0,
        "text": " So maybe how I'm moving my arms and legs and head,",
        "tokens": [
          50364,
          407,
          1310,
          577,
          286,
          478,
          2684,
          452,
          5812,
          293,
          5668,
          293,
          1378,
          11,
          50516
        ]
      },
      {
        "avg_logprob": -0.21448049683501755,
        "compression_ratio": 1.5798045602605864,
        "end": 262.3,
        "id": 95,
        "no_speech_prob": 0.000016701367712812498,
        "seek": 25810,
        "start": 261.14000000000004,
        "temperature": 0,
        "text": " that will be the input.",
        "tokens": [
          50516,
          300,
          486,
          312,
          264,
          4846,
          13,
          50574
        ]
      },
      {
        "avg_logprob": -0.21448049683501755,
        "compression_ratio": 1.5798045602605864,
        "end": 264.70000000000005,
        "id": 96,
        "no_speech_prob": 0.000016701367712812498,
        "seek": 25810,
        "start": 262.3,
        "temperature": 0,
        "text": " And the output would be a musical instrument,",
        "tokens": [
          50574,
          400,
          264,
          5598,
          576,
          312,
          257,
          9165,
          7198,
          11,
          50694
        ]
      },
      {
        "avg_logprob": -0.21448049683501755,
        "compression_ratio": 1.5798045602605864,
        "end": 266.38,
        "id": 97,
        "no_speech_prob": 0.000016701367712812498,
        "seek": 25810,
        "start": 264.70000000000005,
        "temperature": 0,
        "text": " a note that's being played.",
        "tokens": [
          50694,
          257,
          3637,
          300,
          311,
          885,
          3737,
          13,
          50778
        ]
      },
      {
        "avg_logprob": -0.21448049683501755,
        "compression_ratio": 1.5798045602605864,
        "end": 268.94,
        "id": 98,
        "no_speech_prob": 0.000016701367712812498,
        "seek": 25810,
        "start": 266.38,
        "temperature": 0,
        "text": " So I could somehow play different notes",
        "tokens": [
          50778,
          407,
          286,
          727,
          6063,
          862,
          819,
          5570,
          50906
        ]
      },
      {
        "avg_logprob": -0.21448049683501755,
        "compression_ratio": 1.5798045602605864,
        "end": 270.70000000000005,
        "id": 99,
        "no_speech_prob": 0.000016701367712812498,
        "seek": 25810,
        "start": 268.94,
        "temperature": 0,
        "text": " based on how I move my body.",
        "tokens": [
          50906,
          2361,
          322,
          577,
          286,
          1286,
          452,
          1772,
          13,
          50994
        ]
      },
      {
        "avg_logprob": -0.21448049683501755,
        "compression_ratio": 1.5798045602605864,
        "end": 273.34000000000003,
        "id": 100,
        "no_speech_prob": 0.000016701367712812498,
        "seek": 25810,
        "start": 270.70000000000005,
        "temperature": 0,
        "text": " This is a scenario that's covered in great detail",
        "tokens": [
          50994,
          639,
          307,
          257,
          9005,
          300,
          311,
          5343,
          294,
          869,
          2607,
          51126
        ]
      },
      {
        "avg_logprob": -0.21448049683501755,
        "compression_ratio": 1.5798045602605864,
        "end": 275.32000000000005,
        "id": 101,
        "no_speech_prob": 0.000016701367712812498,
        "seek": 25810,
        "start": 273.34000000000003,
        "temperature": 0,
        "text": " in Rebecca Feebrink's course, Machine Learning",
        "tokens": [
          51126,
          294,
          19381,
          479,
          1653,
          1443,
          475,
          311,
          1164,
          11,
          22155,
          15205,
          51225
        ]
      },
      {
        "avg_logprob": -0.21448049683501755,
        "compression_ratio": 1.5798045602605864,
        "end": 276.86,
        "id": 102,
        "no_speech_prob": 0.000016701367712812498,
        "seek": 25810,
        "start": 275.32000000000005,
        "temperature": 0,
        "text": " for Artists and Musicians.",
        "tokens": [
          51225,
          337,
          5735,
          1751,
          293,
          7609,
          2567,
          13,
          51302
        ]
      },
      {
        "avg_logprob": -0.21448049683501755,
        "compression_ratio": 1.5798045602605864,
        "end": 279.18,
        "id": 103,
        "no_speech_prob": 0.000016701367712812498,
        "seek": 25810,
        "start": 276.86,
        "temperature": 0,
        "text": " One way that I might boil this idea down",
        "tokens": [
          51302,
          1485,
          636,
          300,
          286,
          1062,
          13329,
          341,
          1558,
          760,
          51418
        ]
      },
      {
        "avg_logprob": -0.21448049683501755,
        "compression_ratio": 1.5798045602605864,
        "end": 284.34000000000003,
        "id": 104,
        "no_speech_prob": 0.000016701367712812498,
        "seek": 25810,
        "start": 279.18,
        "temperature": 0,
        "text": " into its very simplest version is think about a 2D canvas.",
        "tokens": [
          51418,
          666,
          1080,
          588,
          22811,
          3037,
          307,
          519,
          466,
          257,
          568,
          35,
          16267,
          13,
          51676
        ]
      },
      {
        "avg_logprob": -0.21448049683501755,
        "compression_ratio": 1.5798045602605864,
        "end": 286.26000000000005,
        "id": 105,
        "no_speech_prob": 0.000016701367712812498,
        "seek": 25810,
        "start": 284.34000000000003,
        "temperature": 0,
        "text": " And it's very convenient that I'm using P5,",
        "tokens": [
          51676,
          400,
          309,
          311,
          588,
          10851,
          300,
          286,
          478,
          1228,
          430,
          20,
          11,
          51772
        ]
      },
      {
        "avg_logprob": -0.18709940343470008,
        "compression_ratio": 1.7881944444444444,
        "end": 288.74,
        "id": 106,
        "no_speech_prob": 0.0001767447974998504,
        "seek": 28626,
        "start": 286.26,
        "temperature": 0,
        "text": " because that's the thing that exists in P5.js.",
        "tokens": [
          50364,
          570,
          300,
          311,
          264,
          551,
          300,
          8198,
          294,
          430,
          20,
          13,
          25530,
          13,
          50488
        ]
      },
      {
        "avg_logprob": -0.18709940343470008,
        "compression_ratio": 1.7881944444444444,
        "end": 290.38,
        "id": 107,
        "no_speech_prob": 0.0001767447974998504,
        "seek": 28626,
        "start": 288.74,
        "temperature": 0,
        "text": " And what I'm going to do is I'm going",
        "tokens": [
          50488,
          400,
          437,
          286,
          478,
          516,
          281,
          360,
          307,
          286,
          478,
          516,
          50570
        ]
      },
      {
        "avg_logprob": -0.18709940343470008,
        "compression_ratio": 1.7881944444444444,
        "end": 293.78,
        "id": 108,
        "no_speech_prob": 0.0001767447974998504,
        "seek": 28626,
        "start": 290.38,
        "temperature": 0,
        "text": " to say there is a mouse in that canvas.",
        "tokens": [
          50570,
          281,
          584,
          456,
          307,
          257,
          9719,
          294,
          300,
          16267,
          13,
          50740
        ]
      },
      {
        "avg_logprob": -0.18709940343470008,
        "compression_ratio": 1.7881944444444444,
        "end": 295.82,
        "id": 109,
        "no_speech_prob": 0.0001767447974998504,
        "seek": 28626,
        "start": 293.78,
        "temperature": 0,
        "text": " And the mouse is going to move around the canvas.",
        "tokens": [
          50740,
          400,
          264,
          9719,
          307,
          516,
          281,
          1286,
          926,
          264,
          16267,
          13,
          50842
        ]
      },
      {
        "avg_logprob": -0.18709940343470008,
        "compression_ratio": 1.7881944444444444,
        "end": 299.06,
        "id": 110,
        "no_speech_prob": 0.0001767447974998504,
        "seek": 28626,
        "start": 295.82,
        "temperature": 0,
        "text": " And based on where it is, it will play a particular note.",
        "tokens": [
          50842,
          400,
          2361,
          322,
          689,
          309,
          307,
          11,
          309,
          486,
          862,
          257,
          1729,
          3637,
          13,
          51004
        ]
      },
      {
        "avg_logprob": -0.18709940343470008,
        "compression_ratio": 1.7881944444444444,
        "end": 301.09999999999997,
        "id": 111,
        "no_speech_prob": 0.0001767447974998504,
        "seek": 28626,
        "start": 299.06,
        "temperature": 0,
        "text": " Now, of course, I could program this same idea",
        "tokens": [
          51004,
          823,
          11,
          295,
          1164,
          11,
          286,
          727,
          1461,
          341,
          912,
          1558,
          51106
        ]
      },
      {
        "avg_logprob": -0.18709940343470008,
        "compression_ratio": 1.7881944444444444,
        "end": 301.98,
        "id": 112,
        "no_speech_prob": 0.0001767447974998504,
        "seek": 28626,
        "start": 301.09999999999997,
        "temperature": 0,
        "text": " with an if statement.",
        "tokens": [
          51106,
          365,
          364,
          498,
          5629,
          13,
          51150
        ]
      },
      {
        "avg_logprob": -0.18709940343470008,
        "compression_ratio": 1.7881944444444444,
        "end": 305.94,
        "id": 113,
        "no_speech_prob": 0.0001767447974998504,
        "seek": 28626,
        "start": 301.98,
        "temperature": 0,
        "text": " But this is really what it means to work with machine learning.",
        "tokens": [
          51150,
          583,
          341,
          307,
          534,
          437,
          309,
          1355,
          281,
          589,
          365,
          3479,
          2539,
          13,
          51348
        ]
      },
      {
        "avg_logprob": -0.18709940343470008,
        "compression_ratio": 1.7881944444444444,
        "end": 310.4,
        "id": 114,
        "no_speech_prob": 0.0001767447974998504,
        "seek": 28626,
        "start": 305.94,
        "temperature": 0,
        "text": " Instead of programming the rules explicitly into code, what",
        "tokens": [
          51348,
          7156,
          295,
          9410,
          264,
          4474,
          20803,
          666,
          3089,
          11,
          437,
          51571
        ]
      },
      {
        "avg_logprob": -0.18709940343470008,
        "compression_ratio": 1.7881944444444444,
        "end": 314.21999999999997,
        "id": 115,
        "no_speech_prob": 0.0001767447974998504,
        "seek": 28626,
        "start": 310.4,
        "temperature": 0,
        "text": " I'm going to do is give the code a whole bunch of examples",
        "tokens": [
          51571,
          286,
          478,
          516,
          281,
          360,
          307,
          976,
          264,
          3089,
          257,
          1379,
          3840,
          295,
          5110,
          51762
        ]
      },
      {
        "avg_logprob": -0.18709940343470008,
        "compression_ratio": 1.7881944444444444,
        "end": 316.18,
        "id": 116,
        "no_speech_prob": 0.0001767447974998504,
        "seek": 28626,
        "start": 314.21999999999997,
        "temperature": 0,
        "text": " and have it learn those rules.",
        "tokens": [
          51762,
          293,
          362,
          309,
          1466,
          729,
          4474,
          13,
          51860
        ]
      },
      {
        "avg_logprob": -0.27188057595110954,
        "compression_ratio": 1.5829596412556053,
        "end": 319.54,
        "id": 117,
        "no_speech_prob": 0.000044001106289215386,
        "seek": 31618,
        "start": 316.58,
        "temperature": 0,
        "text": " So I want to demonstrate that process in a scenario",
        "tokens": [
          50384,
          407,
          286,
          528,
          281,
          11698,
          300,
          1399,
          294,
          257,
          9005,
          50532
        ]
      },
      {
        "avg_logprob": -0.27188057595110954,
        "compression_ratio": 1.5829596412556053,
        "end": 321.54,
        "id": 118,
        "no_speech_prob": 0.000044001106289215386,
        "seek": 31618,
        "start": 319.54,
        "temperature": 0,
        "text": " where it's very obvious how it's working,",
        "tokens": [
          50532,
          689,
          309,
          311,
          588,
          6322,
          577,
          309,
          311,
          1364,
          11,
          50632
        ]
      },
      {
        "avg_logprob": -0.27188057595110954,
        "compression_ratio": 1.5829596412556053,
        "end": 322.98,
        "id": 119,
        "no_speech_prob": 0.000044001106289215386,
        "seek": 31618,
        "start": 321.54,
        "temperature": 0,
        "text": " so that then we can build on that",
        "tokens": [
          50632,
          370,
          300,
          550,
          321,
          393,
          1322,
          322,
          300,
          50704
        ]
      },
      {
        "avg_logprob": -0.27188057595110954,
        "compression_ratio": 1.5829596412556053,
        "end": 324.82,
        "id": 120,
        "no_speech_prob": 0.000044001106289215386,
        "seek": 31618,
        "start": 322.98,
        "temperature": 0,
        "text": " into much more complex scenarios.",
        "tokens": [
          50704,
          666,
          709,
          544,
          3997,
          15077,
          13,
          50796
        ]
      },
      {
        "avg_logprob": -0.27188057595110954,
        "compression_ratio": 1.5829596412556053,
        "end": 337.98,
        "id": 121,
        "no_speech_prob": 0.000044001106289215386,
        "seek": 31618,
        "start": 324.82,
        "temperature": 0,
        "text": " The steps are collect data, two, train model, then three.",
        "tokens": [
          50796,
          440,
          4439,
          366,
          2500,
          1412,
          11,
          732,
          11,
          3847,
          2316,
          11,
          550,
          1045,
          13,
          51454
        ]
      },
      {
        "avg_logprob": -0.27188057595110954,
        "compression_ratio": 1.5829596412556053,
        "end": 340.62,
        "id": 122,
        "no_speech_prob": 0.000044001106289215386,
        "seek": 31618,
        "start": 337.98,
        "temperature": 0,
        "text": " I guess we can call this prediction.",
        "tokens": [
          51454,
          286,
          2041,
          321,
          393,
          818,
          341,
          17630,
          13,
          51586
        ]
      },
      {
        "avg_logprob": -0.27188057595110954,
        "compression_ratio": 1.5829596412556053,
        "end": 343.7,
        "id": 123,
        "no_speech_prob": 0.000044001106289215386,
        "seek": 31618,
        "start": 340.62,
        "temperature": 0,
        "text": " So that's also sometimes referred to as inference.",
        "tokens": [
          51586,
          407,
          300,
          311,
          611,
          2171,
          10839,
          281,
          382,
          38253,
          13,
          51740
        ]
      },
      {
        "avg_logprob": -0.27188057595110954,
        "compression_ratio": 1.5829596412556053,
        "end": 345.58,
        "id": 124,
        "no_speech_prob": 0.000044001106289215386,
        "seek": 31618,
        "start": 343.7,
        "temperature": 0,
        "text": " That's really when we're deploying the model.",
        "tokens": [
          51740,
          663,
          311,
          534,
          562,
          321,
          434,
          34198,
          264,
          2316,
          13,
          51834
        ]
      },
      {
        "avg_logprob": -0.1862320432475969,
        "compression_ratio": 1.7312775330396475,
        "end": 347.5,
        "id": 125,
        "no_speech_prob": 0.00019110372522845864,
        "seek": 34558,
        "start": 345.58,
        "temperature": 0,
        "text": " We're making use of the model.",
        "tokens": [
          50364,
          492,
          434,
          1455,
          764,
          295,
          264,
          2316,
          13,
          50460
        ]
      },
      {
        "avg_logprob": -0.1862320432475969,
        "compression_ratio": 1.7312775330396475,
        "end": 351.21999999999997,
        "id": 126,
        "no_speech_prob": 0.00019110372522845864,
        "seek": 34558,
        "start": 347.5,
        "temperature": 0,
        "text": " Right here, this is my representation of the model.",
        "tokens": [
          50460,
          1779,
          510,
          11,
          341,
          307,
          452,
          10290,
          295,
          264,
          2316,
          13,
          50646
        ]
      },
      {
        "avg_logprob": -0.1862320432475969,
        "compression_ratio": 1.7312775330396475,
        "end": 354.53999999999996,
        "id": 127,
        "no_speech_prob": 0.00019110372522845864,
        "seek": 34558,
        "start": 351.21999999999997,
        "temperature": 0,
        "text": " So in this case, if I want to start with a classification",
        "tokens": [
          50646,
          407,
          294,
          341,
          1389,
          11,
          498,
          286,
          528,
          281,
          722,
          365,
          257,
          21538,
          50812
        ]
      },
      {
        "avg_logprob": -0.1862320432475969,
        "compression_ratio": 1.7312775330396475,
        "end": 356.34,
        "id": 128,
        "no_speech_prob": 0.00019110372522845864,
        "seek": 34558,
        "start": 354.53999999999996,
        "temperature": 0,
        "text": " problem, and I will show you demonstrations",
        "tokens": [
          50812,
          1154,
          11,
          293,
          286,
          486,
          855,
          291,
          34714,
          50902
        ]
      },
      {
        "avg_logprob": -0.1862320432475969,
        "compression_ratio": 1.7312775330396475,
        "end": 359.02,
        "id": 129,
        "no_speech_prob": 0.00019110372522845864,
        "seek": 34558,
        "start": 356.34,
        "temperature": 0,
        "text": " of classification and regression,",
        "tokens": [
          50902,
          295,
          21538,
          293,
          24590,
          11,
          51036
        ]
      },
      {
        "avg_logprob": -0.1862320432475969,
        "compression_ratio": 1.7312775330396475,
        "end": 364.65999999999997,
        "id": 130,
        "no_speech_prob": 0.00019110372522845864,
        "seek": 34558,
        "start": 359.02,
        "temperature": 0,
        "text": " I'm going to have two inputs, input one and input two,",
        "tokens": [
          51036,
          286,
          478,
          516,
          281,
          362,
          732,
          15743,
          11,
          4846,
          472,
          293,
          4846,
          732,
          11,
          51318
        ]
      },
      {
        "avg_logprob": -0.1862320432475969,
        "compression_ratio": 1.7312775330396475,
        "end": 369.2,
        "id": 131,
        "no_speech_prob": 0.00019110372522845864,
        "seek": 34558,
        "start": 364.65999999999997,
        "temperature": 0,
        "text": " often referred to as x's in a machine learning context.",
        "tokens": [
          51318,
          2049,
          10839,
          281,
          382,
          2031,
          311,
          294,
          257,
          3479,
          2539,
          4319,
          13,
          51545
        ]
      },
      {
        "avg_logprob": -0.1862320432475969,
        "compression_ratio": 1.7312775330396475,
        "end": 373.78,
        "id": 132,
        "no_speech_prob": 0.00019110372522845864,
        "seek": 34558,
        "start": 369.2,
        "temperature": 0,
        "text": " Those inputs are going to go in to this machine learning model.",
        "tokens": [
          51545,
          3950,
          15743,
          366,
          516,
          281,
          352,
          294,
          281,
          341,
          3479,
          2539,
          2316,
          13,
          51774
        ]
      },
      {
        "avg_logprob": -0.2332950557043793,
        "compression_ratio": 1.6044444444444443,
        "end": 376.94,
        "id": 133,
        "no_speech_prob": 0.000007296375315490877,
        "seek": 37378,
        "start": 373.78,
        "temperature": 0,
        "text": " The output is going to be one of, let's say,",
        "tokens": [
          50364,
          440,
          5598,
          307,
          516,
          281,
          312,
          472,
          295,
          11,
          718,
          311,
          584,
          11,
          50522
        ]
      },
      {
        "avg_logprob": -0.2332950557043793,
        "compression_ratio": 1.6044444444444443,
        "end": 379.26,
        "id": 134,
        "no_speech_prob": 0.000007296375315490877,
        "seek": 37378,
        "start": 376.94,
        "temperature": 0,
        "text": " three different categories.",
        "tokens": [
          50522,
          1045,
          819,
          10479,
          13,
          50638
        ]
      },
      {
        "avg_logprob": -0.2332950557043793,
        "compression_ratio": 1.6044444444444443,
        "end": 387.58,
        "id": 135,
        "no_speech_prob": 0.000007296375315490877,
        "seek": 37378,
        "start": 379.26,
        "temperature": 0,
        "text": " So I'm going to have three outputs, C, D, and E.",
        "tokens": [
          50638,
          407,
          286,
          478,
          516,
          281,
          362,
          1045,
          23930,
          11,
          383,
          11,
          413,
          11,
          293,
          462,
          13,
          51054
        ]
      },
      {
        "avg_logprob": -0.2332950557043793,
        "compression_ratio": 1.6044444444444443,
        "end": 391.65999999999997,
        "id": 136,
        "no_speech_prob": 0.000007296375315490877,
        "seek": 37378,
        "start": 387.58,
        "temperature": 0,
        "text": " So two inputs, and in this case, three outputs.",
        "tokens": [
          51054,
          407,
          732,
          15743,
          11,
          293,
          294,
          341,
          1389,
          11,
          1045,
          23930,
          13,
          51258
        ]
      },
      {
        "avg_logprob": -0.2332950557043793,
        "compression_ratio": 1.6044444444444443,
        "end": 393.34,
        "id": 137,
        "no_speech_prob": 0.000007296375315490877,
        "seek": 37378,
        "start": 391.65999999999997,
        "temperature": 0,
        "text": " My diagram looks a little bit weird,",
        "tokens": [
          51258,
          1222,
          10686,
          1542,
          257,
          707,
          857,
          3657,
          11,
          51342
        ]
      },
      {
        "avg_logprob": -0.2332950557043793,
        "compression_ratio": 1.6044444444444443,
        "end": 395.46,
        "id": 138,
        "no_speech_prob": 0.000007296375315490877,
        "seek": 37378,
        "start": 393.34,
        "temperature": 0,
        "text": " so I'm going to fix it up for a second.",
        "tokens": [
          51342,
          370,
          286,
          478,
          516,
          281,
          3191,
          309,
          493,
          337,
          257,
          1150,
          13,
          51448
        ]
      },
      {
        "avg_logprob": -0.2332950557043793,
        "compression_ratio": 1.6044444444444443,
        "end": 397.97999999999996,
        "id": 139,
        "no_speech_prob": 0.000007296375315490877,
        "seek": 37378,
        "start": 395.46,
        "temperature": 0,
        "text": " Now, all this time, I've just been putting the letters NL",
        "tokens": [
          51448,
          823,
          11,
          439,
          341,
          565,
          11,
          286,
          600,
          445,
          668,
          3372,
          264,
          7825,
          426,
          43,
          51574
        ]
      },
      {
        "avg_logprob": -0.2332950557043793,
        "compression_ratio": 1.6044444444444443,
        "end": 400.65999999999997,
        "id": 140,
        "no_speech_prob": 0.000007296375315490877,
        "seek": 37378,
        "start": 397.97999999999996,
        "temperature": 0,
        "text": " in here for machine learning, or maybe referring to this",
        "tokens": [
          51574,
          294,
          510,
          337,
          3479,
          2539,
          11,
          420,
          1310,
          13761,
          281,
          341,
          51708
        ]
      },
      {
        "avg_logprob": -0.2327291222028835,
        "compression_ratio": 1.625,
        "end": 403.74,
        "id": 141,
        "no_speech_prob": 0.004007251933217049,
        "seek": 40066,
        "start": 400.66,
        "temperature": 0,
        "text": " as a model, because in truth, other things,",
        "tokens": [
          50364,
          382,
          257,
          2316,
          11,
          570,
          294,
          3494,
          11,
          661,
          721,
          11,
          50518
        ]
      },
      {
        "avg_logprob": -0.2327291222028835,
        "compression_ratio": 1.625,
        "end": 406.38000000000005,
        "id": 142,
        "no_speech_prob": 0.004007251933217049,
        "seek": 40066,
        "start": 403.74,
        "temperature": 0,
        "text": " other kinds of algorithms, other types of ideas",
        "tokens": [
          50518,
          661,
          3685,
          295,
          14642,
          11,
          661,
          3467,
          295,
          3487,
          50650
        ]
      },
      {
        "avg_logprob": -0.2327291222028835,
        "compression_ratio": 1.625,
        "end": 410.06,
        "id": 143,
        "no_speech_prob": 0.004007251933217049,
        "seek": 40066,
        "start": 406.38000000000005,
        "temperature": 0,
        "text": " beyond a neural network could slot in here.",
        "tokens": [
          50650,
          4399,
          257,
          18161,
          3209,
          727,
          14747,
          294,
          510,
          13,
          50834
        ]
      },
      {
        "avg_logprob": -0.2327291222028835,
        "compression_ratio": 1.625,
        "end": 414.26000000000005,
        "id": 144,
        "no_speech_prob": 0.004007251933217049,
        "seek": 40066,
        "start": 410.06,
        "temperature": 0,
        "text": " But the ML5 generic blank machine learning model",
        "tokens": [
          50834,
          583,
          264,
          21601,
          20,
          19577,
          8247,
          3479,
          2539,
          2316,
          51044
        ]
      },
      {
        "avg_logprob": -0.2327291222028835,
        "compression_ratio": 1.625,
        "end": 417.1,
        "id": 145,
        "no_speech_prob": 0.004007251933217049,
        "seek": 40066,
        "start": 414.26000000000005,
        "temperature": 0,
        "text": " that you can train is a neural network one.",
        "tokens": [
          51044,
          300,
          291,
          393,
          3847,
          307,
          257,
          18161,
          3209,
          472,
          13,
          51186
        ]
      },
      {
        "avg_logprob": -0.2327291222028835,
        "compression_ratio": 1.625,
        "end": 420.58000000000004,
        "id": 146,
        "no_speech_prob": 0.004007251933217049,
        "seek": 40066,
        "start": 417.1,
        "temperature": 0,
        "text": " So if I were to try to zoom into this for a moment, what",
        "tokens": [
          51186,
          407,
          498,
          286,
          645,
          281,
          853,
          281,
          8863,
          666,
          341,
          337,
          257,
          1623,
          11,
          437,
          51360
        ]
      },
      {
        "avg_logprob": -0.2327291222028835,
        "compression_ratio": 1.625,
        "end": 422.78000000000003,
        "id": 147,
        "no_speech_prob": 0.004007251933217049,
        "seek": 40066,
        "start": 420.58000000000004,
        "temperature": 0,
        "text": " I would actually see is something",
        "tokens": [
          51360,
          286,
          576,
          767,
          536,
          307,
          746,
          51470
        ]
      },
      {
        "avg_logprob": -0.2327291222028835,
        "compression_ratio": 1.625,
        "end": 425.38,
        "id": 148,
        "no_speech_prob": 0.004007251933217049,
        "seek": 40066,
        "start": 422.78000000000003,
        "temperature": 0,
        "text": " that looks something like this.",
        "tokens": [
          51470,
          300,
          1542,
          746,
          411,
          341,
          13,
          51600
        ]
      },
      {
        "avg_logprob": -0.4210173049063053,
        "compression_ratio": 1.691358024691358,
        "end": 429.34,
        "id": 149,
        "no_speech_prob": 0.00007368585647782311,
        "seek": 42538,
        "start": 425.38,
        "temperature": 0,
        "text": " This is my zoomed in diagram of really",
        "tokens": [
          50364,
          639,
          307,
          452,
          8863,
          292,
          294,
          10686,
          295,
          534,
          50562
        ]
      },
      {
        "avg_logprob": -0.4210173049063053,
        "compression_ratio": 1.691358024691358,
        "end": 430.9,
        "id": 150,
        "no_speech_prob": 0.00007368585647782311,
        "seek": 42538,
        "start": 429.34,
        "temperature": 0,
        "text": " what's going on in here.",
        "tokens": [
          50562,
          437,
          311,
          516,
          322,
          294,
          510,
          13,
          50640
        ]
      },
      {
        "avg_logprob": -0.4210173049063053,
        "compression_ratio": 1.691358024691358,
        "end": 434.1,
        "id": 151,
        "no_speech_prob": 0.00007368585647782311,
        "seek": 42538,
        "start": 430.9,
        "temperature": 0,
        "text": " A neural network is a network of neurons.",
        "tokens": [
          50640,
          316,
          18161,
          3209,
          307,
          257,
          3209,
          295,
          22027,
          13,
          50800
        ]
      },
      {
        "avg_logprob": -0.4210173049063053,
        "compression_ratio": 1.691358024691358,
        "end": 437.7,
        "id": 152,
        "no_speech_prob": 0.00007368585647782311,
        "seek": 42538,
        "start": 434.1,
        "temperature": 0,
        "text": " Technically, this is a feed forward multilayer perceptron,",
        "tokens": [
          50800,
          42494,
          11,
          341,
          307,
          257,
          3154,
          2128,
          2120,
          388,
          11167,
          43276,
          2044,
          11,
          50980
        ]
      },
      {
        "avg_logprob": -0.4210173049063053,
        "compression_ratio": 1.691358024691358,
        "end": 441.62,
        "id": 153,
        "no_speech_prob": 0.00007368585647782311,
        "seek": 42538,
        "start": 437.7,
        "temperature": 0,
        "text": " because the inputs, which are represented right here,",
        "tokens": [
          50980,
          570,
          264,
          15743,
          11,
          597,
          366,
          10379,
          558,
          510,
          11,
          51176
        ]
      },
      {
        "avg_logprob": -0.4210173049063053,
        "compression_ratio": 1.691358024691358,
        "end": 443.82,
        "id": 154,
        "no_speech_prob": 0.00007368585647782311,
        "seek": 42538,
        "start": 441.62,
        "temperature": 0,
        "text": " get fed through these connections,",
        "tokens": [
          51176,
          483,
          4636,
          807,
          613,
          9271,
          11,
          51286
        ]
      },
      {
        "avg_logprob": -0.4210173049063053,
        "compression_ratio": 1.691358024691358,
        "end": 446.65999999999997,
        "id": 155,
        "no_speech_prob": 0.00007368585647782311,
        "seek": 42538,
        "start": 443.82,
        "temperature": 0,
        "text": " they're weighted connections, and get added up all together",
        "tokens": [
          51286,
          436,
          434,
          32807,
          9271,
          11,
          293,
          483,
          3869,
          493,
          439,
          1214,
          51428
        ]
      },
      {
        "avg_logprob": -0.4210173049063053,
        "compression_ratio": 1.691358024691358,
        "end": 451.14,
        "id": 156,
        "no_speech_prob": 0.00007368585647782311,
        "seek": 42538,
        "start": 446.65999999999997,
        "temperature": 0,
        "text": " and arrive in this layer, which is known as the hidden layer.",
        "tokens": [
          51428,
          293,
          8881,
          294,
          341,
          4583,
          11,
          597,
          307,
          2570,
          382,
          264,
          7633,
          4583,
          13,
          51652
        ]
      },
      {
        "avg_logprob": -0.4210173049063053,
        "compression_ratio": 1.691358024691358,
        "end": 452.62,
        "id": 157,
        "no_speech_prob": 0.00007368585647782311,
        "seek": 42538,
        "start": 451.14,
        "temperature": 0,
        "text": " And they're connected to each other",
        "tokens": [
          51652,
          400,
          436,
          434,
          4582,
          281,
          1184,
          661,
          51726
        ]
      },
      {
        "avg_logprob": -0.20521949952648533,
        "compression_ratio": 2.0391304347826087,
        "end": 454.98,
        "id": 158,
        "no_speech_prob": 0.000472853280371055,
        "seek": 45262,
        "start": 452.66,
        "temperature": 0,
        "text": " which is known as the hidden layer.",
        "tokens": [
          50366,
          597,
          307,
          2570,
          382,
          264,
          7633,
          4583,
          13,
          50482
        ]
      },
      {
        "avg_logprob": -0.20521949952648533,
        "compression_ratio": 2.0391304347826087,
        "end": 457.66,
        "id": 159,
        "no_speech_prob": 0.000472853280371055,
        "seek": 45262,
        "start": 454.98,
        "temperature": 0,
        "text": " And there can be multiple hidden layers and different kinds",
        "tokens": [
          50482,
          400,
          456,
          393,
          312,
          3866,
          7633,
          7914,
          293,
          819,
          3685,
          50616
        ]
      },
      {
        "avg_logprob": -0.20521949952648533,
        "compression_ratio": 2.0391304347826087,
        "end": 461.26,
        "id": 160,
        "no_speech_prob": 0.000472853280371055,
        "seek": 45262,
        "start": 457.66,
        "temperature": 0,
        "text": " of hidden layers, but the data is summed and processed",
        "tokens": [
          50616,
          295,
          7633,
          7914,
          11,
          457,
          264,
          1412,
          307,
          2408,
          1912,
          293,
          18846,
          50796
        ]
      },
      {
        "avg_logprob": -0.20521949952648533,
        "compression_ratio": 2.0391304347826087,
        "end": 464.54,
        "id": 161,
        "no_speech_prob": 0.000472853280371055,
        "seek": 45262,
        "start": 461.26,
        "temperature": 0,
        "text": " through a mathematical function called an activation function,",
        "tokens": [
          50796,
          807,
          257,
          18894,
          2445,
          1219,
          364,
          24433,
          2445,
          11,
          50960
        ]
      },
      {
        "avg_logprob": -0.20521949952648533,
        "compression_ratio": 2.0391304347826087,
        "end": 468.7,
        "id": 162,
        "no_speech_prob": 0.000472853280371055,
        "seek": 45262,
        "start": 464.54,
        "temperature": 0,
        "text": " and then fed out of the hidden layer and into the output",
        "tokens": [
          50960,
          293,
          550,
          4636,
          484,
          295,
          264,
          7633,
          4583,
          293,
          666,
          264,
          5598,
          51168
        ]
      },
      {
        "avg_logprob": -0.20521949952648533,
        "compression_ratio": 2.0391304347826087,
        "end": 469.26,
        "id": 163,
        "no_speech_prob": 0.000472853280371055,
        "seek": 45262,
        "start": 468.7,
        "temperature": 0,
        "text": " layer.",
        "tokens": [
          51168,
          4583,
          13,
          51196
        ]
      },
      {
        "avg_logprob": -0.20521949952648533,
        "compression_ratio": 2.0391304347826087,
        "end": 472.66,
        "id": 164,
        "no_speech_prob": 0.000472853280371055,
        "seek": 45262,
        "start": 469.26,
        "temperature": 0,
        "text": " And the output layer, after all of the hidden outputs",
        "tokens": [
          51196,
          400,
          264,
          5598,
          4583,
          11,
          934,
          439,
          295,
          264,
          7633,
          23930,
          51366
        ]
      },
      {
        "avg_logprob": -0.20521949952648533,
        "compression_ratio": 2.0391304347826087,
        "end": 475.38,
        "id": 165,
        "no_speech_prob": 0.000472853280371055,
        "seek": 45262,
        "start": 472.66,
        "temperature": 0,
        "text": " are summed and passed through an activation function,",
        "tokens": [
          51366,
          366,
          2408,
          1912,
          293,
          4678,
          807,
          364,
          24433,
          2445,
          11,
          51502
        ]
      },
      {
        "avg_logprob": -0.20521949952648533,
        "compression_ratio": 2.0391304347826087,
        "end": 477.1,
        "id": 166,
        "no_speech_prob": 0.000472853280371055,
        "seek": 45262,
        "start": 475.38,
        "temperature": 0,
        "text": " we get a set of numbers out.",
        "tokens": [
          51502,
          321,
          483,
          257,
          992,
          295,
          3547,
          484,
          13,
          51588
        ]
      },
      {
        "avg_logprob": -0.20521949952648533,
        "compression_ratio": 2.0391304347826087,
        "end": 482.58,
        "id": 167,
        "no_speech_prob": 0.000472853280371055,
        "seek": 45262,
        "start": 477.1,
        "temperature": 0,
        "text": " And those numbers might look like this, 0.2, 0.7, 0.1.",
        "tokens": [
          51588,
          400,
          729,
          3547,
          1062,
          574,
          411,
          341,
          11,
          1958,
          13,
          17,
          11,
          1958,
          13,
          22,
          11,
          1958,
          13,
          16,
          13,
          51862
        ]
      },
      {
        "avg_logprob": -0.199661377937563,
        "compression_ratio": 1.7366412213740459,
        "end": 487.74,
        "id": 168,
        "no_speech_prob": 0.0000630272988928482,
        "seek": 48258,
        "start": 482.58,
        "temperature": 0,
        "text": " Meaning a 20% chance of being category C, a 70% chance",
        "tokens": [
          50364,
          19948,
          257,
          945,
          4,
          2931,
          295,
          885,
          7719,
          383,
          11,
          257,
          5285,
          4,
          2931,
          50622
        ]
      },
      {
        "avg_logprob": -0.199661377937563,
        "compression_ratio": 1.7366412213740459,
        "end": 492.46,
        "id": 169,
        "no_speech_prob": 0.0000630272988928482,
        "seek": 48258,
        "start": 487.74,
        "temperature": 0,
        "text": " of being category D, or a 10% chance of being category E.",
        "tokens": [
          50622,
          295,
          885,
          7719,
          413,
          11,
          420,
          257,
          1266,
          4,
          2931,
          295,
          885,
          7719,
          462,
          13,
          50858
        ]
      },
      {
        "avg_logprob": -0.199661377937563,
        "compression_ratio": 1.7366412213740459,
        "end": 495.9,
        "id": 170,
        "no_speech_prob": 0.0000630272988928482,
        "seek": 48258,
        "start": 492.46,
        "temperature": 0,
        "text": " So there's a lot more details of what's going on in here,",
        "tokens": [
          50858,
          407,
          456,
          311,
          257,
          688,
          544,
          4365,
          295,
          437,
          311,
          516,
          322,
          294,
          510,
          11,
          51030
        ]
      },
      {
        "avg_logprob": -0.199661377937563,
        "compression_ratio": 1.7366412213740459,
        "end": 497.82,
        "id": 171,
        "no_speech_prob": 0.0000630272988928482,
        "seek": 48258,
        "start": 495.9,
        "temperature": 0,
        "text": " and I certainly, once again, would refer you",
        "tokens": [
          51030,
          293,
          286,
          3297,
          11,
          1564,
          797,
          11,
          576,
          2864,
          291,
          51126
        ]
      },
      {
        "avg_logprob": -0.199661377937563,
        "compression_ratio": 1.7366412213740459,
        "end": 499.97999999999996,
        "id": 172,
        "no_speech_prob": 0.0000630272988928482,
        "seek": 48258,
        "start": 497.82,
        "temperature": 0,
        "text": " to the various things that I'll link in this video's",
        "tokens": [
          51126,
          281,
          264,
          3683,
          721,
          300,
          286,
          603,
          2113,
          294,
          341,
          960,
          311,
          51234
        ]
      },
      {
        "avg_logprob": -0.199661377937563,
        "compression_ratio": 1.7366412213740459,
        "end": 500.62,
        "id": 173,
        "no_speech_prob": 0.0000630272988928482,
        "seek": 48258,
        "start": 499.97999999999996,
        "temperature": 0,
        "text": " description.",
        "tokens": [
          51234,
          3855,
          13,
          51266
        ]
      },
      {
        "avg_logprob": -0.199661377937563,
        "compression_ratio": 1.7366412213740459,
        "end": 503.46,
        "id": 174,
        "no_speech_prob": 0.0000630272988928482,
        "seek": 48258,
        "start": 500.62,
        "temperature": 0,
        "text": " The idea here is that a neural network is a machine learning",
        "tokens": [
          51266,
          440,
          1558,
          510,
          307,
          300,
          257,
          18161,
          3209,
          307,
          257,
          3479,
          2539,
          51408
        ]
      },
      {
        "avg_logprob": -0.199661377937563,
        "compression_ratio": 1.7366412213740459,
        "end": 504.9,
        "id": 175,
        "no_speech_prob": 0.0000630272988928482,
        "seek": 48258,
        "start": 503.46,
        "temperature": 0,
        "text": " model that can be trained.",
        "tokens": [
          51408,
          2316,
          300,
          393,
          312,
          8895,
          13,
          51480
        ]
      },
      {
        "avg_logprob": -0.199661377937563,
        "compression_ratio": 1.7366412213740459,
        "end": 507.86,
        "id": 176,
        "no_speech_prob": 0.0000630272988928482,
        "seek": 48258,
        "start": 504.9,
        "temperature": 0,
        "text": " It can be shown a lot of examples of inputs",
        "tokens": [
          51480,
          467,
          393,
          312,
          4898,
          257,
          688,
          295,
          5110,
          295,
          15743,
          51628
        ]
      },
      {
        "avg_logprob": -0.199661377937563,
        "compression_ratio": 1.7366412213740459,
        "end": 510.29999999999995,
        "id": 177,
        "no_speech_prob": 0.0000630272988928482,
        "seek": 48258,
        "start": 507.86,
        "temperature": 0,
        "text": " with their correct corresponding outputs,",
        "tokens": [
          51628,
          365,
          641,
          3006,
          11760,
          23930,
          11,
          51750
        ]
      },
      {
        "avg_logprob": -0.25403024244678113,
        "compression_ratio": 1.706896551724138,
        "end": 512.22,
        "id": 178,
        "no_speech_prob": 0.00022693276696372777,
        "seek": 51030,
        "start": 510.3,
        "temperature": 0,
        "text": " and it can tune all of the weights",
        "tokens": [
          50364,
          293,
          309,
          393,
          10864,
          439,
          295,
          264,
          17443,
          50460
        ]
      },
      {
        "avg_logprob": -0.25403024244678113,
        "compression_ratio": 1.706896551724138,
        "end": 515.74,
        "id": 179,
        "no_speech_prob": 0.00022693276696372777,
        "seek": 51030,
        "start": 512.22,
        "temperature": 0,
        "text": " of all these connections so that when it later gets new data,",
        "tokens": [
          50460,
          295,
          439,
          613,
          9271,
          370,
          300,
          562,
          309,
          1780,
          2170,
          777,
          1412,
          11,
          50636
        ]
      },
      {
        "avg_logprob": -0.25403024244678113,
        "compression_ratio": 1.706896551724138,
        "end": 518.4,
        "id": 180,
        "no_speech_prob": 0.00022693276696372777,
        "seek": 51030,
        "start": 515.74,
        "temperature": 0,
        "text": " it can make appropriate predictions.",
        "tokens": [
          50636,
          309,
          393,
          652,
          6854,
          21264,
          13,
          50769
        ]
      },
      {
        "avg_logprob": -0.25403024244678113,
        "compression_ratio": 1.706896551724138,
        "end": 521.3,
        "id": 181,
        "no_speech_prob": 0.00022693276696372777,
        "seek": 51030,
        "start": 518.4,
        "temperature": 0,
        "text": " This is everything that the ml5 library",
        "tokens": [
          50769,
          639,
          307,
          1203,
          300,
          264,
          23271,
          20,
          6405,
          50914
        ]
      },
      {
        "avg_logprob": -0.25403024244678113,
        "compression_ratio": 1.706896551724138,
        "end": 523.22,
        "id": 182,
        "no_speech_prob": 0.00022693276696372777,
        "seek": 51030,
        "start": 521.3,
        "temperature": 0,
        "text": " will take care of for you.",
        "tokens": [
          50914,
          486,
          747,
          1127,
          295,
          337,
          291,
          13,
          51010
        ]
      },
      {
        "avg_logprob": -0.25403024244678113,
        "compression_ratio": 1.706896551724138,
        "end": 525.32,
        "id": 183,
        "no_speech_prob": 0.00022693276696372777,
        "seek": 51030,
        "start": 523.22,
        "temperature": 0,
        "text": " And for us, we're going to really just be working",
        "tokens": [
          51010,
          400,
          337,
          505,
          11,
          321,
          434,
          516,
          281,
          534,
          445,
          312,
          1364,
          51115
        ]
      },
      {
        "avg_logprob": -0.25403024244678113,
        "compression_ratio": 1.706896551724138,
        "end": 529.22,
        "id": 184,
        "no_speech_prob": 0.00022693276696372777,
        "seek": 51030,
        "start": 525.32,
        "temperature": 0,
        "text": " with the inputs and the outputs, collecting our training data,",
        "tokens": [
          51115,
          365,
          264,
          15743,
          293,
          264,
          23930,
          11,
          12510,
          527,
          3097,
          1412,
          11,
          51310
        ]
      },
      {
        "avg_logprob": -0.25403024244678113,
        "compression_ratio": 1.706896551724138,
        "end": 532.34,
        "id": 185,
        "no_speech_prob": 0.00022693276696372777,
        "seek": 51030,
        "start": 529.22,
        "temperature": 0,
        "text": " training the model, and predicting outputs.",
        "tokens": [
          51310,
          3097,
          264,
          2316,
          11,
          293,
          32884,
          23930,
          13,
          51466
        ]
      },
      {
        "avg_logprob": -0.25403024244678113,
        "compression_ratio": 1.706896551724138,
        "end": 534.42,
        "id": 186,
        "no_speech_prob": 0.00022693276696372777,
        "seek": 51030,
        "start": 532.34,
        "temperature": 0,
        "text": " Now that I've gotten through that explanation,",
        "tokens": [
          51466,
          823,
          300,
          286,
          600,
          5768,
          807,
          300,
          10835,
          11,
          51570
        ]
      },
      {
        "avg_logprob": -0.25403024244678113,
        "compression_ratio": 1.706896551724138,
        "end": 535.88,
        "id": 187,
        "no_speech_prob": 0.00022693276696372777,
        "seek": 51030,
        "start": 534.42,
        "temperature": 0,
        "text": " I really want to just write some code",
        "tokens": [
          51570,
          286,
          534,
          528,
          281,
          445,
          2464,
          512,
          3089,
          51643
        ]
      },
      {
        "avg_logprob": -0.25403024244678113,
        "compression_ratio": 1.706896551724138,
        "end": 537.94,
        "id": 188,
        "no_speech_prob": 0.00022693276696372777,
        "seek": 51030,
        "start": 535.88,
        "temperature": 0,
        "text": " and show you how this all works.",
        "tokens": [
          51643,
          293,
          855,
          291,
          577,
          341,
          439,
          1985,
          13,
          51746
        ]
      },
      {
        "avg_logprob": -0.25403024244678113,
        "compression_ratio": 1.706896551724138,
        "end": 538.98,
        "id": 189,
        "no_speech_prob": 0.00022693276696372777,
        "seek": 51030,
        "start": 537.94,
        "temperature": 0,
        "text": " Sorry to interrupt.",
        "tokens": [
          51746,
          4919,
          281,
          12729,
          13,
          51798
        ]
      },
      {
        "avg_logprob": -0.2209692717976653,
        "compression_ratio": 1.7236467236467237,
        "end": 541.66,
        "id": 190,
        "no_speech_prob": 0.00734560564160347,
        "seek": 53898,
        "start": 538.98,
        "temperature": 0,
        "text": " It is me from around four days in the future.",
        "tokens": [
          50364,
          467,
          307,
          385,
          490,
          926,
          1451,
          1708,
          294,
          264,
          2027,
          13,
          50498
        ]
      },
      {
        "avg_logprob": -0.2209692717976653,
        "compression_ratio": 1.7236467236467237,
        "end": 542.9,
        "id": 191,
        "no_speech_prob": 0.00734560564160347,
        "seek": 53898,
        "start": 541.66,
        "temperature": 0,
        "text": " I did actually continue this.",
        "tokens": [
          50498,
          286,
          630,
          767,
          2354,
          341,
          13,
          50560
        ]
      },
      {
        "avg_logprob": -0.2209692717976653,
        "compression_ratio": 1.7236467236467237,
        "end": 544.4200000000001,
        "id": 192,
        "no_speech_prob": 0.00734560564160347,
        "seek": 53898,
        "start": 542.9,
        "temperature": 0,
        "text": " This was recorded during a live stream,",
        "tokens": [
          50560,
          639,
          390,
          8287,
          1830,
          257,
          1621,
          4309,
          11,
          50636
        ]
      },
      {
        "avg_logprob": -0.2209692717976653,
        "compression_ratio": 1.7236467236467237,
        "end": 546.66,
        "id": 193,
        "no_speech_prob": 0.00734560564160347,
        "seek": 53898,
        "start": 544.4200000000001,
        "temperature": 0,
        "text": " and I did go all the way through and make this example.",
        "tokens": [
          50636,
          293,
          286,
          630,
          352,
          439,
          264,
          636,
          807,
          293,
          652,
          341,
          1365,
          13,
          50748
        ]
      },
      {
        "avg_logprob": -0.2209692717976653,
        "compression_ratio": 1.7236467236467237,
        "end": 548.54,
        "id": 194,
        "no_speech_prob": 0.00734560564160347,
        "seek": 53898,
        "start": 546.66,
        "temperature": 0,
        "text": " But I made some pretty significant errors",
        "tokens": [
          50748,
          583,
          286,
          1027,
          512,
          1238,
          4776,
          13603,
          50842
        ]
      },
      {
        "avg_logprob": -0.2209692717976653,
        "compression_ratio": 1.7236467236467237,
        "end": 550.22,
        "id": 195,
        "no_speech_prob": 0.00734560564160347,
        "seek": 53898,
        "start": 548.54,
        "temperature": 0,
        "text": " in how I use the ml5 library.",
        "tokens": [
          50842,
          294,
          577,
          286,
          764,
          264,
          23271,
          20,
          6405,
          13,
          50926
        ]
      },
      {
        "avg_logprob": -0.2209692717976653,
        "compression_ratio": 1.7236467236467237,
        "end": 554.14,
        "id": 196,
        "no_speech_prob": 0.00734560564160347,
        "seek": 53898,
        "start": 550.22,
        "temperature": 0,
        "text": " So I've come back to rerecord and try this again.",
        "tokens": [
          50926,
          407,
          286,
          600,
          808,
          646,
          281,
          46453,
          66,
          765,
          293,
          853,
          341,
          797,
          13,
          51122
        ]
      },
      {
        "avg_logprob": -0.2209692717976653,
        "compression_ratio": 1.7236467236467237,
        "end": 555.46,
        "id": 197,
        "no_speech_prob": 0.00734560564160347,
        "seek": 53898,
        "start": 554.14,
        "temperature": 0,
        "text": " I'm sure I'll make other mistakes",
        "tokens": [
          51122,
          286,
          478,
          988,
          286,
          603,
          652,
          661,
          8038,
          51188
        ]
      },
      {
        "avg_logprob": -0.2209692717976653,
        "compression_ratio": 1.7236467236467237,
        "end": 556.66,
        "id": 198,
        "no_speech_prob": 0.00734560564160347,
        "seek": 53898,
        "start": 555.46,
        "temperature": 0,
        "text": " and things will go wrong.",
        "tokens": [
          51188,
          293,
          721,
          486,
          352,
          2085,
          13,
          51248
        ]
      },
      {
        "avg_logprob": -0.2209692717976653,
        "compression_ratio": 1.7236467236467237,
        "end": 558.5,
        "id": 199,
        "no_speech_prob": 0.00734560564160347,
        "seek": 53898,
        "start": 556.66,
        "temperature": 0,
        "text": " But if you want to watch the original version,",
        "tokens": [
          51248,
          583,
          498,
          291,
          528,
          281,
          1159,
          264,
          3380,
          3037,
          11,
          51340
        ]
      },
      {
        "avg_logprob": -0.2209692717976653,
        "compression_ratio": 1.7236467236467237,
        "end": 559.62,
        "id": 200,
        "no_speech_prob": 0.00734560564160347,
        "seek": 53898,
        "start": 558.5,
        "temperature": 0,
        "text": " I'll link to that in the video's description.",
        "tokens": [
          51340,
          286,
          603,
          2113,
          281,
          300,
          294,
          264,
          960,
          311,
          3855,
          13,
          51396
        ]
      },
      {
        "avg_logprob": -0.2209692717976653,
        "compression_ratio": 1.7236467236467237,
        "end": 561.26,
        "id": 201,
        "no_speech_prob": 0.00734560564160347,
        "seek": 53898,
        "start": 559.62,
        "temperature": 0,
        "text": " But I'm going to start over right now.",
        "tokens": [
          51396,
          583,
          286,
          478,
          516,
          281,
          722,
          670,
          558,
          586,
          13,
          51478
        ]
      },
      {
        "avg_logprob": -0.2209692717976653,
        "compression_ratio": 1.7236467236467237,
        "end": 563.9200000000001,
        "id": 202,
        "no_speech_prob": 0.00734560564160347,
        "seek": 53898,
        "start": 561.26,
        "temperature": 0,
        "text": " Quickly want to point out that in addition to the p5 libraries,",
        "tokens": [
          51478,
          31800,
          528,
          281,
          935,
          484,
          300,
          294,
          4500,
          281,
          264,
          280,
          20,
          15148,
          11,
          51611
        ]
      },
      {
        "avg_logprob": -0.2209692717976653,
        "compression_ratio": 1.7236467236467237,
        "end": 568.5,
        "id": 203,
        "no_speech_prob": 0.00734560564160347,
        "seek": 53898,
        "start": 563.9200000000001,
        "temperature": 0,
        "text": " I've added a reference to the ml5 library version 0.4.2",
        "tokens": [
          51611,
          286,
          600,
          3869,
          257,
          6408,
          281,
          264,
          23271,
          20,
          6405,
          3037,
          1958,
          13,
          19,
          13,
          17,
          51840
        ]
      },
      {
        "avg_logprob": -0.17464590072631836,
        "compression_ratio": 1.7378277153558053,
        "end": 570.3,
        "id": 204,
        "no_speech_prob": 0.0026729837991297245,
        "seek": 56850,
        "start": 568.5,
        "temperature": 0,
        "text": " in index.html.",
        "tokens": [
          50364,
          294,
          8186,
          13,
          357,
          15480,
          13,
          50454
        ]
      },
      {
        "avg_logprob": -0.17464590072631836,
        "compression_ratio": 1.7378277153558053,
        "end": 574.78,
        "id": 205,
        "no_speech_prob": 0.0026729837991297245,
        "seek": 56850,
        "start": 570.3,
        "temperature": 0,
        "text": " In my blank p5 sketch, I can add an ml5 neural network.",
        "tokens": [
          50454,
          682,
          452,
          8247,
          280,
          20,
          12325,
          11,
          286,
          393,
          909,
          364,
          23271,
          20,
          18161,
          3209,
          13,
          50678
        ]
      },
      {
        "avg_logprob": -0.17464590072631836,
        "compression_ratio": 1.7378277153558053,
        "end": 575.94,
        "id": 206,
        "no_speech_prob": 0.0026729837991297245,
        "seek": 56850,
        "start": 574.78,
        "temperature": 0,
        "text": " So I need a new variable.",
        "tokens": [
          50678,
          407,
          286,
          643,
          257,
          777,
          7006,
          13,
          50736
        ]
      },
      {
        "avg_logprob": -0.17464590072631836,
        "compression_ratio": 1.7378277153558053,
        "end": 579.38,
        "id": 207,
        "no_speech_prob": 0.0026729837991297245,
        "seek": 56850,
        "start": 575.94,
        "temperature": 0,
        "text": " I'm going to call that model.",
        "tokens": [
          50736,
          286,
          478,
          516,
          281,
          818,
          300,
          2316,
          13,
          50908
        ]
      },
      {
        "avg_logprob": -0.17464590072631836,
        "compression_ratio": 1.7378277153558053,
        "end": 583.66,
        "id": 208,
        "no_speech_prob": 0.0026729837991297245,
        "seek": 56850,
        "start": 579.38,
        "temperature": 0,
        "text": " And I'm going to set that model equal to ml5.neuralnetwork.",
        "tokens": [
          50908,
          400,
          286,
          478,
          516,
          281,
          992,
          300,
          2316,
          2681,
          281,
          23271,
          20,
          13,
          716,
          1807,
          7129,
          1902,
          13,
          51122
        ]
      },
      {
        "avg_logprob": -0.17464590072631836,
        "compression_ratio": 1.7378277153558053,
        "end": 586.3,
        "id": 209,
        "no_speech_prob": 0.0026729837991297245,
        "seek": 56850,
        "start": 583.66,
        "temperature": 0,
        "text": " Whenever I create a neural network object,",
        "tokens": [
          51122,
          14159,
          286,
          1884,
          257,
          18161,
          3209,
          2657,
          11,
          51254
        ]
      },
      {
        "avg_logprob": -0.17464590072631836,
        "compression_ratio": 1.7378277153558053,
        "end": 587.26,
        "id": 210,
        "no_speech_prob": 0.0026729837991297245,
        "seek": 56850,
        "start": 586.3,
        "temperature": 0,
        "text": " I need to configure it.",
        "tokens": [
          51254,
          286,
          643,
          281,
          22162,
          309,
          13,
          51302
        ]
      },
      {
        "avg_logprob": -0.17464590072631836,
        "compression_ratio": 1.7378277153558053,
        "end": 589.26,
        "id": 211,
        "no_speech_prob": 0.0026729837991297245,
        "seek": 56850,
        "start": 587.26,
        "temperature": 0,
        "text": " I need to give it some information about what's",
        "tokens": [
          51302,
          286,
          643,
          281,
          976,
          309,
          512,
          1589,
          466,
          437,
          311,
          51402
        ]
      },
      {
        "avg_logprob": -0.17464590072631836,
        "compression_ratio": 1.7378277153558053,
        "end": 590.46,
        "id": 212,
        "no_speech_prob": 0.0026729837991297245,
        "seek": 56850,
        "start": 589.26,
        "temperature": 0,
        "text": " going inside there.",
        "tokens": [
          51402,
          516,
          1854,
          456,
          13,
          51462
        ]
      },
      {
        "avg_logprob": -0.17464590072631836,
        "compression_ratio": 1.7378277153558053,
        "end": 593.82,
        "id": 213,
        "no_speech_prob": 0.0026729837991297245,
        "seek": 56850,
        "start": 590.46,
        "temperature": 0,
        "text": " And the guide for doing this is the ml5 website.",
        "tokens": [
          51462,
          400,
          264,
          5934,
          337,
          884,
          341,
          307,
          264,
          23271,
          20,
          3144,
          13,
          51630
        ]
      },
      {
        "avg_logprob": -0.17464590072631836,
        "compression_ratio": 1.7378277153558053,
        "end": 595.34,
        "id": 214,
        "no_speech_prob": 0.0026729837991297245,
        "seek": 56850,
        "start": 593.82,
        "temperature": 0,
        "text": " So here on the ml5 website, you can",
        "tokens": [
          51630,
          407,
          510,
          322,
          264,
          23271,
          20,
          3144,
          11,
          291,
          393,
          51706
        ]
      },
      {
        "avg_logprob": -0.17464590072631836,
        "compression_ratio": 1.7378277153558053,
        "end": 598.38,
        "id": 215,
        "no_speech_prob": 0.0026729837991297245,
        "seek": 56850,
        "start": 595.34,
        "temperature": 0,
        "text": " see this quick start, which has some sort of sample code,",
        "tokens": [
          51706,
          536,
          341,
          1702,
          722,
          11,
          597,
          575,
          512,
          1333,
          295,
          6889,
          3089,
          11,
          51858
        ]
      },
      {
        "avg_logprob": -0.205505603292714,
        "compression_ratio": 1.7098039215686274,
        "end": 601.58,
        "id": 216,
        "no_speech_prob": 0.00015356212679762393,
        "seek": 59838,
        "start": 598.42,
        "temperature": 0,
        "text": " some documentation of the usage of the neural network function,",
        "tokens": [
          50366,
          512,
          14333,
          295,
          264,
          14924,
          295,
          264,
          18161,
          3209,
          2445,
          11,
          50524
        ]
      },
      {
        "avg_logprob": -0.205505603292714,
        "compression_ratio": 1.7098039215686274,
        "end": 604.9,
        "id": 217,
        "no_speech_prob": 0.00015356212679762393,
        "seek": 59838,
        "start": 601.58,
        "temperature": 0,
        "text": " and a bunch of different ways of initializing a neural network.",
        "tokens": [
          50524,
          293,
          257,
          3840,
          295,
          819,
          2098,
          295,
          5883,
          3319,
          257,
          18161,
          3209,
          13,
          50690
        ]
      },
      {
        "avg_logprob": -0.205505603292714,
        "compression_ratio": 1.7098039215686274,
        "end": 608.14,
        "id": 218,
        "no_speech_prob": 0.00015356212679762393,
        "seek": 59838,
        "start": 604.9,
        "temperature": 0,
        "text": " And all of these involve a variable called options.",
        "tokens": [
          50690,
          400,
          439,
          295,
          613,
          9494,
          257,
          7006,
          1219,
          3956,
          13,
          50852
        ]
      },
      {
        "avg_logprob": -0.205505603292714,
        "compression_ratio": 1.7098039215686274,
        "end": 611.26,
        "id": 219,
        "no_speech_prob": 0.00015356212679762393,
        "seek": 59838,
        "start": 608.14,
        "temperature": 0,
        "text": " The idea is that I'm creating an object that's",
        "tokens": [
          50852,
          440,
          1558,
          307,
          300,
          286,
          478,
          4084,
          364,
          2657,
          300,
          311,
          51008
        ]
      },
      {
        "avg_logprob": -0.205505603292714,
        "compression_ratio": 1.7098039215686274,
        "end": 614.78,
        "id": 220,
        "no_speech_prob": 0.00015356212679762393,
        "seek": 59838,
        "start": 611.26,
        "temperature": 0,
        "text": " going to store the properties of the neural network.",
        "tokens": [
          51008,
          516,
          281,
          3531,
          264,
          7221,
          295,
          264,
          18161,
          3209,
          13,
          51184
        ]
      },
      {
        "avg_logprob": -0.205505603292714,
        "compression_ratio": 1.7098039215686274,
        "end": 617.18,
        "id": 221,
        "no_speech_prob": 0.00015356212679762393,
        "seek": 59838,
        "start": 614.78,
        "temperature": 0,
        "text": " And then when I call ml5.neuralnetwork,",
        "tokens": [
          51184,
          400,
          550,
          562,
          286,
          818,
          23271,
          20,
          13,
          716,
          1807,
          7129,
          1902,
          11,
          51304
        ]
      },
      {
        "avg_logprob": -0.205505603292714,
        "compression_ratio": 1.7098039215686274,
        "end": 618.9399999999999,
        "id": 222,
        "no_speech_prob": 0.00015356212679762393,
        "seek": 59838,
        "start": 617.18,
        "temperature": 0,
        "text": " I pass that object in.",
        "tokens": [
          51304,
          286,
          1320,
          300,
          2657,
          294,
          13,
          51392
        ]
      },
      {
        "avg_logprob": -0.205505603292714,
        "compression_ratio": 1.7098039215686274,
        "end": 622.22,
        "id": 223,
        "no_speech_prob": 0.00015356212679762393,
        "seek": 59838,
        "start": 618.9399999999999,
        "temperature": 0,
        "text": " So for example, looking here at my diagram,",
        "tokens": [
          51392,
          407,
          337,
          1365,
          11,
          1237,
          510,
          412,
          452,
          10686,
          11,
          51556
        ]
      },
      {
        "avg_logprob": -0.205505603292714,
        "compression_ratio": 1.7098039215686274,
        "end": 626.7,
        "id": 224,
        "no_speech_prob": 0.00015356212679762393,
        "seek": 59838,
        "start": 622.22,
        "temperature": 0,
        "text": " I can see there are two inputs and three outputs.",
        "tokens": [
          51556,
          286,
          393,
          536,
          456,
          366,
          732,
          15743,
          293,
          1045,
          23930,
          13,
          51780
        ]
      },
      {
        "avg_logprob": -0.18186294849102314,
        "compression_ratio": 1.6521739130434783,
        "end": 629.62,
        "id": 225,
        "no_speech_prob": 0.0010005016811192036,
        "seek": 62670,
        "start": 626.7,
        "temperature": 0,
        "text": " That's something that I could configure in the options.",
        "tokens": [
          50364,
          663,
          311,
          746,
          300,
          286,
          727,
          22162,
          294,
          264,
          3956,
          13,
          50510
        ]
      },
      {
        "avg_logprob": -0.18186294849102314,
        "compression_ratio": 1.6521739130434783,
        "end": 633.58,
        "id": 226,
        "no_speech_prob": 0.0010005016811192036,
        "seek": 62670,
        "start": 629.62,
        "temperature": 0,
        "text": " Inputs 2, outputs 3.",
        "tokens": [
          50510,
          682,
          2582,
          82,
          568,
          11,
          23930,
          805,
          13,
          50708
        ]
      },
      {
        "avg_logprob": -0.18186294849102314,
        "compression_ratio": 1.6521739130434783,
        "end": 635.3000000000001,
        "id": 227,
        "no_speech_prob": 0.0010005016811192036,
        "seek": 62670,
        "start": 633.58,
        "temperature": 0,
        "text": " At a minimum, this is all you need",
        "tokens": [
          50708,
          1711,
          257,
          7285,
          11,
          341,
          307,
          439,
          291,
          643,
          50794
        ]
      },
      {
        "avg_logprob": -0.18186294849102314,
        "compression_ratio": 1.6521739130434783,
        "end": 637.46,
        "id": 228,
        "no_speech_prob": 0.0010005016811192036,
        "seek": 62670,
        "start": 635.3000000000001,
        "temperature": 0,
        "text": " to configure an ml5 neural network.",
        "tokens": [
          50794,
          281,
          22162,
          364,
          23271,
          20,
          18161,
          3209,
          13,
          50902
        ]
      },
      {
        "avg_logprob": -0.18186294849102314,
        "compression_ratio": 1.6521739130434783,
        "end": 638.26,
        "id": 229,
        "no_speech_prob": 0.0010005016811192036,
        "seek": 62670,
        "start": 637.46,
        "temperature": 0,
        "text": " How many inputs?",
        "tokens": [
          50902,
          1012,
          867,
          15743,
          30,
          50942
        ]
      },
      {
        "avg_logprob": -0.18186294849102314,
        "compression_ratio": 1.6521739130434783,
        "end": 639.3000000000001,
        "id": 230,
        "no_speech_prob": 0.0010005016811192036,
        "seek": 62670,
        "start": 638.26,
        "temperature": 0,
        "text": " How many outputs?",
        "tokens": [
          50942,
          1012,
          867,
          23930,
          30,
          50994
        ]
      },
      {
        "avg_logprob": -0.18186294849102314,
        "compression_ratio": 1.6521739130434783,
        "end": 641.7,
        "id": 231,
        "no_speech_prob": 0.0010005016811192036,
        "seek": 62670,
        "start": 639.3000000000001,
        "temperature": 0,
        "text": " If I scroll through the ml5 documentation page,",
        "tokens": [
          50994,
          759,
          286,
          11369,
          807,
          264,
          23271,
          20,
          14333,
          3028,
          11,
          51114
        ]
      },
      {
        "avg_logprob": -0.18186294849102314,
        "compression_ratio": 1.6521739130434783,
        "end": 644.1400000000001,
        "id": 232,
        "no_speech_prob": 0.0010005016811192036,
        "seek": 62670,
        "start": 641.7,
        "temperature": 0,
        "text": " you'll see there are a variety of other ways",
        "tokens": [
          51114,
          291,
          603,
          536,
          456,
          366,
          257,
          5673,
          295,
          661,
          2098,
          51236
        ]
      },
      {
        "avg_logprob": -0.18186294849102314,
        "compression_ratio": 1.6521739130434783,
        "end": 646.1,
        "id": 233,
        "no_speech_prob": 0.0010005016811192036,
        "seek": 62670,
        "start": 644.1400000000001,
        "temperature": 0,
        "text": " that I could configure a neural network.",
        "tokens": [
          51236,
          300,
          286,
          727,
          22162,
          257,
          18161,
          3209,
          13,
          51334
        ]
      },
      {
        "avg_logprob": -0.18186294849102314,
        "compression_ratio": 1.6521739130434783,
        "end": 648.5,
        "id": 234,
        "no_speech_prob": 0.0010005016811192036,
        "seek": 62670,
        "start": 646.1,
        "temperature": 0,
        "text": " For example, I can actually give it a data file.",
        "tokens": [
          51334,
          1171,
          1365,
          11,
          286,
          393,
          767,
          976,
          309,
          257,
          1412,
          3991,
          13,
          51454
        ]
      },
      {
        "avg_logprob": -0.18186294849102314,
        "compression_ratio": 1.6521739130434783,
        "end": 650.7800000000001,
        "id": 235,
        "no_speech_prob": 0.0010005016811192036,
        "seek": 62670,
        "start": 648.5,
        "temperature": 0,
        "text": " So ml5 has functionality built into it",
        "tokens": [
          51454,
          407,
          23271,
          20,
          575,
          14980,
          3094,
          666,
          309,
          51568
        ]
      },
      {
        "avg_logprob": -0.18186294849102314,
        "compression_ratio": 1.6521739130434783,
        "end": 653.7,
        "id": 236,
        "no_speech_prob": 0.0010005016811192036,
        "seek": 62670,
        "start": 650.7800000000001,
        "temperature": 0,
        "text": " that can take a CSV, or comma separated value file,",
        "tokens": [
          51568,
          300,
          393,
          747,
          257,
          48814,
          11,
          420,
          22117,
          12005,
          2158,
          3991,
          11,
          51714
        ]
      },
      {
        "avg_logprob": -0.19737827076631434,
        "compression_ratio": 1.7925170068027212,
        "end": 656.74,
        "id": 237,
        "no_speech_prob": 0.00955931842327118,
        "seek": 65370,
        "start": 653.7,
        "temperature": 0,
        "text": " or a JSON data file, and configure inputs and outputs",
        "tokens": [
          50364,
          420,
          257,
          31828,
          1412,
          3991,
          11,
          293,
          22162,
          15743,
          293,
          23930,
          50516
        ]
      },
      {
        "avg_logprob": -0.19737827076631434,
        "compression_ratio": 1.7925170068027212,
        "end": 658.1,
        "id": 238,
        "no_speech_prob": 0.00955931842327118,
        "seek": 65370,
        "start": 656.74,
        "temperature": 0,
        "text": " based on what's in that file.",
        "tokens": [
          50516,
          2361,
          322,
          437,
          311,
          294,
          300,
          3991,
          13,
          50584
        ]
      },
      {
        "avg_logprob": -0.19737827076631434,
        "compression_ratio": 1.7925170068027212,
        "end": 659.76,
        "id": 239,
        "no_speech_prob": 0.00955931842327118,
        "seek": 65370,
        "start": 658.1,
        "temperature": 0,
        "text": " So I need to come back to that and cover",
        "tokens": [
          50584,
          407,
          286,
          643,
          281,
          808,
          646,
          281,
          300,
          293,
          2060,
          50667
        ]
      },
      {
        "avg_logprob": -0.19737827076631434,
        "compression_ratio": 1.7925170068027212,
        "end": 660.86,
        "id": 240,
        "no_speech_prob": 0.00955931842327118,
        "seek": 65370,
        "start": 659.76,
        "temperature": 0,
        "text": " that in a separate video.",
        "tokens": [
          50667,
          300,
          294,
          257,
          4994,
          960,
          13,
          50722
        ]
      },
      {
        "avg_logprob": -0.19737827076631434,
        "compression_ratio": 1.7925170068027212,
        "end": 663.22,
        "id": 241,
        "no_speech_prob": 0.00955931842327118,
        "seek": 65370,
        "start": 660.86,
        "temperature": 0,
        "text": " But actually, the way that I want to do it here",
        "tokens": [
          50722,
          583,
          767,
          11,
          264,
          636,
          300,
          286,
          528,
          281,
          360,
          309,
          510,
          50840
        ]
      },
      {
        "avg_logprob": -0.19737827076631434,
        "compression_ratio": 1.7925170068027212,
        "end": 665.5400000000001,
        "id": 242,
        "no_speech_prob": 0.00955931842327118,
        "seek": 65370,
        "start": 663.22,
        "temperature": 0,
        "text": " is actually this particular way.",
        "tokens": [
          50840,
          307,
          767,
          341,
          1729,
          636,
          13,
          50956
        ]
      },
      {
        "avg_logprob": -0.19737827076631434,
        "compression_ratio": 1.7925170068027212,
        "end": 668.22,
        "id": 243,
        "no_speech_prob": 0.00955931842327118,
        "seek": 65370,
        "start": 665.5400000000001,
        "temperature": 0,
        "text": " Instead of specifying the number of inputs",
        "tokens": [
          50956,
          7156,
          295,
          1608,
          5489,
          264,
          1230,
          295,
          15743,
          51090
        ]
      },
      {
        "avg_logprob": -0.19737827076631434,
        "compression_ratio": 1.7925170068027212,
        "end": 670.86,
        "id": 244,
        "no_speech_prob": 0.00955931842327118,
        "seek": 65370,
        "start": 668.22,
        "temperature": 0,
        "text": " and the number of outputs, it's much more convenient for me",
        "tokens": [
          51090,
          293,
          264,
          1230,
          295,
          23930,
          11,
          309,
          311,
          709,
          544,
          10851,
          337,
          385,
          51222
        ]
      },
      {
        "avg_logprob": -0.19737827076631434,
        "compression_ratio": 1.7925170068027212,
        "end": 671.94,
        "id": 245,
        "no_speech_prob": 0.00955931842327118,
        "seek": 65370,
        "start": 670.86,
        "temperature": 0,
        "text": " to name them.",
        "tokens": [
          51222,
          281,
          1315,
          552,
          13,
          51276
        ]
      },
      {
        "avg_logprob": -0.19737827076631434,
        "compression_ratio": 1.7925170068027212,
        "end": 674.0600000000001,
        "id": 246,
        "no_speech_prob": 0.00955931842327118,
        "seek": 65370,
        "start": 671.94,
        "temperature": 0,
        "text": " So here are the inputs, an x and the y.",
        "tokens": [
          51276,
          407,
          510,
          366,
          264,
          15743,
          11,
          364,
          2031,
          293,
          264,
          288,
          13,
          51382
        ]
      },
      {
        "avg_logprob": -0.19737827076631434,
        "compression_ratio": 1.7925170068027212,
        "end": 676.62,
        "id": 247,
        "no_speech_prob": 0.00955931842327118,
        "seek": 65370,
        "start": 674.0600000000001,
        "temperature": 0,
        "text": " And here are the outputs, a label.",
        "tokens": [
          51382,
          400,
          510,
          366,
          264,
          23930,
          11,
          257,
          7645,
          13,
          51510
        ]
      },
      {
        "avg_logprob": -0.19737827076631434,
        "compression_ratio": 1.7925170068027212,
        "end": 679.6400000000001,
        "id": 248,
        "no_speech_prob": 0.00955931842327118,
        "seek": 65370,
        "start": 676.62,
        "temperature": 0,
        "text": " Now, this is not something that the actual mechanics",
        "tokens": [
          51510,
          823,
          11,
          341,
          307,
          406,
          746,
          300,
          264,
          3539,
          12939,
          51661
        ]
      },
      {
        "avg_logprob": -0.19737827076631434,
        "compression_ratio": 1.7925170068027212,
        "end": 681.0600000000001,
        "id": 249,
        "no_speech_prob": 0.00955931842327118,
        "seek": 65370,
        "start": 679.6400000000001,
        "temperature": 0,
        "text": " of a neural network uses.",
        "tokens": [
          51661,
          295,
          257,
          18161,
          3209,
          4960,
          13,
          51732
        ]
      },
      {
        "avg_logprob": -0.19737827076631434,
        "compression_ratio": 1.7925170068027212,
        "end": 682.26,
        "id": 250,
        "no_speech_prob": 0.00955931842327118,
        "seek": 65370,
        "start": 681.0600000000001,
        "temperature": 0,
        "text": " Inputs don't have names.",
        "tokens": [
          51732,
          682,
          2582,
          82,
          500,
          380,
          362,
          5288,
          13,
          51792
        ]
      },
      {
        "avg_logprob": -0.20308524540492467,
        "compression_ratio": 1.7198581560283688,
        "end": 683.7,
        "id": 251,
        "no_speech_prob": 0.003945384174585342,
        "seek": 68226,
        "start": 682.26,
        "temperature": 0,
        "text": " Outputs don't have names.",
        "tokens": [
          50364,
          5925,
          2582,
          82,
          500,
          380,
          362,
          5288,
          13,
          50436
        ]
      },
      {
        "avg_logprob": -0.20308524540492467,
        "compression_ratio": 1.7198581560283688,
        "end": 686.66,
        "id": 252,
        "no_speech_prob": 0.003945384174585342,
        "seek": 68226,
        "start": 683.7,
        "temperature": 0,
        "text": " These are just numbers flowing through this feedforward",
        "tokens": [
          50436,
          1981,
          366,
          445,
          3547,
          13974,
          807,
          341,
          3154,
          13305,
          50584
        ]
      },
      {
        "avg_logprob": -0.20308524540492467,
        "compression_ratio": 1.7198581560283688,
        "end": 687.18,
        "id": 253,
        "no_speech_prob": 0.003945384174585342,
        "seek": 68226,
        "start": 686.66,
        "temperature": 0,
        "text": " network.",
        "tokens": [
          50584,
          3209,
          13,
          50610
        ]
      },
      {
        "avg_logprob": -0.20308524540492467,
        "compression_ratio": 1.7198581560283688,
        "end": 689.14,
        "id": 254,
        "no_speech_prob": 0.003945384174585342,
        "seek": 68226,
        "start": 687.18,
        "temperature": 0,
        "text": " But for us, from a zoomed out view,",
        "tokens": [
          50610,
          583,
          337,
          505,
          11,
          490,
          257,
          8863,
          292,
          484,
          1910,
          11,
          50708
        ]
      },
      {
        "avg_logprob": -0.20308524540492467,
        "compression_ratio": 1.7198581560283688,
        "end": 690.92,
        "id": 255,
        "no_speech_prob": 0.003945384174585342,
        "seek": 68226,
        "start": 689.14,
        "temperature": 0,
        "text": " we can maintain the neural network",
        "tokens": [
          50708,
          321,
          393,
          6909,
          264,
          18161,
          3209,
          50797
        ]
      },
      {
        "avg_logprob": -0.20308524540492467,
        "compression_ratio": 1.7198581560283688,
        "end": 693.5,
        "id": 256,
        "no_speech_prob": 0.003945384174585342,
        "seek": 68226,
        "start": 690.92,
        "temperature": 0,
        "text": " and use it more easily by naming things.",
        "tokens": [
          50797,
          293,
          764,
          309,
          544,
          3612,
          538,
          25290,
          721,
          13,
          50926
        ]
      },
      {
        "avg_logprob": -0.20308524540492467,
        "compression_ratio": 1.7198581560283688,
        "end": 697.26,
        "id": 257,
        "no_speech_prob": 0.003945384174585342,
        "seek": 68226,
        "start": 693.5,
        "temperature": 0,
        "text": " Adjusting that in the code, I'll have an x and a y.",
        "tokens": [
          50926,
          34049,
          278,
          300,
          294,
          264,
          3089,
          11,
          286,
          603,
          362,
          364,
          2031,
          293,
          257,
          288,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.20308524540492467,
        "compression_ratio": 1.7198581560283688,
        "end": 698.46,
        "id": 258,
        "no_speech_prob": 0.003945384174585342,
        "seek": 68226,
        "start": 697.26,
        "temperature": 0,
        "text": " These are my inputs.",
        "tokens": [
          51114,
          1981,
          366,
          452,
          15743,
          13,
          51174
        ]
      },
      {
        "avg_logprob": -0.20308524540492467,
        "compression_ratio": 1.7198581560283688,
        "end": 700.8199999999999,
        "id": 259,
        "no_speech_prob": 0.003945384174585342,
        "seek": 68226,
        "start": 698.46,
        "temperature": 0,
        "text": " There's two, and they have names, x and y.",
        "tokens": [
          51174,
          821,
          311,
          732,
          11,
          293,
          436,
          362,
          5288,
          11,
          2031,
          293,
          288,
          13,
          51292
        ]
      },
      {
        "avg_logprob": -0.20308524540492467,
        "compression_ratio": 1.7198581560283688,
        "end": 702.74,
        "id": 260,
        "no_speech_prob": 0.003945384174585342,
        "seek": 68226,
        "start": 700.8199999999999,
        "temperature": 0,
        "text": " The really confusing thing here is",
        "tokens": [
          51292,
          440,
          534,
          13181,
          551,
          510,
          307,
          51388
        ]
      },
      {
        "avg_logprob": -0.20308524540492467,
        "compression_ratio": 1.7198581560283688,
        "end": 704.54,
        "id": 261,
        "no_speech_prob": 0.003945384174585342,
        "seek": 68226,
        "start": 702.74,
        "temperature": 0,
        "text": " what to do about the outputs.",
        "tokens": [
          51388,
          437,
          281,
          360,
          466,
          264,
          23930,
          13,
          51478
        ]
      },
      {
        "avg_logprob": -0.20308524540492467,
        "compression_ratio": 1.7198581560283688,
        "end": 707.4399999999999,
        "id": 262,
        "no_speech_prob": 0.003945384174585342,
        "seek": 68226,
        "start": 704.54,
        "temperature": 0,
        "text": " So while technically speaking, the way I diagram this",
        "tokens": [
          51478,
          407,
          1339,
          12120,
          4124,
          11,
          264,
          636,
          286,
          10686,
          341,
          51623
        ]
      },
      {
        "avg_logprob": -0.20308524540492467,
        "compression_ratio": 1.7198581560283688,
        "end": 711.14,
        "id": 263,
        "no_speech_prob": 0.003945384174585342,
        "seek": 68226,
        "start": 707.4399999999999,
        "temperature": 0,
        "text": " is correct, and there are three output neurons,",
        "tokens": [
          51623,
          307,
          3006,
          11,
          293,
          456,
          366,
          1045,
          5598,
          22027,
          11,
          51808
        ]
      },
      {
        "avg_logprob": -0.19366358851527307,
        "compression_ratio": 1.5681818181818181,
        "end": 714.54,
        "id": 264,
        "no_speech_prob": 0.00015843594155739993,
        "seek": 71114,
        "start": 711.14,
        "temperature": 0,
        "text": " each scoring a probability for all three categories.",
        "tokens": [
          50364,
          1184,
          22358,
          257,
          8482,
          337,
          439,
          1045,
          10479,
          13,
          50534
        ]
      },
      {
        "avg_logprob": -0.19366358851527307,
        "compression_ratio": 1.5681818181818181,
        "end": 716.9399999999999,
        "id": 265,
        "no_speech_prob": 0.00015843594155739993,
        "seek": 71114,
        "start": 714.54,
        "temperature": 0,
        "text": " From the zoomed out view, we can think of it",
        "tokens": [
          50534,
          3358,
          264,
          8863,
          292,
          484,
          1910,
          11,
          321,
          393,
          519,
          295,
          309,
          50654
        ]
      },
      {
        "avg_logprob": -0.19366358851527307,
        "compression_ratio": 1.5681818181818181,
        "end": 720.8199999999999,
        "id": 266,
        "no_speech_prob": 0.00015843594155739993,
        "seek": 71114,
        "start": 716.9399999999999,
        "temperature": 0,
        "text": " as the neural network ending up with one singular result.",
        "tokens": [
          50654,
          382,
          264,
          18161,
          3209,
          8121,
          493,
          365,
          472,
          20010,
          1874,
          13,
          50848
        ]
      },
      {
        "avg_logprob": -0.19366358851527307,
        "compression_ratio": 1.5681818181818181,
        "end": 724.66,
        "id": 267,
        "no_speech_prob": 0.00015843594155739993,
        "seek": 71114,
        "start": 720.8199999999999,
        "temperature": 0,
        "text": " What is the label it's classified the input data in?",
        "tokens": [
          50848,
          708,
          307,
          264,
          7645,
          309,
          311,
          20627,
          264,
          4846,
          1412,
          294,
          30,
          51040
        ]
      },
      {
        "avg_logprob": -0.19366358851527307,
        "compression_ratio": 1.5681818181818181,
        "end": 729.26,
        "id": 268,
        "no_speech_prob": 0.00015843594155739993,
        "seek": 71114,
        "start": 724.66,
        "temperature": 0,
        "text": " So ML5 is going to handle the number of categories",
        "tokens": [
          51040,
          407,
          21601,
          20,
          307,
          516,
          281,
          4813,
          264,
          1230,
          295,
          10479,
          51270
        ]
      },
      {
        "avg_logprob": -0.19366358851527307,
        "compression_ratio": 1.5681818181818181,
        "end": 731.14,
        "id": 269,
        "no_speech_prob": 0.00015843594155739993,
        "seek": 71114,
        "start": 729.26,
        "temperature": 0,
        "text": " and how to score all those things for you.",
        "tokens": [
          51270,
          293,
          577,
          281,
          6175,
          439,
          729,
          721,
          337,
          291,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.19366358851527307,
        "compression_ratio": 1.5681818181818181,
        "end": 734.38,
        "id": 270,
        "no_speech_prob": 0.00015843594155739993,
        "seek": 71114,
        "start": 731.14,
        "temperature": 0,
        "text": " So if we're naming stuff, I can actually just right here",
        "tokens": [
          51364,
          407,
          498,
          321,
          434,
          25290,
          1507,
          11,
          286,
          393,
          767,
          445,
          558,
          510,
          51526
        ]
      },
      {
        "avg_logprob": -0.19366358851527307,
        "compression_ratio": 1.5681818181818181,
        "end": 737.02,
        "id": 271,
        "no_speech_prob": 0.00015843594155739993,
        "seek": 71114,
        "start": 734.38,
        "temperature": 0,
        "text": " say label.",
        "tokens": [
          51526,
          584,
          7645,
          13,
          51658
        ]
      },
      {
        "avg_logprob": -0.19366358851527307,
        "compression_ratio": 1.5681818181818181,
        "end": 739.38,
        "id": 272,
        "no_speech_prob": 0.00015843594155739993,
        "seek": 71114,
        "start": 737.02,
        "temperature": 0,
        "text": " And as I start to create the training data,",
        "tokens": [
          51658,
          400,
          382,
          286,
          722,
          281,
          1884,
          264,
          3097,
          1412,
          11,
          51776
        ]
      },
      {
        "avg_logprob": -0.20462170692339335,
        "compression_ratio": 1.9822695035460993,
        "end": 742.02,
        "id": 273,
        "no_speech_prob": 0.001432530116289854,
        "seek": 73938,
        "start": 739.38,
        "temperature": 0,
        "text": " I'm going to come back to this and explain where that number",
        "tokens": [
          50364,
          286,
          478,
          516,
          281,
          808,
          646,
          281,
          341,
          293,
          2903,
          689,
          300,
          1230,
          50496
        ]
      },
      {
        "avg_logprob": -0.20462170692339335,
        "compression_ratio": 1.9822695035460993,
        "end": 743.18,
        "id": 274,
        "no_speech_prob": 0.001432530116289854,
        "seek": 73938,
        "start": 742.02,
        "temperature": 0,
        "text": " 3 comes back in.",
        "tokens": [
          50496,
          805,
          1487,
          646,
          294,
          13,
          50554
        ]
      },
      {
        "avg_logprob": -0.20462170692339335,
        "compression_ratio": 1.9822695035460993,
        "end": 746.02,
        "id": 275,
        "no_speech_prob": 0.001432530116289854,
        "seek": 73938,
        "start": 743.18,
        "temperature": 0,
        "text": " There's one more property to the options that's",
        "tokens": [
          50554,
          821,
          311,
          472,
          544,
          4707,
          281,
          264,
          3956,
          300,
          311,
          50696
        ]
      },
      {
        "avg_logprob": -0.20462170692339335,
        "compression_ratio": 1.9822695035460993,
        "end": 747.78,
        "id": 276,
        "no_speech_prob": 0.001432530116289854,
        "seek": 73938,
        "start": 746.02,
        "temperature": 0,
        "text": " very important for me to specify,",
        "tokens": [
          50696,
          588,
          1021,
          337,
          385,
          281,
          16500,
          11,
          50784
        ]
      },
      {
        "avg_logprob": -0.20462170692339335,
        "compression_ratio": 1.9822695035460993,
        "end": 751.5,
        "id": 277,
        "no_speech_prob": 0.001432530116289854,
        "seek": 73938,
        "start": 747.78,
        "temperature": 0,
        "text": " and that is the task that I want the neural network to perform.",
        "tokens": [
          50784,
          293,
          300,
          307,
          264,
          5633,
          300,
          286,
          528,
          264,
          18161,
          3209,
          281,
          2042,
          13,
          50970
        ]
      },
      {
        "avg_logprob": -0.20462170692339335,
        "compression_ratio": 1.9822695035460993,
        "end": 753.9399999999999,
        "id": 278,
        "no_speech_prob": 0.001432530116289854,
        "seek": 73938,
        "start": 751.5,
        "temperature": 0,
        "text": " And in this case, the task is classification.",
        "tokens": [
          50970,
          400,
          294,
          341,
          1389,
          11,
          264,
          5633,
          307,
          21538,
          13,
          51092
        ]
      },
      {
        "avg_logprob": -0.20462170692339335,
        "compression_ratio": 1.9822695035460993,
        "end": 756.66,
        "id": 279,
        "no_speech_prob": 0.001432530116289854,
        "seek": 73938,
        "start": 753.9399999999999,
        "temperature": 0,
        "text": " The other task that I could have specified is a regression.",
        "tokens": [
          51092,
          440,
          661,
          5633,
          300,
          286,
          727,
          362,
          22206,
          307,
          257,
          24590,
          13,
          51228
        ]
      },
      {
        "avg_logprob": -0.20462170692339335,
        "compression_ratio": 1.9822695035460993,
        "end": 758.4,
        "id": 280,
        "no_speech_prob": 0.001432530116289854,
        "seek": 73938,
        "start": 756.66,
        "temperature": 0,
        "text": " And I'll come back and do other examples",
        "tokens": [
          51228,
          400,
          286,
          603,
          808,
          646,
          293,
          360,
          661,
          5110,
          51315
        ]
      },
      {
        "avg_logprob": -0.20462170692339335,
        "compression_ratio": 1.9822695035460993,
        "end": 760.18,
        "id": 281,
        "no_speech_prob": 0.001432530116289854,
        "seek": 73938,
        "start": 758.4,
        "temperature": 0,
        "text": " that use a neural network to perform a regression.",
        "tokens": [
          51315,
          300,
          764,
          257,
          18161,
          3209,
          281,
          2042,
          257,
          24590,
          13,
          51404
        ]
      },
      {
        "avg_logprob": -0.20462170692339335,
        "compression_ratio": 1.9822695035460993,
        "end": 763.1,
        "id": 282,
        "no_speech_prob": 0.001432530116289854,
        "seek": 73938,
        "start": 760.18,
        "temperature": 0,
        "text": " We'll see what that is and how that works in future videos.",
        "tokens": [
          51404,
          492,
          603,
          536,
          437,
          300,
          307,
          293,
          577,
          300,
          1985,
          294,
          2027,
          2145,
          13,
          51550
        ]
      },
      {
        "avg_logprob": -0.20462170692339335,
        "compression_ratio": 1.9822695035460993,
        "end": 764.9,
        "id": 283,
        "no_speech_prob": 0.001432530116289854,
        "seek": 73938,
        "start": 763.1,
        "temperature": 0,
        "text": " In this case, though, it's a classification",
        "tokens": [
          51550,
          682,
          341,
          1389,
          11,
          1673,
          11,
          309,
          311,
          257,
          21538,
          51640
        ]
      },
      {
        "avg_logprob": -0.20462170692339335,
        "compression_ratio": 1.9822695035460993,
        "end": 766.3,
        "id": 284,
        "no_speech_prob": 0.001432530116289854,
        "seek": 73938,
        "start": 764.9,
        "temperature": 0,
        "text": " because I want the neural network",
        "tokens": [
          51640,
          570,
          286,
          528,
          264,
          18161,
          3209,
          51710
        ]
      },
      {
        "avg_logprob": -0.21906109779111801,
        "compression_ratio": 1.7518248175182483,
        "end": 770.3399999999999,
        "id": 285,
        "no_speech_prob": 0.0015247768023982644,
        "seek": 76630,
        "start": 766.3,
        "temperature": 0,
        "text": " to classify the input into one of three discrete categories.",
        "tokens": [
          50364,
          281,
          33872,
          264,
          4846,
          666,
          472,
          295,
          1045,
          27706,
          10479,
          13,
          50566
        ]
      },
      {
        "avg_logprob": -0.21906109779111801,
        "compression_ratio": 1.7518248175182483,
        "end": 774.4599999999999,
        "id": 286,
        "no_speech_prob": 0.0015247768023982644,
        "seek": 76630,
        "start": 770.3399999999999,
        "temperature": 0,
        "text": " So now we are ready for the first step, collect data.",
        "tokens": [
          50566,
          407,
          586,
          321,
          366,
          1919,
          337,
          264,
          700,
          1823,
          11,
          2500,
          1412,
          13,
          50772
        ]
      },
      {
        "avg_logprob": -0.21906109779111801,
        "compression_ratio": 1.7518248175182483,
        "end": 777.74,
        "id": 287,
        "no_speech_prob": 0.0015247768023982644,
        "seek": 76630,
        "start": 774.4599999999999,
        "temperature": 0,
        "text": " And this should really say collect training data.",
        "tokens": [
          50772,
          400,
          341,
          820,
          534,
          584,
          2500,
          3097,
          1412,
          13,
          50936
        ]
      },
      {
        "avg_logprob": -0.21906109779111801,
        "compression_ratio": 1.7518248175182483,
        "end": 782.06,
        "id": 288,
        "no_speech_prob": 0.0015247768023982644,
        "seek": 76630,
        "start": 777.74,
        "temperature": 0,
        "text": " Collecting training data means I need to have a set of inputs",
        "tokens": [
          50936,
          31896,
          278,
          3097,
          1412,
          1355,
          286,
          643,
          281,
          362,
          257,
          992,
          295,
          15743,
          51152
        ]
      },
      {
        "avg_logprob": -0.21906109779111801,
        "compression_ratio": 1.7518248175182483,
        "end": 785.0999999999999,
        "id": 289,
        "no_speech_prob": 0.0015247768023982644,
        "seek": 76630,
        "start": 782.06,
        "temperature": 0,
        "text": " and their correct corresponding output.",
        "tokens": [
          51152,
          293,
          641,
          3006,
          11760,
          5598,
          13,
          51304
        ]
      },
      {
        "avg_logprob": -0.21906109779111801,
        "compression_ratio": 1.7518248175182483,
        "end": 787.2199999999999,
        "id": 290,
        "no_speech_prob": 0.0015247768023982644,
        "seek": 76630,
        "start": 785.0999999999999,
        "temperature": 0,
        "text": " And in this case, I want to collect that data",
        "tokens": [
          51304,
          400,
          294,
          341,
          1389,
          11,
          286,
          528,
          281,
          2500,
          300,
          1412,
          51410
        ]
      },
      {
        "avg_logprob": -0.21906109779111801,
        "compression_ratio": 1.7518248175182483,
        "end": 789.06,
        "id": 291,
        "no_speech_prob": 0.0015247768023982644,
        "seek": 76630,
        "start": 787.2199999999999,
        "temperature": 0,
        "text": " through user interaction.",
        "tokens": [
          51410,
          807,
          4195,
          9285,
          13,
          51502
        ]
      },
      {
        "avg_logprob": -0.21906109779111801,
        "compression_ratio": 1.7518248175182483,
        "end": 790.74,
        "id": 292,
        "no_speech_prob": 0.0015247768023982644,
        "seek": 76630,
        "start": 789.06,
        "temperature": 0,
        "text": " And I'll do that with mouse clicks.",
        "tokens": [
          51502,
          400,
          286,
          603,
          360,
          300,
          365,
          9719,
          18521,
          13,
          51586
        ]
      },
      {
        "avg_logprob": -0.21906109779111801,
        "compression_ratio": 1.7518248175182483,
        "end": 793.9599999999999,
        "id": 293,
        "no_speech_prob": 0.0015247768023982644,
        "seek": 76630,
        "start": 790.74,
        "temperature": 0,
        "text": " So I'm going to write a function called mousePressed.",
        "tokens": [
          51586,
          407,
          286,
          478,
          516,
          281,
          2464,
          257,
          2445,
          1219,
          9719,
          47,
          3805,
          13,
          51747
        ]
      },
      {
        "avg_logprob": -0.21906109779111801,
        "compression_ratio": 1.7518248175182483,
        "end": 796.0799999999999,
        "id": 294,
        "no_speech_prob": 0.0015247768023982644,
        "seek": 76630,
        "start": 793.9599999999999,
        "temperature": 0,
        "text": " And I'm actually going to get rid of the draw loop.",
        "tokens": [
          51747,
          400,
          286,
          478,
          767,
          516,
          281,
          483,
          3973,
          295,
          264,
          2642,
          6367,
          13,
          51853
        ]
      },
      {
        "avg_logprob": -0.2431468478703903,
        "compression_ratio": 1.6810344827586208,
        "end": 798.12,
        "id": 295,
        "no_speech_prob": 0.00007141875539673492,
        "seek": 79608,
        "start": 796.08,
        "temperature": 0,
        "text": " Just to get started, every time I click the mouse,",
        "tokens": [
          50364,
          1449,
          281,
          483,
          1409,
          11,
          633,
          565,
          286,
          2052,
          264,
          9719,
          11,
          50466
        ]
      },
      {
        "avg_logprob": -0.2431468478703903,
        "compression_ratio": 1.6810344827586208,
        "end": 799.88,
        "id": 296,
        "no_speech_prob": 0.00007141875539673492,
        "seek": 79608,
        "start": 798.12,
        "temperature": 0,
        "text": " let's draw a circle on the screen.",
        "tokens": [
          50466,
          718,
          311,
          2642,
          257,
          6329,
          322,
          264,
          2568,
          13,
          50554
        ]
      },
      {
        "avg_logprob": -0.2431468478703903,
        "compression_ratio": 1.6810344827586208,
        "end": 805.8000000000001,
        "id": 297,
        "no_speech_prob": 0.00007141875539673492,
        "seek": 79608,
        "start": 799.88,
        "temperature": 0,
        "text": " MouseX, mouseY with a radius of 24.",
        "tokens": [
          50554,
          29383,
          55,
          11,
          9719,
          56,
          365,
          257,
          15845,
          295,
          4022,
          13,
          50850
        ]
      },
      {
        "avg_logprob": -0.2431468478703903,
        "compression_ratio": 1.6810344827586208,
        "end": 808.6,
        "id": 298,
        "no_speech_prob": 0.00007141875539673492,
        "seek": 79608,
        "start": 805.8000000000001,
        "temperature": 0,
        "text": " And let's also put a letter in the center of the circle.",
        "tokens": [
          50850,
          400,
          718,
          311,
          611,
          829,
          257,
          5063,
          294,
          264,
          3056,
          295,
          264,
          6329,
          13,
          50990
        ]
      },
      {
        "avg_logprob": -0.2431468478703903,
        "compression_ratio": 1.6810344827586208,
        "end": 815.0400000000001,
        "id": 299,
        "no_speech_prob": 0.00007141875539673492,
        "seek": 79608,
        "start": 812.88,
        "temperature": 0,
        "text": " So now as I click, I'm collecting data points.",
        "tokens": [
          51204,
          407,
          586,
          382,
          286,
          2052,
          11,
          286,
          478,
          12510,
          1412,
          2793,
          13,
          51312
        ]
      },
      {
        "avg_logprob": -0.2431468478703903,
        "compression_ratio": 1.6810344827586208,
        "end": 818.72,
        "id": 300,
        "no_speech_prob": 0.00007141875539673492,
        "seek": 79608,
        "start": 815.0400000000001,
        "temperature": 0,
        "text": " I'm collecting x and y's that go with the category C.",
        "tokens": [
          51312,
          286,
          478,
          12510,
          2031,
          293,
          288,
          311,
          300,
          352,
          365,
          264,
          7719,
          383,
          13,
          51496
        ]
      },
      {
        "avg_logprob": -0.2431468478703903,
        "compression_ratio": 1.6810344827586208,
        "end": 820.36,
        "id": 301,
        "no_speech_prob": 0.00007141875539673492,
        "seek": 79608,
        "start": 818.72,
        "temperature": 0,
        "text": " But I also want to collect x and y's that",
        "tokens": [
          51496,
          583,
          286,
          611,
          528,
          281,
          2500,
          2031,
          293,
          288,
          311,
          300,
          51578
        ]
      },
      {
        "avg_logprob": -0.2431468478703903,
        "compression_ratio": 1.6810344827586208,
        "end": 821.9200000000001,
        "id": 302,
        "no_speech_prob": 0.00007141875539673492,
        "seek": 79608,
        "start": 820.36,
        "temperature": 0,
        "text": " go with different categories.",
        "tokens": [
          51578,
          352,
          365,
          819,
          10479,
          13,
          51656
        ]
      },
      {
        "avg_logprob": -0.2431468478703903,
        "compression_ratio": 1.6810344827586208,
        "end": 824.6800000000001,
        "id": 303,
        "no_speech_prob": 0.00007141875539673492,
        "seek": 79608,
        "start": 821.9200000000001,
        "temperature": 0,
        "text": " So let me do that through a key press.",
        "tokens": [
          51656,
          407,
          718,
          385,
          360,
          300,
          807,
          257,
          2141,
          1886,
          13,
          51794
        ]
      },
      {
        "avg_logprob": -0.2291049049014137,
        "compression_ratio": 1.7045454545454546,
        "end": 827.8399999999999,
        "id": 304,
        "no_speech_prob": 0.0002453689812682569,
        "seek": 82468,
        "start": 824.68,
        "temperature": 0,
        "text": " I'm going to create a variable called targetLabel.",
        "tokens": [
          50364,
          286,
          478,
          516,
          281,
          1884,
          257,
          7006,
          1219,
          3779,
          43,
          18657,
          13,
          50522
        ]
      },
      {
        "avg_logprob": -0.2291049049014137,
        "compression_ratio": 1.7045454545454546,
        "end": 831.68,
        "id": 305,
        "no_speech_prob": 0.0002453689812682569,
        "seek": 82468,
        "start": 827.8399999999999,
        "temperature": 0,
        "text": " And I'm just give that a default value of C.",
        "tokens": [
          50522,
          400,
          286,
          478,
          445,
          976,
          300,
          257,
          7576,
          2158,
          295,
          383,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.2291049049014137,
        "compression_ratio": 1.7045454545454546,
        "end": 833.28,
        "id": 306,
        "no_speech_prob": 0.0002453689812682569,
        "seek": 82468,
        "start": 831.68,
        "temperature": 0,
        "text": " Then I'm going to add keyPressed.",
        "tokens": [
          50714,
          1396,
          286,
          478,
          516,
          281,
          909,
          2141,
          47,
          3805,
          13,
          50794
        ]
      },
      {
        "avg_logprob": -0.2291049049014137,
        "compression_ratio": 1.7045454545454546,
        "end": 838.5999999999999,
        "id": 307,
        "no_speech_prob": 0.0002453689812682569,
        "seek": 82468,
        "start": 833.28,
        "temperature": 0,
        "text": " And I'll just set targetLabel equal to the key that I press.",
        "tokens": [
          50794,
          400,
          286,
          603,
          445,
          992,
          3779,
          43,
          18657,
          2681,
          281,
          264,
          2141,
          300,
          286,
          1886,
          13,
          51060
        ]
      },
      {
        "avg_logprob": -0.2291049049014137,
        "compression_ratio": 1.7045454545454546,
        "end": 841.0799999999999,
        "id": 308,
        "no_speech_prob": 0.0002453689812682569,
        "seek": 82468,
        "start": 838.5999999999999,
        "temperature": 0,
        "text": " Then I'll draw the target label instead.",
        "tokens": [
          51060,
          1396,
          286,
          603,
          2642,
          264,
          3779,
          7645,
          2602,
          13,
          51184
        ]
      },
      {
        "avg_logprob": -0.2291049049014137,
        "compression_ratio": 1.7045454545454546,
        "end": 842.52,
        "id": 309,
        "no_speech_prob": 0.0002453689812682569,
        "seek": 82468,
        "start": 841.0799999999999,
        "temperature": 0,
        "text": " So here's a bunch of C's.",
        "tokens": [
          51184,
          407,
          510,
          311,
          257,
          3840,
          295,
          383,
          311,
          13,
          51256
        ]
      },
      {
        "avg_logprob": -0.2291049049014137,
        "compression_ratio": 1.7045454545454546,
        "end": 846.12,
        "id": 310,
        "no_speech_prob": 0.0002453689812682569,
        "seek": 82468,
        "start": 842.52,
        "temperature": 0,
        "text": " Now I'm going to press D. Here's a bunch of D's.",
        "tokens": [
          51256,
          823,
          286,
          478,
          516,
          281,
          1886,
          413,
          13,
          1692,
          311,
          257,
          3840,
          295,
          413,
          311,
          13,
          51436
        ]
      },
      {
        "avg_logprob": -0.2291049049014137,
        "compression_ratio": 1.7045454545454546,
        "end": 847.4,
        "id": 311,
        "no_speech_prob": 0.0002453689812682569,
        "seek": 82468,
        "start": 846.12,
        "temperature": 0,
        "text": " It's lowercase.",
        "tokens": [
          51436,
          467,
          311,
          3126,
          9765,
          13,
          51500
        ]
      },
      {
        "avg_logprob": -0.2291049049014137,
        "compression_ratio": 1.7045454545454546,
        "end": 850.16,
        "id": 312,
        "no_speech_prob": 0.0002453689812682569,
        "seek": 82468,
        "start": 847.4,
        "temperature": 0,
        "text": " Let me add to uppercase.",
        "tokens": [
          51500,
          961,
          385,
          909,
          281,
          11775,
          2869,
          651,
          13,
          51638
        ]
      },
      {
        "avg_logprob": -0.2291049049014137,
        "compression_ratio": 1.7045454545454546,
        "end": 851.9599999999999,
        "id": 313,
        "no_speech_prob": 0.0002453689812682569,
        "seek": 82468,
        "start": 850.16,
        "temperature": 0,
        "text": " Let's make sure this works.",
        "tokens": [
          51638,
          961,
          311,
          652,
          988,
          341,
          1985,
          13,
          51728
        ]
      },
      {
        "avg_logprob": -0.2101879931510763,
        "compression_ratio": 1.6631578947368422,
        "end": 856.08,
        "id": 314,
        "no_speech_prob": 0.002590966410934925,
        "seek": 85196,
        "start": 851.96,
        "temperature": 0,
        "text": " A bunch of C's, some D's, and E. Now, of course,",
        "tokens": [
          50364,
          316,
          3840,
          295,
          383,
          311,
          11,
          512,
          413,
          311,
          11,
          293,
          462,
          13,
          823,
          11,
          295,
          1164,
          11,
          50570
        ]
      },
      {
        "avg_logprob": -0.2101879931510763,
        "compression_ratio": 1.6631578947368422,
        "end": 857.4000000000001,
        "id": 315,
        "no_speech_prob": 0.002590966410934925,
        "seek": 85196,
        "start": 856.08,
        "temperature": 0,
        "text": " I could do other.",
        "tokens": [
          50570,
          286,
          727,
          360,
          661,
          13,
          50636
        ]
      },
      {
        "avg_logprob": -0.2101879931510763,
        "compression_ratio": 1.6631578947368422,
        "end": 859,
        "id": 316,
        "no_speech_prob": 0.002590966410934925,
        "seek": 85196,
        "start": 857.4000000000001,
        "temperature": 0,
        "text": " I could do any letter right now.",
        "tokens": [
          50636,
          286,
          727,
          360,
          604,
          5063,
          558,
          586,
          13,
          50716
        ]
      },
      {
        "avg_logprob": -0.2101879931510763,
        "compression_ratio": 1.6631578947368422,
        "end": 861.6,
        "id": 317,
        "no_speech_prob": 0.002590966410934925,
        "seek": 85196,
        "start": 859,
        "temperature": 0,
        "text": " So I probably would want to add some kind of error checking",
        "tokens": [
          50716,
          407,
          286,
          1391,
          576,
          528,
          281,
          909,
          512,
          733,
          295,
          6713,
          8568,
          50846
        ]
      },
      {
        "avg_logprob": -0.2101879931510763,
        "compression_ratio": 1.6631578947368422,
        "end": 865.2,
        "id": 318,
        "no_speech_prob": 0.002590966410934925,
        "seek": 85196,
        "start": 861.6,
        "temperature": 0,
        "text": " or determine what I want to let be the actual target labels.",
        "tokens": [
          50846,
          420,
          6997,
          437,
          286,
          528,
          281,
          718,
          312,
          264,
          3539,
          3779,
          16949,
          13,
          51026
        ]
      },
      {
        "avg_logprob": -0.2101879931510763,
        "compression_ratio": 1.6631578947368422,
        "end": 867.44,
        "id": 319,
        "no_speech_prob": 0.002590966410934925,
        "seek": 85196,
        "start": 865.2,
        "temperature": 0,
        "text": " But for now, I'm going to just let it be a free for all",
        "tokens": [
          51026,
          583,
          337,
          586,
          11,
          286,
          478,
          516,
          281,
          445,
          718,
          309,
          312,
          257,
          1737,
          337,
          439,
          51138
        ]
      },
      {
        "avg_logprob": -0.2101879931510763,
        "compression_ratio": 1.6631578947368422,
        "end": 870.84,
        "id": 320,
        "no_speech_prob": 0.002590966410934925,
        "seek": 85196,
        "start": 867.44,
        "temperature": 0,
        "text": " and just restrict myself to C, D, and E.",
        "tokens": [
          51138,
          293,
          445,
          7694,
          2059,
          281,
          383,
          11,
          413,
          11,
          293,
          462,
          13,
          51308
        ]
      },
      {
        "avg_logprob": -0.2101879931510763,
        "compression_ratio": 1.6631578947368422,
        "end": 872.8000000000001,
        "id": 321,
        "no_speech_prob": 0.002590966410934925,
        "seek": 85196,
        "start": 870.84,
        "temperature": 0,
        "text": " I didn't actually collect the data, though.",
        "tokens": [
          51308,
          286,
          994,
          380,
          767,
          2500,
          264,
          1412,
          11,
          1673,
          13,
          51406
        ]
      },
      {
        "avg_logprob": -0.2101879931510763,
        "compression_ratio": 1.6631578947368422,
        "end": 874.8000000000001,
        "id": 322,
        "no_speech_prob": 0.002590966410934925,
        "seek": 85196,
        "start": 872.8000000000001,
        "temperature": 0,
        "text": " I'm just showing you a very crude user",
        "tokens": [
          51406,
          286,
          478,
          445,
          4099,
          291,
          257,
          588,
          30796,
          4195,
          51506
        ]
      },
      {
        "avg_logprob": -0.2101879931510763,
        "compression_ratio": 1.6631578947368422,
        "end": 877.52,
        "id": 323,
        "no_speech_prob": 0.002590966410934925,
        "seek": 85196,
        "start": 874.8000000000001,
        "temperature": 0,
        "text": " interface for indicating where I've clicked",
        "tokens": [
          51506,
          9226,
          337,
          25604,
          689,
          286,
          600,
          23370,
          51642
        ]
      },
      {
        "avg_logprob": -0.2101879931510763,
        "compression_ratio": 1.6631578947368422,
        "end": 878.74,
        "id": 324,
        "no_speech_prob": 0.002590966410934925,
        "seek": 85196,
        "start": 877.52,
        "temperature": 0,
        "text": " and what letter I've pressed.",
        "tokens": [
          51642,
          293,
          437,
          5063,
          286,
          600,
          17355,
          13,
          51703
        ]
      },
      {
        "avg_logprob": -0.24912472094519664,
        "compression_ratio": 1.6535087719298245,
        "end": 884.3,
        "id": 325,
        "no_speech_prob": 0.00014883835683576763,
        "seek": 87874,
        "start": 878.74,
        "temperature": 0,
        "text": " So let me create a variable called trainingData.",
        "tokens": [
          50364,
          407,
          718,
          385,
          1884,
          257,
          7006,
          1219,
          3097,
          35,
          3274,
          13,
          50642
        ]
      },
      {
        "avg_logprob": -0.24912472094519664,
        "compression_ratio": 1.6535087719298245,
        "end": 886.58,
        "id": 326,
        "no_speech_prob": 0.00014883835683576763,
        "seek": 87874,
        "start": 884.3,
        "temperature": 0,
        "text": " I'm going to make that an array.",
        "tokens": [
          50642,
          286,
          478,
          516,
          281,
          652,
          300,
          364,
          10225,
          13,
          50756
        ]
      },
      {
        "avg_logprob": -0.24912472094519664,
        "compression_ratio": 1.6535087719298245,
        "end": 888.66,
        "id": 327,
        "no_speech_prob": 0.00014883835683576763,
        "seek": 87874,
        "start": 886.58,
        "temperature": 0,
        "text": " Then whenever I click the mouse, I'm",
        "tokens": [
          50756,
          1396,
          5699,
          286,
          2052,
          264,
          9719,
          11,
          286,
          478,
          50860
        ]
      },
      {
        "avg_logprob": -0.24912472094519664,
        "compression_ratio": 1.6535087719298245,
        "end": 890.78,
        "id": 328,
        "no_speech_prob": 0.00014883835683576763,
        "seek": 87874,
        "start": 888.66,
        "temperature": 0,
        "text": " going to say my inputs are.",
        "tokens": [
          50860,
          516,
          281,
          584,
          452,
          15743,
          366,
          13,
          50966
        ]
      },
      {
        "avg_logprob": -0.24912472094519664,
        "compression_ratio": 1.6535087719298245,
        "end": 893.46,
        "id": 329,
        "no_speech_prob": 0.00014883835683576763,
        "seek": 87874,
        "start": 890.78,
        "temperature": 0,
        "text": " Now, because I named the inputs when",
        "tokens": [
          50966,
          823,
          11,
          570,
          286,
          4926,
          264,
          15743,
          562,
          51100
        ]
      },
      {
        "avg_logprob": -0.24912472094519664,
        "compression_ratio": 1.6535087719298245,
        "end": 894.82,
        "id": 330,
        "no_speech_prob": 0.00014883835683576763,
        "seek": 87874,
        "start": 893.46,
        "temperature": 0,
        "text": " I configured the neural network, I",
        "tokens": [
          51100,
          286,
          30538,
          264,
          18161,
          3209,
          11,
          286,
          51168
        ]
      },
      {
        "avg_logprob": -0.24912472094519664,
        "compression_ratio": 1.6535087719298245,
        "end": 897.34,
        "id": 331,
        "no_speech_prob": 0.00014883835683576763,
        "seek": 87874,
        "start": 894.82,
        "temperature": 0,
        "text": " can create an object with an x and a y",
        "tokens": [
          51168,
          393,
          1884,
          364,
          2657,
          365,
          364,
          2031,
          293,
          257,
          288,
          51294
        ]
      },
      {
        "avg_logprob": -0.24912472094519664,
        "compression_ratio": 1.6535087719298245,
        "end": 899.14,
        "id": 332,
        "no_speech_prob": 0.00014883835683576763,
        "seek": 87874,
        "start": 897.34,
        "temperature": 0,
        "text": " and also another one with a label.",
        "tokens": [
          51294,
          293,
          611,
          1071,
          472,
          365,
          257,
          7645,
          13,
          51384
        ]
      },
      {
        "avg_logprob": -0.24912472094519664,
        "compression_ratio": 1.6535087719298245,
        "end": 900.3,
        "id": 333,
        "no_speech_prob": 0.00014883835683576763,
        "seek": 87874,
        "start": 899.14,
        "temperature": 0,
        "text": " You'll see.",
        "tokens": [
          51384,
          509,
          603,
          536,
          13,
          51442
        ]
      },
      {
        "avg_logprob": -0.24912472094519664,
        "compression_ratio": 1.6535087719298245,
        "end": 904.78,
        "id": 334,
        "no_speech_prob": 0.00014883835683576763,
        "seek": 87874,
        "start": 900.3,
        "temperature": 0,
        "text": " x is mouseX, y is mouseY.",
        "tokens": [
          51442,
          2031,
          307,
          9719,
          55,
          11,
          288,
          307,
          9719,
          56,
          13,
          51666
        ]
      },
      {
        "avg_logprob": -0.24912472094519664,
        "compression_ratio": 1.6535087719298245,
        "end": 906.66,
        "id": 335,
        "no_speech_prob": 0.00014883835683576763,
        "seek": 87874,
        "start": 904.78,
        "temperature": 0,
        "text": " And then I'm going to make one called outputs.",
        "tokens": [
          51666,
          400,
          550,
          286,
          478,
          516,
          281,
          652,
          472,
          1219,
          23930,
          13,
          51760
        ]
      },
      {
        "avg_logprob": -0.2467747146277119,
        "compression_ratio": 1.7793594306049823,
        "end": 910.1,
        "id": 336,
        "no_speech_prob": 0.0005703144706785679,
        "seek": 90666,
        "start": 907.66,
        "temperature": 0,
        "text": " These are the outputs, but this is called a target.",
        "tokens": [
          50414,
          1981,
          366,
          264,
          23930,
          11,
          457,
          341,
          307,
          1219,
          257,
          3779,
          13,
          50536
        ]
      },
      {
        "avg_logprob": -0.2467747146277119,
        "compression_ratio": 1.7793594306049823,
        "end": 912.06,
        "id": 337,
        "no_speech_prob": 0.0005703144706785679,
        "seek": 90666,
        "start": 910.1,
        "temperature": 0,
        "text": " That's a word I can use here because this",
        "tokens": [
          50536,
          663,
          311,
          257,
          1349,
          286,
          393,
          764,
          510,
          570,
          341,
          50634
        ]
      },
      {
        "avg_logprob": -0.2467747146277119,
        "compression_ratio": 1.7793594306049823,
        "end": 915.42,
        "id": 338,
        "no_speech_prob": 0.0005703144706785679,
        "seek": 90666,
        "start": 912.06,
        "temperature": 0,
        "text": " is the target output that I want the neural network to learn",
        "tokens": [
          50634,
          307,
          264,
          3779,
          5598,
          300,
          286,
          528,
          264,
          18161,
          3209,
          281,
          1466,
          50802
        ]
      },
      {
        "avg_logprob": -0.2467747146277119,
        "compression_ratio": 1.7793594306049823,
        "end": 917.18,
        "id": 339,
        "no_speech_prob": 0.0005703144706785679,
        "seek": 90666,
        "start": 915.42,
        "temperature": 0,
        "text": " given these inputs.",
        "tokens": [
          50802,
          2212,
          613,
          15743,
          13,
          50890
        ]
      },
      {
        "avg_logprob": -0.2467747146277119,
        "compression_ratio": 1.7793594306049823,
        "end": 920.18,
        "id": 340,
        "no_speech_prob": 0.0005703144706785679,
        "seek": 90666,
        "start": 917.18,
        "temperature": 0,
        "text": " So I'm going to say target equals label,",
        "tokens": [
          50890,
          407,
          286,
          478,
          516,
          281,
          584,
          3779,
          6915,
          7645,
          11,
          51040
        ]
      },
      {
        "avg_logprob": -0.2467747146277119,
        "compression_ratio": 1.7793594306049823,
        "end": 922.5,
        "id": 341,
        "no_speech_prob": 0.0005703144706785679,
        "seek": 90666,
        "start": 920.18,
        "temperature": 0,
        "text": " and the label is the target label.",
        "tokens": [
          51040,
          293,
          264,
          7645,
          307,
          264,
          3779,
          7645,
          13,
          51156
        ]
      },
      {
        "avg_logprob": -0.2467747146277119,
        "compression_ratio": 1.7793594306049823,
        "end": 924.9,
        "id": 342,
        "no_speech_prob": 0.0005703144706785679,
        "seek": 90666,
        "start": 922.5,
        "temperature": 0,
        "text": " And actually, I don't need this training data array.",
        "tokens": [
          51156,
          400,
          767,
          11,
          286,
          500,
          380,
          643,
          341,
          3097,
          1412,
          10225,
          13,
          51276
        ]
      },
      {
        "avg_logprob": -0.2467747146277119,
        "compression_ratio": 1.7793594306049823,
        "end": 927.42,
        "id": 343,
        "no_speech_prob": 0.0005703144706785679,
        "seek": 90666,
        "start": 924.9,
        "temperature": 0,
        "text": " I was thinking I wanted to use that so I could store",
        "tokens": [
          51276,
          286,
          390,
          1953,
          286,
          1415,
          281,
          764,
          300,
          370,
          286,
          727,
          3531,
          51402
        ]
      },
      {
        "avg_logprob": -0.2467747146277119,
        "compression_ratio": 1.7793594306049823,
        "end": 930.3399999999999,
        "id": 344,
        "no_speech_prob": 0.0005703144706785679,
        "seek": 90666,
        "start": 927.42,
        "temperature": 0,
        "text": " all of the data myself in an array.",
        "tokens": [
          51402,
          439,
          295,
          264,
          1412,
          2059,
          294,
          364,
          10225,
          13,
          51548
        ]
      },
      {
        "avg_logprob": -0.2467747146277119,
        "compression_ratio": 1.7793594306049823,
        "end": 933.1,
        "id": 345,
        "no_speech_prob": 0.0005703144706785679,
        "seek": 90666,
        "start": 930.3399999999999,
        "temperature": 0,
        "text": " And that could be very useful in a lot of contexts.",
        "tokens": [
          51548,
          400,
          300,
          727,
          312,
          588,
          4420,
          294,
          257,
          688,
          295,
          30628,
          13,
          51686
        ]
      },
      {
        "avg_logprob": -0.2467747146277119,
        "compression_ratio": 1.7793594306049823,
        "end": 935.9399999999999,
        "id": 346,
        "no_speech_prob": 0.0005703144706785679,
        "seek": 90666,
        "start": 933.1,
        "temperature": 0,
        "text": " Actually, all that I need to do here is just say model,",
        "tokens": [
          51686,
          5135,
          11,
          439,
          300,
          286,
          643,
          281,
          360,
          510,
          307,
          445,
          584,
          2316,
          11,
          51828
        ]
      },
      {
        "avg_logprob": -0.20931694425385575,
        "compression_ratio": 1.7532467532467533,
        "end": 940.94,
        "id": 347,
        "no_speech_prob": 0.000032192303478950635,
        "seek": 93594,
        "start": 935.94,
        "temperature": 0,
        "text": " add data, inputs, target.",
        "tokens": [
          50364,
          909,
          1412,
          11,
          15743,
          11,
          3779,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.20931694425385575,
        "compression_ratio": 1.7532467532467533,
        "end": 944.2600000000001,
        "id": 348,
        "no_speech_prob": 0.000032192303478950635,
        "seek": 93594,
        "start": 940.94,
        "temperature": 0,
        "text": " So this is a function in the ML5 neural network class",
        "tokens": [
          50614,
          407,
          341,
          307,
          257,
          2445,
          294,
          264,
          21601,
          20,
          18161,
          3209,
          1508,
          50780
        ]
      },
      {
        "avg_logprob": -0.20931694425385575,
        "compression_ratio": 1.7532467532467533,
        "end": 947.2600000000001,
        "id": 349,
        "no_speech_prob": 0.000032192303478950635,
        "seek": 93594,
        "start": 944.2600000000001,
        "temperature": 0,
        "text": " where the model can accept training data",
        "tokens": [
          50780,
          689,
          264,
          2316,
          393,
          3241,
          3097,
          1412,
          50930
        ]
      },
      {
        "avg_logprob": -0.20931694425385575,
        "compression_ratio": 1.7532467532467533,
        "end": 949.7600000000001,
        "id": 350,
        "no_speech_prob": 0.000032192303478950635,
        "seek": 93594,
        "start": 947.2600000000001,
        "temperature": 0,
        "text": " as pairs of inputs and target.",
        "tokens": [
          50930,
          382,
          15494,
          295,
          15743,
          293,
          3779,
          13,
          51055
        ]
      },
      {
        "avg_logprob": -0.20931694425385575,
        "compression_ratio": 1.7532467532467533,
        "end": 952.5400000000001,
        "id": 351,
        "no_speech_prob": 0.000032192303478950635,
        "seek": 93594,
        "start": 949.7600000000001,
        "temperature": 0,
        "text": " And I need to make sure that the inputs and the target",
        "tokens": [
          51055,
          400,
          286,
          643,
          281,
          652,
          988,
          300,
          264,
          15743,
          293,
          264,
          3779,
          51194
        ]
      },
      {
        "avg_logprob": -0.20931694425385575,
        "compression_ratio": 1.7532467532467533,
        "end": 955.5,
        "id": 352,
        "no_speech_prob": 0.000032192303478950635,
        "seek": 93594,
        "start": 952.5400000000001,
        "temperature": 0,
        "text": " match up with how I configure the neural network.",
        "tokens": [
          51194,
          2995,
          493,
          365,
          577,
          286,
          22162,
          264,
          18161,
          3209,
          13,
          51342
        ]
      },
      {
        "avg_logprob": -0.20931694425385575,
        "compression_ratio": 1.7532467532467533,
        "end": 958.5400000000001,
        "id": 353,
        "no_speech_prob": 0.000032192303478950635,
        "seek": 93594,
        "start": 955.5,
        "temperature": 0,
        "text": " And they do because I have an x and a y and a label.",
        "tokens": [
          51342,
          400,
          436,
          360,
          570,
          286,
          362,
          364,
          2031,
          293,
          257,
          288,
          293,
          257,
          7645,
          13,
          51494
        ]
      },
      {
        "avg_logprob": -0.20931694425385575,
        "compression_ratio": 1.7532467532467533,
        "end": 961.98,
        "id": 354,
        "no_speech_prob": 0.000032192303478950635,
        "seek": 93594,
        "start": 958.5400000000001,
        "temperature": 0,
        "text": " And now I have an x and a y and a label here.",
        "tokens": [
          51494,
          400,
          586,
          286,
          362,
          364,
          2031,
          293,
          257,
          288,
          293,
          257,
          7645,
          510,
          13,
          51666
        ]
      },
      {
        "avg_logprob": -0.20931694425385575,
        "compression_ratio": 1.7532467532467533,
        "end": 964.86,
        "id": 355,
        "no_speech_prob": 0.000032192303478950635,
        "seek": 93594,
        "start": 961.98,
        "temperature": 0,
        "text": " Now, rightfully so, you might be asking yourself,",
        "tokens": [
          51666,
          823,
          11,
          558,
          2277,
          370,
          11,
          291,
          1062,
          312,
          3365,
          1803,
          11,
          51810
        ]
      },
      {
        "avg_logprob": -0.21335058574435078,
        "compression_ratio": 1.9025974025974026,
        "end": 967.86,
        "id": 356,
        "no_speech_prob": 0.0008040827233344316,
        "seek": 96486,
        "start": 964.86,
        "temperature": 0,
        "text": " what happened to the fact that we were restricting ourselves",
        "tokens": [
          50364,
          437,
          2011,
          281,
          264,
          1186,
          300,
          321,
          645,
          1472,
          37714,
          4175,
          50514
        ]
      },
      {
        "avg_logprob": -0.21335058574435078,
        "compression_ratio": 1.9025974025974026,
        "end": 970.7,
        "id": 357,
        "no_speech_prob": 0.0008040827233344316,
        "seek": 96486,
        "start": 967.86,
        "temperature": 0,
        "text": " to three possible categorical outputs?",
        "tokens": [
          50514,
          281,
          1045,
          1944,
          19250,
          804,
          23930,
          30,
          50656
        ]
      },
      {
        "avg_logprob": -0.21335058574435078,
        "compression_ratio": 1.9025974025974026,
        "end": 974.58,
        "id": 358,
        "no_speech_prob": 0.0008040827233344316,
        "seek": 96486,
        "start": 970.7,
        "temperature": 0,
        "text": " And this is where a higher level library like ML5 comes in.",
        "tokens": [
          50656,
          400,
          341,
          307,
          689,
          257,
          2946,
          1496,
          6405,
          411,
          21601,
          20,
          1487,
          294,
          13,
          50850
        ]
      },
      {
        "avg_logprob": -0.21335058574435078,
        "compression_ratio": 1.9025974025974026,
        "end": 977.0600000000001,
        "id": 359,
        "no_speech_prob": 0.0008040827233344316,
        "seek": 96486,
        "start": 974.58,
        "temperature": 0,
        "text": " It's just saying, I know you're going to do classification.",
        "tokens": [
          50850,
          467,
          311,
          445,
          1566,
          11,
          286,
          458,
          291,
          434,
          516,
          281,
          360,
          21538,
          13,
          50974
        ]
      },
      {
        "avg_logprob": -0.21335058574435078,
        "compression_ratio": 1.9025974025974026,
        "end": 978.5600000000001,
        "id": 360,
        "no_speech_prob": 0.0008040827233344316,
        "seek": 96486,
        "start": 977.0600000000001,
        "temperature": 0,
        "text": " I know I'm going to give you a label.",
        "tokens": [
          50974,
          286,
          458,
          286,
          478,
          516,
          281,
          976,
          291,
          257,
          7645,
          13,
          51049
        ]
      },
      {
        "avg_logprob": -0.21335058574435078,
        "compression_ratio": 1.9025974025974026,
        "end": 980.22,
        "id": 361,
        "no_speech_prob": 0.0008040827233344316,
        "seek": 96486,
        "start": 978.5600000000001,
        "temperature": 0,
        "text": " I know you're going to give me some training data.",
        "tokens": [
          51049,
          286,
          458,
          291,
          434,
          516,
          281,
          976,
          385,
          512,
          3097,
          1412,
          13,
          51132
        ]
      },
      {
        "avg_logprob": -0.21335058574435078,
        "compression_ratio": 1.9025974025974026,
        "end": 982.0600000000001,
        "id": 362,
        "no_speech_prob": 0.0008040827233344316,
        "seek": 96486,
        "start": 980.22,
        "temperature": 0,
        "text": " So just give me all the training data.",
        "tokens": [
          51132,
          407,
          445,
          976,
          385,
          439,
          264,
          3097,
          1412,
          13,
          51224
        ]
      },
      {
        "avg_logprob": -0.21335058574435078,
        "compression_ratio": 1.9025974025974026,
        "end": 984.38,
        "id": 363,
        "no_speech_prob": 0.0008040827233344316,
        "seek": 96486,
        "start": 982.0600000000001,
        "temperature": 0,
        "text": " I will count how many possible outputs",
        "tokens": [
          51224,
          286,
          486,
          1207,
          577,
          867,
          1944,
          23930,
          51340
        ]
      },
      {
        "avg_logprob": -0.21335058574435078,
        "compression_ratio": 1.9025974025974026,
        "end": 987.42,
        "id": 364,
        "no_speech_prob": 0.0008040827233344316,
        "seek": 96486,
        "start": 984.38,
        "temperature": 0,
        "text": " there are after you finish giving me the training data.",
        "tokens": [
          51340,
          456,
          366,
          934,
          291,
          2413,
          2902,
          385,
          264,
          3097,
          1412,
          13,
          51492
        ]
      },
      {
        "avg_logprob": -0.21335058574435078,
        "compression_ratio": 1.9025974025974026,
        "end": 990.14,
        "id": 365,
        "no_speech_prob": 0.0008040827233344316,
        "seek": 96486,
        "start": 987.42,
        "temperature": 0,
        "text": " So as long as I give it a bunch of examples with a C,",
        "tokens": [
          51492,
          407,
          382,
          938,
          382,
          286,
          976,
          309,
          257,
          3840,
          295,
          5110,
          365,
          257,
          383,
          11,
          51628
        ]
      },
      {
        "avg_logprob": -0.21335058574435078,
        "compression_ratio": 1.9025974025974026,
        "end": 992.34,
        "id": 366,
        "no_speech_prob": 0.0008040827233344316,
        "seek": 96486,
        "start": 990.14,
        "temperature": 0,
        "text": " a bunch of examples with a D, and a bunch of examples",
        "tokens": [
          51628,
          257,
          3840,
          295,
          5110,
          365,
          257,
          413,
          11,
          293,
          257,
          3840,
          295,
          5110,
          51738
        ]
      },
      {
        "avg_logprob": -0.21335058574435078,
        "compression_ratio": 1.9025974025974026,
        "end": 994.3000000000001,
        "id": 367,
        "no_speech_prob": 0.0008040827233344316,
        "seek": 96486,
        "start": 992.34,
        "temperature": 0,
        "text": " with an E, it will configure itself",
        "tokens": [
          51738,
          365,
          364,
          462,
          11,
          309,
          486,
          22162,
          2564,
          51836
        ]
      },
      {
        "avg_logprob": -0.22676529372033993,
        "compression_ratio": 1.5597014925373134,
        "end": 998.78,
        "id": 368,
        "no_speech_prob": 0.00008888073352864012,
        "seek": 99430,
        "start": 994.3,
        "temperature": 0,
        "text": " to work with a limit of three possible labels as the output.",
        "tokens": [
          50364,
          281,
          589,
          365,
          257,
          4948,
          295,
          1045,
          1944,
          16949,
          382,
          264,
          5598,
          13,
          50588
        ]
      },
      {
        "avg_logprob": -0.22676529372033993,
        "compression_ratio": 1.5597014925373134,
        "end": 1002.78,
        "id": 369,
        "no_speech_prob": 0.00008888073352864012,
        "seek": 99430,
        "start": 998.78,
        "temperature": 0,
        "text": " Let me quickly test to see if I get any errors.",
        "tokens": [
          50588,
          961,
          385,
          2661,
          1500,
          281,
          536,
          498,
          286,
          483,
          604,
          13603,
          13,
          50788
        ]
      },
      {
        "avg_logprob": -0.22676529372033993,
        "compression_ratio": 1.5597014925373134,
        "end": 1007.2199999999999,
        "id": 370,
        "no_speech_prob": 0.00008888073352864012,
        "seek": 99430,
        "start": 1002.78,
        "temperature": 0,
        "text": " C, D, E. No, seems to be working.",
        "tokens": [
          50788,
          383,
          11,
          413,
          11,
          462,
          13,
          883,
          11,
          2544,
          281,
          312,
          1364,
          13,
          51010
        ]
      },
      {
        "avg_logprob": -0.22676529372033993,
        "compression_ratio": 1.5597014925373134,
        "end": 1007.8,
        "id": 371,
        "no_speech_prob": 0.00008888073352864012,
        "seek": 99430,
        "start": 1007.2199999999999,
        "temperature": 0,
        "text": " Good.",
        "tokens": [
          51010,
          2205,
          13,
          51039
        ]
      },
      {
        "avg_logprob": -0.22676529372033993,
        "compression_ratio": 1.5597014925373134,
        "end": 1012.14,
        "id": 372,
        "no_speech_prob": 0.00008888073352864012,
        "seek": 99430,
        "start": 1007.8,
        "temperature": 0,
        "text": " I am ready for the next step, training the model.",
        "tokens": [
          51039,
          286,
          669,
          1919,
          337,
          264,
          958,
          1823,
          11,
          3097,
          264,
          2316,
          13,
          51256
        ]
      },
      {
        "avg_logprob": -0.22676529372033993,
        "compression_ratio": 1.5597014925373134,
        "end": 1015.4599999999999,
        "id": 373,
        "no_speech_prob": 0.00008888073352864012,
        "seek": 99430,
        "start": 1012.14,
        "temperature": 0,
        "text": " This is a really easy one for us because the ML5 neural network",
        "tokens": [
          51256,
          639,
          307,
          257,
          534,
          1858,
          472,
          337,
          505,
          570,
          264,
          21601,
          20,
          18161,
          3209,
          51422
        ]
      },
      {
        "avg_logprob": -0.22676529372033993,
        "compression_ratio": 1.5597014925373134,
        "end": 1018.7199999999999,
        "id": 374,
        "no_speech_prob": 0.00008888073352864012,
        "seek": 99430,
        "start": 1015.4599999999999,
        "temperature": 0,
        "text": " class has a function called train.",
        "tokens": [
          51422,
          1508,
          575,
          257,
          2445,
          1219,
          3847,
          13,
          51585
        ]
      },
      {
        "avg_logprob": -0.22676529372033993,
        "compression_ratio": 1.5597014925373134,
        "end": 1020.6999999999999,
        "id": 375,
        "no_speech_prob": 0.00008888073352864012,
        "seek": 99430,
        "start": 1018.7199999999999,
        "temperature": 0,
        "text": " So I can just call that train function.",
        "tokens": [
          51585,
          407,
          286,
          393,
          445,
          818,
          300,
          3847,
          2445,
          13,
          51684
        ]
      },
      {
        "avg_logprob": -0.22676529372033993,
        "compression_ratio": 1.5597014925373134,
        "end": 1022.24,
        "id": 376,
        "no_speech_prob": 0.00008888073352864012,
        "seek": 99430,
        "start": 1020.6999999999999,
        "temperature": 0,
        "text": " Certainly, it would make sense for me",
        "tokens": [
          51684,
          16628,
          11,
          309,
          576,
          652,
          2020,
          337,
          385,
          51761
        ]
      },
      {
        "avg_logprob": -0.22676529372033993,
        "compression_ratio": 1.5597014925373134,
        "end": 1024.12,
        "id": 377,
        "no_speech_prob": 0.00008888073352864012,
        "seek": 99430,
        "start": 1022.24,
        "temperature": 0,
        "text": " to build some kind of user interface here.",
        "tokens": [
          51761,
          281,
          1322,
          512,
          733,
          295,
          4195,
          9226,
          510,
          13,
          51855
        ]
      },
      {
        "avg_logprob": -0.1971263885498047,
        "compression_ratio": 1.8388278388278387,
        "end": 1026.6999999999998,
        "id": 378,
        "no_speech_prob": 0.000032192252547247335,
        "seek": 102412,
        "start": 1024.1399999999999,
        "temperature": 0,
        "text": " But I'm just going to keep going with my key pressed method.",
        "tokens": [
          50365,
          583,
          286,
          478,
          445,
          516,
          281,
          1066,
          516,
          365,
          452,
          2141,
          17355,
          3170,
          13,
          50493
        ]
      },
      {
        "avg_logprob": -0.1971263885498047,
        "compression_ratio": 1.8388278388278387,
        "end": 1030.9399999999998,
        "id": 379,
        "no_speech_prob": 0.000032192252547247335,
        "seek": 102412,
        "start": 1026.6999999999998,
        "temperature": 0,
        "text": " And I'm going to check and say, if the key pressed is T,",
        "tokens": [
          50493,
          400,
          286,
          478,
          516,
          281,
          1520,
          293,
          584,
          11,
          498,
          264,
          2141,
          17355,
          307,
          314,
          11,
          50705
        ]
      },
      {
        "avg_logprob": -0.1971263885498047,
        "compression_ratio": 1.8388278388278387,
        "end": 1034.1,
        "id": 380,
        "no_speech_prob": 0.000032192252547247335,
        "seek": 102412,
        "start": 1030.9399999999998,
        "temperature": 0,
        "text": " then call model.train.",
        "tokens": [
          50705,
          550,
          818,
          2316,
          13,
          83,
          7146,
          13,
          50863
        ]
      },
      {
        "avg_logprob": -0.1971263885498047,
        "compression_ratio": 1.8388278388278387,
        "end": 1035.58,
        "id": 381,
        "no_speech_prob": 0.000032192252547247335,
        "seek": 102412,
        "start": 1034.1,
        "temperature": 0,
        "text": " When I train the model, I can also",
        "tokens": [
          50863,
          1133,
          286,
          3847,
          264,
          2316,
          11,
          286,
          393,
          611,
          50937
        ]
      },
      {
        "avg_logprob": -0.1971263885498047,
        "compression_ratio": 1.8388278388278387,
        "end": 1038.3,
        "id": 382,
        "no_speech_prob": 0.000032192252547247335,
        "seek": 102412,
        "start": 1035.58,
        "temperature": 0,
        "text": " give it some options that set various properties",
        "tokens": [
          50937,
          976,
          309,
          512,
          3956,
          300,
          992,
          3683,
          7221,
          51073
        ]
      },
      {
        "avg_logprob": -0.1971263885498047,
        "compression_ratio": 1.8388278388278387,
        "end": 1040.06,
        "id": 383,
        "no_speech_prob": 0.000032192252547247335,
        "seek": 102412,
        "start": 1038.3,
        "temperature": 0,
        "text": " of the training process itself.",
        "tokens": [
          51073,
          295,
          264,
          3097,
          1399,
          2564,
          13,
          51161
        ]
      },
      {
        "avg_logprob": -0.1971263885498047,
        "compression_ratio": 1.8388278388278387,
        "end": 1043.34,
        "id": 384,
        "no_speech_prob": 0.000032192252547247335,
        "seek": 102412,
        "start": 1040.06,
        "temperature": 0,
        "text": " So I'm going to create another options object.",
        "tokens": [
          51161,
          407,
          286,
          478,
          516,
          281,
          1884,
          1071,
          3956,
          2657,
          13,
          51325
        ]
      },
      {
        "avg_logprob": -0.1971263885498047,
        "compression_ratio": 1.8388278388278387,
        "end": 1044.9799999999998,
        "id": 385,
        "no_speech_prob": 0.000032192252547247335,
        "seek": 102412,
        "start": 1043.34,
        "temperature": 0,
        "text": " Information on what those options are",
        "tokens": [
          51325,
          15357,
          322,
          437,
          729,
          3956,
          366,
          51407
        ]
      },
      {
        "avg_logprob": -0.1971263885498047,
        "compression_ratio": 1.8388278388278387,
        "end": 1047.2199999999998,
        "id": 386,
        "no_speech_prob": 0.000032192252547247335,
        "seek": 102412,
        "start": 1044.9799999999998,
        "temperature": 0,
        "text": " is on the ML5 documentation page.",
        "tokens": [
          51407,
          307,
          322,
          264,
          21601,
          20,
          14333,
          3028,
          13,
          51519
        ]
      },
      {
        "avg_logprob": -0.1971263885498047,
        "compression_ratio": 1.8388278388278387,
        "end": 1048.82,
        "id": 387,
        "no_speech_prob": 0.000032192252547247335,
        "seek": 102412,
        "start": 1047.2199999999998,
        "temperature": 0,
        "text": " I'm going to just use one option.",
        "tokens": [
          51519,
          286,
          478,
          516,
          281,
          445,
          764,
          472,
          3614,
          13,
          51599
        ]
      },
      {
        "avg_logprob": -0.1971263885498047,
        "compression_ratio": 1.8388278388278387,
        "end": 1050.6599999999999,
        "id": 388,
        "no_speech_prob": 0.000032192252547247335,
        "seek": 102412,
        "start": 1048.82,
        "temperature": 0,
        "text": " I'm going to set something called an epoch.",
        "tokens": [
          51599,
          286,
          478,
          516,
          281,
          992,
          746,
          1219,
          364,
          30992,
          339,
          13,
          51691
        ]
      },
      {
        "avg_logprob": -0.1971263885498047,
        "compression_ratio": 1.8388278388278387,
        "end": 1053.34,
        "id": 389,
        "no_speech_prob": 0.000032192252547247335,
        "seek": 102412,
        "start": 1050.6599999999999,
        "temperature": 0,
        "text": " So I'm going to set the number of epochs to 100.",
        "tokens": [
          51691,
          407,
          286,
          478,
          516,
          281,
          992,
          264,
          1230,
          295,
          30992,
          28346,
          281,
          2319,
          13,
          51825
        ]
      },
      {
        "avg_logprob": -0.21304870233303164,
        "compression_ratio": 1.881720430107527,
        "end": 1054.72,
        "id": 390,
        "no_speech_prob": 0.00003944245690945536,
        "seek": 105334,
        "start": 1053.36,
        "temperature": 0,
        "text": " So what is an epoch?",
        "tokens": [
          50365,
          407,
          437,
          307,
          364,
          30992,
          339,
          30,
          50433
        ]
      },
      {
        "avg_logprob": -0.21304870233303164,
        "compression_ratio": 1.881720430107527,
        "end": 1058.12,
        "id": 391,
        "no_speech_prob": 0.00003944245690945536,
        "seek": 105334,
        "start": 1054.72,
        "temperature": 0,
        "text": " If I look at my training data, I have 30 data points.",
        "tokens": [
          50433,
          759,
          286,
          574,
          412,
          452,
          3097,
          1412,
          11,
          286,
          362,
          2217,
          1412,
          2793,
          13,
          50603
        ]
      },
      {
        "avg_logprob": -0.21304870233303164,
        "compression_ratio": 1.881720430107527,
        "end": 1060.1599999999999,
        "id": 392,
        "no_speech_prob": 0.00003944245690945536,
        "seek": 105334,
        "start": 1058.12,
        "temperature": 0,
        "text": " And I'm going to feed all of those things",
        "tokens": [
          50603,
          400,
          286,
          478,
          516,
          281,
          3154,
          439,
          295,
          729,
          721,
          50705
        ]
      },
      {
        "avg_logprob": -0.21304870233303164,
        "compression_ratio": 1.881720430107527,
        "end": 1061.32,
        "id": 393,
        "no_speech_prob": 0.00003944245690945536,
        "seek": 105334,
        "start": 1060.1599999999999,
        "temperature": 0,
        "text": " into the neural network.",
        "tokens": [
          50705,
          666,
          264,
          18161,
          3209,
          13,
          50763
        ]
      },
      {
        "avg_logprob": -0.21304870233303164,
        "compression_ratio": 1.881720430107527,
        "end": 1063.28,
        "id": 394,
        "no_speech_prob": 0.00003944245690945536,
        "seek": 105334,
        "start": 1061.32,
        "temperature": 0,
        "text": " I'm going to say, hey, neural network,",
        "tokens": [
          50763,
          286,
          478,
          516,
          281,
          584,
          11,
          4177,
          11,
          18161,
          3209,
          11,
          50861
        ]
      },
      {
        "avg_logprob": -0.21304870233303164,
        "compression_ratio": 1.881720430107527,
        "end": 1065.28,
        "id": 395,
        "no_speech_prob": 0.00003944245690945536,
        "seek": 105334,
        "start": 1063.28,
        "temperature": 0,
        "text": " here's an xy that goes with a c.",
        "tokens": [
          50861,
          510,
          311,
          364,
          2031,
          88,
          300,
          1709,
          365,
          257,
          269,
          13,
          50961
        ]
      },
      {
        "avg_logprob": -0.21304870233303164,
        "compression_ratio": 1.881720430107527,
        "end": 1067.24,
        "id": 396,
        "no_speech_prob": 0.00003944245690945536,
        "seek": 105334,
        "start": 1065.28,
        "temperature": 0,
        "text": " Here's an xy that goes with a c.",
        "tokens": [
          50961,
          1692,
          311,
          364,
          2031,
          88,
          300,
          1709,
          365,
          257,
          269,
          13,
          51059
        ]
      },
      {
        "avg_logprob": -0.21304870233303164,
        "compression_ratio": 1.881720430107527,
        "end": 1070.04,
        "id": 397,
        "no_speech_prob": 0.00003944245690945536,
        "seek": 105334,
        "start": 1067.24,
        "temperature": 0,
        "text": " Now, one thing that's important that ML5 does for you",
        "tokens": [
          51059,
          823,
          11,
          472,
          551,
          300,
          311,
          1021,
          300,
          21601,
          20,
          775,
          337,
          291,
          51199
        ]
      },
      {
        "avg_logprob": -0.21304870233303164,
        "compression_ratio": 1.881720430107527,
        "end": 1072.6,
        "id": 398,
        "no_speech_prob": 0.00003944245690945536,
        "seek": 105334,
        "start": 1070.04,
        "temperature": 0,
        "text": " behind the scenes is it shuffles all those into random order.",
        "tokens": [
          51199,
          2261,
          264,
          8026,
          307,
          309,
          402,
          1245,
          904,
          439,
          729,
          666,
          4974,
          1668,
          13,
          51327
        ]
      },
      {
        "avg_logprob": -0.21304870233303164,
        "compression_ratio": 1.881720430107527,
        "end": 1074.22,
        "id": 399,
        "no_speech_prob": 0.00003944245690945536,
        "seek": 105334,
        "start": 1072.6,
        "temperature": 0,
        "text": " Because the neural network's not going",
        "tokens": [
          51327,
          1436,
          264,
          18161,
          3209,
          311,
          406,
          516,
          51408
        ]
      },
      {
        "avg_logprob": -0.21304870233303164,
        "compression_ratio": 1.881720430107527,
        "end": 1077.1599999999999,
        "id": 400,
        "no_speech_prob": 0.00003944245690945536,
        "seek": 105334,
        "start": 1074.22,
        "temperature": 0,
        "text": " to learn so effectively if I send in all the c's and all",
        "tokens": [
          51408,
          281,
          1466,
          370,
          8659,
          498,
          286,
          2845,
          294,
          439,
          264,
          269,
          311,
          293,
          439,
          51555
        ]
      },
      {
        "avg_logprob": -0.21304870233303164,
        "compression_ratio": 1.881720430107527,
        "end": 1078.6,
        "id": 401,
        "no_speech_prob": 0.00003944245690945536,
        "seek": 105334,
        "start": 1077.1599999999999,
        "temperature": 0,
        "text": " the d's and then all the e's.",
        "tokens": [
          51555,
          264,
          274,
          311,
          293,
          550,
          439,
          264,
          308,
          311,
          13,
          51627
        ]
      },
      {
        "avg_logprob": -0.21304870233303164,
        "compression_ratio": 1.881720430107527,
        "end": 1080.28,
        "id": 402,
        "no_speech_prob": 0.00003944245690945536,
        "seek": 105334,
        "start": 1078.6,
        "temperature": 0,
        "text": " I want to send them in random order.",
        "tokens": [
          51627,
          286,
          528,
          281,
          2845,
          552,
          294,
          4974,
          1668,
          13,
          51711
        ]
      },
      {
        "avg_logprob": -0.1943641148560436,
        "compression_ratio": 1.7138047138047139,
        "end": 1083.74,
        "id": 403,
        "no_speech_prob": 0.0001941129012266174,
        "seek": 108028,
        "start": 1080.28,
        "temperature": 0,
        "text": " Sending in all 30 of those is one epoch.",
        "tokens": [
          50364,
          318,
          2029,
          294,
          439,
          2217,
          295,
          729,
          307,
          472,
          30992,
          339,
          13,
          50537
        ]
      },
      {
        "avg_logprob": -0.1943641148560436,
        "compression_ratio": 1.7138047138047139,
        "end": 1086.34,
        "id": 404,
        "no_speech_prob": 0.0001941129012266174,
        "seek": 108028,
        "start": 1083.74,
        "temperature": 0,
        "text": " Typically, that's not enough for the neural network",
        "tokens": [
          50537,
          23129,
          11,
          300,
          311,
          406,
          1547,
          337,
          264,
          18161,
          3209,
          50667
        ]
      },
      {
        "avg_logprob": -0.1943641148560436,
        "compression_ratio": 1.7138047138047139,
        "end": 1089.26,
        "id": 405,
        "no_speech_prob": 0.0001941129012266174,
        "seek": 108028,
        "start": 1086.34,
        "temperature": 0,
        "text": " to learn the optimal configuration of weights.",
        "tokens": [
          50667,
          281,
          1466,
          264,
          16252,
          11694,
          295,
          17443,
          13,
          50813
        ]
      },
      {
        "avg_logprob": -0.1943641148560436,
        "compression_ratio": 1.7138047138047139,
        "end": 1092.5,
        "id": 406,
        "no_speech_prob": 0.0001941129012266174,
        "seek": 108028,
        "start": 1089.26,
        "temperature": 0,
        "text": " So you want to send it in again and again and again.",
        "tokens": [
          50813,
          407,
          291,
          528,
          281,
          2845,
          309,
          294,
          797,
          293,
          797,
          293,
          797,
          13,
          50975
        ]
      },
      {
        "avg_logprob": -0.1943641148560436,
        "compression_ratio": 1.7138047138047139,
        "end": 1095.46,
        "id": 407,
        "no_speech_prob": 0.0001941129012266174,
        "seek": 108028,
        "start": 1092.5,
        "temperature": 0,
        "text": " So if I have 30 data points and I train for 100 epochs,",
        "tokens": [
          50975,
          407,
          498,
          286,
          362,
          2217,
          1412,
          2793,
          293,
          286,
          3847,
          337,
          2319,
          30992,
          28346,
          11,
          51123
        ]
      },
      {
        "avg_logprob": -0.1943641148560436,
        "compression_ratio": 1.7138047138047139,
        "end": 1099.02,
        "id": 408,
        "no_speech_prob": 0.0001941129012266174,
        "seek": 108028,
        "start": 1095.46,
        "temperature": 0,
        "text": " that's sending stuff through the neural network 3,000 times.",
        "tokens": [
          51123,
          300,
          311,
          7750,
          1507,
          807,
          264,
          18161,
          3209,
          805,
          11,
          1360,
          1413,
          13,
          51301
        ]
      },
      {
        "avg_logprob": -0.1943641148560436,
        "compression_ratio": 1.7138047138047139,
        "end": 1101.02,
        "id": 409,
        "no_speech_prob": 0.0001941129012266174,
        "seek": 108028,
        "start": 1099.02,
        "temperature": 0,
        "text": " Now, in truth, there's more to it than this.",
        "tokens": [
          51301,
          823,
          11,
          294,
          3494,
          11,
          456,
          311,
          544,
          281,
          309,
          813,
          341,
          13,
          51401
        ]
      },
      {
        "avg_logprob": -0.1943641148560436,
        "compression_ratio": 1.7138047138047139,
        "end": 1102.6,
        "id": 410,
        "no_speech_prob": 0.0001941129012266174,
        "seek": 108028,
        "start": 1101.02,
        "temperature": 0,
        "text": " There's something called a batch size,",
        "tokens": [
          51401,
          821,
          311,
          746,
          1219,
          257,
          15245,
          2744,
          11,
          51480
        ]
      },
      {
        "avg_logprob": -0.1943641148560436,
        "compression_ratio": 1.7138047138047139,
        "end": 1105.72,
        "id": 411,
        "no_speech_prob": 0.0001941129012266174,
        "seek": 108028,
        "start": 1102.6,
        "temperature": 0,
        "text": " because I might consider the data in smaller batches out",
        "tokens": [
          51480,
          570,
          286,
          1062,
          1949,
          264,
          1412,
          294,
          4356,
          15245,
          279,
          484,
          51636
        ]
      },
      {
        "avg_logprob": -0.1943641148560436,
        "compression_ratio": 1.7138047138047139,
        "end": 1106.44,
        "id": 412,
        "no_speech_prob": 0.0001941129012266174,
        "seek": 108028,
        "start": 1105.72,
        "temperature": 0,
        "text": " of those 30.",
        "tokens": [
          51636,
          295,
          729,
          2217,
          13,
          51672
        ]
      },
      {
        "avg_logprob": -0.1943641148560436,
        "compression_ratio": 1.7138047138047139,
        "end": 1109.08,
        "id": 413,
        "no_speech_prob": 0.0001941129012266174,
        "seek": 108028,
        "start": 1106.44,
        "temperature": 0,
        "text": " And that can affect how I adjust the weights.",
        "tokens": [
          51672,
          400,
          300,
          393,
          3345,
          577,
          286,
          4369,
          264,
          17443,
          13,
          51804
        ]
      },
      {
        "avg_logprob": -0.2210544694400003,
        "compression_ratio": 1.9316546762589928,
        "end": 1111.3799999999999,
        "id": 414,
        "no_speech_prob": 0.00026118956157006323,
        "seek": 110908,
        "start": 1109.1,
        "temperature": 0,
        "text": " But we don't need to worry about that.",
        "tokens": [
          50365,
          583,
          321,
          500,
          380,
          643,
          281,
          3292,
          466,
          300,
          13,
          50479
        ]
      },
      {
        "avg_logprob": -0.2210544694400003,
        "compression_ratio": 1.9316546762589928,
        "end": 1113.9399999999998,
        "id": 415,
        "no_speech_prob": 0.00026118956157006323,
        "seek": 110908,
        "start": 1111.3799999999999,
        "temperature": 0,
        "text": " Setting the number of epochs is a good starting point for us",
        "tokens": [
          50479,
          21063,
          264,
          1230,
          295,
          30992,
          28346,
          307,
          257,
          665,
          2891,
          935,
          337,
          505,
          50607
        ]
      },
      {
        "avg_logprob": -0.2210544694400003,
        "compression_ratio": 1.9316546762589928,
        "end": 1116.22,
        "id": 416,
        "no_speech_prob": 0.00026118956157006323,
        "seek": 110908,
        "start": 1113.9399999999998,
        "temperature": 0,
        "text": " to start thinking about the process of training",
        "tokens": [
          50607,
          281,
          722,
          1953,
          466,
          264,
          1399,
          295,
          3097,
          50721
        ]
      },
      {
        "avg_logprob": -0.2210544694400003,
        "compression_ratio": 1.9316546762589928,
        "end": 1117.34,
        "id": 417,
        "no_speech_prob": 0.00026118956157006323,
        "seek": 110908,
        "start": 1116.22,
        "temperature": 0,
        "text": " a neural network.",
        "tokens": [
          50721,
          257,
          18161,
          3209,
          13,
          50777
        ]
      },
      {
        "avg_logprob": -0.2210544694400003,
        "compression_ratio": 1.9316546762589928,
        "end": 1120.74,
        "id": 418,
        "no_speech_prob": 0.00026118956157006323,
        "seek": 110908,
        "start": 1117.34,
        "temperature": 0,
        "text": " So I can pass to the train function the options.",
        "tokens": [
          50777,
          407,
          286,
          393,
          1320,
          281,
          264,
          3847,
          2445,
          264,
          3956,
          13,
          50947
        ]
      },
      {
        "avg_logprob": -0.2210544694400003,
        "compression_ratio": 1.9316546762589928,
        "end": 1123.84,
        "id": 419,
        "no_speech_prob": 0.00026118956157006323,
        "seek": 110908,
        "start": 1120.74,
        "temperature": 0,
        "text": " And then the train function also has two callbacks.",
        "tokens": [
          50947,
          400,
          550,
          264,
          3847,
          2445,
          611,
          575,
          732,
          818,
          17758,
          13,
          51102
        ]
      },
      {
        "avg_logprob": -0.2210544694400003,
        "compression_ratio": 1.9316546762589928,
        "end": 1125.8999999999999,
        "id": 420,
        "no_speech_prob": 0.00026118956157006323,
        "seek": 110908,
        "start": 1123.84,
        "temperature": 0,
        "text": " One is optional, but I'm going to use them both.",
        "tokens": [
          51102,
          1485,
          307,
          17312,
          11,
          457,
          286,
          478,
          516,
          281,
          764,
          552,
          1293,
          13,
          51205
        ]
      },
      {
        "avg_logprob": -0.2210544694400003,
        "compression_ratio": 1.9316546762589928,
        "end": 1129.48,
        "id": 421,
        "no_speech_prob": 0.00026118956157006323,
        "seek": 110908,
        "start": 1125.8999999999999,
        "temperature": 0,
        "text": " There's a while training callback and then",
        "tokens": [
          51205,
          821,
          311,
          257,
          1339,
          3097,
          818,
          3207,
          293,
          550,
          51384
        ]
      },
      {
        "avg_logprob": -0.2210544694400003,
        "compression_ratio": 1.9316546762589928,
        "end": 1131.58,
        "id": 422,
        "no_speech_prob": 0.00026118956157006323,
        "seek": 110908,
        "start": 1129.48,
        "temperature": 0,
        "text": " a finished training callback.",
        "tokens": [
          51384,
          257,
          4335,
          3097,
          818,
          3207,
          13,
          51489
        ]
      },
      {
        "avg_logprob": -0.2210544694400003,
        "compression_ratio": 1.9316546762589928,
        "end": 1133.54,
        "id": 423,
        "no_speech_prob": 0.00026118956157006323,
        "seek": 110908,
        "start": 1131.58,
        "temperature": 0,
        "text": " The idea is that there's a number of events",
        "tokens": [
          51489,
          440,
          1558,
          307,
          300,
          456,
          311,
          257,
          1230,
          295,
          3931,
          51587
        ]
      },
      {
        "avg_logprob": -0.2210544694400003,
        "compression_ratio": 1.9316546762589928,
        "end": 1135.6599999999999,
        "id": 424,
        "no_speech_prob": 0.00026118956157006323,
        "seek": 110908,
        "start": 1133.54,
        "temperature": 0,
        "text": " happening while you're training the neural network.",
        "tokens": [
          51587,
          2737,
          1339,
          291,
          434,
          3097,
          264,
          18161,
          3209,
          13,
          51693
        ]
      },
      {
        "avg_logprob": -0.2210544694400003,
        "compression_ratio": 1.9316546762589928,
        "end": 1138.9399999999998,
        "id": 425,
        "no_speech_prob": 0.00026118956157006323,
        "seek": 110908,
        "start": 1135.6599999999999,
        "temperature": 0,
        "text": " The while training callback is executed every epoch.",
        "tokens": [
          51693,
          440,
          1339,
          3097,
          818,
          3207,
          307,
          17577,
          633,
          30992,
          339,
          13,
          51857
        ]
      },
      {
        "avg_logprob": -0.22053497120485469,
        "compression_ratio": 1.7874015748031495,
        "end": 1140.88,
        "id": 426,
        "no_speech_prob": 0.000058291097957408056,
        "seek": 113894,
        "start": 1138.96,
        "temperature": 0,
        "text": " So that'll get executed 100 times.",
        "tokens": [
          50365,
          407,
          300,
          603,
          483,
          17577,
          2319,
          1413,
          13,
          50461
        ]
      },
      {
        "avg_logprob": -0.22053497120485469,
        "compression_ratio": 1.7874015748031495,
        "end": 1142.28,
        "id": 427,
        "no_speech_prob": 0.000058291097957408056,
        "seek": 113894,
        "start": 1140.88,
        "temperature": 0,
        "text": " And the finished training callback",
        "tokens": [
          50461,
          400,
          264,
          4335,
          3097,
          818,
          3207,
          50531
        ]
      },
      {
        "avg_logprob": -0.22053497120485469,
        "compression_ratio": 1.7874015748031495,
        "end": 1144.76,
        "id": 428,
        "no_speech_prob": 0.000058291097957408056,
        "seek": 113894,
        "start": 1142.28,
        "temperature": 0,
        "text": " is executed when the whole thing is finished.",
        "tokens": [
          50531,
          307,
          17577,
          562,
          264,
          1379,
          551,
          307,
          4335,
          13,
          50655
        ]
      },
      {
        "avg_logprob": -0.22053497120485469,
        "compression_ratio": 1.7874015748031495,
        "end": 1146.16,
        "id": 429,
        "no_speech_prob": 0.000058291097957408056,
        "seek": 113894,
        "start": 1144.76,
        "temperature": 0,
        "text": " So let me write those functions.",
        "tokens": [
          50655,
          407,
          718,
          385,
          2464,
          729,
          6828,
          13,
          50725
        ]
      },
      {
        "avg_logprob": -0.22053497120485469,
        "compression_ratio": 1.7874015748031495,
        "end": 1153.28,
        "id": 430,
        "no_speech_prob": 0.000058291097957408056,
        "seek": 113894,
        "start": 1148.72,
        "temperature": 0,
        "text": " In finished training, I'm just going to add a console log.",
        "tokens": [
          50853,
          682,
          4335,
          3097,
          11,
          286,
          478,
          445,
          516,
          281,
          909,
          257,
          11076,
          3565,
          13,
          51081
        ]
      },
      {
        "avg_logprob": -0.22053497120485469,
        "compression_ratio": 1.7874015748031495,
        "end": 1156.3600000000001,
        "id": 431,
        "no_speech_prob": 0.000058291097957408056,
        "seek": 113894,
        "start": 1153.28,
        "temperature": 0,
        "text": " While training actually receives information",
        "tokens": [
          51081,
          3987,
          3097,
          767,
          20717,
          1589,
          51235
        ]
      },
      {
        "avg_logprob": -0.22053497120485469,
        "compression_ratio": 1.7874015748031495,
        "end": 1157.6000000000001,
        "id": 432,
        "no_speech_prob": 0.000058291097957408056,
        "seek": 113894,
        "start": 1156.3600000000001,
        "temperature": 0,
        "text": " about the training process.",
        "tokens": [
          51235,
          466,
          264,
          3097,
          1399,
          13,
          51297
        ]
      },
      {
        "avg_logprob": -0.22053497120485469,
        "compression_ratio": 1.7874015748031495,
        "end": 1162.1200000000001,
        "id": 433,
        "no_speech_prob": 0.000058291097957408056,
        "seek": 113894,
        "start": 1157.6000000000001,
        "temperature": 0,
        "text": " And it receives two things, an epoch and a loss.",
        "tokens": [
          51297,
          400,
          309,
          20717,
          732,
          721,
          11,
          364,
          30992,
          339,
          293,
          257,
          4470,
          13,
          51523
        ]
      },
      {
        "avg_logprob": -0.22053497120485469,
        "compression_ratio": 1.7874015748031495,
        "end": 1164.3600000000001,
        "id": 434,
        "no_speech_prob": 0.000058291097957408056,
        "seek": 113894,
        "start": 1162.1200000000001,
        "temperature": 0,
        "text": " These callbacks really work as debugging tools",
        "tokens": [
          51523,
          1981,
          818,
          17758,
          534,
          589,
          382,
          45592,
          3873,
          51635
        ]
      },
      {
        "avg_logprob": -0.22053497120485469,
        "compression_ratio": 1.7874015748031495,
        "end": 1167.0800000000002,
        "id": 435,
        "no_speech_prob": 0.000058291097957408056,
        "seek": 113894,
        "start": 1164.3600000000001,
        "temperature": 0,
        "text": " for me to look at how the training process is going.",
        "tokens": [
          51635,
          337,
          385,
          281,
          574,
          412,
          577,
          264,
          3097,
          1399,
          307,
          516,
          13,
          51771
        ]
      },
      {
        "avg_logprob": -0.22053497120485469,
        "compression_ratio": 1.7874015748031495,
        "end": 1168.28,
        "id": 436,
        "no_speech_prob": 0.000058291097957408056,
        "seek": 113894,
        "start": 1167.0800000000002,
        "temperature": 0,
        "text": " Oh, that epoch finished.",
        "tokens": [
          51771,
          876,
          11,
          300,
          30992,
          339,
          4335,
          13,
          51831
        ]
      },
      {
        "avg_logprob": -0.2108173035738761,
        "compression_ratio": 1.5698529411764706,
        "end": 1169.26,
        "id": 437,
        "no_speech_prob": 0.00016346439952030778,
        "seek": 116828,
        "start": 1168.34,
        "temperature": 0,
        "text": " What was the loss?",
        "tokens": [
          50367,
          708,
          390,
          264,
          4470,
          30,
          50413
        ]
      },
      {
        "avg_logprob": -0.2108173035738761,
        "compression_ratio": 1.5698529411764706,
        "end": 1172.3799999999999,
        "id": 438,
        "no_speech_prob": 0.00016346439952030778,
        "seek": 116828,
        "start": 1169.26,
        "temperature": 0,
        "text": " And I need to come back and talk about what loss is.",
        "tokens": [
          50413,
          400,
          286,
          643,
          281,
          808,
          646,
          293,
          751,
          466,
          437,
          4470,
          307,
          13,
          50569
        ]
      },
      {
        "avg_logprob": -0.2108173035738761,
        "compression_ratio": 1.5698529411764706,
        "end": 1174.78,
        "id": 439,
        "no_speech_prob": 0.00016346439952030778,
        "seek": 116828,
        "start": 1172.3799999999999,
        "temperature": 0,
        "text": " But I can really look at what's happening while it's training",
        "tokens": [
          50569,
          583,
          286,
          393,
          534,
          574,
          412,
          437,
          311,
          2737,
          1339,
          309,
          311,
          3097,
          50689
        ]
      },
      {
        "avg_logprob": -0.2108173035738761,
        "compression_ratio": 1.5698529411764706,
        "end": 1176.8999999999999,
        "id": 440,
        "no_speech_prob": 0.00016346439952030778,
        "seek": 116828,
        "start": 1174.78,
        "temperature": 0,
        "text": " and then know that the training has finished.",
        "tokens": [
          50689,
          293,
          550,
          458,
          300,
          264,
          3097,
          575,
          4335,
          13,
          50795
        ]
      },
      {
        "avg_logprob": -0.2108173035738761,
        "compression_ratio": 1.5698529411764706,
        "end": 1182.06,
        "id": 441,
        "no_speech_prob": 0.00016346439952030778,
        "seek": 116828,
        "start": 1176.8999999999999,
        "temperature": 0,
        "text": " ML5, however, has built into it a visualization functionality",
        "tokens": [
          50795,
          21601,
          20,
          11,
          4461,
          11,
          575,
          3094,
          666,
          309,
          257,
          25801,
          14980,
          51053
        ]
      },
      {
        "avg_logprob": -0.2108173035738761,
        "compression_ratio": 1.5698529411764706,
        "end": 1184.66,
        "id": 442,
        "no_speech_prob": 0.00016346439952030778,
        "seek": 116828,
        "start": 1182.06,
        "temperature": 0,
        "text": " that's part of TensorFlow.js itself,",
        "tokens": [
          51053,
          300,
          311,
          644,
          295,
          37624,
          13,
          25530,
          2564,
          11,
          51183
        ]
      },
      {
        "avg_logprob": -0.2108173035738761,
        "compression_ratio": 1.5698529411764706,
        "end": 1187.46,
        "id": 443,
        "no_speech_prob": 0.00016346439952030778,
        "seek": 116828,
        "start": 1184.66,
        "temperature": 0,
        "text": " particularly this library called tf.vis.",
        "tokens": [
          51183,
          4098,
          341,
          6405,
          1219,
          256,
          69,
          13,
          4938,
          13,
          51323
        ]
      },
      {
        "avg_logprob": -0.2108173035738761,
        "compression_ratio": 1.5698529411764706,
        "end": 1190.62,
        "id": 444,
        "no_speech_prob": 0.00016346439952030778,
        "seek": 116828,
        "start": 1187.46,
        "temperature": 0,
        "text": " And I can enable that by adding one more option",
        "tokens": [
          51323,
          400,
          286,
          393,
          9528,
          300,
          538,
          5127,
          472,
          544,
          3614,
          51481
        ]
      },
      {
        "avg_logprob": -0.2108173035738761,
        "compression_ratio": 1.5698529411764706,
        "end": 1193.02,
        "id": 445,
        "no_speech_prob": 0.00016346439952030778,
        "seek": 116828,
        "start": 1190.62,
        "temperature": 0,
        "text": " to my neural network configuration.",
        "tokens": [
          51481,
          281,
          452,
          18161,
          3209,
          11694,
          13,
          51601
        ]
      },
      {
        "avg_logprob": -0.2108173035738761,
        "compression_ratio": 1.5698529411764706,
        "end": 1197.34,
        "id": 446,
        "no_speech_prob": 0.00016346439952030778,
        "seek": 116828,
        "start": 1193.02,
        "temperature": 0,
        "text": " And that is debug true.",
        "tokens": [
          51601,
          400,
          300,
          307,
          24083,
          2074,
          13,
          51817
        ]
      },
      {
        "avg_logprob": -0.17841294232536764,
        "compression_ratio": 1.583657587548638,
        "end": 1200.12,
        "id": 447,
        "no_speech_prob": 0.000046838827984174713,
        "seek": 119734,
        "start": 1197.34,
        "temperature": 0,
        "text": " If I add debug true, I'm going to get much better tools",
        "tokens": [
          50364,
          759,
          286,
          909,
          24083,
          2074,
          11,
          286,
          478,
          516,
          281,
          483,
          709,
          1101,
          3873,
          50503
        ]
      },
      {
        "avg_logprob": -0.17841294232536764,
        "compression_ratio": 1.583657587548638,
        "end": 1202.76,
        "id": 448,
        "no_speech_prob": 0.000046838827984174713,
        "seek": 119734,
        "start": 1200.12,
        "temperature": 0,
        "text": " than what I've got here with my own callbacks.",
        "tokens": [
          50503,
          813,
          437,
          286,
          600,
          658,
          510,
          365,
          452,
          1065,
          818,
          17758,
          13,
          50635
        ]
      },
      {
        "avg_logprob": -0.17841294232536764,
        "compression_ratio": 1.583657587548638,
        "end": 1206.36,
        "id": 449,
        "no_speech_prob": 0.000046838827984174713,
        "seek": 119734,
        "start": 1202.76,
        "temperature": 0,
        "text": " There's one more thing that I've missed here.",
        "tokens": [
          50635,
          821,
          311,
          472,
          544,
          551,
          300,
          286,
          600,
          6721,
          510,
          13,
          50815
        ]
      },
      {
        "avg_logprob": -0.17841294232536764,
        "compression_ratio": 1.583657587548638,
        "end": 1210.48,
        "id": 450,
        "no_speech_prob": 0.000046838827984174713,
        "seek": 119734,
        "start": 1206.36,
        "temperature": 0,
        "text": " And that has to do with normalizing the data.",
        "tokens": [
          50815,
          400,
          300,
          575,
          281,
          360,
          365,
          2710,
          3319,
          264,
          1412,
          13,
          51021
        ]
      },
      {
        "avg_logprob": -0.17841294232536764,
        "compression_ratio": 1.583657587548638,
        "end": 1213.08,
        "id": 451,
        "no_speech_prob": 0.000046838827984174713,
        "seek": 119734,
        "start": 1210.48,
        "temperature": 0,
        "text": " What does our trading data look like?",
        "tokens": [
          51021,
          708,
          775,
          527,
          9529,
          1412,
          574,
          411,
          30,
          51151
        ]
      },
      {
        "avg_logprob": -0.17841294232536764,
        "compression_ratio": 1.583657587548638,
        "end": 1215.3,
        "id": 452,
        "no_speech_prob": 0.000046838827984174713,
        "seek": 119734,
        "start": 1213.08,
        "temperature": 0,
        "text": " Remember, I've got this P5 canvas.",
        "tokens": [
          51151,
          5459,
          11,
          286,
          600,
          658,
          341,
          430,
          20,
          16267,
          13,
          51262
        ]
      },
      {
        "avg_logprob": -0.17841294232536764,
        "compression_ratio": 1.583657587548638,
        "end": 1218.1599999999999,
        "id": 453,
        "no_speech_prob": 0.000046838827984174713,
        "seek": 119734,
        "start": 1215.3,
        "temperature": 0,
        "text": " Maybe it's 400 by 400.",
        "tokens": [
          51262,
          2704,
          309,
          311,
          8423,
          538,
          8423,
          13,
          51405
        ]
      },
      {
        "avg_logprob": -0.17841294232536764,
        "compression_ratio": 1.583657587548638,
        "end": 1222.48,
        "id": 454,
        "no_speech_prob": 0.000046838827984174713,
        "seek": 119734,
        "start": 1218.1599999999999,
        "temperature": 0,
        "text": " Any given input is a mouse click into that canvas, like here.",
        "tokens": [
          51405,
          2639,
          2212,
          4846,
          307,
          257,
          9719,
          2052,
          666,
          300,
          16267,
          11,
          411,
          510,
          13,
          51621
        ]
      },
      {
        "avg_logprob": -0.17841294232536764,
        "compression_ratio": 1.583657587548638,
        "end": 1226.8,
        "id": 455,
        "no_speech_prob": 0.000046838827984174713,
        "seek": 119734,
        "start": 1222.48,
        "temperature": 0,
        "text": " And so this might be the mouse location 100 comma 100.",
        "tokens": [
          51621,
          400,
          370,
          341,
          1062,
          312,
          264,
          9719,
          4914,
          2319,
          22117,
          2319,
          13,
          51837
        ]
      },
      {
        "avg_logprob": -0.21481843697008238,
        "compression_ratio": 1.6677966101694914,
        "end": 1229.8999999999999,
        "id": 456,
        "no_speech_prob": 0.0000056824273997335695,
        "seek": 122680,
        "start": 1226.8,
        "temperature": 0,
        "text": " So that would mean the literal number 100",
        "tokens": [
          50364,
          407,
          300,
          576,
          914,
          264,
          20411,
          1230,
          2319,
          50519
        ]
      },
      {
        "avg_logprob": -0.21481843697008238,
        "compression_ratio": 1.6677966101694914,
        "end": 1232.54,
        "id": 457,
        "no_speech_prob": 0.0000056824273997335695,
        "seek": 122680,
        "start": 1229.8999999999999,
        "temperature": 0,
        "text": " is being fed into the neural network.",
        "tokens": [
          50519,
          307,
          885,
          4636,
          666,
          264,
          18161,
          3209,
          13,
          50651
        ]
      },
      {
        "avg_logprob": -0.21481843697008238,
        "compression_ratio": 1.6677966101694914,
        "end": 1234.4199999999998,
        "id": 458,
        "no_speech_prob": 0.0000056824273997335695,
        "seek": 122680,
        "start": 1232.54,
        "temperature": 0,
        "text": " But neural networks are generally",
        "tokens": [
          50651,
          583,
          18161,
          9590,
          366,
          5101,
          50745
        ]
      },
      {
        "avg_logprob": -0.21481843697008238,
        "compression_ratio": 1.6677966101694914,
        "end": 1237.6599999999999,
        "id": 459,
        "no_speech_prob": 0.0000056824273997335695,
        "seek": 122680,
        "start": 1234.4199999999998,
        "temperature": 0,
        "text": " tuned to work with data that's all standardized",
        "tokens": [
          50745,
          10870,
          281,
          589,
          365,
          1412,
          300,
          311,
          439,
          31677,
          50907
        ]
      },
      {
        "avg_logprob": -0.21481843697008238,
        "compression_ratio": 1.6677966101694914,
        "end": 1239.22,
        "id": 460,
        "no_speech_prob": 0.0000056824273997335695,
        "seek": 122680,
        "start": 1237.6599999999999,
        "temperature": 0,
        "text": " within a particular range.",
        "tokens": [
          50907,
          1951,
          257,
          1729,
          3613,
          13,
          50985
        ]
      },
      {
        "avg_logprob": -0.21481843697008238,
        "compression_ratio": 1.6677966101694914,
        "end": 1241.76,
        "id": 461,
        "no_speech_prob": 0.0000056824273997335695,
        "seek": 122680,
        "start": 1239.22,
        "temperature": 0,
        "text": " And there could be a variety of ways you might want to use one",
        "tokens": [
          50985,
          400,
          456,
          727,
          312,
          257,
          5673,
          295,
          2098,
          291,
          1062,
          528,
          281,
          764,
          472,
          51112
        ]
      },
      {
        "avg_logprob": -0.21481843697008238,
        "compression_ratio": 1.6677966101694914,
        "end": 1243.22,
        "id": 462,
        "no_speech_prob": 0.0000056824273997335695,
        "seek": 122680,
        "start": 1241.76,
        "temperature": 0,
        "text": " range versus another.",
        "tokens": [
          51112,
          3613,
          5717,
          1071,
          13,
          51185
        ]
      },
      {
        "avg_logprob": -0.21481843697008238,
        "compression_ratio": 1.6677966101694914,
        "end": 1245.26,
        "id": 463,
        "no_speech_prob": 0.0000056824273997335695,
        "seek": 122680,
        "start": 1243.22,
        "temperature": 0,
        "text": " But in many cases, you always want",
        "tokens": [
          51185,
          583,
          294,
          867,
          3331,
          11,
          291,
          1009,
          528,
          51287
        ]
      },
      {
        "avg_logprob": -0.21481843697008238,
        "compression_ratio": 1.6677966101694914,
        "end": 1249.5,
        "id": 464,
        "no_speech_prob": 0.0000056824273997335695,
        "seek": 122680,
        "start": 1245.26,
        "temperature": 0,
        "text": " to squash your input data into a range between 0 and 1.",
        "tokens": [
          51287,
          281,
          30725,
          428,
          4846,
          1412,
          666,
          257,
          3613,
          1296,
          1958,
          293,
          502,
          13,
          51499
        ]
      },
      {
        "avg_logprob": -0.21481843697008238,
        "compression_ratio": 1.6677966101694914,
        "end": 1251.82,
        "id": 465,
        "no_speech_prob": 0.0000056824273997335695,
        "seek": 122680,
        "start": 1249.5,
        "temperature": 0,
        "text": " And that process is called normalization.",
        "tokens": [
          51499,
          400,
          300,
          1399,
          307,
          1219,
          2710,
          2144,
          13,
          51615
        ]
      },
      {
        "avg_logprob": -0.21481843697008238,
        "compression_ratio": 1.6677966101694914,
        "end": 1253.9199999999998,
        "id": 466,
        "no_speech_prob": 0.0000056824273997335695,
        "seek": 122680,
        "start": 1251.82,
        "temperature": 0,
        "text": " So that would be really easy for me to do myself.",
        "tokens": [
          51615,
          407,
          300,
          576,
          312,
          534,
          1858,
          337,
          385,
          281,
          360,
          2059,
          13,
          51720
        ]
      },
      {
        "avg_logprob": -0.21481843697008238,
        "compression_ratio": 1.6677966101694914,
        "end": 1255.8999999999999,
        "id": 467,
        "no_speech_prob": 0.0000056824273997335695,
        "seek": 122680,
        "start": 1253.9199999999998,
        "temperature": 0,
        "text": " Because if I know the width is 400,",
        "tokens": [
          51720,
          1436,
          498,
          286,
          458,
          264,
          11402,
          307,
          8423,
          11,
          51819
        ]
      },
      {
        "avg_logprob": -0.1975303087078157,
        "compression_ratio": 1.6875,
        "end": 1259.96,
        "id": 468,
        "no_speech_prob": 0.0000498595109093003,
        "seek": 125590,
        "start": 1255.9,
        "temperature": 0,
        "text": " I could just say 100 divided by 400 is 0.25.",
        "tokens": [
          50364,
          286,
          727,
          445,
          584,
          2319,
          6666,
          538,
          8423,
          307,
          1958,
          13,
          6074,
          13,
          50567
        ]
      },
      {
        "avg_logprob": -0.1975303087078157,
        "compression_ratio": 1.6875,
        "end": 1262.64,
        "id": 469,
        "no_speech_prob": 0.0000498595109093003,
        "seek": 125590,
        "start": 1259.96,
        "temperature": 0,
        "text": " So I could apply this normalization math myself",
        "tokens": [
          50567,
          407,
          286,
          727,
          3079,
          341,
          2710,
          2144,
          5221,
          2059,
          50701
        ]
      },
      {
        "avg_logprob": -0.1975303087078157,
        "compression_ratio": 1.6875,
        "end": 1263.4,
        "id": 470,
        "no_speech_prob": 0.0000498595109093003,
        "seek": 125590,
        "start": 1262.64,
        "temperature": 0,
        "text": " in the code.",
        "tokens": [
          50701,
          294,
          264,
          3089,
          13,
          50739
        ]
      },
      {
        "avg_logprob": -0.1975303087078157,
        "compression_ratio": 1.6875,
        "end": 1265.6000000000001,
        "id": 471,
        "no_speech_prob": 0.0000498595109093003,
        "seek": 125590,
        "start": 1263.4,
        "temperature": 0,
        "text": " But ml5 has a function built into it",
        "tokens": [
          50739,
          583,
          23271,
          20,
          575,
          257,
          2445,
          3094,
          666,
          309,
          50849
        ]
      },
      {
        "avg_logprob": -0.1975303087078157,
        "compression_ratio": 1.6875,
        "end": 1267.8000000000002,
        "id": 472,
        "no_speech_prob": 0.0000498595109093003,
        "seek": 125590,
        "start": 1265.6000000000001,
        "temperature": 0,
        "text": " that you can call right before you train the data that",
        "tokens": [
          50849,
          300,
          291,
          393,
          818,
          558,
          949,
          291,
          3847,
          264,
          1412,
          300,
          50959
        ]
      },
      {
        "avg_logprob": -0.1975303087078157,
        "compression_ratio": 1.6875,
        "end": 1270.5600000000002,
        "id": 473,
        "no_speech_prob": 0.0000498595109093003,
        "seek": 125590,
        "start": 1267.8000000000002,
        "temperature": 0,
        "text": " will look at the minimum and maximums of all of your input",
        "tokens": [
          50959,
          486,
          574,
          412,
          264,
          7285,
          293,
          6674,
          82,
          295,
          439,
          295,
          428,
          4846,
          51097
        ]
      },
      {
        "avg_logprob": -0.1975303087078157,
        "compression_ratio": 1.6875,
        "end": 1272.5600000000002,
        "id": 474,
        "no_speech_prob": 0.0000498595109093003,
        "seek": 125590,
        "start": 1270.5600000000002,
        "temperature": 0,
        "text": " data and normalize it.",
        "tokens": [
          51097,
          1412,
          293,
          2710,
          1125,
          309,
          13,
          51197
        ]
      },
      {
        "avg_logprob": -0.1975303087078157,
        "compression_ratio": 1.6875,
        "end": 1274.96,
        "id": 475,
        "no_speech_prob": 0.0000498595109093003,
        "seek": 125590,
        "start": 1272.5600000000002,
        "temperature": 0,
        "text": " So coming over here, I can call that function right",
        "tokens": [
          51197,
          407,
          1348,
          670,
          510,
          11,
          286,
          393,
          818,
          300,
          2445,
          558,
          51317
        ]
      },
      {
        "avg_logprob": -0.1975303087078157,
        "compression_ratio": 1.6875,
        "end": 1280.8600000000001,
        "id": 476,
        "no_speech_prob": 0.0000498595109093003,
        "seek": 125590,
        "start": 1274.96,
        "temperature": 0,
        "text": " before I train the model by saying model.normalizeData.",
        "tokens": [
          51317,
          949,
          286,
          3847,
          264,
          2316,
          538,
          1566,
          2316,
          13,
          23157,
          1125,
          35,
          3274,
          13,
          51612
        ]
      },
      {
        "avg_logprob": -0.1975303087078157,
        "compression_ratio": 1.6875,
        "end": 1284.8000000000002,
        "id": 477,
        "no_speech_prob": 0.0000498595109093003,
        "seek": 125590,
        "start": 1280.8600000000001,
        "temperature": 0,
        "text": " And now I think I am ready to actually train",
        "tokens": [
          51612,
          400,
          586,
          286,
          519,
          286,
          669,
          1919,
          281,
          767,
          3847,
          51809
        ]
      },
      {
        "avg_logprob": -0.2385728851822782,
        "compression_ratio": 1.6411290322580645,
        "end": 1290.02,
        "id": 478,
        "no_speech_prob": 0.00008750295091886073,
        "seek": 128480,
        "start": 1284.8,
        "temperature": 0,
        "text": " the model for the very first time and complete step two.",
        "tokens": [
          50364,
          264,
          2316,
          337,
          264,
          588,
          700,
          565,
          293,
          3566,
          1823,
          732,
          13,
          50625
        ]
      },
      {
        "avg_logprob": -0.2385728851822782,
        "compression_ratio": 1.6411290322580645,
        "end": 1291.58,
        "id": 479,
        "no_speech_prob": 0.00008750295091886073,
        "seek": 128480,
        "start": 1290.02,
        "temperature": 0,
        "text": " Let's give it a try.",
        "tokens": [
          50625,
          961,
          311,
          976,
          309,
          257,
          853,
          13,
          50703
        ]
      },
      {
        "avg_logprob": -0.2385728851822782,
        "compression_ratio": 1.6411290322580645,
        "end": 1293.68,
        "id": 480,
        "no_speech_prob": 0.00008750295091886073,
        "seek": 128480,
        "start": 1291.58,
        "temperature": 0,
        "text": " Let's add a console log to know that the training",
        "tokens": [
          50703,
          961,
          311,
          909,
          257,
          11076,
          3565,
          281,
          458,
          300,
          264,
          3097,
          50808
        ]
      },
      {
        "avg_logprob": -0.2385728851822782,
        "compression_ratio": 1.6411290322580645,
        "end": 1296.46,
        "id": 481,
        "no_speech_prob": 0.00008750295091886073,
        "seek": 128480,
        "start": 1293.68,
        "temperature": 0,
        "text": " process is starting.",
        "tokens": [
          50808,
          1399,
          307,
          2891,
          13,
          50947
        ]
      },
      {
        "avg_logprob": -0.2385728851822782,
        "compression_ratio": 1.6411290322580645,
        "end": 1297.78,
        "id": 482,
        "no_speech_prob": 0.00008750295091886073,
        "seek": 128480,
        "start": 1296.46,
        "temperature": 0,
        "text": " Let's collect a lot of data.",
        "tokens": [
          50947,
          961,
          311,
          2500,
          257,
          688,
          295,
          1412,
          13,
          51013
        ]
      },
      {
        "avg_logprob": -0.2385728851822782,
        "compression_ratio": 1.6411290322580645,
        "end": 1305.08,
        "id": 483,
        "no_speech_prob": 0.00008750295091886073,
        "seek": 128480,
        "start": 1302.46,
        "temperature": 0,
        "text": " Now, I'm clustering all my C's and D's and E's together.",
        "tokens": [
          51247,
          823,
          11,
          286,
          478,
          596,
          48673,
          439,
          452,
          383,
          311,
          293,
          413,
          311,
          293,
          462,
          311,
          1214,
          13,
          51378
        ]
      },
      {
        "avg_logprob": -0.2385728851822782,
        "compression_ratio": 1.6411290322580645,
        "end": 1306.74,
        "id": 484,
        "no_speech_prob": 0.00008750295091886073,
        "seek": 128480,
        "start": 1305.08,
        "temperature": 0,
        "text": " Because I want to create a scenario that",
        "tokens": [
          51378,
          1436,
          286,
          528,
          281,
          1884,
          257,
          9005,
          300,
          51461
        ]
      },
      {
        "avg_logprob": -0.2385728851822782,
        "compression_ratio": 1.6411290322580645,
        "end": 1308.86,
        "id": 485,
        "no_speech_prob": 0.00008750295091886073,
        "seek": 128480,
        "start": 1306.74,
        "temperature": 0,
        "text": " should be easy for the neural network to learn.",
        "tokens": [
          51461,
          820,
          312,
          1858,
          337,
          264,
          18161,
          3209,
          281,
          1466,
          13,
          51567
        ]
      },
      {
        "avg_logprob": -0.2385728851822782,
        "compression_ratio": 1.6411290322580645,
        "end": 1310.54,
        "id": 486,
        "no_speech_prob": 0.00008750295091886073,
        "seek": 128480,
        "start": 1308.86,
        "temperature": 0,
        "text": " Again, I don't need a neural network",
        "tokens": [
          51567,
          3764,
          11,
          286,
          500,
          380,
          643,
          257,
          18161,
          3209,
          51651
        ]
      },
      {
        "avg_logprob": -0.2385728851822782,
        "compression_ratio": 1.6411290322580645,
        "end": 1313.1,
        "id": 487,
        "no_speech_prob": 0.00008750295091886073,
        "seek": 128480,
        "start": 1310.54,
        "temperature": 0,
        "text": " to figure out that there's C's in the top left",
        "tokens": [
          51651,
          281,
          2573,
          484,
          300,
          456,
          311,
          383,
          311,
          294,
          264,
          1192,
          1411,
          51779
        ]
      },
      {
        "avg_logprob": -0.21607941075375206,
        "compression_ratio": 1.6431095406360423,
        "end": 1315.1599999999999,
        "id": 488,
        "no_speech_prob": 0.00023413558665197343,
        "seek": 131310,
        "start": 1313.1,
        "temperature": 0,
        "text": " and D's in the top right and E's on the bottom.",
        "tokens": [
          50364,
          293,
          413,
          311,
          294,
          264,
          1192,
          558,
          293,
          462,
          311,
          322,
          264,
          2767,
          13,
          50467
        ]
      },
      {
        "avg_logprob": -0.21607941075375206,
        "compression_ratio": 1.6431095406360423,
        "end": 1317.48,
        "id": 489,
        "no_speech_prob": 0.00023413558665197343,
        "seek": 131310,
        "start": 1315.1599999999999,
        "temperature": 0,
        "text": " But if the neural network can learn this scenario,",
        "tokens": [
          50467,
          583,
          498,
          264,
          18161,
          3209,
          393,
          1466,
          341,
          9005,
          11,
          50583
        ]
      },
      {
        "avg_logprob": -0.21607941075375206,
        "compression_ratio": 1.6431095406360423,
        "end": 1320,
        "id": 490,
        "no_speech_prob": 0.00023413558665197343,
        "seek": 131310,
        "start": 1317.48,
        "temperature": 0,
        "text": " more complex and interesting ones,",
        "tokens": [
          50583,
          544,
          3997,
          293,
          1880,
          2306,
          11,
          50709
        ]
      },
      {
        "avg_logprob": -0.21607941075375206,
        "compression_ratio": 1.6431095406360423,
        "end": 1321.9599999999998,
        "id": 491,
        "no_speech_prob": 0.00023413558665197343,
        "seek": 131310,
        "start": 1320,
        "temperature": 0,
        "text": " it could possibly learn as well.",
        "tokens": [
          50709,
          309,
          727,
          6264,
          1466,
          382,
          731,
          13,
          50807
        ]
      },
      {
        "avg_logprob": -0.21607941075375206,
        "compression_ratio": 1.6431095406360423,
        "end": 1324.52,
        "id": 492,
        "no_speech_prob": 0.00023413558665197343,
        "seek": 131310,
        "start": 1321.9599999999998,
        "temperature": 0,
        "text": " So again, if you remember, my exciting interface",
        "tokens": [
          50807,
          407,
          797,
          11,
          498,
          291,
          1604,
          11,
          452,
          4670,
          9226,
          50935
        ]
      },
      {
        "avg_logprob": -0.21607941075375206,
        "compression_ratio": 1.6431095406360423,
        "end": 1326.1599999999999,
        "id": 493,
        "no_speech_prob": 0.00023413558665197343,
        "seek": 131310,
        "start": 1324.52,
        "temperature": 0,
        "text": " was to press the T button.",
        "tokens": [
          50935,
          390,
          281,
          1886,
          264,
          314,
          2960,
          13,
          51017
        ]
      },
      {
        "avg_logprob": -0.21607941075375206,
        "compression_ratio": 1.6431095406360423,
        "end": 1327.36,
        "id": 494,
        "no_speech_prob": 0.00023413558665197343,
        "seek": 131310,
        "start": 1326.1599999999999,
        "temperature": 0,
        "text": " So I'm now going to press it.",
        "tokens": [
          51017,
          407,
          286,
          478,
          586,
          516,
          281,
          1886,
          309,
          13,
          51077
        ]
      },
      {
        "avg_logprob": -0.21607941075375206,
        "compression_ratio": 1.6431095406360423,
        "end": 1332.9199999999998,
        "id": 495,
        "no_speech_prob": 0.00023413558665197343,
        "seek": 131310,
        "start": 1330.4399999999998,
        "temperature": 0,
        "text": " And this is the debug view that pops out.",
        "tokens": [
          51231,
          400,
          341,
          307,
          264,
          24083,
          1910,
          300,
          16795,
          484,
          13,
          51355
        ]
      },
      {
        "avg_logprob": -0.21607941075375206,
        "compression_ratio": 1.6431095406360423,
        "end": 1336.3999999999999,
        "id": 496,
        "no_speech_prob": 0.00023413558665197343,
        "seek": 131310,
        "start": 1332.9199999999998,
        "temperature": 0,
        "text": " This comes up because I put debug as true.",
        "tokens": [
          51355,
          639,
          1487,
          493,
          570,
          286,
          829,
          24083,
          382,
          2074,
          13,
          51529
        ]
      },
      {
        "avg_logprob": -0.21607941075375206,
        "compression_ratio": 1.6431095406360423,
        "end": 1339.1999999999998,
        "id": 497,
        "no_speech_prob": 0.00023413558665197343,
        "seek": 131310,
        "start": 1336.3999999999999,
        "temperature": 0,
        "text": " And what you're seeing, you saw the epochs",
        "tokens": [
          51529,
          400,
          437,
          291,
          434,
          2577,
          11,
          291,
          1866,
          264,
          30992,
          28346,
          51669
        ]
      },
      {
        "avg_logprob": -0.21607941075375206,
        "compression_ratio": 1.6431095406360423,
        "end": 1340.48,
        "id": 498,
        "no_speech_prob": 0.00023413558665197343,
        "seek": 131310,
        "start": 1339.1999999999998,
        "temperature": 0,
        "text": " being console logged here.",
        "tokens": [
          51669,
          885,
          11076,
          27231,
          510,
          13,
          51733
        ]
      },
      {
        "avg_logprob": -0.21607941075375206,
        "compression_ratio": 1.6431095406360423,
        "end": 1341.9599999999998,
        "id": 499,
        "no_speech_prob": 0.00023413558665197343,
        "seek": 131310,
        "start": 1340.48,
        "temperature": 0,
        "text": " You see that it says finish training.",
        "tokens": [
          51733,
          509,
          536,
          300,
          309,
          1619,
          2413,
          3097,
          13,
          51807
        ]
      },
      {
        "avg_logprob": -0.19460413097280316,
        "compression_ratio": 1.5844748858447488,
        "end": 1345.74,
        "id": 500,
        "no_speech_prob": 0.000021112460672156885,
        "seek": 134196,
        "start": 1341.98,
        "temperature": 0,
        "text": " But this is showing me a graph of the loss.",
        "tokens": [
          50365,
          583,
          341,
          307,
          4099,
          385,
          257,
          4295,
          295,
          264,
          4470,
          13,
          50553
        ]
      },
      {
        "avg_logprob": -0.19460413097280316,
        "compression_ratio": 1.5844748858447488,
        "end": 1348.78,
        "id": 501,
        "no_speech_prob": 0.000021112460672156885,
        "seek": 134196,
        "start": 1345.74,
        "temperature": 0,
        "text": " The x-axis is the epoch.",
        "tokens": [
          50553,
          440,
          2031,
          12,
          24633,
          307,
          264,
          30992,
          339,
          13,
          50705
        ]
      },
      {
        "avg_logprob": -0.19460413097280316,
        "compression_ratio": 1.5844748858447488,
        "end": 1352.02,
        "id": 502,
        "no_speech_prob": 0.000021112460672156885,
        "seek": 134196,
        "start": 1348.78,
        "temperature": 0,
        "text": " And the y-axis is the value of the loss.",
        "tokens": [
          50705,
          400,
          264,
          288,
          12,
          24633,
          307,
          264,
          2158,
          295,
          264,
          4470,
          13,
          50867
        ]
      },
      {
        "avg_logprob": -0.19460413097280316,
        "compression_ratio": 1.5844748858447488,
        "end": 1353.58,
        "id": 503,
        "no_speech_prob": 0.000021112460672156885,
        "seek": 134196,
        "start": 1352.02,
        "temperature": 0,
        "text": " So what is loss?",
        "tokens": [
          50867,
          407,
          437,
          307,
          4470,
          30,
          50945
        ]
      },
      {
        "avg_logprob": -0.19460413097280316,
        "compression_ratio": 1.5844748858447488,
        "end": 1355.82,
        "id": 504,
        "no_speech_prob": 0.000021112460672156885,
        "seek": 134196,
        "start": 1353.58,
        "temperature": 0,
        "text": " If this particular data point that I'm",
        "tokens": [
          50945,
          759,
          341,
          1729,
          1412,
          935,
          300,
          286,
          478,
          51057
        ]
      },
      {
        "avg_logprob": -0.19460413097280316,
        "compression_ratio": 1.5844748858447488,
        "end": 1357.82,
        "id": 505,
        "no_speech_prob": 0.000021112460672156885,
        "seek": 134196,
        "start": 1355.82,
        "temperature": 0,
        "text": " sending into the neural network is",
        "tokens": [
          51057,
          7750,
          666,
          264,
          18161,
          3209,
          307,
          51157
        ]
      },
      {
        "avg_logprob": -0.19460413097280316,
        "compression_ratio": 1.5844748858447488,
        "end": 1363.6200000000001,
        "id": 506,
        "no_speech_prob": 0.000021112460672156885,
        "seek": 134196,
        "start": 1357.82,
        "temperature": 0,
        "text": " paired with the target of C, when it gets sent in,",
        "tokens": [
          51157,
          25699,
          365,
          264,
          3779,
          295,
          383,
          11,
          562,
          309,
          2170,
          2279,
          294,
          11,
          51447
        ]
      },
      {
        "avg_logprob": -0.19460413097280316,
        "compression_ratio": 1.5844748858447488,
        "end": 1365.7,
        "id": 507,
        "no_speech_prob": 0.000021112460672156885,
        "seek": 134196,
        "start": 1363.6200000000001,
        "temperature": 0,
        "text": " the x gets sent in 0.25.",
        "tokens": [
          51447,
          264,
          2031,
          2170,
          2279,
          294,
          1958,
          13,
          6074,
          13,
          51551
        ]
      },
      {
        "avg_logprob": -0.19460413097280316,
        "compression_ratio": 1.5844748858447488,
        "end": 1367.3600000000001,
        "id": 508,
        "no_speech_prob": 0.000021112460672156885,
        "seek": 134196,
        "start": 1365.7,
        "temperature": 0,
        "text": " I should make the y something different.",
        "tokens": [
          51551,
          286,
          820,
          652,
          264,
          288,
          746,
          819,
          13,
          51634
        ]
      },
      {
        "avg_logprob": -0.19460413097280316,
        "compression_ratio": 1.5844748858447488,
        "end": 1369.3,
        "id": 509,
        "no_speech_prob": 0.000021112460672156885,
        "seek": 134196,
        "start": 1367.3600000000001,
        "temperature": 0,
        "text": " Like, let's say the y is 200.",
        "tokens": [
          51634,
          1743,
          11,
          718,
          311,
          584,
          264,
          288,
          307,
          2331,
          13,
          51731
        ]
      },
      {
        "avg_logprob": -0.16088764963586347,
        "compression_ratio": 1.7946768060836502,
        "end": 1371.9199999999998,
        "id": 510,
        "no_speech_prob": 0.00003944255877286196,
        "seek": 136930,
        "start": 1369.3,
        "temperature": 0,
        "text": " The y gets sent in as 0.5.",
        "tokens": [
          50364,
          440,
          288,
          2170,
          2279,
          294,
          382,
          1958,
          13,
          20,
          13,
          50495
        ]
      },
      {
        "avg_logprob": -0.16088764963586347,
        "compression_ratio": 1.7946768060836502,
        "end": 1375,
        "id": 511,
        "no_speech_prob": 0.00003944255877286196,
        "seek": 136930,
        "start": 1371.9199999999998,
        "temperature": 0,
        "text": " The neural network is going to guess C, D, or E.",
        "tokens": [
          50495,
          440,
          18161,
          3209,
          307,
          516,
          281,
          2041,
          383,
          11,
          413,
          11,
          420,
          462,
          13,
          50649
        ]
      },
      {
        "avg_logprob": -0.16088764963586347,
        "compression_ratio": 1.7946768060836502,
        "end": 1377.1599999999999,
        "id": 512,
        "no_speech_prob": 0.00003944255877286196,
        "seek": 136930,
        "start": 1375,
        "temperature": 0,
        "text": " Then it has to decide, did it get it right",
        "tokens": [
          50649,
          1396,
          309,
          575,
          281,
          4536,
          11,
          630,
          309,
          483,
          309,
          558,
          50757
        ]
      },
      {
        "avg_logprob": -0.16088764963586347,
        "compression_ratio": 1.7946768060836502,
        "end": 1378.04,
        "id": 513,
        "no_speech_prob": 0.00003944255877286196,
        "seek": 136930,
        "start": 1377.1599999999999,
        "temperature": 0,
        "text": " or did it get it wrong?",
        "tokens": [
          50757,
          420,
          630,
          309,
          483,
          309,
          2085,
          30,
          50801
        ]
      },
      {
        "avg_logprob": -0.16088764963586347,
        "compression_ratio": 1.7946768060836502,
        "end": 1379.44,
        "id": 514,
        "no_speech_prob": 0.00003944255877286196,
        "seek": 136930,
        "start": 1378.04,
        "temperature": 0,
        "text": " Was there an error?",
        "tokens": [
          50801,
          3027,
          456,
          364,
          6713,
          30,
          50871
        ]
      },
      {
        "avg_logprob": -0.16088764963586347,
        "compression_ratio": 1.7946768060836502,
        "end": 1381.28,
        "id": 515,
        "no_speech_prob": 0.00003944255877286196,
        "seek": 136930,
        "start": 1379.44,
        "temperature": 0,
        "text": " So if it happened to guess C, it's",
        "tokens": [
          50871,
          407,
          498,
          309,
          2011,
          281,
          2041,
          383,
          11,
          309,
          311,
          50963
        ]
      },
      {
        "avg_logprob": -0.16088764963586347,
        "compression_ratio": 1.7946768060836502,
        "end": 1383.04,
        "id": 516,
        "no_speech_prob": 0.00003944255877286196,
        "seek": 136930,
        "start": 1381.28,
        "temperature": 0,
        "text": " going to have gotten it right.",
        "tokens": [
          50963,
          516,
          281,
          362,
          5768,
          309,
          558,
          13,
          51051
        ]
      },
      {
        "avg_logprob": -0.16088764963586347,
        "compression_ratio": 1.7946768060836502,
        "end": 1385.3999999999999,
        "id": 517,
        "no_speech_prob": 0.00003944255877286196,
        "seek": 136930,
        "start": 1383.04,
        "temperature": 0,
        "text": " You can think of the error as 0.",
        "tokens": [
          51051,
          509,
          393,
          519,
          295,
          264,
          6713,
          382,
          1958,
          13,
          51169
        ]
      },
      {
        "avg_logprob": -0.16088764963586347,
        "compression_ratio": 1.7946768060836502,
        "end": 1388.04,
        "id": 518,
        "no_speech_prob": 0.00003944255877286196,
        "seek": 136930,
        "start": 1385.3999999999999,
        "temperature": 0,
        "text": " If it's gotten it wrong, if it guessed D,",
        "tokens": [
          51169,
          759,
          309,
          311,
          5768,
          309,
          2085,
          11,
          498,
          309,
          21852,
          413,
          11,
          51301
        ]
      },
      {
        "avg_logprob": -0.16088764963586347,
        "compression_ratio": 1.7946768060836502,
        "end": 1390.04,
        "id": 519,
        "no_speech_prob": 0.00003944255877286196,
        "seek": 136930,
        "start": 1388.04,
        "temperature": 0,
        "text": " then there is an error.",
        "tokens": [
          51301,
          550,
          456,
          307,
          364,
          6713,
          13,
          51401
        ]
      },
      {
        "avg_logprob": -0.16088764963586347,
        "compression_ratio": 1.7946768060836502,
        "end": 1391.6399999999999,
        "id": 520,
        "no_speech_prob": 0.00003944255877286196,
        "seek": 136930,
        "start": 1390.04,
        "temperature": 0,
        "text": " Now, what the value of that error",
        "tokens": [
          51401,
          823,
          11,
          437,
          264,
          2158,
          295,
          300,
          6713,
          51481
        ]
      },
      {
        "avg_logprob": -0.16088764963586347,
        "compression_ratio": 1.7946768060836502,
        "end": 1394.6,
        "id": 521,
        "no_speech_prob": 0.00003944255877286196,
        "seek": 136930,
        "start": 1391.6399999999999,
        "temperature": 0,
        "text": " is actually has to do with the scoring",
        "tokens": [
          51481,
          307,
          767,
          575,
          281,
          360,
          365,
          264,
          22358,
          51629
        ]
      },
      {
        "avg_logprob": -0.16088764963586347,
        "compression_ratio": 1.7946768060836502,
        "end": 1396.36,
        "id": 522,
        "no_speech_prob": 0.00003944255877286196,
        "seek": 136930,
        "start": 1394.6,
        "temperature": 0,
        "text": " that it's doing based on its confidence",
        "tokens": [
          51629,
          300,
          309,
          311,
          884,
          2361,
          322,
          1080,
          6687,
          51717
        ]
      },
      {
        "avg_logprob": -0.16088764963586347,
        "compression_ratio": 1.7946768060836502,
        "end": 1397.96,
        "id": 523,
        "no_speech_prob": 0.00003944255877286196,
        "seek": 136930,
        "start": 1396.36,
        "temperature": 0,
        "text": " that it's one label or another.",
        "tokens": [
          51717,
          300,
          309,
          311,
          472,
          7645,
          420,
          1071,
          13,
          51797
        ]
      },
      {
        "avg_logprob": -0.192099741262983,
        "compression_ratio": 1.8836206896551724,
        "end": 1401.5,
        "id": 524,
        "no_speech_prob": 0.000009666105142969172,
        "seek": 139796,
        "start": 1397.96,
        "temperature": 0,
        "text": " Maybe it was like 99% sure it was a D.",
        "tokens": [
          50364,
          2704,
          309,
          390,
          411,
          11803,
          4,
          988,
          309,
          390,
          257,
          413,
          13,
          50541
        ]
      },
      {
        "avg_logprob": -0.192099741262983,
        "compression_ratio": 1.8836206896551724,
        "end": 1403.1200000000001,
        "id": 525,
        "no_speech_prob": 0.000009666105142969172,
        "seek": 139796,
        "start": 1401.5,
        "temperature": 0,
        "text": " It's going to have a big error then.",
        "tokens": [
          50541,
          467,
          311,
          516,
          281,
          362,
          257,
          955,
          6713,
          550,
          13,
          50622
        ]
      },
      {
        "avg_logprob": -0.192099741262983,
        "compression_ratio": 1.8836206896551724,
        "end": 1406.8600000000001,
        "id": 526,
        "no_speech_prob": 0.000009666105142969172,
        "seek": 139796,
        "start": 1403.1200000000001,
        "temperature": 0,
        "text": " But if it was only like 60% sure it was a D and 40% sure it",
        "tokens": [
          50622,
          583,
          498,
          309,
          390,
          787,
          411,
          4060,
          4,
          988,
          309,
          390,
          257,
          413,
          293,
          3356,
          4,
          988,
          309,
          50809
        ]
      },
      {
        "avg_logprob": -0.192099741262983,
        "compression_ratio": 1.8836206896551724,
        "end": 1409.6200000000001,
        "id": 527,
        "no_speech_prob": 0.000009666105142969172,
        "seek": 139796,
        "start": 1406.8600000000001,
        "temperature": 0,
        "text": " was a C, then that error is going to be smaller.",
        "tokens": [
          50809,
          390,
          257,
          383,
          11,
          550,
          300,
          6713,
          307,
          516,
          281,
          312,
          4356,
          13,
          50947
        ]
      },
      {
        "avg_logprob": -0.192099741262983,
        "compression_ratio": 1.8836206896551724,
        "end": 1412.66,
        "id": 528,
        "no_speech_prob": 0.000009666105142969172,
        "seek": 139796,
        "start": 1409.6200000000001,
        "temperature": 0,
        "text": " But that error, another word for that error, is loss.",
        "tokens": [
          50947,
          583,
          300,
          6713,
          11,
          1071,
          1349,
          337,
          300,
          6713,
          11,
          307,
          4470,
          13,
          51099
        ]
      },
      {
        "avg_logprob": -0.192099741262983,
        "compression_ratio": 1.8836206896551724,
        "end": 1416.38,
        "id": 529,
        "no_speech_prob": 0.000009666105142969172,
        "seek": 139796,
        "start": 1412.66,
        "temperature": 0,
        "text": " So as it sends all of the data over a given epoch",
        "tokens": [
          51099,
          407,
          382,
          309,
          14790,
          439,
          295,
          264,
          1412,
          670,
          257,
          2212,
          30992,
          339,
          51285
        ]
      },
      {
        "avg_logprob": -0.192099741262983,
        "compression_ratio": 1.8836206896551724,
        "end": 1417.98,
        "id": 530,
        "no_speech_prob": 0.000009666105142969172,
        "seek": 139796,
        "start": 1416.38,
        "temperature": 0,
        "text": " through the neural network, it's going",
        "tokens": [
          51285,
          807,
          264,
          18161,
          3209,
          11,
          309,
          311,
          516,
          51365
        ]
      },
      {
        "avg_logprob": -0.192099741262983,
        "compression_ratio": 1.8836206896551724,
        "end": 1422.42,
        "id": 531,
        "no_speech_prob": 0.000009666105142969172,
        "seek": 139796,
        "start": 1417.98,
        "temperature": 0,
        "text": " to summarize all of the errors into a loss value.",
        "tokens": [
          51365,
          281,
          20858,
          439,
          295,
          264,
          13603,
          666,
          257,
          4470,
          2158,
          13,
          51587
        ]
      },
      {
        "avg_logprob": -0.192099741262983,
        "compression_ratio": 1.8836206896551724,
        "end": 1425.5,
        "id": 532,
        "no_speech_prob": 0.000009666105142969172,
        "seek": 139796,
        "start": 1422.42,
        "temperature": 0,
        "text": " So as the neural network trains the model with the training",
        "tokens": [
          51587,
          407,
          382,
          264,
          18161,
          3209,
          16329,
          264,
          2316,
          365,
          264,
          3097,
          51741
        ]
      },
      {
        "avg_logprob": -0.23023839314778646,
        "compression_ratio": 1.6852459016393442,
        "end": 1428.38,
        "id": 533,
        "no_speech_prob": 0.005384902004152536,
        "seek": 142550,
        "start": 1425.5,
        "temperature": 0,
        "text": " data over and over again, epoch by epoch,",
        "tokens": [
          50364,
          1412,
          670,
          293,
          670,
          797,
          11,
          30992,
          339,
          538,
          30992,
          339,
          11,
          50508
        ]
      },
      {
        "avg_logprob": -0.23023839314778646,
        "compression_ratio": 1.6852459016393442,
        "end": 1430.04,
        "id": 534,
        "no_speech_prob": 0.005384902004152536,
        "seek": 142550,
        "start": 1428.38,
        "temperature": 0,
        "text": " that loss should be going down.",
        "tokens": [
          50508,
          300,
          4470,
          820,
          312,
          516,
          760,
          13,
          50591
        ]
      },
      {
        "avg_logprob": -0.23023839314778646,
        "compression_ratio": 1.6852459016393442,
        "end": 1433.6,
        "id": 535,
        "no_speech_prob": 0.005384902004152536,
        "seek": 142550,
        "start": 1430.04,
        "temperature": 0,
        "text": " It's getting better and making more correct guesses over time.",
        "tokens": [
          50591,
          467,
          311,
          1242,
          1101,
          293,
          1455,
          544,
          3006,
          42703,
          670,
          565,
          13,
          50769
        ]
      },
      {
        "avg_logprob": -0.23023839314778646,
        "compression_ratio": 1.6852459016393442,
        "end": 1435.28,
        "id": 536,
        "no_speech_prob": 0.005384902004152536,
        "seek": 142550,
        "start": 1433.6,
        "temperature": 0,
        "text": " Based on what the graph is doing here,",
        "tokens": [
          50769,
          18785,
          322,
          437,
          264,
          4295,
          307,
          884,
          510,
          11,
          50853
        ]
      },
      {
        "avg_logprob": -0.23023839314778646,
        "compression_ratio": 1.6852459016393442,
        "end": 1437.56,
        "id": 537,
        "no_speech_prob": 0.005384902004152536,
        "seek": 142550,
        "start": 1435.28,
        "temperature": 0,
        "text": " this indicates to me a couple of things.",
        "tokens": [
          50853,
          341,
          16203,
          281,
          385,
          257,
          1916,
          295,
          721,
          13,
          50967
        ]
      },
      {
        "avg_logprob": -0.23023839314778646,
        "compression_ratio": 1.6852459016393442,
        "end": 1440.32,
        "id": 538,
        "no_speech_prob": 0.005384902004152536,
        "seek": 142550,
        "start": 1437.56,
        "temperature": 0,
        "text": " One is it's learning kind of slowly.",
        "tokens": [
          50967,
          1485,
          307,
          309,
          311,
          2539,
          733,
          295,
          5692,
          13,
          51105
        ]
      },
      {
        "avg_logprob": -0.23023839314778646,
        "compression_ratio": 1.6852459016393442,
        "end": 1443.12,
        "id": 539,
        "no_speech_prob": 0.005384902004152536,
        "seek": 142550,
        "start": 1440.32,
        "temperature": 0,
        "text": " So one possibility could be just give it more epochs.",
        "tokens": [
          51105,
          407,
          472,
          7959,
          727,
          312,
          445,
          976,
          309,
          544,
          30992,
          28346,
          13,
          51245
        ]
      },
      {
        "avg_logprob": -0.23023839314778646,
        "compression_ratio": 1.6852459016393442,
        "end": 1445.12,
        "id": 540,
        "no_speech_prob": 0.005384902004152536,
        "seek": 142550,
        "start": 1443.12,
        "temperature": 0,
        "text": " So maybe what I actually want to do",
        "tokens": [
          51245,
          407,
          1310,
          437,
          286,
          767,
          528,
          281,
          360,
          51345
        ]
      },
      {
        "avg_logprob": -0.23023839314778646,
        "compression_ratio": 1.6852459016393442,
        "end": 1448.2,
        "id": 541,
        "no_speech_prob": 0.005384902004152536,
        "seek": 142550,
        "start": 1445.12,
        "temperature": 0,
        "text": " is go back into the code and give it",
        "tokens": [
          51345,
          307,
          352,
          646,
          666,
          264,
          3089,
          293,
          976,
          309,
          51499
        ]
      },
      {
        "avg_logprob": -0.23023839314778646,
        "compression_ratio": 1.6852459016393442,
        "end": 1450.08,
        "id": 542,
        "no_speech_prob": 0.005384902004152536,
        "seek": 142550,
        "start": 1448.2,
        "temperature": 0,
        "text": " 200 epochs instead of 100.",
        "tokens": [
          51499,
          2331,
          30992,
          28346,
          2602,
          295,
          2319,
          13,
          51593
        ]
      },
      {
        "avg_logprob": -0.23023839314778646,
        "compression_ratio": 1.6852459016393442,
        "end": 1452.52,
        "id": 543,
        "no_speech_prob": 0.005384902004152536,
        "seek": 142550,
        "start": 1450.08,
        "temperature": 0,
        "text": " Truth of the matter is I have a very, very, very small data",
        "tokens": [
          51593,
          20522,
          295,
          264,
          1871,
          307,
          286,
          362,
          257,
          588,
          11,
          588,
          11,
          588,
          1359,
          1412,
          51715
        ]
      },
      {
        "avg_logprob": -0.23023839314778646,
        "compression_ratio": 1.6852459016393442,
        "end": 1453.16,
        "id": 544,
        "no_speech_prob": 0.005384902004152536,
        "seek": 142550,
        "start": 1452.52,
        "temperature": 0,
        "text": " set here.",
        "tokens": [
          51715,
          992,
          510,
          13,
          51747
        ]
      },
      {
        "avg_logprob": -0.23023839314778646,
        "compression_ratio": 1.6852459016393442,
        "end": 1455.28,
        "id": 545,
        "no_speech_prob": 0.005384902004152536,
        "seek": 142550,
        "start": 1453.16,
        "temperature": 0,
        "text": " So with a little bit of data, I need",
        "tokens": [
          51747,
          407,
          365,
          257,
          707,
          857,
          295,
          1412,
          11,
          286,
          643,
          51853
        ]
      },
      {
        "avg_logprob": -0.23598743739881015,
        "compression_ratio": 1.8327868852459017,
        "end": 1456.78,
        "id": 546,
        "no_speech_prob": 0.00019716912356670946,
        "seek": 145528,
        "start": 1455.28,
        "temperature": 0,
        "text": " a lot more epochs, and it kind of makes",
        "tokens": [
          50364,
          257,
          688,
          544,
          30992,
          28346,
          11,
          293,
          309,
          733,
          295,
          1669,
          50439
        ]
      },
      {
        "avg_logprob": -0.23598743739881015,
        "compression_ratio": 1.8327868852459017,
        "end": 1458.22,
        "id": 547,
        "no_speech_prob": 0.00019716912356670946,
        "seek": 145528,
        "start": 1456.78,
        "temperature": 0,
        "text": " it feel like it's more data.",
        "tokens": [
          50439,
          309,
          841,
          411,
          309,
          311,
          544,
          1412,
          13,
          50511
        ]
      },
      {
        "avg_logprob": -0.23598743739881015,
        "compression_ratio": 1.8327868852459017,
        "end": 1460.66,
        "id": 548,
        "no_speech_prob": 0.00019716912356670946,
        "seek": 145528,
        "start": 1458.22,
        "temperature": 0,
        "text": " Another way that I could tackle this issue",
        "tokens": [
          50511,
          3996,
          636,
          300,
          286,
          727,
          14896,
          341,
          2734,
          50633
        ]
      },
      {
        "avg_logprob": -0.23598743739881015,
        "compression_ratio": 1.8327868852459017,
        "end": 1462.8999999999999,
        "id": 549,
        "no_speech_prob": 0.00019716912356670946,
        "seek": 145528,
        "start": 1460.66,
        "temperature": 0,
        "text": " is by adding another property to the options object",
        "tokens": [
          50633,
          307,
          538,
          5127,
          1071,
          4707,
          281,
          264,
          3956,
          2657,
          50745
        ]
      },
      {
        "avg_logprob": -0.23598743739881015,
        "compression_ratio": 1.8327868852459017,
        "end": 1464.46,
        "id": 550,
        "no_speech_prob": 0.00019716912356670946,
        "seek": 145528,
        "start": 1462.8999999999999,
        "temperature": 0,
        "text": " when I configure the neural network.",
        "tokens": [
          50745,
          562,
          286,
          22162,
          264,
          18161,
          3209,
          13,
          50823
        ]
      },
      {
        "avg_logprob": -0.23598743739881015,
        "compression_ratio": 1.8327868852459017,
        "end": 1467.1399999999999,
        "id": 551,
        "no_speech_prob": 0.00019716912356670946,
        "seek": 145528,
        "start": 1464.46,
        "temperature": 0,
        "text": " And that property is something called a learning rate.",
        "tokens": [
          50823,
          400,
          300,
          4707,
          307,
          746,
          1219,
          257,
          2539,
          3314,
          13,
          50957
        ]
      },
      {
        "avg_logprob": -0.23598743739881015,
        "compression_ratio": 1.8327868852459017,
        "end": 1471.26,
        "id": 552,
        "no_speech_prob": 0.00019716912356670946,
        "seek": 145528,
        "start": 1467.1399999999999,
        "temperature": 0,
        "text": " The learning rate refers to how much these dials",
        "tokens": [
          50957,
          440,
          2539,
          3314,
          14942,
          281,
          577,
          709,
          613,
          5502,
          82,
          51163
        ]
      },
      {
        "avg_logprob": -0.23598743739881015,
        "compression_ratio": 1.8327868852459017,
        "end": 1473.8999999999999,
        "id": 553,
        "no_speech_prob": 0.00019716912356670946,
        "seek": 145528,
        "start": 1471.26,
        "temperature": 0,
        "text": " should turn based on the errors that it's",
        "tokens": [
          51163,
          820,
          1261,
          2361,
          322,
          264,
          13603,
          300,
          309,
          311,
          51295
        ]
      },
      {
        "avg_logprob": -0.23598743739881015,
        "compression_ratio": 1.8327868852459017,
        "end": 1476.54,
        "id": 554,
        "no_speech_prob": 0.00019716912356670946,
        "seek": 145528,
        "start": 1473.8999999999999,
        "temperature": 0,
        "text": " seeing as the neural network is looking at the training data.",
        "tokens": [
          51295,
          2577,
          382,
          264,
          18161,
          3209,
          307,
          1237,
          412,
          264,
          3097,
          1412,
          13,
          51427
        ]
      },
      {
        "avg_logprob": -0.23598743739881015,
        "compression_ratio": 1.8327868852459017,
        "end": 1477.54,
        "id": 555,
        "no_speech_prob": 0.00019716912356670946,
        "seek": 145528,
        "start": 1476.54,
        "temperature": 0,
        "text": " So it got an error.",
        "tokens": [
          51427,
          407,
          309,
          658,
          364,
          6713,
          13,
          51477
        ]
      },
      {
        "avg_logprob": -0.23598743739881015,
        "compression_ratio": 1.8327868852459017,
        "end": 1478.98,
        "id": 556,
        "no_speech_prob": 0.00019716912356670946,
        "seek": 145528,
        "start": 1477.54,
        "temperature": 0,
        "text": " Should I turn the dial a lot, or should I",
        "tokens": [
          51477,
          6454,
          286,
          1261,
          264,
          5502,
          257,
          688,
          11,
          420,
          820,
          286,
          51549
        ]
      },
      {
        "avg_logprob": -0.23598743739881015,
        "compression_ratio": 1.8327868852459017,
        "end": 1480.22,
        "id": 557,
        "no_speech_prob": 0.00019716912356670946,
        "seek": 145528,
        "start": 1478.98,
        "temperature": 0,
        "text": " turn it just a little bit?",
        "tokens": [
          51549,
          1261,
          309,
          445,
          257,
          707,
          857,
          30,
          51611
        ]
      },
      {
        "avg_logprob": -0.23598743739881015,
        "compression_ratio": 1.8327868852459017,
        "end": 1483.5,
        "id": 558,
        "no_speech_prob": 0.00019716912356670946,
        "seek": 145528,
        "start": 1480.22,
        "temperature": 0,
        "text": " If I turn it a lot, I might get closer to the correct result.",
        "tokens": [
          51611,
          759,
          286,
          1261,
          309,
          257,
          688,
          11,
          286,
          1062,
          483,
          4966,
          281,
          264,
          3006,
          1874,
          13,
          51775
        ]
      },
      {
        "avg_logprob": -0.23065727761706467,
        "compression_ratio": 1.7664670658682635,
        "end": 1485.92,
        "id": 559,
        "no_speech_prob": 0.000027969241273240186,
        "seek": 148350,
        "start": 1483.52,
        "temperature": 0,
        "text": " But I could also overshoot that correct result.",
        "tokens": [
          50365,
          583,
          286,
          727,
          611,
          15488,
          24467,
          300,
          3006,
          1874,
          13,
          50485
        ]
      },
      {
        "avg_logprob": -0.23065727761706467,
        "compression_ratio": 1.7664670658682635,
        "end": 1488.56,
        "id": 560,
        "no_speech_prob": 0.000027969241273240186,
        "seek": 148350,
        "start": 1485.92,
        "temperature": 0,
        "text": " So this kind of hyperparameter tuning",
        "tokens": [
          50485,
          407,
          341,
          733,
          295,
          9848,
          2181,
          335,
          2398,
          15164,
          50617
        ]
      },
      {
        "avg_logprob": -0.23065727761706467,
        "compression_ratio": 1.7664670658682635,
        "end": 1490.64,
        "id": 561,
        "no_speech_prob": 0.000027969241273240186,
        "seek": 148350,
        "start": 1488.56,
        "temperature": 0,
        "text": " is a fancy word for saying, well,",
        "tokens": [
          50617,
          307,
          257,
          10247,
          1349,
          337,
          1566,
          11,
          731,
          11,
          50721
        ]
      },
      {
        "avg_logprob": -0.23065727761706467,
        "compression_ratio": 1.7664670658682635,
        "end": 1493.14,
        "id": 562,
        "no_speech_prob": 0.000027969241273240186,
        "seek": 148350,
        "start": 1490.64,
        "temperature": 0,
        "text": " I want to try this learning rate, this number of epochs.",
        "tokens": [
          50721,
          286,
          528,
          281,
          853,
          341,
          2539,
          3314,
          11,
          341,
          1230,
          295,
          30992,
          28346,
          13,
          50846
        ]
      },
      {
        "avg_logprob": -0.23065727761706467,
        "compression_ratio": 1.7664670658682635,
        "end": 1494.72,
        "id": 563,
        "no_speech_prob": 0.000027969241273240186,
        "seek": 148350,
        "start": 1493.14,
        "temperature": 0,
        "text": " These are the kinds of things that you",
        "tokens": [
          50846,
          1981,
          366,
          264,
          3685,
          295,
          721,
          300,
          291,
          50925
        ]
      },
      {
        "avg_logprob": -0.23065727761706467,
        "compression_ratio": 1.7664670658682635,
        "end": 1496.8,
        "id": 564,
        "no_speech_prob": 0.000027969241273240186,
        "seek": 148350,
        "start": 1494.72,
        "temperature": 0,
        "text": " could experiment with by training your model over",
        "tokens": [
          50925,
          727,
          5120,
          365,
          538,
          3097,
          428,
          2316,
          670,
          51029
        ]
      },
      {
        "avg_logprob": -0.23065727761706467,
        "compression_ratio": 1.7664670658682635,
        "end": 1498.6,
        "id": 565,
        "no_speech_prob": 0.000027969241273240186,
        "seek": 148350,
        "start": 1496.8,
        "temperature": 0,
        "text": " and over again with different properties.",
        "tokens": [
          51029,
          293,
          670,
          797,
          365,
          819,
          7221,
          13,
          51119
        ]
      },
      {
        "avg_logprob": -0.23065727761706467,
        "compression_ratio": 1.7664670658682635,
        "end": 1501.18,
        "id": 566,
        "no_speech_prob": 0.000027969241273240186,
        "seek": 148350,
        "start": 1498.6,
        "temperature": 0,
        "text": " But for me right now, I'm going to leave the default learning",
        "tokens": [
          51119,
          583,
          337,
          385,
          558,
          586,
          11,
          286,
          478,
          516,
          281,
          1856,
          264,
          7576,
          2539,
          51248
        ]
      },
      {
        "avg_logprob": -0.23065727761706467,
        "compression_ratio": 1.7664670658682635,
        "end": 1503.2,
        "id": 567,
        "no_speech_prob": 0.000027969241273240186,
        "seek": 148350,
        "start": 1501.18,
        "temperature": 0,
        "text": " rate and just experiment with the number of epochs.",
        "tokens": [
          51248,
          3314,
          293,
          445,
          5120,
          365,
          264,
          1230,
          295,
          30992,
          28346,
          13,
          51349
        ]
      },
      {
        "avg_logprob": -0.23065727761706467,
        "compression_ratio": 1.7664670658682635,
        "end": 1504.4,
        "id": 568,
        "no_speech_prob": 0.000027969241273240186,
        "seek": 148350,
        "start": 1503.2,
        "temperature": 0,
        "text": " And maybe in some future videos, I'll",
        "tokens": [
          51349,
          400,
          1310,
          294,
          512,
          2027,
          2145,
          11,
          286,
          603,
          51409
        ]
      },
      {
        "avg_logprob": -0.23065727761706467,
        "compression_ratio": 1.7664670658682635,
        "end": 1506.44,
        "id": 569,
        "no_speech_prob": 0.000027969241273240186,
        "seek": 148350,
        "start": 1504.4,
        "temperature": 0,
        "text": " come back and look at some of the other parameters",
        "tokens": [
          51409,
          808,
          646,
          293,
          574,
          412,
          512,
          295,
          264,
          661,
          9834,
          51511
        ]
      },
      {
        "avg_logprob": -0.23065727761706467,
        "compression_ratio": 1.7664670658682635,
        "end": 1508.36,
        "id": 570,
        "no_speech_prob": 0.000027969241273240186,
        "seek": 148350,
        "start": 1506.44,
        "temperature": 0,
        "text": " and what might happen as I tune them.",
        "tokens": [
          51511,
          293,
          437,
          1062,
          1051,
          382,
          286,
          10864,
          552,
          13,
          51607
        ]
      },
      {
        "avg_logprob": -0.23065727761706467,
        "compression_ratio": 1.7664670658682635,
        "end": 1511.16,
        "id": 571,
        "no_speech_prob": 0.000027969241273240186,
        "seek": 148350,
        "start": 1508.36,
        "temperature": 0,
        "text": " Let's try one more time.",
        "tokens": [
          51607,
          961,
          311,
          853,
          472,
          544,
          565,
          13,
          51747
        ]
      },
      {
        "avg_logprob": -0.23065727761706467,
        "compression_ratio": 1.7664670658682635,
        "end": 1512.2,
        "id": 572,
        "no_speech_prob": 0.000027969241273240186,
        "seek": 148350,
        "start": 1511.16,
        "temperature": 0,
        "text": " Collecting data.",
        "tokens": [
          51747,
          31896,
          278,
          1412,
          13,
          51799
        ]
      },
      {
        "avg_logprob": -0.42429137229919434,
        "compression_ratio": 1.5327510917030567,
        "end": 1513.94,
        "id": 573,
        "no_speech_prob": 0.0000468387697765138,
        "seek": 151220,
        "start": 1512.74,
        "temperature": 0,
        "text": " And training the model.",
        "tokens": [
          50391,
          400,
          3097,
          264,
          2316,
          13,
          50451
        ]
      },
      {
        "avg_logprob": -0.42429137229919434,
        "compression_ratio": 1.5327510917030567,
        "end": 1519.74,
        "id": 574,
        "no_speech_prob": 0.0000468387697765138,
        "seek": 151220,
        "start": 1518.94,
        "temperature": 0,
        "text": " Ooh, wacky.",
        "tokens": [
          50701,
          7951,
          11,
          42138,
          88,
          13,
          50741
        ]
      },
      {
        "avg_logprob": -0.42429137229919434,
        "compression_ratio": 1.5327510917030567,
        "end": 1524.82,
        "id": 575,
        "no_speech_prob": 0.0000468387697765138,
        "seek": 151220,
        "start": 1523.74,
        "temperature": 0,
        "text": " So this is really good.",
        "tokens": [
          50941,
          407,
          341,
          307,
          534,
          665,
          13,
          50995
        ]
      },
      {
        "avg_logprob": -0.42429137229919434,
        "compression_ratio": 1.5327510917030567,
        "end": 1526.94,
        "id": 576,
        "no_speech_prob": 0.0000468387697765138,
        "seek": 151220,
        "start": 1524.82,
        "temperature": 0,
        "text": " I want to see that loss go all the way down.",
        "tokens": [
          50995,
          286,
          528,
          281,
          536,
          300,
          4470,
          352,
          439,
          264,
          636,
          760,
          13,
          51101
        ]
      },
      {
        "avg_logprob": -0.42429137229919434,
        "compression_ratio": 1.5327510917030567,
        "end": 1531.94,
        "id": 577,
        "no_speech_prob": 0.0000468387697765138,
        "seek": 151220,
        "start": 1526.94,
        "temperature": 0,
        "text": " We can see at the very end here, it gets down to 0.096314.",
        "tokens": [
          51101,
          492,
          393,
          536,
          412,
          264,
          588,
          917,
          510,
          11,
          309,
          2170,
          760,
          281,
          1958,
          13,
          13811,
          21,
          18,
          7271,
          13,
          51351
        ]
      },
      {
        "avg_logprob": -0.42429137229919434,
        "compression_ratio": 1.5327510917030567,
        "end": 1534.26,
        "id": 578,
        "no_speech_prob": 0.0000468387697765138,
        "seek": 151220,
        "start": 1531.94,
        "temperature": 0,
        "text": " And you could also see that it's starting to level out.",
        "tokens": [
          51351,
          400,
          291,
          727,
          611,
          536,
          300,
          309,
          311,
          2891,
          281,
          1496,
          484,
          13,
          51467
        ]
      },
      {
        "avg_logprob": -0.42429137229919434,
        "compression_ratio": 1.5327510917030567,
        "end": 1536.8600000000001,
        "id": 579,
        "no_speech_prob": 0.0000468387697765138,
        "seek": 151220,
        "start": 1534.26,
        "temperature": 0,
        "text": " That indicates to me that if I'd given it more epochs,",
        "tokens": [
          51467,
          663,
          16203,
          281,
          385,
          300,
          498,
          286,
          1116,
          2212,
          309,
          544,
          30992,
          28346,
          11,
          51597
        ]
      },
      {
        "avg_logprob": -0.42429137229919434,
        "compression_ratio": 1.5327510917030567,
        "end": 1539.66,
        "id": 580,
        "no_speech_prob": 0.0000468387697765138,
        "seek": 151220,
        "start": 1536.8600000000001,
        "temperature": 0,
        "text": " maybe I would squeeze out a tiny bit more accuracy.",
        "tokens": [
          51597,
          1310,
          286,
          576,
          13578,
          484,
          257,
          5870,
          857,
          544,
          14170,
          13,
          51737
        ]
      },
      {
        "avg_logprob": -0.42429137229919434,
        "compression_ratio": 1.5327510917030567,
        "end": 1540.94,
        "id": 581,
        "no_speech_prob": 0.0000468387697765138,
        "seek": 151220,
        "start": 1539.66,
        "temperature": 0,
        "text": " But this is pretty good.",
        "tokens": [
          51737,
          583,
          341,
          307,
          1238,
          665,
          13,
          51801
        ]
      },
      {
        "avg_logprob": -0.32334504476407677,
        "compression_ratio": 1.7097791798107256,
        "end": 1543.8,
        "id": 582,
        "no_speech_prob": 0.016402479261159897,
        "seek": 154094,
        "start": 1541.24,
        "temperature": 0,
        "text": " And that, my friends, is the end of step two.",
        "tokens": [
          50379,
          400,
          300,
          11,
          452,
          1855,
          11,
          307,
          264,
          917,
          295,
          1823,
          732,
          13,
          50507
        ]
      },
      {
        "avg_logprob": -0.32334504476407677,
        "compression_ratio": 1.7097791798107256,
        "end": 1544.56,
        "id": 583,
        "no_speech_prob": 0.016402479261159897,
        "seek": 154094,
        "start": 1543.8,
        "temperature": 0,
        "text": " Guess what?",
        "tokens": [
          50507,
          17795,
          437,
          30,
          50545
        ]
      },
      {
        "avg_logprob": -0.32334504476407677,
        "compression_ratio": 1.7097791798107256,
        "end": 1546.0800000000002,
        "id": 584,
        "no_speech_prob": 0.016402479261159897,
        "seek": 154094,
        "start": 1544.56,
        "temperature": 0,
        "text": " Only one step left.",
        "tokens": [
          50545,
          5686,
          472,
          1823,
          1411,
          13,
          50621
        ]
      },
      {
        "avg_logprob": -0.32334504476407677,
        "compression_ratio": 1.7097791798107256,
        "end": 1548.3200000000002,
        "id": 585,
        "no_speech_prob": 0.016402479261159897,
        "seek": 154094,
        "start": 1546.0800000000002,
        "temperature": 0,
        "text": " And this one is prediction.",
        "tokens": [
          50621,
          400,
          341,
          472,
          307,
          17630,
          13,
          50733
        ]
      },
      {
        "avg_logprob": -0.32334504476407677,
        "compression_ratio": 1.7097791798107256,
        "end": 1550.92,
        "id": 586,
        "no_speech_prob": 0.016402479261159897,
        "seek": 154094,
        "start": 1548.3200000000002,
        "temperature": 0,
        "text": " Meaning the idea now that I've trained the model",
        "tokens": [
          50733,
          19948,
          264,
          1558,
          586,
          300,
          286,
          600,
          8895,
          264,
          2316,
          50863
        ]
      },
      {
        "avg_logprob": -0.32334504476407677,
        "compression_ratio": 1.7097791798107256,
        "end": 1552.72,
        "id": 587,
        "no_speech_prob": 0.016402479261159897,
        "seek": 154094,
        "start": 1550.92,
        "temperature": 0,
        "text": " is I want to give it new inputs.",
        "tokens": [
          50863,
          307,
          286,
          528,
          281,
          976,
          309,
          777,
          15743,
          13,
          50953
        ]
      },
      {
        "avg_logprob": -0.32334504476407677,
        "compression_ratio": 1.7097791798107256,
        "end": 1553.8400000000001,
        "id": 588,
        "no_speech_prob": 0.016402479261159897,
        "seek": 154094,
        "start": 1552.72,
        "temperature": 0,
        "text": " I'm not giving you a target.",
        "tokens": [
          50953,
          286,
          478,
          406,
          2902,
          291,
          257,
          3779,
          13,
          51009
        ]
      },
      {
        "avg_logprob": -0.32334504476407677,
        "compression_ratio": 1.7097791798107256,
        "end": 1555.3600000000001,
        "id": 589,
        "no_speech_prob": 0.016402479261159897,
        "seek": 154094,
        "start": 1553.8400000000001,
        "temperature": 0,
        "text": " I'm not telling you what the answer is.",
        "tokens": [
          51009,
          286,
          478,
          406,
          3585,
          291,
          437,
          264,
          1867,
          307,
          13,
          51085
        ]
      },
      {
        "avg_logprob": -0.32334504476407677,
        "compression_ratio": 1.7097791798107256,
        "end": 1556.64,
        "id": 590,
        "no_speech_prob": 0.016402479261159897,
        "seek": 154094,
        "start": 1555.3600000000001,
        "temperature": 0,
        "text": " Neural network, you've learned.",
        "tokens": [
          51085,
          1734,
          1807,
          3209,
          11,
          291,
          600,
          3264,
          13,
          51149
        ]
      },
      {
        "avg_logprob": -0.32334504476407677,
        "compression_ratio": 1.7097791798107256,
        "end": 1558.48,
        "id": 591,
        "no_speech_prob": 0.016402479261159897,
        "seek": 154094,
        "start": 1556.64,
        "temperature": 0,
        "text": " You've thought about this a lot.",
        "tokens": [
          51149,
          509,
          600,
          1194,
          466,
          341,
          257,
          688,
          13,
          51241
        ]
      },
      {
        "avg_logprob": -0.32334504476407677,
        "compression_ratio": 1.7097791798107256,
        "end": 1560.48,
        "id": 592,
        "no_speech_prob": 0.016402479261159897,
        "seek": 154094,
        "start": 1558.48,
        "temperature": 0,
        "text": " I've taught you all I can teach you.",
        "tokens": [
          51241,
          286,
          600,
          5928,
          291,
          439,
          286,
          393,
          2924,
          291,
          13,
          51341
        ]
      },
      {
        "avg_logprob": -0.32334504476407677,
        "compression_ratio": 1.7097791798107256,
        "end": 1562.24,
        "id": 593,
        "no_speech_prob": 0.016402479261159897,
        "seek": 154094,
        "start": 1560.48,
        "temperature": 0,
        "text": " Now make some guesses for me.",
        "tokens": [
          51341,
          823,
          652,
          512,
          42703,
          337,
          385,
          13,
          51429
        ]
      },
      {
        "avg_logprob": -0.32334504476407677,
        "compression_ratio": 1.7097791798107256,
        "end": 1564.0800000000002,
        "id": 594,
        "no_speech_prob": 0.016402479261159897,
        "seek": 154094,
        "start": 1562.24,
        "temperature": 0,
        "text": " To implement this, I think something useful",
        "tokens": [
          51429,
          1407,
          4445,
          341,
          11,
          286,
          519,
          746,
          4420,
          51521
        ]
      },
      {
        "avg_logprob": -0.32334504476407677,
        "compression_ratio": 1.7097791798107256,
        "end": 1566.24,
        "id": 595,
        "no_speech_prob": 0.016402479261159897,
        "seek": 154094,
        "start": 1564.0800000000002,
        "temperature": 0,
        "text": " could be for me to create a variable that's",
        "tokens": [
          51521,
          727,
          312,
          337,
          385,
          281,
          1884,
          257,
          7006,
          300,
          311,
          51629
        ]
      },
      {
        "avg_logprob": -0.32334504476407677,
        "compression_ratio": 1.7097791798107256,
        "end": 1567.96,
        "id": 596,
        "no_speech_prob": 0.016402479261159897,
        "seek": 154094,
        "start": 1566.24,
        "temperature": 0,
        "text": " like the state of the program.",
        "tokens": [
          51629,
          411,
          264,
          1785,
          295,
          264,
          1461,
          13,
          51715
        ]
      },
      {
        "avg_logprob": -0.32334504476407677,
        "compression_ratio": 1.7097791798107256,
        "end": 1569.3600000000001,
        "id": 597,
        "no_speech_prob": 0.016402479261159897,
        "seek": 154094,
        "start": 1567.96,
        "temperature": 0,
        "text": " And at the beginning of the state,",
        "tokens": [
          51715,
          400,
          412,
          264,
          2863,
          295,
          264,
          1785,
          11,
          51785
        ]
      },
      {
        "avg_logprob": -0.4167788050196192,
        "compression_ratio": 1.8461538461538463,
        "end": 1571.06,
        "id": 598,
        "no_speech_prob": 0.02442258968949318,
        "seek": 156936,
        "start": 1569.4199999999998,
        "temperature": 0.4,
        "text": " I would say state is program.",
        "tokens": [
          50367,
          286,
          576,
          584,
          1785,
          307,
          1461,
          13,
          50449
        ]
      },
      {
        "avg_logprob": -0.4167788050196192,
        "compression_ratio": 1.8461538461538463,
        "end": 1573.4599999999998,
        "id": 599,
        "no_speech_prob": 0.02442258968949318,
        "seek": 156936,
        "start": 1571.06,
        "temperature": 0.4,
        "text": " And at the beginning of the state would be collection.",
        "tokens": [
          50449,
          400,
          412,
          264,
          2863,
          295,
          264,
          1785,
          576,
          312,
          5765,
          13,
          50569
        ]
      },
      {
        "avg_logprob": -0.4167788050196192,
        "compression_ratio": 1.8461538461538463,
        "end": 1576.34,
        "id": 600,
        "no_speech_prob": 0.02442258968949318,
        "seek": 156936,
        "start": 1573.4599999999998,
        "temperature": 0.4,
        "text": " And when the state is collection,",
        "tokens": [
          50569,
          400,
          562,
          264,
          1785,
          307,
          5765,
          11,
          50713
        ]
      },
      {
        "avg_logprob": -0.4167788050196192,
        "compression_ratio": 1.8461538461538463,
        "end": 1578.54,
        "id": 601,
        "no_speech_prob": 0.02442258968949318,
        "seek": 156936,
        "start": 1576.34,
        "temperature": 0.4,
        "text": " that's where I want to set the target label",
        "tokens": [
          50713,
          300,
          311,
          689,
          286,
          528,
          281,
          992,
          264,
          3779,
          7645,
          50823
        ]
      },
      {
        "avg_logprob": -0.4167788050196192,
        "compression_ratio": 1.8461538461538463,
        "end": 1580.26,
        "id": 602,
        "no_speech_prob": 0.02442258968949318,
        "seek": 156936,
        "start": 1578.54,
        "temperature": 0.4,
        "text": " and add the data to the model.",
        "tokens": [
          50823,
          293,
          909,
          264,
          1412,
          281,
          264,
          2316,
          13,
          50909
        ]
      },
      {
        "avg_logprob": -0.4167788050196192,
        "compression_ratio": 1.8461538461538463,
        "end": 1585.54,
        "id": 603,
        "no_speech_prob": 0.02442258968949318,
        "seek": 156936,
        "start": 1580.26,
        "temperature": 0.4,
        "text": " When I press the T key, then the state is training.",
        "tokens": [
          50909,
          1133,
          286,
          1886,
          264,
          314,
          2141,
          11,
          550,
          264,
          1785,
          307,
          3097,
          13,
          51173
        ]
      },
      {
        "avg_logprob": -0.4167788050196192,
        "compression_ratio": 1.8461538461538463,
        "end": 1587.4199999999998,
        "id": 604,
        "no_speech_prob": 0.02442258968949318,
        "seek": 156936,
        "start": 1585.54,
        "temperature": 0.4,
        "text": " And then when I'm finished training,",
        "tokens": [
          51173,
          400,
          550,
          562,
          286,
          478,
          4335,
          3097,
          11,
          51267
        ]
      },
      {
        "avg_logprob": -0.4167788050196192,
        "compression_ratio": 1.8461538461538463,
        "end": 1591.74,
        "id": 605,
        "no_speech_prob": 0.02442258968949318,
        "seek": 156936,
        "start": 1587.4199999999998,
        "temperature": 0.4,
        "text": " I could say the state is prediction.",
        "tokens": [
          51267,
          286,
          727,
          584,
          264,
          1785,
          307,
          17630,
          13,
          51483
        ]
      },
      {
        "avg_logprob": -0.4167788050196192,
        "compression_ratio": 1.8461538461538463,
        "end": 1593.2199999999998,
        "id": 606,
        "no_speech_prob": 0.02442258968949318,
        "seek": 156936,
        "start": 1591.74,
        "temperature": 0.4,
        "text": " And ultimately, I think I just want",
        "tokens": [
          51483,
          400,
          6284,
          11,
          286,
          519,
          286,
          445,
          528,
          51557
        ]
      },
      {
        "avg_logprob": -0.4167788050196192,
        "compression_ratio": 1.8461538461538463,
        "end": 1598.82,
        "id": 607,
        "no_speech_prob": 0.02442258968949318,
        "seek": 156936,
        "start": 1593.2199999999998,
        "temperature": 0.4,
        "text": " to draw those circles during the collection process.",
        "tokens": [
          51557,
          281,
          2642,
          729,
          13040,
          1830,
          264,
          5765,
          1399,
          13,
          51837
        ]
      },
      {
        "avg_logprob": -0.19774681931241936,
        "compression_ratio": 1.6143497757847534,
        "end": 1603.8799999999999,
        "id": 608,
        "no_speech_prob": 0.00007031177665339783,
        "seek": 159882,
        "start": 1599.1599999999999,
        "temperature": 0,
        "text": " If the state is prediction, then I",
        "tokens": [
          50381,
          759,
          264,
          1785,
          307,
          17630,
          11,
          550,
          286,
          50617
        ]
      },
      {
        "avg_logprob": -0.19774681931241936,
        "compression_ratio": 1.6143497757847534,
        "end": 1610.84,
        "id": 609,
        "no_speech_prob": 0.00007031177665339783,
        "seek": 159882,
        "start": 1603.8799999999999,
        "temperature": 0,
        "text": " want to ask the model to classify the inputs.",
        "tokens": [
          50617,
          528,
          281,
          1029,
          264,
          2316,
          281,
          33872,
          264,
          15743,
          13,
          50965
        ]
      },
      {
        "avg_logprob": -0.19774681931241936,
        "compression_ratio": 1.6143497757847534,
        "end": 1613.8799999999999,
        "id": 610,
        "no_speech_prob": 0.00007031177665339783,
        "seek": 159882,
        "start": 1610.84,
        "temperature": 0,
        "text": " The idea being that there are no targets.",
        "tokens": [
          50965,
          440,
          1558,
          885,
          300,
          456,
          366,
          572,
          12911,
          13,
          51117
        ]
      },
      {
        "avg_logprob": -0.19774681931241936,
        "compression_ratio": 1.6143497757847534,
        "end": 1615.1399999999999,
        "id": 611,
        "no_speech_prob": 0.00007031177665339783,
        "seek": 159882,
        "start": 1613.8799999999999,
        "temperature": 0,
        "text": " The model is trained.",
        "tokens": [
          51117,
          440,
          2316,
          307,
          8895,
          13,
          51180
        ]
      },
      {
        "avg_logprob": -0.19774681931241936,
        "compression_ratio": 1.6143497757847534,
        "end": 1616.12,
        "id": 612,
        "no_speech_prob": 0.00007031177665339783,
        "seek": 159882,
        "start": 1615.1399999999999,
        "temperature": 0,
        "text": " Here are some inputs.",
        "tokens": [
          51180,
          1692,
          366,
          512,
          15743,
          13,
          51229
        ]
      },
      {
        "avg_logprob": -0.19774681931241936,
        "compression_ratio": 1.6143497757847534,
        "end": 1617.48,
        "id": 613,
        "no_speech_prob": 0.00007031177665339783,
        "seek": 159882,
        "start": 1616.12,
        "temperature": 0,
        "text": " Classify them for me.",
        "tokens": [
          51229,
          9471,
          2505,
          552,
          337,
          385,
          13,
          51297
        ]
      },
      {
        "avg_logprob": -0.19774681931241936,
        "compression_ratio": 1.6143497757847534,
        "end": 1619.36,
        "id": 614,
        "no_speech_prob": 0.00007031177665339783,
        "seek": 159882,
        "start": 1617.48,
        "temperature": 0,
        "text": " So where do I get the results back?",
        "tokens": [
          51297,
          407,
          689,
          360,
          286,
          483,
          264,
          3542,
          646,
          30,
          51391
        ]
      },
      {
        "avg_logprob": -0.19774681931241936,
        "compression_ratio": 1.6143497757847534,
        "end": 1620.56,
        "id": 615,
        "no_speech_prob": 0.00007031177665339783,
        "seek": 159882,
        "start": 1619.36,
        "temperature": 0,
        "text": " I need a callback.",
        "tokens": [
          51391,
          286,
          643,
          257,
          818,
          3207,
          13,
          51451
        ]
      },
      {
        "avg_logprob": -0.19774681931241936,
        "compression_ratio": 1.6143497757847534,
        "end": 1623.4199999999998,
        "id": 616,
        "no_speech_prob": 0.00007031177665339783,
        "seek": 159882,
        "start": 1620.56,
        "temperature": 0,
        "text": " I can define a function called gotResults.",
        "tokens": [
          51451,
          286,
          393,
          6964,
          257,
          2445,
          1219,
          658,
          33274,
          33361,
          13,
          51594
        ]
      },
      {
        "avg_logprob": -0.19774681931241936,
        "compression_ratio": 1.6143497757847534,
        "end": 1625.24,
        "id": 617,
        "no_speech_prob": 0.00007031177665339783,
        "seek": 159882,
        "start": 1623.4199999999998,
        "temperature": 0,
        "text": " Just like all the other ml5 stuff",
        "tokens": [
          51594,
          1449,
          411,
          439,
          264,
          661,
          23271,
          20,
          1507,
          51685
        ]
      },
      {
        "avg_logprob": -0.19774681931241936,
        "compression_ratio": 1.6143497757847534,
        "end": 1627.12,
        "id": 618,
        "no_speech_prob": 0.00007031177665339783,
        "seek": 159882,
        "start": 1625.24,
        "temperature": 0,
        "text": " that I've looked at in previous videos,",
        "tokens": [
          51685,
          300,
          286,
          600,
          2956,
          412,
          294,
          3894,
          2145,
          11,
          51779
        ]
      },
      {
        "avg_logprob": -0.2271421370967742,
        "compression_ratio": 1.8666666666666667,
        "end": 1630.84,
        "id": 619,
        "no_speech_prob": 0.00010889668919844553,
        "seek": 162712,
        "start": 1627.12,
        "temperature": 0,
        "text": " there can be an error or there could actually be results.",
        "tokens": [
          50364,
          456,
          393,
          312,
          364,
          6713,
          420,
          456,
          727,
          767,
          312,
          3542,
          13,
          50550
        ]
      },
      {
        "avg_logprob": -0.2271421370967742,
        "compression_ratio": 1.8666666666666667,
        "end": 1633.1599999999999,
        "id": 620,
        "no_speech_prob": 0.00010889668919844553,
        "seek": 162712,
        "start": 1630.84,
        "temperature": 0,
        "text": " If there's an error, don't do anything.",
        "tokens": [
          50550,
          759,
          456,
          311,
          364,
          6713,
          11,
          500,
          380,
          360,
          1340,
          13,
          50666
        ]
      },
      {
        "avg_logprob": -0.2271421370967742,
        "compression_ratio": 1.8666666666666667,
        "end": 1637.1,
        "id": 621,
        "no_speech_prob": 0.00010889668919844553,
        "seek": 162712,
        "start": 1633.1599999999999,
        "temperature": 0,
        "text": " Otherwise, let's take a look at the results.",
        "tokens": [
          50666,
          10328,
          11,
          718,
          311,
          747,
          257,
          574,
          412,
          264,
          3542,
          13,
          50863
        ]
      },
      {
        "avg_logprob": -0.2271421370967742,
        "compression_ratio": 1.8666666666666667,
        "end": 1638.78,
        "id": 622,
        "no_speech_prob": 0.00010889668919844553,
        "seek": 162712,
        "start": 1637.1,
        "temperature": 0,
        "text": " Let's try this again.",
        "tokens": [
          50863,
          961,
          311,
          853,
          341,
          797,
          13,
          50947
        ]
      },
      {
        "avg_logprob": -0.2271421370967742,
        "compression_ratio": 1.8666666666666667,
        "end": 1640.78,
        "id": 623,
        "no_speech_prob": 0.00010889668919844553,
        "seek": 162712,
        "start": 1638.78,
        "temperature": 0,
        "text": " I can't believe I have to collect the data again.",
        "tokens": [
          50947,
          286,
          393,
          380,
          1697,
          286,
          362,
          281,
          2500,
          264,
          1412,
          797,
          13,
          51047
        ]
      },
      {
        "avg_logprob": -0.2271421370967742,
        "compression_ratio": 1.8666666666666667,
        "end": 1644.5,
        "id": 624,
        "no_speech_prob": 0.00010889668919844553,
        "seek": 162712,
        "start": 1640.78,
        "temperature": 0,
        "text": " Wouldn't it be nice if I could save the data so that I don't",
        "tokens": [
          51047,
          26291,
          380,
          309,
          312,
          1481,
          498,
          286,
          727,
          3155,
          264,
          1412,
          370,
          300,
          286,
          500,
          380,
          51233
        ]
      },
      {
        "avg_logprob": -0.2271421370967742,
        "compression_ratio": 1.8666666666666667,
        "end": 1647.4599999999998,
        "id": 625,
        "no_speech_prob": 0.00010889668919844553,
        "seek": 162712,
        "start": 1644.5,
        "temperature": 0,
        "text": " have to collect it again if I've made changes to my code?",
        "tokens": [
          51233,
          362,
          281,
          2500,
          309,
          797,
          498,
          286,
          600,
          1027,
          2962,
          281,
          452,
          3089,
          30,
          51381
        ]
      },
      {
        "avg_logprob": -0.2271421370967742,
        "compression_ratio": 1.8666666666666667,
        "end": 1648.3,
        "id": 626,
        "no_speech_prob": 0.00010889668919844553,
        "seek": 162712,
        "start": 1647.4599999999998,
        "temperature": 0,
        "text": " In fact, it is.",
        "tokens": [
          51381,
          682,
          1186,
          11,
          309,
          307,
          13,
          51423
        ]
      },
      {
        "avg_logprob": -0.2271421370967742,
        "compression_ratio": 1.8666666666666667,
        "end": 1650.4199999999998,
        "id": 627,
        "no_speech_prob": 0.00010889668919844553,
        "seek": 162712,
        "start": 1648.3,
        "temperature": 0,
        "text": " And I will come back and do a separate video",
        "tokens": [
          51423,
          400,
          286,
          486,
          808,
          646,
          293,
          360,
          257,
          4994,
          960,
          51529
        ]
      },
      {
        "avg_logprob": -0.2271421370967742,
        "compression_ratio": 1.8666666666666667,
        "end": 1652.02,
        "id": 628,
        "no_speech_prob": 0.00010889668919844553,
        "seek": 162712,
        "start": 1650.4199999999998,
        "temperature": 0,
        "text": " all about how to save the data.",
        "tokens": [
          51529,
          439,
          466,
          577,
          281,
          3155,
          264,
          1412,
          13,
          51609
        ]
      },
      {
        "avg_logprob": -0.2271421370967742,
        "compression_ratio": 1.8666666666666667,
        "end": 1654.2199999999998,
        "id": 629,
        "no_speech_prob": 0.00010889668919844553,
        "seek": 162712,
        "start": 1652.02,
        "temperature": 0,
        "text": " And in fact, I could also save the trained model.",
        "tokens": [
          51609,
          400,
          294,
          1186,
          11,
          286,
          727,
          611,
          3155,
          264,
          8895,
          2316,
          13,
          51719
        ]
      },
      {
        "avg_logprob": -0.2271421370967742,
        "compression_ratio": 1.8666666666666667,
        "end": 1656.4599999999998,
        "id": 630,
        "no_speech_prob": 0.00010889668919844553,
        "seek": 162712,
        "start": 1654.2199999999998,
        "temperature": 0,
        "text": " So I could load that trained model into another sketch.",
        "tokens": [
          51719,
          407,
          286,
          727,
          3677,
          300,
          8895,
          2316,
          666,
          1071,
          12325,
          13,
          51831
        ]
      },
      {
        "avg_logprob": -0.2736493552603373,
        "compression_ratio": 1.6755725190839694,
        "end": 1658.68,
        "id": 631,
        "no_speech_prob": 0.0000297730239253724,
        "seek": 165646,
        "start": 1656.52,
        "temperature": 0,
        "text": " Or all sorts of possibilities.",
        "tokens": [
          50367,
          1610,
          439,
          7527,
          295,
          12178,
          13,
          50475
        ]
      },
      {
        "avg_logprob": -0.2736493552603373,
        "compression_ratio": 1.6755725190839694,
        "end": 1660.8400000000001,
        "id": 632,
        "no_speech_prob": 0.0000297730239253724,
        "seek": 165646,
        "start": 1658.68,
        "temperature": 0,
        "text": " And I will also come back and look at saving data,",
        "tokens": [
          50475,
          400,
          286,
          486,
          611,
          808,
          646,
          293,
          574,
          412,
          6816,
          1412,
          11,
          50583
        ]
      },
      {
        "avg_logprob": -0.2736493552603373,
        "compression_ratio": 1.6755725190839694,
        "end": 1662.96,
        "id": 633,
        "no_speech_prob": 0.0000297730239253724,
        "seek": 165646,
        "start": 1660.8400000000001,
        "temperature": 0,
        "text": " and saving the model, and reloading those things.",
        "tokens": [
          50583,
          293,
          6816,
          264,
          2316,
          11,
          293,
          25628,
          278,
          729,
          721,
          13,
          50689
        ]
      },
      {
        "avg_logprob": -0.2736493552603373,
        "compression_ratio": 1.6755725190839694,
        "end": 1664.72,
        "id": 634,
        "no_speech_prob": 0.0000297730239253724,
        "seek": 165646,
        "start": 1662.96,
        "temperature": 0,
        "text": " But for right now, I'm just going to,",
        "tokens": [
          50689,
          583,
          337,
          558,
          586,
          11,
          286,
          478,
          445,
          516,
          281,
          11,
          50777
        ]
      },
      {
        "avg_logprob": -0.2736493552603373,
        "compression_ratio": 1.6755725190839694,
        "end": 1667.6000000000001,
        "id": 635,
        "no_speech_prob": 0.0000297730239253724,
        "seek": 165646,
        "start": 1664.72,
        "temperature": 0,
        "text": " because I have the time to do it and I can speed through this",
        "tokens": [
          50777,
          570,
          286,
          362,
          264,
          565,
          281,
          360,
          309,
          293,
          286,
          393,
          3073,
          807,
          341,
          50921
        ]
      },
      {
        "avg_logprob": -0.2736493552603373,
        "compression_ratio": 1.6755725190839694,
        "end": 1668.76,
        "id": 636,
        "no_speech_prob": 0.0000297730239253724,
        "seek": 165646,
        "start": 1667.6000000000001,
        "temperature": 0,
        "text": " when you're watching it, I'm just",
        "tokens": [
          50921,
          562,
          291,
          434,
          1976,
          309,
          11,
          286,
          478,
          445,
          50979
        ]
      },
      {
        "avg_logprob": -0.2736493552603373,
        "compression_ratio": 1.6755725190839694,
        "end": 1671.52,
        "id": 637,
        "no_speech_prob": 0.0000297730239253724,
        "seek": 165646,
        "start": 1668.76,
        "temperature": 0,
        "text": " going to constantly recollect the data over and over again.",
        "tokens": [
          50979,
          516,
          281,
          6460,
          39495,
          557,
          264,
          1412,
          670,
          293,
          670,
          797,
          13,
          51117
        ]
      },
      {
        "avg_logprob": -0.2736493552603373,
        "compression_ratio": 1.6755725190839694,
        "end": 1677.56,
        "id": 638,
        "no_speech_prob": 0.0000297730239253724,
        "seek": 165646,
        "start": 1671.52,
        "temperature": 0,
        "text": " The model is trained.",
        "tokens": [
          51117,
          440,
          2316,
          307,
          8895,
          13,
          51419
        ]
      },
      {
        "avg_logprob": -0.2736493552603373,
        "compression_ratio": 1.6755725190839694,
        "end": 1679.32,
        "id": 639,
        "no_speech_prob": 0.0000297730239253724,
        "seek": 165646,
        "start": 1677.56,
        "temperature": 0,
        "text": " And if I did things correctly, it'll",
        "tokens": [
          51419,
          400,
          498,
          286,
          630,
          721,
          8944,
          11,
          309,
          603,
          51507
        ]
      },
      {
        "avg_logprob": -0.2736493552603373,
        "compression_ratio": 1.6755725190839694,
        "end": 1684.1200000000001,
        "id": 640,
        "no_speech_prob": 0.0000297730239253724,
        "seek": 165646,
        "start": 1679.32,
        "temperature": 0,
        "text": " now show me some results when I click into the canvas.",
        "tokens": [
          51507,
          586,
          855,
          385,
          512,
          3542,
          562,
          286,
          2052,
          666,
          264,
          16267,
          13,
          51747
        ]
      },
      {
        "avg_logprob": -0.21934827168782553,
        "compression_ratio": 1.752,
        "end": 1687.1399999999999,
        "id": 641,
        "no_speech_prob": 0.00026947856531478465,
        "seek": 168412,
        "start": 1684.12,
        "temperature": 0,
        "text": " I'm going to click over by the C's.",
        "tokens": [
          50364,
          286,
          478,
          516,
          281,
          2052,
          670,
          538,
          264,
          383,
          311,
          13,
          50515
        ]
      },
      {
        "avg_logprob": -0.21934827168782553,
        "compression_ratio": 1.752,
        "end": 1687.9599999999998,
        "id": 642,
        "no_speech_prob": 0.00026947856531478465,
        "seek": 168412,
        "start": 1687.1399999999999,
        "temperature": 0,
        "text": " This is good.",
        "tokens": [
          50515,
          639,
          307,
          665,
          13,
          50556
        ]
      },
      {
        "avg_logprob": -0.21934827168782553,
        "compression_ratio": 1.752,
        "end": 1689.9799999999998,
        "id": 643,
        "no_speech_prob": 0.00026947856531478465,
        "seek": 168412,
        "start": 1687.9599999999998,
        "temperature": 0,
        "text": " I got an array back, that results array,",
        "tokens": [
          50556,
          286,
          658,
          364,
          10225,
          646,
          11,
          300,
          3542,
          10225,
          11,
          50657
        ]
      },
      {
        "avg_logprob": -0.21934827168782553,
        "compression_ratio": 1.752,
        "end": 1691.5,
        "id": 644,
        "no_speech_prob": 0.00026947856531478465,
        "seek": 168412,
        "start": 1689.9799999999998,
        "temperature": 0,
        "text": " and has three objects in it.",
        "tokens": [
          50657,
          293,
          575,
          1045,
          6565,
          294,
          309,
          13,
          50733
        ]
      },
      {
        "avg_logprob": -0.21934827168782553,
        "compression_ratio": 1.752,
        "end": 1692.86,
        "id": 645,
        "no_speech_prob": 0.00026947856531478465,
        "seek": 168412,
        "start": 1691.5,
        "temperature": 0,
        "text": " What are those objects?",
        "tokens": [
          50733,
          708,
          366,
          729,
          6565,
          30,
          50801
        ]
      },
      {
        "avg_logprob": -0.21934827168782553,
        "compression_ratio": 1.752,
        "end": 1695.9799999999998,
        "id": 646,
        "no_speech_prob": 0.00026947856531478465,
        "seek": 168412,
        "start": 1692.86,
        "temperature": 0,
        "text": " The first one is the label C with a confidence score",
        "tokens": [
          50801,
          440,
          700,
          472,
          307,
          264,
          7645,
          383,
          365,
          257,
          6687,
          6175,
          50957
        ]
      },
      {
        "avg_logprob": -0.21934827168782553,
        "compression_ratio": 1.752,
        "end": 1698.82,
        "id": 647,
        "no_speech_prob": 0.00026947856531478465,
        "seek": 168412,
        "start": 1695.9799999999998,
        "temperature": 0,
        "text": " of 88.5%.",
        "tokens": [
          50957,
          295,
          24587,
          13,
          20,
          6856,
          51099
        ]
      },
      {
        "avg_logprob": -0.21934827168782553,
        "compression_ratio": 1.752,
        "end": 1699.34,
        "id": 648,
        "no_speech_prob": 0.00026947856531478465,
        "seek": 168412,
        "start": 1698.82,
        "temperature": 0,
        "text": " That's good.",
        "tokens": [
          51099,
          663,
          311,
          665,
          13,
          51125
        ]
      },
      {
        "avg_logprob": -0.21934827168782553,
        "compression_ratio": 1.752,
        "end": 1700.6999999999998,
        "id": 649,
        "no_speech_prob": 0.00026947856531478465,
        "seek": 168412,
        "start": 1699.34,
        "temperature": 0,
        "text": " That's what I should have gotten.",
        "tokens": [
          51125,
          663,
          311,
          437,
          286,
          820,
          362,
          5768,
          13,
          51193
        ]
      },
      {
        "avg_logprob": -0.21934827168782553,
        "compression_ratio": 1.752,
        "end": 1704.1399999999999,
        "id": 650,
        "no_speech_prob": 0.00026947856531478465,
        "seek": 168412,
        "start": 1700.6999999999998,
        "temperature": 0,
        "text": " The second one is D, a confidence score of 7%.",
        "tokens": [
          51193,
          440,
          1150,
          472,
          307,
          413,
          11,
          257,
          6687,
          6175,
          295,
          1614,
          6856,
          51365
        ]
      },
      {
        "avg_logprob": -0.21934827168782553,
        "compression_ratio": 1.752,
        "end": 1708.86,
        "id": 651,
        "no_speech_prob": 0.00026947856531478465,
        "seek": 168412,
        "start": 1704.1399999999999,
        "temperature": 0,
        "text": " Third one, E, confidence score of, I guess, around 5%.",
        "tokens": [
          51365,
          12548,
          472,
          11,
          462,
          11,
          6687,
          6175,
          295,
          11,
          286,
          2041,
          11,
          926,
          1025,
          6856,
          51601
        ]
      },
      {
        "avg_logprob": -0.21934827168782553,
        "compression_ratio": 1.752,
        "end": 1710.54,
        "id": 652,
        "no_speech_prob": 0.00026947856531478465,
        "seek": 168412,
        "start": 1708.86,
        "temperature": 0,
        "text": " This is exactly what I expect.",
        "tokens": [
          51601,
          639,
          307,
          2293,
          437,
          286,
          2066,
          13,
          51685
        ]
      },
      {
        "avg_logprob": -0.21934827168782553,
        "compression_ratio": 1.752,
        "end": 1713.62,
        "id": 653,
        "no_speech_prob": 0.00026947856531478465,
        "seek": 168412,
        "start": 1710.54,
        "temperature": 0,
        "text": " These confidence scores are what the neural network",
        "tokens": [
          51685,
          1981,
          6687,
          13444,
          366,
          437,
          264,
          18161,
          3209,
          51839
        ]
      },
      {
        "avg_logprob": -0.2094741417811467,
        "compression_ratio": 1.5833333333333333,
        "end": 1715.9199999999998,
        "id": 654,
        "no_speech_prob": 0.00002111247340508271,
        "seek": 171362,
        "start": 1713.62,
        "temperature": 0,
        "text": " is really producing behind the scenes.",
        "tokens": [
          50364,
          307,
          534,
          10501,
          2261,
          264,
          8026,
          13,
          50479
        ]
      },
      {
        "avg_logprob": -0.2094741417811467,
        "compression_ratio": 1.5833333333333333,
        "end": 1719.6799999999998,
        "id": 655,
        "no_speech_prob": 0.00002111247340508271,
        "seek": 171362,
        "start": 1715.9199999999998,
        "temperature": 0,
        "text": " But the ml5 library has taken those confidence scores,",
        "tokens": [
          50479,
          583,
          264,
          23271,
          20,
          6405,
          575,
          2726,
          729,
          6687,
          13444,
          11,
          50667
        ]
      },
      {
        "avg_logprob": -0.2094741417811467,
        "compression_ratio": 1.5833333333333333,
        "end": 1721.8,
        "id": 656,
        "no_speech_prob": 0.00002111247340508271,
        "seek": 171362,
        "start": 1719.6799999999998,
        "temperature": 0,
        "text": " associated with given labels, and then",
        "tokens": [
          50667,
          6615,
          365,
          2212,
          16949,
          11,
          293,
          550,
          50773
        ]
      },
      {
        "avg_logprob": -0.2094741417811467,
        "compression_ratio": 1.5833333333333333,
        "end": 1725.6,
        "id": 657,
        "no_speech_prob": 0.00002111247340508271,
        "seek": 171362,
        "start": 1721.8,
        "temperature": 0,
        "text": " sorted those labels in order of confidence.",
        "tokens": [
          50773,
          25462,
          729,
          16949,
          294,
          1668,
          295,
          6687,
          13,
          50963
        ]
      },
      {
        "avg_logprob": -0.2094741417811467,
        "compression_ratio": 1.5833333333333333,
        "end": 1730.08,
        "id": 658,
        "no_speech_prob": 0.00002111247340508271,
        "seek": 171362,
        "start": 1725.6,
        "temperature": 0,
        "text": " So I will always have in result index 0.label",
        "tokens": [
          50963,
          407,
          286,
          486,
          1009,
          362,
          294,
          1874,
          8186,
          1958,
          13,
          75,
          18657,
          51187
        ]
      },
      {
        "avg_logprob": -0.2094741417811467,
        "compression_ratio": 1.5833333333333333,
        "end": 1732.04,
        "id": 659,
        "no_speech_prob": 0.00002111247340508271,
        "seek": 171362,
        "start": 1730.08,
        "temperature": 0,
        "text": " the label it thinks it should be.",
        "tokens": [
          51187,
          264,
          7645,
          309,
          7309,
          309,
          820,
          312,
          13,
          51285
        ]
      },
      {
        "avg_logprob": -0.2094741417811467,
        "compression_ratio": 1.5833333333333333,
        "end": 1735.28,
        "id": 660,
        "no_speech_prob": 0.00002111247340508271,
        "seek": 171362,
        "start": 1732.04,
        "temperature": 0,
        "text": " So what I can do is grab this drawing code.",
        "tokens": [
          51285,
          407,
          437,
          286,
          393,
          360,
          307,
          4444,
          341,
          6316,
          3089,
          13,
          51447
        ]
      },
      {
        "avg_logprob": -0.2094741417811467,
        "compression_ratio": 1.5833333333333333,
        "end": 1738.6,
        "id": 661,
        "no_speech_prob": 0.00002111247340508271,
        "seek": 171362,
        "start": 1735.28,
        "temperature": 0,
        "text": " And I can put it right down here.",
        "tokens": [
          51447,
          400,
          286,
          393,
          829,
          309,
          558,
          760,
          510,
          13,
          51613
        ]
      },
      {
        "avg_logprob": -0.2094741417811467,
        "compression_ratio": 1.5833333333333333,
        "end": 1743.36,
        "id": 662,
        "no_speech_prob": 0.00002111247340508271,
        "seek": 171362,
        "start": 1738.6,
        "temperature": 0,
        "text": " Maybe I'll change it to blue with some alpha.",
        "tokens": [
          51613,
          2704,
          286,
          603,
          1319,
          309,
          281,
          3344,
          365,
          512,
          8961,
          13,
          51851
        ]
      },
      {
        "avg_logprob": -0.30422834916548297,
        "compression_ratio": 1.5884476534296028,
        "end": 1745.3799999999999,
        "id": 663,
        "no_speech_prob": 0.00004908654227619991,
        "seek": 174336,
        "start": 1743.3799999999999,
        "temperature": 0,
        "text": " And instead of target label, I'm looking",
        "tokens": [
          50365,
          400,
          2602,
          295,
          3779,
          7645,
          11,
          286,
          478,
          1237,
          50465
        ]
      },
      {
        "avg_logprob": -0.30422834916548297,
        "compression_ratio": 1.5884476534296028,
        "end": 1748.6999999999998,
        "id": 664,
        "no_speech_prob": 0.00004908654227619991,
        "seek": 174336,
        "start": 1745.3799999999999,
        "temperature": 0,
        "text": " at results index 0.label.",
        "tokens": [
          50465,
          412,
          3542,
          8186,
          1958,
          13,
          75,
          18657,
          13,
          50631
        ]
      },
      {
        "avg_logprob": -0.30422834916548297,
        "compression_ratio": 1.5884476534296028,
        "end": 1751.52,
        "id": 665,
        "no_speech_prob": 0.00004908654227619991,
        "seek": 174336,
        "start": 1748.6999999999998,
        "temperature": 0,
        "text": " Now, truth is, I shouldn't be using mouseX and mouseY here.",
        "tokens": [
          50631,
          823,
          11,
          3494,
          307,
          11,
          286,
          4659,
          380,
          312,
          1228,
          9719,
          55,
          293,
          9719,
          56,
          510,
          13,
          50772
        ]
      },
      {
        "avg_logprob": -0.30422834916548297,
        "compression_ratio": 1.5884476534296028,
        "end": 1753.62,
        "id": 666,
        "no_speech_prob": 0.00004908654227619991,
        "seek": 174336,
        "start": 1751.52,
        "temperature": 0,
        "text": " I should be actually saving those inputs, maybe",
        "tokens": [
          50772,
          286,
          820,
          312,
          767,
          6816,
          729,
          15743,
          11,
          1310,
          50877
        ]
      },
      {
        "avg_logprob": -0.30422834916548297,
        "compression_ratio": 1.5884476534296028,
        "end": 1755.1399999999999,
        "id": 667,
        "no_speech_prob": 0.00004908654227619991,
        "seek": 174336,
        "start": 1753.62,
        "temperature": 0,
        "text": " in a global variable or passing them.",
        "tokens": [
          50877,
          294,
          257,
          4338,
          7006,
          420,
          8437,
          552,
          13,
          50953
        ]
      },
      {
        "avg_logprob": -0.30422834916548297,
        "compression_ratio": 1.5884476534296028,
        "end": 1757.02,
        "id": 668,
        "no_speech_prob": 0.00004908654227619991,
        "seek": 174336,
        "start": 1755.1399999999999,
        "temperature": 0,
        "text": " But I think the prediction is going to happen fast enough",
        "tokens": [
          50953,
          583,
          286,
          519,
          264,
          17630,
          307,
          516,
          281,
          1051,
          2370,
          1547,
          51047
        ]
      },
      {
        "avg_logprob": -0.30422834916548297,
        "compression_ratio": 1.5884476534296028,
        "end": 1758.86,
        "id": 669,
        "no_speech_prob": 0.00004908654227619991,
        "seek": 174336,
        "start": 1757.02,
        "temperature": 0,
        "text": " that I'm not really going to be able to move my mouse.",
        "tokens": [
          51047,
          300,
          286,
          478,
          406,
          534,
          516,
          281,
          312,
          1075,
          281,
          1286,
          452,
          9719,
          13,
          51139
        ]
      },
      {
        "avg_logprob": -0.30422834916548297,
        "compression_ratio": 1.5884476534296028,
        "end": 1760.26,
        "id": 670,
        "no_speech_prob": 0.00004908654227619991,
        "seek": 174336,
        "start": 1758.86,
        "temperature": 0,
        "text": " So I think it'll work out OK.",
        "tokens": [
          51139,
          407,
          286,
          519,
          309,
          603,
          589,
          484,
          2264,
          13,
          51209
        ]
      },
      {
        "avg_logprob": -0.30422834916548297,
        "compression_ratio": 1.5884476534296028,
        "end": 1761.3799999999999,
        "id": 671,
        "no_speech_prob": 0.00004908654227619991,
        "seek": 174336,
        "start": 1760.26,
        "temperature": 0,
        "text": " Let's give this a try.",
        "tokens": [
          51209,
          961,
          311,
          976,
          341,
          257,
          853,
          13,
          51265
        ]
      },
      {
        "avg_logprob": -0.30422834916548297,
        "compression_ratio": 1.5884476534296028,
        "end": 1763.02,
        "id": 672,
        "no_speech_prob": 0.00004908654227619991,
        "seek": 174336,
        "start": 1761.3799999999999,
        "temperature": 0,
        "text": " Oh, I got to collect all the data again.",
        "tokens": [
          51265,
          876,
          11,
          286,
          658,
          281,
          2500,
          439,
          264,
          1412,
          797,
          13,
          51347
        ]
      },
      {
        "avg_logprob": -0.30422834916548297,
        "compression_ratio": 1.5884476534296028,
        "end": 1766.5,
        "id": 673,
        "no_speech_prob": 0.00004908654227619991,
        "seek": 174336,
        "start": 1763.02,
        "temperature": 0,
        "text": " And train the model.",
        "tokens": [
          51347,
          400,
          3847,
          264,
          2316,
          13,
          51521
        ]
      },
      {
        "avg_logprob": -0.31716018786533273,
        "compression_ratio": 1.7447698744769875,
        "end": 1773.56,
        "id": 674,
        "no_speech_prob": 0.0028009051457047462,
        "seek": 176650,
        "start": 1767.4,
        "temperature": 0,
        "text": " And now I should be able to click here and see a C.",
        "tokens": [
          50409,
          400,
          586,
          286,
          820,
          312,
          1075,
          281,
          2052,
          510,
          293,
          536,
          257,
          383,
          13,
          50717
        ]
      },
      {
        "avg_logprob": -0.31716018786533273,
        "compression_ratio": 1.7447698744769875,
        "end": 1774.56,
        "id": 675,
        "no_speech_prob": 0.0028009051457047462,
        "seek": 176650,
        "start": 1773.56,
        "temperature": 0,
        "text": " I did.",
        "tokens": [
          50717,
          286,
          630,
          13,
          50767
        ]
      },
      {
        "avg_logprob": -0.31716018786533273,
        "compression_ratio": 1.7447698744769875,
        "end": 1776.32,
        "id": 676,
        "no_speech_prob": 0.0028009051457047462,
        "seek": 176650,
        "start": 1774.56,
        "temperature": 0,
        "text": " And a D. I did.",
        "tokens": [
          50767,
          400,
          257,
          413,
          13,
          286,
          630,
          13,
          50855
        ]
      },
      {
        "avg_logprob": -0.31716018786533273,
        "compression_ratio": 1.7447698744769875,
        "end": 1779.2,
        "id": 677,
        "no_speech_prob": 0.0028009051457047462,
        "seek": 176650,
        "start": 1776.32,
        "temperature": 0,
        "text": " And an E. Let's move along here and see,",
        "tokens": [
          50855,
          400,
          364,
          462,
          13,
          961,
          311,
          1286,
          2051,
          510,
          293,
          536,
          11,
          50999
        ]
      },
      {
        "avg_logprob": -0.31716018786533273,
        "compression_ratio": 1.7447698744769875,
        "end": 1781.36,
        "id": 678,
        "no_speech_prob": 0.0028009051457047462,
        "seek": 176650,
        "start": 1779.2,
        "temperature": 0,
        "text": " when does it change to C?",
        "tokens": [
          50999,
          562,
          775,
          309,
          1319,
          281,
          383,
          30,
          51107
        ]
      },
      {
        "avg_logprob": -0.31716018786533273,
        "compression_ratio": 1.7447698744769875,
        "end": 1782.24,
        "id": 679,
        "no_speech_prob": 0.0028009051457047462,
        "seek": 176650,
        "start": 1781.36,
        "temperature": 0,
        "text": " It changes to C there.",
        "tokens": [
          51107,
          467,
          2962,
          281,
          383,
          456,
          13,
          51151
        ]
      },
      {
        "avg_logprob": -0.31716018786533273,
        "compression_ratio": 1.7447698744769875,
        "end": 1786.2,
        "id": 680,
        "no_speech_prob": 0.0028009051457047462,
        "seek": 176650,
        "start": 1782.24,
        "temperature": 0,
        "text": " That's like a decision threshold-like thingy.",
        "tokens": [
          51151,
          663,
          311,
          411,
          257,
          3537,
          14678,
          12,
          4092,
          551,
          88,
          13,
          51349
        ]
      },
      {
        "avg_logprob": -0.31716018786533273,
        "compression_ratio": 1.7447698744769875,
        "end": 1787.92,
        "id": 681,
        "no_speech_prob": 0.0028009051457047462,
        "seek": 176650,
        "start": 1786.2,
        "temperature": 0,
        "text": " You know what would be interesting to do?",
        "tokens": [
          51349,
          509,
          458,
          437,
          576,
          312,
          1880,
          281,
          360,
          30,
          51435
        ]
      },
      {
        "avg_logprob": -0.31716018786533273,
        "compression_ratio": 1.7447698744769875,
        "end": 1790.16,
        "id": 682,
        "no_speech_prob": 0.0028009051457047462,
        "seek": 176650,
        "start": 1787.92,
        "temperature": 0,
        "text": " We could draw a map of what all the decisions",
        "tokens": [
          51435,
          492,
          727,
          2642,
          257,
          4471,
          295,
          437,
          439,
          264,
          5327,
          51547
        ]
      },
      {
        "avg_logprob": -0.31716018786533273,
        "compression_ratio": 1.7447698744769875,
        "end": 1791.82,
        "id": 683,
        "no_speech_prob": 0.0028009051457047462,
        "seek": 176650,
        "start": 1790.16,
        "temperature": 0,
        "text": " are across all the pixels.",
        "tokens": [
          51547,
          366,
          2108,
          439,
          264,
          18668,
          13,
          51630
        ]
      },
      {
        "avg_logprob": -0.31716018786533273,
        "compression_ratio": 1.7447698744769875,
        "end": 1793.56,
        "id": 684,
        "no_speech_prob": 0.0028009051457047462,
        "seek": 176650,
        "start": 1791.82,
        "temperature": 0,
        "text": " That's a project you should do.",
        "tokens": [
          51630,
          663,
          311,
          257,
          1716,
          291,
          820,
          360,
          13,
          51717
        ]
      },
      {
        "avg_logprob": -0.31716018786533273,
        "compression_ratio": 1.7447698744769875,
        "end": 1794.4,
        "id": 685,
        "no_speech_prob": 0.0028009051457047462,
        "seek": 176650,
        "start": 1793.56,
        "temperature": 0,
        "text": " And click over here.",
        "tokens": [
          51717,
          400,
          2052,
          670,
          510,
          13,
          51759
        ]
      },
      {
        "avg_logprob": -0.31716018786533273,
        "compression_ratio": 1.7447698744769875,
        "end": 1796.2,
        "id": 686,
        "no_speech_prob": 0.0028009051457047462,
        "seek": 176650,
        "start": 1794.4,
        "temperature": 0,
        "text": " I should get a D. C. What's over here?",
        "tokens": [
          51759,
          286,
          820,
          483,
          257,
          413,
          13,
          383,
          13,
          708,
          311,
          670,
          510,
          30,
          51849
        ]
      },
      {
        "avg_logprob": -0.2399075519607728,
        "compression_ratio": 1.853658536585366,
        "end": 1798.5800000000002,
        "id": 687,
        "no_speech_prob": 0.00014202338934410363,
        "seek": 179620,
        "start": 1796.22,
        "temperature": 0,
        "text": " A D, a D, a D, an E. Oh, this is fascinating.",
        "tokens": [
          50365,
          316,
          413,
          11,
          257,
          413,
          11,
          257,
          413,
          11,
          364,
          462,
          13,
          876,
          11,
          341,
          307,
          10343,
          13,
          50483
        ]
      },
      {
        "avg_logprob": -0.2399075519607728,
        "compression_ratio": 1.853658536585366,
        "end": 1799.66,
        "id": 688,
        "no_speech_prob": 0.00014202338934410363,
        "seek": 179620,
        "start": 1798.5800000000002,
        "temperature": 0,
        "text": " I love that this works.",
        "tokens": [
          50483,
          286,
          959,
          300,
          341,
          1985,
          13,
          50537
        ]
      },
      {
        "avg_logprob": -0.2399075519607728,
        "compression_ratio": 1.853658536585366,
        "end": 1801.02,
        "id": 689,
        "no_speech_prob": 0.00014202338934410363,
        "seek": 179620,
        "start": 1799.66,
        "temperature": 0,
        "text": " So guess what?",
        "tokens": [
          50537,
          407,
          2041,
          437,
          30,
          50605
        ]
      },
      {
        "avg_logprob": -0.2399075519607728,
        "compression_ratio": 1.853658536585366,
        "end": 1802.06,
        "id": 690,
        "no_speech_prob": 0.00014202338934410363,
        "seek": 179620,
        "start": 1801.02,
        "temperature": 0,
        "text": " This is actually done.",
        "tokens": [
          50605,
          639,
          307,
          767,
          1096,
          13,
          50657
        ]
      },
      {
        "avg_logprob": -0.2399075519607728,
        "compression_ratio": 1.853658536585366,
        "end": 1806.02,
        "id": 691,
        "no_speech_prob": 0.00014202338934410363,
        "seek": 179620,
        "start": 1802.06,
        "temperature": 0,
        "text": " But the whole point of what I wanted to do here",
        "tokens": [
          50657,
          583,
          264,
          1379,
          935,
          295,
          437,
          286,
          1415,
          281,
          360,
          510,
          50855
        ]
      },
      {
        "avg_logprob": -0.2399075519607728,
        "compression_ratio": 1.853658536585366,
        "end": 1807.66,
        "id": 692,
        "no_speech_prob": 0.00014202338934410363,
        "seek": 179620,
        "start": 1806.02,
        "temperature": 0,
        "text": " was to have it play sound.",
        "tokens": [
          50855,
          390,
          281,
          362,
          309,
          862,
          1626,
          13,
          50937
        ]
      },
      {
        "avg_logprob": -0.2399075519607728,
        "compression_ratio": 1.853658536585366,
        "end": 1810.02,
        "id": 693,
        "no_speech_prob": 0.00014202338934410363,
        "seek": 179620,
        "start": 1807.66,
        "temperature": 0,
        "text": " Because I want this to be the beginning of an idea",
        "tokens": [
          50937,
          1436,
          286,
          528,
          341,
          281,
          312,
          264,
          2863,
          295,
          364,
          1558,
          51055
        ]
      },
      {
        "avg_logprob": -0.2399075519607728,
        "compression_ratio": 1.853658536585366,
        "end": 1813.42,
        "id": 694,
        "no_speech_prob": 0.00014202338934410363,
        "seek": 179620,
        "start": 1810.02,
        "temperature": 0,
        "text": " that I could maybe play musical notes by moving my hand around.",
        "tokens": [
          51055,
          300,
          286,
          727,
          1310,
          862,
          9165,
          5570,
          538,
          2684,
          452,
          1011,
          926,
          13,
          51225
        ]
      },
      {
        "avg_logprob": -0.2399075519607728,
        "compression_ratio": 1.853658536585366,
        "end": 1815.18,
        "id": 695,
        "no_speech_prob": 0.00014202338934410363,
        "seek": 179620,
        "start": 1813.42,
        "temperature": 0,
        "text": " Imagine, again, the inputs being instead",
        "tokens": [
          51225,
          11739,
          11,
          797,
          11,
          264,
          15743,
          885,
          2602,
          51313
        ]
      },
      {
        "avg_logprob": -0.2399075519607728,
        "compression_ratio": 1.853658536585366,
        "end": 1819.14,
        "id": 696,
        "no_speech_prob": 0.00014202338934410363,
        "seek": 179620,
        "start": 1815.18,
        "temperature": 0,
        "text": " of the xy of mouse clicks, the xy of some type of hand",
        "tokens": [
          51313,
          295,
          264,
          2031,
          88,
          295,
          9719,
          18521,
          11,
          264,
          2031,
          88,
          295,
          512,
          2010,
          295,
          1011,
          51511
        ]
      },
      {
        "avg_logprob": -0.2399075519607728,
        "compression_ratio": 1.853658536585366,
        "end": 1819.82,
        "id": 697,
        "no_speech_prob": 0.00014202338934410363,
        "seek": 179620,
        "start": 1819.14,
        "temperature": 0,
        "text": " tracking.",
        "tokens": [
          51511,
          11603,
          13,
          51545
        ]
      },
      {
        "avg_logprob": -0.2399075519607728,
        "compression_ratio": 1.853658536585366,
        "end": 1822.9,
        "id": 698,
        "no_speech_prob": 0.00014202338934410363,
        "seek": 179620,
        "start": 1819.82,
        "temperature": 0,
        "text": " Or I could actually have more than just two inputs.",
        "tokens": [
          51545,
          1610,
          286,
          727,
          767,
          362,
          544,
          813,
          445,
          732,
          15743,
          13,
          51699
        ]
      },
      {
        "avg_logprob": -0.2399075519607728,
        "compression_ratio": 1.853658536585366,
        "end": 1825.26,
        "id": 699,
        "no_speech_prob": 0.00014202338934410363,
        "seek": 179620,
        "start": 1822.9,
        "temperature": 0,
        "text": " Because I could take the xy of this, and the xy of this,",
        "tokens": [
          51699,
          1436,
          286,
          727,
          747,
          264,
          2031,
          88,
          295,
          341,
          11,
          293,
          264,
          2031,
          88,
          295,
          341,
          11,
          51817
        ]
      },
      {
        "avg_logprob": -0.2399075519607728,
        "compression_ratio": 1.853658536585366,
        "end": 1826.06,
        "id": 700,
        "no_speech_prob": 0.00014202338934410363,
        "seek": 179620,
        "start": 1825.26,
        "temperature": 0,
        "text": " and the xy of this.",
        "tokens": [
          51817,
          293,
          264,
          2031,
          88,
          295,
          341,
          13,
          51857
        ]
      },
      {
        "avg_logprob": -0.2564848849647923,
        "compression_ratio": 1.691588785046729,
        "end": 1827.76,
        "id": 701,
        "no_speech_prob": 0.0001660374691709876,
        "seek": 182606,
        "start": 1826.08,
        "temperature": 0,
        "text": " Or whatever kind of other data.",
        "tokens": [
          50365,
          1610,
          2035,
          733,
          295,
          661,
          1412,
          13,
          50449
        ]
      },
      {
        "avg_logprob": -0.2564848849647923,
        "compression_ratio": 1.691588785046729,
        "end": 1829.72,
        "id": 702,
        "no_speech_prob": 0.0001660374691709876,
        "seek": 182606,
        "start": 1827.76,
        "temperature": 0,
        "text": " Maybe you've hooked up a whole bunch of sensors.",
        "tokens": [
          50449,
          2704,
          291,
          600,
          20410,
          493,
          257,
          1379,
          3840,
          295,
          14840,
          13,
          50547
        ]
      },
      {
        "avg_logprob": -0.2564848849647923,
        "compression_ratio": 1.691588785046729,
        "end": 1831.96,
        "id": 703,
        "no_speech_prob": 0.0001660374691709876,
        "seek": 182606,
        "start": 1829.72,
        "temperature": 0,
        "text": " And you've got a bunch of different force sensors",
        "tokens": [
          50547,
          400,
          291,
          600,
          658,
          257,
          3840,
          295,
          819,
          3464,
          14840,
          50659
        ]
      },
      {
        "avg_logprob": -0.2564848849647923,
        "compression_ratio": 1.691588785046729,
        "end": 1832.76,
        "id": 704,
        "no_speech_prob": 0.0001660374691709876,
        "seek": 182606,
        "start": 1831.96,
        "temperature": 0,
        "text": " and an Arduino.",
        "tokens": [
          50659,
          293,
          364,
          39539,
          13,
          50699
        ]
      },
      {
        "avg_logprob": -0.2564848849647923,
        "compression_ratio": 1.691588785046729,
        "end": 1834.44,
        "id": 705,
        "no_speech_prob": 0.0001660374691709876,
        "seek": 182606,
        "start": 1832.76,
        "temperature": 0,
        "text": " And those could be the inputs to your neural network.",
        "tokens": [
          50699,
          400,
          729,
          727,
          312,
          264,
          15743,
          281,
          428,
          18161,
          3209,
          13,
          50783
        ]
      },
      {
        "avg_logprob": -0.2564848849647923,
        "compression_ratio": 1.691588785046729,
        "end": 1835.44,
        "id": 706,
        "no_speech_prob": 0.0001660374691709876,
        "seek": 182606,
        "start": 1834.44,
        "temperature": 0,
        "text": " So many possibilities.",
        "tokens": [
          50783,
          407,
          867,
          12178,
          13,
          50833
        ]
      },
      {
        "avg_logprob": -0.2564848849647923,
        "compression_ratio": 1.691588785046729,
        "end": 1838,
        "id": 707,
        "no_speech_prob": 0.0001660374691709876,
        "seek": 182606,
        "start": 1835.44,
        "temperature": 0,
        "text": " But I'm not going to explore all those possibilities right now,",
        "tokens": [
          50833,
          583,
          286,
          478,
          406,
          516,
          281,
          6839,
          439,
          729,
          12178,
          558,
          586,
          11,
          50961
        ]
      },
      {
        "avg_logprob": -0.2564848849647923,
        "compression_ratio": 1.691588785046729,
        "end": 1838.5,
        "id": 708,
        "no_speech_prob": 0.0001660374691709876,
        "seek": 182606,
        "start": 1838,
        "temperature": 0,
        "text": " at least.",
        "tokens": [
          50961,
          412,
          1935,
          13,
          50986
        ]
      },
      {
        "avg_logprob": -0.2564848849647923,
        "compression_ratio": 1.691588785046729,
        "end": 1841.8999999999999,
        "id": 709,
        "no_speech_prob": 0.0001660374691709876,
        "seek": 182606,
        "start": 1838.5,
        "temperature": 0,
        "text": " But I do want to show you the output of playing a note.",
        "tokens": [
          50986,
          583,
          286,
          360,
          528,
          281,
          855,
          291,
          264,
          5598,
          295,
          2433,
          257,
          3637,
          13,
          51156
        ]
      },
      {
        "avg_logprob": -0.2564848849647923,
        "compression_ratio": 1.691588785046729,
        "end": 1844.4199999999998,
        "id": 710,
        "no_speech_prob": 0.0001660374691709876,
        "seek": 182606,
        "start": 1841.8999999999999,
        "temperature": 0,
        "text": " I made a video tutorial that you could go back and watch,",
        "tokens": [
          51156,
          286,
          1027,
          257,
          960,
          7073,
          300,
          291,
          727,
          352,
          646,
          293,
          1159,
          11,
          51282
        ]
      },
      {
        "avg_logprob": -0.2564848849647923,
        "compression_ratio": 1.691588785046729,
        "end": 1849.04,
        "id": 711,
        "no_speech_prob": 0.0001660374691709876,
        "seek": 182606,
        "start": 1844.4199999999998,
        "temperature": 0,
        "text": " if you want, about how to use a sound envelope with a sound",
        "tokens": [
          51282,
          498,
          291,
          528,
          11,
          466,
          577,
          281,
          764,
          257,
          1626,
          19989,
          365,
          257,
          1626,
          51513
        ]
      },
      {
        "avg_logprob": -0.2564848849647923,
        "compression_ratio": 1.691588785046729,
        "end": 1852.32,
        "id": 712,
        "no_speech_prob": 0.0001660374691709876,
        "seek": 182606,
        "start": 1849.04,
        "temperature": 0,
        "text": " oscillator in P5 to generate a tone.",
        "tokens": [
          51513,
          43859,
          294,
          430,
          20,
          281,
          8460,
          257,
          8027,
          13,
          51677
        ]
      },
      {
        "avg_logprob": -0.2564848849647923,
        "compression_ratio": 1.691588785046729,
        "end": 1853.84,
        "id": 713,
        "no_speech_prob": 0.0001660374691709876,
        "seek": 182606,
        "start": 1852.32,
        "temperature": 0,
        "text": " And so I'm just going to, for now,",
        "tokens": [
          51677,
          400,
          370,
          286,
          478,
          445,
          516,
          281,
          11,
          337,
          586,
          11,
          51753
        ]
      },
      {
        "avg_logprob": -0.2338228697824006,
        "compression_ratio": 1.6076555023923444,
        "end": 1856.3799999999999,
        "id": 714,
        "no_speech_prob": 0.0006986728403717279,
        "seek": 185384,
        "start": 1853.86,
        "temperature": 0,
        "text": " just grab this code, all of this,",
        "tokens": [
          50365,
          445,
          4444,
          341,
          3089,
          11,
          439,
          295,
          341,
          11,
          50491
        ]
      },
      {
        "avg_logprob": -0.2338228697824006,
        "compression_ratio": 1.6076555023923444,
        "end": 1858.4599999999998,
        "id": 715,
        "no_speech_prob": 0.0006986728403717279,
        "seek": 185384,
        "start": 1856.3799999999999,
        "temperature": 0,
        "text": " the oscillator and the envelope.",
        "tokens": [
          50491,
          264,
          43859,
          293,
          264,
          19989,
          13,
          50595
        ]
      },
      {
        "avg_logprob": -0.2338228697824006,
        "compression_ratio": 1.6076555023923444,
        "end": 1861.1799999999998,
        "id": 716,
        "no_speech_prob": 0.0006986728403717279,
        "seek": 185384,
        "start": 1858.4599999999998,
        "temperature": 0,
        "text": " I'm going to paste all that in setup here.",
        "tokens": [
          50595,
          286,
          478,
          516,
          281,
          9163,
          439,
          300,
          294,
          8657,
          510,
          13,
          50731
        ]
      },
      {
        "avg_logprob": -0.2338228697824006,
        "compression_ratio": 1.6076555023923444,
        "end": 1863.6599999999999,
        "id": 717,
        "no_speech_prob": 0.0006986728403717279,
        "seek": 185384,
        "start": 1861.1799999999998,
        "temperature": 0,
        "text": " And this, by the way, has changed to the full word",
        "tokens": [
          50731,
          400,
          341,
          11,
          538,
          264,
          636,
          11,
          575,
          3105,
          281,
          264,
          1577,
          1349,
          50855
        ]
      },
      {
        "avg_logprob": -0.2338228697824006,
        "compression_ratio": 1.6076555023923444,
        "end": 1865.72,
        "id": 718,
        "no_speech_prob": 0.0006986728403717279,
        "seek": 185384,
        "start": 1863.6599999999999,
        "temperature": 0,
        "text": " envelope, since I last made that tutorial.",
        "tokens": [
          50855,
          19989,
          11,
          1670,
          286,
          1036,
          1027,
          300,
          7073,
          13,
          50958
        ]
      },
      {
        "avg_logprob": -0.2338228697824006,
        "compression_ratio": 1.6076555023923444,
        "end": 1868.4199999999998,
        "id": 719,
        "no_speech_prob": 0.0006986728403717279,
        "seek": 185384,
        "start": 1865.72,
        "temperature": 0,
        "text": " And now, whenever I click the mouse,",
        "tokens": [
          50958,
          400,
          586,
          11,
          5699,
          286,
          2052,
          264,
          9719,
          11,
          51093
        ]
      },
      {
        "avg_logprob": -0.2338228697824006,
        "compression_ratio": 1.6076555023923444,
        "end": 1873.8999999999999,
        "id": 720,
        "no_speech_prob": 0.0006986728403717279,
        "seek": 185384,
        "start": 1868.4199999999998,
        "temperature": 0,
        "text": " I should be able to say, envelope play.",
        "tokens": [
          51093,
          286,
          820,
          312,
          1075,
          281,
          584,
          11,
          19989,
          862,
          13,
          51367
        ]
      },
      {
        "avg_logprob": -0.2338228697824006,
        "compression_ratio": 1.6076555023923444,
        "end": 1880.86,
        "id": 721,
        "no_speech_prob": 0.0006986728403717279,
        "seek": 185384,
        "start": 1873.8999999999999,
        "temperature": 0,
        "text": " So if I do this, when I click, you hear this note play.",
        "tokens": [
          51367,
          407,
          498,
          286,
          360,
          341,
          11,
          562,
          286,
          2052,
          11,
          291,
          1568,
          341,
          3637,
          862,
          13,
          51715
        ]
      },
      {
        "avg_logprob": -0.15691670719881234,
        "compression_ratio": 1.7651006711409396,
        "end": 1884.56,
        "id": 722,
        "no_speech_prob": 0.00017130692140199244,
        "seek": 188086,
        "start": 1880.8799999999999,
        "temperature": 0,
        "text": " But I want it to play C, D, or E.",
        "tokens": [
          50365,
          583,
          286,
          528,
          309,
          281,
          862,
          383,
          11,
          413,
          11,
          420,
          462,
          13,
          50549
        ]
      },
      {
        "avg_logprob": -0.15691670719881234,
        "compression_ratio": 1.7651006711409396,
        "end": 1886.32,
        "id": 723,
        "no_speech_prob": 0.00017130692140199244,
        "seek": 188086,
        "start": 1884.56,
        "temperature": 0,
        "text": " And honestly, I could make a lot of notes",
        "tokens": [
          50549,
          400,
          6095,
          11,
          286,
          727,
          652,
          257,
          688,
          295,
          5570,
          50637
        ]
      },
      {
        "avg_logprob": -0.15691670719881234,
        "compression_ratio": 1.7651006711409396,
        "end": 1888.9199999999998,
        "id": 724,
        "no_speech_prob": 0.00017130692140199244,
        "seek": 188086,
        "start": 1886.32,
        "temperature": 0,
        "text": " right now, since I can have more than just three categories.",
        "tokens": [
          50637,
          558,
          586,
          11,
          1670,
          286,
          393,
          362,
          544,
          813,
          445,
          1045,
          10479,
          13,
          50767
        ]
      },
      {
        "avg_logprob": -0.15691670719881234,
        "compression_ratio": 1.7651006711409396,
        "end": 1891.1599999999999,
        "id": 725,
        "no_speech_prob": 0.00017130692140199244,
        "seek": 188086,
        "start": 1888.9199999999998,
        "temperature": 0,
        "text": " But let's just stick with C, D, and E.",
        "tokens": [
          50767,
          583,
          718,
          311,
          445,
          2897,
          365,
          383,
          11,
          413,
          11,
          293,
          462,
          13,
          50879
        ]
      },
      {
        "avg_logprob": -0.15691670719881234,
        "compression_ratio": 1.7651006711409396,
        "end": 1893.2199999999998,
        "id": 726,
        "no_speech_prob": 0.00017130692140199244,
        "seek": 188086,
        "start": 1891.1599999999999,
        "temperature": 0,
        "text": " What I need to play a particular note",
        "tokens": [
          50879,
          708,
          286,
          643,
          281,
          862,
          257,
          1729,
          3637,
          50982
        ]
      },
      {
        "avg_logprob": -0.15691670719881234,
        "compression_ratio": 1.7651006711409396,
        "end": 1895.28,
        "id": 727,
        "no_speech_prob": 0.00017130692140199244,
        "seek": 188086,
        "start": 1893.2199999999998,
        "temperature": 0,
        "text": " is the frequency of that note.",
        "tokens": [
          50982,
          307,
          264,
          7893,
          295,
          300,
          3637,
          13,
          51085
        ]
      },
      {
        "avg_logprob": -0.15691670719881234,
        "compression_ratio": 1.7651006711409396,
        "end": 1897.12,
        "id": 728,
        "no_speech_prob": 0.00017130692140199244,
        "seek": 188086,
        "start": 1895.28,
        "temperature": 0,
        "text": " And I can find this on this Wikipedia page",
        "tokens": [
          51085,
          400,
          286,
          393,
          915,
          341,
          322,
          341,
          28999,
          3028,
          51177
        ]
      },
      {
        "avg_logprob": -0.15691670719881234,
        "compression_ratio": 1.7651006711409396,
        "end": 1898.76,
        "id": 729,
        "no_speech_prob": 0.00017130692140199244,
        "seek": 188086,
        "start": 1897.12,
        "temperature": 0,
        "text": " about frequencies and piano notes.",
        "tokens": [
          51177,
          466,
          20250,
          293,
          9211,
          5570,
          13,
          51259
        ]
      },
      {
        "avg_logprob": -0.15691670719881234,
        "compression_ratio": 1.7651006711409396,
        "end": 1901,
        "id": 730,
        "no_speech_prob": 0.00017130692140199244,
        "seek": 188086,
        "start": 1898.76,
        "temperature": 0,
        "text": " So I'll start with C4, D4, and E4.",
        "tokens": [
          51259,
          407,
          286,
          603,
          722,
          365,
          383,
          19,
          11,
          413,
          19,
          11,
          293,
          462,
          19,
          13,
          51371
        ]
      },
      {
        "avg_logprob": -0.15691670719881234,
        "compression_ratio": 1.7651006711409396,
        "end": 1904.24,
        "id": 731,
        "no_speech_prob": 0.00017130692140199244,
        "seek": 188086,
        "start": 1901,
        "temperature": 0,
        "text": " I'll make an object that's a lookup table for those notes.",
        "tokens": [
          51371,
          286,
          603,
          652,
          364,
          2657,
          300,
          311,
          257,
          574,
          1010,
          3199,
          337,
          729,
          5570,
          13,
          51533
        ]
      },
      {
        "avg_logprob": -0.15691670719881234,
        "compression_ratio": 1.7651006711409396,
        "end": 1907.8799999999999,
        "id": 732,
        "no_speech_prob": 0.00017130692140199244,
        "seek": 188086,
        "start": 1904.24,
        "temperature": 0,
        "text": " So I have the C, D, and E all matched with their frequency.",
        "tokens": [
          51533,
          407,
          286,
          362,
          264,
          383,
          11,
          413,
          11,
          293,
          462,
          439,
          21447,
          365,
          641,
          7893,
          13,
          51715
        ]
      },
      {
        "avg_logprob": -0.15691670719881234,
        "compression_ratio": 1.7651006711409396,
        "end": 1910.7199999999998,
        "id": 733,
        "no_speech_prob": 0.00017130692140199244,
        "seek": 188086,
        "start": 1907.8799999999999,
        "temperature": 0,
        "text": " I should make sure that the envelope and the wave",
        "tokens": [
          51715,
          286,
          820,
          652,
          988,
          300,
          264,
          19989,
          293,
          264,
          5772,
          51857
        ]
      },
      {
        "avg_logprob": -0.2219790049961635,
        "compression_ratio": 1.5813953488372092,
        "end": 1917.38,
        "id": 734,
        "no_speech_prob": 0.000024682860384928063,
        "seek": 191072,
        "start": 1910.78,
        "temperature": 0,
        "text": " are global variables, because now, when I play the note,",
        "tokens": [
          50367,
          366,
          4338,
          9102,
          11,
          570,
          586,
          11,
          562,
          286,
          862,
          264,
          3637,
          11,
          50697
        ]
      },
      {
        "avg_logprob": -0.2219790049961635,
        "compression_ratio": 1.5813953488372092,
        "end": 1923.74,
        "id": 735,
        "no_speech_prob": 0.000024682860384928063,
        "seek": 191072,
        "start": 1917.38,
        "temperature": 0,
        "text": " I could set the frequency to notes index target label.",
        "tokens": [
          50697,
          286,
          727,
          992,
          264,
          7893,
          281,
          5570,
          8186,
          3779,
          7645,
          13,
          51015
        ]
      },
      {
        "avg_logprob": -0.2219790049961635,
        "compression_ratio": 1.5813953488372092,
        "end": 1926.42,
        "id": 736,
        "no_speech_prob": 0.000024682860384928063,
        "seek": 191072,
        "start": 1923.74,
        "temperature": 0,
        "text": " This will look up the numeric frequency associated",
        "tokens": [
          51015,
          639,
          486,
          574,
          493,
          264,
          7866,
          299,
          7893,
          6615,
          51149
        ]
      },
      {
        "avg_logprob": -0.2219790049961635,
        "compression_ratio": 1.5813953488372092,
        "end": 1928.5,
        "id": 737,
        "no_speech_prob": 0.000024682860384928063,
        "seek": 191072,
        "start": 1926.42,
        "temperature": 0,
        "text": " with that label and set the sound oscillator",
        "tokens": [
          51149,
          365,
          300,
          7645,
          293,
          992,
          264,
          1626,
          43859,
          51253
        ]
      },
      {
        "avg_logprob": -0.2219790049961635,
        "compression_ratio": 1.5813953488372092,
        "end": 1931.1000000000001,
        "id": 738,
        "no_speech_prob": 0.000024682860384928063,
        "seek": 191072,
        "start": 1928.5,
        "temperature": 0,
        "text": " to that frequency.",
        "tokens": [
          51253,
          281,
          300,
          7893,
          13,
          51383
        ]
      },
      {
        "avg_logprob": -0.2219790049961635,
        "compression_ratio": 1.5813953488372092,
        "end": 1940.22,
        "id": 739,
        "no_speech_prob": 0.000024682860384928063,
        "seek": 191072,
        "start": 1931.1000000000001,
        "temperature": 0,
        "text": " C, C, C, D, D, D, E, E, E. Now, if I press F,",
        "tokens": [
          51383,
          383,
          11,
          383,
          11,
          383,
          11,
          413,
          11,
          413,
          11,
          413,
          11,
          462,
          11,
          462,
          11,
          462,
          13,
          823,
          11,
          498,
          286,
          1886,
          479,
          11,
          51839
        ]
      },
      {
        "avg_logprob": -0.2377532958984375,
        "compression_ratio": 1.6550522648083623,
        "end": 1941.88,
        "id": 740,
        "no_speech_prob": 0.0000475762972200755,
        "seek": 194022,
        "start": 1940.22,
        "temperature": 0,
        "text": " it's not going to change, because I didn't put F",
        "tokens": [
          50364,
          309,
          311,
          406,
          516,
          281,
          1319,
          11,
          570,
          286,
          994,
          380,
          829,
          479,
          50447
        ]
      },
      {
        "avg_logprob": -0.2377532958984375,
        "compression_ratio": 1.6550522648083623,
        "end": 1942.68,
        "id": 741,
        "no_speech_prob": 0.0000475762972200755,
        "seek": 194022,
        "start": 1941.88,
        "temperature": 0,
        "text": " in that lookup table.",
        "tokens": [
          50447,
          294,
          300,
          574,
          1010,
          3199,
          13,
          50487
        ]
      },
      {
        "avg_logprob": -0.2377532958984375,
        "compression_ratio": 1.6550522648083623,
        "end": 1943.64,
        "id": 742,
        "no_speech_prob": 0.0000475762972200755,
        "seek": 194022,
        "start": 1942.68,
        "temperature": 0,
        "text": " But you could add more notes.",
        "tokens": [
          50487,
          583,
          291,
          727,
          909,
          544,
          5570,
          13,
          50535
        ]
      },
      {
        "avg_logprob": -0.2377532958984375,
        "compression_ratio": 1.6550522648083623,
        "end": 1944.4,
        "id": 743,
        "no_speech_prob": 0.0000475762972200755,
        "seek": 194022,
        "start": 1943.64,
        "temperature": 0,
        "text": " Add more notes.",
        "tokens": [
          50535,
          5349,
          544,
          5570,
          13,
          50573
        ]
      },
      {
        "avg_logprob": -0.2377532958984375,
        "compression_ratio": 1.6550522648083623,
        "end": 1945.56,
        "id": 744,
        "no_speech_prob": 0.0000475762972200755,
        "seek": 194022,
        "start": 1944.4,
        "temperature": 0,
        "text": " More notes.",
        "tokens": [
          50573,
          5048,
          5570,
          13,
          50631
        ]
      },
      {
        "avg_logprob": -0.2377532958984375,
        "compression_ratio": 1.6550522648083623,
        "end": 1946.68,
        "id": 745,
        "no_speech_prob": 0.0000475762972200755,
        "seek": 194022,
        "start": 1945.56,
        "temperature": 0,
        "text": " Then guess what?",
        "tokens": [
          50631,
          1396,
          2041,
          437,
          30,
          50687
        ]
      },
      {
        "avg_logprob": -0.2377532958984375,
        "compression_ratio": 1.6550522648083623,
        "end": 1949.72,
        "id": 746,
        "no_speech_prob": 0.0000475762972200755,
        "seek": 194022,
        "start": 1946.68,
        "temperature": 0,
        "text": " All I need to do is take this exact same code.",
        "tokens": [
          50687,
          1057,
          286,
          643,
          281,
          360,
          307,
          747,
          341,
          1900,
          912,
          3089,
          13,
          50839
        ]
      },
      {
        "avg_logprob": -0.2377532958984375,
        "compression_ratio": 1.6550522648083623,
        "end": 1953.76,
        "id": 747,
        "no_speech_prob": 0.0000475762972200755,
        "seek": 194022,
        "start": 1949.72,
        "temperature": 0,
        "text": " After prediction, instead of the target label,",
        "tokens": [
          50839,
          2381,
          17630,
          11,
          2602,
          295,
          264,
          3779,
          7645,
          11,
          51041
        ]
      },
      {
        "avg_logprob": -0.2377532958984375,
        "compression_ratio": 1.6550522648083623,
        "end": 1955.4,
        "id": 748,
        "no_speech_prob": 0.0000475762972200755,
        "seek": 194022,
        "start": 1953.76,
        "temperature": 0,
        "text": " let me just put this in another variable",
        "tokens": [
          51041,
          718,
          385,
          445,
          829,
          341,
          294,
          1071,
          7006,
          51123
        ]
      },
      {
        "avg_logprob": -0.2377532958984375,
        "compression_ratio": 1.6550522648083623,
        "end": 1958.2,
        "id": 749,
        "no_speech_prob": 0.0000475762972200755,
        "seek": 194022,
        "start": 1955.4,
        "temperature": 0,
        "text": " so it doesn't look so insane.",
        "tokens": [
          51123,
          370,
          309,
          1177,
          380,
          574,
          370,
          10838,
          13,
          51263
        ]
      },
      {
        "avg_logprob": -0.2377532958984375,
        "compression_ratio": 1.6550522648083623,
        "end": 1961,
        "id": 750,
        "no_speech_prob": 0.0000475762972200755,
        "seek": 194022,
        "start": 1958.2,
        "temperature": 0,
        "text": " Results index label, draw the label,",
        "tokens": [
          51263,
          5015,
          33361,
          8186,
          7645,
          11,
          2642,
          264,
          7645,
          11,
          51403
        ]
      },
      {
        "avg_logprob": -0.2377532958984375,
        "compression_ratio": 1.6550522648083623,
        "end": 1964.76,
        "id": 751,
        "no_speech_prob": 0.0000475762972200755,
        "seek": 194022,
        "start": 1961,
        "temperature": 0,
        "text": " then play the note associated with that label.",
        "tokens": [
          51403,
          550,
          862,
          264,
          3637,
          6615,
          365,
          300,
          7645,
          13,
          51591
        ]
      },
      {
        "avg_logprob": -0.2377532958984375,
        "compression_ratio": 1.6550522648083623,
        "end": 1966.4,
        "id": 752,
        "no_speech_prob": 0.0000475762972200755,
        "seek": 194022,
        "start": 1964.76,
        "temperature": 0,
        "text": " I think this project is done.",
        "tokens": [
          51591,
          286,
          519,
          341,
          1716,
          307,
          1096,
          13,
          51673
        ]
      },
      {
        "avg_logprob": -0.2377532958984375,
        "compression_ratio": 1.6550522648083623,
        "end": 1967.56,
        "id": 753,
        "no_speech_prob": 0.0000475762972200755,
        "seek": 194022,
        "start": 1966.4,
        "temperature": 0,
        "text": " Let's try it.",
        "tokens": [
          51673,
          961,
          311,
          853,
          309,
          13,
          51731
        ]
      },
      {
        "avg_logprob": -0.2377532958984375,
        "compression_ratio": 1.6550522648083623,
        "end": 1969.56,
        "id": 754,
        "no_speech_prob": 0.0000475762972200755,
        "seek": 194022,
        "start": 1967.56,
        "temperature": 0,
        "text": " I'm going to collect the data again.",
        "tokens": [
          51731,
          286,
          478,
          516,
          281,
          2500,
          264,
          1412,
          797,
          13,
          51831
        ]
      },
      {
        "avg_logprob": -0.4369511127471924,
        "compression_ratio": 1.2135922330097086,
        "end": 1971.1799999999998,
        "id": 755,
        "no_speech_prob": 0.0002269315009471029,
        "seek": 196956,
        "start": 1969.58,
        "temperature": 0,
        "text": " I'm really coming back and showing",
        "tokens": [
          50365,
          286,
          478,
          534,
          1348,
          646,
          293,
          4099,
          50445
        ]
      },
      {
        "avg_logprob": -0.4369511127471924,
        "compression_ratio": 1.2135922330097086,
        "end": 1972.26,
        "id": 756,
        "no_speech_prob": 0.0002269315009471029,
        "seek": 196956,
        "start": 1971.1799999999998,
        "temperature": 0,
        "text": " you how to save the data.",
        "tokens": [
          50445,
          291,
          577,
          281,
          3155,
          264,
          1412,
          13,
          50499
        ]
      },
      {
        "avg_logprob": -0.4369511127471924,
        "compression_ratio": 1.2135922330097086,
        "end": 1973.26,
        "id": 757,
        "no_speech_prob": 0.0002269315009471029,
        "seek": 196956,
        "start": 1972.26,
        "temperature": 0,
        "text": " Time to train the model.",
        "tokens": [
          50499,
          6161,
          281,
          3847,
          264,
          2316,
          13,
          50549
        ]
      },
      {
        "avg_logprob": -0.4369511127471924,
        "compression_ratio": 1.2135922330097086,
        "end": 1985.86,
        "id": 758,
        "no_speech_prob": 0.0002269315009471029,
        "seek": 196956,
        "start": 1983.4199999999998,
        "temperature": 0,
        "text": " Moment of truth.",
        "tokens": [
          51057,
          19093,
          295,
          3494,
          13,
          51179
        ]
      },
      {
        "avg_logprob": -0.4369511127471924,
        "compression_ratio": 1.2135922330097086,
        "end": 1987.7,
        "id": 759,
        "no_speech_prob": 0.0002269315009471029,
        "seek": 196956,
        "start": 1985.86,
        "temperature": 0,
        "text": " Time to do prediction.",
        "tokens": [
          51179,
          6161,
          281,
          360,
          17630,
          13,
          51271
        ]
      },
      {
        "avg_logprob": -0.2608431552318817,
        "compression_ratio": 1.687719298245614,
        "end": 2002.3799999999999,
        "id": 760,
        "no_speech_prob": 0.0020507120061665773,
        "seek": 199956,
        "start": 1999.78,
        "temperature": 0,
        "text": " I kind of want to do this as I just drag the mouse around.",
        "tokens": [
          50375,
          286,
          733,
          295,
          528,
          281,
          360,
          341,
          382,
          286,
          445,
          5286,
          264,
          9719,
          926,
          13,
          50505
        ]
      },
      {
        "avg_logprob": -0.2608431552318817,
        "compression_ratio": 1.687719298245614,
        "end": 2003.4199999999998,
        "id": 761,
        "no_speech_prob": 0.0020507120061665773,
        "seek": 199956,
        "start": 2002.3799999999999,
        "temperature": 0,
        "text": " Oh, and guess what?",
        "tokens": [
          50505,
          876,
          11,
          293,
          2041,
          437,
          30,
          50557
        ]
      },
      {
        "avg_logprob": -0.2608431552318817,
        "compression_ratio": 1.687719298245614,
        "end": 2005.8999999999999,
        "id": 762,
        "no_speech_prob": 0.0020507120061665773,
        "seek": 199956,
        "start": 2003.4199999999998,
        "temperature": 0,
        "text": " This would be such a good demonstration of a regression.",
        "tokens": [
          50557,
          639,
          576,
          312,
          1270,
          257,
          665,
          16520,
          295,
          257,
          24590,
          13,
          50681
        ]
      },
      {
        "avg_logprob": -0.2608431552318817,
        "compression_ratio": 1.687719298245614,
        "end": 2007.78,
        "id": 763,
        "no_speech_prob": 0.0020507120061665773,
        "seek": 199956,
        "start": 2005.8999999999999,
        "temperature": 0,
        "text": " So I should come, the next video I should do,",
        "tokens": [
          50681,
          407,
          286,
          820,
          808,
          11,
          264,
          958,
          960,
          286,
          820,
          360,
          11,
          50775
        ]
      },
      {
        "avg_logprob": -0.2608431552318817,
        "compression_ratio": 1.687719298245614,
        "end": 2009.94,
        "id": 764,
        "no_speech_prob": 0.0020507120061665773,
        "seek": 199956,
        "start": 2007.78,
        "temperature": 0,
        "text": " I should just come back and do this exact same thing,",
        "tokens": [
          50775,
          286,
          820,
          445,
          808,
          646,
          293,
          360,
          341,
          1900,
          912,
          551,
          11,
          50883
        ]
      },
      {
        "avg_logprob": -0.2608431552318817,
        "compression_ratio": 1.687719298245614,
        "end": 2010.86,
        "id": 765,
        "no_speech_prob": 0.0020507120061665773,
        "seek": 199956,
        "start": 2009.94,
        "temperature": 0,
        "text": " but with a regression.",
        "tokens": [
          50883,
          457,
          365,
          257,
          24590,
          13,
          50929
        ]
      },
      {
        "avg_logprob": -0.2608431552318817,
        "compression_ratio": 1.687719298245614,
        "end": 2011.74,
        "id": 766,
        "no_speech_prob": 0.0020507120061665773,
        "seek": 199956,
        "start": 2010.86,
        "temperature": 0,
        "text": " What would that be?",
        "tokens": [
          50929,
          708,
          576,
          300,
          312,
          30,
          50973
        ]
      },
      {
        "avg_logprob": -0.2608431552318817,
        "compression_ratio": 1.687719298245614,
        "end": 2014.74,
        "id": 767,
        "no_speech_prob": 0.0020507120061665773,
        "seek": 199956,
        "start": 2011.74,
        "temperature": 0,
        "text": " Instead of having categorical output, which",
        "tokens": [
          50973,
          7156,
          295,
          1419,
          19250,
          804,
          5598,
          11,
          597,
          51123
        ]
      },
      {
        "avg_logprob": -0.2608431552318817,
        "compression_ratio": 1.687719298245614,
        "end": 2017.4199999999998,
        "id": 768,
        "no_speech_prob": 0.0020507120061665773,
        "seek": 199956,
        "start": 2014.74,
        "temperature": 0,
        "text": " you could only have a C or D or an E,",
        "tokens": [
          51123,
          291,
          727,
          787,
          362,
          257,
          383,
          420,
          413,
          420,
          364,
          462,
          11,
          51257
        ]
      },
      {
        "avg_logprob": -0.2608431552318817,
        "compression_ratio": 1.687719298245614,
        "end": 2019.94,
        "id": 769,
        "no_speech_prob": 0.0020507120061665773,
        "seek": 199956,
        "start": 2017.4199999999998,
        "temperature": 0,
        "text": " a regression would have numeric output.",
        "tokens": [
          51257,
          257,
          24590,
          576,
          362,
          7866,
          299,
          5598,
          13,
          51383
        ]
      },
      {
        "avg_logprob": -0.2608431552318817,
        "compression_ratio": 1.687719298245614,
        "end": 2021.58,
        "id": 770,
        "no_speech_prob": 0.0020507120061665773,
        "seek": 199956,
        "start": 2019.94,
        "temperature": 0,
        "text": " You could think of it as a slider.",
        "tokens": [
          51383,
          509,
          727,
          519,
          295,
          309,
          382,
          257,
          26046,
          13,
          51465
        ]
      },
      {
        "avg_logprob": -0.2608431552318817,
        "compression_ratio": 1.687719298245614,
        "end": 2026.62,
        "id": 771,
        "no_speech_prob": 0.0020507120061665773,
        "seek": 199956,
        "start": 2021.58,
        "temperature": 0,
        "text": " So maybe if the frequency of C is around 262,",
        "tokens": [
          51465,
          407,
          1310,
          498,
          264,
          7893,
          295,
          383,
          307,
          926,
          7551,
          17,
          11,
          51717
        ]
      },
      {
        "avg_logprob": -0.2588978503123823,
        "compression_ratio": 1.71301775147929,
        "end": 2031.4799999999998,
        "id": 772,
        "no_speech_prob": 0.0010322262533009052,
        "seek": 202662,
        "start": 2026.62,
        "temperature": 0,
        "text": " and the frequency of D is around 330, maybe in between,",
        "tokens": [
          50364,
          293,
          264,
          7893,
          295,
          413,
          307,
          926,
          45374,
          11,
          1310,
          294,
          1296,
          11,
          50607
        ]
      },
      {
        "avg_logprob": -0.2588978503123823,
        "compression_ratio": 1.71301775147929,
        "end": 2032.84,
        "id": 773,
        "no_speech_prob": 0.0010322262533009052,
        "seek": 202662,
        "start": 2031.4799999999998,
        "temperature": 0,
        "text": " I'd play a note.",
        "tokens": [
          50607,
          286,
          1116,
          862,
          257,
          3637,
          13,
          50675
        ]
      },
      {
        "avg_logprob": -0.2588978503123823,
        "compression_ratio": 1.71301775147929,
        "end": 2036.1599999999999,
        "id": 774,
        "no_speech_prob": 0.0010322262533009052,
        "seek": 202662,
        "start": 2032.84,
        "temperature": 0,
        "text": " I'd play like C sharp that's in between C and D right over",
        "tokens": [
          50675,
          286,
          1116,
          862,
          411,
          383,
          8199,
          300,
          311,
          294,
          1296,
          383,
          293,
          413,
          558,
          670,
          50841
        ]
      },
      {
        "avg_logprob": -0.2588978503123823,
        "compression_ratio": 1.71301775147929,
        "end": 2037.04,
        "id": 775,
        "no_speech_prob": 0.0010322262533009052,
        "seek": 202662,
        "start": 2036.1599999999999,
        "temperature": 0,
        "text": " here.",
        "tokens": [
          50841,
          510,
          13,
          50885
        ]
      },
      {
        "avg_logprob": -0.2588978503123823,
        "compression_ratio": 1.71301775147929,
        "end": 2037.8799999999999,
        "id": 776,
        "no_speech_prob": 0.0010322262533009052,
        "seek": 202662,
        "start": 2037.04,
        "temperature": 0,
        "text": " That would be a regression.",
        "tokens": [
          50885,
          663,
          576,
          312,
          257,
          24590,
          13,
          50927
        ]
      },
      {
        "avg_logprob": -0.2588978503123823,
        "compression_ratio": 1.71301775147929,
        "end": 2038.4799999999998,
        "id": 777,
        "no_speech_prob": 0.0010322262533009052,
        "seek": 202662,
        "start": 2037.8799999999999,
        "temperature": 0,
        "text": " But I'll come back.",
        "tokens": [
          50927,
          583,
          286,
          603,
          808,
          646,
          13,
          50957
        ]
      },
      {
        "avg_logprob": -0.2588978503123823,
        "compression_ratio": 1.71301775147929,
        "end": 2040.4799999999998,
        "id": 778,
        "no_speech_prob": 0.0010322262533009052,
        "seek": 202662,
        "start": 2038.4799999999998,
        "temperature": 0,
        "text": " I'll explain all that and do that in a separate video",
        "tokens": [
          50957,
          286,
          603,
          2903,
          439,
          300,
          293,
          360,
          300,
          294,
          257,
          4994,
          960,
          51057
        ]
      },
      {
        "avg_logprob": -0.2588978503123823,
        "compression_ratio": 1.71301775147929,
        "end": 2041.12,
        "id": 779,
        "no_speech_prob": 0.0010322262533009052,
        "seek": 202662,
        "start": 2040.4799999999998,
        "temperature": 0,
        "text": " tutorial.",
        "tokens": [
          51057,
          7073,
          13,
          51089
        ]
      },
      {
        "avg_logprob": -0.2588978503123823,
        "compression_ratio": 1.71301775147929,
        "end": 2043.6,
        "id": 780,
        "no_speech_prob": 0.0010322262533009052,
        "seek": 202662,
        "start": 2041.12,
        "temperature": 0,
        "text": " So there's too many directions you could go in just",
        "tokens": [
          51089,
          407,
          456,
          311,
          886,
          867,
          11095,
          291,
          727,
          352,
          294,
          445,
          51213
        ]
      },
      {
        "avg_logprob": -0.2588978503123823,
        "compression_ratio": 1.71301775147929,
        "end": 2045.04,
        "id": 781,
        "no_speech_prob": 0.0010322262533009052,
        "seek": 202662,
        "start": 2043.6,
        "temperature": 0,
        "text": " from watching this.",
        "tokens": [
          51213,
          490,
          1976,
          341,
          13,
          51285
        ]
      },
      {
        "avg_logprob": -0.2588978503123823,
        "compression_ratio": 1.71301775147929,
        "end": 2046.7199999999998,
        "id": 782,
        "no_speech_prob": 0.0010322262533009052,
        "seek": 202662,
        "start": 2045.04,
        "temperature": 0,
        "text": " At a minimum, if you're watching this video",
        "tokens": [
          51285,
          1711,
          257,
          7285,
          11,
          498,
          291,
          434,
          1976,
          341,
          960,
          51369
        ]
      },
      {
        "avg_logprob": -0.2588978503123823,
        "compression_ratio": 1.71301775147929,
        "end": 2049.44,
        "id": 783,
        "no_speech_prob": 0.0010322262533009052,
        "seek": 202662,
        "start": 2046.7199999999998,
        "temperature": 0,
        "text": " and you want to try it, see if you can recreate this process.",
        "tokens": [
          51369,
          293,
          291,
          528,
          281,
          853,
          309,
          11,
          536,
          498,
          291,
          393,
          25833,
          341,
          1399,
          13,
          51505
        ]
      },
      {
        "avg_logprob": -0.2588978503123823,
        "compression_ratio": 1.71301775147929,
        "end": 2051.44,
        "id": 784,
        "no_speech_prob": 0.0010322262533009052,
        "seek": 202662,
        "start": 2049.44,
        "temperature": 0,
        "text": " You're going to find it quite frustrating to have",
        "tokens": [
          51505,
          509,
          434,
          516,
          281,
          915,
          309,
          1596,
          16522,
          281,
          362,
          51605
        ]
      },
      {
        "avg_logprob": -0.2588978503123823,
        "compression_ratio": 1.71301775147929,
        "end": 2053.04,
        "id": 785,
        "no_speech_prob": 0.0010322262533009052,
        "seek": 202662,
        "start": 2051.44,
        "temperature": 0,
        "text": " to collect the data over and over again.",
        "tokens": [
          51605,
          281,
          2500,
          264,
          1412,
          670,
          293,
          670,
          797,
          13,
          51685
        ]
      },
      {
        "avg_logprob": -0.2588978503123823,
        "compression_ratio": 1.71301775147929,
        "end": 2056.48,
        "id": 786,
        "no_speech_prob": 0.0010322262533009052,
        "seek": 202662,
        "start": 2053.04,
        "temperature": 0,
        "text": " So you might want to skip ahead if I have those videos ready",
        "tokens": [
          51685,
          407,
          291,
          1062,
          528,
          281,
          10023,
          2286,
          498,
          286,
          362,
          729,
          2145,
          1919,
          51857
        ]
      },
      {
        "avg_logprob": -0.2865960841276208,
        "compression_ratio": 1.5021097046413503,
        "end": 2058.94,
        "id": 787,
        "no_speech_prob": 0.00003480801751720719,
        "seek": 205648,
        "start": 2056.82,
        "temperature": 0,
        "text": " to see how to save the data you've collected.",
        "tokens": [
          50381,
          281,
          536,
          577,
          281,
          3155,
          264,
          1412,
          291,
          600,
          11087,
          13,
          50487
        ]
      },
      {
        "avg_logprob": -0.2865960841276208,
        "compression_ratio": 1.5021097046413503,
        "end": 2062.26,
        "id": 788,
        "no_speech_prob": 0.00003480801751720719,
        "seek": 205648,
        "start": 2058.94,
        "temperature": 0,
        "text": " But certainly doing this with more notes",
        "tokens": [
          50487,
          583,
          3297,
          884,
          341,
          365,
          544,
          5570,
          50653
        ]
      },
      {
        "avg_logprob": -0.2865960841276208,
        "compression_ratio": 1.5021097046413503,
        "end": 2064.7,
        "id": 789,
        "no_speech_prob": 0.00003480801751720719,
        "seek": 205648,
        "start": 2062.26,
        "temperature": 0,
        "text": " and thinking about the input in a very different way",
        "tokens": [
          50653,
          293,
          1953,
          466,
          264,
          4846,
          294,
          257,
          588,
          819,
          636,
          50775
        ]
      },
      {
        "avg_logprob": -0.2865960841276208,
        "compression_ratio": 1.5021097046413503,
        "end": 2067.78,
        "id": 790,
        "no_speech_prob": 0.00003480801751720719,
        "seek": 205648,
        "start": 2064.7,
        "temperature": 0,
        "text": " would be a good starting point for you to try.",
        "tokens": [
          50775,
          576,
          312,
          257,
          665,
          2891,
          935,
          337,
          291,
          281,
          853,
          13,
          50929
        ]
      },
      {
        "avg_logprob": -0.2865960841276208,
        "compression_ratio": 1.5021097046413503,
        "end": 2069.22,
        "id": 791,
        "no_speech_prob": 0.00003480801751720719,
        "seek": 205648,
        "start": 2067.78,
        "temperature": 0,
        "text": " So thanks so much for watching.",
        "tokens": [
          50929,
          407,
          3231,
          370,
          709,
          337,
          1976,
          13,
          51001
        ]
      },
      {
        "avg_logprob": -0.2865960841276208,
        "compression_ratio": 1.5021097046413503,
        "end": 2072.78,
        "id": 792,
        "no_speech_prob": 0.00003480801751720719,
        "seek": 205648,
        "start": 2069.22,
        "temperature": 0,
        "text": " Many more tutorials about the ML5 neural network",
        "tokens": [
          51001,
          5126,
          544,
          17616,
          466,
          264,
          21601,
          20,
          18161,
          3209,
          51179
        ]
      },
      {
        "avg_logprob": -0.2865960841276208,
        "compression_ratio": 1.5021097046413503,
        "end": 2073.82,
        "id": 793,
        "no_speech_prob": 0.00003480801751720719,
        "seek": 205648,
        "start": 2072.78,
        "temperature": 0,
        "text": " functionality to come.",
        "tokens": [
          51179,
          14980,
          281,
          808,
          13,
          51231
        ]
      },
      {
        "avg_logprob": -0.2865960841276208,
        "compression_ratio": 1.5021097046413503,
        "end": 2077.86,
        "id": 794,
        "no_speech_prob": 0.00003480801751720719,
        "seek": 205648,
        "start": 2073.82,
        "temperature": 0,
        "text": " And I'll see you in those where we train more models.",
        "tokens": [
          51231,
          400,
          286,
          603,
          536,
          291,
          294,
          729,
          689,
          321,
          3847,
          544,
          5245,
          13,
          51433
        ]
      },
      {
        "avg_logprob": -0.2865960841276208,
        "compression_ratio": 1.5021097046413503,
        "end": 2078.46,
        "id": 795,
        "no_speech_prob": 0.00003480801751720719,
        "seek": 205648,
        "start": 2077.86,
        "temperature": 0,
        "text": " Woof, woof.",
        "tokens": [
          51433,
          10468,
          69,
          11,
          21657,
          69,
          13,
          51463
        ]
      },
      {
        "avg_logprob": -0.6574872732162476,
        "compression_ratio": 0.38461538461538464,
        "end": 2080.2,
        "id": 796,
        "no_speech_prob": 0.8343117237091064,
        "seek": 207846,
        "start": 2078.46,
        "temperature": 0,
        "text": " Woof.",
        "tokens": [
          50373,
          10468,
          69,
          13,
          50451
        ]
      }
    ],
    "transcription": " Hello, and welcome to another beginner's guide to machine learning video tutorial with ml5.js. Very excited about this one. I'm typically excited about the video tutorials I make, but this one I'm particularly excited about, because I'm going to look at something that has recently arrived in the ml5.js library. So first of all, use version 0.4.2, or a more recent version perhaps, but that's the version I'll be using in this video. And I want to look at this functionality in the ml5 library called ml5 neural network. It is a function in ml5 that creates a empty, or blank, so to speak, neural network. Everything that I've showed you in this video series so far has involved loading a pre-trained model. So a neural network architecture that's already been trained with some data. And in this video, I want to look at making an empty, a blank slate, configuring a neural network, collecting data, training the model, and doing inference. And the context that I want to look at that is with real-time interactive data. So I'm going to come back and maybe use some more traditional data sets. There's a data set that's on the ml5 examples with the Titanic survival data set. I have the data set for my color classifier series. So I'll come back and show you some examples of those as well. But in this first video, I just want to do something very generic, which is create a blank neural network, use mouse clicks to train it, and then move the mouse around for it to make guesses or predictions. And that might sound like a weird thing to do. And hopefully, it'll start to make sense as I build the code and step through all the processes. I also want to highlight for you the Wekinator project, which is a free open source piece of software created by Rebecca Fribrich in 2009 for training machine learning models. And I would especially encourage you to watch Rebecca Fribrich's talk from the I-O conference in 2018, where she talks about creativity and inclusion in machine learning and goes through some demonstrations with Wekinator and processing and other pieces of software. So a lot of the work that I'm doing with ml5 is entirely based on recreations of many of the example demonstrations that Rebecca Fribrich made and has done research about for years and years with the Wekinator project. So in fact, the examples that I'm going to make in this video and the next one and the next follow-ups are direct ports, in a way, of some of the original Wekinator and processing examples. But I'm going to do it all in JavaScript in the browser with p5 and the ml5.js library. There's also a fairly lengthy history of creative artists training machine learning models in real time to control musical instruments, a performance, a visual art piece. And I would encourage you to check out some of these projects. Our guide for figuring out how to write the code is going to be the ml5 website. And there's a page on the ml5 website for the neural network function. But before I start diving into the code, let's take a minute to talk about what a neural network is. Now, by no means in this video am I going to do a comprehensive deep dive into what a neural network is and how to code one from scratch. I will refer you to many other wonderful resources where you could do that deep dive, starting with the 3Blue1Brown video, what is a neural network, and some of the subsequent ones. I have also a 10 to 15 part video series where I build a neural network from scratch in JavaScript based on a particular book called Make Your Own Neural Network that is in Python. I have other videos that are guides around machine learning concepts where I talk about different kinds of neural networks. So I will link to all of those in this video description. But here, I'm going to use the whiteboard over here just to give you a very zoomed out, high level overview of what I'm talking about. So a machine learning system, in the most basic sense, involves inputs and outputs. So let's say for a moment that the goal that I have is to train a machine learning model to use my body as the input. So maybe how I'm moving my arms and legs and head, that will be the input. And the output would be a musical instrument, a note that's being played. So I could somehow play different notes based on how I move my body. This is a scenario that's covered in great detail in Rebecca Feebrink's course, Machine Learning for Artists and Musicians. One way that I might boil this idea down into its very simplest version is think about a 2D canvas. And it's very convenient that I'm using P5, because that's the thing that exists in P5.js. And what I'm going to do is I'm going to say there is a mouse in that canvas. And the mouse is going to move around the canvas. And based on where it is, it will play a particular note. Now, of course, I could program this same idea with an if statement. But this is really what it means to work with machine learning. Instead of programming the rules explicitly into code, what I'm going to do is give the code a whole bunch of examples and have it learn those rules. So I want to demonstrate that process in a scenario where it's very obvious how it's working, so that then we can build on that into much more complex scenarios. The steps are collect data, two, train model, then three. I guess we can call this prediction. So that's also sometimes referred to as inference. That's really when we're deploying the model. We're making use of the model. Right here, this is my representation of the model. So in this case, if I want to start with a classification problem, and I will show you demonstrations of classification and regression, I'm going to have two inputs, input one and input two, often referred to as x's in a machine learning context. Those inputs are going to go in to this machine learning model. The output is going to be one of, let's say, three different categories. So I'm going to have three outputs, C, D, and E. So two inputs, and in this case, three outputs. My diagram looks a little bit weird, so I'm going to fix it up for a second. Now, all this time, I've just been putting the letters NL in here for machine learning, or maybe referring to this as a model, because in truth, other things, other kinds of algorithms, other types of ideas beyond a neural network could slot in here. But the ML5 generic blank machine learning model that you can train is a neural network one. So if I were to try to zoom into this for a moment, what I would actually see is something that looks something like this. This is my zoomed in diagram of really what's going on in here. A neural network is a network of neurons. Technically, this is a feed forward multilayer perceptron, because the inputs, which are represented right here, get fed through these connections, they're weighted connections, and get added up all together and arrive in this layer, which is known as the hidden layer. And they're connected to each other which is known as the hidden layer. And there can be multiple hidden layers and different kinds of hidden layers, but the data is summed and processed through a mathematical function called an activation function, and then fed out of the hidden layer and into the output layer. And the output layer, after all of the hidden outputs are summed and passed through an activation function, we get a set of numbers out. And those numbers might look like this, 0.2, 0.7, 0.1. Meaning a 20% chance of being category C, a 70% chance of being category D, or a 10% chance of being category E. So there's a lot more details of what's going on in here, and I certainly, once again, would refer you to the various things that I'll link in this video's description. The idea here is that a neural network is a machine learning model that can be trained. It can be shown a lot of examples of inputs with their correct corresponding outputs, and it can tune all of the weights of all these connections so that when it later gets new data, it can make appropriate predictions. This is everything that the ml5 library will take care of for you. And for us, we're going to really just be working with the inputs and the outputs, collecting our training data, training the model, and predicting outputs. Now that I've gotten through that explanation, I really want to just write some code and show you how this all works. Sorry to interrupt. It is me from around four days in the future. I did actually continue this. This was recorded during a live stream, and I did go all the way through and make this example. But I made some pretty significant errors in how I use the ml5 library. So I've come back to rerecord and try this again. I'm sure I'll make other mistakes and things will go wrong. But if you want to watch the original version, I'll link to that in the video's description. But I'm going to start over right now. Quickly want to point out that in addition to the p5 libraries, I've added a reference to the ml5 library version 0.4.2 in index.html. In my blank p5 sketch, I can add an ml5 neural network. So I need a new variable. I'm going to call that model. And I'm going to set that model equal to ml5.neuralnetwork. Whenever I create a neural network object, I need to configure it. I need to give it some information about what's going inside there. And the guide for doing this is the ml5 website. So here on the ml5 website, you can see this quick start, which has some sort of sample code, some documentation of the usage of the neural network function, and a bunch of different ways of initializing a neural network. And all of these involve a variable called options. The idea is that I'm creating an object that's going to store the properties of the neural network. And then when I call ml5.neuralnetwork, I pass that object in. So for example, looking here at my diagram, I can see there are two inputs and three outputs. That's something that I could configure in the options. Inputs 2, outputs 3. At a minimum, this is all you need to configure an ml5 neural network. How many inputs? How many outputs? If I scroll through the ml5 documentation page, you'll see there are a variety of other ways that I could configure a neural network. For example, I can actually give it a data file. So ml5 has functionality built into it that can take a CSV, or comma separated value file, or a JSON data file, and configure inputs and outputs based on what's in that file. So I need to come back to that and cover that in a separate video. But actually, the way that I want to do it here is actually this particular way. Instead of specifying the number of inputs and the number of outputs, it's much more convenient for me to name them. So here are the inputs, an x and the y. And here are the outputs, a label. Now, this is not something that the actual mechanics of a neural network uses. Inputs don't have names. Outputs don't have names. These are just numbers flowing through this feedforward network. But for us, from a zoomed out view, we can maintain the neural network and use it more easily by naming things. Adjusting that in the code, I'll have an x and a y. These are my inputs. There's two, and they have names, x and y. The really confusing thing here is what to do about the outputs. So while technically speaking, the way I diagram this is correct, and there are three output neurons, each scoring a probability for all three categories. From the zoomed out view, we can think of it as the neural network ending up with one singular result. What is the label it's classified the input data in? So ML5 is going to handle the number of categories and how to score all those things for you. So if we're naming stuff, I can actually just right here say label. And as I start to create the training data, I'm going to come back to this and explain where that number 3 comes back in. There's one more property to the options that's very important for me to specify, and that is the task that I want the neural network to perform. And in this case, the task is classification. The other task that I could have specified is a regression. And I'll come back and do other examples that use a neural network to perform a regression. We'll see what that is and how that works in future videos. In this case, though, it's a classification because I want the neural network to classify the input into one of three discrete categories. So now we are ready for the first step, collect data. And this should really say collect training data. Collecting training data means I need to have a set of inputs and their correct corresponding output. And in this case, I want to collect that data through user interaction. And I'll do that with mouse clicks. So I'm going to write a function called mousePressed. And I'm actually going to get rid of the draw loop. Just to get started, every time I click the mouse, let's draw a circle on the screen. MouseX, mouseY with a radius of 24. And let's also put a letter in the center of the circle. So now as I click, I'm collecting data points. I'm collecting x and y's that go with the category C. But I also want to collect x and y's that go with different categories. So let me do that through a key press. I'm going to create a variable called targetLabel. And I'm just give that a default value of C. Then I'm going to add keyPressed. And I'll just set targetLabel equal to the key that I press. Then I'll draw the target label instead. So here's a bunch of C's. Now I'm going to press D. Here's a bunch of D's. It's lowercase. Let me add to uppercase. Let's make sure this works. A bunch of C's, some D's, and E. Now, of course, I could do other. I could do any letter right now. So I probably would want to add some kind of error checking or determine what I want to let be the actual target labels. But for now, I'm going to just let it be a free for all and just restrict myself to C, D, and E. I didn't actually collect the data, though. I'm just showing you a very crude user interface for indicating where I've clicked and what letter I've pressed. So let me create a variable called trainingData. I'm going to make that an array. Then whenever I click the mouse, I'm going to say my inputs are. Now, because I named the inputs when I configured the neural network, I can create an object with an x and a y and also another one with a label. You'll see. x is mouseX, y is mouseY. And then I'm going to make one called outputs. These are the outputs, but this is called a target. That's a word I can use here because this is the target output that I want the neural network to learn given these inputs. So I'm going to say target equals label, and the label is the target label. And actually, I don't need this training data array. I was thinking I wanted to use that so I could store all of the data myself in an array. And that could be very useful in a lot of contexts. Actually, all that I need to do here is just say model, add data, inputs, target. So this is a function in the ML5 neural network class where the model can accept training data as pairs of inputs and target. And I need to make sure that the inputs and the target match up with how I configure the neural network. And they do because I have an x and a y and a label. And now I have an x and a y and a label here. Now, rightfully so, you might be asking yourself, what happened to the fact that we were restricting ourselves to three possible categorical outputs? And this is where a higher level library like ML5 comes in. It's just saying, I know you're going to do classification. I know I'm going to give you a label. I know you're going to give me some training data. So just give me all the training data. I will count how many possible outputs there are after you finish giving me the training data. So as long as I give it a bunch of examples with a C, a bunch of examples with a D, and a bunch of examples with an E, it will configure itself to work with a limit of three possible labels as the output. Let me quickly test to see if I get any errors. C, D, E. No, seems to be working. Good. I am ready for the next step, training the model. This is a really easy one for us because the ML5 neural network class has a function called train. So I can just call that train function. Certainly, it would make sense for me to build some kind of user interface here. But I'm just going to keep going with my key pressed method. And I'm going to check and say, if the key pressed is T, then call model.train. When I train the model, I can also give it some options that set various properties of the training process itself. So I'm going to create another options object. Information on what those options are is on the ML5 documentation page. I'm going to just use one option. I'm going to set something called an epoch. So I'm going to set the number of epochs to 100. So what is an epoch? If I look at my training data, I have 30 data points. And I'm going to feed all of those things into the neural network. I'm going to say, hey, neural network, here's an xy that goes with a c. Here's an xy that goes with a c. Now, one thing that's important that ML5 does for you behind the scenes is it shuffles all those into random order. Because the neural network's not going to learn so effectively if I send in all the c's and all the d's and then all the e's. I want to send them in random order. Sending in all 30 of those is one epoch. Typically, that's not enough for the neural network to learn the optimal configuration of weights. So you want to send it in again and again and again. So if I have 30 data points and I train for 100 epochs, that's sending stuff through the neural network 3,000 times. Now, in truth, there's more to it than this. There's something called a batch size, because I might consider the data in smaller batches out of those 30. And that can affect how I adjust the weights. But we don't need to worry about that. Setting the number of epochs is a good starting point for us to start thinking about the process of training a neural network. So I can pass to the train function the options. And then the train function also has two callbacks. One is optional, but I'm going to use them both. There's a while training callback and then a finished training callback. The idea is that there's a number of events happening while you're training the neural network. The while training callback is executed every epoch. So that'll get executed 100 times. And the finished training callback is executed when the whole thing is finished. So let me write those functions. In finished training, I'm just going to add a console log. While training actually receives information about the training process. And it receives two things, an epoch and a loss. These callbacks really work as debugging tools for me to look at how the training process is going. Oh, that epoch finished. What was the loss? And I need to come back and talk about what loss is. But I can really look at what's happening while it's training and then know that the training has finished. ML5, however, has built into it a visualization functionality that's part of TensorFlow.js itself, particularly this library called tf.vis. And I can enable that by adding one more option to my neural network configuration. And that is debug true. If I add debug true, I'm going to get much better tools than what I've got here with my own callbacks. There's one more thing that I've missed here. And that has to do with normalizing the data. What does our trading data look like? Remember, I've got this P5 canvas. Maybe it's 400 by 400. Any given input is a mouse click into that canvas, like here. And so this might be the mouse location 100 comma 100. So that would mean the literal number 100 is being fed into the neural network. But neural networks are generally tuned to work with data that's all standardized within a particular range. And there could be a variety of ways you might want to use one range versus another. But in many cases, you always want to squash your input data into a range between 0 and 1. And that process is called normalization. So that would be really easy for me to do myself. Because if I know the width is 400, I could just say 100 divided by 400 is 0.25. So I could apply this normalization math myself in the code. But ml5 has a function built into it that you can call right before you train the data that will look at the minimum and maximums of all of your input data and normalize it. So coming over here, I can call that function right before I train the model by saying model.normalizeData. And now I think I am ready to actually train the model for the very first time and complete step two. Let's give it a try. Let's add a console log to know that the training process is starting. Let's collect a lot of data. Now, I'm clustering all my C's and D's and E's together. Because I want to create a scenario that should be easy for the neural network to learn. Again, I don't need a neural network to figure out that there's C's in the top left and D's in the top right and E's on the bottom. But if the neural network can learn this scenario, more complex and interesting ones, it could possibly learn as well. So again, if you remember, my exciting interface was to press the T button. So I'm now going to press it. And this is the debug view that pops out. This comes up because I put debug as true. And what you're seeing, you saw the epochs being console logged here. You see that it says finish training. But this is showing me a graph of the loss. The x-axis is the epoch. And the y-axis is the value of the loss. So what is loss? If this particular data point that I'm sending into the neural network is paired with the target of C, when it gets sent in, the x gets sent in 0.25. I should make the y something different. Like, let's say the y is 200. The y gets sent in as 0.5. The neural network is going to guess C, D, or E. Then it has to decide, did it get it right or did it get it wrong? Was there an error? So if it happened to guess C, it's going to have gotten it right. You can think of the error as 0. If it's gotten it wrong, if it guessed D, then there is an error. Now, what the value of that error is actually has to do with the scoring that it's doing based on its confidence that it's one label or another. Maybe it was like 99% sure it was a D. It's going to have a big error then. But if it was only like 60% sure it was a D and 40% sure it was a C, then that error is going to be smaller. But that error, another word for that error, is loss. So as it sends all of the data over a given epoch through the neural network, it's going to summarize all of the errors into a loss value. So as the neural network trains the model with the training data over and over again, epoch by epoch, that loss should be going down. It's getting better and making more correct guesses over time. Based on what the graph is doing here, this indicates to me a couple of things. One is it's learning kind of slowly. So one possibility could be just give it more epochs. So maybe what I actually want to do is go back into the code and give it 200 epochs instead of 100. Truth of the matter is I have a very, very, very small data set here. So with a little bit of data, I need a lot more epochs, and it kind of makes it feel like it's more data. Another way that I could tackle this issue is by adding another property to the options object when I configure the neural network. And that property is something called a learning rate. The learning rate refers to how much these dials should turn based on the errors that it's seeing as the neural network is looking at the training data. So it got an error. Should I turn the dial a lot, or should I turn it just a little bit? If I turn it a lot, I might get closer to the correct result. But I could also overshoot that correct result. So this kind of hyperparameter tuning is a fancy word for saying, well, I want to try this learning rate, this number of epochs. These are the kinds of things that you could experiment with by training your model over and over again with different properties. But for me right now, I'm going to leave the default learning rate and just experiment with the number of epochs. And maybe in some future videos, I'll come back and look at some of the other parameters and what might happen as I tune them. Let's try one more time. Collecting data. And training the model. Ooh, wacky. So this is really good. I want to see that loss go all the way down. We can see at the very end here, it gets down to 0.096314. And you could also see that it's starting to level out. That indicates to me that if I'd given it more epochs, maybe I would squeeze out a tiny bit more accuracy. But this is pretty good. And that, my friends, is the end of step two. Guess what? Only one step left. And this one is prediction. Meaning the idea now that I've trained the model is I want to give it new inputs. I'm not giving you a target. I'm not telling you what the answer is. Neural network, you've learned. You've thought about this a lot. I've taught you all I can teach you. Now make some guesses for me. To implement this, I think something useful could be for me to create a variable that's like the state of the program. And at the beginning of the state, I would say state is program. And at the beginning of the state would be collection. And when the state is collection, that's where I want to set the target label and add the data to the model. When I press the T key, then the state is training. And then when I'm finished training, I could say the state is prediction. And ultimately, I think I just want to draw those circles during the collection process. If the state is prediction, then I want to ask the model to classify the inputs. The idea being that there are no targets. The model is trained. Here are some inputs. Classify them for me. So where do I get the results back? I need a callback. I can define a function called gotResults. Just like all the other ml5 stuff that I've looked at in previous videos, there can be an error or there could actually be results. If there's an error, don't do anything. Otherwise, let's take a look at the results. Let's try this again. I can't believe I have to collect the data again. Wouldn't it be nice if I could save the data so that I don't have to collect it again if I've made changes to my code? In fact, it is. And I will come back and do a separate video all about how to save the data. And in fact, I could also save the trained model. So I could load that trained model into another sketch. Or all sorts of possibilities. And I will also come back and look at saving data, and saving the model, and reloading those things. But for right now, I'm just going to, because I have the time to do it and I can speed through this when you're watching it, I'm just going to constantly recollect the data over and over again. The model is trained. And if I did things correctly, it'll now show me some results when I click into the canvas. I'm going to click over by the C's. This is good. I got an array back, that results array, and has three objects in it. What are those objects? The first one is the label C with a confidence score of 88.5%. That's good. That's what I should have gotten. The second one is D, a confidence score of 7%. Third one, E, confidence score of, I guess, around 5%. This is exactly what I expect. These confidence scores are what the neural network is really producing behind the scenes. But the ml5 library has taken those confidence scores, associated with given labels, and then sorted those labels in order of confidence. So I will always have in result index 0.label the label it thinks it should be. So what I can do is grab this drawing code. And I can put it right down here. Maybe I'll change it to blue with some alpha. And instead of target label, I'm looking at results index 0.label. Now, truth is, I shouldn't be using mouseX and mouseY here. I should be actually saving those inputs, maybe in a global variable or passing them. But I think the prediction is going to happen fast enough that I'm not really going to be able to move my mouse. So I think it'll work out OK. Let's give this a try. Oh, I got to collect all the data again. And train the model. And now I should be able to click here and see a C. I did. And a D. I did. And an E. Let's move along here and see, when does it change to C? It changes to C there. That's like a decision threshold-like thingy. You know what would be interesting to do? We could draw a map of what all the decisions are across all the pixels. That's a project you should do. And click over here. I should get a D. C. What's over here? A D, a D, a D, an E. Oh, this is fascinating. I love that this works. So guess what? This is actually done. But the whole point of what I wanted to do here was to have it play sound. Because I want this to be the beginning of an idea that I could maybe play musical notes by moving my hand around. Imagine, again, the inputs being instead of the xy of mouse clicks, the xy of some type of hand tracking. Or I could actually have more than just two inputs. Because I could take the xy of this, and the xy of this, and the xy of this. Or whatever kind of other data. Maybe you've hooked up a whole bunch of sensors. And you've got a bunch of different force sensors and an Arduino. And those could be the inputs to your neural network. So many possibilities. But I'm not going to explore all those possibilities right now, at least. But I do want to show you the output of playing a note. I made a video tutorial that you could go back and watch, if you want, about how to use a sound envelope with a sound oscillator in P5 to generate a tone. And so I'm just going to, for now, just grab this code, all of this, the oscillator and the envelope. I'm going to paste all that in setup here. And this, by the way, has changed to the full word envelope, since I last made that tutorial. And now, whenever I click the mouse, I should be able to say, envelope play. So if I do this, when I click, you hear this note play. But I want it to play C, D, or E. And honestly, I could make a lot of notes right now, since I can have more than just three categories. But let's just stick with C, D, and E. What I need to play a particular note is the frequency of that note. And I can find this on this Wikipedia page about frequencies and piano notes. So I'll start with C4, D4, and E4. I'll make an object that's a lookup table for those notes. So I have the C, D, and E all matched with their frequency. I should make sure that the envelope and the wave are global variables, because now, when I play the note, I could set the frequency to notes index target label. This will look up the numeric frequency associated with that label and set the sound oscillator to that frequency. C, C, C, D, D, D, E, E, E. Now, if I press F, it's not going to change, because I didn't put F in that lookup table. But you could add more notes. Add more notes. More notes. Then guess what? All I need to do is take this exact same code. After prediction, instead of the target label, let me just put this in another variable so it doesn't look so insane. Results index label, draw the label, then play the note associated with that label. I think this project is done. Let's try it. I'm going to collect the data again. I'm really coming back and showing you how to save the data. Time to train the model. Moment of truth. Time to do prediction. I kind of want to do this as I just drag the mouse around. Oh, and guess what? This would be such a good demonstration of a regression. So I should come, the next video I should do, I should just come back and do this exact same thing, but with a regression. What would that be? Instead of having categorical output, which you could only have a C or D or an E, a regression would have numeric output. You could think of it as a slider. So maybe if the frequency of C is around 262, and the frequency of D is around 330, maybe in between, I'd play a note. I'd play like C sharp that's in between C and D right over here. That would be a regression. But I'll come back. I'll explain all that and do that in a separate video tutorial. So there's too many directions you could go in just from watching this. At a minimum, if you're watching this video and you want to try it, see if you can recreate this process. You're going to find it quite frustrating to have to collect the data over and over again. So you might want to skip ahead if I have those videos ready to see how to save the data you've collected. But certainly doing this with more notes and thinking about the input in a very different way would be a good starting point for you to try. So thanks so much for watching. Many more tutorials about the ML5 neural network functionality to come. And I'll see you in those where we train more models. Woof, woof. Woof.",
    "translation": null
  },
  "error": null,
  "status": "succeeded",
  "created_at": "2023-09-26T21:03:33.670921Z",
  "started_at": "2023-09-26T21:14:49.538865Z",
  "completed_at": "2023-09-26T21:23:04.029953Z",
  "webhook": "https://83ceaa0b612c.ngrok.app/?video_id=8HEgeAbYphA",
  "webhook_events_filter": [
    "completed"
  ],
  "metrics": {
    "predict_time": 494.491088
  },
  "urls": {
    "cancel": "https://api.replicate.com/v1/predictions/gmoiynzb7wcu4kb67uwgydvfe4/cancel",
    "get": "https://api.replicate.com/v1/predictions/gmoiynzb7wcu4kb67uwgydvfe4"
  }
}