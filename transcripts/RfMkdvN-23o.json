{
  "id": "6i3vdfbbg3zohj2mv2svdxzkbu",
  "version": "91ee9c0c3df30478510ff8c8a3a545add1ad0259ad3a9f78fba57fbc05ee64f7",
  "input": {
    "audio": "https://upcdn.io/FW25b4F/raw/coding-train/RfMkdvN-23o.m4a"
  },
  "logs": "Transcribe with large-v2 model\nDetected language: English\n  0%|          | 0/103486 [00:00<?, ?frames/s]\n  3%|▎         | 2800/103486 [00:05<03:34, 468.63frames/s]\n  5%|▌         | 5500/103486 [00:13<04:06, 398.16frames/s]\n  8%|▊         | 8100/103486 [00:20<04:11, 380.02frames/s]\n 11%|█         | 11000/103486 [00:28<04:10, 369.82frames/s]\n 13%|█▎        | 13900/103486 [00:36<04:03, 367.52frames/s]\n 16%|█▌        | 16800/103486 [00:47<04:27, 324.52frames/s]\n 19%|█▊        | 19400/103486 [00:56<04:21, 320.98frames/s]\n 21%|██▏       | 22200/103486 [01:03<03:58, 340.98frames/s]\n 24%|██▍       | 24600/103486 [01:10<03:49, 343.89frames/s]\n 26%|██▋       | 27300/103486 [01:16<03:30, 361.77frames/s]\n 29%|██▉       | 30000/103486 [01:24<03:29, 351.51frames/s]\n 32%|███▏      | 32800/103486 [01:33<03:25, 343.34frames/s]\n 34%|███▍      | 35100/103486 [01:40<03:25, 333.41frames/s]\n 37%|███▋      | 38000/103486 [01:48<03:09, 345.17frames/s]\n 39%|███▉      | 40600/103486 [01:55<02:56, 356.33frames/s]\n 42%|████▏     | 43200/103486 [02:03<02:54, 345.18frames/s]\n 44%|████▍     | 45900/103486 [02:09<02:37, 366.67frames/s]\n 47%|████▋     | 48800/103486 [02:17<02:28, 367.57frames/s]\n 50%|████▉     | 51700/103486 [02:25<02:21, 364.90frames/s]\n 52%|█████▏    | 54300/103486 [02:33<02:18, 354.22frames/s]\n 55%|█████▌    | 57100/103486 [02:40<02:07, 364.61frames/s]\n 58%|█████▊    | 59900/103486 [02:48<02:01, 359.22frames/s]\n 60%|██████    | 62500/103486 [02:55<01:54, 359.15frames/s]\n 63%|██████▎   | 65400/103486 [03:03<01:45, 361.19frames/s]\n 66%|██████▌   | 68200/103486 [03:10<01:34, 372.58frames/s]\n 69%|██████▊   | 71000/103486 [03:17<01:25, 379.24frames/s]\n 71%|███████▏  | 73900/103486 [03:27<01:22, 358.56frames/s]\n 74%|███████▍  | 76600/103486 [03:31<01:06, 403.85frames/s]\n 77%|███████▋  | 79300/103486 [03:37<00:57, 422.69frames/s]\n 79%|███████▉  | 82200/103486 [03:44<00:51, 416.82frames/s]\n 82%|████████▏ | 84800/103486 [03:51<00:45, 410.12frames/s]\n 85%|████████▍ | 87600/103486 [03:58<00:39, 402.39frames/s]\n 87%|████████▋ | 90300/103486 [04:06<00:34, 386.18frames/s]\n 90%|████████▉ | 93100/103486 [04:14<00:28, 368.78frames/s]\n 93%|█████████▎| 96000/103486 [04:24<00:22, 333.27frames/s]\n 95%|█████████▌| 98500/103486 [04:33<00:15, 324.43frames/s]\n 98%|█████████▊| 101200/103486 [04:42<00:07, 317.35frames/s]\n 99%|█████████▉| 102500/103486 [04:46<00:03, 310.45frames/s]\n100%|██████████| 103486/103486 [04:49<00:00, 315.03frames/s]\n100%|██████████| 103486/103486 [04:49<00:00, 357.26frames/s]\n",
  "output": {
    "detected_language": "english",
    "segments": [
      {
        "avg_logprob": -0.2557320227989784,
        "compression_ratio": 1.8732394366197183,
        "end": 6,
        "id": 0,
        "no_speech_prob": 0.0067960359156131744,
        "seek": 0,
        "start": 0,
        "temperature": 0,
        "text": " Hello and welcome to the second video in module one of working with data and APIs in JavaScript.",
        "tokens": [
          50364,
          2425,
          293,
          2928,
          281,
          264,
          1150,
          960,
          294,
          10088,
          472,
          295,
          1364,
          365,
          1412,
          293,
          21445,
          294,
          15778,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.2557320227989784,
        "compression_ratio": 1.8732394366197183,
        "end": 10,
        "id": 1,
        "no_speech_prob": 0.0067960359156131744,
        "seek": 0,
        "start": 6,
        "temperature": 0,
        "text": " Now we're going to do some real stuff in this video. We did real stuff in the previous video,",
        "tokens": [
          50664,
          823,
          321,
          434,
          516,
          281,
          360,
          512,
          957,
          1507,
          294,
          341,
          960,
          13,
          492,
          630,
          957,
          1507,
          294,
          264,
          3894,
          960,
          11,
          50864
        ]
      },
      {
        "avg_logprob": -0.2557320227989784,
        "compression_ratio": 1.8732394366197183,
        "end": 15,
        "id": 2,
        "no_speech_prob": 0.0067960359156131744,
        "seek": 0,
        "start": 10,
        "temperature": 0,
        "text": " but the previous video was just about practicing with the Fetch API and getting some image files.",
        "tokens": [
          50864,
          457,
          264,
          3894,
          960,
          390,
          445,
          466,
          11350,
          365,
          264,
          479,
          7858,
          9362,
          293,
          1242,
          512,
          3256,
          7098,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.2557320227989784,
        "compression_ratio": 1.8732394366197183,
        "end": 18,
        "id": 3,
        "no_speech_prob": 0.0067960359156131744,
        "seek": 0,
        "start": 15,
        "temperature": 0,
        "text": " We weren't really working with data, we weren't doing anything with that data yet.",
        "tokens": [
          51114,
          492,
          4999,
          380,
          534,
          1364,
          365,
          1412,
          11,
          321,
          4999,
          380,
          884,
          1340,
          365,
          300,
          1412,
          1939,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.2557320227989784,
        "compression_ratio": 1.8732394366197183,
        "end": 22,
        "id": 4,
        "no_speech_prob": 0.0067960359156131744,
        "seek": 0,
        "start": 18,
        "temperature": 0,
        "text": " In this video, I want to take a look at this idea of tabular data.",
        "tokens": [
          51264,
          682,
          341,
          960,
          11,
          286,
          528,
          281,
          747,
          257,
          574,
          412,
          341,
          1558,
          295,
          4421,
          1040,
          1412,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.2557320227989784,
        "compression_ratio": 1.8732394366197183,
        "end": 28,
        "id": 5,
        "no_speech_prob": 0.0067960359156131744,
        "seek": 0,
        "start": 22,
        "temperature": 0,
        "text": " There are a lot of different file formats for storing data in a table format in tabular data.",
        "tokens": [
          51464,
          821,
          366,
          257,
          688,
          295,
          819,
          3991,
          25879,
          337,
          26085,
          1412,
          294,
          257,
          3199,
          7877,
          294,
          4421,
          1040,
          1412,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.23667171597480774,
        "compression_ratio": 1.7737226277372262,
        "end": 32,
        "id": 6,
        "no_speech_prob": 0.01115768775343895,
        "seek": 2800,
        "start": 28,
        "temperature": 0,
        "text": " The one that I want to look at in this video, and probably the most, I would think it's the most common one,",
        "tokens": [
          50364,
          440,
          472,
          300,
          286,
          528,
          281,
          574,
          412,
          294,
          341,
          960,
          11,
          293,
          1391,
          264,
          881,
          11,
          286,
          576,
          519,
          309,
          311,
          264,
          881,
          2689,
          472,
          11,
          50564
        ]
      },
      {
        "avg_logprob": -0.23667171597480774,
        "compression_ratio": 1.7737226277372262,
        "end": 35,
        "id": 7,
        "no_speech_prob": 0.01115768775343895,
        "seek": 2800,
        "start": 32,
        "temperature": 0,
        "text": " is CSV or comma separated value.",
        "tokens": [
          50564,
          307,
          48814,
          420,
          22117,
          12005,
          2158,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.23667171597480774,
        "compression_ratio": 1.7737226277372262,
        "end": 40,
        "id": 8,
        "no_speech_prob": 0.01115768775343895,
        "seek": 2800,
        "start": 35,
        "temperature": 0,
        "text": " Meaning the data, the data in the table is literally separated by commas.",
        "tokens": [
          50714,
          19948,
          264,
          1412,
          11,
          264,
          1412,
          294,
          264,
          3199,
          307,
          3736,
          12005,
          538,
          800,
          296,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.23667171597480774,
        "compression_ratio": 1.7737226277372262,
        "end": 46,
        "id": 9,
        "no_speech_prob": 0.01115768775343895,
        "seek": 2800,
        "start": 40,
        "temperature": 0,
        "text": " The first line of text, after all, this file, this CSV file is ultimately just a plain text file,",
        "tokens": [
          50964,
          440,
          700,
          1622,
          295,
          2487,
          11,
          934,
          439,
          11,
          341,
          3991,
          11,
          341,
          48814,
          3991,
          307,
          6284,
          445,
          257,
          11121,
          2487,
          3991,
          11,
          51264
        ]
      },
      {
        "avg_logprob": -0.23667171597480774,
        "compression_ratio": 1.7737226277372262,
        "end": 48,
        "id": 10,
        "no_speech_prob": 0.01115768775343895,
        "seek": 2800,
        "start": 46,
        "temperature": 0,
        "text": " might function as something like a header row.",
        "tokens": [
          51264,
          1062,
          2445,
          382,
          746,
          411,
          257,
          23117,
          5386,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.23667171597480774,
        "compression_ratio": 1.7737226277372262,
        "end": 51,
        "id": 11,
        "no_speech_prob": 0.01115768775343895,
        "seek": 2800,
        "start": 48,
        "temperature": 0,
        "text": " So it would have the names of the fields of data you're going to have.",
        "tokens": [
          51364,
          407,
          309,
          576,
          362,
          264,
          5288,
          295,
          264,
          7909,
          295,
          1412,
          291,
          434,
          516,
          281,
          362,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.23667171597480774,
        "compression_ratio": 1.7737226277372262,
        "end": 55,
        "id": 12,
        "no_speech_prob": 0.01115768775343895,
        "seek": 2800,
        "start": 51,
        "temperature": 0,
        "text": " So it might have something like item, comma, cuteness.",
        "tokens": [
          51514,
          407,
          309,
          1062,
          362,
          746,
          411,
          3174,
          11,
          22117,
          11,
          1723,
          15264,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.17420601844787598,
        "compression_ratio": 1.7615384615384615,
        "end": 59,
        "id": 13,
        "no_speech_prob": 0.029309900477528572,
        "seek": 5500,
        "start": 55,
        "temperature": 0,
        "text": " So you're going to have a table of things and a cuteness score.",
        "tokens": [
          50364,
          407,
          291,
          434,
          516,
          281,
          362,
          257,
          3199,
          295,
          721,
          293,
          257,
          1723,
          15264,
          6175,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.17420601844787598,
        "compression_ratio": 1.7615384615384615,
        "end": 64,
        "id": 14,
        "no_speech_prob": 0.029309900477528572,
        "seek": 5500,
        "start": 59,
        "temperature": 0,
        "text": " So all the rest of the lines would have the actual items and their cuteness scores.",
        "tokens": [
          50564,
          407,
          439,
          264,
          1472,
          295,
          264,
          3876,
          576,
          362,
          264,
          3539,
          4754,
          293,
          641,
          1723,
          15264,
          13444,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.17420601844787598,
        "compression_ratio": 1.7615384615384615,
        "end": 68,
        "id": 15,
        "no_speech_prob": 0.029309900477528572,
        "seek": 5500,
        "start": 64,
        "temperature": 0,
        "text": " So you could have puppy, comma, 10.",
        "tokens": [
          50814,
          407,
          291,
          727,
          362,
          18196,
          11,
          22117,
          11,
          1266,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.17420601844787598,
        "compression_ratio": 1.7615384615384615,
        "end": 70,
        "id": 16,
        "no_speech_prob": 0.029309900477528572,
        "seek": 5500,
        "start": 68,
        "temperature": 0,
        "text": " Kitten, comma, 10.",
        "tokens": [
          51014,
          591,
          2987,
          11,
          22117,
          11,
          1266,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.17420601844787598,
        "compression_ratio": 1.7615384615384615,
        "end": 73,
        "id": 17,
        "no_speech_prob": 0.029309900477528572,
        "seek": 5500,
        "start": 70,
        "temperature": 0,
        "text": " Because we live in a world where everything has a cuteness score of 10.",
        "tokens": [
          51114,
          1436,
          321,
          1621,
          294,
          257,
          1002,
          689,
          1203,
          575,
          257,
          1723,
          15264,
          6175,
          295,
          1266,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.17420601844787598,
        "compression_ratio": 1.7615384615384615,
        "end": 74,
        "id": 18,
        "no_speech_prob": 0.029309900477528572,
        "seek": 5500,
        "start": 73,
        "temperature": 0,
        "text": " But I want to do something with real data.",
        "tokens": [
          51264,
          583,
          286,
          528,
          281,
          360,
          746,
          365,
          957,
          1412,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.17420601844787598,
        "compression_ratio": 1.7615384615384615,
        "end": 78,
        "id": 19,
        "no_speech_prob": 0.029309900477528572,
        "seek": 5500,
        "start": 74,
        "temperature": 0,
        "text": " Data that's out there in the world that I can grab with the Fetch function,",
        "tokens": [
          51314,
          11888,
          300,
          311,
          484,
          456,
          294,
          264,
          1002,
          300,
          286,
          393,
          4444,
          365,
          264,
          479,
          7858,
          2445,
          11,
          51514
        ]
      },
      {
        "avg_logprob": -0.17420601844787598,
        "compression_ratio": 1.7615384615384615,
        "end": 81,
        "id": 20,
        "no_speech_prob": 0.029309900477528572,
        "seek": 5500,
        "start": 78,
        "temperature": 0,
        "text": " load onto my webpage, and do something with, for example, graph.",
        "tokens": [
          51514,
          3677,
          3911,
          452,
          37852,
          11,
          293,
          360,
          746,
          365,
          11,
          337,
          1365,
          11,
          4295,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.19186316418046712,
        "compression_ratio": 1.6794425087108014,
        "end": 84,
        "id": 21,
        "no_speech_prob": 0.18008361756801605,
        "seek": 8100,
        "start": 82,
        "temperature": 0,
        "text": " And so the data set that I'm going to show you, it comes from NASA,",
        "tokens": [
          50414,
          400,
          370,
          264,
          1412,
          992,
          300,
          286,
          478,
          516,
          281,
          855,
          291,
          11,
          309,
          1487,
          490,
          12077,
          11,
          50514
        ]
      },
      {
        "avg_logprob": -0.19186316418046712,
        "compression_ratio": 1.6794425087108014,
        "end": 86,
        "id": 22,
        "no_speech_prob": 0.18008361756801605,
        "seek": 8100,
        "start": 84,
        "temperature": 0,
        "text": " National Aeronautics and Space Administration,",
        "tokens": [
          50514,
          4862,
          316,
          16308,
          1375,
          1167,
          293,
          8705,
          17187,
          11,
          50614
        ]
      },
      {
        "avg_logprob": -0.19186316418046712,
        "compression_ratio": 1.6794425087108014,
        "end": 89,
        "id": 23,
        "no_speech_prob": 0.18008361756801605,
        "seek": 8100,
        "start": 86,
        "temperature": 0,
        "text": " in particular from the Goddard Institute for Space Studies.",
        "tokens": [
          50614,
          294,
          1729,
          490,
          264,
          1265,
          67,
          515,
          9446,
          337,
          8705,
          17515,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.19186316418046712,
        "compression_ratio": 1.6794425087108014,
        "end": 98,
        "id": 24,
        "no_speech_prob": 0.18008361756801605,
        "seek": 8100,
        "start": 89,
        "temperature": 0,
        "text": " This CSV file includes the combined global average land surface air and sea surface water temperature",
        "tokens": [
          50764,
          639,
          48814,
          3991,
          5974,
          264,
          9354,
          4338,
          4274,
          2117,
          3753,
          1988,
          293,
          4158,
          3753,
          1281,
          4292,
          51214
        ]
      },
      {
        "avg_logprob": -0.19186316418046712,
        "compression_ratio": 1.6794425087108014,
        "end": 101,
        "id": 25,
        "no_speech_prob": 0.18008361756801605,
        "seek": 8100,
        "start": 98,
        "temperature": 0,
        "text": " from 1880 all the way to present.",
        "tokens": [
          51214,
          490,
          2443,
          4702,
          439,
          264,
          636,
          281,
          1974,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.19186316418046712,
        "compression_ratio": 1.6794425087108014,
        "end": 103,
        "id": 26,
        "no_speech_prob": 0.18008361756801605,
        "seek": 8100,
        "start": 101,
        "temperature": 0,
        "text": " It's stored in sort of a funny way.",
        "tokens": [
          51364,
          467,
          311,
          12187,
          294,
          1333,
          295,
          257,
          4074,
          636,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.19186316418046712,
        "compression_ratio": 1.6794425087108014,
        "end": 109,
        "id": 27,
        "no_speech_prob": 0.18008361756801605,
        "seek": 8100,
        "start": 103,
        "temperature": 0,
        "text": " What the values that are actually in the data set are the difference from the mean temperature.",
        "tokens": [
          51464,
          708,
          264,
          4190,
          300,
          366,
          767,
          294,
          264,
          1412,
          992,
          366,
          264,
          2649,
          490,
          264,
          914,
          4292,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.19186316418046712,
        "compression_ratio": 1.6794425087108014,
        "end": 110,
        "id": 28,
        "no_speech_prob": 0.18008361756801605,
        "seek": 8100,
        "start": 109,
        "temperature": 0,
        "text": " What do I mean by the mean temperature?",
        "tokens": [
          51764,
          708,
          360,
          286,
          914,
          538,
          264,
          914,
          4292,
          30,
          51814
        ]
      },
      {
        "avg_logprob": -0.17025170099167597,
        "compression_ratio": 1.76,
        "end": 111,
        "id": 29,
        "no_speech_prob": 0.0021156712900847197,
        "seek": 11000,
        "start": 110,
        "temperature": 0,
        "text": " Well, I mean the average temperature.",
        "tokens": [
          50364,
          1042,
          11,
          286,
          914,
          264,
          4274,
          4292,
          13,
          50414
        ]
      },
      {
        "avg_logprob": -0.17025170099167597,
        "compression_ratio": 1.76,
        "end": 113,
        "id": 30,
        "no_speech_prob": 0.0021156712900847197,
        "seek": 11000,
        "start": 111,
        "temperature": 0,
        "text": " Well, what's the average temperature?",
        "tokens": [
          50414,
          1042,
          11,
          437,
          311,
          264,
          4274,
          4292,
          30,
          50514
        ]
      },
      {
        "avg_logprob": -0.17025170099167597,
        "compression_ratio": 1.76,
        "end": 120,
        "id": 31,
        "no_speech_prob": 0.0021156712900847197,
        "seek": 11000,
        "start": 113,
        "temperature": 0,
        "text": " Well, it so happens that there is the average world temperature as recorded from 1951 to 1980,",
        "tokens": [
          50514,
          1042,
          11,
          309,
          370,
          2314,
          300,
          456,
          307,
          264,
          4274,
          1002,
          4292,
          382,
          8287,
          490,
          10858,
          16,
          281,
          13626,
          11,
          50864
        ]
      },
      {
        "avg_logprob": -0.17025170099167597,
        "compression_ratio": 1.76,
        "end": 127,
        "id": 32,
        "no_speech_prob": 0.0021156712900847197,
        "seek": 11000,
        "start": 120,
        "temperature": 0,
        "text": " which also recorded and averaged by NASA, the Earth Observatory website, at 14 degrees Celsius.",
        "tokens": [
          50864,
          597,
          611,
          8287,
          293,
          18247,
          2980,
          538,
          12077,
          11,
          264,
          4755,
          42547,
          4745,
          3144,
          11,
          412,
          3499,
          5310,
          22658,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.17025170099167597,
        "compression_ratio": 1.76,
        "end": 133,
        "id": 33,
        "no_speech_prob": 0.0021156712900847197,
        "seek": 11000,
        "start": 127,
        "temperature": 0,
        "text": " So the data in this CSV file is the difference from the mean, from 14 degrees Celsius,",
        "tokens": [
          51214,
          407,
          264,
          1412,
          294,
          341,
          48814,
          3991,
          307,
          264,
          2649,
          490,
          264,
          914,
          11,
          490,
          3499,
          5310,
          22658,
          11,
          51514
        ]
      },
      {
        "avg_logprob": -0.17025170099167597,
        "compression_ratio": 1.76,
        "end": 139,
        "id": 34,
        "no_speech_prob": 0.0021156712900847197,
        "seek": 11000,
        "start": 133,
        "temperature": 0,
        "text": " from combined land surface air and sea surface water temperature from 1880 to present.",
        "tokens": [
          51514,
          490,
          9354,
          2117,
          3753,
          1988,
          293,
          4158,
          3753,
          1281,
          4292,
          490,
          2443,
          4702,
          281,
          1974,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.16226200262705484,
        "compression_ratio": 1.7864406779661017,
        "end": 145,
        "id": 35,
        "no_speech_prob": 0.02595588192343712,
        "seek": 13900,
        "start": 139,
        "temperature": 0,
        "text": " So I want to load that CSV file, parse it, graph it, and we're done.",
        "tokens": [
          50364,
          407,
          286,
          528,
          281,
          3677,
          300,
          48814,
          3991,
          11,
          48377,
          309,
          11,
          4295,
          309,
          11,
          293,
          321,
          434,
          1096,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.16226200262705484,
        "compression_ratio": 1.7864406779661017,
        "end": 147,
        "id": 36,
        "no_speech_prob": 0.02595588192343712,
        "seek": 13900,
        "start": 145,
        "temperature": 0,
        "text": " I'm going to do this in two parts.",
        "tokens": [
          50664,
          286,
          478,
          516,
          281,
          360,
          341,
          294,
          732,
          3166,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.16226200262705484,
        "compression_ratio": 1.7864406779661017,
        "end": 151,
        "id": 37,
        "no_speech_prob": 0.02595588192343712,
        "seek": 13900,
        "start": 147,
        "temperature": 0,
        "text": " The first part that you're watching right now is just loading the CSV file, parsing it.",
        "tokens": [
          50764,
          440,
          700,
          644,
          300,
          291,
          434,
          1976,
          558,
          586,
          307,
          445,
          15114,
          264,
          48814,
          3991,
          11,
          21156,
          278,
          309,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.16226200262705484,
        "compression_ratio": 1.7864406779661017,
        "end": 156,
        "id": 38,
        "no_speech_prob": 0.02595588192343712,
        "seek": 13900,
        "start": 151,
        "temperature": 0,
        "text": " I want to be able to see it maybe as a console log in the browser, in the Chrome developer tools.",
        "tokens": [
          50964,
          286,
          528,
          281,
          312,
          1075,
          281,
          536,
          309,
          1310,
          382,
          257,
          11076,
          3565,
          294,
          264,
          11185,
          11,
          294,
          264,
          15327,
          10754,
          3873,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.16226200262705484,
        "compression_ratio": 1.7864406779661017,
        "end": 160,
        "id": 39,
        "no_speech_prob": 0.02595588192343712,
        "seek": 13900,
        "start": 156,
        "temperature": 0,
        "text": " And then once I see that I have the data there, then I want to try to graph it.",
        "tokens": [
          51214,
          400,
          550,
          1564,
          286,
          536,
          300,
          286,
          362,
          264,
          1412,
          456,
          11,
          550,
          286,
          528,
          281,
          853,
          281,
          4295,
          309,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.16226200262705484,
        "compression_ratio": 1.7864406779661017,
        "end": 165,
        "id": 40,
        "no_speech_prob": 0.02595588192343712,
        "seek": 13900,
        "start": 160,
        "temperature": 0,
        "text": " I'm going to graph it using a particular JavaScript library called chart.js.",
        "tokens": [
          51414,
          286,
          478,
          516,
          281,
          4295,
          309,
          1228,
          257,
          1729,
          15778,
          6405,
          1219,
          6927,
          13,
          25530,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.16226200262705484,
        "compression_ratio": 1.7864406779661017,
        "end": 168,
        "id": 41,
        "no_speech_prob": 0.02595588192343712,
        "seek": 13900,
        "start": 165,
        "temperature": 0,
        "text": " I'll talk about some other ways that you can choose to graph stuff then as well.",
        "tokens": [
          51664,
          286,
          603,
          751,
          466,
          512,
          661,
          2098,
          300,
          291,
          393,
          2826,
          281,
          4295,
          1507,
          550,
          382,
          731,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.20188096753594015,
        "compression_ratio": 1.671641791044776,
        "end": 171,
        "id": 42,
        "no_speech_prob": 0.13843707740306854,
        "seek": 16800,
        "start": 168,
        "temperature": 0,
        "text": " If you want to follow along with coding, I'm about to start coding,",
        "tokens": [
          50364,
          759,
          291,
          528,
          281,
          1524,
          2051,
          365,
          17720,
          11,
          286,
          478,
          466,
          281,
          722,
          17720,
          11,
          50514
        ]
      },
      {
        "avg_logprob": -0.20188096753594015,
        "compression_ratio": 1.671641791044776,
        "end": 175,
        "id": 43,
        "no_speech_prob": 0.13843707740306854,
        "seek": 16800,
        "start": 171,
        "temperature": 0,
        "text": " you're first going to want to grab that CSV file and have it stored locally on your computer.",
        "tokens": [
          50514,
          291,
          434,
          700,
          516,
          281,
          528,
          281,
          4444,
          300,
          48814,
          3991,
          293,
          362,
          309,
          12187,
          16143,
          322,
          428,
          3820,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.20188096753594015,
        "compression_ratio": 1.671641791044776,
        "end": 180,
        "id": 44,
        "no_speech_prob": 0.13843707740306854,
        "seek": 16800,
        "start": 175,
        "temperature": 0,
        "text": " So it's a pretty easy process. You just want to go to data.giss.nasa.gov slash GIS temp.",
        "tokens": [
          50714,
          407,
          309,
          311,
          257,
          1238,
          1858,
          1399,
          13,
          509,
          445,
          528,
          281,
          352,
          281,
          1412,
          13,
          70,
          891,
          13,
          77,
          9994,
          13,
          16089,
          17330,
          47860,
          18274,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.20188096753594015,
        "compression_ratio": 1.671641791044776,
        "end": 183,
        "id": 45,
        "no_speech_prob": 0.13843707740306854,
        "seek": 16800,
        "start": 180,
        "temperature": 0,
        "text": " The URL is here and in the video's description.",
        "tokens": [
          50964,
          440,
          12905,
          307,
          510,
          293,
          294,
          264,
          960,
          311,
          3855,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.20188096753594015,
        "compression_ratio": 1.671641791044776,
        "end": 186,
        "id": 46,
        "no_speech_prob": 0.13843707740306854,
        "seek": 16800,
        "start": 183,
        "temperature": 0,
        "text": " And then you're going to scroll all the way down and find the place on the web page that says",
        "tokens": [
          51114,
          400,
          550,
          291,
          434,
          516,
          281,
          11369,
          439,
          264,
          636,
          760,
          293,
          915,
          264,
          1081,
          322,
          264,
          3670,
          3028,
          300,
          1619,
          51264
        ]
      },
      {
        "avg_logprob": -0.20188096753594015,
        "compression_ratio": 1.671641791044776,
        "end": 190,
        "id": 47,
        "no_speech_prob": 0.13843707740306854,
        "seek": 16800,
        "start": 186,
        "temperature": 0,
        "text": " tables of global and hemispheric monthly means and zonal annual means.",
        "tokens": [
          51264,
          8020,
          295,
          4338,
          293,
          8636,
          7631,
          23920,
          12878,
          1355,
          293,
          710,
          21523,
          9784,
          1355,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.20188096753594015,
        "compression_ratio": 1.671641791044776,
        "end": 194,
        "id": 48,
        "no_speech_prob": 0.13843707740306854,
        "seek": 16800,
        "start": 190,
        "temperature": 0,
        "text": " So there are actually a ton of different data sets on this web page, and you might explore them.",
        "tokens": [
          51464,
          407,
          456,
          366,
          767,
          257,
          2952,
          295,
          819,
          1412,
          6352,
          322,
          341,
          3670,
          3028,
          11,
          293,
          291,
          1062,
          6839,
          552,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.18074361739620085,
        "compression_ratio": 1.6501766784452296,
        "end": 199,
        "id": 49,
        "no_speech_prob": 0.18239131569862366,
        "seek": 19400,
        "start": 194,
        "temperature": 0,
        "text": " And perhaps as an exercise, try doing graphing a different data set on this web page.",
        "tokens": [
          50364,
          400,
          4317,
          382,
          364,
          5380,
          11,
          853,
          884,
          1295,
          79,
          571,
          257,
          819,
          1412,
          992,
          322,
          341,
          3670,
          3028,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.18074361739620085,
        "compression_ratio": 1.6501766784452296,
        "end": 205,
        "id": 50,
        "no_speech_prob": 0.18239131569862366,
        "seek": 19400,
        "start": 199,
        "temperature": 0,
        "text": " But the one that I'm using is the last entry on that section called zonal annual means from 1880 to present.",
        "tokens": [
          50614,
          583,
          264,
          472,
          300,
          286,
          478,
          1228,
          307,
          264,
          1036,
          8729,
          322,
          300,
          3541,
          1219,
          710,
          21523,
          9784,
          1355,
          490,
          2443,
          4702,
          281,
          1974,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.18074361739620085,
        "compression_ratio": 1.6501766784452296,
        "end": 208,
        "id": 51,
        "no_speech_prob": 0.18239131569862366,
        "seek": 19400,
        "start": 205,
        "temperature": 0,
        "text": " And I'm using the CSV file format.",
        "tokens": [
          50914,
          400,
          286,
          478,
          1228,
          264,
          48814,
          3991,
          7877,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.18074361739620085,
        "compression_ratio": 1.6501766784452296,
        "end": 213,
        "id": 52,
        "no_speech_prob": 0.18239131569862366,
        "seek": 19400,
        "start": 208,
        "temperature": 0,
        "text": " You'll notice there's also a TXT file format that's probably tab delimited",
        "tokens": [
          51064,
          509,
          603,
          3449,
          456,
          311,
          611,
          257,
          314,
          20542,
          3991,
          7877,
          300,
          311,
          1391,
          4421,
          1103,
          332,
          1226,
          51314
        ]
      },
      {
        "avg_logprob": -0.18074361739620085,
        "compression_ratio": 1.6501766784452296,
        "end": 218,
        "id": 53,
        "no_speech_prob": 0.18239131569862366,
        "seek": 19400,
        "start": 213,
        "temperature": 0,
        "text": " so that the data records have tabs in between them instead of commas.",
        "tokens": [
          51314,
          370,
          300,
          264,
          1412,
          7724,
          362,
          20743,
          294,
          1296,
          552,
          2602,
          295,
          800,
          296,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.18074361739620085,
        "compression_ratio": 1.6501766784452296,
        "end": 222,
        "id": 54,
        "no_speech_prob": 0.18239131569862366,
        "seek": 19400,
        "start": 218,
        "temperature": 0,
        "text": " Again, there's a variety of different formats, but the CSV is the one that I'm going to use.",
        "tokens": [
          51564,
          3764,
          11,
          456,
          311,
          257,
          5673,
          295,
          819,
          25879,
          11,
          457,
          264,
          48814,
          307,
          264,
          472,
          300,
          286,
          478,
          516,
          281,
          764,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.15306239482785058,
        "compression_ratio": 1.623076923076923,
        "end": 224,
        "id": 55,
        "no_speech_prob": 0.006589491385966539,
        "seek": 22200,
        "start": 222,
        "temperature": 0,
        "text": " Time to start coding.",
        "tokens": [
          50364,
          6161,
          281,
          722,
          17720,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.15306239482785058,
        "compression_ratio": 1.623076923076923,
        "end": 227,
        "id": 56,
        "no_speech_prob": 0.006589491385966539,
        "seek": 22200,
        "start": 224,
        "temperature": 0,
        "text": " So let's check in and see if you want to follow along.",
        "tokens": [
          50464,
          407,
          718,
          311,
          1520,
          294,
          293,
          536,
          498,
          291,
          528,
          281,
          1524,
          2051,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.15306239482785058,
        "compression_ratio": 1.623076923076923,
        "end": 229,
        "id": 57,
        "no_speech_prob": 0.006589491385966539,
        "seek": 22200,
        "start": 227,
        "temperature": 0,
        "text": " Let's check in and see if you have exactly what I have.",
        "tokens": [
          50614,
          961,
          311,
          1520,
          294,
          293,
          536,
          498,
          291,
          362,
          2293,
          437,
          286,
          362,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.15306239482785058,
        "compression_ratio": 1.623076923076923,
        "end": 231,
        "id": 58,
        "no_speech_prob": 0.006589491385966539,
        "seek": 22200,
        "start": 229,
        "temperature": 0,
        "text": " So what I have is some boilerplate HTML.",
        "tokens": [
          50714,
          407,
          437,
          286,
          362,
          307,
          512,
          39228,
          37008,
          17995,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.15306239482785058,
        "compression_ratio": 1.623076923076923,
        "end": 237,
        "id": 59,
        "no_speech_prob": 0.006589491385966539,
        "seek": 22200,
        "start": 231,
        "temperature": 0,
        "text": " It's just a plain index.html file with a title, a head, a body, and an empty script tag.",
        "tokens": [
          50814,
          467,
          311,
          445,
          257,
          11121,
          8186,
          13,
          357,
          15480,
          3991,
          365,
          257,
          4876,
          11,
          257,
          1378,
          11,
          257,
          1772,
          11,
          293,
          364,
          6707,
          5755,
          6162,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.15306239482785058,
        "compression_ratio": 1.623076923076923,
        "end": 243,
        "id": 60,
        "no_speech_prob": 0.006589491385966539,
        "seek": 22200,
        "start": 237,
        "temperature": 0,
        "text": " I've got links to where the data is coming from just to make sure I'm referencing and crediting properly in my code.",
        "tokens": [
          51114,
          286,
          600,
          658,
          6123,
          281,
          689,
          264,
          1412,
          307,
          1348,
          490,
          445,
          281,
          652,
          988,
          286,
          478,
          40582,
          293,
          3864,
          1748,
          6108,
          294,
          452,
          3089,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.15306239482785058,
        "compression_ratio": 1.623076923076923,
        "end": 246,
        "id": 61,
        "no_speech_prob": 0.006589491385966539,
        "seek": 22200,
        "start": 243,
        "temperature": 0,
        "text": " And then I also have that CSV file itself.",
        "tokens": [
          51414,
          400,
          550,
          286,
          611,
          362,
          300,
          48814,
          3991,
          2564,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.1856028908177426,
        "compression_ratio": 1.6890459363957597,
        "end": 252,
        "id": 62,
        "no_speech_prob": 0.12589967250823975,
        "seek": 24600,
        "start": 246,
        "temperature": 0,
        "text": " So I'm in Visual Studio Code, and you can see there's my index.html, and there's my CSV file in the same local directory.",
        "tokens": [
          50364,
          407,
          286,
          478,
          294,
          23187,
          13500,
          15549,
          11,
          293,
          291,
          393,
          536,
          456,
          311,
          452,
          8186,
          13,
          357,
          15480,
          11,
          293,
          456,
          311,
          452,
          48814,
          3991,
          294,
          264,
          912,
          2654,
          21120,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.1856028908177426,
        "compression_ratio": 1.6890459363957597,
        "end": 255,
        "id": 63,
        "no_speech_prob": 0.12589967250823975,
        "seek": 24600,
        "start": 252,
        "temperature": 0,
        "text": " But you might be using a different text editor or a different environment.",
        "tokens": [
          50664,
          583,
          291,
          1062,
          312,
          1228,
          257,
          819,
          2487,
          9839,
          420,
          257,
          819,
          2823,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.1856028908177426,
        "compression_ratio": 1.6890459363957597,
        "end": 259,
        "id": 64,
        "no_speech_prob": 0.12589967250823975,
        "seek": 24600,
        "start": 255,
        "temperature": 0,
        "text": " All of this will work as long as you have your HTML file and your CSV file.",
        "tokens": [
          50814,
          1057,
          295,
          341,
          486,
          589,
          382,
          938,
          382,
          291,
          362,
          428,
          17995,
          3991,
          293,
          428,
          48814,
          3991,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.1856028908177426,
        "compression_ratio": 1.6890459363957597,
        "end": 262,
        "id": 65,
        "no_speech_prob": 0.12589967250823975,
        "seek": 24600,
        "start": 259,
        "temperature": 0,
        "text": " Let's take a look at that CSV file.",
        "tokens": [
          51014,
          961,
          311,
          747,
          257,
          574,
          412,
          300,
          48814,
          3991,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.1856028908177426,
        "compression_ratio": 1.6890459363957597,
        "end": 264,
        "id": 66,
        "no_speech_prob": 0.12589967250823975,
        "seek": 24600,
        "start": 262,
        "temperature": 0,
        "text": " So here's the CSV file.",
        "tokens": [
          51164,
          407,
          510,
          311,
          264,
          48814,
          3991,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.1856028908177426,
        "compression_ratio": 1.6890459363957597,
        "end": 270,
        "id": 67,
        "no_speech_prob": 0.12589967250823975,
        "seek": 24600,
        "start": 264,
        "temperature": 0,
        "text": " You can see that there are a number of columns, year, glob, which I assume stands for global,",
        "tokens": [
          51264,
          509,
          393,
          536,
          300,
          456,
          366,
          257,
          1230,
          295,
          13766,
          11,
          1064,
          11,
          16125,
          11,
          597,
          286,
          6552,
          7382,
          337,
          4338,
          11,
          51564
        ]
      },
      {
        "avg_logprob": -0.1856028908177426,
        "compression_ratio": 1.6890459363957597,
        "end": 273,
        "id": 68,
        "no_speech_prob": 0.12589967250823975,
        "seek": 24600,
        "start": 270,
        "temperature": 0,
        "text": " and HEM, Northern Hemisphere, et cetera, et cetera.",
        "tokens": [
          51564,
          293,
          389,
          6683,
          11,
          14335,
          18568,
          31048,
          11,
          1030,
          11458,
          11,
          1030,
          11458,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.16201880670362903,
        "compression_ratio": 1.5890410958904109,
        "end": 278,
        "id": 69,
        "no_speech_prob": 0.02479652687907219,
        "seek": 27300,
        "start": 273,
        "temperature": 0,
        "text": " And then you can see the columns of data each being separated by commas.",
        "tokens": [
          50364,
          400,
          550,
          291,
          393,
          536,
          264,
          13766,
          295,
          1412,
          1184,
          885,
          12005,
          538,
          800,
          296,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.16201880670362903,
        "compression_ratio": 1.5890410958904109,
        "end": 280,
        "id": 70,
        "no_speech_prob": 0.02479652687907219,
        "seek": 27300,
        "start": 278,
        "temperature": 0,
        "text": " So this isn't really meant to be human-readable.",
        "tokens": [
          50614,
          407,
          341,
          1943,
          380,
          534,
          4140,
          281,
          312,
          1952,
          12,
          2538,
          712,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.16201880670362903,
        "compression_ratio": 1.5890410958904109,
        "end": 284,
        "id": 71,
        "no_speech_prob": 0.02479652687907219,
        "seek": 27300,
        "start": 280,
        "temperature": 0,
        "text": " There are ways of viewing a CSV that's more human-readable.",
        "tokens": [
          50714,
          821,
          366,
          2098,
          295,
          17480,
          257,
          48814,
          300,
          311,
          544,
          1952,
          12,
          2538,
          712,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.16201880670362903,
        "compression_ratio": 1.5890410958904109,
        "end": 288,
        "id": 72,
        "no_speech_prob": 0.02479652687907219,
        "seek": 27300,
        "start": 284,
        "temperature": 0,
        "text": " For example, here's how that same data looks in spreadsheet format.",
        "tokens": [
          50914,
          1171,
          1365,
          11,
          510,
          311,
          577,
          300,
          912,
          1412,
          1542,
          294,
          27733,
          7877,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.16201880670362903,
        "compression_ratio": 1.5890410958904109,
        "end": 291,
        "id": 73,
        "no_speech_prob": 0.02479652687907219,
        "seek": 27300,
        "start": 288,
        "temperature": 0,
        "text": " You might notice here, however, that it is colored.",
        "tokens": [
          51114,
          509,
          1062,
          3449,
          510,
          11,
          4461,
          11,
          300,
          309,
          307,
          14332,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.16201880670362903,
        "compression_ratio": 1.5890410958904109,
        "end": 293,
        "id": 74,
        "no_speech_prob": 0.02479652687907219,
        "seek": 27300,
        "start": 291,
        "temperature": 0,
        "text": " Each column has a different color.",
        "tokens": [
          51264,
          6947,
          7738,
          575,
          257,
          819,
          2017,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.16201880670362903,
        "compression_ratio": 1.5890410958904109,
        "end": 300,
        "id": 75,
        "no_speech_prob": 0.02479652687907219,
        "seek": 27300,
        "start": 293,
        "temperature": 0,
        "text": " This is because I'm using a Visual Studio Code extension called Rainbow CSV, which it's as if it was, like, tailor-made for me.",
        "tokens": [
          51364,
          639,
          307,
          570,
          286,
          478,
          1228,
          257,
          23187,
          13500,
          15549,
          10320,
          1219,
          29477,
          48814,
          11,
          597,
          309,
          311,
          382,
          498,
          309,
          390,
          11,
          411,
          11,
          33068,
          12,
          10341,
          337,
          385,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.17239218267775674,
        "compression_ratio": 1.6644295302013423,
        "end": 306,
        "id": 76,
        "no_speech_prob": 0.04272137209773064,
        "seek": 30000,
        "start": 301,
        "temperature": 0,
        "text": " And I'll include a link in this video description if you want to install that extension as well so you can have things color-coded.",
        "tokens": [
          50414,
          400,
          286,
          603,
          4090,
          257,
          2113,
          294,
          341,
          960,
          3855,
          498,
          291,
          528,
          281,
          3625,
          300,
          10320,
          382,
          731,
          370,
          291,
          393,
          362,
          721,
          2017,
          12,
          66,
          12340,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.17239218267775674,
        "compression_ratio": 1.6644295302013423,
        "end": 316,
        "id": 77,
        "no_speech_prob": 0.04272137209773064,
        "seek": 30000,
        "start": 306,
        "temperature": 0,
        "text": " Another thing I really like to do when I'm working with a data set for the first time is I like to give myself a test file that has much less stuff in it.",
        "tokens": [
          50664,
          3996,
          551,
          286,
          534,
          411,
          281,
          360,
          562,
          286,
          478,
          1364,
          365,
          257,
          1412,
          992,
          337,
          264,
          700,
          565,
          307,
          286,
          411,
          281,
          976,
          2059,
          257,
          1500,
          3991,
          300,
          575,
          709,
          1570,
          1507,
          294,
          309,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.17239218267775674,
        "compression_ratio": 1.6644295302013423,
        "end": 321,
        "id": 78,
        "no_speech_prob": 0.04272137209773064,
        "seek": 30000,
        "start": 316,
        "temperature": 0,
        "text": " Because if I want to console log and check stuff, sometimes this big file, this isn't that big of a file.",
        "tokens": [
          51164,
          1436,
          498,
          286,
          528,
          281,
          11076,
          3565,
          293,
          1520,
          1507,
          11,
          2171,
          341,
          955,
          3991,
          11,
          341,
          1943,
          380,
          300,
          955,
          295,
          257,
          3991,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.17239218267775674,
        "compression_ratio": 1.6644295302013423,
        "end": 324,
        "id": 79,
        "no_speech_prob": 0.04272137209773064,
        "seek": 30000,
        "start": 321,
        "temperature": 0,
        "text": " It's just, you know, 1880 to 2018.",
        "tokens": [
          51414,
          467,
          311,
          445,
          11,
          291,
          458,
          11,
          2443,
          4702,
          281,
          6096,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.17239218267775674,
        "compression_ratio": 1.6644295302013423,
        "end": 328,
        "id": 80,
        "no_speech_prob": 0.04272137209773064,
        "seek": 30000,
        "start": 324,
        "temperature": 0,
        "text": " But potentially, I could have, like, a really, really big data file.",
        "tokens": [
          51564,
          583,
          7263,
          11,
          286,
          727,
          362,
          11,
          411,
          11,
          257,
          534,
          11,
          534,
          955,
          1412,
          3991,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.14711579179341813,
        "compression_ratio": 1.8093023255813954,
        "end": 333,
        "id": 81,
        "no_speech_prob": 0.021286197006702423,
        "seek": 32800,
        "start": 328,
        "temperature": 0,
        "text": " So something I'm going to do is I'm going to just quickly do a save as and call this test.csv.",
        "tokens": [
          50364,
          407,
          746,
          286,
          478,
          516,
          281,
          360,
          307,
          286,
          478,
          516,
          281,
          445,
          2661,
          360,
          257,
          3155,
          382,
          293,
          818,
          341,
          1500,
          13,
          14368,
          85,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.14711579179341813,
        "compression_ratio": 1.8093023255813954,
        "end": 337,
        "id": 82,
        "no_speech_prob": 0.021286197006702423,
        "seek": 32800,
        "start": 333,
        "temperature": 0,
        "text": " And so now you can see that I have a separate test.csv file.",
        "tokens": [
          50614,
          400,
          370,
          586,
          291,
          393,
          536,
          300,
          286,
          362,
          257,
          4994,
          1500,
          13,
          14368,
          85,
          3991,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.14711579179341813,
        "compression_ratio": 1.8093023255813954,
        "end": 339,
        "id": 83,
        "no_speech_prob": 0.021286197006702423,
        "seek": 32800,
        "start": 337,
        "temperature": 0,
        "text": " And I'm going to just leave two years in there.",
        "tokens": [
          50814,
          400,
          286,
          478,
          516,
          281,
          445,
          1856,
          732,
          924,
          294,
          456,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.14711579179341813,
        "compression_ratio": 1.8093023255813954,
        "end": 342,
        "id": 84,
        "no_speech_prob": 0.021286197006702423,
        "seek": 32800,
        "start": 339,
        "temperature": 0,
        "text": " So I'm going to scroll all the way down and delete everything.",
        "tokens": [
          50914,
          407,
          286,
          478,
          516,
          281,
          11369,
          439,
          264,
          636,
          760,
          293,
          12097,
          1203,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.14711579179341813,
        "compression_ratio": 1.8093023255813954,
        "end": 351,
        "id": 85,
        "no_speech_prob": 0.021286197006702423,
        "seek": 32800,
        "start": 342,
        "temperature": 0,
        "text": " And now I have a CSV file that just has three rows in it, the header row and then the data for 1880 and the data for 1881.",
        "tokens": [
          51064,
          400,
          586,
          286,
          362,
          257,
          48814,
          3991,
          300,
          445,
          575,
          1045,
          13241,
          294,
          309,
          11,
          264,
          23117,
          5386,
          293,
          550,
          264,
          1412,
          337,
          2443,
          4702,
          293,
          264,
          1412,
          337,
          2443,
          32875,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.14621734619140625,
        "compression_ratio": 1.7182539682539681,
        "end": 353,
        "id": 86,
        "no_speech_prob": 0.05261612311005592,
        "seek": 35100,
        "start": 351,
        "temperature": 0,
        "text": " So I'm going to work with this first.",
        "tokens": [
          50364,
          407,
          286,
          478,
          516,
          281,
          589,
          365,
          341,
          700,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.14621734619140625,
        "compression_ratio": 1.7182539682539681,
        "end": 358,
        "id": 87,
        "no_speech_prob": 0.05261612311005592,
        "seek": 35100,
        "start": 353,
        "temperature": 0,
        "text": " And once I have the parsing and everything I want to do working properly, then I'll load the real data.",
        "tokens": [
          50464,
          400,
          1564,
          286,
          362,
          264,
          21156,
          278,
          293,
          1203,
          286,
          528,
          281,
          360,
          1364,
          6108,
          11,
          550,
          286,
          603,
          3677,
          264,
          957,
          1412,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.14621734619140625,
        "compression_ratio": 1.7182539682539681,
        "end": 363,
        "id": 88,
        "no_speech_prob": 0.05261612311005592,
        "seek": 35100,
        "start": 358,
        "temperature": 0,
        "text": " So the first step is exactly what you might think, fetch test.csv.",
        "tokens": [
          50714,
          407,
          264,
          700,
          1823,
          307,
          2293,
          437,
          291,
          1062,
          519,
          11,
          23673,
          1500,
          13,
          14368,
          85,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.14621734619140625,
        "compression_ratio": 1.7182539682539681,
        "end": 365,
        "id": 89,
        "no_speech_prob": 0.05261612311005592,
        "seek": 35100,
        "start": 363,
        "temperature": 0,
        "text": " Let's write that code.",
        "tokens": [
          50964,
          961,
          311,
          2464,
          300,
          3089,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.14621734619140625,
        "compression_ratio": 1.7182539682539681,
        "end": 369,
        "id": 90,
        "no_speech_prob": 0.05261612311005592,
        "seek": 35100,
        "start": 365,
        "temperature": 0,
        "text": " I'm going to write fetch test.csv.",
        "tokens": [
          51064,
          286,
          478,
          516,
          281,
          2464,
          23673,
          1500,
          13,
          14368,
          85,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.14621734619140625,
        "compression_ratio": 1.7182539682539681,
        "end": 372,
        "id": 91,
        "no_speech_prob": 0.05261612311005592,
        "seek": 35100,
        "start": 369,
        "temperature": 0,
        "text": " And then, remember, fetch returns a promise.",
        "tokens": [
          51264,
          400,
          550,
          11,
          1604,
          11,
          23673,
          11247,
          257,
          6228,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.14621734619140625,
        "compression_ratio": 1.7182539682539681,
        "end": 380,
        "id": 92,
        "no_speech_prob": 0.05261612311005592,
        "seek": 35100,
        "start": 372,
        "temperature": 0,
        "text": " And I can handle the resolution of that promise when it is finished loading the data with.then and any errors with.catch.",
        "tokens": [
          51414,
          400,
          286,
          393,
          4813,
          264,
          8669,
          295,
          300,
          6228,
          562,
          309,
          307,
          4335,
          15114,
          264,
          1412,
          365,
          2411,
          19096,
          293,
          604,
          13603,
          365,
          2411,
          66,
          852,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.13436680369906956,
        "compression_ratio": 1.7302904564315353,
        "end": 383,
        "id": 93,
        "no_speech_prob": 0.002082952531054616,
        "seek": 38000,
        "start": 380,
        "temperature": 0,
        "text": " But I prefer to use the await and async syntax.",
        "tokens": [
          50364,
          583,
          286,
          4382,
          281,
          764,
          264,
          19670,
          293,
          382,
          34015,
          28431,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.13436680369906956,
        "compression_ratio": 1.7302904564315353,
        "end": 388,
        "id": 94,
        "no_speech_prob": 0.002082952531054616,
        "seek": 38000,
        "start": 383,
        "temperature": 0,
        "text": " So I'm actually going to put this in a function called get data.",
        "tokens": [
          50514,
          407,
          286,
          478,
          767,
          516,
          281,
          829,
          341,
          294,
          257,
          2445,
          1219,
          483,
          1412,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.13436680369906956,
        "compression_ratio": 1.7302904564315353,
        "end": 390,
        "id": 95,
        "no_speech_prob": 0.002082952531054616,
        "seek": 38000,
        "start": 388,
        "temperature": 0,
        "text": " I might think of a different name for that later.",
        "tokens": [
          50764,
          286,
          1062,
          519,
          295,
          257,
          819,
          1315,
          337,
          300,
          1780,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.13436680369906956,
        "compression_ratio": 1.7302904564315353,
        "end": 396,
        "id": 96,
        "no_speech_prob": 0.002082952531054616,
        "seek": 38000,
        "start": 390,
        "temperature": 0,
        "text": " And I'm going to say the response equals await fetch test.csv.",
        "tokens": [
          50864,
          400,
          286,
          478,
          516,
          281,
          584,
          264,
          4134,
          6915,
          19670,
          23673,
          1500,
          13,
          14368,
          85,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.13436680369906956,
        "compression_ratio": 1.7302904564315353,
        "end": 397,
        "id": 97,
        "no_speech_prob": 0.002082952531054616,
        "seek": 38000,
        "start": 396,
        "temperature": 0,
        "text": " So I'm writing a function.",
        "tokens": [
          51164,
          407,
          286,
          478,
          3579,
          257,
          2445,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.13436680369906956,
        "compression_ratio": 1.7302904564315353,
        "end": 406,
        "id": 98,
        "no_speech_prob": 0.002082952531054616,
        "seek": 38000,
        "start": 397,
        "temperature": 0,
        "text": " Oh, and this function, I almost forgot, has to have the keyword async because it's an asynchronous function that's making asynchronous calls with the await keyword.",
        "tokens": [
          51214,
          876,
          11,
          293,
          341,
          2445,
          11,
          286,
          1920,
          5298,
          11,
          575,
          281,
          362,
          264,
          20428,
          382,
          34015,
          570,
          309,
          311,
          364,
          49174,
          2445,
          300,
          311,
          1455,
          49174,
          5498,
          365,
          264,
          19670,
          20428,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.16891153590885674,
        "compression_ratio": 1.6115384615384616,
        "end": 410,
        "id": 99,
        "no_speech_prob": 0.07263270020484924,
        "seek": 40600,
        "start": 406,
        "temperature": 0,
        "text": " So the response equals await fetch.test.csv.",
        "tokens": [
          50364,
          407,
          264,
          4134,
          6915,
          19670,
          23673,
          13,
          31636,
          13,
          14368,
          85,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.16891153590885674,
        "compression_ratio": 1.6115384615384616,
        "end": 416,
        "id": 100,
        "no_speech_prob": 0.07263270020484924,
        "seek": 40600,
        "start": 410,
        "temperature": 0,
        "text": " Now, you might remember on the web fetch API, there are a variety of kinds of data streams that might come in.",
        "tokens": [
          50564,
          823,
          11,
          291,
          1062,
          1604,
          322,
          264,
          3670,
          23673,
          9362,
          11,
          456,
          366,
          257,
          5673,
          295,
          3685,
          295,
          1412,
          15842,
          300,
          1062,
          808,
          294,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.16891153590885674,
        "compression_ratio": 1.6115384615384616,
        "end": 418,
        "id": 101,
        "no_speech_prob": 0.07263270020484924,
        "seek": 40600,
        "start": 416,
        "temperature": 0,
        "text": " There's a blob.",
        "tokens": [
          50864,
          821,
          311,
          257,
          46115,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.16891153590885674,
        "compression_ratio": 1.6115384615384616,
        "end": 419,
        "id": 102,
        "no_speech_prob": 0.07263270020484924,
        "seek": 40600,
        "start": 418,
        "temperature": 0,
        "text": " There's a JSON.",
        "tokens": [
          50964,
          821,
          311,
          257,
          31828,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.16891153590885674,
        "compression_ratio": 1.6115384615384616,
        "end": 420,
        "id": 103,
        "no_speech_prob": 0.07263270020484924,
        "seek": 40600,
        "start": 419,
        "temperature": 0,
        "text": " There's an array buffer.",
        "tokens": [
          51014,
          821,
          311,
          364,
          10225,
          21762,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.16891153590885674,
        "compression_ratio": 1.6115384615384616,
        "end": 421,
        "id": 104,
        "no_speech_prob": 0.07263270020484924,
        "seek": 40600,
        "start": 420,
        "temperature": 0,
        "text": " There's text.",
        "tokens": [
          51064,
          821,
          311,
          2487,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.16891153590885674,
        "compression_ratio": 1.6115384615384616,
        "end": 423,
        "id": 105,
        "no_speech_prob": 0.07263270020484924,
        "seek": 40600,
        "start": 421,
        "temperature": 0,
        "text": " And this is what I want to actually use, raw text.",
        "tokens": [
          51114,
          400,
          341,
          307,
          437,
          286,
          528,
          281,
          767,
          764,
          11,
          8936,
          2487,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.16891153590885674,
        "compression_ratio": 1.6115384615384616,
        "end": 429,
        "id": 106,
        "no_speech_prob": 0.07263270020484924,
        "seek": 40600,
        "start": 423,
        "temperature": 0,
        "text": " Even though it's tabular data in CSV format, I'm going to do the parsing of it manually in my own code.",
        "tokens": [
          51214,
          2754,
          1673,
          309,
          311,
          4421,
          1040,
          1412,
          294,
          48814,
          7877,
          11,
          286,
          478,
          516,
          281,
          360,
          264,
          21156,
          278,
          295,
          309,
          16945,
          294,
          452,
          1065,
          3089,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.16891153590885674,
        "compression_ratio": 1.6115384615384616,
        "end": 432,
        "id": 107,
        "no_speech_prob": 0.07263270020484924,
        "seek": 40600,
        "start": 429,
        "temperature": 0,
        "text": " So I just want to receive it as text.",
        "tokens": [
          51514,
          407,
          286,
          445,
          528,
          281,
          4774,
          309,
          382,
          2487,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.2029803757815017,
        "compression_ratio": 1.6804123711340206,
        "end": 435,
        "id": 108,
        "no_speech_prob": 0.01854623109102249,
        "seek": 43200,
        "start": 432,
        "temperature": 0,
        "text": " And that means I'm going to say const.",
        "tokens": [
          50364,
          400,
          300,
          1355,
          286,
          478,
          516,
          281,
          584,
          1817,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.2029803757815017,
        "compression_ratio": 1.6804123711340206,
        "end": 437,
        "id": 109,
        "no_speech_prob": 0.01854623109102249,
        "seek": 43200,
        "start": 435,
        "temperature": 0,
        "text": " I'm just going to say table equals.",
        "tokens": [
          50514,
          286,
          478,
          445,
          516,
          281,
          584,
          3199,
          6915,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.2029803757815017,
        "compression_ratio": 1.6804123711340206,
        "end": 446,
        "id": 110,
        "no_speech_prob": 0.01854623109102249,
        "seek": 43200,
        "start": 437,
        "temperature": 0,
        "text": " Maybe I'll just call this all data equals await response dot text.",
        "tokens": [
          50614,
          2704,
          286,
          603,
          445,
          818,
          341,
          439,
          1412,
          6915,
          19670,
          4134,
          5893,
          2487,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.2029803757815017,
        "compression_ratio": 1.6804123711340206,
        "end": 449,
        "id": 111,
        "no_speech_prob": 0.01854623109102249,
        "seek": 43200,
        "start": 446,
        "temperature": 0,
        "text": " So let's console log that data.",
        "tokens": [
          51064,
          407,
          718,
          311,
          11076,
          3565,
          300,
          1412,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.2029803757815017,
        "compression_ratio": 1.6804123711340206,
        "end": 453,
        "id": 112,
        "no_speech_prob": 0.01854623109102249,
        "seek": 43200,
        "start": 449,
        "temperature": 0,
        "text": " And let's call the function get data here.",
        "tokens": [
          51214,
          400,
          718,
          311,
          818,
          264,
          2445,
          483,
          1412,
          510,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.2029803757815017,
        "compression_ratio": 1.6804123711340206,
        "end": 457,
        "id": 113,
        "no_speech_prob": 0.01854623109102249,
        "seek": 43200,
        "start": 453,
        "temperature": 0,
        "text": " And then let's go and see this running actually in the browser.",
        "tokens": [
          51414,
          400,
          550,
          718,
          311,
          352,
          293,
          536,
          341,
          2614,
          767,
          294,
          264,
          11185,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.2029803757815017,
        "compression_ratio": 1.6804123711340206,
        "end": 458,
        "id": 114,
        "no_speech_prob": 0.01854623109102249,
        "seek": 43200,
        "start": 457,
        "temperature": 0,
        "text": " And here it is.",
        "tokens": [
          51614,
          400,
          510,
          309,
          307,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.2029803757815017,
        "compression_ratio": 1.6804123711340206,
        "end": 459,
        "id": 115,
        "no_speech_prob": 0.01854623109102249,
        "seek": 43200,
        "start": 458,
        "temperature": 0,
        "text": " And you can see, there we go.",
        "tokens": [
          51664,
          400,
          291,
          393,
          536,
          11,
          456,
          321,
          352,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.14110447918927227,
        "compression_ratio": 1.8280701754385964,
        "end": 462,
        "id": 116,
        "no_speech_prob": 0.3738311231136322,
        "seek": 45900,
        "start": 459,
        "temperature": 0,
        "text": " The data has been logged to the console.",
        "tokens": [
          50364,
          440,
          1412,
          575,
          668,
          27231,
          281,
          264,
          11076,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.14110447918927227,
        "compression_ratio": 1.8280701754385964,
        "end": 468,
        "id": 117,
        "no_speech_prob": 0.3738311231136322,
        "seek": 45900,
        "start": 462,
        "temperature": 0,
        "text": " Now, ultimately here, there are a variety of JavaScript libraries that will parse a CSV for you.",
        "tokens": [
          50514,
          823,
          11,
          6284,
          510,
          11,
          456,
          366,
          257,
          5673,
          295,
          15778,
          15148,
          300,
          486,
          48377,
          257,
          48814,
          337,
          291,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.14110447918927227,
        "compression_ratio": 1.8280701754385964,
        "end": 475,
        "id": 118,
        "no_speech_prob": 0.3738311231136322,
        "seek": 45900,
        "start": 468,
        "temperature": 0,
        "text": " And by I mean parse, I mean figure out where all the commas are and break up the data and put it into objects and make it usable for you.",
        "tokens": [
          50814,
          400,
          538,
          286,
          914,
          48377,
          11,
          286,
          914,
          2573,
          484,
          689,
          439,
          264,
          800,
          296,
          366,
          293,
          1821,
          493,
          264,
          1412,
          293,
          829,
          309,
          666,
          6565,
          293,
          652,
          309,
          29975,
          337,
          291,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.14110447918927227,
        "compression_ratio": 1.8280701754385964,
        "end": 480,
        "id": 119,
        "no_speech_prob": 0.3738311231136322,
        "seek": 45900,
        "start": 475,
        "temperature": 0,
        "text": " D3, which is a JavaScript library for data visualization, has a parser in it.",
        "tokens": [
          51164,
          413,
          18,
          11,
          597,
          307,
          257,
          15778,
          6405,
          337,
          1412,
          25801,
          11,
          575,
          257,
          21156,
          260,
          294,
          309,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.14110447918927227,
        "compression_ratio": 1.8280701754385964,
        "end": 487,
        "id": 120,
        "no_speech_prob": 0.3738311231136322,
        "seek": 45900,
        "start": 480,
        "temperature": 0,
        "text": " P5.js, which is a JavaScript library that I use a lot on this channel, has a load table function, which will actually parse the CSV for you.",
        "tokens": [
          51414,
          430,
          20,
          13,
          25530,
          11,
          597,
          307,
          257,
          15778,
          6405,
          300,
          286,
          764,
          257,
          688,
          322,
          341,
          2269,
          11,
          575,
          257,
          3677,
          3199,
          2445,
          11,
          597,
          486,
          767,
          48377,
          264,
          48814,
          337,
          291,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.14110447918927227,
        "compression_ratio": 1.8280701754385964,
        "end": 488,
        "id": 121,
        "no_speech_prob": 0.3738311231136322,
        "seek": 45900,
        "start": 487,
        "temperature": 0,
        "text": " And there are many others.",
        "tokens": [
          51764,
          400,
          456,
          366,
          867,
          2357,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.16157865524291992,
        "compression_ratio": 1.7337662337662338,
        "end": 491,
        "id": 122,
        "no_speech_prob": 0.040844451636075974,
        "seek": 48800,
        "start": 488,
        "temperature": 0,
        "text": " So I'll include some links to those in the video description.",
        "tokens": [
          50364,
          407,
          286,
          603,
          4090,
          512,
          6123,
          281,
          729,
          294,
          264,
          960,
          3855,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.16157865524291992,
        "compression_ratio": 1.7337662337662338,
        "end": 493,
        "id": 123,
        "no_speech_prob": 0.040844451636075974,
        "seek": 48800,
        "start": 491,
        "temperature": 0,
        "text": " But I think it's a useful exercise right now.",
        "tokens": [
          50514,
          583,
          286,
          519,
          309,
          311,
          257,
          4420,
          5380,
          558,
          586,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.16157865524291992,
        "compression_ratio": 1.7337662337662338,
        "end": 498,
        "id": 124,
        "no_speech_prob": 0.040844451636075974,
        "seek": 48800,
        "start": 493,
        "temperature": 0,
        "text": " It's simple enough data for us to do the parsing manually with the split function.",
        "tokens": [
          50614,
          467,
          311,
          2199,
          1547,
          1412,
          337,
          505,
          281,
          360,
          264,
          21156,
          278,
          16945,
          365,
          264,
          7472,
          2445,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.16157865524291992,
        "compression_ratio": 1.7337662337662338,
        "end": 500,
        "id": 125,
        "no_speech_prob": 0.040844451636075974,
        "seek": 48800,
        "start": 498,
        "temperature": 0,
        "text": " What split function?",
        "tokens": [
          50864,
          708,
          7472,
          2445,
          30,
          50964
        ]
      },
      {
        "avg_logprob": -0.16157865524291992,
        "compression_ratio": 1.7337662337662338,
        "end": 501,
        "id": 126,
        "no_speech_prob": 0.040844451636075974,
        "seek": 48800,
        "start": 500,
        "temperature": 0,
        "text": " What are you talking about?",
        "tokens": [
          50964,
          708,
          366,
          291,
          1417,
          466,
          30,
          51014
        ]
      },
      {
        "avg_logprob": -0.16157865524291992,
        "compression_ratio": 1.7337662337662338,
        "end": 510,
        "id": 127,
        "no_speech_prob": 0.040844451636075974,
        "seek": 48800,
        "start": 501,
        "temperature": 0,
        "text": " So the JavaScript string class, anytime you have a piece of text in a variable in JavaScript, it's a string object, has a function called split.",
        "tokens": [
          51014,
          407,
          264,
          15778,
          6798,
          1508,
          11,
          13038,
          291,
          362,
          257,
          2522,
          295,
          2487,
          294,
          257,
          7006,
          294,
          15778,
          11,
          309,
          311,
          257,
          6798,
          2657,
          11,
          575,
          257,
          2445,
          1219,
          7472,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.16157865524291992,
        "compression_ratio": 1.7337662337662338,
        "end": 516,
        "id": 128,
        "no_speech_prob": 0.040844451636075974,
        "seek": 48800,
        "start": 510,
        "temperature": 0,
        "text": " And that function allows you to take any arbitrary text and split it up into different elements of an array.",
        "tokens": [
          51464,
          400,
          300,
          2445,
          4045,
          291,
          281,
          747,
          604,
          23211,
          2487,
          293,
          7472,
          309,
          493,
          666,
          819,
          4959,
          295,
          364,
          10225,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.16157865524291992,
        "compression_ratio": 1.7337662337662338,
        "end": 517,
        "id": 129,
        "no_speech_prob": 0.040844451636075974,
        "seek": 48800,
        "start": 516,
        "temperature": 0,
        "text": " And that's basically what we want to do.",
        "tokens": [
          51764,
          400,
          300,
          311,
          1936,
          437,
          321,
          528,
          281,
          360,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.15635362267494202,
        "compression_ratio": 1.752988047808765,
        "end": 518,
        "id": 130,
        "no_speech_prob": 0.0053848098032176495,
        "seek": 51700,
        "start": 517,
        "temperature": 0,
        "text": " We want to split up all the rows.",
        "tokens": [
          50364,
          492,
          528,
          281,
          7472,
          493,
          439,
          264,
          13241,
          13,
          50414
        ]
      },
      {
        "avg_logprob": -0.15635362267494202,
        "compression_ratio": 1.752988047808765,
        "end": 521,
        "id": 131,
        "no_speech_prob": 0.0053848098032176495,
        "seek": 51700,
        "start": 518,
        "temperature": 0,
        "text": " And then each row, we want to split up all the columns.",
        "tokens": [
          50414,
          400,
          550,
          1184,
          5386,
          11,
          321,
          528,
          281,
          7472,
          493,
          439,
          264,
          13766,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.15635362267494202,
        "compression_ratio": 1.752988047808765,
        "end": 527,
        "id": 132,
        "no_speech_prob": 0.0053848098032176495,
        "seek": 51700,
        "start": 521,
        "temperature": 0,
        "text": " The split function requires a single argument, a separator, or otherwise known as a delimiter.",
        "tokens": [
          50564,
          440,
          7472,
          2445,
          7029,
          257,
          2167,
          6770,
          11,
          257,
          3128,
          1639,
          11,
          420,
          5911,
          2570,
          382,
          257,
          1103,
          332,
          1681,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.15635362267494202,
        "compression_ratio": 1.752988047808765,
        "end": 530,
        "id": 133,
        "no_speech_prob": 0.0053848098032176495,
        "seek": 51700,
        "start": 527,
        "temperature": 0,
        "text": " And in this case, we have two kinds of delimiters.",
        "tokens": [
          50864,
          400,
          294,
          341,
          1389,
          11,
          321,
          362,
          732,
          3685,
          295,
          1103,
          332,
          270,
          433,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.15635362267494202,
        "compression_ratio": 1.752988047808765,
        "end": 536,
        "id": 134,
        "no_speech_prob": 0.0053848098032176495,
        "seek": 51700,
        "start": 530,
        "temperature": 0,
        "text": " For each row, the delimiter, the thing that differentiates one row from another, is a line break.",
        "tokens": [
          51014,
          1171,
          1184,
          5386,
          11,
          264,
          1103,
          332,
          1681,
          11,
          264,
          551,
          300,
          27372,
          1024,
          472,
          5386,
          490,
          1071,
          11,
          307,
          257,
          1622,
          1821,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.15635362267494202,
        "compression_ratio": 1.752988047808765,
        "end": 539,
        "id": 135,
        "no_speech_prob": 0.0053848098032176495,
        "seek": 51700,
        "start": 536,
        "temperature": 0,
        "text": " So first, let's call split with line break.",
        "tokens": [
          51314,
          407,
          700,
          11,
          718,
          311,
          818,
          7472,
          365,
          1622,
          1821,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.15635362267494202,
        "compression_ratio": 1.752988047808765,
        "end": 543,
        "id": 136,
        "no_speech_prob": 0.0053848098032176495,
        "seek": 51700,
        "start": 539,
        "temperature": 0,
        "text": " Going to my code, I can say, and I'm going to call these rows.",
        "tokens": [
          51464,
          10963,
          281,
          452,
          3089,
          11,
          286,
          393,
          584,
          11,
          293,
          286,
          478,
          516,
          281,
          818,
          613,
          13241,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.1697138608512232,
        "compression_ratio": 1.6592592592592592,
        "end": 550,
        "id": 137,
        "no_speech_prob": 0.04603147506713867,
        "seek": 54300,
        "start": 543,
        "temperature": 0,
        "text": " The rows equals data.split, and I'm going to split by backslash n.",
        "tokens": [
          50364,
          440,
          13241,
          6915,
          1412,
          13,
          46535,
          270,
          11,
          293,
          286,
          478,
          516,
          281,
          7472,
          538,
          646,
          10418,
          1299,
          297,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.1697138608512232,
        "compression_ratio": 1.6592592592592592,
        "end": 557,
        "id": 138,
        "no_speech_prob": 0.04603147506713867,
        "seek": 54300,
        "start": 550,
        "temperature": 0,
        "text": " So backslash n is an escape character sequence that indicates a line break or new line.",
        "tokens": [
          50714,
          407,
          646,
          10418,
          1299,
          297,
          307,
          364,
          7615,
          2517,
          8310,
          300,
          16203,
          257,
          1622,
          1821,
          420,
          777,
          1622,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.1697138608512232,
        "compression_ratio": 1.6592592592592592,
        "end": 562,
        "id": 139,
        "no_speech_prob": 0.04603147506713867,
        "seek": 54300,
        "start": 557,
        "temperature": 0,
        "text": " Depending on your file format, you might need slash r also, which is like a carriage return.",
        "tokens": [
          51064,
          22539,
          322,
          428,
          3991,
          7877,
          11,
          291,
          1062,
          643,
          17330,
          367,
          611,
          11,
          597,
          307,
          411,
          257,
          31811,
          2736,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.1697138608512232,
        "compression_ratio": 1.6592592592592592,
        "end": 565,
        "id": 140,
        "no_speech_prob": 0.04603147506713867,
        "seek": 54300,
        "start": 562,
        "temperature": 0,
        "text": " You can also use something called a regular expression here.",
        "tokens": [
          51314,
          509,
          393,
          611,
          764,
          746,
          1219,
          257,
          3890,
          6114,
          510,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.1697138608512232,
        "compression_ratio": 1.6592592592592592,
        "end": 566,
        "id": 141,
        "no_speech_prob": 0.04603147506713867,
        "seek": 54300,
        "start": 565,
        "temperature": 0,
        "text": " This should also work.",
        "tokens": [
          51464,
          639,
          820,
          611,
          589,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.1697138608512232,
        "compression_ratio": 1.6592592592592592,
        "end": 570,
        "id": 142,
        "no_speech_prob": 0.04603147506713867,
        "seek": 54300,
        "start": 566,
        "temperature": 0,
        "text": " Instead of in quotes, if I have forward slashes, the delimiter is a regular expression.",
        "tokens": [
          51514,
          7156,
          295,
          294,
          19963,
          11,
          498,
          286,
          362,
          2128,
          1061,
          12808,
          11,
          264,
          1103,
          332,
          1681,
          307,
          257,
          3890,
          6114,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.1697138608512232,
        "compression_ratio": 1.6592592592592592,
        "end": 571,
        "id": 143,
        "no_speech_prob": 0.04603147506713867,
        "seek": 54300,
        "start": 570,
        "temperature": 0,
        "text": " What's a regular expression?",
        "tokens": [
          51714,
          708,
          311,
          257,
          3890,
          6114,
          30,
          51764
        ]
      },
      {
        "avg_logprob": -0.19295811286339393,
        "compression_ratio": 1.6791808873720135,
        "end": 575,
        "id": 144,
        "no_speech_prob": 0.01363655086606741,
        "seek": 57100,
        "start": 571,
        "temperature": 0,
        "text": " That's beyond the scope of what we're doing in this particular video,",
        "tokens": [
          50364,
          663,
          311,
          4399,
          264,
          11923,
          295,
          437,
          321,
          434,
          884,
          294,
          341,
          1729,
          960,
          11,
          50564
        ]
      },
      {
        "avg_logprob": -0.19295811286339393,
        "compression_ratio": 1.6791808873720135,
        "end": 578,
        "id": 145,
        "no_speech_prob": 0.01363655086606741,
        "seek": 57100,
        "start": 575,
        "temperature": 0,
        "text": " but regular expressions are so useful when doing string parsing",
        "tokens": [
          50564,
          457,
          3890,
          15277,
          366,
          370,
          4420,
          562,
          884,
          6798,
          21156,
          278,
          50714
        ]
      },
      {
        "avg_logprob": -0.19295811286339393,
        "compression_ratio": 1.6791808873720135,
        "end": 582,
        "id": 146,
        "no_speech_prob": 0.01363655086606741,
        "seek": 57100,
        "start": 578,
        "temperature": 0,
        "text": " that I will also link in this video's description to a whole series of videos that I have about that.",
        "tokens": [
          50714,
          300,
          286,
          486,
          611,
          2113,
          294,
          341,
          960,
          311,
          3855,
          281,
          257,
          1379,
          2638,
          295,
          2145,
          300,
          286,
          362,
          466,
          300,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.19295811286339393,
        "compression_ratio": 1.6791808873720135,
        "end": 587,
        "id": 147,
        "no_speech_prob": 0.01363655086606741,
        "seek": 57100,
        "start": 582,
        "temperature": 0,
        "text": " But for now, just the backslash n in single quotes should do for us.",
        "tokens": [
          50914,
          583,
          337,
          586,
          11,
          445,
          264,
          646,
          10418,
          1299,
          297,
          294,
          2167,
          19963,
          820,
          360,
          337,
          505,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.19295811286339393,
        "compression_ratio": 1.6791808873720135,
        "end": 592,
        "id": 148,
        "no_speech_prob": 0.01363655086606741,
        "seek": 57100,
        "start": 587,
        "temperature": 0,
        "text": " So I'm going to say console.log rows just to make sure that works.",
        "tokens": [
          51164,
          407,
          286,
          478,
          516,
          281,
          584,
          11076,
          13,
          4987,
          13241,
          445,
          281,
          652,
          988,
          300,
          1985,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.19295811286339393,
        "compression_ratio": 1.6791808873720135,
        "end": 593,
        "id": 149,
        "no_speech_prob": 0.01363655086606741,
        "seek": 57100,
        "start": 592,
        "temperature": 0,
        "text": " And it does.",
        "tokens": [
          51414,
          400,
          309,
          775,
          13,
          51464
        ]
      },
      {
        "avg_logprob": -0.19295811286339393,
        "compression_ratio": 1.6791808873720135,
        "end": 599,
        "id": 150,
        "no_speech_prob": 0.01363655086606741,
        "seek": 57100,
        "start": 593,
        "temperature": 0,
        "text": " So we can see here, we have, this is the raw text, and now this is split into an array with three elements.",
        "tokens": [
          51464,
          407,
          321,
          393,
          536,
          510,
          11,
          321,
          362,
          11,
          341,
          307,
          264,
          8936,
          2487,
          11,
          293,
          586,
          341,
          307,
          7472,
          666,
          364,
          10225,
          365,
          1045,
          4959,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.18013426462809246,
        "compression_ratio": 1.8007662835249043,
        "end": 602,
        "id": 151,
        "no_speech_prob": 0.009125333279371262,
        "seek": 59900,
        "start": 599,
        "temperature": 0,
        "text": " Each element is one line in that array.",
        "tokens": [
          50364,
          6947,
          4478,
          307,
          472,
          1622,
          294,
          300,
          10225,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.18013426462809246,
        "compression_ratio": 1.8007662835249043,
        "end": 606,
        "id": 152,
        "no_speech_prob": 0.009125333279371262,
        "seek": 59900,
        "start": 602,
        "temperature": 0,
        "text": " And one thing, though, we don't actually need the first row.",
        "tokens": [
          50514,
          400,
          472,
          551,
          11,
          1673,
          11,
          321,
          500,
          380,
          767,
          643,
          264,
          700,
          5386,
          13,
          50714
        ]
      },
      {
        "avg_logprob": -0.18013426462809246,
        "compression_ratio": 1.8007662835249043,
        "end": 612,
        "id": 153,
        "no_speech_prob": 0.009125333279371262,
        "seek": 59900,
        "start": 606,
        "temperature": 0,
        "text": " The first row is really useful, important information for us as human beings to think about what the data is,",
        "tokens": [
          50714,
          440,
          700,
          5386,
          307,
          534,
          4420,
          11,
          1021,
          1589,
          337,
          505,
          382,
          1952,
          8958,
          281,
          519,
          466,
          437,
          264,
          1412,
          307,
          11,
          51014
        ]
      },
      {
        "avg_logprob": -0.18013426462809246,
        "compression_ratio": 1.8007662835249043,
        "end": 615,
        "id": 154,
        "no_speech_prob": 0.009125333279371262,
        "seek": 59900,
        "start": 612,
        "temperature": 0,
        "text": " but just for parsing it, I don't actually need it.",
        "tokens": [
          51014,
          457,
          445,
          337,
          21156,
          278,
          309,
          11,
          286,
          500,
          380,
          767,
          643,
          309,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.18013426462809246,
        "compression_ratio": 1.8007662835249043,
        "end": 618,
        "id": 155,
        "no_speech_prob": 0.009125333279371262,
        "seek": 59900,
        "start": 615,
        "temperature": 0,
        "text": " An easy way that we can remove that first row is with the slice function.",
        "tokens": [
          51164,
          1107,
          1858,
          636,
          300,
          321,
          393,
          4159,
          300,
          700,
          5386,
          307,
          365,
          264,
          13153,
          2445,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.18013426462809246,
        "compression_ratio": 1.8007662835249043,
        "end": 623,
        "id": 156,
        "no_speech_prob": 0.009125333279371262,
        "seek": 59900,
        "start": 618,
        "temperature": 0,
        "text": " The slice function is an array function in JavaScript that makes a copy of an array,",
        "tokens": [
          51314,
          440,
          13153,
          2445,
          307,
          364,
          10225,
          2445,
          294,
          15778,
          300,
          1669,
          257,
          5055,
          295,
          364,
          10225,
          11,
          51564
        ]
      },
      {
        "avg_logprob": -0.18013426462809246,
        "compression_ratio": 1.8007662835249043,
        "end": 625,
        "id": 157,
        "no_speech_prob": 0.009125333279371262,
        "seek": 59900,
        "start": 623,
        "temperature": 0,
        "text": " but a portion of the array from beginning to end.",
        "tokens": [
          51564,
          457,
          257,
          8044,
          295,
          264,
          10225,
          490,
          2863,
          281,
          917,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.18936979972710044,
        "compression_ratio": 1.7574468085106383,
        "end": 633,
        "id": 158,
        "no_speech_prob": 0.055003002285957336,
        "seek": 62500,
        "start": 626,
        "temperature": 0,
        "text": " So I want the array all the way to the end, but I want it from the element 2, which is index 1, to the end.",
        "tokens": [
          50414,
          407,
          286,
          528,
          264,
          10225,
          439,
          264,
          636,
          281,
          264,
          917,
          11,
          457,
          286,
          528,
          309,
          490,
          264,
          4478,
          568,
          11,
          597,
          307,
          8186,
          502,
          11,
          281,
          264,
          917,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.18936979972710044,
        "compression_ratio": 1.7574468085106383,
        "end": 641,
        "id": 159,
        "no_speech_prob": 0.055003002285957336,
        "seek": 62500,
        "start": 633,
        "temperature": 0,
        "text": " So in other words, what I can do is I can say data split by line break dot slice index 1.",
        "tokens": [
          50764,
          407,
          294,
          661,
          2283,
          11,
          437,
          286,
          393,
          360,
          307,
          286,
          393,
          584,
          1412,
          7472,
          538,
          1622,
          1821,
          5893,
          13153,
          8186,
          502,
          13,
          51164
        ]
      },
      {
        "avg_logprob": -0.18936979972710044,
        "compression_ratio": 1.7574468085106383,
        "end": 648,
        "id": 160,
        "no_speech_prob": 0.055003002285957336,
        "seek": 62500,
        "start": 641,
        "temperature": 0,
        "text": " So this will basically delete the zero element and give me a copy of the array from index 1 to the end.",
        "tokens": [
          51164,
          407,
          341,
          486,
          1936,
          12097,
          264,
          4018,
          4478,
          293,
          976,
          385,
          257,
          5055,
          295,
          264,
          10225,
          490,
          8186,
          502,
          281,
          264,
          917,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.18936979972710044,
        "compression_ratio": 1.7574468085106383,
        "end": 651,
        "id": 161,
        "no_speech_prob": 0.055003002285957336,
        "seek": 62500,
        "start": 648,
        "temperature": 0,
        "text": " And if we go back to the browser, we can see, there we go.",
        "tokens": [
          51514,
          400,
          498,
          321,
          352,
          646,
          281,
          264,
          11185,
          11,
          321,
          393,
          536,
          11,
          456,
          321,
          352,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.18936979972710044,
        "compression_ratio": 1.7574468085106383,
        "end": 654,
        "id": 162,
        "no_speech_prob": 0.055003002285957336,
        "seek": 62500,
        "start": 651,
        "temperature": 0,
        "text": " We now have an array with just these two rows in it.",
        "tokens": [
          51664,
          492,
          586,
          362,
          364,
          10225,
          365,
          445,
          613,
          732,
          13241,
          294,
          309,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.2025438088637132,
        "compression_ratio": 1.611353711790393,
        "end": 657,
        "id": 163,
        "no_speech_prob": 0.00002282795321661979,
        "seek": 65400,
        "start": 654,
        "temperature": 0,
        "text": " Perfect. So what's the next step?",
        "tokens": [
          50364,
          10246,
          13,
          407,
          437,
          311,
          264,
          958,
          1823,
          30,
          50514
        ]
      },
      {
        "avg_logprob": -0.2025438088637132,
        "compression_ratio": 1.611353711790393,
        "end": 662,
        "id": 164,
        "no_speech_prob": 0.00002282795321661979,
        "seek": 65400,
        "start": 657,
        "temperature": 0,
        "text": " The next step is splitting each one of these rows into all of the fields.",
        "tokens": [
          50514,
          440,
          958,
          1823,
          307,
          30348,
          1184,
          472,
          295,
          613,
          13241,
          666,
          439,
          295,
          264,
          7909,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.2025438088637132,
        "compression_ratio": 1.611353711790393,
        "end": 665,
        "id": 165,
        "no_speech_prob": 0.00002282795321661979,
        "seek": 65400,
        "start": 662,
        "temperature": 0,
        "text": " And truth of the matter is, I only need, for what I'm doing right now,",
        "tokens": [
          50764,
          400,
          3494,
          295,
          264,
          1871,
          307,
          11,
          286,
          787,
          643,
          11,
          337,
          437,
          286,
          478,
          884,
          558,
          586,
          11,
          50914
        ]
      },
      {
        "avg_logprob": -0.2025438088637132,
        "compression_ratio": 1.611353711790393,
        "end": 671,
        "id": 166,
        "no_speech_prob": 0.00002282795321661979,
        "seek": 65400,
        "start": 665,
        "temperature": 0,
        "text": " I only need the year and the difference from the mean temperature globally.",
        "tokens": [
          50914,
          286,
          787,
          643,
          264,
          1064,
          293,
          264,
          2649,
          490,
          264,
          914,
          4292,
          18958,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.2025438088637132,
        "compression_ratio": 1.611353711790393,
        "end": 674,
        "id": 167,
        "no_speech_prob": 0.00002282795321661979,
        "seek": 65400,
        "start": 671,
        "temperature": 0,
        "text": " And that's this data, this negative.18.",
        "tokens": [
          51214,
          400,
          300,
          311,
          341,
          1412,
          11,
          341,
          3671,
          2411,
          6494,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.2025438088637132,
        "compression_ratio": 1.611353711790393,
        "end": 682,
        "id": 168,
        "no_speech_prob": 0.00002282795321661979,
        "seek": 65400,
        "start": 674,
        "temperature": 0,
        "text": " So I'm now going to say for let i equal 0, i is less than rows dot length.",
        "tokens": [
          51364,
          407,
          286,
          478,
          586,
          516,
          281,
          584,
          337,
          718,
          741,
          2681,
          1958,
          11,
          741,
          307,
          1570,
          813,
          13241,
          5893,
          4641,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.19263195541669736,
        "compression_ratio": 1.6596638655462186,
        "end": 684,
        "id": 169,
        "no_speech_prob": 0.07585416734218597,
        "seek": 68200,
        "start": 682,
        "temperature": 0,
        "text": " And I'm going to just iterate over all of the rows.",
        "tokens": [
          50364,
          400,
          286,
          478,
          516,
          281,
          445,
          44497,
          670,
          439,
          295,
          264,
          13241,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.19263195541669736,
        "compression_ratio": 1.6596638655462186,
        "end": 688,
        "id": 170,
        "no_speech_prob": 0.07585416734218597,
        "seek": 68200,
        "start": 684,
        "temperature": 0,
        "text": " You know what? This would be a nice time for a for each loop.",
        "tokens": [
          50464,
          509,
          458,
          437,
          30,
          639,
          576,
          312,
          257,
          1481,
          565,
          337,
          257,
          337,
          1184,
          6367,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.19263195541669736,
        "compression_ratio": 1.6596638655462186,
        "end": 697,
        "id": 171,
        "no_speech_prob": 0.07585416734218597,
        "seek": 68200,
        "start": 688,
        "temperature": 0,
        "text": " So I'm going to do rows dot for each, for each row.",
        "tokens": [
          50664,
          407,
          286,
          478,
          516,
          281,
          360,
          13241,
          5893,
          337,
          1184,
          11,
          337,
          1184,
          5386,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.19263195541669736,
        "compression_ratio": 1.6596638655462186,
        "end": 701,
        "id": 172,
        "no_speech_prob": 0.07585416734218597,
        "seek": 68200,
        "start": 697,
        "temperature": 0,
        "text": " And once again, I'm using the ES6 JavaScript arrow syntax.",
        "tokens": [
          51114,
          400,
          1564,
          797,
          11,
          286,
          478,
          1228,
          264,
          12564,
          21,
          15778,
          11610,
          28431,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.19263195541669736,
        "compression_ratio": 1.6596638655462186,
        "end": 707,
        "id": 173,
        "no_speech_prob": 0.07585416734218597,
        "seek": 68200,
        "start": 701,
        "temperature": 0,
        "text": " So for each is a higher order function that allows me to apply something to every element of the array.",
        "tokens": [
          51314,
          407,
          337,
          1184,
          307,
          257,
          2946,
          1668,
          2445,
          300,
          4045,
          385,
          281,
          3079,
          746,
          281,
          633,
          4478,
          295,
          264,
          10225,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.19263195541669736,
        "compression_ratio": 1.6596638655462186,
        "end": 710,
        "id": 174,
        "no_speech_prob": 0.07585416734218597,
        "seek": 68200,
        "start": 707,
        "temperature": 0,
        "text": " And each element of the array is represented by this variable row.",
        "tokens": [
          51614,
          400,
          1184,
          4478,
          295,
          264,
          10225,
          307,
          10379,
          538,
          341,
          7006,
          5386,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.1927171875448788,
        "compression_ratio": 1.912280701754386,
        "end": 716,
        "id": 175,
        "no_speech_prob": 0.028006648644804955,
        "seek": 71000,
        "start": 710,
        "temperature": 0,
        "text": " So if I just say console dot log row and go look in here, we can see, there we go.",
        "tokens": [
          50364,
          407,
          498,
          286,
          445,
          584,
          11076,
          5893,
          3565,
          5386,
          293,
          352,
          574,
          294,
          510,
          11,
          321,
          393,
          536,
          11,
          456,
          321,
          352,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.1927171875448788,
        "compression_ratio": 1.912280701754386,
        "end": 719,
        "id": 176,
        "no_speech_prob": 0.028006648644804955,
        "seek": 71000,
        "start": 716,
        "temperature": 0,
        "text": " We're console logging each row. But that's not what I want to do.",
        "tokens": [
          50664,
          492,
          434,
          11076,
          27991,
          1184,
          5386,
          13,
          583,
          300,
          311,
          406,
          437,
          286,
          528,
          281,
          360,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.1927171875448788,
        "compression_ratio": 1.912280701754386,
        "end": 723,
        "id": 177,
        "no_speech_prob": 0.028006648644804955,
        "seek": 71000,
        "start": 719,
        "temperature": 0,
        "text": " I want to say const, you know what I'm going to do?",
        "tokens": [
          50814,
          286,
          528,
          281,
          584,
          1817,
          11,
          291,
          458,
          437,
          286,
          478,
          516,
          281,
          360,
          30,
          51014
        ]
      },
      {
        "avg_logprob": -0.1927171875448788,
        "compression_ratio": 1.912280701754386,
        "end": 728,
        "id": 178,
        "no_speech_prob": 0.028006648644804955,
        "seek": 71000,
        "start": 723,
        "temperature": 0,
        "text": " I'm going to call this row and I'm going to call this ELT for like element of the array.",
        "tokens": [
          51014,
          286,
          478,
          516,
          281,
          818,
          341,
          5386,
          293,
          286,
          478,
          516,
          281,
          818,
          341,
          14426,
          51,
          337,
          411,
          4478,
          295,
          264,
          10225,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.1927171875448788,
        "compression_ratio": 1.912280701754386,
        "end": 733,
        "id": 179,
        "no_speech_prob": 0.028006648644804955,
        "seek": 71000,
        "start": 728,
        "temperature": 0,
        "text": " And I'll say row equals ELT split by commas.",
        "tokens": [
          51264,
          400,
          286,
          603,
          584,
          5386,
          6915,
          14426,
          51,
          7472,
          538,
          800,
          296,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.1927171875448788,
        "compression_ratio": 1.912280701754386,
        "end": 734,
        "id": 180,
        "no_speech_prob": 0.028006648644804955,
        "seek": 71000,
        "start": 733,
        "temperature": 0,
        "text": " And then I'll console log row.",
        "tokens": [
          51514,
          400,
          550,
          286,
          603,
          11076,
          3565,
          5386,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.1927171875448788,
        "compression_ratio": 1.912280701754386,
        "end": 739,
        "id": 181,
        "no_speech_prob": 0.028006648644804955,
        "seek": 71000,
        "start": 734,
        "temperature": 0,
        "text": " So what I want to do is for each row, I want to split it up by commas.",
        "tokens": [
          51564,
          407,
          437,
          286,
          528,
          281,
          360,
          307,
          337,
          1184,
          5386,
          11,
          286,
          528,
          281,
          7472,
          309,
          493,
          538,
          800,
          296,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.22039296627044677,
        "compression_ratio": 1.5914634146341464,
        "end": 742,
        "id": 182,
        "no_speech_prob": 0.020331965759396553,
        "seek": 73900,
        "start": 739,
        "temperature": 0,
        "text": " And just to be, so let's make sure that works.",
        "tokens": [
          50364,
          400,
          445,
          281,
          312,
          11,
          370,
          718,
          311,
          652,
          988,
          300,
          1985,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.22039296627044677,
        "compression_ratio": 1.5914634146341464,
        "end": 744,
        "id": 183,
        "no_speech_prob": 0.020331965759396553,
        "seek": 73900,
        "start": 742,
        "temperature": 0,
        "text": " Let's go and we can see.",
        "tokens": [
          50514,
          961,
          311,
          352,
          293,
          321,
          393,
          536,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.22039296627044677,
        "compression_ratio": 1.5914634146341464,
        "end": 751,
        "id": 184,
        "no_speech_prob": 0.020331965759396553,
        "seek": 73900,
        "start": 744,
        "temperature": 0,
        "text": " Okay, so we can see that I've got both 1880 as an array and 1881 as an array.",
        "tokens": [
          50614,
          1033,
          11,
          370,
          321,
          393,
          536,
          300,
          286,
          600,
          658,
          1293,
          2443,
          4702,
          382,
          364,
          10225,
          293,
          2443,
          32875,
          382,
          364,
          10225,
          13,
          50964
        ]
      },
      {
        "avg_logprob": -0.22039296627044677,
        "compression_ratio": 1.5914634146341464,
        "end": 757,
        "id": 185,
        "no_speech_prob": 0.020331965759396553,
        "seek": 73900,
        "start": 751,
        "temperature": 0,
        "text": " And then I want to say const year equals row index zero.",
        "tokens": [
          50964,
          400,
          550,
          286,
          528,
          281,
          584,
          1817,
          1064,
          6915,
          5386,
          8186,
          4018,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.22039296627044677,
        "compression_ratio": 1.5914634146341464,
        "end": 766,
        "id": 186,
        "no_speech_prob": 0.020331965759396553,
        "seek": 73900,
        "start": 757,
        "temperature": 0,
        "text": " And then const temp, temperature equals row index one.",
        "tokens": [
          51264,
          400,
          550,
          1817,
          18274,
          11,
          4292,
          6915,
          5386,
          8186,
          472,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.17947551939222547,
        "compression_ratio": 1.5551181102362204,
        "end": 770,
        "id": 187,
        "no_speech_prob": 0.083886057138443,
        "seek": 76600,
        "start": 766,
        "temperature": 0,
        "text": " Let me remove the first console log to sort of clean things up a little bit.",
        "tokens": [
          50364,
          961,
          385,
          4159,
          264,
          700,
          11076,
          3565,
          281,
          1333,
          295,
          2541,
          721,
          493,
          257,
          707,
          857,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.17947551939222547,
        "compression_ratio": 1.5551181102362204,
        "end": 774,
        "id": 188,
        "no_speech_prob": 0.083886057138443,
        "seek": 76600,
        "start": 770,
        "temperature": 0,
        "text": " And let me run this and I should see just 1880 temperature, 1881 temperature.",
        "tokens": [
          50564,
          400,
          718,
          385,
          1190,
          341,
          293,
          286,
          820,
          536,
          445,
          2443,
          4702,
          4292,
          11,
          2443,
          32875,
          4292,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.17947551939222547,
        "compression_ratio": 1.5551181102362204,
        "end": 776,
        "id": 189,
        "no_speech_prob": 0.083886057138443,
        "seek": 76600,
        "start": 774,
        "temperature": 0,
        "text": " And that's exactly what I have here.",
        "tokens": [
          50764,
          400,
          300,
          311,
          2293,
          437,
          286,
          362,
          510,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.17947551939222547,
        "compression_ratio": 1.5551181102362204,
        "end": 783,
        "id": 190,
        "no_speech_prob": 0.083886057138443,
        "seek": 76600,
        "start": 776,
        "temperature": 0,
        "text": " And guess what? Now that we've worked this out, I can go and use the full data set.",
        "tokens": [
          50864,
          400,
          2041,
          437,
          30,
          823,
          300,
          321,
          600,
          2732,
          341,
          484,
          11,
          286,
          393,
          352,
          293,
          764,
          264,
          1577,
          1412,
          992,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.17947551939222547,
        "compression_ratio": 1.5551181102362204,
        "end": 789,
        "id": 191,
        "no_speech_prob": 0.083886057138443,
        "seek": 76600,
        "start": 783,
        "temperature": 0,
        "text": " So I'm going to just change from test dot CSV to this more complicated file name,",
        "tokens": [
          51214,
          407,
          286,
          478,
          516,
          281,
          445,
          1319,
          490,
          1500,
          5893,
          48814,
          281,
          341,
          544,
          6179,
          3991,
          1315,
          11,
          51514
        ]
      },
      {
        "avg_logprob": -0.17947551939222547,
        "compression_ratio": 1.5551181102362204,
        "end": 793,
        "id": 192,
        "no_speech_prob": 0.083886057138443,
        "seek": 76600,
        "start": 789,
        "temperature": 0,
        "text": " zone annual dot TS plus DSST dot CSV.",
        "tokens": [
          51514,
          6668,
          9784,
          5893,
          37645,
          1804,
          15816,
          6840,
          5893,
          48814,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.16420948934212004,
        "compression_ratio": 1.7152777777777777,
        "end": 797,
        "id": 193,
        "no_speech_prob": 0.02595674991607666,
        "seek": 79300,
        "start": 793,
        "temperature": 0,
        "text": " So that's the full data set that I downloaded from the NASA website.",
        "tokens": [
          50364,
          407,
          300,
          311,
          264,
          1577,
          1412,
          992,
          300,
          286,
          21748,
          490,
          264,
          12077,
          3144,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.16420948934212004,
        "compression_ratio": 1.7152777777777777,
        "end": 798,
        "id": 194,
        "no_speech_prob": 0.02595674991607666,
        "seek": 79300,
        "start": 797,
        "temperature": 0,
        "text": " I'm going to press save.",
        "tokens": [
          50564,
          286,
          478,
          516,
          281,
          1886,
          3155,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.16420948934212004,
        "compression_ratio": 1.7152777777777777,
        "end": 801,
        "id": 195,
        "no_speech_prob": 0.02595674991607666,
        "seek": 79300,
        "start": 798,
        "temperature": 0,
        "text": " I'm going to go back and we can see, there we go.",
        "tokens": [
          50614,
          286,
          478,
          516,
          281,
          352,
          646,
          293,
          321,
          393,
          536,
          11,
          456,
          321,
          352,
          13,
          50764
        ]
      },
      {
        "avg_logprob": -0.16420948934212004,
        "compression_ratio": 1.7152777777777777,
        "end": 807,
        "id": 196,
        "no_speech_prob": 0.02595674991607666,
        "seek": 79300,
        "start": 801,
        "temperature": 0,
        "text": " We have every single year and the difference from the mean temperature next to it.",
        "tokens": [
          50764,
          492,
          362,
          633,
          2167,
          1064,
          293,
          264,
          2649,
          490,
          264,
          914,
          4292,
          958,
          281,
          309,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.16420948934212004,
        "compression_ratio": 1.7152777777777777,
        "end": 812,
        "id": 197,
        "no_speech_prob": 0.02595674991607666,
        "seek": 79300,
        "start": 807,
        "temperature": 0,
        "text": " Now I just noticed if I go all the way to the bottom, there's a little bit of an extra undefined here.",
        "tokens": [
          51064,
          823,
          286,
          445,
          5694,
          498,
          286,
          352,
          439,
          264,
          636,
          281,
          264,
          2767,
          11,
          456,
          311,
          257,
          707,
          857,
          295,
          364,
          2857,
          674,
          5666,
          2001,
          510,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.16420948934212004,
        "compression_ratio": 1.7152777777777777,
        "end": 817,
        "id": 198,
        "no_speech_prob": 0.02595674991607666,
        "seek": 79300,
        "start": 812,
        "temperature": 0,
        "text": " So it looks like probably I need to clean up my data file a tiny bit.",
        "tokens": [
          51314,
          407,
          309,
          1542,
          411,
          1391,
          286,
          643,
          281,
          2541,
          493,
          452,
          1412,
          3991,
          257,
          5870,
          857,
          13,
          51564
        ]
      },
      {
        "avg_logprob": -0.16420948934212004,
        "compression_ratio": 1.7152777777777777,
        "end": 819,
        "id": 199,
        "no_speech_prob": 0.02595674991607666,
        "seek": 79300,
        "start": 817,
        "temperature": 0,
        "text": " I'm assuming there's an extra line break at the bottom.",
        "tokens": [
          51564,
          286,
          478,
          11926,
          456,
          311,
          364,
          2857,
          1622,
          1821,
          412,
          264,
          2767,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.16420948934212004,
        "compression_ratio": 1.7152777777777777,
        "end": 822,
        "id": 200,
        "no_speech_prob": 0.02595674991607666,
        "seek": 79300,
        "start": 819,
        "temperature": 0,
        "text": " You can see there's an extra line 141.",
        "tokens": [
          51664,
          509,
          393,
          536,
          456,
          311,
          364,
          2857,
          1622,
          3499,
          16,
          13,
          51814
        ]
      },
      {
        "avg_logprob": -0.17185150782267253,
        "compression_ratio": 1.6035714285714286,
        "end": 826,
        "id": 201,
        "no_speech_prob": 0.0037071770057082176,
        "seek": 82200,
        "start": 822,
        "temperature": 0,
        "text": " And so I'm going to just delete that, hit save, and then we can see, there we go.",
        "tokens": [
          50364,
          400,
          370,
          286,
          478,
          516,
          281,
          445,
          12097,
          300,
          11,
          2045,
          3155,
          11,
          293,
          550,
          321,
          393,
          536,
          11,
          456,
          321,
          352,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.17185150782267253,
        "compression_ratio": 1.6035714285714286,
        "end": 828,
        "id": 202,
        "no_speech_prob": 0.0037071770057082176,
        "seek": 82200,
        "start": 826,
        "temperature": 0,
        "text": " Undefined is no longer appearing there.",
        "tokens": [
          50564,
          2719,
          5666,
          2001,
          307,
          572,
          2854,
          19870,
          456,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.17185150782267253,
        "compression_ratio": 1.6035714285714286,
        "end": 835,
        "id": 203,
        "no_speech_prob": 0.0037071770057082176,
        "seek": 82200,
        "start": 828,
        "temperature": 0,
        "text": " So it's important for me to mention that I have kind of created this very pre-prepared easy situation.",
        "tokens": [
          50664,
          407,
          309,
          311,
          1021,
          337,
          385,
          281,
          2152,
          300,
          286,
          362,
          733,
          295,
          2942,
          341,
          588,
          659,
          12,
          3712,
          45573,
          1858,
          2590,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.17185150782267253,
        "compression_ratio": 1.6035714285714286,
        "end": 841,
        "id": 204,
        "no_speech_prob": 0.0037071770057082176,
        "seek": 82200,
        "start": 835,
        "temperature": 0,
        "text": " I know that this data file has no empty data, no mistakes in it, no empty pieces.",
        "tokens": [
          51014,
          286,
          458,
          300,
          341,
          1412,
          3991,
          575,
          572,
          6707,
          1412,
          11,
          572,
          8038,
          294,
          309,
          11,
          572,
          6707,
          3755,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.17185150782267253,
        "compression_ratio": 1.6035714285714286,
        "end": 843,
        "id": 205,
        "no_speech_prob": 0.0037071770057082176,
        "seek": 82200,
        "start": 841,
        "temperature": 0,
        "text": " It's actually already in CSV format.",
        "tokens": [
          51314,
          467,
          311,
          767,
          1217,
          294,
          48814,
          7877,
          13,
          51414
        ]
      },
      {
        "avg_logprob": -0.17185150782267253,
        "compression_ratio": 1.6035714285714286,
        "end": 848,
        "id": 206,
        "no_speech_prob": 0.0037071770057082176,
        "seek": 82200,
        "start": 843,
        "temperature": 0,
        "text": " Just removing that little extra line break at the end was like a tiny bit of cleanup that I needed to do.",
        "tokens": [
          51414,
          1449,
          12720,
          300,
          707,
          2857,
          1622,
          1821,
          412,
          264,
          917,
          390,
          411,
          257,
          5870,
          857,
          295,
          40991,
          300,
          286,
          2978,
          281,
          360,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.17672469967701396,
        "compression_ratio": 1.6842105263157894,
        "end": 854,
        "id": 207,
        "no_speech_prob": 0.15609025955200195,
        "seek": 84800,
        "start": 849,
        "temperature": 0,
        "text": " And in fact, there's a function in JavaScript that just said data.trim that would have cleaned that up for me anyway.",
        "tokens": [
          50414,
          400,
          294,
          1186,
          11,
          456,
          311,
          257,
          2445,
          294,
          15778,
          300,
          445,
          848,
          1412,
          13,
          83,
          5565,
          300,
          576,
          362,
          16146,
          300,
          493,
          337,
          385,
          4033,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.17672469967701396,
        "compression_ratio": 1.6842105263157894,
        "end": 859,
        "id": 208,
        "no_speech_prob": 0.15609025955200195,
        "seek": 84800,
        "start": 854,
        "temperature": 0,
        "text": " But I do want to emphasize, what if the data actually has commas in it?",
        "tokens": [
          50664,
          583,
          286,
          360,
          528,
          281,
          16078,
          11,
          437,
          498,
          264,
          1412,
          767,
          575,
          800,
          296,
          294,
          309,
          30,
          50914
        ]
      },
      {
        "avg_logprob": -0.17672469967701396,
        "compression_ratio": 1.6842105263157894,
        "end": 863,
        "id": 209,
        "no_speech_prob": 0.15609025955200195,
        "seek": 84800,
        "start": 859,
        "temperature": 0,
        "text": " So if the data has commas in it, my parsing system is going to break down.",
        "tokens": [
          50914,
          407,
          498,
          264,
          1412,
          575,
          800,
          296,
          294,
          309,
          11,
          452,
          21156,
          278,
          1185,
          307,
          516,
          281,
          1821,
          760,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.17672469967701396,
        "compression_ratio": 1.6842105263157894,
        "end": 865,
        "id": 210,
        "no_speech_prob": 0.15609025955200195,
        "seek": 84800,
        "start": 863,
        "temperature": 0,
        "text": " Well, there are conventions for this.",
        "tokens": [
          51114,
          1042,
          11,
          456,
          366,
          33520,
          337,
          341,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.17672469967701396,
        "compression_ratio": 1.6842105263157894,
        "end": 873,
        "id": 211,
        "no_speech_prob": 0.15609025955200195,
        "seek": 84800,
        "start": 865,
        "temperature": 0,
        "text": " CSV files actually use quotes around the information that shouldn't be split where there actually is a comma in there.",
        "tokens": [
          51214,
          48814,
          7098,
          767,
          764,
          19963,
          926,
          264,
          1589,
          300,
          4659,
          380,
          312,
          7472,
          689,
          456,
          767,
          307,
          257,
          22117,
          294,
          456,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.17672469967701396,
        "compression_ratio": 1.6842105263157894,
        "end": 876,
        "id": 212,
        "no_speech_prob": 0.15609025955200195,
        "seek": 84800,
        "start": 873,
        "temperature": 0,
        "text": " You might find that your data isn't already in CSV format.",
        "tokens": [
          51614,
          509,
          1062,
          915,
          300,
          428,
          1412,
          1943,
          380,
          1217,
          294,
          48814,
          7877,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.1947576567882628,
        "compression_ratio": 1.667785234899329,
        "end": 878,
        "id": 213,
        "no_speech_prob": 0.05500060319900513,
        "seek": 87600,
        "start": 876,
        "temperature": 0,
        "text": " You found this data you want to use, but it's a PDF.",
        "tokens": [
          50364,
          509,
          1352,
          341,
          1412,
          291,
          528,
          281,
          764,
          11,
          457,
          309,
          311,
          257,
          17752,
          13,
          50464
        ]
      },
      {
        "avg_logprob": -0.1947576567882628,
        "compression_ratio": 1.667785234899329,
        "end": 880,
        "id": 214,
        "no_speech_prob": 0.05500060319900513,
        "seek": 87600,
        "start": 878,
        "temperature": 0,
        "text": " It's like scanned.",
        "tokens": [
          50464,
          467,
          311,
          411,
          45089,
          13,
          50564
        ]
      },
      {
        "avg_logprob": -0.1947576567882628,
        "compression_ratio": 1.667785234899329,
        "end": 887,
        "id": 215,
        "no_speech_prob": 0.05500060319900513,
        "seek": 87600,
        "start": 880,
        "temperature": 0,
        "text": " Well, you're going to have to do optical character recognition to turn it into data that you can work with or transcribe it manually.",
        "tokens": [
          50564,
          1042,
          11,
          291,
          434,
          516,
          281,
          362,
          281,
          360,
          20674,
          2517,
          11150,
          281,
          1261,
          309,
          666,
          1412,
          300,
          291,
          393,
          589,
          365,
          420,
          1145,
          8056,
          309,
          16945,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.1947576567882628,
        "compression_ratio": 1.667785234899329,
        "end": 891,
        "id": 216,
        "no_speech_prob": 0.05500060319900513,
        "seek": 87600,
        "start": 887,
        "temperature": 0,
        "text": " This might be data that you want to collect yourself from your own sensor readings.",
        "tokens": [
          50914,
          639,
          1062,
          312,
          1412,
          300,
          291,
          528,
          281,
          2500,
          1803,
          490,
          428,
          1065,
          10200,
          27319,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.1947576567882628,
        "compression_ratio": 1.667785234899329,
        "end": 896,
        "id": 217,
        "no_speech_prob": 0.05500060319900513,
        "seek": 87600,
        "start": 891,
        "temperature": 0,
        "text": " So there is a ton of work that can go into prepping and cleaning data for a project like this.",
        "tokens": [
          51114,
          407,
          456,
          307,
          257,
          2952,
          295,
          589,
          300,
          393,
          352,
          666,
          659,
          3759,
          293,
          8924,
          1412,
          337,
          257,
          1716,
          411,
          341,
          13,
          51364
        ]
      },
      {
        "avg_logprob": -0.1947576567882628,
        "compression_ratio": 1.667785234899329,
        "end": 903,
        "id": 218,
        "no_speech_prob": 0.05500060319900513,
        "seek": 87600,
        "start": 896,
        "temperature": 0,
        "text": " But we're getting started here in the sort of basic sense of just already having an easy-to-use data set for us.",
        "tokens": [
          51364,
          583,
          321,
          434,
          1242,
          1409,
          510,
          294,
          264,
          1333,
          295,
          3875,
          2020,
          295,
          445,
          1217,
          1419,
          364,
          1858,
          12,
          1353,
          12,
          438,
          1412,
          992,
          337,
          505,
          13,
          51714
        ]
      },
      {
        "avg_logprob": -0.18112227876307602,
        "compression_ratio": 1.8588235294117648,
        "end": 908,
        "id": 219,
        "no_speech_prob": 0.24796809256076813,
        "seek": 90300,
        "start": 903,
        "temperature": 0,
        "text": " In some of the future videos, I will look at collecting your own data, and we'll see that as well.",
        "tokens": [
          50364,
          682,
          512,
          295,
          264,
          2027,
          2145,
          11,
          286,
          486,
          574,
          412,
          12510,
          428,
          1065,
          1412,
          11,
          293,
          321,
          603,
          536,
          300,
          382,
          731,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.18112227876307602,
        "compression_ratio": 1.8588235294117648,
        "end": 913,
        "id": 220,
        "no_speech_prob": 0.24796809256076813,
        "seek": 90300,
        "start": 908,
        "temperature": 0,
        "text": " Another little quick bit of refactoring that I could do here is I think this rows variable is a little bit confusing.",
        "tokens": [
          50614,
          3996,
          707,
          1702,
          857,
          295,
          1895,
          578,
          3662,
          300,
          286,
          727,
          360,
          510,
          307,
          286,
          519,
          341,
          13241,
          7006,
          307,
          257,
          707,
          857,
          13181,
          13,
          50864
        ]
      },
      {
        "avg_logprob": -0.18112227876307602,
        "compression_ratio": 1.8588235294117648,
        "end": 918,
        "id": 221,
        "no_speech_prob": 0.24796809256076813,
        "seek": 90300,
        "start": 913,
        "temperature": 0,
        "text": " This is really ultimately the variable that holds the entire table.",
        "tokens": [
          50864,
          639,
          307,
          534,
          6284,
          264,
          7006,
          300,
          9190,
          264,
          2302,
          3199,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.18112227876307602,
        "compression_ratio": 1.8588235294117648,
        "end": 921,
        "id": 222,
        "no_speech_prob": 0.24796809256076813,
        "seek": 90300,
        "start": 918,
        "temperature": 0,
        "text": " I'm taking the raw data, splitting it up into rows.",
        "tokens": [
          51114,
          286,
          478,
          1940,
          264,
          8936,
          1412,
          11,
          30348,
          309,
          493,
          666,
          13241,
          13,
          51264
        ]
      },
      {
        "avg_logprob": -0.18112227876307602,
        "compression_ratio": 1.8588235294117648,
        "end": 922,
        "id": 223,
        "no_speech_prob": 0.24796809256076813,
        "seek": 90300,
        "start": 921,
        "temperature": 0,
        "text": " That's the table.",
        "tokens": [
          51264,
          663,
          311,
          264,
          3199,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.18112227876307602,
        "compression_ratio": 1.8588235294117648,
        "end": 931,
        "id": 224,
        "no_speech_prob": 0.24796809256076813,
        "seek": 90300,
        "start": 922,
        "temperature": 0,
        "text": " And now taking the raw data and splitting it up into rows, that's really the table that's holding all that information.",
        "tokens": [
          51314,
          400,
          586,
          1940,
          264,
          8936,
          1412,
          293,
          30348,
          309,
          493,
          666,
          13241,
          11,
          300,
          311,
          534,
          264,
          3199,
          300,
          311,
          5061,
          439,
          300,
          1589,
          13,
          51764
        ]
      },
      {
        "avg_logprob": -0.1636002175759949,
        "compression_ratio": 1.9029850746268657,
        "end": 934,
        "id": 225,
        "no_speech_prob": 0.001956980675458908,
        "seek": 93100,
        "start": 931,
        "temperature": 0,
        "text": " So the table, this is really looking not at each element of the array.",
        "tokens": [
          50364,
          407,
          264,
          3199,
          11,
          341,
          307,
          534,
          1237,
          406,
          412,
          1184,
          4478,
          295,
          264,
          10225,
          13,
          50514
        ]
      },
      {
        "avg_logprob": -0.1636002175759949,
        "compression_ratio": 1.9029850746268657,
        "end": 937,
        "id": 226,
        "no_speech_prob": 0.001956980675458908,
        "seek": 93100,
        "start": 934,
        "temperature": 0,
        "text": " This is now looking at each row of the table.",
        "tokens": [
          50514,
          639,
          307,
          586,
          1237,
          412,
          1184,
          5386,
          295,
          264,
          3199,
          13,
          50664
        ]
      },
      {
        "avg_logprob": -0.1636002175759949,
        "compression_ratio": 1.9029850746268657,
        "end": 940,
        "id": 227,
        "no_speech_prob": 0.001956980675458908,
        "seek": 93100,
        "start": 937,
        "temperature": 0,
        "text": " And then it would make sense to call this is splitting up.",
        "tokens": [
          50664,
          400,
          550,
          309,
          576,
          652,
          2020,
          281,
          818,
          341,
          307,
          30348,
          493,
          13,
          50814
        ]
      },
      {
        "avg_logprob": -0.1636002175759949,
        "compression_ratio": 1.9029850746268657,
        "end": 942,
        "id": 228,
        "no_speech_prob": 0.001956980675458908,
        "seek": 93100,
        "start": 940,
        "temperature": 0,
        "text": " This is an array that's all the columns.",
        "tokens": [
          50814,
          639,
          307,
          364,
          10225,
          300,
          311,
          439,
          264,
          13766,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.1636002175759949,
        "compression_ratio": 1.9029850746268657,
        "end": 944,
        "id": 229,
        "no_speech_prob": 0.001956980675458908,
        "seek": 93100,
        "start": 942,
        "temperature": 0,
        "text": " So maybe I'll write that fully out.",
        "tokens": [
          50914,
          407,
          1310,
          286,
          603,
          2464,
          300,
          4498,
          484,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.1636002175759949,
        "compression_ratio": 1.9029850746268657,
        "end": 945,
        "id": 230,
        "no_speech_prob": 0.001956980675458908,
        "seek": 93100,
        "start": 944,
        "temperature": 0,
        "text": " So this is columns.",
        "tokens": [
          51014,
          407,
          341,
          307,
          13766,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.1636002175759949,
        "compression_ratio": 1.9029850746268657,
        "end": 946,
        "id": 231,
        "no_speech_prob": 0.001956980675458908,
        "seek": 93100,
        "start": 945,
        "temperature": 0,
        "text": " This is row.",
        "tokens": [
          51064,
          639,
          307,
          5386,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.1636002175759949,
        "compression_ratio": 1.9029850746268657,
        "end": 948,
        "id": 232,
        "no_speech_prob": 0.001956980675458908,
        "seek": 93100,
        "start": 946,
        "temperature": 0,
        "text": " And then this is row.split.",
        "tokens": [
          51114,
          400,
          550,
          341,
          307,
          5386,
          13,
          46535,
          270,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.1636002175759949,
        "compression_ratio": 1.9029850746268657,
        "end": 954,
        "id": 233,
        "no_speech_prob": 0.001956980675458908,
        "seek": 93100,
        "start": 948,
        "temperature": 0,
        "text": " So I think this is a bit more clear in terms of what's actually going on here in parsing that CSV.",
        "tokens": [
          51214,
          407,
          286,
          519,
          341,
          307,
          257,
          857,
          544,
          1850,
          294,
          2115,
          295,
          437,
          311,
          767,
          516,
          322,
          510,
          294,
          21156,
          278,
          300,
          48814,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.1636002175759949,
        "compression_ratio": 1.9029850746268657,
        "end": 957,
        "id": 234,
        "no_speech_prob": 0.001956980675458908,
        "seek": 93100,
        "start": 954,
        "temperature": 0,
        "text": " So I'm getting the raw data as text.",
        "tokens": [
          51514,
          407,
          286,
          478,
          1242,
          264,
          8936,
          1412,
          382,
          2487,
          13,
          51664
        ]
      },
      {
        "avg_logprob": -0.1636002175759949,
        "compression_ratio": 1.9029850746268657,
        "end": 960,
        "id": 235,
        "no_speech_prob": 0.001956980675458908,
        "seek": 93100,
        "start": 957,
        "temperature": 0,
        "text": " I'm splitting it up, putting it into a variable called data,",
        "tokens": [
          51664,
          286,
          478,
          30348,
          309,
          493,
          11,
          3372,
          309,
          666,
          257,
          7006,
          1219,
          1412,
          11,
          51814
        ]
      },
      {
        "avg_logprob": -0.19223009638425684,
        "compression_ratio": 1.7105263157894737,
        "end": 969,
        "id": 236,
        "no_speech_prob": 0.004007251001894474,
        "seek": 96000,
        "start": 960,
        "temperature": 0,
        "text": " going through each row of the table, splitting each row into its corresponding columns,",
        "tokens": [
          50364,
          516,
          807,
          1184,
          220,
          1892,
          295,
          264,
          3199,
          11,
          30348,
          1184,
          5386,
          666,
          1080,
          11760,
          13766,
          11,
          50814
        ]
      },
      {
        "avg_logprob": -0.19223009638425684,
        "compression_ratio": 1.7105263157894737,
        "end": 974,
        "id": 237,
        "no_speech_prob": 0.004007251001894474,
        "seek": 96000,
        "start": 969,
        "temperature": 0,
        "text": " and then I forgot this now has to be columns index 0, columns index 1.",
        "tokens": [
          50814,
          293,
          550,
          286,
          5298,
          341,
          586,
          575,
          281,
          312,
          13766,
          8186,
          1958,
          11,
          13766,
          8186,
          502,
          13,
          51064
        ]
      },
      {
        "avg_logprob": -0.19223009638425684,
        "compression_ratio": 1.7105263157894737,
        "end": 975,
        "id": 238,
        "no_speech_prob": 0.004007251001894474,
        "seek": 96000,
        "start": 974,
        "temperature": 0,
        "text": " There we go.",
        "tokens": [
          51064,
          821,
          321,
          352,
          13,
          51114
        ]
      },
      {
        "avg_logprob": -0.19223009638425684,
        "compression_ratio": 1.7105263157894737,
        "end": 977,
        "id": 239,
        "no_speech_prob": 0.004007251001894474,
        "seek": 96000,
        "start": 975,
        "temperature": 0,
        "text": " I think I like this better, a little bit of refactoring.",
        "tokens": [
          51114,
          286,
          519,
          286,
          411,
          341,
          1101,
          11,
          257,
          707,
          857,
          295,
          1895,
          578,
          3662,
          13,
          51214
        ]
      },
      {
        "avg_logprob": -0.19223009638425684,
        "compression_ratio": 1.7105263157894737,
        "end": 979,
        "id": 240,
        "no_speech_prob": 0.004007251001894474,
        "seek": 96000,
        "start": 977,
        "temperature": 0,
        "text": " This is something that's very useful to do when you're working on something.",
        "tokens": [
          51214,
          639,
          307,
          746,
          300,
          311,
          588,
          4420,
          281,
          360,
          562,
          291,
          434,
          1364,
          322,
          746,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.19223009638425684,
        "compression_ratio": 1.7105263157894737,
        "end": 983,
        "id": 241,
        "no_speech_prob": 0.004007251001894474,
        "seek": 96000,
        "start": 979,
        "temperature": 0,
        "text": " Maybe you make up some variable names as you're going and you come back and refactor it to something a bit more clear.",
        "tokens": [
          51314,
          2704,
          291,
          652,
          493,
          512,
          7006,
          5288,
          382,
          291,
          434,
          516,
          293,
          291,
          808,
          646,
          293,
          1895,
          15104,
          309,
          281,
          746,
          257,
          857,
          544,
          1850,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.19223009638425684,
        "compression_ratio": 1.7105263157894737,
        "end": 985,
        "id": 242,
        "no_speech_prob": 0.004007251001894474,
        "seek": 96000,
        "start": 983,
        "temperature": 0,
        "text": " We're ready for the next step.",
        "tokens": [
          51514,
          492,
          434,
          1919,
          337,
          264,
          958,
          1823,
          13,
          51614
        ]
      },
      {
        "avg_logprob": -0.15826458401150173,
        "compression_ratio": 1.6920529801324504,
        "end": 990,
        "id": 243,
        "no_speech_prob": 0.08151166886091232,
        "seek": 98500,
        "start": 985,
        "temperature": 0,
        "text": " Now that we see the data logged there in the console, we know we could do something like add it to a DOM element.",
        "tokens": [
          50364,
          823,
          300,
          321,
          536,
          264,
          1412,
          27231,
          456,
          294,
          264,
          11076,
          11,
          321,
          458,
          321,
          727,
          360,
          746,
          411,
          909,
          309,
          281,
          257,
          35727,
          4478,
          13,
          50614
        ]
      },
      {
        "avg_logprob": -0.15826458401150173,
        "compression_ratio": 1.6920529801324504,
        "end": 996,
        "id": 244,
        "no_speech_prob": 0.08151166886091232,
        "seek": 98500,
        "start": 990,
        "temperature": 0,
        "text": " We could present it back to the user, to the viewer, the user of that web page in some form.",
        "tokens": [
          50614,
          492,
          727,
          1974,
          309,
          646,
          281,
          264,
          4195,
          11,
          281,
          264,
          16767,
          11,
          264,
          4195,
          295,
          300,
          3670,
          3028,
          294,
          512,
          1254,
          13,
          50914
        ]
      },
      {
        "avg_logprob": -0.15826458401150173,
        "compression_ratio": 1.6920529801324504,
        "end": 998,
        "id": 245,
        "no_speech_prob": 0.08151166886091232,
        "seek": 98500,
        "start": 996,
        "temperature": 0,
        "text": " So what I want to do is try to do a simple line chart.",
        "tokens": [
          50914,
          407,
          437,
          286,
          528,
          281,
          360,
          307,
          853,
          281,
          360,
          257,
          2199,
          1622,
          6927,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.15826458401150173,
        "compression_ratio": 1.6920529801324504,
        "end": 1004,
        "id": 246,
        "no_speech_prob": 0.08151166886091232,
        "seek": 98500,
        "start": 998,
        "temperature": 0,
        "text": " I think this will be a nice way of showing the data, and I'm going to do that with a JavaScript library called chart.js.",
        "tokens": [
          51014,
          286,
          519,
          341,
          486,
          312,
          257,
          1481,
          636,
          295,
          4099,
          264,
          1412,
          11,
          293,
          286,
          478,
          516,
          281,
          360,
          300,
          365,
          257,
          15778,
          6405,
          1219,
          6927,
          13,
          25530,
          13,
          51314
        ]
      },
      {
        "avg_logprob": -0.15826458401150173,
        "compression_ratio": 1.6920529801324504,
        "end": 1008,
        "id": 247,
        "no_speech_prob": 0.08151166886091232,
        "seek": 98500,
        "start": 1004,
        "temperature": 0,
        "text": " So before I get there, though, maybe you want to try a little exercise yourself.",
        "tokens": [
          51314,
          407,
          949,
          286,
          483,
          456,
          11,
          1673,
          11,
          1310,
          291,
          528,
          281,
          853,
          257,
          707,
          5380,
          1803,
          13,
          51514
        ]
      },
      {
        "avg_logprob": -0.15826458401150173,
        "compression_ratio": 1.6920529801324504,
        "end": 1012,
        "id": 248,
        "no_speech_prob": 0.08151166886091232,
        "seek": 98500,
        "start": 1008,
        "temperature": 0,
        "text": " Can you console log a different column of data?",
        "tokens": [
          51514,
          1664,
          291,
          11076,
          3565,
          257,
          819,
          7738,
          295,
          1412,
          30,
          51714
        ]
      },
      {
        "avg_logprob": -0.17447655236543114,
        "compression_ratio": 1.5491329479768785,
        "end": 1015,
        "id": 249,
        "no_speech_prob": 0.039043378084897995,
        "seek": 101200,
        "start": 1012,
        "temperature": 0,
        "text": " Can you load a different CSV that you found and do the same thing with?",
        "tokens": [
          50364,
          1664,
          291,
          3677,
          257,
          819,
          48814,
          300,
          291,
          1352,
          293,
          360,
          264,
          912,
          551,
          365,
          30,
          50514
        ]
      },
      {
        "avg_logprob": -0.17447655236543114,
        "compression_ratio": 1.5491329479768785,
        "end": 1021,
        "id": 250,
        "no_speech_prob": 0.039043378084897995,
        "seek": 101200,
        "start": 1015,
        "temperature": 0,
        "text": " See if you can find your own data set that you might want to play with and just get the data appearing in the console,",
        "tokens": [
          50514,
          3008,
          498,
          291,
          393,
          915,
          428,
          1065,
          1412,
          992,
          300,
          291,
          1062,
          528,
          281,
          862,
          365,
          293,
          445,
          483,
          264,
          1412,
          19870,
          294,
          264,
          11076,
          11,
          50814
        ]
      },
      {
        "avg_logprob": -0.17447655236543114,
        "compression_ratio": 1.5491329479768785,
        "end": 1025,
        "id": 251,
        "no_speech_prob": 0.039043378084897995,
        "seek": 101200,
        "start": 1021,
        "temperature": 0,
        "text": " and then you'll be ready for the next video doing something with charting it.",
        "tokens": [
          50814,
          293,
          550,
          291,
          603,
          312,
          1919,
          337,
          264,
          958,
          960,
          884,
          746,
          365,
          6927,
          278,
          309,
          13,
          51014
        ]
      },
      {
        "avg_logprob": -0.9959095120429993,
        "compression_ratio": 0.8292682926829268,
        "end": 1033,
        "id": 252,
        "no_speech_prob": 0.8072434067726135,
        "seek": 102500,
        "start": 1025,
        "temperature": 0.2,
        "text": " [♪ music playing ♪",
        "tokens": [
          50364,
          44529,
          1318,
          2433,
          220,
          158,
          247,
          103,
          50764
        ]
      },
      {
        "avg_logprob": -0.9959095120429993,
        "compression_ratio": 0.8292682926829268,
        "end": 1035,
        "id": 253,
        "no_speech_prob": 0.8072434067726135,
        "seek": 102500,
        "start": 1033,
        "temperature": 0.2,
        "text": "...and done.",
        "tokens": [
          50764,
          1097,
          474,
          1096,
          13,
          50864
        ]
      }
    ],
    "transcription": " Hello and welcome to the second video in module one of working with data and APIs in JavaScript. Now we're going to do some real stuff in this video. We did real stuff in the previous video, but the previous video was just about practicing with the Fetch API and getting some image files. We weren't really working with data, we weren't doing anything with that data yet. In this video, I want to take a look at this idea of tabular data. There are a lot of different file formats for storing data in a table format in tabular data. The one that I want to look at in this video, and probably the most, I would think it's the most common one, is CSV or comma separated value. Meaning the data, the data in the table is literally separated by commas. The first line of text, after all, this file, this CSV file is ultimately just a plain text file, might function as something like a header row. So it would have the names of the fields of data you're going to have. So it might have something like item, comma, cuteness. So you're going to have a table of things and a cuteness score. So all the rest of the lines would have the actual items and their cuteness scores. So you could have puppy, comma, 10. Kitten, comma, 10. Because we live in a world where everything has a cuteness score of 10. But I want to do something with real data. Data that's out there in the world that I can grab with the Fetch function, load onto my webpage, and do something with, for example, graph. And so the data set that I'm going to show you, it comes from NASA, National Aeronautics and Space Administration, in particular from the Goddard Institute for Space Studies. This CSV file includes the combined global average land surface air and sea surface water temperature from 1880 all the way to present. It's stored in sort of a funny way. What the values that are actually in the data set are the difference from the mean temperature. What do I mean by the mean temperature? Well, I mean the average temperature. Well, what's the average temperature? Well, it so happens that there is the average world temperature as recorded from 1951 to 1980, which also recorded and averaged by NASA, the Earth Observatory website, at 14 degrees Celsius. So the data in this CSV file is the difference from the mean, from 14 degrees Celsius, from combined land surface air and sea surface water temperature from 1880 to present. So I want to load that CSV file, parse it, graph it, and we're done. I'm going to do this in two parts. The first part that you're watching right now is just loading the CSV file, parsing it. I want to be able to see it maybe as a console log in the browser, in the Chrome developer tools. And then once I see that I have the data there, then I want to try to graph it. I'm going to graph it using a particular JavaScript library called chart.js. I'll talk about some other ways that you can choose to graph stuff then as well. If you want to follow along with coding, I'm about to start coding, you're first going to want to grab that CSV file and have it stored locally on your computer. So it's a pretty easy process. You just want to go to data.giss.nasa.gov slash GIS temp. The URL is here and in the video's description. And then you're going to scroll all the way down and find the place on the web page that says tables of global and hemispheric monthly means and zonal annual means. So there are actually a ton of different data sets on this web page, and you might explore them. And perhaps as an exercise, try doing graphing a different data set on this web page. But the one that I'm using is the last entry on that section called zonal annual means from 1880 to present. And I'm using the CSV file format. You'll notice there's also a TXT file format that's probably tab delimited so that the data records have tabs in between them instead of commas. Again, there's a variety of different formats, but the CSV is the one that I'm going to use. Time to start coding. So let's check in and see if you want to follow along. Let's check in and see if you have exactly what I have. So what I have is some boilerplate HTML. It's just a plain index.html file with a title, a head, a body, and an empty script tag. I've got links to where the data is coming from just to make sure I'm referencing and crediting properly in my code. And then I also have that CSV file itself. So I'm in Visual Studio Code, and you can see there's my index.html, and there's my CSV file in the same local directory. But you might be using a different text editor or a different environment. All of this will work as long as you have your HTML file and your CSV file. Let's take a look at that CSV file. So here's the CSV file. You can see that there are a number of columns, year, glob, which I assume stands for global, and HEM, Northern Hemisphere, et cetera, et cetera. And then you can see the columns of data each being separated by commas. So this isn't really meant to be human-readable. There are ways of viewing a CSV that's more human-readable. For example, here's how that same data looks in spreadsheet format. You might notice here, however, that it is colored. Each column has a different color. This is because I'm using a Visual Studio Code extension called Rainbow CSV, which it's as if it was, like, tailor-made for me. And I'll include a link in this video description if you want to install that extension as well so you can have things color-coded. Another thing I really like to do when I'm working with a data set for the first time is I like to give myself a test file that has much less stuff in it. Because if I want to console log and check stuff, sometimes this big file, this isn't that big of a file. It's just, you know, 1880 to 2018. But potentially, I could have, like, a really, really big data file. So something I'm going to do is I'm going to just quickly do a save as and call this test.csv. And so now you can see that I have a separate test.csv file. And I'm going to just leave two years in there. So I'm going to scroll all the way down and delete everything. And now I have a CSV file that just has three rows in it, the header row and then the data for 1880 and the data for 1881. So I'm going to work with this first. And once I have the parsing and everything I want to do working properly, then I'll load the real data. So the first step is exactly what you might think, fetch test.csv. Let's write that code. I'm going to write fetch test.csv. And then, remember, fetch returns a promise. And I can handle the resolution of that promise when it is finished loading the data with.then and any errors with.catch. But I prefer to use the await and async syntax. So I'm actually going to put this in a function called get data. I might think of a different name for that later. And I'm going to say the response equals await fetch test.csv. So I'm writing a function. Oh, and this function, I almost forgot, has to have the keyword async because it's an asynchronous function that's making asynchronous calls with the await keyword. So the response equals await fetch.test.csv. Now, you might remember on the web fetch API, there are a variety of kinds of data streams that might come in. There's a blob. There's a JSON. There's an array buffer. There's text. And this is what I want to actually use, raw text. Even though it's tabular data in CSV format, I'm going to do the parsing of it manually in my own code. So I just want to receive it as text. And that means I'm going to say const. I'm just going to say table equals. Maybe I'll just call this all data equals await response dot text. So let's console log that data. And let's call the function get data here. And then let's go and see this running actually in the browser. And here it is. And you can see, there we go. The data has been logged to the console. Now, ultimately here, there are a variety of JavaScript libraries that will parse a CSV for you. And by I mean parse, I mean figure out where all the commas are and break up the data and put it into objects and make it usable for you. D3, which is a JavaScript library for data visualization, has a parser in it. P5.js, which is a JavaScript library that I use a lot on this channel, has a load table function, which will actually parse the CSV for you. And there are many others. So I'll include some links to those in the video description. But I think it's a useful exercise right now. It's simple enough data for us to do the parsing manually with the split function. What split function? What are you talking about? So the JavaScript string class, anytime you have a piece of text in a variable in JavaScript, it's a string object, has a function called split. And that function allows you to take any arbitrary text and split it up into different elements of an array. And that's basically what we want to do. We want to split up all the rows. And then each row, we want to split up all the columns. The split function requires a single argument, a separator, or otherwise known as a delimiter. And in this case, we have two kinds of delimiters. For each row, the delimiter, the thing that differentiates one row from another, is a line break. So first, let's call split with line break. Going to my code, I can say, and I'm going to call these rows. The rows equals data.split, and I'm going to split by backslash n. So backslash n is an escape character sequence that indicates a line break or new line. Depending on your file format, you might need slash r also, which is like a carriage return. You can also use something called a regular expression here. This should also work. Instead of in quotes, if I have forward slashes, the delimiter is a regular expression. What's a regular expression? That's beyond the scope of what we're doing in this particular video, but regular expressions are so useful when doing string parsing that I will also link in this video's description to a whole series of videos that I have about that. But for now, just the backslash n in single quotes should do for us. So I'm going to say console.log rows just to make sure that works. And it does. So we can see here, we have, this is the raw text, and now this is split into an array with three elements. Each element is one line in that array. And one thing, though, we don't actually need the first row. The first row is really useful, important information for us as human beings to think about what the data is, but just for parsing it, I don't actually need it. An easy way that we can remove that first row is with the slice function. The slice function is an array function in JavaScript that makes a copy of an array, but a portion of the array from beginning to end. So I want the array all the way to the end, but I want it from the element 2, which is index 1, to the end. So in other words, what I can do is I can say data split by line break dot slice index 1. So this will basically delete the zero element and give me a copy of the array from index 1 to the end. And if we go back to the browser, we can see, there we go. We now have an array with just these two rows in it. Perfect. So what's the next step? The next step is splitting each one of these rows into all of the fields. And truth of the matter is, I only need, for what I'm doing right now, I only need the year and the difference from the mean temperature globally. And that's this data, this negative.18. So I'm now going to say for let i equal 0, i is less than rows dot length. And I'm going to just iterate over all of the rows. You know what? This would be a nice time for a for each loop. So I'm going to do rows dot for each, for each row. And once again, I'm using the ES6 JavaScript arrow syntax. So for each is a higher order function that allows me to apply something to every element of the array. And each element of the array is represented by this variable row. So if I just say console dot log row and go look in here, we can see, there we go. We're console logging each row. But that's not what I want to do. I want to say const, you know what I'm going to do? I'm going to call this row and I'm going to call this ELT for like element of the array. And I'll say row equals ELT split by commas. And then I'll console log row. So what I want to do is for each row, I want to split it up by commas. And just to be, so let's make sure that works. Let's go and we can see. Okay, so we can see that I've got both 1880 as an array and 1881 as an array. And then I want to say const year equals row index zero. And then const temp, temperature equals row index one. Let me remove the first console log to sort of clean things up a little bit. And let me run this and I should see just 1880 temperature, 1881 temperature. And that's exactly what I have here. And guess what? Now that we've worked this out, I can go and use the full data set. So I'm going to just change from test dot CSV to this more complicated file name, zone annual dot TS plus DSST dot CSV. So that's the full data set that I downloaded from the NASA website. I'm going to press save. I'm going to go back and we can see, there we go. We have every single year and the difference from the mean temperature next to it. Now I just noticed if I go all the way to the bottom, there's a little bit of an extra undefined here. So it looks like probably I need to clean up my data file a tiny bit. I'm assuming there's an extra line break at the bottom. You can see there's an extra line 141. And so I'm going to just delete that, hit save, and then we can see, there we go. Undefined is no longer appearing there. So it's important for me to mention that I have kind of created this very pre-prepared easy situation. I know that this data file has no empty data, no mistakes in it, no empty pieces. It's actually already in CSV format. Just removing that little extra line break at the end was like a tiny bit of cleanup that I needed to do. And in fact, there's a function in JavaScript that just said data.trim that would have cleaned that up for me anyway. But I do want to emphasize, what if the data actually has commas in it? So if the data has commas in it, my parsing system is going to break down. Well, there are conventions for this. CSV files actually use quotes around the information that shouldn't be split where there actually is a comma in there. You might find that your data isn't already in CSV format. You found this data you want to use, but it's a PDF. It's like scanned. Well, you're going to have to do optical character recognition to turn it into data that you can work with or transcribe it manually. This might be data that you want to collect yourself from your own sensor readings. So there is a ton of work that can go into prepping and cleaning data for a project like this. But we're getting started here in the sort of basic sense of just already having an easy-to-use data set for us. In some of the future videos, I will look at collecting your own data, and we'll see that as well. Another little quick bit of refactoring that I could do here is I think this rows variable is a little bit confusing. This is really ultimately the variable that holds the entire table. I'm taking the raw data, splitting it up into rows. That's the table. And now taking the raw data and splitting it up into rows, that's really the table that's holding all that information. So the table, this is really looking not at each element of the array. This is now looking at each row of the table. And then it would make sense to call this is splitting up. This is an array that's all the columns. So maybe I'll write that fully out. So this is columns. This is row. And then this is row.split. So I think this is a bit more clear in terms of what's actually going on here in parsing that CSV. So I'm getting the raw data as text. I'm splitting it up, putting it into a variable called data, going through each row of the table, splitting each row into its corresponding columns, and then I forgot this now has to be columns index 0, columns index 1. There we go. I think I like this better, a little bit of refactoring. This is something that's very useful to do when you're working on something. Maybe you make up some variable names as you're going and you come back and refactor it to something a bit more clear. We're ready for the next step. Now that we see the data logged there in the console, we know we could do something like add it to a DOM element. We could present it back to the user, to the viewer, the user of that web page in some form. So what I want to do is try to do a simple line chart. I think this will be a nice way of showing the data, and I'm going to do that with a JavaScript library called chart.js. So before I get there, though, maybe you want to try a little exercise yourself. Can you console log a different column of data? Can you load a different CSV that you found and do the same thing with? See if you can find your own data set that you might want to play with and just get the data appearing in the console, and then you'll be ready for the next video doing something with charting it. [♪ music playing ♪...and done.",
    "translation": null
  },
  "error": null,
  "status": "succeeded",
  "created_at": "2023-09-26T21:03:20.879421Z",
  "started_at": "2023-09-26T21:04:15.291011Z",
  "completed_at": "2023-09-26T21:09:08.834848Z",
  "webhook": "https://83ceaa0b612c.ngrok.app/?video_id=RfMkdvN-23o",
  "webhook_events_filter": [
    "completed"
  ],
  "metrics": {
    "predict_time": 293.543837
  },
  "urls": {
    "cancel": "https://api.replicate.com/v1/predictions/6i3vdfbbg3zohj2mv2svdxzkbu/cancel",
    "get": "https://api.replicate.com/v1/predictions/6i3vdfbbg3zohj2mv2svdxzkbu"
  }
}